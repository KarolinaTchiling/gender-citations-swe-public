FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Bauer, V
   Bouchara, T
   Duris, O
   Labossiere, C
   Clément, MN
   Bourdot, P
AF Bauer, Valentin
   Bouchara, Tifanie
   Duris, Olivier
   Labossiere, Charlotte
   Clement, Marie-Noelle
   Bourdot, Patrick
TI Head-mounted augmented reality to support reassurance and social
   interaction for autistic children with severe learning disabilities
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE autism; augmented reality; multisensory; mediation; social interaction;
   children; wellbeing
ID VIRTUAL ENVIRONMENTS; ADOLESCENTS; SNOEZELEN; BEHAVIOR
AB Augmented Reality (AR) is promising to complement autism approaches, but so far has mainly focused on training socio-emotional abilities for autistic children with mild learning disabilities. To better consider autistic children with severe learning disabilities and complex needs (SLN), stakeholders advise using collaborative AR sensory-based mediation approaches. Magic Bubbles is a multisensory AR environment created based on stakeholders' interviews, then adapted for a day hospital setting in collaboration with practitioners, and finally validated in terms of acceptability and usability for autistic children with SLN. In this paper, we report on our latest study that explores three main research questions: 1) To what extent can Magic Bubbles secure autistic children with SLN? 2) To what extent can Magic Bubbles prompt the dyadic relationship between an autistic child with SLN and a practitioner? 3) What is the overall quality of experience for autistic children with SLN when using Magic Bubbles? To answer these questions, seven autistic children with SLN participated in at least six weekly sessions over three months in a day hospital setting. Data collection and analysis used qualitative and quantitative methods, mainly drawing upon grounded theory to evaluate their experiences. Findings validate the three research questions, offer a detailed account of children's experiences with AR, and outline future directions.
C1 [Bauer, Valentin; Bouchara, Tifanie; Bourdot, Patrick] Univ Paris Saclay, VENISE Team, CNRS, LISN, Orsay, France.
   [Duris, Olivier; Labossiere, Charlotte; Clement, Marie-Noelle] Day Hosp Andre Boulloche, Assoc CEREP PHYMENTIN, Paris, France.
C3 Universite Paris Cite; Centre National de la Recherche Scientifique
   (CNRS); Universite Paris Saclay
RP Bauer, V (corresponding author), Univ Paris Saclay, VENISE Team, CNRS, LISN, Orsay, France.
EM valentin.bauer@lisn.fr
RI Bouchara, Tifanie/KEJ-5345-2024
OI BAUER, Valentin/0000-0002-3922-7507
FU DIM RFSI Ile de France; French government; French government
   [ANR-21-ESRE-0030 / CONTINUUM]
FX We want to thank the children who participated in the protocol, and
   their parents who agreed with their participation. We also want to thank
   the entire clinical team of the day hospital Andre Boulloche who enabled
   us to conduct this experience. This work is part of the AudioXR4TSA
   project, funded by the DIM RFSI Ile de France. This work was also
   supported by French government funding managed by the National Research
   Agency under the Investments for the Future program (PIA) under grant
   ANR-21-ESRE-0030 / CONTINUUM.
CR APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Aruanno B, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P40, DOI 10.1145/3234695.3236351
   Ayres A., 1972, Sensory integration and learning disorders
   Bailey B, 2022, REV J AUTISM DEV DIS, V9, P160, DOI 10.1007/s40489-020-00230-x
   Basadonne I, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11111459
   Bauer V, 2022, LECT NOTES COMPUT SC, V13484, P53, DOI 10.1007/978-3-031-16234-3_4
   Bauer V, 2021, INT SYM MIX AUGMENT, P254, DOI 10.1109/ISMAR-Adjunct54149.2021.00059
   Bauer V, 2023, J AUTISM DEV DISORD, V53, P2078, DOI 10.1007/s10803-022-05447-9
   Berenguer C, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176143
   Bottema-Beutel K, 2021, AUTISM ADULTHOOD, V3, P18, DOI 10.1089/aut.2020.0014
   Bozgeyikli L, 2018, IEEE T LEARN TECHNOL, V11, P133, DOI 10.1109/TLT.2017.2739747
   Brooke J., 1996, USABILITY EVALUATION, P6
   Cai YY, 2013, IEEE T NEUR SYS REH, V21, P208, DOI 10.1109/TNSRE.2013.2240700
   Cavus N, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131910532
   Coyle C, 2004, J INTELLECT DEV DIS, V29, P3, DOI 10.1080/08927020410001662642
   Daniels J, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0035-3
   Dechsling A, 2021, RES DEV DISABIL, V111, DOI 10.1016/j.ridd.2021.103885
   FLANAGAN JC, 1954, PSYCHOL BULL, V51, P327, DOI 10.1037/h0061470
   Garzotto F, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P478, DOI 10.1145/3078072.3084312
   Garzotto F, 2018, IEEE PERVAS COMPUT, V17, P38, DOI 10.1109/MPRV.2018.011591060
   Glaser B, 1967, Discovery of grounded theory strategies for qualitative research, DOI [10.4324/9780203793206, DOI 10.4324/9780203793206]
   Happé F, 2020, J CHILD PSYCHOL PSYC, V61, P218, DOI 10.1111/jcpp.13176
   Kapp S., 2019, Autistic Community and the Neurodiversity Movement
   Karami B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.665326
   Kenny L, 2016, AUTISM, V20, P442, DOI 10.1177/1362361315588200
   Khowaja K, 2020, IEEE ACCESS, V8, P78779, DOI 10.1109/ACCESS.2020.2986608
   Kouo JL, 2021, J AUTISM DEV DISORD, V51, P2829, DOI 10.1007/s10803-020-04716-9
   Krasny-Pacini A, 2018, ANN PHYS REHABIL MED, V61, P164, DOI 10.1016/j.rehab.2017.12.002
   Lancioni GE, 2002, DISABIL REHABIL, V24, P175, DOI 10.1080/09638280110074911
   Lheureux-Davidse C., 2014, AUTISMES PSYCHANALYS, P141, DOI [10.3917/eres.amy.2014.01.0141, DOI 10.3917/ERES.AMY.2014.01.0141]
   Mankoff J, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P3
   Mora-Guiard Joan, 2017, International Journal of Child-Computer Interaction, V11, P62, DOI 10.1016/j.ijcci.2016.10.006
   Neely L, 2013, RES AUTISM SPECT DIS, V7, P509, DOI 10.1016/j.rasd.2012.12.004
   Newbutt N, 2020, CYBERPSYCH BEH SOC N, V23, P23, DOI 10.1089/cyber.2019.0206
   Novakovic N, 2019, RES DEV DISABIL, V89, P51, DOI 10.1016/j.ridd.2019.03.007
   Oliver M, 2013, DISABIL SOC, V28, P1024, DOI 10.1080/09687599.2013.818773
   Parés N, 2005, IEEE T VIS COMPUT GR, V11, P734, DOI 10.1109/TVCG.2005.88
   Parsons S, 2020, DISABIL SOC, V35, P201, DOI 10.1080/09687599.2019.1624152
   Ringland KE, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P156, DOI 10.1145/3308561.3353785
   Ringland KE, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P873, DOI 10.1145/2632048.2632065
   Riva G, 2012, CYBERPSYCH BEH SOC N, V15, P69, DOI 10.1089/cyber.2011.0139
   Robertson CE, 2017, NAT REV NEUROSCI, V18, P671, DOI 10.1038/nrn.2017.112
   Rozenblatt S., 2011, ENCY CLIN NEUROPSYCH, P1395, DOI [10.1007/978-0-387-79948-3_193, DOI 10.1007/978-0-387-79948-3_193]
   Russell G, 2019, MOL AUTISM, V10, DOI 10.1186/s13229-019-0260-x
   Sahin NT, 2018, J CLIN MED, V7, DOI 10.3390/jcm7080188
   Sandbank M, 2020, PSYCHOL BULL, V146, P1, DOI 10.1037/bul0000215
   Sandgreen H, 2021, J AUTISM DEV DISORD, V51, P3138, DOI 10.1007/s10803-020-04778-9
   Schoen SA, 2019, AUTISM RES, V12, P6, DOI 10.1002/aur.2046
   Schopler E., 2010, CHILDHOOD AUTISM RAT
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Scott J., 2006, Social theory: Central issues in sociology
   Spiel Katharina, 2017, International Journal of Child-Computer Interaction, V11, P50, DOI 10.1016/j.ijcci.2016.10.007
   Spiel K, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3344919
   Tager-Flusberg H, 2017, AUTISM, V21, P852, DOI 10.1177/1362361316654605
   Wallace S, 2010, AUTISM, V14, P199, DOI 10.1177/1362361310363283
   Washington Peter, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130977
   Winnicott D.W., 1980, Playing and reality
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   World Health Organization-WHO, 1993, The ICD-10 Classification of Mental and Behavioural Disorders: Diagnostic Criteria for Research, DOI DOI 10.5664/JCSM.8986
NR 59
TC 0
Z9 0
U1 3
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 28
PY 2023
VL 4
AR 1106061
DI 10.3389/frvir.2023.1106061
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XN9
UT WOS:001023312500001
OA gold
DA 2024-07-18
ER

PT J
AU Schwajda, D
   Friedl, J
   Pointecker, F
   Jetter, HC
   Anthes, C
AF Schwajda, Daniel
   Friedl, Judith
   Pointecker, Fabian
   Jetter, Hans-Christian
   Anthes, Christoph
TI Transforming graph data visualisations from 2D displays into augmented
   reality 3D space: A quantitative study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive analytics; cross reality; user studies; cross virtuality;
   augmented reality; graphs; data visualisation
ID INFORMATION VISUALIZATION; MOTION LINES; LAYOUT; REPRESENTATION;
   NAVIGATION; OBJECT; CAVE
AB Modern video-based head-mounted displays allow users to operate along Milgram's entire reality-virtuality continuum. This opens up the field for novel cross-reality applications that distribute data analytics tasks along this continuum to combine benefits of established 2D information visualisation in the real environment with immersive analytics. In this publication, we explore this potential by transforming 2D graph data from a planar, large-scale display in the real environment into a spherical layout in augmented reality 3D space, letting it appear as if the graph is moving out of the display. We focus on design aspects of this transformation that potentially help users to form a joint mental model of both visualisations and to continue their tasks seamlessly in augmented reality. For this purpose, we implemented a framework of transformation parameters that can be categorised as follows: transformation methods, node transformation order (groupings) and different ways of visual interconnection. Variants in each of these areas were investigated in three quantitative user studies in which users had to solve a simple cluster search task. We confirmed that a visual transformation from 2D to 3D helps users to continue their tasks in augmented reality with less interruptions, and that node transformation order should be adjusted to data and task context. We further identified that users can perform tasks more efficiently when a user-controlled transformation is used, while a constant transformation with fixed duration can contribute to lower error rates.
C1 [Schwajda, Daniel; Friedl, Judith; Pointecker, Fabian; Anthes, Christoph] Univ Appl Sci Upper Austria, HIVE Res Grp, Hagenberg, Austria.
   [Jetter, Hans-Christian] Univ Lubeck, Inst Multimedia & Interact Syst, Lubeck, Germany.
C3 University of Lubeck
RP Schwajda, D; Friedl, J (corresponding author), Univ Appl Sci Upper Austria, HIVE Res Grp, Hagenberg, Austria.
EM daniel.schwajda@d-code.at; judith.friedl@fh-ooe.at
FU government of Upper Austria
FX & nbsp;This publication is a part of the X-PRO project. The project
   X-PRO is financed by research subsidies granted by the government of
   Upper Austria.
CR Ahmed A, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P81
   Andrews K, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P793, DOI 10.1109/IV.2002.1028871
   [Anonymous], 1997, NPIV 97 P 1997 WORKS, DOI DOI 10.1145/275519.275531
   Archambault D., 2018, REIMAGINING MENTAL M
   Archambault D, 2007, IEEE T VIS COMPUT GR, V13, P305, DOI 10.1109/TVCG.2007.46
   Bederson B. B., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P28, DOI 10.1109/INFVIS.1999.801854
   Belcher D, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P84, DOI 10.1109/ISMAR.2003.1240691
   Brath R, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P25, DOI 10.1109/3DVis.2014.7160096
   Bschel W., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445651
   Burcu M, 2020, PHARMACOEPIDEM DR S, V29, P1228, DOI 10.1002/pds.4975
   Burr DC, 2002, J NEUROSCI, V22, P8661
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Capece N, 2018, IEEE INT CON INF VIS, P448, DOI 10.1109/iV.2018.00084
   CARPENDALE S., 2004, INFOVIS 2004, pp3, DOI DOI 10.1109/INFVIS.2004.53
   Chalbi A, 2020, IEEE T VIS COMPUT GR, V26, P386, DOI 10.1109/TVCG.2019.2934288
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/ICSENS.2015.7370446, 10.1109/GLOCOM.2015.7417476]
   Cohn N, 2015, BRAIN RES, V1601, P73, DOI 10.1016/j.brainres.2015.01.018
   Cohn Neil, 2013, The visual language of comics: Introduction to the structure and cognition of sequential images
   Cools R, 2022, INT SYM MIX AUGMENT, P528, DOI 10.1109/ISMAR55827.2022.00069
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   De Araújo BR, 2013, COMPUT GRAPH-UK, V37, P165, DOI 10.1016/j.cag.2012.12.005
   Drogemuller A., 2018, 2018 International Symposium on Big Data Visual and Immersive Analytics (BDVA), P1, DOI [10.1109/BDVA.2018.8533895, DOI 10.1109/BDVA.2018.8533895]
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Erra U, 2019, INT J HUM-COMPUT INT, V35, P75, DOI 10.1080/10447318.2018.1429061
   Feiner S., 1991, UIST Fourth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P9, DOI 10.1145/120782.120783
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Garcia-Hernandez R.J., 2016, 2016 IEEE Aerospace Conference, IEEE, P1, DOI DOI 10.1109/AERO.2016.7500608
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gibson H, 2013, INFORM VISUAL, V12, P324, DOI 10.1177/1473871612455749
   Gomes J., 1999, WARPING MORPHING GRA
   Gross MH, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P11, DOI 10.1109/INFVIS.1997.636759
   Hachul S, 2006, LECT NOTES COMPUT SC, V3843, P235
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Henry JAG, 2010, PROCEDIA COMPUT SCI, V1, P1731, DOI 10.1016/j.procs.2010.04.195
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Hong S.-H., 2005, Graph Drawing, P471, DOI [10.1007/978-3-540-31843-9_49, DOI 10.1007/978-3-540-31843-9_49]
   Huang YJ, 2017, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2017.8031577
   Jeong CS, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P19, DOI 10.1109/INFVIS.1998.729555
   Jetter HC, 2021, ISS '21 COMPANION: COMPANION PROCEEDINGS OF THE 2021 CONFERENCE ON INTERACTIVE SURFACES AND SPACES SPONSORED, P46, DOI 10.1145/3447932.3487940
   Joos L, 2022, IEEE T VIS COMPUT GR, V28, P3651, DOI 10.1109/TVCG.2022.3203001
   Joshi P., 2006, ACM Siggraph 2006 Courses, P17, DOI 10.1145/1185657.1185857
   Kawabe T, 2007, VIS COGN, V15, P305, DOI 10.1080/13506280600591036
   Kawabe T, 2006, EXP BRAIN RES, V175, P372, DOI 10.1007/s00221-006-0673-6
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kijima R, 1997, P IEEE VIRT REAL ANN, P130, DOI 10.1109/VRAIS.1997.583062
   Kim HJ, 1998, PERCEPTION, V27, P785, DOI 10.1068/p270785
   Kister U, 2017, COMPUT GRAPH FORUM, V36, P503, DOI 10.1111/cgf.13206
   Kotlarek J, 2020, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis48177.2020.4722
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Kwon OH, 2015, IEEE PAC VIS SYMP, P63, DOI 10.1109/PACIFICVIS.2015.7156357
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168168
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lu JW, 2020, J SUPERCOMPUT, V76, P9654, DOI 10.1007/s11227-020-03226-w
   Mahmud T., 2018, 2018 INT S BIG DAT V, P1, DOI DOI 10.1109/BDVA.2018.8533893
   Malik K, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P270, DOI 10.1109/PDGC.2016.7913158
   Marriott K., 2018, IMMERSIVE ANAL
   Maurer F, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3535256
   McCloud S., 1993, Understanding Comics: The Invisible Art
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Munzner T, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P2, DOI 10.1109/INFVIS.1997.636718
   Nacenta MA, 2009, HUM-COMPUT INTERACT, V24, P170, DOI 10.1080/07370020902819882
   Nishimoto A, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357579
   Pointecker F, 2022, INT SYM MIX AUGMENT, P827, DOI 10.1109/ISMAR55827.2022.00101
   Prouzeau A, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P241, DOI 10.1145/3343055.3359709
   Reipschläger P, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P29, DOI 10.1145/3343055.3359718
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Rhyne TM, 2021, IEEE COMPUT GRAPH, V41, P125, DOI 10.1109/MCG.2021.3075258
   Riegler A., 2020, INT WORKSH CROSS REA, P1
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Santos E. D., 2022, VIS 2022 POST IEEE C, P1
   Schulz HJ, 2009, IEEE PAC VIS SYMP, P81, DOI 10.1109/PACIFICVIS.2009.4906841
   Schwotzer D, 2021, INHAL TOXICOL, V33, P33, DOI 10.1080/08958378.2020.1867260
   Seraji MR, 2022, IEEE INT SYMP M AU R, P146, DOI 10.1109/ISMAR-Adjunct57072.2022.00035
   Seraji MR, 2022, IEEE INT SYMP M AU R, P155, DOI 10.1109/ISMAR-Adjunct57072.2022.00036
   Shengzhi Wu, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3383170
   Spur M, 2022, ISPRS ANN PHOTO REM, V5-4, P235, DOI 10.5194/isprs-annals-V-4-2022-235-2022
   Tripathi S, 2014, BIOINFORMATICS, V30, P2834, DOI 10.1093/bioinformatics/btu384
   Urribarri DK, 2013, J UNIVERS COMPUT SCI, V19, P132
   Wagner JA, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P483, DOI 10.1109/VR.2018.8447558
   WALKER JQ, 1990, SOFTWARE PRACT EXPER, V20, P685, DOI 10.1002/spe.4380200705
   Wang NJ, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3531116
   Ware C, 1996, ACM T GRAPHIC, V15, P121, DOI 10.1145/234972.234975
   Ware C., 2010, INFORM VISUALIZATION
   Wasserman S., 1994, Social network analysis: Methods and applications'
   Willems SP, 2008, M&SOM-MANUF SERV OP, V10, P19, DOI 10.1287/msom.1070.0176
   Wong B, 2011, NAT METHODS, V8, P441, DOI 10.1038/nmeth.1618
   Wong C, 2017, P IMMERSIVE ANALYTIC, P1
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 95
TC 1
Z9 1
U1 4
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 28
PY 2023
VL 4
AR 1155628
DI 10.3389/frvir.2023.1155628
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YC2
UT WOS:001023326900001
OA gold
DA 2024-07-18
ER

PT J
AU Huang, CK
   Buster, TW
   Siu, KC
   Burnfield, JM
AF Huang, Chun-Kai
   Buster, Thad W.
   Siu, Ka-Chun
   Burnfield, Judith M.
TI Combining a non-immersive virtual reality gaming with motor-assisted
   elliptical exercise increases engagement and physiologic effort in
   children
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; serious gaming; engagement; electromyography; heart
   rate; joint kinematics
ID CRITICALLY-ILL-CHILDREN; CEREBRAL-PALSY; WALKING IMPLICATIONS; WII-HAB;
   IMPROVEMENTS; RECOVERY; FITNESS; STROKE; IMPACT; AUTISM
AB Virtual reality (VR) gaming is promising in sustaining children's participation during intensive physical rehabilitation. This study investigated how integration of a custom active serious gaming with a robot-motorized elliptical impacted children's perception of engagement (Intrinsic Motivation Inventory), physiologic effort (i.e., exercise speed, heart rate, lower extremity muscle activation), and joint kinematics while overriding the motor's assistance. Compared to Non-VR condition, during the VR-enhanced condition participants' perceived engagement was 23% greater (p = 0.01), self-selected speed was 10% faster (p = 0.02), heart rate was 7% higher (p = 0.08) and muscle demands increased. Sagittal plane kinematics demonstrated only a small change at the knee. This study demonstrated that VR plays an essential role in promoting greater engagement and physiologic effort in children performing a cyclic locomotor rehabilitation task, without causing any adverse events or substantial disruption in lower extremity joint kinematics. The outcomes of this study provide a foundation for understanding the role of future VR-enhanced interventions and research studies that weigh/balance the need to physiologically challenge a child during training with the value of promoting task-related training to help promote recovery of walking.
C1 [Huang, Chun-Kai] Univ Kansas, Dept Phys Therapy Rehabil Sci & Athlet Training, Med Ctr, Kansas City, KS 66045 USA.
   [Huang, Chun-Kai; Buster, Thad W.; Burnfield, Judith M.] Madonna Rehabil Hosp, Inst Rehabil Sci & Engn, Lincoln, NE 68506 USA.
   [Huang, Chun-Kai; Siu, Ka-Chun] Univ Nebraska Med Ctr, Dept Hlth & Rehabil Sci, Omaha, NE 68104 USA.
C3 University of Kansas; University of Kansas Medical Center; University of
   Nebraska System; University of Nebraska Medical Center
RP Huang, CK (corresponding author), Univ Kansas, Dept Phys Therapy Rehabil Sci & Athlet Training, Med Ctr, Kansas City, KS 66045 USA.; Huang, CK; Burnfield, JM (corresponding author), Madonna Rehabil Hosp, Inst Rehabil Sci & Engn, Lincoln, NE 68506 USA.; Huang, CK (corresponding author), Univ Nebraska Med Ctr, Dept Hlth & Rehabil Sci, Omaha, NE 68104 USA.
EM chuang7@kumc.edu; jburnfield@madonna.org
RI Huang, Chun-Kai/I-5540-2019
OI Huang, Chun-Kai/0000-0002-4220-4410; Burnfield,
   Judith/0000-0001-6184-5179; /0000-0002-6968-5760
FU National Institute on Disability and Rehabilitation Research, Department
   of Education [H133G130274]; National Institute on Disability,
   Independent Living, and Rehabilitation Research, Administration for
   Community Living [90IF0060]; Joseph R. and Barbara A. Gard Family
   Foundation
FX The contents of this work were developed, in part, under a grant
   initially received from the National Institute on Disability and
   Rehabilitation Research, Department of Education (H133G130274; Principal
   Investigator: Burnfield) and subsequently funded through a grant from
   the National Institute on Disability, Independent Living, and
   Rehabilitation Research, Administration for Community Living (90IF0060;
   Principal Investigator: Burnfield). The contents of the article do not
   necessarily represent the policy of the Department of Education or the
   Administration for Community Living, and endorsement by the federal
   government should not be assumed. Additional support was provided by
   Joseph R. and Barbara A. Gard Family Foundation.
CR Abdulsatar F, 2013, J PEDIATR REHAB MED, V6, P193, DOI 10.3233/PRM-130260
   Burnfield JM, 2018, Cardiopulm Phys Ther J, V30, P115, DOI [10.1097/CPT.0000000000000098, DOI 10.1097/CPT.0000000000000098]
   Burnfield JM, 2021, J PEDIATR REHAB MED, V14, P539, DOI 10.3233/PRM-200717
   Burnfield JM, 2019, J MED DEVICES, V13, DOI 10.1115/1.4041588
   Burnfield JM, 2018, PEDIATR PHYS THER, V30, pE1, DOI 10.1097/PEP.0000000000000541
   Burnfield JM, 2017, GAIT POSTURE, V51, P194, DOI 10.1016/j.gaitpost.2016.10.018
   Burnfield JM, 2011, PHYS THER, V91, P1604, DOI 10.2522/ptj.20100332
   Burnfield JM, 2010, PHYS THER, V90, P289, DOI 10.2522/ptj.20090033
   Cesar GM, 2020, EUR J PHYSIOTHER, V22, P124, DOI 10.1080/21679169.2018.1536764
   Deutsch JE, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00850-2
   Deutsch JE, 2017, PEDIATR PHYS THER, V29, pS23, DOI 10.1097/PEP.0000000000000387
   Fritz Stacy L, 2007, J Neurol Phys Ther, V31, P71
   Hirsch MA, 2016, PARKINSONISM RELAT D, V22, pS78, DOI 10.1016/j.parkreldis.2015.09.030
   Hislop HJ MJ., 2007, Daniels and Worthingham's muscle testing: techniques of manual examination, V8th
   Hubbard IJ, 2009, OCCUP THER INT, V16, P175, DOI 10.1002/oti.275
   Irons S.L., 2015, CARDIOPULMONARY PHYS, V26, P36, DOI [10.1097/CPT.0000000000000007, DOI 10.1097/CPT.0000000000000007]
   KADABA MP, 1989, J ORTHOP RES, V7, P849, DOI 10.1002/jor.1100070611
   Katz-Leurer M, 2003, CLIN REHABIL, V17, P735, DOI 10.1191/0269215503cr671oa
   Kim J., 2011, VIRTUAL REAL-LONDON, P419, DOI [10.5772/553, DOI 10.5772/553]
   Labruyère R, 2013, RES DEV DISABIL, V34, P3906, DOI 10.1016/j.ridd.2013.07.031
   Liu T, 2013, PERCEPT MOTOR SKILL, V116, P197, DOI 10.2466/10.25.PMS.116.1.197-209
   Monedero J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118470
   Nelson CA, 2015, J MED DEVICES, V9, DOI 10.1115/1.4030276
   Nelson CA, 2011, J MED DEVICES, V5, DOI 10.1115/1.4003693
   O'Connor CM, 2007, GAIT POSTURE, V25, P469, DOI 10.1016/j.gaitpost.2006.05.016
   Perry J, 2010, GAIT ANALYSIS: NORMAL AND PATHOLOGICAL FUNCTION, SECOND EDITION, P1
   Pfeifer CM, 2019, J MED DEVICES, V13, DOI 10.1115/1.4041337
   RICHARDS CL, 1993, ARCH PHYS MED REHAB, V74, P612, DOI 10.1016/0003-9993(93)90159-8
   Robert M, 2013, PHYS THER, V93, P1084, DOI 10.2522/ptj.20120204
   Salem Y, 2014, J PEDIATR REHAB MED, V7, P273, DOI 10.3233/PRM-140296
   Salem Y, 2012, PHYSIOTHERAPY, V98, P189, DOI 10.1016/j.physio.2012.06.003
   Schuler T, 2011, NEUROREHABILITATION, V28, P401, DOI 10.3233/NRE-2011-0670
   Shimada H, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0263-9
   Walker ML, 2010, ARCH PHYS MED REHAB, V91, P115, DOI 10.1016/j.apmr.2009.09.009
   Wuang YP, 2011, RES DEV DISABIL, V32, P2398, DOI 10.1016/j.ridd.2011.07.020
   You SH, 2005, STROKE, V36, P1166, DOI 10.1161/01.STR.0000162715.43417.91
NR 36
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 7
PY 2022
VL 3
AR 1063187
DI 10.3389/frvir.2022.1063187
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XB5
UT WOS:001023300100001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Döllinger, N
   Wolf, E
   Mal, D
   Wenninger, S
   Botsch, M
   Latoschik, ME
   Wienrich, C
AF Doellinger, Nina
   Wolf, Erik
   Mal, David
   Wenninger, Stephan
   Botsch, Mario
   Latoschik, Marc Erich
   Wienrich, Carolin
TI Resize Me! Exploring the user experience of embodied realistic
   modulatable avatars for body image intervention in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; avatar embodiment; user experience; body awareness;
   body weight perception; body weight modification; body image
   disturbance; eating and body weight disorders
ID INTEROCEPTIVE AWARENESS; EATING-DISORDERS; DISTURBANCE; OWNERSHIP;
   SCALE; REPRESENTATION; ENVIRONMENTS; PERCEPTION; ANIMATION; EXPOSURE
AB Obesity is a serious disease that can affect both physical and psychological well-being. Due to weight stigmatization, many affected individuals suffer from body image disturbances whereby they perceive their body in a distorted way, evaluate it negatively, or neglect it. Beyond established interventions such as mirror exposure, recent advancements aim to complement body image treatments by the embodiment of visually altered virtual bodies in virtual reality (VR). We present a high-fidelity prototype of an advanced VR system that allows users to embody a rapidly generated personalized, photorealistic avatar and to realistically modulate its body weight in real-time within a carefully designed virtual environment. In a formative multi-method approach, a total of 12 participants rated the general user experience (UX) of our system during body scan and VR experience using semi-structured qualitative interviews and multiple quantitative UX measures. Using body weight modification tasks, we further compared three different interaction methods for real-time body weight modification and measured our system's impact on the body image relevant measures body awareness and body weight perception. From the feedback received, demonstrating an already solid UX of our overall system and providing constructive input for further improvement, we derived a set of design guidelines to guide future development and evaluation processes of systems supporting body image interventions.
C1 [Doellinger, Nina; Mal, David; Wienrich, Carolin] Univ Wurzburg, Psychol Intelligent Interact Syst Grp, Wurzburg, Germany.
   [Wolf, Erik; Mal, David; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
   [Wenninger, Stephan; Botsch, Mario] TU Dortmund Univ, Comp Graph Grp, Dortmund, Germany.
C3 University of Wurzburg; University of Wurzburg; Dortmund University of
   Technology
RP Döllinger, N (corresponding author), Univ Wurzburg, Psychol Intelligent Interact Syst Grp, Wurzburg, Germany.; Wolf, E (corresponding author), Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
EM nina.doellinger@uni-wuerzburg.de; erik.wolf@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600; Wenninger,
   Stephan/0009-0008-2404-7117; Dollinger, Nina/0000-0002-0609-8841
FU German Federal Ministry of Education and Research in the project ViTraS
   [16SV8219, 16SV8225]; University of Wuerzburg
FX This research has been funded by the German Federal Ministry of
   Education and Research in the project ViTraS (project numbers 16SV8219
   and 16SV8225). It was further supported by the Open Access Publication
   Fund of the University of Wuerzburg.
CR Achenbach J, 2018, P EUR WORKSH VIS COM, P67
   Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Agisoft, 2021, MET PRO
   Alcañiz M, 2000, CYBERPSYCHOL BEHAV, V3, P433, DOI 10.1089/10949310050078896
   Alleva JM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139177
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2020, SPSS Statistics
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Arnold A. G., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P1003
   Autodesk, 2014, CHAR GEN
   Bailenson Jeremy N, 2004, Berkshire Encyclopedia of Human-Computer Interaction, P64, DOI DOI 10.1108/095041206106853731
   Bartl A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694617
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Botsch M., 2010, Polygon Mesh Processing
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Bouaziz S, 2014, EUROGRAPHICS TUTORIA, P1, DOI [10.2312/egt.20141021, DOI 10.1118/1.4830428]
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Cornelissen KK, 2016, BRIT J HEALTH PSYCH, V21, P555, DOI 10.1111/bjhp.12185
   Cornelissen KK, 2015, BODY IMAGE, V13, P75, DOI 10.1016/j.bodyim.2015.01.001
   Cornelissen PL, 2018, BODY IMAGE, V24, P116, DOI 10.1016/j.bodyim.2017.12.007
   De Greef S, 2006, FORENSIC SCI INT, V159, pS126, DOI 10.1016/j.forsciint.2006.02.034
   Docteur A, 2010, OBESITY, V18, P1464, DOI 10.1038/oby.2009.418
   Döllinger N, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519613
   Dollinger N., 2019, Mensch und Computer 2019-Workshopband, DOI [DOI 10.18420/MUC2019-WS-633, 10.18420/muc2019-ws-633]
   Eilers K., 1986, Zeitschrift fur Arbeitswissenschaft, P214
   Epic Games, 2021, MET HUM
   Farrell C, 2006, EUR EAT DISORD REV, V14, P289, DOI 10.1002/erv.693
   Ferrer-Garcia M, 2018, ANN REV CYBERTHERAPY, V16, P111
   Ferrer-Garcia M, 2013, J CONTEMP PSYCHOTHER, V43, P207, DOI 10.1007/s10879-013-9240-1
   Ferrer-García M, 2009, BEHAV MODIF, V33, P830, DOI 10.1177/0145445509348056
   Filippetti ML, 2017, COGNITION, V159, P1, DOI 10.1016/j.cognition.2016.11.002
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Griffen TC, 2018, CLIN PSYCHOL REV, V65, P163, DOI 10.1016/j.cpr.2018.08.006
   Halbig A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.837616
   Hayes AF, 2007, BEHAV RES METHODS, V39, P709, DOI 10.3758/BF03192961
   He Ding, 2000, INT IMMERSIVE PROJEC, P1, DOI 10.1080/09638280400009071
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Horne M, 2020, INTERNET INTERV, V19, DOI 10.1016/j.invent.2019.100295
   Hudson GM, 2020, EUR J INVEST HEALTH, V10, P579, DOI 10.3390/ejihpe10020043
   International Organization for Standardization, 2019, 159SC4 ISOTC
   Johnstone AM, 2008, J HUM NUTR DIET, V21, P256, DOI 10.1111/j.1365-277X.2008.00862.x
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Keizer A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163921
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Komaritzan M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694244
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Longo MR, 2017, Q J EXP PSYCHOL, V70, P378, DOI 10.1080/17470218.2016.1143956
   Maalin N, 2021, BEHAV RES METHODS, V53, P1308, DOI 10.3758/s13428-020-01494-1
   Maximova K, 2008, INT J OBESITY, V32, P1008, DOI 10.1038/ijo.2008.15
   Meadows A., 2018, Body image, eating, and weight: a guide to assessment, treatment, and prevention, P381
   Muller M., 2016, Proceedings of the 9th International Conference on Motion in Games, MIG'16, P55, DOI [DOI 10.1145/2994258.2994269, 10.1145/2994258.2994269]
   Neyret S, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00031
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nimcharoen C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P158, DOI 10.1109/ISMAR-Adjunct.2018.00057
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Peat CM, 2011, PSYCHOL WOMEN QUART, V35, P441, DOI 10.1177/0361684311400389
   Piryankova IV, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641568
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Preston C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199426
   Pujades S, 2019, IEEE T VIS COMPUT GR, V25, P1887, DOI 10.1109/TVCG.2019.2898748
   Putze S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376144
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Riva G, 1997, PRESENCE-TELEOP VIRT, V6, P106, DOI 10.1162/pres.1997.6.1.106
   Robinette KM., Civilian American and European Surface Anthropometry Resource (CAESAR), V1, DOI DOI 10.21236/ADA406704
   Rosen J.C., 2001, BODY IMAGE EATING DI, P425, DOI [10.1037/10502-017, DOI 10.1037/10502-017]
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sorkine O., 2005, Eurographics 2005-State of the Art Reports, V4, P53, DOI [10.2312/egst.20051044, DOI 10.2312/EGST.20051044]
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stauffert JP, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3450379
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Stefan N, 2021, NAT REV ENDOCRINOL, V17, P135, DOI 10.1038/s41574-020-00462-1
   Tanay G, 2013, PSYCHOL ASSESSMENT, V25, P1286, DOI 10.1037/a0034044
   Tang XJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4689, DOI 10.1145/3474085.3475334
   Tcha-Tokey K, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927955
   Thaler A., 2019, ROLE VISUAL CUES BOD, V56
   Thaler A., 2018, FRONT ICT, V5, P18, DOI [DOI 10.3389/FICT.2018.00018, 10.3389/fict.2018, DOI 10.3389/FICT.2018]
   Thaler A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192152
   Thompson JK, 1998, OBES RES, V6, P375, DOI 10.1002/j.1550-8528.1998.tb00366.x
   Todd J, 2019, BODY IMAGE, V31, P171, DOI 10.1016/j.bodyim.2019.10.004
   Todd J, 2019, BODY IMAGE, V29, P6, DOI 10.1016/j.bodyim.2019.02.003
   Turbyne C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.657638
   Unity Technologies, 2019, Unity
   Valtolina GG, 1998, PERCEPT MOTOR SKILL, V86, P1363, DOI 10.2466/pms.1998.86.3c.1363
   Valve Corporation, 2020, STEAMVR
   Valve Corporation, 2020, INDEX
   Venegas O, 2020, Obesity: global impact and epidemiology, P19
   Walker DC, 2018, INT J EAT DISORDER, V51, P745, DOI 10.1002/eat.22867
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Wenninger S., 2020, 26 ACM S VIRTUAL REA, P1, DOI [DOI 10.1145/3385956.3418940, 10.1145/3385956.3418940]
   WHO Consultation, 2000, WHO TECH REP SER, V894, P1
   Wiederhold BK, 2016, CYBERPSYCH BEH SOC N, V19, P67, DOI 10.1089/cyber.2016.0012
   Wienrich Carolin, 2020, i-com: Journal of Interactive Media, V19, P103, DOI 10.1515/icom-2020-0008
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
   Wolf E., 2022, 2022 IEEE INT S MIX, P1
   Wolf E, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P350, DOI 10.1109/VR51125.2022.00054
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Wolf E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR50410.2021.00027
   World Health Organization, 2019, International statistical classification of diseases and related health problems, V11th
   World Health Organization, 2021, OB OV
   Wu HY, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0204-7
   Xiao QJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1800, DOI 10.1145/3394171.3413873
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zanetti T, 2013, EUR EAT DISORD REV, V21, P32, DOI 10.1002/erv.2190
   Zhao HM, 2018, IEEE COMPUT GRAPH, V38, P77, DOI 10.1109/MCG.2018.011461529
   Zhou SZ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778863
   Zijlstra F.R.H., 1993, Efficiency in Work Behavior
   Ziser K, 2018, INT J EAT DISORDER, V51, P1121, DOI 10.1002/eat.22946
NR 117
TC 8
Z9 8
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 11
PY 2022
VL 3
AR 935449
DI 10.3389/frvir.2022.935449
PG 22
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XA0
UT WOS:001023298600001
OA gold, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU MacCallum, K
AF MacCallum, Kathryn
TI The integration of extended reality for student-developed games to
   support cross-curricular learning
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cross-curriculum; affordance; technology-enhanced learning; digital
   technologies; extended reality; student-created artefacts
ID AUGMENTED REALITY; EDUCATION; AFFORDANCES; IMMERSION; DESIGN
AB While eXtended Reality (XR) ha s been shown to provide rich promise, its adoption within the educational context for student created games is still limited. Recent advances in XR technology, especially in mobile XR tools, have made XR more accessible. These advances have also enabled the development of student-created XR experiences that provide opportunities for integrating learning with technology skills development. Through the integration of critical digital skills across the curriculum, students can demonstrate a range of learning outcomes across many different learning areas. In this study, we explore how the affordances of XR can be leveraged to enable new learning opportunities, specifically in enabling students to design their own XR learning experiences. We also explore how the added context of XR games provides additional benefits to engage and motivate learners. In this article, we identify and explore twelve affordances framed in the notions of engagement, authenticity and contextualisation. These affordances have been identified in the literature to highlight the benefits of XR and were explored in terms of how the added context of student-created games leveraged these affordances. Drawing on a wider research project, we identify three scenarios that were adopted by three teachers (Mathematics, Science and Language teacher) to teach a range of subjects that drew on XR student-created games. From this analysis, we conclude with six proposed design principles that could be adopted by other teachers to help guide them in applying a similar approach in their teaching.
C1 [MacCallum, Kathryn] Univ Canterbury, Fac Educ, Christchurch, New Zealand.
C3 University of Canterbury
RP MacCallum, K (corresponding author), Univ Canterbury, Fac Educ, Christchurch, New Zealand.
EM Kathryn.maccallum@canterbury.ac.nz
RI MacCallum, Kathryn/ABB-3506-2021
OI MacCallum, Kathryn/0000-0003-3844-7628
FU New Zealand Teaching and Learning Research Initiative (TLRI) [ID9193]
FX This study forms part of a larger research project (Experiences and
   reflections of teachers on the use of mixed reality technologies to
   foster cross-curricular learning opportunities) funded by a grant from
   the New Zealand Teaching and Learning Research Initiative (TLRI) #
   ID9193.
CR Admiraal W, 2011, COMPUT HUM BEHAV, V27, P1185, DOI 10.1016/j.chb.2010.12.013
   Ananiadou K., 2009, OECD Education Working Papers, DOI DOI 10.1787/218525261154
   Anastasiadis T., 2018, International Journal of Advances in Scientific Research and Engineering, V4, P139, DOI https://doi.org/10.31695/IJASRE.2018.33016
   [Anonymous], 2012, Educational technology, teacher knowledge, and classroom impact: A research handbook on frameworks and approaches, DOI 10.4018/978-1-60960-750-0.ch002
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Benlahcene A, 2021, J APPL RES HIGH EDUC, V13, P1290, DOI 10.1108/JARHE-06-2020-0157
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Buchholtz N., 2020, P 2020 WORLD C MOB C
   Çöltekin A, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9070439
   Cook J, 2010, INT J MOB BLENDED LE, V2, P1, DOI 10.4018/jmbl.2010070101
   Csikszentmihalyi M., 1996, CREATIVITY FLOW PSYC
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Di Natale AF, 2020, BRIT J EDUC TECHNOL, V51, P2006, DOI 10.1111/bjet.13030
   Ekaputra G., 2013, P INF SYST INT C ISI, P1
   Fluck A, 2016, EDUC TECHNOL SOC, V19, P38
   Fredricks JA, 2016, LEARN INSTR, V43, P1, DOI 10.1016/j.learninstruc.2016.02.002
   Furió D, 2013, COMPUT EDUC, V64, P24, DOI 10.1016/j.compedu.2012.12.015
   Gillis A.e., 2002, Research for nurses: Methods and interpretation
   GREENO JG, 1994, PSYCHOL REV, V101, P336, DOI 10.1037/0033-295X.101.2.336
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Herrington J., 2011, P ASCILITE HOBART 20, P594
   Jacobson J, 2017, SMART COMPUT INTELL, P35, DOI 10.1007/978-981-10-5490-7_3
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Johnson-Glenberg MC, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01819
   Kafai YB, 2015, EDUC PSYCHOL-US, V50, P313, DOI 10.1080/00461520.2015.1124022
   Kamarainen Amy., 2018, The Bulletin of the Ecological Society of America, V99, P259, DOI [DOI 10.1002/BES2.1396, 10.1002/bes2.1396]
   Kaufmann H., 2003, Collaborative augmented reality in education, P2
   Kemmis S, 2011, PROF LEARN DEV SCH H, V7, P11, DOI 10.1007/978-94-007-0805-1_2
   MacDonald C., 2012, CANADIAN J ACTION RE, V13, P34, DOI [10.33524/cjar.v13i2.37, https://doi.org/10.33524/cjar.v13i2.37, DOI 10.33524/CJAR.V13I2.37]
   Margrett JA, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.760064
   Markus ML, 2008, J ASSOC INF SYST, V9, P609
   Ministry of Education, 2017, DIGITAL TECHNOLOGIES
   Mitas O, 2018, ANN TOURISM RES, V72, P98, DOI 10.1016/j.annals.2018.07.002
   Morrison A, 2011, COMPUT GRAPH-UK, V35, P789, DOI 10.1016/j.cag.2011.04.009
   O'Neil HF., 2004, Issues in the Computer-Based Assessment of Collaborative Problem Solving
   Parsons D, 2021, ADV MED EDUC PRACT, V12, P77, DOI 10.2147/AMEP.S249891
   Petrucco C., 2016, J E LEARNING KNOWL S, V12
   Plomp T., 2007, An Introduction to Educational Design-based research. Proceedings of the seminar conducted at the East China Normal University, Shanghai (PR China), November 23-26, P9
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rivet AE, 2008, J RES SCI TEACH, V45, P79, DOI 10.1002/tea.20203
   Rosenbaum E., 2007, Journal of Science Education and Technology, V16, P31, DOI DOI 10.1007/S10956-006-9036-0
   Sánchez J, 2011, COMPUT EDUC, V57, P1943, DOI 10.1016/j.compedu.2011.04.012
   Schmidt J.A., 2010, INT ENCY ED, V3rd, P605
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Stringer E. T., 2013, Action research, V4th
   Thomas S., 2004, Learning with mobile devices: A book of papers, P173
   Tsay CHH, 2020, J COMPUT ASSIST LEAR, V36, P128, DOI 10.1111/jcal.12385
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
NR 50
TC 2
Z9 2
U1 4
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 15
PY 2022
VL 3
AR 888689
DI 10.3389/frvir.2022.888689
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WS0
UT WOS:001023290600001
OA gold
DA 2024-07-18
ER

PT J
AU Mercado, VR
   Argelaguet, F
   Casiez, G
   Lécuyer, A
AF Mercado, Victor Rodrigo
   Argelaguet, Ferran
   Casiez, Gery
   Lecuyer, Anatole
TI Watch out for the Robot! Designing Visual Feedback Safety Techniques
   When Interacting With Encountered-Type Haptic Displays
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; encountered-type haptic display; immersion; perceived
   safety; human robot interaction; visual feedback
ID VIRTUAL ENVIRONMENTS
AB Encountered-Type Haptic Displays (ETHDs) enable users to touch virtual surfaces by using robotic actuators capable of co-locating real and virtual surfaces without encumbering users with actuators. One of the main challenges of ETHDs is to ensure that the robotic actuators do not interfere with the VR experience by avoiding unexpected collisions with users. This paper presents a design space for safety techniques using visual feedback to make users aware of the robot's state and thus reduce unintended potential collisions. The blocks that compose this design space focus on what and when the feedback is displayed and how it protects the user. Using this design space, a set of 18 techniques was developed exploring variations of the three dimensions. An evaluation questionnaire focusing on immersion and perceived safety was designed and evaluated by a group of experts, which was used to provide a first assessment of the proposed techniques.
C1 [Mercado, Victor Rodrigo; Argelaguet, Ferran; Lecuyer, Anatole] Inria Rennes Bretagne Atlantique, Rennes, France.
   [Casiez, Gery] Univ Lille, Inria, CNRS, Cent Lille,UMR CRIStAL 9189, Lille, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Universite de Lille; Centrale Lille; Inria
RP Mercado, VR (corresponding author), Inria Rennes Bretagne Atlantique, Rennes, France.
EM vrmercado@outlook.com
CR Abtahi P., 2019, P ACM CHI, V1, P589, DOI [10.1145/3290605.3300589, DOI 10.1145/3290605.3300589]
   Araujo B, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P218, DOI 10.1145/2839462.2839484
   Bartneck C., 2017, MEASURING ANTHROPOMO
   Chen CJ, 2020, ROBOT CIM-INT MANUF, V64, DOI 10.1016/j.rcim.2020.101948
   Cirio G, 2012, IEEE T VIS COMPUT GR, V18, P546, DOI 10.1109/TVCG.2012.60
   Guhl J, 2018, PROC CIRP, V76, P167, DOI 10.1016/j.procir.2018.01.029
   Hartmann J., 2019, P 2019 CHI C HUM FAC, P1, DOI [10.1145/3290605.3300577, DOI 10.1145/3290605.3300577]
   Hirata R., 1996, T VIRTUAL REAL SOC J, V1, P32
   Kanamori K, 2018, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR.2018.00033
   Kang H, 2020, VISUAL COMPUT, V36, P2065, DOI 10.1007/s00371-020-01907-4
   K„stner L, 2019, Arxiv, DOI arXiv:1912.12109
   Kim Y, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1814
   Kuts V, 2017, LECT NOTES COMPUT SC, V10324, P212, DOI 10.1007/978-3-319-60922-5_16
   Lacoche J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139142
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Medeiros D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P21, DOI 10.1109/VR50410.2021.00022
   Mercado V, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P230, DOI [10.1109/VR46266.2020.00-62, 10.1109/VR46266.2020.1581077413070]
   Mercado V, 2021, IEEE T VIS COMPUT GR, V27, P2237, DOI 10.1109/TVCG.2019.2963190
   Mercado VR, 2021, IEEE T HAPTICS, V14, P449, DOI 10.1109/TOH.2021.3061150
   Moray N., 2013, Mental workload: Its theory and measurement, V8
   Oculus, 2021, OC GUARD SYST
   Oyekan JO, 2019, ROBOT CIM-INT MANUF, V55, P41, DOI 10.1016/j.rcim.2018.07.006
   Posselt J., 2017, P 14 ANN EUROVR C, P11
   Scavarelli A., 2017, P 2017 CHI C EXT ABS, P2915, DOI DOI 10.1145/3027063
   Shepherd DC, 2019, 2019 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON ROBOTICS SOFTWARE ENGINEERING (ROSE 2019), P13, DOI 10.1109/RoSE.2019.00007
   Steam, 2021, STEAMVR CHAP FAQ
   Vonach E, 2017, P IEEE VIRT REAL ANN, P74, DOI 10.1109/VR.2017.7892233
   Vosniakos GC, 2019, PROCEDIA MANUF, V38, P524, DOI 10.1016/j.promfg.2020.01.066
   Yang KT, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P499, DOI 10.1145/3242587.3242630
   Yokokohji Y, 2005, INT J ROBOT RES, V24, P717, DOI 10.1177/0278364905057123
   Yokokohji Y, 2001, P IEEE VIRT REAL ANN, P271, DOI 10.1109/VR.2001.913796
   Yokokohji Y, 1996, P IEEE VIRT REAL ANN, P46, DOI 10.1109/VRAIS.1996.490509
NR 32
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 12
PY 2022
VL 3
AR 928517
DI 10.3389/frvir.2022.928517
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AQ0
UT WOS:001019294800001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Herur-Raman, A
   Almeida, ND
   Greenleaf, W
   Williams, D
   Karshenas, A
   Sherman, JH
AF Herur-Raman, Aalap
   Almeida, Neil D. D.
   Greenleaf, Walter
   Williams, Dorian
   Karshenas, Allie
   Sherman, Jonathan H. H.
TI Next-Generation Simulation-Integrating Extended Reality Technology Into
   Medical Education
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; extended reality; medical education; simulation; 3D;
   learning; surgical training; medical school
ID VIRTUAL STANDARDIZED-PATIENT; ANATOMICAL SCIENCES; COMMUNICATION;
   STUDENTS; ENVIRONMENTS; SKILLS; TOOL
AB In recent years, the advancement of eXtended Reality (XR) technologies including Virtual and Augmented reality (VR and AR respectively) has created new human-computer interfaces that come increasingly closer to replicating natural human movements, interactions, and experiences. In medicine, there is a need for tools that accelerate learning and enhance the realism of training as medical procedures and responsibilities become increasingly complex and time constraints are placed on trainee work. XR and other novel simulation technologies are now being adapted for medical education and are enabling further interactivity, immersion, and safety in medical training. In this review, we investigate efforts to adopt XR into medical education curriculums and simulation labs to help trainees enhance their understanding of anatomy, practice empathetic communication, rehearse clinical procedures, and refine surgical skills. Furthermore, we discuss the current state of the field of XR technology and highlight the advantages of using virtual immersive teaching tools considering the COVID-19 pandemic. Finally, we lay out a vision for the next generation of medical simulation labs using XR devices summarizing the best practices from our and others' experiences.
C1 [Herur-Raman, Aalap; Almeida, Neil D. D.] George Washington Univ, GW Sch Med & Hlth Sci, Washington, DC USA.
   [Greenleaf, Walter] Stanford Univ, mediaX, Stanford, CA USA.
   [Greenleaf, Walter] Stanford Univ, Virtual Human Interact Lab, Stanford, CA USA.
   [Williams, Dorian] West Virginia Univ, Sch Med, Dept Family Med, Morgantown, WV USA.
   [Karshenas, Allie] West Virginia Univ, Dept Pharmaceut Syst & Policy, Morgantown, WV USA.
   [Sherman, Jonathan H. H.] West Virginia Univ, Berkeley Med Ctr, Dept Neurol Surg, Martinsburg, WV 25401 USA.
C3 George Washington University; Stanford University; Stanford University;
   West Virginia University; West Virginia University
RP Sherman, JH (corresponding author), West Virginia Univ, Berkeley Med Ctr, Dept Neurol Surg, Martinsburg, WV 25401 USA.
EM jsherman0620@gmail.com
RI Greenleaf, Walter/JYP-6559-2024
OI Greenleaf, Walter/0000-0002-5979-0831; Herur-Raman,
   Aalap/0000-0002-7676-8222
CR Alfalah SFM, 2019, VIRTUAL REAL-LONDON, V23, P229, DOI 10.1007/s10055-018-0359-y
   Alsoufi A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242905
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Basdogan C, 2001, IEEE-ASME T MECH, V6, P269, DOI 10.1109/3516.951365
   Bendok BR, 2014, OPER NEUROSURG, V10, P191, DOI 10.1227/NEU.0000000000000300
   Bond G, 2021, MED EDUC ONLINE, V26, DOI 10.1080/10872981.2020.1842661
   Bond WF, 2019, SIMUL HEALTHC, V14, P241, DOI 10.1097/SIH.0000000000000373
   Bracq MS, 2019, NURS EDUC TODAY, V79, P153, DOI 10.1016/j.nedt.2019.05.026
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Courteille O, 2014, BMC MED EDUC, V14, DOI 10.1186/1472-6920-14-64
   Dixon-Woods M, 2011, BMJ QUAL SAF, V20, pI47, DOI 10.1136/bmjqs.2010.046227
   Donofrio CA, 2020, OPER NEUROSURG, V19, P330, DOI 10.1093/ons/opz420
   Drake RL, 2014, ANAT SCI EDUC, V7, P321, DOI 10.1002/ase.1468
   Dubin AK, 2017, J MINIM INVAS GYN, V24, P1185, DOI 10.1016/j.jmig.2017.07.019
   Epstein RM, 2005, ANN FAM MED, V3, P415, DOI 10.1370/afm.348
   Erolin C, 2019, J VIS COMMUN MED, V42, P93, DOI 10.1080/17453054.2019.1597626
   Fertleman C, 2018, FRONT PUBLIC HEALTH, V6, DOI 10.3389/fpubh.2018.00044
   Franchi T, 2020, ANAT SCI EDUC, V13, P309, DOI 10.1002/ase.1966
   Franzeck FM, 2012, SURG ENDOSC, V26, P235, DOI 10.1007/s00464-011-1860-5
   Ghosh SK, 2017, ANAT SCI EDUC, V10, P286, DOI 10.1002/ase.1649
   Goh Poh-Sun, 2020, MedEdPublish (2016), V9, P49, DOI 10.15694/mep.2020.000049.1
   Grow Brian., 2017, Reuters
   Guedes HG, 2019, INT J SURG, V61, P60, DOI 10.1016/j.ijsu.2018.12.001
   Guetterman TC, 2019, J MED INTERNET RES, V21, DOI 10.2196/15459
   Hariri S, 2004, MED EDUC, V38, P896, DOI 10.1111/j.1365-2929.2004.01897.x
   Hauze SW, 2019, ADV EXP MED BIOL, V1120, P1, DOI 10.1007/978-3-030-06070-1_1
   Houser Jeremy J, 2018, Mo Med, V115, P61
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Iwanaga J, 2021, CLIN ANAT, V34, P108, DOI 10.1002/ca.23655
   Javan R, 2020, J DIGIT IMAGING, V33, P776, DOI 10.1007/s10278-019-00315-y
   Jean WC, 2021, NEUROSURG FOCUS, V51, DOI 10.3171/2021.5.FOCUS201036
   Jean WC, 2019, ACTA NEUROCHIR, V161, P975, DOI 10.1007/s00701-019-03887-4
   Keifenheim KE, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0443-x
   Khan R, 2019, ENDOSCOPY, V51, P653, DOI 10.1055/a-0894-4400
   Kourtesis P, 2020, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00012
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kron FW, 2017, PATIENT EDUC COUNS, V100, P748, DOI 10.1016/j.pec.2016.10.024
   Liu Y, 2018, IEEE MULTIMEDIA, V25, P8, DOI 10.1109/MMUL.2018.2873473
   Maicher K, 2017, SIMUL HEALTHC, V12, P124, DOI 10.1097/SIH.0000000000000195
   Maicher KR, 2019, MED TEACH, V41, P1053, DOI 10.1080/0142159X.2019.1616683
   McBride JM, 2018, ANAT SCI EDUC, V11, P7, DOI 10.1002/ase.1760
   McGrath JL, 2018, ACAD EMERG MED, V25, P186, DOI 10.1111/acem.13308
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nicolosi F, 2018, NEUROSURG FOCUS, V45, DOI 10.3171/2018.7.FOCUS18288
   O'Connor P, 2019, SYMP VLSI CIRCUITS, pC186, DOI 10.23919/vlsic.2019.8778092
   Ooi SZY, 2020, MED EDUC ONLINE, V25, DOI 10.1080/10872981.2020.1823089
   Pather N, 2020, ANAT SCI EDUC, V13, P284, DOI 10.1002/ase.1968
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Ramsey-Stewart G, 2010, MED J AUSTRALIA, V193, P668, DOI 10.5694/j.1326-5377.2010.tb04099.x
   Rogers EM, 2003, DIFFUSION INNOVATION
   Rushton MA, 2020, CIN-COMPUT INFORM NU, V38, P281, DOI 10.1097/CIN.0000000000000608
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Stepan K, 2017, INT FORUM ALLERGY RH, V7, P1006, DOI 10.1002/alr.21986
   Tai AX, 2021, WORLD NEUROSURG, V146, pE1335, DOI 10.1016/j.wneu.2020.11.173
   Tai AX, 2020, WORLD NEUROSURG, V134, pE144, DOI 10.1016/j.wneu.2019.09.152
   Tai AX, 2020, OPER NEUROSURG, V18, P542, DOI 10.1093/ons/opz201
   Tang Kevin S, 2020, Can Med Educ J, V11, pe81, DOI 10.36834/cmej.61705
   Theoret C, 2020, MED EDUC, V54, P591, DOI 10.1111/medu.14181
   Uchida T, 2019, ACAD MED, V94, P129, DOI 10.1097/ACM.0000000000002433
   UpSurgeOn, 2021, PROM PER
   Vargas MV, 2017, J MINIM INVAS GYN, V24, P420, DOI 10.1016/j.jmig.2016.12.016
   Vozenilek J, 2004, ACAD EMERG MED, V11, P1149, DOI 10.1197/j.aem.2004.08.003
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Wilson AB, 2018, CLIN ANAT, V31, P122, DOI 10.1002/ca.22934
   Yanagawa B, 2019, CURR OPIN CARDIOL, V34, P571, DOI 10.1097/HCO.0000000000000659
   Yarramreddy A, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P186, DOI 10.1109/SPW.2018.00034
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Zweifach Sarah M, 2019, Digit Biomark, V3, P14, DOI 10.1159/000498923
NR 71
TC 17
Z9 17
U1 5
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 7
PY 2021
VL 2
AR 693399
DI 10.3389/frvir.2021.693399
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AA6
UT WOS:001019279300001
OA gold
DA 2024-07-18
ER

PT J
AU de Castro, KN
   Brown, EDV
   Neilan, RM
   Wallace, SE
AF de Castro, Kate N.
   Donoso Brown, Elena V.
   Miller Neilan, Rachael
   Wallace, Sarah E.
TI Feasibility of Using Commercially Available Accelerometers to Monitor
   Upper Extremity Home Practice With Persons Post-stroke: A Secondary Data
   Analysis
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE accelerometers; rehabilatation; stroke; upper extremity; home exercise;
   hemiparesis
ID VALIDITY; REHABILITATION; STROKE
AB Background: Adherence to home practice rehabilitation programs is important for efficacy; however, adherence is challenging for many individuals post-stroke. Accelerometers have emerged as a potential means to support home practice. This secondary data analysis explored the use of a commercially available accelerometer with custom software to collect and analyze data to corroborate self-reported practice collected during a home program.
   Methods: The initial study was a single subject design trial that investigated the effect of preferred music listening on adherence to an upper extremity home practice program (Trial Number NCT02906956. ClinicalTrials.gov). The participants (n = 7) were post-stroke adults with aphasia and hemiparesis of the upper extremity. Participants completed home program exercises while wearing accelerometers and recorded practice times in a logbook. Data were collected, cleaned, processed, and analyzed to facilitate descriptive comparisons and clinical interpretations of accelerometer output data.
   Results: Across all participants, an average of 47% of data were captured and usable for analysis. Five out of seven participants self-reported longer practice times compared to accelerometer duration output by a mean of 66.5 s. Individual exercise set mean total angular velocity and standard deviation of acceleration demonstrated potential for use across time to monitor change.
   Conclusions: One challenge of integrating accelerometers into clinical practice is the amount of data loss and the steps for data processing. The comparisons of available accelerometer data to the self-reported logs, however, were generally representative. Future investigations should explore ways to increase data capture and accessibility of the data for feedback to the client and practitioner.
C1 [de Castro, Kate N.; Donoso Brown, Elena V.] Duquesne Univ, Rangos Sch Hlth Sci, Dept Occupat Therapy, Pittsburgh, PA 15282 USA.
   [Miller Neilan, Rachael] Duquesne Univ, McAnulty Coll Liberal Arts, Dept Math & Comp Sci, Pittsburgh, PA USA.
   [Wallace, Sarah E.] Duquesne Univ, Rangos Sch Hlth Sci, Dept Speech Language Pathol, Commun & Cognit Lab, Pittsburgh, PA USA.
C3 Duquesne University; Duquesne University; Duquesne University
RP Brown, EDV (corresponding author), Duquesne Univ, Rangos Sch Hlth Sci, Dept Occupat Therapy, Pittsburgh, PA 15282 USA.
EM donosobrowne@duq.edu
OI Miller Neilan, Rachael/0000-0003-4074-0436
FU internal Duquesne University grant from the Aging Research and Teaching
   Consortium
FX The initial study was funded through an internal Duquesne University
   grant from the Aging Research and Teaching Consortium.
CR ActiGraph, 2018, INTR CENTREPOINT INS
   Bailey RR, 2015, NEUROREHAB NEURAL RE, V29, P969, DOI 10.1177/1545968315583720
   Brown EVD, 2020, TOP STROKE REHABIL, V27, P377, DOI 10.1080/10749357.2019.1707950
   Brown EVD, 2017, TOP STROKE REHABIL, V24, P573, DOI 10.1080/10749357.2017.1366013
   Brown EDV, 2021, PHYS OCCUP THER GERI, V39, P219, DOI 10.1080/02703181.2020.1865500
   Frost R, 2017, ARCH PHYS MED REHAB, V98, P1241, DOI 10.1016/j.apmr.2016.08.482
   Gomes Tamires Teixeira, 2019, Rev. bras. ter. intensiva, V31, P456, DOI [10.5935/0103-507X.20190078, 10.5935/0103-507x.20190078]
   Gough M, 2019, AM J OCCUP THER, V73, DOI 10.5014/ajot.2019.73S1-PO8015
   Lang C.E., 2014, Upper-extremity task-specific training after stroke or disability: A manual for occupational therapy and physical therapy
   Lee SI, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2829208
   Noorkoiv M, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-144
   Perng SS, 2020, SENSOR MATER, V32, P2007, DOI 10.18494/SAM.2020.2789
   Reiterer V, 2008, EUR NEUROL, V60, P285, DOI 10.1159/000157882
   Rowe VT, 2019, AM J OCCUP THER, V73, DOI 10.5014/ajot.2019.030692
   Standen P, 2015, PHYS THER, V95, P350, DOI 10.2522/ptj.20130564
   Urbin MA, 2015, J NEUROL PHYS THER, V39, P111, DOI 10.1097/NPT.0000000000000085
   Uswatte G, 2006, ARCH PHYS MED REHAB, V87, P1340, DOI 10.1016/j.apmr.2006.06.006
   Waddell KJ, 2018, ARCH PHYS MED REHAB, V99, P1913, DOI 10.1016/j.apmr.2017.12.025
   Wallace SE, 2019, TOP STROKE REHABIL, V25, P599, DOI 10.1080/10749357.2018.1517492
NR 19
TC 0
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 21
PY 2021
VL 2
AR 642434
DI 10.3389/frvir.2021.642434
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XI0
UT WOS:001023306600001
OA gold
DA 2024-07-18
ER

PT J
AU Gagnon, HC
   Zhao, Y
   Richardson, M
   Pointon, GD
   Stefanucci, JK
   Creem-Regehr, SH
   Bodenheimer, B
AF Gagnon, Holly C.
   Zhao, Yu
   Richardson, Matthew
   Pointon, Grant D.
   Stefanucci, Jeanine K.
   Creem-Regehr, Sarah H.
   Bodenheimer, Bobby
TI Gap Affordance Judgments in Mixed Reality: Testing the Role of Display
   Weight and Field of View
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE affordances; augmented reality; virtual reality; perception; field of
   view
ID VIRTUAL ENVIRONMENTS; DISTANCE PERCEPTION; SCALE; WALKING
AB Measures of perceived affordances-judgments of action capabilities-are an objective way to assess whether users perceive mediated environments similarly to the real world. Previous studies suggest that judgments of stepping over a virtual gap using augmented reality (AR) are underestimated relative to judgments of real-world gaps, which are generally overestimated. Across three experiments, we investigated whether two factors associated with AR devices contributed to the observed underestimation: weight and field of view (FOV). In the first experiment, observers judged whether they could step over virtual gaps while wearing the HoloLens (virtual gaps) or not (real-world gaps). The second experiment tested whether weight contributes to underestimation of perceived affordances by having participants wear the HoloLens during judgments of both virtual and real gaps. We replicated the effect of underestimation of step capabilities in AR as compared to the real world in both Experiments 1 and 2. The third experiment tested whether FOV influenced judgments by simulating a narrow (similar to the HoloLens) FOV in virtual reality (VR). Judgments made with a reduced FOV were compared to judgments made with the wider FOV of the HTC Vive Pro. The results showed relative underestimation of judgments of stepping over gaps in narrow vs. wide FOV VR. Taken together, the results suggest that there is little influence of weight of the HoloLens on perceived affordances for stepping, but that the reduced FOV of the HoloLens may contribute to the underestimation of stepping affordances observed in AR.
C1 [Gagnon, Holly C.; Richardson, Matthew; Pointon, Grant D.; Stefanucci, Jeanine K.; Creem-Regehr, Sarah H.] Univ Utah, Dept Psychol, Salt Lake City, UT 84112 USA.
   [Zhao, Yu; Bodenheimer, Bobby] Vanderbilt Univ, Dept Elect Engn & Comp Sci, Nashville, TN USA.
C3 Utah System of Higher Education; University of Utah; Vanderbilt
   University
RP Gagnon, HC (corresponding author), Univ Utah, Dept Psychol, Salt Lake City, UT 84112 USA.
EM holly.gagnon@psych.utah.edu
FU Office of Naval Research [ONR-N00014-18-1-2964]
FX This work was supported in part by the Office of Naval Research under
   Grant No. ONR-N00014-18-1-2964.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   Bhargava A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P519, DOI [10.1109/VR46266.2020.00-31, 10.1109/VR46266.2020.1581293987781]
   Bhargava A, 2020, VIRTUAL REAL-LONDON, V24, P713, DOI 10.1007/s10055-020-00432-y
   Bong JH, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1886
   Buck LE, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3196885
   Chen L, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P123, DOI 10.1109/ISMAR.2017.29
   Creem-Regehr SH, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00096
   Creem-Regehr SH, 2015, PSYCHOL LEARN MOTIV, V62, P195, DOI 10.1016/bs.plm.2014.09.006
   Creem-Regehr SH, 2005, PERCEPTION, V34, P191, DOI 10.1068/p5144
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Ebrahimi E, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225170
   Franchak JM, 2012, DEV PSYCHOL, V48, P1254, DOI 10.1037/a0027530
   Gagnon HC, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P922, DOI [10.1109/VR46266.2020.00117, 10.1109/VR46266.2020.00112]
   Geuss Michael., 2010, P 7 S APPL PERCEPTIO, P61, DOI [10.1145/1836248.1836259, DOI 10.1145/1836248.1836259]
   Geuss MN, 2015, HUM FACTORS, V57, P1235, DOI 10.1177/0018720815590300
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Grechkin TY, 2013, J EXP PSYCHOL HUMAN, V39, P23, DOI 10.1037/a0029716
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   JIANG Y, 1994, PERCEPT PSYCHOPHYS, V56, P691, DOI 10.3758/BF03208362
   Jones J.A., 2011, Proc. Symposium on Applied perception in Graphics and Visualization, P29
   Jones JA, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/2983631
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Jones JB, 2012, PLANT NUTRITION AND SOIL FERTILITY MANUAL, 2ND EDITION, P119
   Jun E, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2811266
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Li BC, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3165286
   Li BC, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P55, DOI 10.1145/2804408.2804427
   Lin Q., 2011, P S APPL PERC GRAPH, DOI [10.1145/2077451.2077465, DOI 10.1145/2077451.2077465]
   LIN Q., 2013, P ACM S APPL PERCEPT, P107
   Lin QF, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2720020
   Pepe A, 2019, J DIGIT IMAGING, V32, P1008, DOI 10.1007/s10278-019-00272-6
   Plumert JM, 1997, J EXP CHILD PSYCHOL, V67, P317, DOI 10.1006/jecp.1997.2411
   Pointon G., 2018, 2018 IEEE VR 2018 workshop on perceptual and cognitive issues in AR (PERCAR), P1
   Pointon G, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225168
   Proffitt DR, 2006, PERSPECT PSYCHOL SCI, V1, P110, DOI 10.1111/j.1745-6916.2006.00008.x
   Q LIN., 2012, P ACM S APPL PERCEPT, P7
   Raudenbush S.W., 2002, Hierarchical linear models Applications and data analysis methods, VVolume 1
   Regia-Corte T, 2013, VIRTUAL REAL-LONDON, V17, P17, DOI 10.1007/s10055-012-0216-3
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Sinai MJ, 1998, NATURE, V395, P497, DOI 10.1038/26747
   Stefanucci JK, 2015, J EXP PSYCHOL-APPL, V21, P215, DOI 10.1037/xap0000051
   Stefanucci JK, 2009, PERCEPTION, V38, P1782, DOI 10.1068/p6437
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Vassallo R, 2017, PROC SPIE, V10136, DOI 10.1117/12.2255831
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   Willemsen P, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498702
   Wu B, 2004, NATURE, V428, P73, DOI 10.1038/nature02350
   Wu HS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1775, DOI [10.1109/VR.2019.8797965, 10.1109/vr.2019.8797965]
   Ziemer CJ, 2009, ATTEN PERCEPT PSYCHO, V71, P1095, DOI 10.3758/APP.71.5.1096
NR 53
TC 7
Z9 8
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 15
PY 2021
VL 2
AR 654656
DI 10.3389/frvir.2021.654656
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WQ1
UT WOS:001023288700001
OA gold
DA 2024-07-18
ER

PT J
AU Haghzare, L
   Ping, XA
   Arnison, M
   Monaghan, D
   Karlov, D
   Honson, V
   Kim, J
AF Haghzare, Leyla
   Ping, Xiaona
   Arnison, Matthew
   Monaghan, David
   Karlov, David
   Honson, Vanessa
   Kim, Juno
TI Digital fabrics for online shopping and fashion design
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE digital fabrics; perceived sheen; perceived color; specular roughness;
   online shopping; fashion design
ID PERCEPTION; REFLECTANCE
AB Improving the digital presentation of fabrics enhances the online shopping experience and, in turn, reduces textile waste. In this study, we examined how the manipulation of simple surface reflectance models can bias the perception of fabric properties simulated online in a web browser. We showed that motion and three-dimensional (3D) folds (i.e., rumple) influence the perception of sheen for different fabric types (cotton knit and satin). Also, we found complex interactions between these parameters in their effects on perceived sheen and perceived color saturation. Moreover, we showed that changing the level of specular roughness significantly influences visual perception of sheen, color and lightness, which in turn, can categorically alter perceptual judgments of material type. In contrast to visual attributes, specular roughness did not influence visually perceived tactile characteristics of digital fabrics (thickness and stretch). The knowledge gained about perceptual biases of digital fabrics from this study will inform future considerations for optimizing the fidelity of textiles depicted in digital commerce.
C1 [Haghzare, Leyla; Ping, Xiaona; Honson, Vanessa; Kim, Juno] Univ New South Wales, Sch Optometry & Vis Sci, Sensory Proc Res Lab, Kensington, NSW 2052, Australia.
   [Arnison, Matthew; Monaghan, David; Karlov, David] Bandicoot Imaging Sci, Sydney, NSW, Australia.
C3 University of New South Wales Sydney
RP Haghzare, L (corresponding author), Univ New South Wales, Sch Optometry & Vis Sci, Sensory Proc Res Lab, Kensington, NSW 2052, Australia.
EM l.haghzare@unsw.edu.au
FU This research was funded by an ARC Discovery Project grant awarded to JK
   (DP230100303).; ARC Discovery Project;  [DP230100303]
FX This research was funded by an ARC Discovery Project grant awarded to JK
   (DP230100303).
CR Aldas-Manzano Joaquin, 2011, International Journal of Internet Marketing and Advertising, V6, P352, DOI 10.1504/IJIMA.2011.043656
   Anderson BL, 2023, TRENDS COGN SCI, V27, P98, DOI 10.1016/j.tics.2022.10.005
   Anderson BL, 2009, J VISION, V9, DOI 10.1167/9.11.10
   Australian Government, 2021, MIN PRIOR LIST 2021
   Barrow Harry, 1978, Comput. Vis. Syst, V2, P2
   BLAKE A, 1990, NATURE, V343, P165, DOI 10.1038/343165a0
   Cai YY, 2023, J OPT SOC AM A, V40, pA220, DOI 10.1364/JOSAA.479972
   Devderea C., 2018, MANAG DYN KNOWL EC, V6, P471, DOI [10.25019/MDKE/6.3.07, DOI 10.25019/MDKE/6.3.07]
   Doerschner K, 2011, CURR BIOL, V21, P2010, DOI 10.1016/j.cub.2011.10.036
   García-Salirrosas EE, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14106302
   Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10
   Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3
   Garcia-Salirrosas EE, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14052638
   Hartung B., 2002, J VISION, V2, P551, DOI DOI 10.1167/2.7.551
   Honson V, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00485
   Isherwood ZJ, 2021, J VISION, V21, DOI 10.1167/jov.21.2.7
   Kasavan S, 2021, ENVIRON SCI POLLUT R, V28, P44780, DOI 10.1007/s11356-021-15303-5
   Kim J, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.817745
   Kim J, 2012, NAT NEUROSCI, V15, P1590, DOI 10.1038/nn.3221
   Kiyokawa H, 2023, VISION RES, V205, DOI 10.1016/j.visres.2022.108140
   Marlow PJ, 2013, J VISION, V13, DOI 10.1167/13.14.2
   Marlow PJ, 2012, CURR BIOL, V22, P1909, DOI 10.1016/j.cub.2012.08.009
   NICODEMU.FE, 1965, APPL OPTICS, V4, P767, DOI 10.1364/AO.4.000767
   Ohara M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.766056
   Sakano Y, 2010, J VISION, V10, DOI 10.1167/10.9.15
   Vasic N, 2019, J THEOR APPL EL COMM, V14, P70, DOI 10.4067/S0718-18762019000200107
   Wiranata Allysha., 2020, Indonesian Journal of Business and Entrepreneurship
   Xiong L, 2022, GOV INFORM Q, V39, DOI 10.1016/j.giq.2021.101654
   Xue ZB, 2014, TEXT RES J, V84, P246, DOI 10.1177/0040517513485622
NR 29
TC 0
Z9 0
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 21
PY 2023
VL 4
AR 1236095
DI 10.3389/frvir.2023.1236095
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Q5HK6
UT WOS:001057827900001
OA gold
DA 2024-07-18
ER

PT J
AU Fick, T
   Meulstee, JW
   Köllen, MH
   Van Doormaal, JAM
   Van Doormaal, TPC
   Hoving, EW
AF Fick, T.
   Meulstee, J. W.
   Kollen, M. H.
   Van Doormaal, J. A. M.
   Van Doormaal, T. P. C.
   Hoving, E. W.
TI Comparing the influence of mixed reality, a 3D viewer, and MRI on the
   spatial understanding of brain tumours
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE brain tumour; mixed reality; 3D visualization; spatial understanding;
   accuracy
AB Background: Multiple 3D visualization techniques are available that obviates the need for the surgeon to mentally transform the 2D planes from MRI to the 3D anatomy of the patient. We assessed the spatial understanding of a brain tumour when visualized with MRI, 3D models on a monitor or 3D models in mixed reality.Methods: Medical students, neurosurgical residents and neurosurgeons were divided into three groups based on the imaging modality used for preparation: MRI, 3D viewer and mixed reality. After preparation, the participants needed to position, scale, and rotate a virtual tumour inside a virtual head of the patient in the same orientation as the original tumour would be. Primary outcome was the amount of overlap between the placed tumour and the original tumour to evaluate accuracy. Secondary outcomes were the position, volume and rotation deviation compared to the original tumour.Results: A total of 12 medical students, 12 neurosurgical residents, and 12 neurosurgeons were included. For medical students, the mean amount of overlap for the MRI, 3D viewer and mixed reality group was 0.26 (0.22), 0.38 (0.20) and 0.48 (0.20) respectively. For residents 0.45 (0.23), 0.45 (0.19) and 0.68 (0.11) and for neurosurgeons 0.39 (0.20), 0.50 (0.27) and 0.67 (0.14). The amount of overlap for mixed reality was significantly higher on all expertise levels compared to MRI and on resident and neurosurgeon level also compared to the 3D viewer. Furthermore, mixed reality showed the lowest deviations in position, volume and rotation on all expertise levels.Conclusion: Mixed reality enhances the spatial understanding of brain tumours compared to MRI and 3D models on a monitor. The preoperative use of mixed reality may therefore support the surgeon to improve spatial 3D related surgical tasks such as patient positioning and planning surgical trajectories.
C1 [Fick, T.; Meulstee, J. W.; Hoving, E. W.] Princess Maxima Ctr Pediat Oncol, Dept Neurooncol, Utrecht, Netherlands.
   [Kollen, M. H.] Univ Amsterdam, Dept Neurosurg, Med Ctr, Amsterdam, Netherlands.
   [Van Doormaal, J. A. M.; Van Doormaal, T. P. C.] Univ Med Ctr Utrecht, Dept Neurosurg, Utrecht, Netherlands.
   [Van Doormaal, T. P. C.] Univ Hosp Zurich, Dept Neurosurg, Zurich, Switzerland.
C3 University of Amsterdam; Utrecht University; Utrecht University Medical
   Center; University of Zurich; University Zurich Hospital
RP Fick, T (corresponding author), Princess Maxima Ctr Pediat Oncol, Dept Neurooncol, Utrecht, Netherlands.
EM t.fick-3@umcutrecht.nl
CR Abhari K, 2015, IEEE T BIO-MED ENG, V62, P1466, DOI 10.1109/TBME.2014.2385874
   Fick T, 2021, NEUROSURG FOCUS, V51, DOI 10.3171/2021.5.FOCUS21200
   Goodell KH, 2006, J LAPAROENDOSC ADV S, V16, P94, DOI 10.1089/lap.2006.16.94
   Goras C, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-026410
   HART S G, 1988, P139
   Huotarinen Antti, 2018, Surg Neurol Int, V9, P71, DOI 10.4103/sni.sni_427_17
   Lowndes BR, 2020, ANN SURG, V271, P686, DOI 10.1097/SLA.0000000000003058
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Preim B., 2014, VISUAL COMPUTING MED, V2, DOI [10.1016/B978-0-12-415873-3.00035-3, DOI 10.1016/B978-0-12-415873-3.00035-3]
   Stadie AT, 2013, NEUROSURGERY, V72, pA63, DOI 10.1227/NEU.0b013e318270d310
   Swennen GRJ, 2009, J ORAL MAXIL SURG, V67, P2080, DOI 10.1016/j.joms.2009.06.007
   van Doormaal JAM, 2021, WORLD NEUROSURG, V156, pE9, DOI 10.1016/j.wneu.2021.07.099
   Villanueva-Meyer JE, 2017, NEUROSURGERY, V81, P397, DOI 10.1093/neuros/nyx103
   Wake N, 2019, UROLOGY, V131, P255, DOI 10.1016/j.urology.2019.06.016
   Wellens LM, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.2633
   Westby C., 2021, J MED LIBR ASSOC, V32, P10, DOI [10.1177/10483950211008345b, DOI 10.1177/10483950211008345B]
NR 16
TC 3
Z9 3
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 4
PY 2023
VL 4
AR 1214520
DI 10.3389/frvir.2023.1214520
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA P4SP1
UT WOS:001050563600001
OA gold
DA 2024-07-18
ER

PT J
AU Jang, SY
   Park, J
   Engberg, M
   MacIntyre, B
   Bolter, JD
AF Jang, So-Youn
   Park, Jisu
   Engberg, Maria
   MacIntyre, Blair
   Bolter, Jay D.
TI RealityMedia: immersive technology and narrative space
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; media studies; educational technology; history of
   writing; visualization; presence; remediation; storytelling
ID VIRTUAL ENVIRONMENTS; MUSEUM; TRAVEL
AB In this paper, we treat VR as a new writing space in the long tradition of inscription. Constructing Virtual Reality (VR) narratives can then be understood as a process of inscribing text in space, and consuming them as a process of "reading" the space. Our research objective is to explore the meaning-making process afforded by spatial narratives-to test whether VR facilitates traditional ways of weaving complex, multiple narrative strands and provides new opportunities for leveraging space. We argue that, as opposed to the linear space of a printed book, a VR narrative space is similar to the physical space of a museum and can be analyzed on three distinct levels: (1) the architecture of the space itself, (2) the collection, and (3) the individual artifacts. To provide a deeper context for designing VR narratives, we designed and implemented a testbed called RealityMedia to explore digital remediations of traditional narrative devices and the spatial, immersive, and interactive affordances of VR. We conducted task-based user study using a VR headset and follow-up qualitative interviews with 20 participants. Our results highlight how the three semantic levels (space, collection, and artifacts) can work together to constitute meaningful narrative experiences in VR.
C1 [Jang, So-Youn; Park, Jisu; MacIntyre, Blair; Bolter, Jay D.] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Engberg, Maria] Malmo Univ, Dept Comp Sci & Media Technol, Malmo, Sweden.
C3 University System of Georgia; Georgia Institute of Technology; Malmo
   University
RP Bolter, JD (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM jdbolter@gatech.edu
RI Engberg, Maria/E-2270-2016
OI Engberg, Maria/0000-0002-9859-2416; /0000-0003-2324-5337
CR [Anonymous], 2007, PROC 6 INT SPAC SYNT
   Benjamin W, 1935, A museum studies approach to heritage, P226
   Bennett Tony., 1995, BIRTH MUSEUM
   Bolter JayDavid., 2021, Reality Media: Augmented and Virtual Reality Cambridge
   Bolter JayDavid Richard Grusin., 1999, REMEDIATION UNDERSTA
   Bordwell David., 1985, CLASSICAL HOLLYWOOD
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Chronis A, 2012, J TRAVEL TOUR MARK, V29, P444, DOI 10.1080/10548408.2012.691395
   Darken R.P., 1996, P SIGCHI C HUMAN FAC, P142, DOI DOI 10.1145/238386.238459
   Dean David., 1994, Museum Exhibition: Theory and Practice
   Dog Naughty., 2013, THE LAST OF US
   Fisher JA, 2017, P IEEE VIRT REAL ANN, P379, DOI 10.1109/VR.2017.7892335
   Gnanadesikan AmaliaE., 2009, The Writing Revolution: Cuneiform to the Internet
   HILLIER B, 2003, 4 INT SPAC SYNT S LO
   Hillier Bill., 2006, COMPANION MUSEUM STU, P282
   Hooper-Greenhill E., 2000, Museums and the Interpretation of Visual Culture, Museum Meanings
   Huang Yu-Chun, 2014, Communications in Computer and Information Science, DOI [10.1007/978-3-319-07857-1_102, DOI 10.1007/978-3-319-07857-1_102]
   Jansen-Osmann P, 2002, COMPUT HUM BEHAV, V18, P427, DOI 10.1016/S0747-5632(01)00055-3
   Jenkins Henry, 2006, CONVERGENCE CULTURE
   Jensen MM, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173798
   Kersten TP, 2017, INT ARCH PHOTOGRAMM, V42-2, P361, DOI 10.5194/isprs-archives-XLII-2-W3-361-2017
   Khorloo O, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2087
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lu FQ, 2017, FRONT ARCHIT RES, V6, P442, DOI 10.1016/j.foar.2017.08.002
   Luik J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300471
   Manovich L, 2013, International Texts in Critical Media Aesthetics, V5
   McCall V, 2014, MUS MANAG CURATORSHI, V29, P19, DOI 10.1080/09647775.2013.869852
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Murray J., 1997, The Future of Narrative in Cyberspace
   Murray JanetH., 2004, First Person: New Media as Story, Performance, and Game, P2
   National Center for Civil and Human Rights, 2022, About the center
   Nielsen J. K., 2014, Museological Review, P22
   Nielsen JK, 2017, MUS MANAGE CURATOR, V32, P440, DOI 10.1080/09647775.2017.1284019
   Noy C, 2021, NARRAT INQ, V31, P287, DOI 10.1075/ni.19121.noy
   Pan ZG, 2009, IEEE COMPUT GRAPH, V29, P91, DOI 10.1109/MCG.2009.103
   Psarra S., 2000, ARQ, V4, P123, DOI [https://doi.org/10.1017/S1359135500002578, DOI 10.1017/S1359135500002578]
   Psarra Sophia., 2005, Reshaping museum space: architecture, design, exhibitions, P78
   Ferrándiz RR, 2014, COMMUN SOC-SPAIN, V27, P73, DOI 10.15581/003.27.4.73-94
   Schorch P, 2013, MUS MANAG CURATORSHI, V28, P193, DOI 10.1080/09647775.2013.776797
   Sookhanaphibarn K, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P185, DOI 10.1109/CW.2009.58
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Tuan Y.F., 1977, Space and Place: The Perspective of Experience
   Tzortzi K, 2014, MUS MANAG CURATORSHI, V29, P327, DOI 10.1080/09647775.2014.939844
   Urban R., 2007, MUSEUMS WEB 2007 P
   Walczak K, 2006, COMPUTER, V39, P93, DOI 10.1109/MC.2006.108
   Wineman JD, 2010, ENVIRON BEHAV, V42, P86, DOI 10.1177/0013916509335534
   Witcomb A., 1994, Social Semiotics, Vol, V4, No, P239, DOI [10.1080/10350339409384436, DOI 10.1080/10350339409384436]
   Wolff A., 2013, ANN C MUS WEB
   Xu J, 2022, CHI C HUM FACT COMP, P1
NR 51
TC 0
Z9 0
U1 4
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 22
PY 2023
VL 4
AR 1155700
DI 10.3389/frvir.2023.1155700
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA S5TI8
UT WOS:001071784800001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Suga, Y
   Takeuchi, M
   Tanaka, S
   Kajimoto, H
AF Suga, Yui
   Takeuchi, Masahiro
   Tanaka, Satoshi
   Kajimoto, Hiroyuki
TI Softness presentation by combining electro-tactile stimulation and force
   feedback
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE softness; force sensation; transcutaneous electrical stimulation;
   haptics; virtual reality
ID DISCRIMINATION; PERCEPTION
AB To provide realistic tactile sensations in a virtual environment, it is necessary to stimulate both the cutaneous and proprioceptive senses. This study focuses on a realistic method of presenting softness through the use of electro-tactile stimulation. Our system combines a force-feedback device with an electric stimulator to create a soft sensation by applying a reaction force and spreading cutaneous sensation based on the amount of indentation. We measured the change in the contact area of gel samples and used electric stimulation to reproduce the increase in the contact area of the sample. We conducted a psychophysical experiment to evaluate the effectiveness of the combination of cutaneous and force sensations and confirmed that the sensation of softness was enhanced by the simultaneous presentation.
C1 [Suga, Yui; Takeuchi, Masahiro; Tanaka, Satoshi; Kajimoto, Hiroyuki] Univ Electrocommun, Dept Informat, Chofu, Japan.
   [Tanaka, Satoshi] Japan Soc Promot Sci JSPS, Chiyoda, Tokyo, Japan.
C3 University of Electro-Communications - Japan; Japan Society for the
   Promotion of Science
RP Suga, Y (corresponding author), Univ Electrocommun, Dept Informat, Chofu, Japan.
EM suga@kaji-lab.jp
FU JSPS KAKENHI [JP20H05957]; Grants-in-Aid for Scientific Research
   [20H05957] Funding Source: KAKEN
FX This research was supported by JSPS KAKENHI (Grant Numbers JP20H05957).
CR Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Bicchi A, 2000, IEEE T ROBOTIC AUTOM, V16, P496, DOI 10.1109/70.880800
   Cornman J, 2017, I IEEE EMBS C NEUR E, P300, DOI 10.1109/NER.2017.8008350
   Debus T, 2002, P SOC PHOTO-OPT INS, V4570, P42, DOI 10.1117/12.454744
   Friedman RM, 2008, EXP BRAIN RES, V191, P133, DOI 10.1007/s00221-008-1507-5
   Fritschi M., 2006, EUROHAPTICS INT C EH, P607
   Fujita K., 2001, 5th World Multiconference on Systemics, Cybernetics and Informatics, P78
   Hauser SC, 2016, IEEE HAPTICS SYM, P247, DOI 10.1109/HAPTICS.2016.7463185
   Hauser SC, 2018, IEEE T HAPTICS, V11, P232, DOI 10.1109/TOH.2017.2715845
   Ikei Y, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P327, DOI 10.1109/HAPTIC.2002.998976
   Kajimoto H, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P587, DOI 10.1109/WHC49131.2021.9517192
   Kim Y., 2006, P EUROHAPTICS PAR FR
   Kyung K.-U., 2005, EFFECTIVELY DISPLAY
   Kyung KU, 2006, LECT NOTES COMPUT SC, V4072, P132
   Lin WK, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abp8738
   Liu J, 2007, 2007 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, P559
   MCNEAL DR, 1976, IEEE T BIO-MED ENG, V23, P329, DOI 10.1109/TBME.1976.324593
   Nakagaki K, 2019, TEI'19: PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P615, DOI 10.1145/3294109.3295621
   Park J, 2018, IEEE T HAPTICS, V11, P518, DOI 10.1109/TOH.2018.2854721
   Root SE, 2018, ACS OMEGA, V3, P662, DOI 10.1021/acsomega.7b01773
   Sato K, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P3
   Scilingo EP, 2010, IEEE T HAPTICS, V3, P109, DOI 10.1109/ToH.2010.2
   SRINIVASAN MA, 1995, J NEUROPHYSIOL, V73, P88, DOI 10.1152/jn.1995.73.1.88
   Takei S., 2015, HAPTIC INTERACTION, P91
   Tezuka M, 2017, SENSOR ACTUAT A-PHYS, V258, P32, DOI 10.1016/j.sna.2017.02.021
   Tiest WMB, 2008, LECT NOTES COMPUT SC, V5024, P255, DOI 10.1007/978-3-540-69057-3_30
   Tiest WMB, 2009, IEEE T HAPTICS, V2, P189, DOI 10.1109/ToH.2009.16
   Tirado Jonathan, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P442, DOI 10.1007/978-3-030-58147-3_49
   Withana A, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/3242587.3242645
   Xu C, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008848
   Xu C, 2020, IEEE T HAPTICS, V13, P4, DOI 10.1109/TOH.2019.2959767
   Yao KM, 2022, NAT MACH INTELL, V4, P893, DOI 10.1038/s42256-022-00543-y
   Yem V., 2018, 2018 IEEE C VIRT REA
   Yem V, 2017, IEEE T HAPTICS, V10, P130, DOI 10.1109/TOH.2016.2605084
   Zhu LF, 2022, IEEE T VIS COMPUT GR, V28, P3928, DOI 10.1109/TVCG.2022.3203087
NR 35
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 24
PY 2023
VL 4
AR 1133146
DI 10.3389/frvir.2023.1133146
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YI7
UT WOS:001023333500001
OA gold
DA 2024-07-18
ER

PT J
AU Reaver, K
AF Reaver, Kai
TI Augmented reality as a participation tool for youth in urban planning
   processes: Case study in Oslo, Norway
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; mixed reality; smart city; user participation; urban
   planning; participatory planning; interaction design
ID PUBLIC-PARTICIPATION
AB Augmented reality (AR) allows objects to be digitally simulated in the real world through smartphones, tablets, and headsets. While there are interesting AR technology case studies in participatory urban planning, this type of research has yet to be conducted within a real-life municipal planning scenario. Following the UN Habitat recommendation that further studies in AR as a participatory tool seek to integrate planning with real citizens, we studied the use of AR for the Oslo Trees plan in Norway. The case study consists of field work with AR between 2020 and 2021 over five weeks, with five different groups of youth participants from eight different districts of Oslo, who were tasked with planning a portion of Oslo's 100,000 new trees. We document how these youths used AR in films, images, drawings, interviews, screen recordings, and recorded presentations. We find that AR is a highly intuitive tool for these youth user groups in design and planning and how the AR schemes impacted the final design of the plan. The use of AR aided users' ability to generate their own planning proposals on site at scale; nearly all participants increased their understanding of participation, urban planning, architecture, and design in the workshops. In addition, the youths experienced an increased sense of confidence in displaying their design intentions and appreciated being given control of the planning process. However, we also found that location tracking and positioning in AR is imprecise and often "buggy" in the current state of the technology, causing irritation among users. Furthermore, despite the high degree of control afforded to users through AR, experts were still needed to verify which tree proposals were viable, offering important insights into how AR could be designed in the future. We conclude with a discussion on opportunities and barriers for the implementation of AR in participatory urban planning, pointing to the need for a more coordinated and holistic approach to both AR technology development and planning policy if the technology is to be developed further for participatory urban planning.
C1 [Reaver, Kai] Oslo Sch Architecture & Design, Oslo, Norway.
C3 Oslo School of Architecture & Design
RP Reaver, K (corresponding author), Oslo Sch Architecture & Design, Oslo, Norway.
EM kai.reaver@aho.no
OI Reaver, Kai/0000-0002-6699-2554
FU Oslo municipality; Municipality of Oslo
FX Oslo municipality provided some funding for technical costs attributed
   to the case. Municipality of Oslo recruited and funded the youth
   participants and their support staff.
CR Al-Kodmany K, 1999, LANDSCAPE URBAN PLAN, V45, P37, DOI 10.1016/S0169-2046(99)00024-9
   [Anonymous], 2017, FUNDAMENTALS WEARABL
   Apple, 2017, FUT IS HER IPHONE 10
   Aristotle, 1905, Aristotle's politics
   ARNSTEIN SR, 1969, J AM I PLANNERS, V35, P216, DOI 10.1080/01944366908977225
   Ausland K, 2019, HVORDAN KAN VIRTUELL
   Azuma R. T., 1997, VIRTUALITY PRESENCE
   Barneombudet, 2018, MEDV
   Berck C., 2017, THESIS U NEBRASKA NE
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Boullier D., 2016, SOCIOLOGIE NUMERIQU
   Brooks R. A., 1990, Robotics and Autonomous Systems, V6, P3, DOI 10.1016/S0921-8890(05)80025-9
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Bygdas A. L., 2022, UNG MEDVIRKNING NORS
   Cardon D., 2015, QUOI REVENT ALGORTIH
   Cardullo P, 2019, GEOJOURNAL, V84, P1, DOI 10.1007/s10708-018-9845-8
   Cele S, 2015, CHILD GEOGR, V13, P14, DOI 10.1080/14733285.2013.827873
   Conroy MM, 2006, ENVIRON PLANN C, V24, P371, DOI 10.1068/c1k
   Cortesi S., 2021, YOUTH EXTENDED REALI
   Cullingworth B., 2006, TOWN COUNTRY PLANNIN, V14
   Depena I. T., 2016, LAPSE PROJECT DESCRI
   Englebart D., 1963, CONCEPTUAL FRAMEWORK
   Ertiö TP, 2015, PLAN PRACT RES, V30, P303, DOI 10.1080/02697459.2015.1052942
   Evans-Cowley J, 2010, PLAN PRACT RES, V25, P397, DOI 10.1080/02697459.2010.503432
   Hagen A. L., 2021, UNG MEDVIRKING KREAT
   Hasler S. C. J., 2017, Civil Engineering and Architecture, V5, P230
   HAY R, 2017, PATHWAYS POE VALUE A
   Holman N, 2013, LOCAL GOV STUD, V39, P71, DOI 10.1080/03003930.2012.675330
   Jacobs Jane, 1961, The Death and life of Great American Cities
   Jutraz A, 2015, LECT NOTES GEOINF CA, P391, DOI 10.1007/978-3-319-18368-8_21
   Kara N., 2007, CHILDREN YOUTH ENV, V17, P563
   Kato H, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P340, DOI 10.1109/ISMAR.2003.1240750
   Kemp S., 2018, Digital in 2018: World's internet users pass the 4 billiom mark
   King S., 1989, CODESIGN PROCESS DES
   Landry C., 2016, DIGITIZED CITY INFLU
   Martinussen E. S., 2019, TRUST IS WORK DESIGN
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Norwegian Ministry of Municipal Affairs and Modernization, 2014, MEDV PLANL
   Nyberg M., 2019, MIXED REALITY PUBLIC
   Pokric B, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P803, DOI 10.1109/WAINA.2014.127
   Reaver K, 2020, ECAADE P ECAAD 2020
   Reaver K., 2022, BUILDINGS MDPI, V12, P1
   Roberts CJ, 2019, ENG CONSTR ARCHIT MA, V26, P2084, DOI 10.1108/ECAM-09-2018-0390
   Scheie M., 2005, FNS BARNEKONVENSJON
   Schmidt L., 2011, MEDVIRKNING PLANPROS
   Shin S, 2017, AUTOMAT CONSTR, V74, P55, DOI 10.1016/j.autcon.2016.11.005
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Sutton JE, 2010, J EXP PSYCHOL LEARN, V36, P1097, DOI 10.1037/a0019938
   Townsend A. M., 2013, Smart Cities: Big Data, Civic hackers, and the Quest for a New Utopia
   Ursin M, 2019, GATEBARNET SOM OFFER
   Wilson A, 2019, ENVIRON PLAN B-URBAN, V46, P286, DOI 10.1177/2399808317712515
   World Bank, 2022, URB DEV OV
   World Economic Forum, 2022, THIS CHART SHOWS IMP
   Yin R. K., 2017, CASE STUDY RES DESIG
NR 54
TC 1
Z9 1
U1 3
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 13
PY 2023
VL 4
AR 1055930
DI 10.3389/frvir.2023.1055930
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RH6
UT WOS:001023149600001
OA gold
DA 2024-07-18
ER

PT J
AU Hughes, CE
   Dieker, LA
   Glavey, EM
   Hines, RA
   Wilkins, I
   Ingraham, K
   Bukaty, CA
   Ali, K
   Shah, SC
   Murphy, J
   Taylor, MS
AF Hughes, Charles E. E.
   Dieker, Lisa A. A.
   Glavey, Eileen M. M.
   Hines, Rebecca A. A.
   Wilkins, Ilene
   Ingraham, Kathleen
   Bukaty, Caitlyn A. A.
   Ali, Kamran
   Shah, Sachin
   Murphy, John
   Taylor, Matthew S. S.
TI RAISE: Robotics & AI to improve STEM and social skills for elementary
   school students
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual learning environment; artificial intelligence; autism spectrum
   disorder; communication skills; digital puppetry; robotics; single case
   study design; visual programming
ID SPECTRUM DISORDERS; RECOGNITION; SCIENCE
AB The authors present the design and implementation of an exploratory virtual learning environment that assists children with autism (ASD) in learning science, technology, engineering, and mathematics (STEM) skills along with improving social-emotional and communication skills. The primary contribution of this exploratory research is how educational research informs technological advances in triggering a virtual AI companion (AIC) for children in need of social-emotional and communication skills development. The AIC adapts to students' varying levels of needed support. This project began by using puppetry control (human-in-the-loop) of the AIC, assisting students with ASD in learning basic coding, practicing their social skills with the AIC, and attaining emotional recognition and regulation skills for effective communication and learning. The student is given the challenge to program a robot, Dash (TM), to move in a square. Based on observed behaviors, the puppeteer controls the virtual agent's actions to support the student in coding the robot. The virtual agent's actions that inform the development of the AIC include speech, facial expressions, gestures, respiration, and heart color changes coded to indicate emotional state. The paper provides exploratory findings of the first 2 years of this 5-year scaling-up research study. The outcomes discussed align with a common approach of research design used for students with disabilities, called single case study research. This type of design does not involve random control trial research; instead, the student acts as her or his own control subject. Students with ASD have substantial individual differences in their social skill deficits, behaviors, communications, and learning needs, which vary greatly from the norm and from other individuals identified with this disability. Therefore, findings are reported as changes within subjects instead of across subjects. While these exploratory observations serve as a basis for longer term research on a larger population, this paper focuses less on student learning and more on evolving technology in AIC and supporting students with ASD in STEM environments.
C1 [Hughes, Charles E. E.; Ali, Kamran; Shah, Sachin; Murphy, John] Univ Cent Florida, Coll Grad Studies, Sch Modeling Simulat & Training, Synthet Real Lab, Orlando, FL 32816 USA.
   [Hughes, Charles E. E.; Ali, Kamran; Shah, Sachin; Murphy, John] Univ Cent Florida, Coll Engn & Comp Sci, Dept Comp Sci, Orlando, FL 32816 USA.
   [Hughes, Charles E. E.; Dieker, Lisa A. A.; Hines, Rebecca A. A.; Ingraham, Kathleen; Bukaty, Caitlyn A. A.] Univ Cent Florida, Coll Community Innovat & Educ, Ctr Res Educ Simulat Technol, Orlando, FL 32816 USA.
   [Glavey, Eileen M. M.] Univ S Florida, Dept Language Literacy EdD Except Educ & Phys Educ, Tampa, FL USA.
   [Wilkins, Ilene] UCP Cent Florida, Orlando, FL USA.
   [Taylor, Matthew S. S.] Salva Regina Univ, Dept Special Educ, Newport, RI USA.
C3 State University System of Florida; University of Central Florida; State
   University System of Florida; University of Central Florida; State
   University System of Florida; University of Central Florida; State
   University System of Florida; University of South Florida
RP Hughes, CE (corresponding author), Univ Cent Florida, Coll Grad Studies, Sch Modeling Simulat & Training, Synthet Real Lab, Orlando, FL 32816 USA.; Hughes, CE (corresponding author), Univ Cent Florida, Coll Engn & Comp Sci, Dept Comp Sci, Orlando, FL 32816 USA.; Hughes, CE (corresponding author), Univ Cent Florida, Coll Community Innovat & Educ, Ctr Res Educ Simulat Technol, Orlando, FL 32816 USA.
EM Charles.Hughes@ucf.edu
OI Ingraham, Kathleen/0000-0003-4197-2335
FU National Science Foundation [2120240, 2114808, 1725554]; U.S. Department
   of Education [P116S210001, H327S210005, H327S200009H]
FX This research was supported in part by grants from the National Science
   Foundation Grants # 2120240, 2114808, 1725554, and from the U.S.
   Department of Education Grants #P116S210001, H327S210005, H327S200009H.
   Any opinions, findings, and conclusions or recommendations expressed in
   this material are those of the authors and do not necessarily reflect
   the views of the sponsors.
CR Abualsamid A., 2018, ADV INTELLIGENT SYST, V794, P871
   Acar C, 2017, J SPEC EDUC, V50, P215, DOI 10.1177/0022466916649164
   Ali Kamran, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P501, DOI 10.1007/978-3-030-64556-4_39
   Ali K, 2021, INT C PATT RECOG, P9460, DOI 10.1109/ICPR48806.2021.9412172
   Anderson K, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P506, DOI 10.1145/3340555.3358662
   [Anonymous], 2004, Individuals with Disabilities Education Act
   [Anonymous], 2013, Diagnostic and Statistical Manual of Mental Disorders: DSM-5, P87, DOI [10.1176/appi.books.9780890425596.893619, DOI 10.1176/APPI.BOOKS.9780890425596, 10.1176/appi.books.9780890425596]
   [Anonymous], 2019, Occupational outlook handbook
   Bai MC, 2019, IEEE IMAGE PROC, P31, DOI [10.1109/icip.2019.8802941, 10.1109/ICIP.2019.8802941]
   Baskoro R. A., 2021, J ELEM ED, V4, P549, DOI [10.23887/ijee.v414.32568, DOI 10.23887/IJEE.V414.32568]
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Belpaeme T, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat5954
   Ben-Ari M., 2018, Elements of Robotics, P1, DOI [10.1007/978-3-319-62533-1_1, DOI 10.1007/978-3-319-62533-1_1]
   Bers Marina Umaschi, 2010, New Dir Youth Dev, V2010, P1, DOI 10.1002/yd.369
   Bulagang AF, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00401-x
   Ciftci Umur Aybars, 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P540, DOI 10.1007/978-3-030-33720-9_42
   Dieker LA, 2019, INT J GAMING COMPUT-, V11, P1, DOI 10.4018/IJGCMS.2019100101
   Donnermann M, 2022, FRONT ROBOT AI, V9, DOI 10.3389/frobt.2022.831633
   Geist E., 2016, Childhood Education, V92, P298, DOI [DOI 10.1080/00094056.2016, DOI 10.1080/00094056.2016.1208008, https://doi.org/10.1080/00094056.2016.1208008]
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Hughes CE, 2015, LECT NOTES COMPUT SC, V8844, P133, DOI 10.1007/978-3-319-17043-5_8
   Humphrey N, 2011, AUTISM, V15, P397, DOI 10.1177/1362361310387804
   Ingraham K. M., 2021, CURRENT PROSPECTIVE, P118
   Keating CT, 2020, CHILD ADOL PSYCH CL, V29, P557, DOI 10.1016/j.chc.2020.02.006
   Khalil A, 2020, IEEE ACCESS, V8, P130751, DOI 10.1109/ACCESS.2020.3006051
   Krzeminska A., 2020, Industry and Higher Education, P229, DOI [DOI 10.1007/978-981-15-0874-5_11, 10.1007/978-981-15-0874-5_11]
   Laugeson EA, 2015, J AUTISM DEV DISORD, V45, P3978, DOI 10.1007/s10803-015-2504-8
   LEVENSON RW, 1990, PSYCHOPHYSIOLOGY, V27, P363, DOI 10.1111/j.1469-8986.1990.tb02330.x
   Lin JJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6453, DOI 10.1109/ICASSP.2018.8461733
   Lye SY, 2014, COMPUT HUM BEHAV, V41, P51, DOI 10.1016/j.chb.2014.09.012
   makewonder.com, BLOCKLY
   Meyer A., 2014, UNIVERSAL DESIGN LEA
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Mutluer T, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.856208
   Nezami OM, 2020, LECT NOTES ARTIF INT, V11908, P273, DOI 10.1007/978-3-030-46133-1_17
   Nojavanasghari B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P137, DOI 10.1145/2993148.2993168
   Odom SL, 2015, J AUTISM DEV DISORD, V45, P3805, DOI 10.1007/s10803-014-2320-6
   Odom SL, 2013, EXCEPT CHILDREN, V79, P233, DOI 10.1177/001440291307900207
   Ola L, 2020, AUTISM, V24, P2021, DOI 10.1177/1362361320932727
   Rahayu S., 2018, International Journal of Trends in Mathematics Education Research, V1, P19, DOI DOI 10.33122/IJTMER.V1I1.27
   Rose D.Meyer., 2008, A practical reader in Universal Design for Learning
   Scassellati B, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat7544
   Seraj M, 2019, 19TH KOLI CALLING CONFERENCE ON COMPUTING EDUCATION RESEARCH (KOLI CALLING 2019), DOI 10.1145/3364510.3364515
   Severson HH, 2007, J SCHOOL PSYCHOL, V45, P193, DOI 10.1016/j.jsp.2006.11.003
   Shu L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030718
   Strawhacker A, 2015, INT J TECHNOL DES ED, V25, P293, DOI 10.1007/s10798-014-9287-7
   Sullivan FR, 2016, J RES TECHNOL EDUC, V48, P105, DOI 10.1080/15391523.2016.1146563
   Syriopoulou-Delli CK, 2022, INT J DEV DISABIL, V68, P73, DOI 10.1080/20473869.2019.1706333
   Taylor MS, 2018, J SPEC EDUC, V52, P78, DOI 10.1177/0022466918761120
   Taylor MS, 2017, J SPEC EDUC TECHNOL, V32, P149, DOI 10.1177/0162643417704439
   Torrado JC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061359
   Valencia K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204485
   Works Teaching., 2014, HIGH LEVERAGE PRACTI
   Zhu JP, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/ab1887
NR 54
TC 9
Z9 9
U1 16
U2 29
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 14
PY 2022
VL 3
AR 968312
DI 10.3389/frvir.2022.968312
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4SJ9
UT WOS:001023178000001
DA 2024-07-18
ER

PT J
AU Cocquyt, CM
   Youngson, N
   Sutton, JE
AF Cocquyt, Chantelle M.
   Youngson, Nicole
   Sutton, Jennifer E.
TI Sex Differences and Cognitive Maps: Studies in the Lab don't Always
   Reflect Cognitive Map Accuracy in Everyday Life
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE spatial cognition; cognitive map; virtual environment; navigation; sex
   differences
ID INDIVIDUAL-DIFFERENCES; MENTAL ROTATION; PEOPLE
AB The ability to create an accurate mental survey representation, or cognitive map, when moving through an environment varies widely across individuals, and we are still trying to understand the origins of these individual differences. Non-immersive virtual environments used to test for cognitive map accuracy in the laboratory have shown sex differences with a performance advantage for men in some studies but not others. When sex differences are demonstrated, it is unclear whether women's performance generalizes to familiar and unfamiliar real-world environments. In Experiment 1, 98 participants explored the virtual environment Silcton and afterwards estimated directions between the landmarks in Silcton and arranged landmarks found in Silcton on a map. In addition, they reported frequently visited real-world locations and then estimated directions between them and drew a map of the locations. Men were more accurate on tests of Silcton than women were, although there was no difference between sexes for accuracy with real-world locations. Within sexes, women were more accurate with the real-world locations than Silcton, while men showed the opposite pattern. In Experiment 2, 21 women were tested with Silcton and their familiar real-world locations as in Experiment 1 but were also walked through an unfamiliar real-world area on campus and completed direction estimation and map drawing tests for the new environment. Overall, women were more accurate with the two real-world environments than Silcton, with some evidence that accuracy with the new real-world environment was more accurate than the familiar real-world locations. Overall, women's ability to create a cognitive map of a virtual environment in the laboratory does not seem to be indicative of their ability to do the same in the real world, and care should be taken when generalizing lab results with virtual environments.
C1 [Cocquyt, Chantelle M.; Sutton, Jennifer E.] Brescia Univ Coll, Sch Behav & Social Sci, London, ON, Canada.
   [Youngson, Nicole; Sutton, Jennifer E.] Western Univ, Dept Psychol, London, ON, Canada.
C3 Western University (University of Western Ontario); Western University
   (University of Western Ontario)
RP Sutton, JE (corresponding author), Brescia Univ Coll, Sch Behav & Social Sci, London, ON, Canada.; Sutton, JE (corresponding author), Western Univ, Dept Psychol, London, ON, Canada.
EM jennifer.sutton@uwo.ca
RI Cocquyt, Chantelle Marie/KFB-9754-2024
OI Cocquyt, Chantelle Marie/0000-0001-9129-0944; Sutton, Jennifer
   E./0000-0001-8729-0546
FU Natural Sciences and Engineering Research Council (NSERC)
FX Funding for these projects was provided by a Discovery Grant from the
   Natural Sciences and Engineering Research Council (NSERC) to JS.
CR [Anonymous], 1998, SPATIAL TEMPORAL REA
   Bediou B, 2018, PSYCHOL BULL, V144, P77, DOI 10.1037/bul0000130
   Bennett ATD, 1996, J EXP BIOL, V199, P219
   Blacker KJ, 2017, VIS COGN, V25, P691, DOI 10.1080/13506285.2017.1322652
   Boone AP, 2018, MEM COGNITION, V46, P909, DOI 10.3758/s13421-018-0811-y
   Castelli L, 2008, COMPUT HUM BEHAV, V24, P1643, DOI 10.1016/j.chb.2007.06.005
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Cherney ID, 2008, SEX ROLES, V59, P776, DOI 10.1007/s11199-008-9498-z
   Dale G, 2020, ANN NY ACAD SCI, V1464, P192, DOI 10.1111/nyas.14295
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Galati A, 2018, SPAT COGN COMPUT, V18, P1, DOI 10.1080/13875868.2017.1332064
   Gardony AL, 2016, BEHAV RES METHODS, V48, P151, DOI 10.3758/s13428-014-0556-x
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Ishikawa T, 2006, COGNITIVE PSYCHOL, V52, P93, DOI 10.1016/j.cogpsych.2005.08.003
   JASP Team, 2020, JASP VERS 0141 COMP
   Nazareth A, 2018, J EXP CHILD PSYCHOL, V170, P86, DOI 10.1016/j.jecp.2018.01.009
   Nowak NT, 2015, J ENVIRON PSYCHOL, V43, P136, DOI 10.1016/j.jenvp.2015.06.007
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   Pagkratidou M, 2020, SPAT COGN COMPUT, V20, P1, DOI 10.1080/13875868.2019.1676248
   Richardson AE, 2011, COMPUT HUM BEHAV, V27, P552, DOI 10.1016/j.chb.2010.10.003
   Schinazi VR, 2013, HIPPOCAMPUS, V23, P515, DOI 10.1002/hipo.22111
   Schmelter A, 2009, EUR J COGN PSYCHOL, V21, P724, DOI 10.1080/09541440802426465
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Warren WH, 2017, COGNITION, V166, P152, DOI 10.1016/j.cognition.2017.05.020
   Weisberg SM, 2018, CURR DIR PSYCHOL SCI, V27, P220, DOI 10.1177/0963721417744521
   Weisberg SM, 2016, J EXP PSYCHOL LEARN, V42, P768, DOI 10.1037/xlm0000200
   Weisberg SM, 2014, J EXP PSYCHOL LEARN, V40, P669, DOI 10.1037/a0035261
   Youngson NL, 2019, CAN J EXP PSYCHOL, V73, P37, DOI 10.1037/cep0000165
NR 29
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 24
PY 2022
VL 3
AR 896081
DI 10.3389/frvir.2022.896081
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2UB1
UT WOS:001021849400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Sato, H
   Sato, Y
   Takamatsu, A
   Makita, M
   Wada, T
AF Sato, Hikaru
   Sato, Yuki
   Takamatsu, Atsushi
   Makita, Mitsuhiro
   Wada, Takahiro
TI Earth-Fixed Books Reduce Motion Sickness When Reading With a
   Head-Mounted Display
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Motion Sickiness; sensory conflict theory; reading task; head mounted
   display; virtual reality; 2D content; Earth-fixed coordinate system;
   Cyber Sickness
ID SIMULATOR
AB There are concerns that viewing two-dimensional (2D) content such as web pages on a head-mounted display (HMD) in the car may aggravate motion sickness. This is because when 2D content is fixed to a head-fixed coordinate system, the appearance of the content does not change even when the body moves; therefore, it is impossible to visually perceive the movement of one's body, resulting in a sensory conflict between the visual and vestibular senses. A method for reducing motion sickness when displaying 3D content on an HMD has been investigated; however, when displaying 2D content, no such method has been investigated. Therefore, this study aims to verify to the possibility of reducing motion sickness from the change of appearance caused by fixing 2D content to the earth-fixed coordinate system when viewing it with an HMD in a moving environment. Participants sat on a seat that was mounted on a vibrating device and moved in the pitch direction while reading a book on the HMD. Consequently, the severity of motion sickness was significantly lower when the book was fixed to the earth-fixed coordinate system than when fixed to the head-fixed coordinate system. This result suggests that by fixing the content to the earth-fixed coordinate system, motion sickness can be reduced because the movement of one's body can be perceived through changes in the appearance of the content, and the sensory conflict between visual and vestibular sensations can be resolved.
C1 [Sato, Hikaru; Takamatsu, Atsushi; Makita, Mitsuhiro] Nissan Res Ctr Nissan Motor Co Ltd, Yokosuka, Kanagawa, Japan.
   [Sato, Hikaru] Ritsumeikan Univ, Grad Sch Informat Sci & Engn, Kusatsu, Shiga, Japan.
   [Sato, Yuki; Wada, Takahiro] Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Japan.
   [Sato, Yuki; Wada, Takahiro] Ritsumeikan Univ, Res Org Sci & Technol, Kusatsu, Japan.
C3 Ritsumeikan University; Nara Institute of Science & Technology;
   Ritsumeikan University
RP Sato, H (corresponding author), Nissan Res Ctr Nissan Motor Co Ltd, Yokosuka, Kanagawa, Japan.; Sato, H (corresponding author), Ritsumeikan Univ, Grad Sch Informat Sci & Engn, Kusatsu, Shiga, Japan.; Sato, Y (corresponding author), Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Japan.; Sato, Y (corresponding author), Ritsumeikan Univ, Res Org Sci & Technol, Kusatsu, Japan.
EM hikaru-sato@mail.nissan.co.jp; sato.yuki@is.naist.jp
FU Nissan Motor Co., Ltd; Japan Science and Technology Agency [JPMJTR20RR];
   Grants-in-Aid for Scientific Research [21H01296] Funding Source: KAKEN
FX This study received funding from Nissan Motor Co., Ltd and Japan Science
   and Technology Agency Grant (# JPMJTR20RR). The funders were not
   involved in the study design, collection, analysis, interpretation of
   data, the writing of this article or the decision to submit it for
   publication. All authors declare no other competing interests.
CR Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bos JE, 2005, AVIAT SPACE ENVIR MD, V76, P1111
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Ferdous SMS, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582169
   GOLDING JF, 1995, AVIAT SPACE ENVIR MD, V66, P1046
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Hemmerich W, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582095
   Hock P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4034, DOI 10.1145/3025453.3025665
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Kato K., 2008, SAE Technical Paper, DOI [10.4271/2008-01-0565, DOI 10.4271/2008-01-0565]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Li JY, 2021, AUTOMOTIVEUI '21: 13TH INTERNATIONAL ACM CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P28, DOI [10.1145/3409118.3475137, 10.1145/34091183475137]
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   McGill M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5655, DOI 10.1145/3025453.3026046
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Morimoto A., 2008, P FISITA 2008 WORLD, P14
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   REASON J, 1978, APPL ERGON, V9, P163, DOI 10.1016/0003-6870(78)90008-X
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rolland J. P., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P56, DOI 10.1109/VRAIS.1995.512480
   Shi RK, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451255
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Wada T., 2016, INT S ADV VEH CONTR, P169, DOI [DOI 10.1007/978-3-319-40503-2, 10.1201/9781315265285-28, DOI 10.1201/9781315265285-28, 10.1007/978-3-319-40503-2]
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
NR 31
TC 7
Z9 7
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 24
PY 2022
VL 3
AR 909005
DI 10.3389/frvir.2022.909005
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SJ6
UT WOS:001021805800001
OA gold
DA 2024-07-18
ER

PT J
AU Melendrez-Ruiz, J
   Goisbault, I
   Charrier, JC
   Pagnat, K
   Dujourdy, L
   Arvisenet, G
   Chambaron, S
AF Melendrez-Ruiz, Juliana
   Goisbault, Isabelle
   Charrier, Jean-Christophe
   Pagnat, Kevin
   Dujourdy, Laurence
   Arvisenet, Gaelle
   Chambaron, Stephanie
TI An Exploratory Study Combining Eye-Tracking and Virtual Reality: Are
   Pulses Good "Eye-Catchers" in Virtual Supermarket Shelves?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE gaze behavior; consumer; immersive environment; plant-based food;
   implicit method
ID ATTENTION; CHOICE; STORE
AB Despite numerous health and environmental benefits, the consumption of pulses (i.e. lentils, chickpeas horizontal ellipsis ) in France has decreased over the past few decades. One potential barrier to pulse consumption may be their shelf placement in French supermarkets. We studied gaze behavior toward pulses in a virtual supermarket. Products from four food categories (animal-based, pulses, starches, and vegetables) were randomly presented on four shelves (canned, dried, ready-to-eat, and refrigerated). Then, a composite super-shelf combined the canned, dried, and refrigerated shelves. Gaze behavior was recorded for the 108 participants in two screening phases: i) the four shelves one-by-one, ii) the super-shelf. Pulses were not strong "eye-catchers": gaze behavior toward pulses varied from shelf to shelf. Similarly, visual attention was different for each food-group during super-shelf screening. These results could be used to implement specific strategies that should be developed in supermarkets to encourage the choice of pulses by consumers, and thus increase pulse consumption.
C1 [Melendrez-Ruiz, Juliana; Arvisenet, Gaelle; Chambaron, Stephanie] Univ Bourgogne Franche Comte, Ctr Sci Gout & Alimentat, AgroSup Dijon, CNRS,INRAe, Dijon, France.
   [Goisbault, Isabelle; Charrier, Jean-Christophe; Pagnat, Kevin] Strategir, R&D & Image & Technol Dept, Bordeaux, France.
   [Dujourdy, Laurence] AgroSup Dijon, Serv Appui Rech, Dijon, France.
C3 INRAE; Institut Agro; AgroSup Dijon; Centre National de la Recherche
   Scientifique (CNRS); Universite de Bourgogne; Institut Agro; AgroSup
   Dijon
RP Melendrez-Ruiz, J (corresponding author), Univ Bourgogne Franche Comte, Ctr Sci Gout & Alimentat, AgroSup Dijon, CNRS,INRAe, Dijon, France.
EM Juliana.melendrezruiz@inrae.fr
RI Chambaron, Stéphanie/GYA-5524-2022
OI Chambaron, Stéphanie/0000-0002-4626-8489; Arvisenet,
   Gaelle/0000-0001-7994-5610; Dujourdy, Laurence/0000-0001-8318-6979
CR ANSES, 2017, DOSSIER DE PRESSE
   Atalay AS, 2012, J CONSUM RES, V39, P848, DOI 10.1086/665984
   Bialkova S, 2020, FOOD QUAL PREFER, V81, DOI 10.1016/j.foodqual.2019.103839
   Burke RR, 2014, REV MARKET RES, V11, P147, DOI 10.1108/S1548-643520140000011006
   Chandon P, 2009, J MARKETING, V73, P1, DOI 10.1509/jmkg.73.6.1
   De Mendiburu Felipe, 2023, CRAN
   Duchowski A. T., 2017, EYE TRACKING METHODO, DOI [10.1007/978-3-319-57883-5, DOI 10.1007/978-3-319-57883-5]
   Duerrschmid K., 2018, Methods in consumer research: Alternative approaches and special applications, V2, P279, DOI [DOI 10.1016/B978-0-08-101743-2.00012-1, 10.1016/b978-0-08-101743-2.00012-1]
   Fuchs P., 2011, VIRTUAL REALITY CONC, P3, DOI 10.1201/b11612
   Gere A, 2020, FOOD QUAL PREFER, V83, DOI 10.1016/j.foodqual.2020.103915
   Hartmann C, 2019, CONTEXT: THE EFFECTS OF ENVIRONMENT ON PRODUCT DESIGN AND EVALUATION, P323, DOI 10.1016/B978-0-12-814495-4.00016-7
   Kobilinsky A., 2016, R PACKAGE AUTOMATIC
   Lamberton CP, 2013, J CONSUM RES, V40, P393, DOI 10.1086/671103
   Lawrence M. A., 2016, ez: Easy Analysis and Visualization of Factorial Experiments. R package version 4.4-0, V4
   Leonard TC, 2008, CONST POLITICAL ECON, V19, P356, DOI 10.1007/s10602-008-9056-2
   Magrini M.-B., 2016, LEGUMES SECS FRANCE
   Meissner M, 2019, J BUS RES, V100, P445, DOI 10.1016/j.jbusres.2017.09.028
   Monteiro CA, 2018, PUBLIC HEALTH NUTR, V21, P5, DOI 10.1017/S1368980017000234
   Morales A, 2005, J RETAILING, V81, P159, DOI 10.1016/j.jretai.2005.03.007
   Orquin JL, 2013, ACTA PSYCHOL, V144, P190, DOI 10.1016/j.actpsy.2013.06.003
   Pizzi G, 2019, COMPUT HUM BEHAV, V96, P1, DOI 10.1016/j.chb.2019.02.008
   Pohlert Thorsten, 2021, CRAN
   Potthoff J, 2020, FOOD QUAL PREFER, V84, DOI 10.1016/j.foodqual.2020.103936
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rio C, 2017, CAH NUTR DIET, V52, P71, DOI 10.1016/j.cnd.2016.11.006
   Rstudio Team, 2020, RSTUDIO INT DEV R RS
   Scheibehenne B, 2010, J CONSUM RES, V37, P409, DOI 10.1086/651235
   Sester C, 2013, FOOD QUAL PREFER, V28, P23, DOI 10.1016/j.foodqual.2012.07.006
   Siegrist M, 2019, FOOD RES INT, V117, P50, DOI 10.1016/j.foodres.2018.02.033
   Steinhauser J, 2019, APPETITE, V141, DOI 10.1016/j.appet.2019.104337
   van der Lans R, 2008, MARKET SCI, V27, P922, DOI 10.1287/mksc.1070.0327
   van Herpen E, 2016, APPETITE, V107, P196, DOI 10.1016/j.appet.2016.07.033
   Widdel H., 1984, THEORETICAL APPL ASP, P21
   Yasui Y, 2019, J PROSTHODONT RES, V63, P210, DOI 10.1016/j.jpor.2018.11.011
NR 34
TC 2
Z9 2
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 31
PY 2021
VL 2
AR 655273
DI 10.3389/frvir.2021.655273
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZU2
UT WOS:001019272900001
OA gold
DA 2024-07-18
ER

PT J
AU Peck, TC
   Gonzalez-Franco, M
AF Peck, Tabitha C.
   Gonzalez-Franco, Mar
TI Avatar Embodiment. A Standardized Questionnaire
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE embodiment; avatar; virtual reality; rubber hand illusion; body
   ownership; agency; questionnaire; age
ID IMMERSIVE VIRTUAL-REALITY; SIGNATURES; MEMORY
AB The aim of this paper is to further the understanding of embodiment by 1) analytically determining the components defining embodiment, 2) increasing comparability and standardization of the measurement of embodiment across experiments by providing a universal embodiment questionnaire that is validated and reliable, and 3) motivating researchers to use a standardized questionnaire. In this paper we validate numerically and refine our previously proposed Embodiment Questionnaire. We collected data from nine experiments, with over 400 questionnaires, that used all or part of the original embodiment 25-item questionnaire. Analysis was performed to eliminate non-universal questions, redundant questions, and questions that were not strongly correlated with other questions. We further numerically categorized and weighted sub-scales and determined that embodiment is comprised of interrelated categories of Appearance, Response, Ownership, and Multi-Sensory. The final questionnaire consists of 16 questions and four interrelated sub-scales with high reliability within each sub-scale, Chronbach's & alpha; ranged from 0.72 to 0.82. Results of the original and refined questionnaire are compared over all nine experiments and in detail for three of the experiments. The updated questionnaire produced a wider range of embodiment scores compared to the original questionnaire, was able to detect the presence of a self-avatar, and was able to discern that participants over 30 years of age have significantly lower embodiment scores compared to participants under 30 years of age. Removed questions and further research of interest to the community are discussed.
C1 [Peck, Tabitha C.] Davidson Coll, Dept Math & Comp Sci, Davidson, NC 28035 USA.
   [Gonzalez-Franco, Mar] Microsoft Res, Redmond, WA USA.
C3 Davidson College; Microsoft
RP Peck, TC (corresponding author), Davidson Coll, Dept Math & Comp Sci, Davidson, NC 28035 USA.
EM tapeck@davidson.edu
RI Gonzalez-Franco, Mar/L-4994-2014; Peck, Tabitha/AAH-2032-2021
FU National Science Foundation [1942146]
FX The research reported in this paper was supported in part by a grant
   from the National Science Foundation (#1942146).
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Alchalabi B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P776, DOI [10.1109/VR.2019.8798263, 10.1109/vr.2019.8798263]
   Allen R., 2000, Human Factors and Ergonomics Society Annual Meeting Proceedings, V44, P542
   [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   Armor D.J., 1974, SOCIOLOGICAL METHODO, P17, DOI [DOI 10.2307/270831, 10.2307/270831]
   Berger CC, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225172
   Blanke O, 2005, BRAIN RES REV, V50, P184, DOI 10.1016/j.brainresrev.2005.05.008
   Boateng GO, 2018, FRONT PUBLIC HEALTH, V6, DOI 10.3389/fpubh.2018.00149
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Field A, 2018, Discovering Statistics Using IBM SPSS Statistics, Vfifth
   Franco M.G., 2014, Neurophysiological Signatures of the Body Representation in the Brain Using Immersive Virtual Reality
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gonzalez-Franco M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P941, DOI [10.1109/VR.2019.8798348, 10.1109/vr.2019.8798348]
   Gonzalez-Franco M, 2019, IEEE T HAPTICS, V12, P319, DOI 10.1109/TOH.2019.2925038
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2014, EXP BRAIN RES, V232, P875, DOI 10.1007/s00221-013-3800-1
   Gonzalez-Liencres C, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00820
   Hutcheson G.D., 1999, The Multivariate Social Scientist: Introductory Statistics Using Generalized Linear Models, DOI DOI 10.4135/9780857028075
   Jung S, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P60, DOI 10.1145/3267782.3267920
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Launois R, 1996, QUAL LIFE RES, V5, P539, DOI 10.1007/BF00439228
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Lush P, 2020, COLLABRA-PSYCHOL, V6, DOI 10.1525/collabra.325
   Malhotra N. K., 2006, HDB MARKETING RES US, P83
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Moffat SD, 2001, NEUROBIOL AGING, V22, P787, DOI 10.1016/S0197-4580(01)00251-2
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Padrao G, 2016, NEUROIMAGE, V124, P147, DOI 10.1016/j.neuroimage.2015.08.022
   Pavone EF, 2016, J NEUROSCI, V36, P268, DOI 10.1523/JNEUROSCI.0494-15.2016
   Peck TC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376419
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1964, DOI 10.1109/TVCG.2020.2973061
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Seitz KR, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P607, DOI [10.1109/VRW50115.2020.0-121, 10.1109/VRW50115.2020.00154]
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Terracciano A, 2006, PERS SOC PSYCHOL B, V32, P999, DOI 10.1177/0146167206288599
NR 45
TC 78
Z9 81
U1 3
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 9
PY 2021
VL 1
AR 575943
DI 10.3389/frvir.2020.575943
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TW4
UT WOS:001021844700001
OA gold
DA 2024-07-18
ER

PT J
AU Kahlon, S
   Lindner, P
   Nordgreen, T
AF Kahlon, Smiti
   Lindner, Philip
   Nordgreen, Tine
TI Gamified virtual reality exposure therapy for adolescents with public
   speaking anxiety: a four-armed randomized controlled trial
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality exposure therapy; public speaking anxiety; self-guided;
   internet interventions; adolescents
ID SOCIAL ANXIETY; COMMUNITY SAMPLE; PHOBIA; DISORDERS; PREVALENCE; FEARS
AB Objective: Public Speaking Anxiety is highly prevalent among adolescents. However, few interventions have been developed specifically for this group. This four-armed randomized trial addressed the following research questions regarding interventions for adolescents with public speaking anxiety (PSA): 1) is Virtual Reality exposure therapy (VRET) more efficacious than online psychoeducation or waitlist, and 2) is VRET followed by online exposure therapy more efficacious than VRET alone or online psychoeducation followed by online exposure therapy?Methods: Adolescents, aged 13-16 with PSA were randomized to four groups: 1) VRET + no additional intervention (n = 20); 2) VRET + online exposure program (n = 20); 3) online psychoeducation program + exposure program (n = 40); or 4) waitlist (n = 20). Self-rated PSA symptoms served as primary outcome measure, with secondary outcomes covering other social anxiety symptoms.Results: Linear mixed models revealed that there was a significant difference in the decrease in PSA symptoms among adolescents receiving VRET compared with waiting list (p = 0.015), but no significant difference to the online psychoeducation program (p = 0.056). However, online psychoeducation program yielded smaller within-group effect sizes compared to VRET, d = 0.33 vs. d = 0.83 respectively. VRET + online exposure program had a significant decrease in PSA symptoms (p = 0.013), but no significant difference from VRET + no additional intervention or online psychoeducation + online exposure program. Symptom reduction remained stable at 3-month follow-up.Conclusion: The study shows the potential of delivering both gamified VRET as well as online psychoeducation and exposure programs as self-guided interventions for adolescents with PSA.Clinical trial registration: clinicaltrials.gov, identifier: NCT04396392
C1 [Kahlon, Smiti; Nordgreen, Tine] Haukeland Hosp, Res Ctr Digital Mental Hlth Serv, Div Psychiat, Bergen, Norway.
   [Lindner, Philip] Karolinska Inst, Ctr Psychiat Res, Dept Clin Neurosci, Stockholm Hlth Care Serv, Stockholm, Sweden.
   [Nordgreen, Tine] Univ Bergen, Fac Med, Dept Global Publ Hlth & Primary Care, Bergen, Norway.
C3 University of Bergen; Haukeland University Hospital; Karolinska
   Institutet; University of Bergen
RP Kahlon, S (corresponding author), Haukeland Hosp, Res Ctr Digital Mental Hlth Serv, Div Psychiat, Bergen, Norway.
EM smiti.kahlon@helse-bergen.no
RI Lindner, Philip/AAO-2628-2020
OI Lindner, Philip/0000-0002-3061-501X
FU Norwegian Research Council (NFR) [259293]
FX This work was supported by the Norwegian Research Council (NFR grant no
   259293).
CR Anderson PL, 2017, COGNITIVE THER RES, V41, P230, DOI 10.1007/s10608-016-9820-y
   [Anonymous], 1995, SOCIAL PHOBIA DIAGNO
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Attensi, 2021, UngSpotlight
   Bartholomay EM, 2016, PERS INDIV DIFFER, V94, P211, DOI 10.1016/j.paid.2016.01.026
   Berger T, 2009, J CLIN PSYCHOL, V65, P1021, DOI 10.1002/jclp.20603
   Blöte AW, 2009, J ANXIETY DISORD, V23, P305, DOI 10.1016/j.janxdis.2008.11.007
   Bovend'Eerdt TJH, 2009, CLIN REHABIL, V23, P352, DOI 10.1177/0269215508101741
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Conley CS, 2022, JMIR MENT HEALTH, V9, DOI 10.2196/34254
   Craske MG, 2008, BEHAV RES THER, V46, P5, DOI 10.1016/j.brat.2007.10.003
   De Croon R., 2021, HCI in games: Experience design and game mechanics
   Donker T, 2009, BMC MED, V7, DOI 10.1186/1741-7015-7-79
   Ebrahimi OV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00488
   Essau CA, 2014, J AFFECT DISORDERS, V163, P125, DOI 10.1016/j.jad.2013.12.033
   Fernández-Alvarez J, 2019, J ANXIETY DISORD, V61, P3, DOI 10.1016/j.janxdis.2018.06.005
   Marinho ACF, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2015.12.012
   Fleming TM, 2017, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00215
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Goldenhersch E, 2020, J MED INTERNET RES, V22, DOI 10.2196/17571
   Grant BF, 2005, J CLIN PSYCHIAT, V66, P1351, DOI 10.4088/JCP.v66n1102
   Gutiérrez-Maldonado J, 2009, ANU PSICOL, V40, P223
   Halldorsson B, 2021, J CHILD PSYCHOL PSYC, V62, P584, DOI 10.1111/jcpp.13400
   Hammady R, 2022, INFORMATION, V13, DOI 10.3390/info13030142
   Hindo CS, 2011, RES SOCIAL WORK PRAC, V21, P528, DOI 10.1177/1049731510393984
   Hofmann SG, 2006, J CONSULT CLIN PSYCH, V74, P687, DOI 10.1037/0022-006X.74.4.687
   Horigome T, 2020, PSYCHOL MED, V50, P2487, DOI 10.1017/S0033291720003785
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Karyotaki E, 2018, PSYCHOL MED, V48, P2456, DOI 10.1017/S0033291718000648
   Kothgassner OD, 2021, NEUROPSYCHIATRIE, V35, P68, DOI 10.1007/s40211-020-00349-7
   Lamo Y, 2022, DIGIT HEALTH, V8, DOI 10.1177/20552076221128678
   Lim MH, 2023, CURR PSYCHOL, V42, P12912, DOI 10.1007/s12144-021-02684-6
   Lindner P, 2021, INT J COGN THER, V14, P23, DOI 10.1007/s41811-020-00090-7
   Lindner P, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/17807
   Lindner P, 2019, J ANXIETY DISORD, V61, P45, DOI 10.1016/j.janxdis.2018.07.003
   Magnusson K., 2018, POWERLMM POWER ANAL
   Mattick RP, 1998, BEHAV RES THER, V36, P455, DOI 10.1016/S0005-7967(97)10031-6
   Mekler ED., 2013, Gamification'13 - First International Conference on Gameful Design, Research, and Applications, P66, DOI [10.1145/2583008.2583017, DOI 10.1145/2583008.2583017]
   Meyerbröker K, 2021, CLIN PSYCHOL PSYCHOT, V28, P466, DOI 10.1002/cpp.2623
   Miloff A, 2020, J MED INTERNET RES, V22, DOI 10.2196/16660
   Miloff A, 2019, BEHAV RES THER, V118, P130, DOI 10.1016/j.brat.2019.04.004
   Morina N, 2023, PSYCHOL MED, V53, P2176, DOI 10.1017/S0033291721001690
   National Institute for Health and Care Excellence, 2013, 159 NICE
   Nordgreen T, 2021, J ENABLING TECHNOL, V15, P241, DOI 10.1108/JET-03-2021-0013
   Parrish DE, 2016, RES SOCIAL WORK PRAC, V26, P825, DOI 10.1177/1049731514568897
   Patterson B, 2016, J PSYCHIATR RES, V83, P112, DOI 10.1016/j.jpsychires.2016.08.015
   Peters L, 2012, PSYCHOL ASSESSMENT, V24, P66, DOI 10.1037/a0024544
   Premkumar P, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.694610
   Reeves R, 2022, BEHAV MODIF, V46, P937, DOI 10.1177/0145445521991102
   Schuurmans J, 2006, AM J GERIAT PSYCHIAT, V14, P255, DOI 10.1097/01.JGP.0000196629.19634.00
   Stein MB, 1996, ARCH GEN PSYCHIAT, V53, P169
   Sülter RE, 2022, COMPUT EDUC, V178, DOI 10.1016/j.compedu.2021.104384
   Valls-Rates I, 2022, FRONT COMMUN, V7, DOI 10.3389/fcomm.2022.910952
   Wiebe A, 2022, CLIN PSYCHOL REV, V98, DOI 10.1016/j.cpr.2022.102213
   Wittchen HU, 1999, PSYCHOL MED, V29, P309, DOI 10.1017/S0033291798008174
   Zainal NH, 2021, BEHAV RES THER, V147, DOI 10.1016/j.brat.2021.103984
NR 57
TC 2
Z9 2
U1 9
U2 14
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 29
PY 2023
VL 4
AR 1240778
DI 10.3389/frvir.2023.1240778
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA R6NE6
UT WOS:001065496100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Bahng, S
   McArthur, V
   Kelly, RM
AF Bahng, Sojung
   McArthur, Victoria
   Kelly, Ryan M. M.
TI Designing immersive stories with novice VR creators: a study of
   autobiographical VR storytelling during the COVID-19 pandemic
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE autobiographical VR storytelling; virtual reality; immersive journalism;
   VR nonfiction; collaborative design
AB Virtual reality (VR) is increasingly being used as a tool for eliciting empathy and emotional identification in fact-based stories. However, it may not be clear whether VR stories authentically deliver the protagonists' perspectives if the works are not created by or with the protagonists themselves. Therefore, it is crucial for the VR community to explore effective methods for democratizing VR storytelling, and to support novice VR designers in creating autobiographical stories. In this paper, we report findings from a collaborative design research project that aimed to create autobiographical stories with novice VR designers who lacked experience in VR storytelling. We collaborated with university students in Canada to design eight individual VR stories that expressed each student's experiences of lockdown, during the early stages of the COVID-19 pandemic. We conducted interviews with the students to understand how VR contributed to conveying their individual experiences. Our findings demonstrate how immersive VR can be used as a meaningful tool for sharing autobiographical stories by delivering the character's feelings, creating a sense of confinement and isolation, expressing inner worlds, and showing environmental details. Our discussion draws attention to the significance of careful camera positioning and movement in VR story design, the meaningful use of limited interaction and disorienting components, and the balance between spatial and temporal information in a three-dimensional environment. Our study highlights the potential of VR as an autobiographical storytelling tool and demonstrates how VR stories can be created through iterative collaboration between VR experts and novices.
C1 [Bahng, Sojung] Queens Univ, DAN Sch Drama & Mus, Dept Film & Media, Kingston, ON, Canada.
   [McArthur, Victoria] Carleton Univ, Sch Journalism & Commun, Media Prod & Design, Ottawa, ON, Canada.
   [Kelly, Ryan M. M.] Univ Melbourne, Sch Comp & Informat Syst, Parkville, Vic, Australia.
C3 Queens University - Canada; Carleton University; University of Melbourne
RP Bahng, S (corresponding author), Queens Univ, DAN Sch Drama & Mus, Dept Film & Media, Kingston, ON, Canada.
EM sojung.bahng@queensu.ca
OI Kelly, Ryan/0000-0002-8773-6656
FU Carleton University; Queen's University; University of Melbourne; FPA
   Postdoctoral Fellowship Award
FX The research has been mainly supported and sponsored by Carleton
   University, collaborating with Queen's University and the University of
   Melbourne; FPA Postdoctoral Fellowship Award.
CR Appel L., 2021, INT J INNOV ED RES, V9, P219, DOI [10.31686/ijier.vol9.iss3.2992, DOI 10.31686/IJIER.VOL9.ISS3.2992]
   Bahng S., 2020, THESIS MONASH U AUST
   Bahng S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376582
   Bahng S, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P639, DOI 10.1145/3374920.3375285
   Bollmer G, 2017, MEDIA INT AUST, V165, P63, DOI 10.1177/1329878X17726794
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Bucher J, 2018, STORYTELLING FOR VIRTUAL REALITY: METHODS AND PRINCIPLES FOR CRAFTING IMMERSIVE NARRATIVES, P1
   Candy L., 2006, Creativity and Cognition Studios, V1, P1
   Crawford-Holland S., 2018, Synoptique, V7, P19
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Dowmunt T, 2013, STUD DOC FILM, V7, P263, DOI 10.1386/sdf.7.3.263_1
   Dziekan V., 2018, ARTLINK, V38, P36, DOI [10.3316/informit.022663397866558, DOI 10.3316/INFORMIT.022663397866558]
   Eisapour M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3174362
   Fisher JA, 2021, LECT NOTES COMPUT SC, V13138, P462, DOI 10.1007/978-3-030-92300-6_47
   Flobak E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300799
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gödde M, 2018, LECT NOTES COMPUT SC, V10910, P184, DOI 10.1007/978-3-319-91584-5_15
   Hansen NB, 2020, PROCEEDINGS OF THE 31ST AUSTRALIAN CONFERENCE ON HUMAN-COMPUTER-INTERACTION (OZCHI'19), P30, DOI 10.1145/3369457.3369460
   Herson B., 2016, Comparative Education Review, V60, P853, DOI DOI 10.1086/688582.
   Hodge J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174088
   Jones S., 2018, Media Practice and Education, V19, P298, DOI 10.1080/25741136.2018.1520538
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   KIM Deoksoon, 2021, Journal of Curriculum Studies Research, V3, P101, DOI [10.46303/jcsr.2021.9, DOI 10.46303/JCSR.2021.9]
   Kim E. S., 2018, ACM SIGCHI C DES INT
   Kvan T, 2000, AUTOMAT CONSTR, V9, P409, DOI 10.1016/S0926-5805(99)00025-4
   Lane Jim., 2002, The autobiographical documentary in America
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   McRoberts J, 2018, STUD DOC FILM, V12, P101, DOI 10.1080/17503280.2017.1344924
   Milk Chris., 2015, Ted Talk
   Mohamed TI, 2022, EDUC INF TECHNOL, V27, P11137, DOI 10.1007/s10639-022-11069-6
   Morley Christine., 2008, Knowing Differently: Artsbased and Collaborative Research Methods, P265
   Mozgai S, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375219
   Nash K, 2018, STUD DOC FILM, V12, P119, DOI 10.1080/17503280.2017.1340796
   Plager T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P693, DOI [10.1109/VRW50115.2020.00-78, 10.1109/VRW50115.2020.00197]
   Ryan Marie-Laure., 2001, NARRATIVE VIRTUAL RE
   Son C, 2020, J MED INTERNET RES, V22, DOI 10.2196/21279
   Teng MQ, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299050
   Tricart C., 2017, Virtual Reality Filmmaking: Techniques Best Practices for VR Filmmakers, DOI 10.4324/9781315280417
   Villa R., 2010, Collaborating with students in instruction and decision making: The untapped resource
   Vosmeer M, 2014, LECT NOTES COMPUT SC, V8832, P140, DOI 10.1007/978-3-319-12337-0_14
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zamenopoulos T., 2018, CODESIGN COLLABORATI
   Zettl H., 2016, SIGHT SOUND MOTION
NR 43
TC 0
Z9 0
U1 11
U2 25
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 14
PY 2023
VL 4
AR 1174701
DI 10.3389/frvir.2023.1174701
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA N8EH4
UT WOS:001039277300001
OA gold
DA 2024-07-18
ER

PT J
AU Bühler, MA
   Lynch, SD
   Bhojwani, TM
   Zidan, A
   Fiset, F
   McFadyen, BJ
   Lamontagne, A
AF Buhler, Marco A. A.
   Lynch, Sean D. D.
   Bhojwani, Trineta M. M.
   Zidan, Ahlam
   Fiset, Felix
   McFadyen, Bradford J. J.
   Lamontagne, Anouk
TI Influence of surgical masks on the avoidance of virtual pedestrians
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE COVID-19; surgical maks; obstacle avoidance; locomotion; virtual reality
ID MOBILE ROBOT; WALKING; CIRCUMVENTION; STRATEGIES; HEALTH
AB To combat the COVID-19 pandemic, governments around the world have proposed a series of mitigation strategies. While responses varied across different governing bodies, recommendations such as social distancing and the use of surgical masks were nearly universal. These recommendations, as well as the social anxiety that emerged during the pandemic, are likely to have influenced pedestrian interactions. In this study, we have examined the effect of surgical masks on locomotor circumvention strategies in response to virtual pedestrians. We further explored the relationship between measures of obstacle clearance and feelings of anxiety related to community ambulation in the context of the pandemic. Using virtual reality, locomotor circumvention strategies in response to approaching pedestrians with and without surgical masks were measured in a sample of 11 healthy young individuals. Additionally, a questionnaire was developed and used to gain insights into participants' behaviours during and after a strict period of restrictions that were in effect before the summer of 2020. Results showed that participants maintained a larger clearance when virtual pedestrians wore a surgical mask. Furthermore, clearance was positively associated with anxiety toward community ambulation in the context of the pandemic. Our findings provide evidence that mask-wearing elicits an increase in physical distancing during pedestrian interactions. Furthermore, results indicate that social context and mental health status influence locomotor outcomes measured in the context of a pedestrian interaction task and highlight the potential of virtual reality simulations to study locomotion in the community setting.
C1 [Buhler, Marco A. A.; Lamontagne, Anouk] McGill Univ, Integrated Program Neurosci, Montreal, PQ, Canada.
   [Buhler, Marco A. A.; Lynch, Sean D. D.; Bhojwani, Trineta M. M.; Zidan, Ahlam; Lamontagne, Anouk] Jewish Rehabil Hosp, CISSS Laval Site Ctr Interdisciplinary Res Rehabil, Laval, PQ, Canada.
   [Lynch, Sean D. D.; Bhojwani, Trineta M. M.; Zidan, Ahlam; Lamontagne, Anouk] McGill Univ, Sch Phys & Occupat Therapy, Montreal, PQ, Canada.
   [Fiset, Felix; McFadyen, Bradford J. J.] Ctr Interdisciplinary Res Rehabil & Social Integra, Laval, PQ, Canada.
   [Fiset, Felix; McFadyen, Bradford J. J.] Univ Laval, Dept readaptat, Laval, PQ, Canada.
C3 McGill University; McGill University; McGill University; Laval
   University
RP Bühler, MA (corresponding author), McGill Univ, Integrated Program Neurosci, Montreal, PQ, Canada.; Bühler, MA (corresponding author), Jewish Rehabil Hosp, CISSS Laval Site Ctr Interdisciplinary Res Rehabil, Laval, PQ, Canada.
EM marco.buhler@mail.mcgill.ca
FU Natural Sciences and Engineering Research Council (NSERC)
   [RGPIN/04471-2016]; Fonds de Recherche du Quebec (FRQS)
FX This work was supported by the Natural Sciences and Engineering Research
   Council (NSERC) under Grant RGPIN/04471-2016 and MB is supported by a
   doctoral award from the Fonds de Recherche du Quebec (FRQS).
CR Anand K B, 2020, Med J Armed Forces India, V76, P136, DOI 10.1016/j.mjafi.2020.04.008
   Aravind G, 2017, RESTOR NEUROL NEUROS, V35, P423, DOI 10.3233/RNN-160709
   Basili P, 2013, GAIT POSTURE, V37, P385, DOI 10.1016/j.gaitpost.2012.08.003
   Bohannon RW, 1997, AGE AGEING, V26, P15, DOI 10.1093/ageing/26.1.15
   Bouchard S., 2004, 3 IEEE INT WORKSH HA
   Boulanger M, 2017, 2017 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION (ICVR)
   Bourgaize SM, 2021, J MOTOR BEHAV, V53, P166, DOI 10.1080/00222895.2020.1742083
   Bühler MA, 2019, GAIT POSTURE, V68, P201, DOI 10.1016/j.gaitpost.2018.10.004
   Bühler MA, 2018, IEEE T NEUR SYS REH, V26, P1813, DOI 10.1109/TNSRE.2018.2865907
   Cartaud A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243023
   Chu DK, 2020, LANCET, V395, P1973, DOI 10.1016/S0140-6736(20)31142-9
   Darekar A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0264-8
   Ehsanifar M, 2021, ENVIRON RES, V200, DOI 10.1016/j.envres.2021.111752
   Eikenberry SE, 2020, INFECT DIS MODEL, V5, P293, DOI 10.1016/j.idm.2020.04.001
   Fiset F, 2020, NEUROSCI LETT, V736, DOI 10.1016/j.neulet.2020.135278
   Gérin-Lajoie M, 2005, MOTOR CONTROL, V9, P242, DOI 10.1123/mcj.9.3.242
   Gérin-Lajoie M, 2006, GAIT POSTURE, V24, P364, DOI 10.1016/j.gaitpost.2005.11.001
   Harper CA, 2021, INT J MENT HEALTH AD, V19, P1875, DOI 10.1007/s11469-020-00281-5
   HAYDUK LA, 1983, PSYCHOL BULL, V94, P293, DOI 10.1037/0033-2909.94.2.293
   Huber M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089589
   Hunter RF, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23937-9
   Jorgensen F, 2021, EUR J PUBLIC HEALTH, V31, P1259, DOI 10.1093/eurpub/ckab136
   Kaiser Peter K, 2009, Trans Am Ophthalmol Soc, V107, P311
   Leung NHL, 2021, NAT REV MICROBIOL, V19, P528, DOI 10.1038/s41579-021-00535-6
   Liebst LS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05270-3
   Luckman A, 2021, J EXP PSYCHOL-APPL, V27, P722, DOI 10.1037/xap0000382
   Marchiori M., 2020, COVID 19 SOCIAL DIST
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Olivier AH, 2013, GAIT POSTURE, V38, P751, DOI 10.1016/j.gaitpost.2013.03.017
   Perry A, 2013, NEUROIMAGE, V83, P761, DOI 10.1016/j.neuroimage.2013.07.042
   Pham QC, 2007, EUR J NEUROSCI, V26, P2391, DOI 10.1111/j.1460-9568.2007.05835.x
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Seres G, 2021, J ECON SCI ASSOC-JES, V7, P139, DOI 10.1007/s40881-021-00108-6
   Silva WS, 2018, GAIT POSTURE, V61, P294, DOI 10.1016/j.gaitpost.2018.01.028
   Vassallo C, 2018, GAIT POSTURE, V60, P188, DOI 10.1016/j.gaitpost.2017.12.002
   Vassallo C, 2017, GAIT POSTURE, V51, P97, DOI 10.1016/j.gaitpost.2016.09.022
   Warren WH, 2008, UNDERST COMPLEX SYST, P45, DOI 10.1007/978-3-540-74479-5_3
   Xiong JQ, 2020, J AFFECT DISORDERS, V277, P55, DOI 10.1016/j.jad.2020.08.001
NR 39
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 23
PY 2023
VL 4
AR 1081003
DI 10.3389/frvir.2023.1081003
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XP8
UT WOS:001023314400001
OA gold
DA 2024-07-18
ER

PT J
AU Hejtmánek, L
   Hula, M
   Herrová, A
   Surovy, P
AF Hejtmanek, Lukas
   Hula, Martin
   Herrova, Anna
   Surovy, Peter
TI Forest digital twin as a relaxation environment: A pilot study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; forest bathing (shinrin-yoku); lidar; nature; stress;
   digital twin; relaxation; well-being
ID URBAN; RESTORATION; STRESS; HEALTH
AB Forest environments have been proven beneficial for physiological well-being, supporting relaxation and meditative processes. Unfortunately, some groups, predominantly those with reduced mobility, are prevented from forest visitation. Presenting such environments in virtual reality could provide a viable substitute. However, as forest structure and composition are important aspects of its restorative power, to accurately compare the efficacy of virtual forests to that of real natural spaces, the virtual environment should match the real location as closely as possible. Furthermore, if participants achieve similar benefits in both settings, virtual copies (digital twins) of forests could be a viable option for studying forest bathing in a controlled environment. We collected LiDAR scans of a forest location near Prague, took spatial audio recordings of the forest ambiance, and built the forest's digital twin in Unreal Engine. To compare the therapeutic efficacy of the virtual forest with its real counterpart, groups of volunteers spent half an hour in either the real forest, the virtual forest, or both. We collected participants' demographic and psychometric data, assessing their relaxation, emotional state, and cybersickness before and after the session. Our data show an increase in relaxation with no significant differences between the environments, although participants' emotional states did not improve in either condition. We found that participants' experiences were comparable between the environments, but cybersickness limited the potential efficacy of virtual forest bathing. The limitations of the virtual forests as a platform for research into forest bathing are discussed.
C1 [Hejtmanek, Lukas] Charles Univ Prague, Fac Humanities, Dept Psychol & Life Sci, Prague, Czech Republic.
   [Hula, Martin; Surovy, Peter] Czech Univ Life Sci, Fac Forestry & Wood Sci, EVA4 0, Prague, Czech Republic.
   [Herrova, Anna] Czech Univ Life Sci, Fac Forestry & Wood Sci, Dept Forest Management, Prague, Czech Republic.
C3 Charles University Prague; Czech University of Life Sciences Prague;
   Czech University of Life Sciences Prague
RP Hejtmánek, L (corresponding author), Charles Univ Prague, Fac Humanities, Dept Psychol & Life Sci, Prague, Czech Republic.; Surovy, P (corresponding author), Czech Univ Life Sci, Fac Forestry & Wood Sci, EVA4 0, Prague, Czech Republic.
EM lukas.hejtmanek@fhs.cuni.cz; surovy@fld.czu.cz
RI Hejtmánek, Lukáš/U-9181-2018
FU EVA4.0 project - OPR DE [CZ.02.1.01/0.0/0.0/16_019/0000803]; Cooperatio
   Program [207 33]; Charles University [207 33]; EU
FX The project was supported by EVA4.0 project reg. No
   CZ.02.1.01/0.0/0.0/16_019/0000803 awarded by OPR DE and EU and the
   Cooperatio Program, research area PSYC, project number 207 333, awarded
   by Charles University.
CR Abbott R, 2022, ACTA ASTRONAUT, V197, P145, DOI 10.1016/j.actaastro.2022.05.025
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Antonelli M, 2022, INT J ENVIRON HEAL R, V32, P1842, DOI 10.1080/09603123.2021.1919293
   Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Barton J, 2010, ENVIRON SCI TECHNOL, V44, P3947, DOI 10.1021/es903183r
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Björling E, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.831026
   Chiang YC, 2017, LANDSCAPE URBAN PLAN, V167, P72, DOI 10.1016/j.landurbplan.2017.06.001
   Cho KS, 2017, TOX RESEARCH, V33, P97, DOI 10.5487/TR.2017.33.2.097
   Corazon SS, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16101711
   CURRAN SL, 1995, PSYCHOL ASSESSMENT, V7, P80, DOI 10.1037/1040-3590.7.1.80
   D'Cunha NM, 2019, GERONTOLOGY, V65, P430, DOI 10.1159/000500040
   Franco LS, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14080864
   Frost S, 2022, J ENVIRON PSYCHOL, V80, DOI 10.1016/j.jenvp.2022.101765
   Gao T, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16173102
   Grilli G, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176125
   Guan H, 2017, ANN FOR RES, V60, P327, DOI 10.15287/afr.2017.897
   Hansen MM, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14080851
   Hartig T, 2003, J ENVIRON PSYCHOL, V23, P109, DOI 10.1016/S0272-4944(02)00109-3
   Ideno Y, 2017, BMC COMPLEM ALTERN M, V17, DOI 10.1186/s12906-017-1912-z
   Jia BB, 2016, BIOMED ENVIRON SCI, V29, P212, DOI 10.3967/bes2016.026
   Kaplan R., 1995, EXPERIENCE NATURE PS
   Kaplan S., 1988, Environmental aesthetics: Theory, research, and applications, DOI 10.1017/CBO9780511571213.006
   Kellert S. R., 1995, The Biophilia Hypothesis
   Kelly Jonathan W., 2022, Frontiers in Virtual Reality, V3, P27
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Koga K, 2013, J PHYSIOL ANTHROPOL, V32, DOI 10.1186/1880-6805-32-7
   Kondo MC, 2018, HEALTH PLACE, V51, P136, DOI 10.1016/j.healthplace.2018.03.001
   Korpela KM, 2008, HEALTH PLACE, V14, P636, DOI 10.1016/j.healthplace.2007.10.008
   Kotera Y, 2022, INT J MENT HEALTH AD, V20, P337, DOI 10.1007/s11469-020-00363-4
   Litleskare S, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17051738
   Luo SX, 2022, LANDSCAPE URBAN PLAN, V220, DOI 10.1016/j.landurbplan.2021.104336
   Mao GX, 2012, J CARDIOL, V60, P495, DOI 10.1016/j.jjcc.2012.08.003
   Martens D, 2011, J ENVIRON PSYCHOL, V31, P36, DOI 10.1016/j.jenvp.2010.11.001
   Mattila O, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106295
   Mygind L, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00943
   Oh B, 2017, ENVIRON HEALTH PREV, V22, DOI 10.1186/s12199-017-0677-9
   Oh KH, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17030685
   Park Bum Jin, 2010, Environmental Health and Preventive Medicine, V15, P18, DOI 10.1007/s12199-009-0086-9
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Pretty J, 2007, J ENVIRON PLANN MAN, V50, P211, DOI 10.1080/09640560601156466
   Pretty J., 2003, GREEN EXERCISE COMPL
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reese G, 2022, VIRTUAL REAL-LONDON, V26, P1245, DOI 10.1007/s10055-022-00631-9
   Rosa CD, 2021, URBAN FOR URBAN GREE, V57, DOI 10.1016/j.ufug.2020.126943
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Simkin J, 2020, URBAN FOR URBAN GREE, V48, DOI 10.1016/j.ufug.2019.126567
   Skoluda N, 2015, PSYCHONEUROENDOCRINO, V51, P227, DOI 10.1016/j.psyneuen.2014.10.002
   Sonntag-Öström E, 2014, URBAN FOR URBAN GREE, V13, P344, DOI 10.1016/j.ufug.2013.12.007
   Takayama N, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14070800
   Ulrich R., 1983, Behavior and the Natural Environment, P85, DOI [DOI 10.1007/978-1-4613-3539-94, DOI 10.1007/978-1-4613-3539-9_4]
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   Unal AB, 2022, URBAN FOR URBAN GREE, V74, DOI 10.1016/j.ufug.2022.127673
   Van den Berg AE, 2014, LANDSCAPE URBAN PLAN, V127, P173, DOI 10.1016/j.landurbplan.2014.04.012
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   White MP, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44097-3
   White MP, 2018, NEUROPSYCH DIS TREAT, V14, P3001, DOI 10.2147/NDT.S179038
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
   Wilson E.O., 1984, P1
NR 59
TC 9
Z9 9
U1 4
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 23
PY 2022
VL 3
AR 1033708
DI 10.3389/frvir.2022.1033708
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XZ3
UT WOS:001023324000001
OA gold
DA 2024-07-18
ER

PT J
AU Dewitz, B
   Bibo, R
   Moazemi, S
   Kalkhoff, S
   Recker, S
   Liebrecht, A
   Lichtenberg, A
   Geiger, C
   Steinicke, F
   Aubin, H
   Schmid, F
AF Dewitz, Bastian
   Bibo, Roman
   Moazemi, Sobhan
   Kalkhoff, Sebastian
   Recker, Stephan
   Liebrecht, Artur
   Lichtenberg, Artur
   Geiger, Christian
   Steinicke, Frank
   Aubin, Hug
   Schmid, Falko
TI Real-time 3D scans of cardiac surgery using a single optical-see-through
   head-mounted display in a mobile setup
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE HoloLens 2; telemedicine; telementoring; cardiac surgery; augmented
   reality; virtual reality
ID AUGMENTED REALITY; VISUALIZATION; HOLOLENS
AB Microsoft HoloLens 2 (HL2) is often found in research and products as a cutting-edge device in Mixed Reality medical applications. One application is surgical telementoring, that allows a remote expert to support surgeries in real-time from afar. However, in this field of research two problems are encountered: First, many systems rely on additional sensors to record the surgery in 3D which makes the deployment cumbersome. Second, clinical testing under real-world surgery conditions is only performed in a small number of research works. In this article, we present a standalone system that allows the capturing of 3D recordings of open cardiac surgeries under clinical conditions using only the existing sensors of HL2. We show difficulties that arose during development, especially related to the optical system of the HL2, and present how they can be solved. The system has successfully been used to record surgeries from the surgeons point of view and the obtained material can be used to reconstruct a 3D view for evaluation by an expert. In a preliminary study, we present a recording of a captured surgery under real-world clinical conditions to expert surgeons which estimate the quality of the recordings and their overall applicability for diagnosis and support. The study shows benefits from a 3D reconstruction compared to video-only transmission regarding perceived quality and feeling of immersion.
C1 [Dewitz, Bastian; Bibo, Roman; Moazemi, Sobhan; Kalkhoff, Sebastian; Liebrecht, Artur; Lichtenberg, Artur; Aubin, Hug; Schmid, Falko] Heinrich Heine Univ Dusseldorf, Med Fac, Dept Cardiac Surg, Dusseldorf, Germany.
   [Dewitz, Bastian; Steinicke, Frank] Univ Hamburg, Inst Human Comp Interact, Dept Informat, Hamburg, Germany.
   [Dewitz, Bastian; Steinicke, Frank] Univ HospitalDusseldorf, Heinrich Heine Univ Dusseldorf, Dusseldorf, Germany.
   [Recker, Stephan] Dortmund Univ Appl Sci & Arts, Comp Sci Fac, Dortmund, Germany.
   [Geiger, Christian] Univ Appl Sci Dusseldorf, Fac Media, Dusseldorf, Germany.
C3 Heinrich Heine University Dusseldorf; University of Hamburg; Heinrich
   Heine University Dusseldorf
RP Dewitz, B (corresponding author), Heinrich Heine Univ Dusseldorf, Med Fac, Dept Cardiac Surg, Dusseldorf, Germany.; Dewitz, B (corresponding author), Univ Hamburg, Inst Human Comp Interact, Dept Informat, Hamburg, Germany.; Dewitz, B (corresponding author), Univ HospitalDusseldorf, Heinrich Heine Univ Dusseldorf, Dusseldorf, Germany.
EM bastian.dewitz@med.uni-duesseldorf.de
RI Steinicke, Frank/AAC-2976-2020; Moazemi, Sobhan/AAY-1712-2021
OI Steinicke, Frank/0000-0001-9879-7414; Moazemi,
   Sobhan/0000-0003-3277-3596
FU Ministry for Economic Affairs, Innovation, Digitalization and Energy of
   the State of North Rhine-Westphalia, Germany; GIGA FOR HEALTH:
   5G-Medizincampus NRW [005-2008-0055]
FX This research work was funded by the Ministry for Economic Affairs,
   Innovation, Digitalization and Energy of the State of North
   Rhine-Westphalia, Germany, in the project GIGA FOR HEALTH:
   5G-Medizincampus NRW. The funding project number is: 005-2008-0055.
CR Bajzik J., 2020, P 24 INT C EL LITH, P1, DOI DOI 10.1109/IEEECONF49502.2020.9141621
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Berger M., 2014, Eurographics 2014-State of the Art Reports, V1, P161, DOI [DOI 10.2312/EGST.20141040, 10.2312/egst.20141040]
   Berguer R, 1999, ARCH SURG-CHICAGO, V134, P1011, DOI 10.1001/archsurg.134.9.1011
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Birlo M, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2022.102361
   Bornkessel C, 2021, PROC EUR CONF ANTENN
   Bradski G, 2000, DR DOBBS J, V25, P120
   Carbone M, 2020, SURG INNOV, V27, P254, DOI 10.1177/1553350620903197
   Choudhary Zubin, 2021, SUI '21: Symposium on Spatial User Interaction, DOI 10.1145/3485279.3488286
   Choudhary Z., 2021, SCALED USER EMBODIED, V1, DOI [10.18420/muc2021-mci-ws16-361, DOI 10.18420/MUC2021-MCI-WS16-361]
   Clarke T., 2020, HOLOLENS 2 VIVE PUCK
   Clarke T., 2020, HOLOLENS 2 MOUNT ZED
   da Silva JG, 2020, SYMP VIRTUAL AUGMENT, P252, DOI 10.1109/SVR51698.2020.00046
   Desselle MR, 2020, COMPUT SCI ENG, V22, P18, DOI 10.1109/MCSE.2020.2972822
   Erickson A, 2019, INT SYM MIX AUGMENT, P202, DOI [10.1109/ISMAR.2019.000-2, 10.1109/ISMAR.2019.00-2]
   Erridge S, 2019, SURG INNOV, V26, P95, DOI 10.1177/1553350618813250
   Fazlali HR, 2018, MED BIOL ENG COMPUT, V56, P1515, DOI 10.1007/s11517-018-1793-4
   Galati R, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8851964
   García-Vázquez V, 2018, INNOV SURG SCI, V3, P167, DOI 10.1515/iss-2018-2001
   Garon M, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P189, DOI [10.1109/ISMAR-Adjunct.2016.0073, 10.1109/ISMAR-Adjunct.2016.64]
   Gasques Danilo, 2021, P 2021 CHI C HUMAN F, P1
   Gsaxner C., 2021, HOLOLENS2 UNITY RES
   Gsaxner C, 2019, LECT NOTES COMPUT SC, V11768, P236, DOI 10.1007/978-3-030-32254-0_27
   Gudivada V., 2017, International Journal on Advances in Software, V10, P1
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Jiang H, 2019, 2019 SPRING SIMULATION CONFERENCE (SPRINGSIM), DOI 10.23919/springsim.2019.8732876
   Jung J, 2015, IEEE T PATTERN ANAL, V37, P1501, DOI 10.1109/TPAMI.2014.2363827
   Kowalski M., 2018, ARXIV
   Lawrence J., 2021, PROJECT STARLINE HIG
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Leuze C. M. J., 2018, P SOC NEUR PAR FRANC
   Liebmann F, 2019, INT J COMPUT ASS RAD, V14, P1157, DOI 10.1007/s11548-019-01973-7
   Long YH, 2024, Arxiv, DOI arXiv:2204.04377
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Microsoft, 2022, MIXEDREALITY WEBRTC
   Mitsuno D, 2019, PLAST RECONSTR SURG, V143, P647, DOI 10.1097/PRS.0000000000005215
   Moezzi Reza, 2022, Proceedings of the International Conference on Intelligent Vision and Computing (ICIVC 2021). Proceedings in Adaptation, Learning and Optimization (15), P507, DOI 10.1007/978-3-030-97196-0_42
   Mohr P., 2021, P 2019 CHI C HUM FAC
   Navab N, 2012, COMPUTER, V45, P48, DOI 10.1109/MC.2012.75
   Nowak J., 2021, POINT CLOUDS COLOR S, P1, DOI [10.1109/MFI52462.2021.9591200i, DOI 10.1109/MFI52462.2021.9591200]
   ORBBEC, 2022, ASTR ORBB 3D
   Park BJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75676-4
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167259
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   Pratt P, 2018, EUR RADIOL EXP, V2, DOI 10.1186/s41747-017-0033-2
   Qian L, 2022, IEEE T VIS COMPUT GR, V28, P2550, DOI 10.1109/TVCG.2020.3037284
   ROBERTS DW, 1986, J NEUROSURG, V65, P545, DOI 10.3171/jns.1986.65.4.0545
   Rojas-Muñoz E, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0284-9
   Rojas-Muñoz E, 2020, SURGERY, V167, P724, DOI 10.1016/j.surg.2019.11.008
   Rosser JC, 2007, SURG ENDOSC, V21, P1458, DOI 10.1007/s00464-007-9263-3
   Rosser James C Jr, 2003, Semin Laparosc Surg, V10, P209, DOI 10.1177/107155170301000409
   Schlosser PD, 2019, J CLIN MONIT COMPUT, V33, P1119, DOI 10.1007/s10877-019-00265-4
   Sielhorst T, 2008, J DISP TECHNOL, V4, P451, DOI 10.1109/JDT.2008.2001575
   Stearns L, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P361, DOI 10.1145/3132525.3134512
   Stearns L, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P28, DOI 10.1145/3234695.3236361
   Stereolabs, 2022, ZED MIN MIX REAL CAM
   Sylos Labini Mauro, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P716, DOI 10.1007/978-3-030-26766-7_65
   Ungureanu D., 2020, ARXIV200811239
   Vassallo R, 2017, PROC SPIE, V10136, DOI 10.1117/12.2255831
   Von Haxthausen Felix, 2021, Current Directions in Biomedical Engineering, V7, P111, DOI 10.1515/cdbme-2021-1024
   Wenhao, 2021, HOLOLENS2 RESEARCHMO
   Wilson AD, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P100, DOI 10.1145/3132272.3134144
   XRGO, 2021, STYL XR AR MR VR INP
   Xue H, 2019, COMPUTERS, V8, DOI 10.3390/computers8010009
   Yi X, 2020, J DIGIT IMAGING, V33, P181, DOI 10.1007/s10278-019-00201-7
   Yoon H, 2021, APPL SYST INNOV, V4, DOI 10.3390/asi4030056
   Yoon JW, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1836
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13386
NR 71
TC 3
Z9 3
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 27
PY 2022
VL 3
AR 949360
DI 10.3389/frvir.2022.949360
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WO7
UT WOS:001023287300001
OA gold
DA 2024-07-18
ER

PT J
AU Timonen, T
   Iso-Mustajaervi, M
   Linder, P
   Vrzakova, H
   Sinkkonen, ST
   Luukkainen, V
   Laitakari, J
   Elomaa, AP
   Dietz, A
AF Timonen, Tomi
   Iso-Mustajaervi, Matti
   Linder, Pia
   Vrzakova, Hana
   Sinkkonen, Saku T.
   Luukkainen, Veera
   Laitakari, Jaakko
   Elomaa, Antti-Pekka
   Dietz, Aarno
TI The feasibility of virtual reality for anatomic training during temporal
   bone dissection course
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; surgical training; surgical planning; temporal bone;
   cadaver; surgical performance
ID SURGICAL SKILLS; PERFORMANCE; SIMULATION; IMPROVE; TOOL
AB Introduction: In recent decades, the lack of educational resources for cadaveric dissections has complicated the hands-on otological surgical training of otorhinolaryngology residents due to the poor availability of cadaver temporal bones, facilities, and limited hours for practice. Since students must gain adequate and patient-safe surgical skills, novel training methods need to be considered. In this proof-of-concept study, a new virtual reality (VR) software is described; this was used during a national temporal bone dissection course where we investigated its feasibility for otological surgical training. Methods: A total of 11 otorhinolaryngology residents attended the annual 2-day hands-on temporal bone dissection course; they were divided into two groups with similar experience levels. Both groups received a lecture on temporal bone anatomy. A total of 22 cadaver temporal bones were harvested for the course; 11 of these bones were imaged by computed tomography. VR software designed for preoperative planning was then used to create 3D models of the imaged temporal bones. Prior to dissection training, the first group underwent a 30-min VR session, where they identified 24 surgically relevant anatomical landmarks on their individual temporal bone. The second group proceeded directly to dissection training. On the second day, the groups were switched. The feasibility of VR training was assessed with three different metrics: surgical performance evaluation using a modified Hopkins objective structured assessment of technical skill (OSATS), time for the surgical exposure of anatomical landmarks, and the user experience collected with a Likert scale questionnaire. Results: No differences were noted in the overall performance between the groups. However, participants with prior VR training had a lower mean time for surgical exposure of anatomical landmarks (antrum 22.09 vs. 27.64 min, p = 0.33; incus 60.00 vs. 76.00, p = 0.03; PSCC 71.83 vs. 88.50, p = 0.17) during dissection training. The participants considered VR beneficial for anatomy teaching, surgery planning, and training. Conclusion: This study demonstrated the feasibility of implementing VR training in a temporal bone dissection course. The VR training demonstrated that even short expert-guided VR sessions are beneficial, and VR training prior to the dissections has a positive effect on the time needed to perform surgical tasks while maintaining comparable performance scores.
C1 [Timonen, Tomi; Iso-Mustajaervi, Matti; Linder, Pia; Dietz, Aarno] Kuopio Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Kuopio, Finland.
   [Timonen, Tomi] Univ Eastern Finland, Inst Clin Med, Sch Med, Kuopio, Finland.
   [Iso-Mustajaervi, Matti; Elomaa, Antti-Pekka] Kuopio Univ Hosp, Microsurg Training Ctr, Kuopio, Finland.
   [Vrzakova, Hana] Univ Eastern Finland, Sch Comp, Kuopio, Finland.
   [Sinkkonen, Saku T.; Luukkainen, Veera] Univ Helsinki, Helsinki Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Helsinki, Finland.
   [Sinkkonen, Saku T.; Luukkainen, Veera] Helsinki Univ Hosp, Tauno Palva Lab, Helsinki, Finland.
   [Laitakari, Jaakko] Oulu Univ, Oulu Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, PEDEGO, Oulu, Finland.
   [Elomaa, Antti-Pekka] Kuopio Univ Hosp, Dept Neurosurg, Kuopio, Finland.
C3 University of Eastern Finland; Kuopio University Hospital; University of
   Eastern Finland; Kuopio University Hospital; University of Eastern
   Finland; University of Eastern Finland; University of Helsinki; Helsinki
   University Central Hospital; University of Helsinki; Helsinki University
   Central Hospital; University of Oulu; University of Eastern Finland;
   Kuopio University Hospital
RP Timonen, T (corresponding author), Kuopio Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Kuopio, Finland.; Timonen, T (corresponding author), Univ Eastern Finland, Inst Clin Med, Sch Med, Kuopio, Finland.
EM tomi.timonen@kuh.fi
RI Iso-Mustajärvi, Matti/ADE-2126-2022
OI Iso-Mustajärvi, Matti/0000-0003-3871-8504; Vrzakova,
   Hana/0000-0002-5624-8588
FU Academy of Finland [333525]; State Research Funding of the Kuopio
   University Hospital [5551865, 5551853]; Finnish ORL-HNS Foundation
   [20210002, 20220027]; North Savo Regional Fund [65202121, 65202054];
   Finnish Cultural Foundation [00211098]; Finnish Society of Ear Surgery
FX The study was funded by the Academy of Finland (AD Grant No. 333525),
   State Research Funding of the Kuopio University Hospital (TT Grant No.
   5551865, AD Grant No. 5551853), The Finnish ORL-HNS Foundation (TT Grant
   No. 20210002 and No. 20220027), North Savo Regional Fund (TT Grant No.
   65202121, AD Grant No. 65202054), Finnish Cultural Foundation (TT Grant
   No. 00211098), and The Finnish Society of Ear Surgery.
CR Al-Noury K, 2012, INDIAN J OTOLARYNGOL, V64, P162, DOI 10.1007/s12070-011-0290-y
   Andersen SAW, 2021, LARYNGOSCOPE, V131, P1855, DOI 10.1002/lary.29542
   Andersen SAW, 2018, OTOL NEUROTOL, V39, P1277, DOI 10.1097/MAO.0000000000002031
   Andersen SAW, 2016, LARYNGOSCOPE, V126, P1883, DOI 10.1002/lary.25710
   Andersen SA, 2015, JAMA OTOLARYNGOL, V141, P913, DOI 10.1001/jamaoto.2015.1563
   Arora A, 2012, OTOLARYNG HEAD NECK, V146, P497, DOI 10.1177/0194599811427385
   Chen S, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-02255-6
   Compton EC, 2020, J OTOLARYNGOL-HEAD N, V49, DOI 10.1186/s40463-020-00411-y
   D'Angelo ALD, 2015, AM J SURG, V209, P645, DOI 10.1016/j.amjsurg.2014.12.013
   Dedmon MM, 2017, AM J OTOLARYNG, V38, P526, DOI 10.1016/j.amjoto.2017.04.005
   Fang TY, 2014, COMPUT METH PROG BIO, V113, P674, DOI 10.1016/j.cmpb.2013.11.005
   Francis HW, 2012, LARYNGOSCOPE, V122, P1385, DOI 10.1002/lary.22378
   Frithioff A, 2018, EUR ARCH OTO-RHINO-L, V275, P357, DOI 10.1007/s00405-017-4824-0
   Gadaleta DJ, 2020, AM J OTOLARYNG, V41, DOI 10.1016/j.amjoto.2019.08.004
   Gawecki W, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103197
   George AP, 2010, J LARYNGOL OTOL, V124, P119, DOI 10.1017/S0022215109991617
   Ghosh SK, 2017, ANAT SCI EDUC, V10, P286, DOI 10.1002/ase.1649
   Herur-Raman A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.693399
   Kashikar TS, 2019, LARYNGOSCOPE INVEST, V4, P420, DOI 10.1002/lio2.277
   Laeeq K, 2009, LARYNGOSCOPE, V119, P2402, DOI 10.1002/lary.20678
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Li M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.675334
   Locketz GD, 2017, OTOLARYNG HEAD NECK, V156, P1142, DOI 10.1177/0194599817691474
   Lui JT, 2017, OTOLARYNG HEAD NECK, V156, P1018, DOI 10.1177/0194599817698440
   Mackay S, 2002, SURG ENDOSC, V16, P957, DOI 10.1007/s00464-001-9132-4
   Mills R, 2003, J LARYNGOL OTOL, V117, P159, DOI 10.1258/002221503321192412
   Mohamadipanah H, 2021, J SURG ONCOL, V124, P200, DOI 10.1002/jso.26519
   Nash R, 2012, J LARYNGOL OTOL, V126, P663, DOI 10.1017/S0022215112000734
   Rajpal S, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.10099
   Reznick RK, 2006, NEW ENGL J MED, V355, P2664, DOI 10.1056/NEJMra054785
   Sánchez-Margallo JA, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.692641
   Sanna M., 2018, TEMPORAL BONE ANATOM
   Sethia R, 2015, CURR OPIN OTOLARYNGO, V23, P355, DOI 10.1097/MOO.0000000000000181
   Thukral CL, 2015, J CLIN DIAGN RES, V9, pTC7, DOI 10.7860/JCDR/2015/12268.6508
   Timonen T, 2022, EUR ARCH OTO-RHINO-L, V279, P4303, DOI 10.1007/s00405-021-07183-9
   Timonen T, 2021, EUR ARCH OTO-RHINO-L, V278, P2795, DOI 10.1007/s00405-020-06360-6
   Xu XH, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.692103
   Yammine K, 2015, ANAT SCI EDUC, V8, P525, DOI 10.1002/ase.1510
   Zhao JJ, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-1994-z
   Zhao YC, 2011, LARYNGOSCOPE, V121, P831, DOI 10.1002/lary.21287
   Zhao YC, 2011, OTOLARYNG HEAD NECK, V144, P357, DOI 10.1177/0194599810391624
NR 41
TC 1
Z9 1
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 15
PY 2022
VL 3
AR 957230
DI 10.3389/frvir.2022.957230
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WX9
UT WOS:001023296500001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Rheu, MMJ
   Ratan, R
   Sah, YJ
   Cherchiglia, L
   Day, T
AF Rheu, Minjin M. J.
   Ratan, Rabindra
   Sah, Young June
   Cherchiglia, Leticia
   Day, Tom
TI Jogging in Your Avatar's Footsteps: The Effects of Avatar Customization
   and Control Intuitiveness
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE avatars; embodiment; identification; physical activity; game design for
   health
ID AFFECTS PHYSICAL-ACTIVITY; ACTIVE VIDEO GAMES; CONCEPTUALIZING
   IDENTIFICATION; SELF; EMBODIMENT; BODY; BOWMAN; THREAT; DOWNS; SEE
AB This study examined the effects of customization and intuitiveness of control on the feeling of identification and embodiment, and the actual running performance of game players after playing a digital runner game developed for this research. A 2 (avatar design: customized vs. not customized) x 2 (avatar controls: intuitive vs. not intuitive) within-subjects experiment (N = 44) found that playing the game with a customized avatar increased identification with and embodiment in the avatar. However, using unintuitive controls with a customized avatar diminished the feeling of identification. Customizing an avatar increased identification with and embodiment in the avatar. However, using unintuitive controls with a customized avatar diminished the feeling of identification. Further, participants' running performance was significantly hindered in the customized avatar and unintuitive controls condition, compared to the other conditions. The expectation that identification and embodiment would mediate the effect of avatar customization and control intuitiveness on physical activity was not supported. Together, these results suggest that avatar customization and control intuitiveness should be prioritized when designers intend to use video games to promote post-game physical activity.
C1 [Rheu, Minjin M. J.] Loyola Univ Chicago, Sch Commun, Chico, IL 60660 USA.
   [Ratan, Rabindra; Cherchiglia, Leticia; Day, Tom] Michigan State Univ, Dept Media & Informat, E Lansing, MI USA.
   [Sah, Young June] Sogang Univ, Sch Media Arts & Sci, Seoul, South Korea.
C3 Loyola University Chicago; Michigan State University; Sogang University
RP Rheu, MMJ (corresponding author), Loyola Univ Chicago, Sch Commun, Chico, IL 60660 USA.
EM mrheu@luc.edu
CR [Anonymous], 2001, MASS COMMUN SOC, DOI DOI 10.1207/S15327825MCS0403_01
   [Anonymous], 2017, AVATAR ASSEMBLED SOC
   Bargh JA, 2002, J SOC ISSUES, V58, P33, DOI 10.1111/1540-4560.00247
   Biddiss E, 2010, ARCH PEDIAT ADOL MED, V164, P664, DOI 10.1001/archpediatrics.2010.104
   Biocca F, 1999, HUM FAC INF, V13, P113, DOI 10.1016/S0923-8433(99)80011-2
   Birk MV, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174234
   Black D, 2017, GAMES CULT, V12, P179, DOI 10.1177/1555412015589175
   Bowman ND, 2020, PSYCHOL POP MEDIA, V9, P283, DOI 10.1037/ppm0000238
   Christou C, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON GAMES AND VIRTUAL WORLDS FOR SERIOUS APPLICATIONS (VS-GAMES)
   Christy KR, 2016, CYBERPSYCH BEH SOC N, V19, P283, DOI 10.1089/cyber.2015.0474
   Dolgov I, 2014, COMPUT HUM BEHAV, V33, P49, DOI 10.1016/j.chb.2013.12.028
   Downs E, 2019, PSYCHOL POP MEDIA CU, V8, P269, DOI 10.1037/ppm0000170
   Ducheneaut N, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1151
   Fox J, 2013, COMPUT HUM BEHAV, V29, P930, DOI 10.1016/j.chb.2012.12.027
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Granqvist A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P201, DOI 10.1145/3242671.3242694
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Hufnal D., 2019, 2019 IEEE GAM ENT, P1
   Jin SAA, 2009, CYBERPSYCHOL BEHAV, V12, P761, DOI 10.1089/cpb.2009.0130
   Kim SY, 2014, COMPUT HUM BEHAV, V36, P376, DOI 10.1016/j.chb.2014.03.067
   Klimmt C, 2009, COMMUN THEOR, V19, P351, DOI 10.1111/j.1468-2885.2009.01347.x
   Lee-Won RJ, 2017, CYBERPSYCH BEH SOC N, V20, P10, DOI 10.1089/cyber.2016.0418
   Li B. J., 2014, EXERCISE ATTITUDE MO, DOI [10.1037/t46181-000, DOI 10.1037/T46181-000]
   McArthur V, 2019, BEHAV INFORM TECHNOL, V38, P230, DOI 10.1080/0144929X.2018.1526969
   McDade-Montez E, 2020, PSYCHOL POP MEDIA, V9, P279, DOI 10.1037/ppm0000225
   Montoya AK, 2019, BEHAV RES METHODS, V51, P61, DOI 10.3758/s13428-018-1088-6
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Peña J, 2014, COMPUT HUM BEHAV, V41, P262, DOI 10.1016/j.chb.2014.09.038
   Peña J, 2016, J COMPUT-MEDIAT COMM, V21, P195, DOI 10.1111/jcc4.12151
   Peña J, 2009, COMMUN RES, V36, P838, DOI 10.1177/0093650209346802
   Peng W, 2013, HEALTH EDUC BEHAV, V40, P171, DOI 10.1177/1090198112444956
   Pimentel D, 2021, NEW MEDIA SOC, V23, P2230, DOI 10.1177/1461444821993124
   Przybylski AK, 2012, PSYCHOL SCI, V23, P69, DOI 10.1177/0956797611418676
   Ratan R., 2013, HDB RES TECHNOSELF I, P322, DOI [10.4018/978-1-4666-2211-1.ch018, DOI 10.4018/978-1-4666-2211-1.CH018]
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Ratan R, 2015, COMPUT HUM BEHAV, V50, P367, DOI 10.1016/j.chb.2015.04.010
   Ratan RA, 2016, COMMUN RES, V43, P1065, DOI 10.1177/0093650215570652
   Roth D, 2019, Arxiv, DOI arXiv:1911.10176
   Seibert J, 2018, VIRTUAL REAL-LONDON, V22, P79, DOI 10.1007/s10055-017-0316-1
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Song W, 2016, MASS COMMUN SOC, V19, P197, DOI 10.1080/15205436.2015.1077972
   Trepte S., 2010, J MEDIA PSYCHOL-GER, V22, P171, DOI [DOI 10.1027/1864-1105/A000022, https://doi.org/10.1027/1864-1105/a000022]
   Turkay S., 2015, Gamification: Concepts, methodologies, tools, and applications, P247, DOI DOI 10.4018/978-1-4666-8200-9.CH012
   Van Looy J, 2012, MEDIA PSYCHOL, V15, P197, DOI 10.1080/15213269.2012.674917
   Velez JA, 2013, J MEDIA PSYCHOL-GER, V25, P190, DOI 10.1027/1864-1105/a000102
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, MEDIA PSYCHOL, V12, P195, DOI 10.1080/15213260902849943
   Yoon G, 2014, PSYCHOL SCI, V25, P1043, DOI 10.1177/0956797613519271
NR 49
TC 1
Z9 1
U1 3
U2 14
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 23
PY 2022
VL 3
AR 873689
DI 10.3389/frvir.2022.873689
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8UG2
UT WOS:001019126900001
OA gold
DA 2024-07-18
ER

PT J
AU Lim, KYT
   Li, SCX
AF Lim, Kenneth Y. T.
   Li, Samuel C. X.
TI Personal Spaces and Communal Consequences: Navigating Geographical
   Tensions With the Socially Responsible Behavior through Embodied
   Thinking (SORBET) Project
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE geography; novice intuitions; social responsibility; COVID-19; embodied
   cognition; cultural-historical activity theory
ID REALITY
AB The COVID-19 pandemic has impacted societies in different ways. This variation is inherently geographical with patterns across space and time reflecting underlying societal inequalities. This study describes a learning intervention designed to afford participants opportunities to experience the diffusion of a (virtual) virus within a community, albeit in a safe way. The intervention was enacted in March 2021 among nine undergraduate teachers-in-training at a teacher-education institute in Singapore. Participants were invited to reflect on the connections between their personal decision-making and its impact on the broader community, after having first undertaken a collaborative task in a virtual environment. The Socially Responsible Behavior through Embodied Thinking (SORBET) Project draws on the learning sciences in terms of embodied cognition and projective identity, and in this study, seeks to apply them to geographical understandings of diffusion. Responses from post-activity interviews are reported along three themes, as structured by the cultural-historical activity theory. Through encouraging reflection on authentic experience, the authors hope to catalyze a more grounded appreciation of the need to practice positive social habits in the context of a pandemic and by extension, contribute to the fight against the virus through the application of geographical thinking at local and global scales.
C1 [Lim, Kenneth Y. T.; Li, Samuel C. X.] Nanyang Technol Univ, Natl Inst Educ, Singapore, Singapore.
C3 Nanyang Technological University; National Institute of Education (NIE)
   Singapore
RP Lim, KYT (corresponding author), Nanyang Technol Univ, Natl Inst Educ, Singapore, Singapore.
EM kenneth.lim@nie.edu.sg
CR Andersson D, 2009, INFORM PROCESS LETT, V109, P1145, DOI 10.1016/j.ipl.2009.07.017
   [Anonymous], 2014, Learning by expanding: An activity-theoretical approach to developmental research
   BARRIBALL KL, 1994, J ADV NURS, V19, P328
   Barsalou LW, 2010, TOP COGN SCI, V2, P716, DOI 10.1111/j.1756-8765.2010.01115.x
   Batty M, 1997, FUTURES, V29, P337, DOI 10.1016/S0016-3287(97)00018-9
   Coelho LC, 2019, Arxiv, DOI arXiv:1905.00973
   Clark A, 2017, A companion to cognitive science, P506
   Cresswell T., 2013, Geographic thought: a critical introduction, V8
   Gee JP, 2003, WHAT VIDEO GAMES HAVE TO TEACH US ABOUT LEARNING AND LITERACY, P1
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Goetz J. P., 1984, Ethnography and qualitative design in educational research
   Gordon E., 2008, Space and Culture, V11, P200
   Granito M., 2012, EFFECT TECHNOLOGY ST
   Gregory Derek., 2011, DICT HUMAN GEOGRAPHY
   Heafner T., 2004, CONT ISSUES TECHNOLO, V4, P42
   Kearsley G., 1998, Educational Technology, V38, P20
   LAMBERT D, 2017, HDB SECONDARY GEOGRA, P20
   Lefebvre Henri, 1991, The production of space
   Leont'ev A.N., 1981, Problems of the development of the mind
   Lim K. Y. T., 2022, SCALING ICT BASED IN
   Lim K. Y. T., 2015, DISCIPLINARY INTUITI
   Lim KYT, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P255
   Lincoln Y.S., 1989, NATURALISTIC INQUIRY
   Mahon BZ, 2015, LANG COGN NEUROSCI, V30, P420, DOI 10.1080/23273798.2014.987791
   Mansilla V.B., 2009, Challenging the Whole Child: Reflections on Best Practices in Learning, Teaching, and Leadership, P97
   Ministry of Education, 2021, GEOGR SYLL UPP SEC
   OpenSimulator, 2020, WHAT IS OPENSIMULATO
   Ratey JohnJ., 2001, A User's Guide to the Brain: Perception, Attention, and the Four Theaters of the Brain
   Roth W.-M., 2012, FORUM QUAL SOZIALFOR, V13
   Roth WM, 2007, REV EDUC RES, V77, P186, DOI 10.3102/0034654306298273
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sasinka C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010003
   Shapiro L., 2019, Embodied Cognition, V2nd
   Smith T.W., 2007, Clearing House, V80, P205, DOI DOI 10.3200/TCHS.80.5.205-210
   SOJA Edward W., 1989, Postmodern Geographies. The Reassertion of Space in Critical Social Theory
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Syvyi MJ, 2022, Arxiv, DOI arXiv:2202.08697
   Thrift N., 2003, KEY CONCEPTS GEOGRAP, P95
   Turan Z, 2018, J GEOGR HIGHER EDUC, V42, P427, DOI 10.1080/03098265.2018.1455174
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Warburton K., 2003, International Journal of Sustainability in Higher Education, V4, P44, DOI [10.1108/14676370310455332, DOI 10.1108/14676370310455332]
   Yannie M., 2000, TechTrends, V44, P42, DOI [DOI 10.1007/BF02818192, 10.1007/bf02818192]
NR 42
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 24
PY 2022
VL 3
AR 863615
DI 10.3389/frvir.2022.863615
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VV3
UT WOS:001019168700001
OA gold
DA 2024-07-18
ER

PT J
AU Halbig, A
   Babu, SK
   Gatter, S
   Latoschik, ME
   Brukamp, K
   von Mammen, S
AF Halbig, Andreas
   Babu, Sooraj K.
   Gatter, Shirin
   Latoschik, Marc Erich
   Brukamp, Kirsten
   von Mammen, Sebastian
TI Opportunities and Challenges of Virtual Reality in Healthcare - A Domain
   Experts Inquiry
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; healthcare; therapy; rehabilitation; ethics; technology
   acceptance; authoring platform; healthcare professionals
ID TECHNOLOGY ACCEPTANCE MODEL; USER ACCEPTANCE; VR JUGGLER; SYSTEM;
   SYMPTOMS; PLATFORM; THERAPY; DEVICES; SCALE
AB In recent years, the applications and accessibility of Virtual Reality (VR) for the healthcare sector have continued to grow. However, so far, most VR applications are only relevant in research settings. Information about what healthcare professionals would need to independently integrate VR applications into their daily working routines is missing. The actual needs and concerns of the people who work in the healthcare sector are often disregarded in the development of VR applications, even though they are the ones who are supposed to use them in practice. By means of this study, we systematically involve health professionals in the development process of VR applications. In particular, we conducted an online survey with 102 healthcare professionals based on a video prototype which demonstrates a software platform that allows them to create and utilise VR experiences on their own. For this study, we adapted and extended the Technology Acceptance Model (TAM). The survey focused on the perceived usefulness and the ease of use of such a platform, as well as the attitude and ethical concerns the users might have. The results show a generally positive attitude toward such a software platform. The users can imagine various use cases in different health domains. However, the perceived usefulness is tied to the actual ease of use of the platform and sufficient support for learning and working with the platform. In the discussion, we explain how these results can be generalized to facilitate the integration of VR in healthcare practice.
C1 [Halbig, Andreas; Babu, Sooraj K.; Latoschik, Marc Erich; von Mammen, Sebastian] Julius Maximilians Univ, Human Comp Interact, Wurzburg, Germany.
   [Gatter, Shirin; Brukamp, Kirsten] Protestant Univ Appl Sci, Res Grp Hlth Technol Eth, Ludwigsburg, Germany.
C3 University of Wurzburg
RP Halbig, A (corresponding author), Julius Maximilians Univ, Human Comp Interact, Wurzburg, Germany.
EM andreas.halbig@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600
FU German Federal Ministry of Education and Research in the project VIA-VR
   [16SV8444, 16SV8445]; Open-Access Publication Fund of the University of
   Wurzburg
FX This publication was supported by the Open-Access Publication Fund of
   the University of Wurzburg. The research has been funded by the German
   Federal Ministry of Education and Research in the project VIA-VR
   (project numbers 16SV8444 and 16SV8445).
CR Allard J, 2004, LECT NOTES COMPUT SC, V3149, P497
   Allard J, 2002, P IEEE VIRT REAL ANN, P273, DOI 10.1109/VR.2002.996534
   Allard J., 2005, 9 INT WORKSH IMM PRO, P59
   Allard J, 2010, PRESENCE-TELEOP VIRT, V19, P142, DOI 10.1162/pres.19.2.142
   Andone D., 2019, AUGMENTED REALITY VI, P147, DOI [10.1007/978-3-030-06246-0_11, DOI 10.1007/978-3-030-06246-0_11]
   Angelov V, 2020, 2ND INTERNATIONAL CONGRESS ON HUMAN-COMPUTER INTERACTION, OPTIMIZATION AND ROBOTIC APPLICATIONS (HORA 2020), P520, DOI 10.1109/hora49412.2020.9152604
   [Anonymous], 2010, OPENSCENEGRAPH 3 0 B
   Arlati S., 2017, INT C WIR MOB COMM H, P117
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Balan O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020496
   Balog A, 2009, STUD INFORM CONTROL, V18, P137
   Beauchamp TL., 2019, Principles of Biomedical Ethics, V8th, DOI DOI 10.5915/43-3-8476
   Bethel W., 1999, ACM SIGGRAPH 99 C AB, V8, P136
   Bierbaum A, 2001, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2001.913774
   Borg G., 1998, BORGS PERCEIVED EXER, V104
   CARLSSON C, 1993, COMPUT GRAPH, V17, P663, DOI 10.1016/0097-8493(93)90115-P
   Cebeci B, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1893
   Chardonnet JR, 2021, VIRTUAL REAL-LONDON, V25, P565, DOI 10.1007/s10055-020-00474-2
   CONWAY M., 2000, P CHI 2000, P486
   Currie J, 2019, INT J COMPUT ASS RAD, V14, P645, DOI 10.1007/s11548-019-01918-0
   da Costa RMEM, 2004, COMPUT METH PROG BIO, V73, P173, DOI 10.1016/S0169-2607(03)00066-X
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dellazizzo L, 2020, J MED INTERNET RES, V22, DOI 10.2196/20889
   Dollinger N., 2019, MENSCH COMP 2019 WOR, P606
   Figueroa P., 2002, P 7 INT C 3D WEB TEC, P53
   Fischbach M, 2017, IEEE T VIS COMPUT GR, V23, P1407, DOI 10.1109/TVCG.2017.2657098
   Fussell SG, 2023, INTERACT LEARN ENVIR, V31, P5442, DOI 10.1080/10494820.2021.2009880
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Garcia-Palacios A, 2007, CYBERPSYCHOL BEHAV, V10, P722, DOI 10.1089/cpb.2007.9962
   Gianola S, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000019136
   Glémarec Y, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.666232
   Gonzalez D. S., 2016, 2016 21 S SIGNAL PRO, P1, DOI DOI 10.1109/STSIVA.2016.7743323
   Greenbaum D, 2015, NAT BIOTECHNOL, V33, P425, DOI 10.1038/nbt.3193
   GREENHALGH C, 1995, INT CON DISTR COMP S, P27, DOI 10.1109/ICDCS.1995.499999
   Groth Colin, 2021, 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P486, DOI 10.1109/VRW52623.2021.00125
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   Ham J, 2017, IEEE ENG MED BIO, P3989, DOI 10.1109/EMBC.2017.8037730
   Hamzeheinejad N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1421, DOI [10.1109/VR.2019.8797763, 10.1109/vr.2019.8797763]
   Hartanto D, 2012, STUD HEALTH TECHNOL, V181, P192, DOI 10.3233/978-1-61499-121-2-192
   Haugstvedt AC, 2012, INT SYM MIX AUGMENT, P247, DOI 10.1109/ISMAR.2012.6402563
   Herumurti D, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, ARTIFICIAL INTELLIGENCE, AND COMMUNICATIONS TECHNOLOGY (IAICT), P139, DOI [10.1109/ICIAICT.2019.8784846, 10.1109/iciaict.2019.8784846]
   Hesina G., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P74, DOI 10.1145/323663.323675
   Hilton D, 2011, STUD COMPUT INTELL, V337, P193
   Islam R, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P148, DOI 10.1109/VRW52623.2021.00035
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   Johnson T, 2020, J PALLIAT MED, V23, P1233, DOI 10.1089/jpm.2019.0411
   Kaimara P, 2022, VIRTUAL REAL-LONDON, V26, P697, DOI 10.1007/s10055-021-00563-w
   Karaosmanoglu Sukran, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3474679
   Karat J, 2003, IBM SYST J, V42, P532, DOI 10.1147/sj.424.0532
   Kaur R, 2019, IEEE ENG MED BIO, P5233, DOI [10.1109/embc.2019.8857647, 10.1109/EMBC.2019.8857647]
   Kellmeyer P, 2019, NAT MED, V25, P1185, DOI 10.1038/s41591-019-0543-y
   Kellmeyer P, 2018, CAMB Q HEALTHC ETHIC, V27, P610, DOI 10.1017/S0963180118000129
   Kelso J, 2002, P IEEE VIRT REAL ANN, P183, DOI 10.1109/VR.2002.996521
   Kern F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P500, DOI [10.1109/VR.2019.8797828, 10.1109/vr.2019.8797828]
   Kool H., 2016, Intersect, V9, P1
   Kuck R., 2008, 5th Workshop of the GI-VR/AR Group, P209
   Kuntze MF, 2002, CYBERPSYCHOL BEHAV, V5, P203, DOI 10.1089/109493102760147187
   Latoschik ME, 2011, P IEEE VIRT REAL ANN, P171, DOI 10.1109/VR.2011.5759457
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee J, 2019, TELEMAT INFORM, V39, P37, DOI 10.1016/j.tele.2018.12.006
   Lee Y., 2003, Communications of the Association for Information Systems, V12, P752, DOI [DOI 10.17705/1CAIS.01250, 10.17705/1CAIS.01250]
   Leung HKN, 1997, SOFTWARE QUAL J, V6, P137, DOI 10.1023/A:1018503800709
   Lewis CH, 1997, ST HEAL T, V44, P35
   Liu YC, 2018, PROCEEDINGS OF THE 2018 1ST IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE INNOVATION AND INVENTION (ICKII 2018), P47, DOI 10.1109/ICKII.2018.8569081
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Manzeschke A., 2015, RESULTS STUDY ETHICA
   Marloth M, 2020, CAMB Q HEALTHC ETHIC, V29, P574, DOI 10.1017/S0963180120000328
   Mathur AS, 2015, P IEEE VIRT REAL ANN, P345, DOI 10.1109/VR.2015.7223437
   Mayring P., 2008, Qualitative Inhaltsanalyse: Grundlagen und Techniken
   Mertens G, 2019, COMPUT HUM BEHAV, V91, P192, DOI 10.1016/j.chb.2018.10.006
   Moldoveanu A, 2019, IEEE ACCESS, V7, P8151, DOI 10.1109/ACCESS.2018.2886271
   Musschenga AW, 1997, J MED PHILOS, V22, P11
   Nebeling M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300826
   Nebeling M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P333, DOI 10.1109/ISMAR-Adjunct.2018.00098
   Neelakantam S., 2017, LEARNING WEB BASED V, P17, DOI [10.1007/978-1-4842-2710-7_4, DOI 10.1007/978-1-4842-2710-7_4]
   Nelles J., 2016, ADV ERGONOMIC DESIGN, P1, DOI [10.1007/978-3-662-53305, DOI 10.1007/978-3-662-53305]
   Nemire K, 1999, Cyberpsychol Behav, V2, P35, DOI 10.1089/cpb.1999.2.35
   Niki K, 2019, J PALLIAT MED, V22, P702, DOI 10.1089/jpm.2018.0527
   Pavlik R. A., 2012, 2012 5th Workshop on Software Engineering and Architectures for Realtime Interactive Systems, P29, DOI 10.1109/SEARIS.2012.6231166
   Plouzeau J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P661, DOI 10.1109/VR.2018.8446192
   Rizzo AS, 2002, STUD NEUROPSYCHOL DE, P243
   Robitaille P, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317022
   Rohlf J., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P381, DOI 10.1145/192161.192262
   Salkevicius J, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8091039
   Sanders EBN, 2002, DESIGN AND THE SOCIAL SCIENCES: MAKING CONNECTIONS, P1
   Santos S. G., 2019, A FRAME EXPERIMENTAT
   SHAW C, 1993, ACM T INFORM SYST, V11, P287, DOI 10.1145/159161.173948
   Shiban Y, 2016, BIOL PSYCHOL, V121, P146, DOI 10.1016/j.biopsycho.2016.03.005
   Snoswell AaronJ., 2019, JMIR BIOMEDICAL ENG, V4, DOI DOI 10.2196/15025
   So S., 2019, EDMEDIA INNOVATE LEA, P1485
   Spiegel JS, 2018, SCI ENG ETHICS, V24, P1537, DOI 10.1007/s11948-017-9979-y
   STRAUSS PS, 1992, COMP GRAPH, V26, P341, DOI 10.1145/142920.134089
   Syed-Abdul S, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1218-8
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Thompson-Lake DGY, 2015, NICOTINE TOB RES, V17, P796, DOI 10.1093/ntr/ntu245
   Tramberend H, 1999, P IEEE VIRT REAL ANN, P14, DOI 10.1109/VR.1999.756918
   Turilli M, 2009, ETHICS INF TECHNOL, V11, P105, DOI 10.1007/s10676-009-9187-9
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   von Mammen S, 2019, INT CONF GAMES VIRTU, P254, DOI 10.1109/vs-games.2019.8864580
   Walker RL, 2014, BIOETHICS, V28, P481, DOI 10.1111/bioe.12023
   Wang W, 2019, 2019 IEEE MTT-S INTERNATIONAL MICROWAVE BIOMEDICAL CONFERENCE (IMBIOC 2019), DOI 10.1109/imbioc.2019.8777805
   Wang YG, 2019, J PSYCHIATR RES, V116, P88, DOI 10.1016/j.jpsychires.2019.06.007
   Weijers D., 2017, Experience machines: The philosophy of virtual worlds, P183
   Wenninger S., 2020, 26 ACM S VIRTUAL REA, P1, DOI [DOI 10.1145/3385956.3418940, 10.1145/3385956.3418940]
   Wolf E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR50410.2021.00027
   Yellowlees PM, 2012, TELEMED E-HEALTH, V18, P558, DOI 10.1089/tmj.2011.0195
   Zajac-Lamparska L, 2019, BMC RES NOTES, V12, DOI 10.1186/s13104-019-4810-2
   Zhang A., 2020, IMMERSIVE VIRTUAL RE
   Zhang L., 2020, P 33 ANN ACM S USER, P342, DOI DOI 10.1145/3379337.3415824
NR 109
TC 35
Z9 35
U1 5
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 23
PY 2022
VL 3
AR 837616
DI 10.3389/frvir.2022.837616
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SL7
UT WOS:001021808000001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Cuesta, M
   Verty, LV
   Ben Abdessalem, H
   Byrns, A
   Bruneau, MA
   Frasson, C
   Belleville, S
AF Cuesta, Marc
   Verty, Lynn Valeyry
   Ben Abdessalem, Hamdi
   Byrns, Alexie
   Bruneau, Marie-Andree
   Frasson, Claude
   Belleville, Sylvie
TI Virtual Reality and EEG-Based Intelligent Agent in Older Adults With
   Subjective Cognitive Decline: A Feasibility Study for Effects on Emotion
   and Cognition
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cognition; emotions; subjective cognitive decline; cybersickness; user
   experience; virtual reality
ID NEGATIVE AFFECT; IMPAIRMENT; APATHY; TECHNOLOGY; VALIDATION; SYMPTOMS;
   DEMENTIA; SCALE; PANAS; TASK
AB Objectives: Immersive virtual reality has tremendous potential to improve cognition in populations with cognitive impairment. We conducted a feasibility and proof-of-concept study to assess the potential of virtual reality and electroencephalography, with or without an intelligent agent, that adapts the presented material to the emotions elicited by the environment.Method: Older adults with subjective cognitive decline recruited from the community received a virtual reality-based intervention taking place in one of two virtual environments, a train (Part 1, N = 19) or a music theatre, complemented by the intelligent agent (Part 2, N = 19). A comparative control group (N = 19) receiving no intervention was also included. All participants completed measures of affect and cognition before and after the intervention. The intervention groups completed measures of cybersickness and user experience after the intervention.Results: Participants did not suffer from increased cybersickness following either intervention. They also reported a positive to highly positive user experience concerning the following aspects: attractivity, hedonic quality-identity and hedonic quality-stimulation. The measures of affect showed no pre-post change when comparing either intervention to the control condition. However, a reduction of negative affect was observed following the train intervention for participants with a high self-reported negative affect at baseline. Finally, there was a significant improvement in working memory when comparing either intervention group to the control condition.Conclusion: Our results support the feasibility and tolerability of the technology, and a positive impact on cognition, paving the way for a larger-scale randomized clinical trial to confirm efficacy.
C1 [Cuesta, Marc; Verty, Lynn Valeyry; Bruneau, Marie-Andree; Belleville, Sylvie] Inst Univ Geriatrie Montreal, Res Ctr, Montreal, PQ, Canada.
   [Verty, Lynn Valeyry; Belleville, Sylvie] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
   [Ben Abdessalem, Hamdi; Byrns, Alexie; Frasson, Claude] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ, Canada.
   [Bruneau, Marie-Andree] Univ Montreal, Dept Psychiat & Addictol, Montreal, PQ, Canada.
C3 Universite de Montreal; Universite de Montreal; Universite de Montreal;
   Universite de Montreal
RP Belleville, S (corresponding author), Inst Univ Geriatrie Montreal, Res Ctr, Montreal, PQ, Canada.; Belleville, S (corresponding author), Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
EM sylvie.belleville@umontreal.ca
CR [Anonymous], 2011, P 3 ACM SIGCHI S ENG
   [Anonymous], 2018, Test of variables of attention continuous Performance test
   Asato MR, 2006, NEUROPSYCHOLOGIA, V44, P2259, DOI 10.1016/j.neuropsychologia.2006.05.010
   Belleville S, 2019, ALZH DEMENT-DADM, V11, P787, DOI 10.1016/j.dadm.2019.07.003
   Ben Abdessalem H, 2020, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON SENSOR NETWORKS (SENSORNETS), P52, DOI 10.5220/0008976700520060
   Ben Abdessalem H, 2017, LECT NOTES ARTIF INT, V10512, P133, DOI 10.1007/978-3-319-67615-9_12
   Biamonti Alessandro., 2014, A "Design Experience for the Enhancement of the Quality of Life for People with Alzheimer's Disease"
   Blair KS, 2007, NEUROIMAGE, V35, P430, DOI 10.1016/j.neuroimage.2006.11.048
   Byrns A., 2020, INT C INT TUT SYST
   Caillaud M, 2020, J GERONTOL B-PSYCHOL, V75, P1382, DOI 10.1093/geronb/gbz120
   Conway A. M., 2013, BROADEN AND BUILD TH, P17
   Lecavalier NC, 2020, NEUROPSYCHOL REHABIL, V30, P462, DOI 10.1080/09602011.2018.1477684
   Crawford JR, 2004, BRIT J CLIN PSYCHOL, V43, P245, DOI 10.1348/0144665031752934
   de la Torre-Luque A, 2017, NORD J MUSIC THER, V26, P124, DOI 10.1080/08098131.2015.1131186
   Dermody G, 2020, J MED INTERNET RES, V22, DOI 10.2196/17331
   Garrison KE, 2019, COGNITION EMOTION, V33, P370, DOI 10.1080/02699931.2018.1438989
   Goldberg L. R., 1992, Psychological Assessment, P26
   Gallego MG, 2017, NEUROLOGIA, V32, P300, DOI 10.1016/j.nrl.2015.12.003
   Guercio BJ, 2015, J NEUROPSYCH CLIN N, V27, pE22, DOI 10.1176/appi.neuropsych.13060141
   Holthe T, 2018, CLIN INTERV AGING, V13, P863, DOI 10.2147/CIA.S154717
   Ismail Z, 2017, J ALZHEIMERS DIS, V56, P929, DOI 10.3233/JAD-160979
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Köhler S, 2010, J AM GERIATR SOC, V58, P873, DOI 10.1111/j.1532-5415.2010.02807.x
   La Corte V, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00173
   Lallemand C., 2015, Eur Rev Appl Psychol, V65, P239, DOI [10.1016/j.erap.2015.08, DOI 10.1016/J.ERAP.2015.08, 10.1016/j.erap.2015.08.002]
   Lanctot Krista L, 2017, Alzheimers Dement (N Y), V3, P440, DOI 10.1016/j.trci.2017.07.001
   Lin Y, 2019, NEUROL SCI, V40, P41, DOI 10.1007/s10072-018-3620-y
   Manera V, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151487
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Ouellet É, 2018, J NEUROSCI METH, V303, P126, DOI 10.1016/j.jneumeth.2018.03.010
   Proctor E, 2011, ADM POLICY MENT HLTH, V38, P65, DOI 10.1007/s10488-010-0319-7
   Robert P, 2018, EUR PSYCHIAT, V54, P71, DOI 10.1016/j.eurpsy.2018.07.008
   Robert PH, 2006, DEMENT GERIATR COGN, V21, P192, DOI 10.1159/000090766
   Saba M, 2020, GERIATR PSYCHOL NEUR, V18, P187, DOI 10.1684/pnv.2020.0860
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Sherman C, 2018, INT PSYCHOGERIATR, V30, P177, DOI 10.1017/S1041610217000527
   Su J, 2017, NEUROSCI LETT, V641, P15, DOI 10.1016/j.neulet.2017.01.038
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Verbruggen F, 2007, COGNITION EMOTION, V21, P391, DOI 10.1080/02699930600625081
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Williams JMG, 1996, PSYCHOL BULL, V120, P3, DOI 10.1037/0033-2909.120.1.3
NR 43
TC 2
Z9 2
U1 8
U2 18
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 19
PY 2022
VL 2
AR 807991
DI 10.3389/frvir.2021.807991
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZX5
UT WOS:001019276200001
OA gold
DA 2024-07-18
ER

PT J
AU Carnell, S
   Miles, A
   Lok, B
AF Carnell, Stephanie
   Miles, Anna
   Lok, Benjamin
TI Evaluating Virtual Patient Interaction Fidelity With Advanced
   Communication Skills Learners
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual patients; medical simulation; virtual reality; simulation-based
   training; instructional design; cognitive load
ID EDUCATION; DESIGN; HEALTH; RESIDENTS; LITERACY; LANGUAGE; MEDICINE
AB Previous research in educational medical simulation has drawn attention to the interplay between a simulation's fidelity and its educational effectiveness. As virtual patients (VPs) are increasingly used in medical simulations for education purposes, a focus on the relationship between virtual patients' fidelity and educational effectiveness should also be investigated. In this paper, we contribute to this investigation by evaluating the use of a virtual patient selection interface (in which learners interact with a virtual patient via a set of pre-defined choices) with advanced medical communication skills learners. To this end, we integrated virtual patient interviews into a graduate-level course for speech-language therapists over the course of 2 years. In the first cohort, students interacted with three VPs using only a chat interface. In the second cohort, students used both a chat interface and a selection interface to interact with the VPs. Our results suggest that these advanced learners view the selection interfaces as more appropriate for novice learners and that their communication behavior was not significantly affected by using the selection interface. Based on these results, we suggest that selection interfaces may be more appropriate for novice communication skills learners, but for applications in which selection interfaces are to be used with advanced learners, additional design research may be needed to best target these interfaces to advanced learners.
C1 [Carnell, Stephanie] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
   [Miles, Anna] Univ Auckland, Speech Sci, Auckland, New Zealand.
   [Lok, Benjamin] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL USA.
C3 State University System of Florida; University of Central Florida;
   University of Auckland; State University System of Florida; University
   of Florida
RP Carnell, S (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
EM stephanie.carnell@ucf.edu
OI Miles, Anna/0000-0003-3260-5824; Lok, Benjamin/0000-0002-1190-3729
CR Agarwal N, 2013, JAMA INTERN MED, V173, P1257, DOI 10.1001/jamainternmed.2013.6060
   [Anonymous], 2001, INT CLASS FUNCT DIS
   Beck Rainer S, 2002, J Am Board Fam Pract, V15, P25
   Berger CR, 2003, LEA COMMUN SER, P257
   BOURHIS RY, 1989, SOC SCI MED, V28, P339, DOI 10.1016/0277-9536(89)90035-X
   BRADSHAW PW, 1975, BRIT J SOC CLIN PSYC, V14, P55, DOI 10.1111/j.2044-8260.1975.tb00149.x
   Carnell S, 2015, LECT NOTES ARTIF INT, V9238, P50, DOI 10.1007/978-3-319-21996-7_5
   Consorti F, 2012, COMPUT EDUC, V59, P1001, DOI 10.1016/j.compedu.2012.04.017
   Cook DA, 2013, MED TEACH, V35, pE844, DOI 10.3109/0142159X.2012.714886
   Dukes LC, 2013, P 2013 INT C INT US, P395, DOI DOI 10.1145/2449396.2449447
   Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532
   Flesch Rudolf, 1949, The art of readable writing, V8
   Gordon D, 1996, CAN MED ASSOC J, V155, P1152
   Graham Suzanne, 2008, Perm J, V12, P67
   Green JA, 2014, PATIENT EDUC COUNS, V95, P76, DOI 10.1016/j.pec.2014.01.004
   Halan S., 2018, P 17 INT C AUT AG MU
   Hill J., 2006, P 25 ARM SCI C ORL F
   Hirumi A, 2016, ETR&D-EDUC TECH RES, V64, P763, DOI 10.1007/s11423-016-9429-6
   Kim J. M., 2009, INT J ARTIF INTELL E, V19, P21, DOI [10.5555/1891970.1891973, DOI 10.5555/1891970.1891973]
   Koch-Weser S, 2009, HEALTH EXPECT, V12, P371, DOI 10.1111/j.1369-7625.2009.00555.x
   Leppink J, 2016, MED TEACH, V38, P669, DOI 10.3109/0142159X.2015.1132829
   Norman G, 2012, MED EDUC, V46, P636, DOI 10.1111/j.1365-2923.2012.04243.x
   Oates DJ, 2009, CIRCULATION, V119, P1049, DOI 10.1161/CIRCULATIONAHA.108.818468
   Rossen B, 2012, INT J HUM-COMPUT ST, V70, P301, DOI 10.1016/j.ijhcs.2011.11.004
   Shaw A, 2009, PATIENT EDUC COUNS, V75, P114, DOI 10.1016/j.pec.2008.09.026
   SMITH RC, 1995, ACAD MED, V70, P729, DOI 10.1097/00001888-199508000-00019
   Speer M., 2015, COMMUNICATING PEDIAT, P221
   Sweller J, 2019, EDUC PSYCHOL REV, V31, P261, DOI 10.1007/s10648-019-09465-5
   Waisman Y, 2003, ISRAEL MED ASSOC J, V5, P567
   Watts PI, 2021, CLIN SIMUL NURS, V58, P14, DOI 10.1016/j.ecns.2021.08.009
   Williamson JML, 2010, INT J CLIN PRACT, V64, P1824, DOI 10.1111/j.1742-1241.2010.02408.x
   Wouda JC, 2012, PATIENT EDUC COUNS, V86, P57, DOI 10.1016/j.pec.2011.03.011
NR 32
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 10
PY 2022
VL 2
AR 801793
DI 10.3389/frvir.2021.801793
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YY3
UT WOS:001019250900001
OA gold
DA 2024-07-18
ER

PT J
AU Reen, FJ
   Jump, O
   McSharry, BP
   Morgan, J
   Murphy, D
   O'Leary, N
   O'Mahony, B
   Scallan, M
   Supple, B
AF Reen, F. Jerry
   Jump, Owen
   McSharry, Brian P.
   Morgan, John
   Murphy, David
   O'Leary, Niall
   O'Mahony, Billy
   Scallan, Martina
   Supple, Briony
TI The Use of Virtual Reality in the Teaching of Challenging Concepts in
   Virology, Cell Culture and Molecular Biology
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; molecular biology; virology; cellular biology;
   immersive learning
ID EDUCATION; LABORATORIES; BIOCHEMISTRY; TECHNOLOGY; SCIENCE
AB The rapidly expanding biotechnology sector horizon is expected to create a surge in demand for expertise underpinning cell and gene therapies, which are recognized as the next generation of medicines. New and innovative approaches to implement active and performative learning in the Molecular Life Sciences are required to support this and to address limitations associated with traditional "front of class" lectern delivery of challenging, three dimensional molecular concepts. Therefore, an immediate need exists for the development and implementation of immersive learning approaches in Virology, Cellular Sciences and Molecular Biology to underpin sustainable development of graduate students for academic and industrial research careers. The Covid-19 pandemic has led to significant changes in the delivery of education globally, with online engagement and accelerated uptake of novel teaching and assessment modalities into majority practice within institutions. This development has been driven by externally imposed necessity and it remains to be seen what form teaching and learning will take post-Covid. Irrespective of the pandemic, technologies are available which can serve intrinsically motivated, discipline specific shifts toward enhanced learner experiences and learning outcomes. Immersive virtual reality offers one such approach to open new entry points for student learning of abstract molecular concepts, which will be just as relevant upon our return to face-to-face teaching. Key to delivering this will be engagement and collaboration by disciplinary and technical experts. Here, we discuss global advances in the area of VR and Molecular Science education and assess potential paths forward for teaching and learning impact and innovative education.
C1 [Reen, F. Jerry; McSharry, Brian P.; Morgan, John; O'Leary, Niall; O'Mahony, Billy; Scallan, Martina] Univ Coll Cork, Sch Microbiol, Cork, Ireland.
   [Reen, F. Jerry] Univ Coll Cork, Synth & Solid State Pharmaceut Ctr, Cork, Ireland.
   [Jump, Owen] Univ Coll Cork, Sch Appl Psychol, Cork, Ireland.
   [Jump, Owen; Supple, Briony] Univ Coll Cork, Ctr Integrat Res Teaching & Learning, Cork, Ireland.
   [McSharry, Brian P.] APC Microbiome Ireland, Cork, Ireland.
   [Murphy, David] Univ Coll Cork, Sch Comp Sci & Informat Technol, Cork, Ireland.
   [Murphy, David] Univ Coll Cork, Sch Comp Sci & Informat Technol, MAVRIC Res Lab, Cork, Ireland.
C3 University College Cork; University College Cork; University College
   Cork; University College Cork; University College Cork; University
   College Cork
RP Reen, FJ (corresponding author), Univ Coll Cork, Sch Microbiol, Cork, Ireland.; Reen, FJ (corresponding author), Univ Coll Cork, Synth & Solid State Pharmaceut Ctr, Cork, Ireland.
EM j.reen@ucc.ie
RI Murphy, David/A-4900-2019; Reen, Jerry/AAG-7155-2019
OI Murphy, David/0000-0002-9685-8292; McSharry, Brian/0000-0003-0473-2789
FU National Forum for the Enhancement of Teaching and Learning in Higher
   Education [TL19UCC1481/02]; Science Foundation Ireland [SSPC-3,
   12/RC/2275_2]; Health Research Board [HRB-ILP-POR-2019-004]; Health
   Research Board/Irish Thoracic Society [MRCG-2018-16]
FX The ELEVATE team acknowledge the support of the National Forum for the
   Enhancement of Teaching and Learning in Higher Education
   (TL19UCC1481/02). FR also acknowledges the support of Science Foundation
   Ireland (SSPC-3, 12/RC/2275_2), the Health Research Board
   (HRB-ILP-POR-2019-004), and the Health Research Board/Irish Thoracic
   Society (MRCG-2018-16).
CR Abdullah J, 2019, VIRTUAL REAL-LONDON, V23, P461, DOI 10.1007/s10055-019-00381-1
   Alalwan N, 2020, STUD EDUC EVAL, V66, DOI 10.1016/j.stueduc.2020.100876
   Alelis G, 2015, BEHAV INFORM TECHNOL, V34, P1064, DOI 10.1080/0144929X.2015.1056548
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Ambrose S.A., 2010, HOW LEARNING WORKS
   Bell E, 2001, NAT REV MOL CELL BIO, V2, P221, DOI 10.1038/35056610
   Bennett JA, 2019, J MICROBIOL BIOL EDU, V20, DOI 10.1128/jmbe.v20i2.1658
   Blythe T., 1998, The teaching for understanding guide, P9
   Bucea-Manea-Tonis R, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12145872
   Bucher K, 2019, J COMPUT EDUC, V6, P53, DOI 10.1007/s40692-018-0121-1
   Cassidy KC, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007747
   Chen C.J., 2009, THEMES SCI TECHNOLOG, V2, P71
   Coan HA, 2020, J TEACH LEARN, V14, P71, DOI 10.22329/jtl.v14i1.6234
   Cook M, 2019, INFORM TECHNOL LIBR, V38, P25, DOI 10.6017/ITAL.V38I4.11075
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Dede C., 2017, VIRTUAL AUGMENTED MI, P5
   Didehbani N, 2016, COMPUT HUM BEHAV, V62, P703, DOI 10.1016/j.chb.2016.04.033
   Fairén M, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01550-5
   Fransson G, 2020, EDUC INF TECHNOL, V25, P3383, DOI 10.1007/s10639-020-10119-1
   Garcia-Bonete MJ, 2019, BIOCHEM MOL BIOL EDU, V47, P16, DOI 10.1002/bmb.21188
   Goligorsky D., 2012, EMPATHY INNOVATION I
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Hernández-de-Menéndez M, 2019, INT J INTERACT DES M, V13, P947, DOI 10.1007/s12008-019-00558-7
   Howitt S., 2008, Australian Biochemist, V39, P14
   Hwang WY, 2013, COMPUT EDUC, V62, P308, DOI 10.1016/j.compedu.2012.10.005
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Johnston APR, 2018, TRAFFIC, V19, P105, DOI 10.1111/tra.12538
   Kaminska MS, 2018, CLIN INTERV AGING, V13, P2329, DOI 10.2147/CIA.S183502
   Knote A., 2020, 26 ACM S VIRT REAL S, DOI [10.1145/3385956.3422097, DOI 10.1145/3385956.3422097]
   Knote A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P82, DOI 10.1109/AIVR46125.2019.00021
   Kozma R, 2005, MODEL MODEL SCI EDUC, V1, P121
   Lave J., 1991, SITUATED LEARNING LE, DOI DOI 10.1017/CBO9780511815355
   Lee J., 1999, International Journal of Instructional Media, V26, P71
   Leung T, 2018, Arxiv, DOI arXiv:1809.08585
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P349, DOI 10.1111/jcal.12335
   McGlynn Sean A., 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P1782, DOI 10.1177/1541931218621404
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Oberdörfer S, 2019, INT J COMPUT GAMES T, V2019, DOI 10.1155/2019/7626349
   Piaget J., 1971, THEORY STAGES COGNIT
   Plechatá A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01330
   Potkonjak V, 2016, COMPUT EDUC, V95, P309, DOI 10.1016/j.compedu.2016.02.002
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rospigliosi P, 2020, INTERACT LEARN ENVIR, V28, P383, DOI 10.1080/10494820.2020.1766753
   Sanchez-Sepulveda MV, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235161
   Schönborn KJ, 2010, BIOCHEM MOL BIOL EDU, V38, P347, DOI 10.1002/bmb.20436
   Selzer MN, 2019, DISPLAYS, V59, P9, DOI 10.1016/j.displa.2019.04.002
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stains M, 2018, SCIENCE, V359, P1468, DOI 10.1126/science.aap8892
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Taçgin Z, 2020, EDUC INF TECHNOL, V25, P2791, DOI 10.1007/s10639-019-10088-0
   Tan S, 2014, SIMULATIONS SERIOUS, DOI [10.4135/978144627305013514692, DOI 10.4135/978144627305013514692]
   Tan S., 2013, 3D IMMERSIVE INTERAC, DOI [10.1007/978-981-4021-90-6_2, DOI 10.1007/978-981-4021-90-6_2]
   Tang YM, 2020, VIRTUAL REAL-LONDON, V24, P797, DOI 10.1007/s10055-020-00427-9
   Tibell LAE, 2010, CBE-LIFE SCI EDUC, V9, P25, DOI 10.1187/cbe.08-09-0055
   Tobias S., 2009, Constructivist instruction: Success or failure?, DOI DOI 10.4324/9780203878842
   Tullis JG, 2011, J MEM LANG, V64, P109, DOI 10.1016/j.jml.2010.11.002
   Vergara D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030915
   Vergara D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214625
   Wiske M.S., 1998, TEACHING UNDERSTANDI
   Xie J, 2011, PHYS REV E, V84, DOI 10.1103/PhysRevE.84.011130
   Zhao JJ, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-1994-z
NR 67
TC 5
Z9 5
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 21
PY 2021
VL 2
AR 670909
DI 10.3389/frvir.2021.670909
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TG9
UT WOS:001021829200001
OA gold
DA 2024-07-18
ER

PT J
AU Firoozabadi, R
   Elhaddad, M
   Drever, S
   Soltani, M
   Githens, M
   Kleweno, CP
   Sharar, SR
   Patterson, DR
   Hoffman, HG
AF Firoozabadi, Reza
   Elhaddad, Moamen
   Drever, Sydney
   Soltani, Maryam
   Githens, Michael
   Kleweno, Conor P. P.
   Sharar, Sam R. R.
   Patterson, David R. R.
   Hoffman, Hunter G. G.
TI Case Report: Virtual Reality Analgesia in an Opioid Sparing Orthopedic
   Outpatient Clinic Setting: A Case Study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; pain; analgesia; ex-fix pin removal; distraction;
   outpatient
ID PAIN MANAGEMENT; BURN INJURIES; DISTRACTION; ATTENTION; EXPECTATIONS;
   MODULATION; MECHANISMS; THERAPY; ANXIETY; HELMET
AB Immersive virtual reality is proving effective as a non-pharmacologic analgesic for a growing number of painful medical procedures. External fixator surgical pins provide adjunctive stability to a broken pelvic bone until the bones heal back together, then pins are removed. The purpose of the present case study was to measure for the first time, whether immersive virtual reality could be used to help reduce pain and anxiety during the orthopedic process of removing external fixator pins from a conscious patient in the orthopedic outpatient clinic, and whether it is feasible to use VR in this context. Using a within-subject within wound care design with treatment order randomized, the patient had his first ex-fix pin unscrewed and removed from his healing pelvic bone while he wore a VR helmet and explored an immersive snowy 3D computer generated world, adjunctive VR. He then had his second pin removed during no VR, standard of care pain medications. The patient reported having 43% less pain intensity, 67% less time spent thinking about pain, and 43% lower anxiety during VR vs. during No VR. In addition, the patient reported that his satisfaction with pain management was improved with the use of VR. Conducting simple orthopedic procedures using oral pain pills in an outpatient setting instead of anesthesia in the operating room greatly reduces the amount of opioids used, lowers medical costs and reduces rare but real risks of expensive complications from anesthesia including oversedation, death, and post-surgical dementia. These preliminary results suggest that immersive VR merits more attention as a potentially viable adjunctive non-pharmacologic form of treatment for acute pain and anxiety during medical procedures in the orthopedic outpatient clinic. Recent multi-billion dollar investments into R and D and mass production have made inexpensive immersive virtual reality products commercially available and cost effective for medical applications. We speculate that in the future, patients may be more willing to have minor surgery procedures in the outpatient clinic, with much lower opioid doses, while fully awake, if offered adjunctive virtual reality as a non-pharmacologic analgesic during the procedure. Additional research and development is recommended.
C1 [Firoozabadi, Reza; Elhaddad, Moamen; Githens, Michael; Kleweno, Conor P. P.] Univ Washington, Harborview Med Ctr, Orthoped Trauma Surg Clin, Seattle, WA USA.
   [Drever, Sydney; Soltani, Maryam; Patterson, David R. R.] Univ Washington, Dept Rehabil Med, Seattle, WA USA.
   [Sharar, Sam R. R.] Univ Washington, Sch Med, Dept Anesthesiol & Pain Med, Seattle, WA USA.
   [Hoffman, Hunter G. G.] Univ Washington, Dept Radiol, Seattle, WA 98195 USA.
   [Hoffman, Hunter G. G.] Univ Washington, Coll Engn, Dept Mech Engn, Seattle, WA 98195 USA.
   [Hoffman, Hunter G. G.] Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
C3 Harborview Medical Center; University of Washington; University of
   Washington Seattle; University of Washington; University of Washington
   Seattle; University of Washington; University of Washington Seattle;
   University of Washington; University of Washington Seattle; University
   of Washington; University of Washington Seattle; University of
   Washington; University of Washington Seattle
RP Hoffman, HG (corresponding author), Univ Washington, Dept Radiol, Seattle, WA 98195 USA.; Hoffman, HG (corresponding author), Univ Washington, Coll Engn, Dept Mech Engn, Seattle, WA 98195 USA.; Hoffman, HG (corresponding author), Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
EM hoontair@gmail.com
FU NIH [R01GM042725]; Mayday Fund
FX & nbsp;This research was supported by NIH grant R01GM042725 to DP, and
   by the Mayday Fund (PI HH and Walter J. Meyer, 3rd, MD).
CR Al-Ghamdi NA, 2020, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00467
   [Anonymous], 1998, Cyberpsychol Behav Soc Netw, DOI [10.1089/cpb.1998.1.195, DOI 10.1089/CPB.1998.1.195]
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02508
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02265
   Benedetti F, 1999, J NEUROSCI, V19, P3639
   Birnie KA, 2017, PAIN, V158, P1012, DOI 10.1097/j.pain.0000000000000913
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Chapman CR, 1998, INT J CLIN EXP HYP, V46, P6, DOI 10.1080/00207149808409987
   Chen QS, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2018.7621
   Dahlquist LM, 2007, HEALTH PSYCHOL, V26, P794, DOI 10.1037/0278-6133.26.6.794
   Eccleston C, 1999, PSYCHOL BULL, V125, P356, DOI 10.1037/0033-2909.125.3.356
   ECCLESTON C, 1994, BRIT J CLIN PSYCHOL, V33, P535, DOI 10.1111/j.2044-8260.1994.tb01150.x
   Fields HL, 2018, PAIN, V159, pS3, DOI 10.1097/j.pain.0000000000001272
   Fragomen A. T., 2018, J LIMB LENGTHEN RECO, V4, P90, DOI [10.4103/jllr.jllr_29_17, DOI 10.4103/JLLR.JLLR_29_17]
   Garrett B, 2014, CLIN J PAIN, V30, P1089, DOI 10.1097/AJP.0000000000000064
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gold JI, 2006, CYBERPSYCHOL BEHAV, V9, P207, DOI 10.1089/cpb.2006.9.207
   Heathcote LC, 2017, EUR J PAIN, V21, P250, DOI 10.1002/ejp.920
   Hemington KS, 2017, J PAIN, V18, P1117, DOI 10.1016/j.jpain.2017.04.009
   Hoffman H. G., 1998, Virtual Reality, V3, P226, DOI 10.1007/BF01408703
   Hoffman H. G., 2019, Virtual reality for psychological and neurocognitive interventions. Virtual reality Technologies for Health and clinical applications, P195, DOI DOI 10.1007/978-1-4939-9482-3_8
   Hoffman HG, 2004, NEUROREPORT, V15, P1245, DOI 10.1097/01.wnr.0000127826.73576.91
   Hoffman HG, 2004, SCI AM, V291, P58, DOI 10.1038/scientificamerican0804-58
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Jensen M.P., 2001, HDB PAIN ASSESSMENT, V2nd, P15
   Jensen MP, 2003, J PAIN, V4, P2, DOI 10.1054/jpai.2003.1
   Kahneman D., 1973, Attention and effort
   Keefe FJ, 2018, PHYS THER, V98, P398, DOI 10.1093/ptj/pzy024
   Keefe FJ, 2012, PAIN, V153, P2163, DOI 10.1016/j.pain.2012.05.030
   Khadra C, 2020, BURNS, V46, P1571, DOI 10.1016/j.burns.2020.04.006
   Khadra C, 2018, J PAIN RES, V11, P343, DOI 10.2147/JPR.S151084
   Le May S, 2021, J ADV NURS, V77, P439, DOI 10.1111/jan.14607
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   LOUIS TA, 1984, NEW ENGL J MED, V310, P24, DOI 10.1056/NEJM198401053100106
   Maani CV, 2011, J TRAUMA, V71, pS125, DOI 10.1097/TA.0b013e31822192e2
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   McDonald C, 2017, ORTHOPEDICS, V40, pE959, DOI 10.3928/01477447-20170918-02
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   Noel M, 2015, PAIN, V156, P800, DOI 10.1097/j.pain.0000000000000102
   Noel M, 2015, PAIN, V156, P31, DOI 10.1016/j.pain.0000000000000001
   Patterson DR, 2006, J ABNORM PSYCHOL, V115, P834, DOI 10.1037/0021-843X.115.4.834
   Patterson D.R., 2010, CLIN HYPNOSIS PAIN C
   Ploner M, 2011, CEREB CORTEX, V21, P719, DOI 10.1093/cercor/bhq146
   Rischer KM, 2020, EUR J PAIN, V24, P1880, DOI 10.1002/ejp.1634
   Sathy AK, 2009, J BONE JOINT SURG AM, V91A, P2803, DOI 10.2106/JBJS.H.00598
   SCHNEIDER W, 1977, PSYCHOL REV, V84, P1, DOI 10.1037/0033-295X.84.1.1
   Sharar SR, 2007, ARCH PHYS MED REHAB, V88, pS43, DOI 10.1016/j.apmr.2007.09.004
   SHIFFRIN RM, 1977, PSYCHOL REV, V84, P127, DOI 10.1037/0033-295X.84.2.127
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Spiegel B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219115
   Steele E, 2003, CYBERPSYCHOL BEHAV, V6, P633, DOI 10.1089/109493103322725405
   SYRJALA KL, 1995, PAIN, V63, P189, DOI 10.1016/0304-3959(95)00039-U
   Wender Regina, 2009, J Cyber Ther Rehabil, V2, P27
NR 56
TC 10
Z9 10
U1 1
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 14
PY 2020
VL 1
AR 553492
DI 10.3389/frvir.2020.553492
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WW7
UT WOS:001023295300001
PM 33585832
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Bastardas-Albero, A
   Vall, B
   Pérez-Testor, C
   Losilla, JM
AF Bastardas-Albero, Adriana
   Vall, Berta
   Perez-Testor, Carles
   Losilla, Josep-Maria
TI Which effective virtual reality (VR) interventions exist for the
   prevention and rehabilitation of intimate partner violence (IPV)?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; intimate partner violence; prevention; rehabilitation;
   immersive; domestic violence
ID SEXUAL VIOLENCE; BYSTANDER EDUCATION; PROGRAM; SYSTEM; ONLINE; TRIAL;
   GIRLS; MEN
AB Purpose: Prevention and rehabilitation of intimate partner violence (IPV) is a very important topic due to its high prevalence, visibility, and potential to generate negative consequences in survivor's physical and mental health. Previous interventions have used traditional, explicit approaches giving mixed results for both prevention and rehabilitation. However, the number of implicit interventions using technological innovations, specifically virtual reality (VR), is limited in this field. In this review, we aim to find the existing literature on immersive VR targeting prevention or rehabilitation of IPV.Method: The search used several databases: PsycINFO by EBSCOHost, and Medline by PubMed, specifically set to find IPV intervention articles, published after 2010, that included VR in their intervention.Results: 11 studies met all of the eligibility criteria and were included in the review.Conclusion: VR has overall proven useful to tackle the prevention and rehabilitation of intimate partner violence, as it offers the unique possibility of experiencing a variety of situations from a different perspective, in a safe and controlled environment. Therefore, it is a tool which has great potential for transformation, as it allows for experiential and implicit learning.
C1 [Bastardas-Albero, Adriana; Vall, Berta; Perez-Testor, Carles] Ramon Llull Univ, Fac Psychol Educ & Sports Sci Blanquerna FPCEE, Barcelona, Spain.
   [Bastardas-Albero, Adriana; Losilla, Josep-Maria] Univ Autonoma Barcelona, Dept Psychobiol & Methodol Hlth Sci, Barcelona, Spain.
C3 Universitat Ramon Llull; Autonomous University of Barcelona
RP Bastardas-Albero, A (corresponding author), Ramon Llull Univ, Fac Psychol Educ & Sports Sci Blanquerna FPCEE, Barcelona, Spain.; Bastardas-Albero, A (corresponding author), Univ Autonoma Barcelona, Dept Psychobiol & Methodol Hlth Sci, Barcelona, Spain.
EM adrianaba@blanquerna.url.edu
RI Losilla, Josep-Maria/K-3044-2014
OI Losilla, Josep-Maria/0000-0002-5140-5847
FU MCIN/AEI [FI: 2022 FI_B1 00192];  [PID2022-141403NB-I00]
FX The author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. Pre-doctoral grant FI:
   2022 FI_B1 00192. This work was supported by Grant PID2022-141403NB-I00
   funded by MCIN/AEI/10.13039/501100011033/FEDER, UE
CR Albarracín D, 2005, PSYCHOL BULL, V131, P856, DOI 10.1037/0033-2909.131.6.856
   Anderson EJ, 2021, TRAUMA VIOLENCE ABUS, V22, P870, DOI 10.1177/1524838019888889
   Arango D., 2014, Interventions to reduce or prevent violence against women and girls: a systematic review of reviews, DOI [10.13140/RG.2.1.2545.6168, DOI 10.13140/RG.2.1.2545.6168]
   Arborelius L, 2013, CRIM BEHAV MENT HEAL, V23, P30, DOI 10.1002/cbm.1849
   Babcock JC, 2004, CLIN PSYCHOL REV, V23, P1023, DOI 10.1016/j.cpr.2002.07.001
   Baños RM, 2011, INT J HUM-COMPUT ST, V69, P602, DOI 10.1016/j.ijhcs.2011.06.002
   Banyard VL, 2007, J COMMUNITY PSYCHOL, V35, P463, DOI 10.1002/jcop.20159
   Banyard VL, 2004, J COMMUNITY PSYCHOL, V32, P61, DOI 10.1002/jcop.10078
   Bell BS, 2008, INT J HUM RESOUR MAN, V19, P1416, DOI 10.1080/09585190802200173
   Bordnick Patrick S, 2011, J Diabetes Sci Technol, V5, P265
   Botella C., 2007, Real. virtual Trat. psicologicos. Cuad. Med. Psicosomatica Psiquiatr. Enlace, V17-31, P82
   Botezatu M, 2010, MED TEACH, V32, P562, DOI 10.3109/01421590903514630
   Butters RP, 2021, CLIN SOC WORK J, V49, P391, DOI 10.1007/s10615-020-00763-y
   Cantos AL, 2015, BEHAV PSYCHOL, V23, P549
   Courteille O, 2008, MED TEACH, V30, pE66, DOI 10.1080/01421590801910216
   de Borst Aline W, 2020, eNeuro, V7, DOI 10.1523/ENEURO.0263-19.2019
   Doss BD, 2020, J CONSULT CLIN PSYCH, V88, P283, DOI 10.1037/ccp0000479
   Draucker CB, 2019, ARCH PSYCHIAT NURS, V33, P37, DOI 10.1016/j.apnu.2018.09.002
   Ellsberg M, 2018, Adolescent dating violence: Theory, research, and prevention, P381
   Ellsberg M, 2015, LANCET, V385, P1555, DOI 10.1016/S0140-6736(14)61703-7
   Foubert JD, 2000, J AM COLL HEALTH, V48, P158, DOI 10.1080/07448480009595691
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Gibbs A, 2020, J ADOLESCENT HEALTH, V66, P323, DOI 10.1016/j.jadohealth.2019.10.004
   Glass N, 2015, BMC PUBLIC HEALTH, V15, DOI 10.1186/s12889-015-2191-6
   Gondolf EW, 2007, AGGRESS VIOLENT BEH, V12, P644, DOI 10.1016/j.avb.2007.03.001
   Gonzalez-Liencres C, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00820
   Heise L., 2011, WHAT WORKS PREVENT P
   Holtzworth-Munroe A, 2004, J INTERPERS VIOLENCE, V19, P1369, DOI 10.1177/0886260504269693
   Johnston T., 2021, Assessment, prevention and rehabilitation of intimate partner violence through immersion in virtual reality. Modifying Cognitions
   Johnston T, 2023, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.788608
   Katz J, 2013, VIOLENCE VICTIMS, V28, P1054, DOI 10.1891/0886-6708.VV-D-12-00113
   Kearney M. S., 2018, Educating men to recognize warning signs of dating violence, DOI [10.13016/6bps-hqqb, DOI 10.13016/6BPS-HQQB]
   Kip H, 2020, INT J FORENSIC MENT, V20, P31, DOI 10.1080/14999013.2020.1808914
   Kip H, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00042
   Kleinsasser A, 2015, PSYCHOL VIOLENCE, V5, P227, DOI 10.1037/a0037393
   Lee MR, 2021, WORLDV EVID-BASED NU, V18, P50, DOI 10.1111/wvn.12478
   Levesque DA, 2016, PSYCHOL VIOLENCE, V6, P421, DOI 10.1037/vio0000049
   Levine M, 2005, PERS SOC PSYCHOL B, V31, P443, DOI 10.1177/0146167204271651
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Martínez Gómez Jorge Arturo, 2014, Pensam. psicol., V12, P117
   McMahon S, 2014, J COLL STUDENT DEV, V55, P78, DOI 10.1353/csd.2014.0001
   McMahon S, 2011, J COLL STUDENT DEV, V52, P115, DOI 10.1353/csd.2011.0002
   Neyret S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62932-w
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Pantziaras I, 2012, INT J MED EDUC, V3, P132, DOI 10.5116/ijme.5004.7c78
   Park S, 2023, PSYCHOL VIOLENCE, V13, P93, DOI 10.1037/vio0000456
   Pence E., 1993, ED GROUPS MEN WHO BA, DOI DOI 10.1891/9780826179913
   Peskin MF, 2019, AM J PUBLIC HEALTH, V109, P1419, DOI [10.2105/AJPH.2019.305218, 10.2105/ajph.2019.305218]
   Rawski S. L., 2022, TECHNOLOGY MIND BEHA, V3, DOI [10.1037/tmb0000074, DOI 10.1037/TMB0000074]
   Repetto C, 2013, PERS UBIQUIT COMPUT, V17, P253, DOI 10.1007/s00779-011-0467-0
   Riva G, 2009, VIRTUAL REAL-LONDON, V13, P159, DOI 10.1007/s10055-009-0121-6
   Rothbaum BO, 2006, BEHAV THER, V37, P80, DOI 10.1016/j.beth.2005.04.004
   Rowe LS, 2015, BEHAV THER, V46, P315, DOI 10.1016/j.beth.2014.11.003
   Sanz J., 2018, Psicopatologia Clinica. Leg. y Forense, V18, P112
   Saunders D G, 1996, Violence Vict, V11, P393
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Seinfeld S, 2023, J INTERPERS VIOLENCE, V38, P2654, DOI 10.1177/08862605221106130
   Seinfeld S, 2021, CORTEX, V135, P268, DOI 10.1016/j.cortex.2020.11.018
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052766
   Stuart GL, 2007, JAMA-J AM MED ASSOC, V298, P560, DOI 10.1001/jama.298.5.560
   Sygel K, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.673089
   Sygel K, 2014, INT J FORENSIC MENT, V13, P369, DOI 10.1080/14999013.2014.951104
   Ticknor B, 2019, CRIM JUSTICE BEHAV, V46, P1319, DOI 10.1177/0093854819842588
   Trabold N, 2020, TRAUMA VIOLENCE ABUS, V21, P311, DOI 10.1177/1524838018767934
   Tuente SK, 2020, J CLIN MED, V9, DOI 10.3390/jcm9072258
   Turner WA, 2014, CLIN PSYCHOL REV, V34, P634, DOI 10.1016/j.cpr.2014.10.003
   Valmaggia LR, 2016, PSYCHIAT RES, V236, P189, DOI 10.1016/j.psychres.2016.01.015
   Ventura S, 2021, CYBERPSYCH BEH SOC N, V24, P258, DOI 10.1089/cyber.2020.0209
   Wu L., 2022, Examining the effects of gender transfer in virtual reality on implicit gender bias, DOI [10.1177/00187208221145264, DOI 10.1177/00187208221145264]
NR 70
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 21
PY 2023
VL 4
AR 1263545
DI 10.3389/frvir.2023.1263545
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DY8W5
UT WOS:001135753600001
OA gold
DA 2024-07-18
ER

PT J
AU Wilson, K
   Pfeiffer, PE
AF Wilson, Katie
   Pfeiffer, Phillip E.
TI Feedback in augmented and virtual reality piano tutoring systems: a mini
   review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; augmented reality; mixed reality; music; piano
   tutoring; feedback systems
AB Researchers in music education are exploring the use of virtual reality (VR) and augmented reality (AR) to support piano instruction. Beginner piano students tend to receive short, infrequent lessons, which they practice on their own. This lack of instructor feedback creates opportunities for students to develop improper technique. Current strategies for using AR and VR to guide solo practice use moving shapes to help students to identify what notes to play. Improvements in commercial AR/VR technology will be needed to provide more detailed real-time feedback.
C1 [Wilson, Katie; Pfeiffer, Phillip E.] East Tennessee State Univ, Dept Comp, Johnson City, TN 37614 USA.
C3 East Tennessee State University
RP Wilson, K (corresponding author), East Tennessee State Univ, Dept Comp, Johnson City, TN 37614 USA.
EM WilsonKatieL@outlook.com
FU East Tennessee State University's Department of Computing
FX & nbsp;East Tennessee State University's Department of Computing
   provided funding for publishing this document.
CR [Anonymous], 2013, P 14 AUSTR US INT C, DOI DOI 10.5555/2525493.2525501
   Awati R., 2022, FIELD VIEW FOV
   Cuthbert M., 2010, P 11 INT SOC MUSIC I, P637, DOI DOI 10.5281/ZENODO.1416114
   Hackl D., 2017, P 10 FORUM MEDIA TEC, P140
   Kohen S, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P76, DOI 10.1109/ISMAR-Adjunct51615.2020.00035
   Liu Z., 2019, P THE 17 INT C VIRTU, P1, DOI [10.1145/3359997.3365748, DOI 10.1145/3359997.3365748]
   Molloy W, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P178, DOI 10.23919/elinfocom.2019.8706474
   Percival G., 2007, EMME 07 P INT WORKSH, P67
   Rigby Liam, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P481, DOI 10.1145/3441000.3441039
   Rogers Katja, 2014, P 9 ACM INT C INT TA, P149, DOI [DOI 10.1145/2669485.2669514, 10.1145/2669485.2669514]
   Sarrazin Natalie., 2016, Music and the Child
   Sevilla G., 2022, META CAPTURES 90 VR
   W3C Music Notation Community Group, 2021, MUSICXML VERS 4 0 FI
   Wijaya F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P585, DOI [10.1109/VRW50115.2020.00144, 10.1109/VRW50115.2020.00143]
NR 14
TC 1
Z9 1
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 29
PY 2023
VL 4
AR 1207397
DI 10.3389/frvir.2023.1207397
PG 5
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XB2
UT WOS:001023299800001
OA gold
DA 2024-07-18
ER

PT J
AU Gu, X
   Chen, LH
   Wang, GP
   Li, S
AF Gu, Xiang
   Chen, Lihan
   Wang, Guoping
   Li, Sheng
TI An alternative paradigm for assessing attitudes in virtual reality -
   Interpersonal distance paradigm: Taking weight stigma as an example
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE implicit association test; interpersonal distance; weight stigma;
   implicit measures; explicit measures; ceiling and floor effect
ID IMPLICIT ASSOCIATION TEST; FAT PEOPLE; PREJUDICE; COGNITION
AB Immersive virtual technology has been widely used to modulate sociocognitive processes, such as changing individuals' implicit attitudes towards specific groups. As to measure the effect, the implicit association test (IAT) is the most used one. However, IAT itself is controversial for its construct validity and commonly requires participants to quit virtual environments (VEs) to complete. Here, we propose an alternative paradigm, the "interpersonal distance paradigm", which measures attitudes using interpersonal distance and can be conducted in VEs. We conducted a user study measuring weight stigma to compare the effectiveness of the interpersonal distance paradigm with two classical paradigms: the questionnaire and IAT. Results revealed a floor effect in the questionnaire method and no significant correlation between the two classic paradigms. The measurement of interpersonal distance showed a weak positive correlation with the questionnaire score, but not with IAT score. In future research, the results of more measurement methods should be combined to obtain more accurate results to better evaluate this new paradigm's validity. The accurate results can help quantify the effects of the programs aiming at reducing weight stigma.
C1 [Gu, Xiang; Wang, Guoping; Li, Sheng] Peking Univ, Sch Comp Sci, Lab Graph & Interact, Beijing, Peoples R China.
   [Chen, Lihan] Peking Univ, Sch Psychol & Cognit Sci, Beijing, Peoples R China.
C3 Peking University; Peking University
RP Li, S (corresponding author), Peking Univ, Sch Comp Sci, Lab Graph & Interact, Beijing, Peoples R China.
EM lisheng@pku.edu.cn
RI wang, guoping/KQU-3394-2024
OI Gu, Xiang/0000-0002-8527-9113
CR ALLISON DB, 1991, INT J EAT DISORDER, V10, P599
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bessenoff GR, 2000, SOC COGNITION, V18, P329, DOI 10.1521/soco.2000.18.4.329
   Brownstein M, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1501
   Chen EY, 2005, OBES RES, V13, P1393, DOI 10.1038/oby.2005.168
   CRANDALL CS, 1994, J PERS SOC PSYCHOL, V66, P882, DOI 10.1037/0022-3514.66.5.882
   Degner J, 2011, SOC COGNITION, V29, P182, DOI 10.1521/soco.2011.29.2.182
   Geraets CNW, 2018, SCHIZOPHR RES, V192, P96, DOI 10.1016/j.schres.2017.04.034
   GOLDMAN JW, 1969, ET CETERA, V26, P241
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Greenwald AG, 2003, J PERS SOC PSYCHOL, V85, P197, DOI 10.1037/0022-3514.85.2.197
   Gu X, 2023, IEEE T VIS COMPUT GR, V29, P4215, DOI 10.1109/TVCG.2022.3184986
   Gulledge Caleb M, 2019, JB JS Open Access, V4, DOI 10.2106/JBJS.OA.19.00015
   Hall J.A., 1984, NONVERBAL SEX DIFFER, DOI DOI 10.56021/9780801824401
   Hofmann W, 2005, PERS SOC PSYCHOL B, V31, P1369, DOI 10.1177/0146167205275613
   Karpinski A, 2001, J PERS SOC PSYCHOL, V81, P774, DOI 10.1037/0022-3514.81.5.774
   Krumpal I, 2013, QUAL QUANT, V47, P2025, DOI 10.1007/s11135-011-9640-9
   Lewis RJ, 1997, OBES RES, V5, P297, DOI 10.1002/j.1550-8528.1997.tb00555.x
   Li S, 2022, IEEE T VIS COMPUT GR, V28, P3035, DOI 10.1109/TVCG.2020.3044563
   Maeda M., 2016, P 2016 ACM INT S WEA
   Menshikova GY, 2018, PSYCHOL RUSS, V11, P18, DOI 10.11621/pir.2018.0102
   Morrison TG, 1999, J SOC PSYCHOL, V139, P436, DOI 10.1080/00224549909598403
   Nosek B. A., 2013, AUTOMATIC PROCESSES
   Oliverl MD, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185703
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Puhl RM, 2008, INT J OBESITY, V32, P992, DOI 10.1038/ijo.2008.22
   The Project Implicit Team, 2011, PROJECT IMPLICIT
   Uzzell D, 2006, BRIT J SOC PSYCHOL, V45, P579, DOI 10.1348/014466605X58384
   Welsch R, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231539
   World Obesity Federation, 2018, WEIGHT STIGM
   Yaremych HE, 2019, J EXP SOC PSYCHOL, V85, DOI 10.1016/j.jesp.2019.103845
NR 31
TC 2
Z9 2
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 21
PY 2022
VL 3
AR 1015791
DI 10.3389/frvir.2022.1015791
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YV4
UT WOS:001023346200001
OA gold
DA 2024-07-18
ER

PT J
AU Bauerfeind, K
   Drueke, J
   Bendewald, L
   Baumann, M
AF Bauerfeind, Kassandra
   Drueke, Julia
   Bendewald, Lennart
   Baumann, Martin
TI How does navigating with Augmented Reality information affect drivers'
   glance behaviour in terms of attention allocation?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Augmented Reality head-up display; glance behaviour; attention
   allocation; ambiguous navigation task; driving simulator study
ID DISPLAY; SYSTEM
AB Drivers can benefit from Augmented Reality (AR) information especially in ambiguous navigation situations compared to conventional Head-up displays (HUD). AR information is correctly superimposed on the relevant objects in the environment and therefore directly related to the driving situation. Hence, it is assumed, that drivers no longer have to switch glances between the AR information and the environment (Kim & Dey, 2009). It has to be investigated whether switching glances between the presented navigation information and the environment can be reduced with AR information compared to HUD information. Furthermore, the question arises whether AR information might capture drivers' attention and therefore distract from the traffic situation compared to a HUD as AR information is presented on the driver's primary visual axis. The aim of the driving simulator study was to examine glance behaviour in terms of attention allocation while participants navigated in an ambiguous left turn situation with an oncoming car in an urban area (N = 58). Hence, drivers were faced with the decision to turn in front of it or let it pass. A conventional HUD and an AR display presented the navigation information to the driver. The drives differed in traffic complexity (low vs. high) to provide indications whether drivers adapt glance behaviour to altered environmental conditions. Besides the navigation task, drivers performed a non-driving-related task to raise drivers' mental load while navigating. Results showed that with the AR display participants payed more attention to an oncoming car in the ambiguous left turn situation than with the HUD, which indicates that AR information was not distracting. Furthermore, participants switched glances significantly less between the AR navigation information and the environment, which indicates that with the AR display the driver did not have to map the virtual information onto the real driving situation. Independently of the display type 88% of the participants let the oncoming car pass the first time in this situation. Moreover, subjective data showed that drivers benefitted from AR information. The results of this study contribute to the investigation and development of AR user interfaces.
C1 [Bauerfeind, Kassandra; Drueke, Julia; Bendewald, Lennart] Volkswagen AG, Wolfsburg, Germany.
   [Baumann, Martin] Univ Ulm, Ulm, Germany.
C3 Volkswagen; Volkswagen Germany; Ulm University
RP Bauerfeind, K (corresponding author), Volkswagen AG, Wolfsburg, Germany.
EM kassandra.bauerfeind@volkswagen.de
CR Abdi L, 2018, J VISUAL-JAPAN, V21, P163, DOI 10.1007/s12650-017-0442-6
   Bauerfeind K., 2018, P HUMAN FACTORS ERGO, P219
   Bauerfeind K, 2021, APPL ERGON, V94, DOI 10.1016/j.apergo.2021.103398
   Bengler K., 2015, P EL DISPL C NUR GER
   Eyraud R, 2015, TRANSPORT RES F-TRAF, V32, P46, DOI 10.1016/j.trf.2015.04.011
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gish K. W., 1995, 808320 DOT HS NAT HI
   GRANT BS, 1995, HUM FAC ERG SOC P, P1087
   Heller O, 1982, FORSCHUNGSBERICHT 19, P1
   Hexagon A. B., 2021, VIRTUAL TEST DRIVE V
   Horrey W. J., 2003, DRIV SIM C N AM P DE
   Israel B., 2012, THESIS TU MUNICH MUN
   Kansteiner N., 2014, ABOUT US
   Kiefer R. J., 1991, SAE TECH PAP, V1991, P910111, DOI [10.4271/910111, DOI 10.4271/910111]
   Kim H., 2013, P 5 INT C AUT US INT, P224, DOI [10.1145/2516540.2516566, DOI 10.1145/2516540.2516566]
   Kim H, 2022, HUM FACTORS, V64, P852, DOI 10.1177/0018720819844845
   Kim S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P133
   Liu YC, 2004, INT J HUM-COMPUT ST, V61, P679, DOI 10.1016/j.ijhcs.2004.06.002
   Medenica Z., 2011, P 13 INT C HUM COMP, P265, DOI DOI 10.1145/2037373.2037414
   Milicic N., 2010, THESIS TU MUNICH MUN
   Pfannmüller L, 2015, PROCEDIA MANUF, V3, P2722, DOI 10.1016/j.promfg.2015.07.678
   Pfannmuller L., 2017, THESIS TU MUNICH MUN
   Rusch ML, 2013, TRANSPORT RES F-TRAF, V16, P127, DOI 10.1016/j.trf.2012.08.007
   Sandbrink J., 2019, THESIS SPRINGER FACH
   Schneid M., 2009, THESIS TU MUNICH MUN
   Tonnis M., 2008, THESIS TU MUNICH MUN
   Winner H., 2015, Handbuch Fahrerassistenzsysteme, DOI DOI 10.1007/978-3-658-05734-3_36
NR 27
TC 1
Z9 1
U1 2
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 16
PY 2022
VL 3
AR 930117
DI 10.3389/frvir.2022.930117
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XG9
UT WOS:001023305500001
OA gold
DA 2024-07-18
ER

PT J
AU Ochs, C
   Sonderegger, A
AF Ochs, Carli
   Sonderegger, Andreas
TI The Interplay Between Presence and Learning
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE presence; memorization; learning; virtual reality; immersion;
   environment; noise
ID TOP VIRTUAL-REALITY; CONTEXT-DEPENDENT MEMORY; HEAD-MOUNTED DISPLAYS;
   DESK-TOP; EXPOSURE THERAPY; HIGHER-EDUCATION; ENVIRONMENTS; OUTCOMES;
   TECHNOLOGY; SYMPTOMS
AB The highly immersive Virtual reality (VR) headset is gaining popularity in multiple application domains. In the context of learning, it has been proposed to be beneficial by increasing presence and attention in noisy and distracting environments, both factors that are considered important for learning. Despite intensified research efforts in recent years, empirical knowledge of experimental research addressing the link between presence and learning in specific environmental contexts is still rather scarce. In this study following an experimental mixed-method approach, the link between presence and memorization as a particular form of learning is addressed by comparing memorization with a highly immersive VR headset to a less immersive system (desktop screen) in noisy and calm learning environments. Using a 2 (learning location) x 2 (learning device) between-subjects design, 63 participants interacted with one of the two devices in either of the two environments. As expected, VR headset users reported higher presence levels. While participants subjectively evaluated the VR headset as a better device for learning, the memorization test scores were higher for desktop screen users in both calm and noisy environments. Learning location did not show significant effects. Attention distraction and context-dependent learning are discussed with regard to the unexpected results, while implications for practice and future research are discussed.
C1 [Ochs, Carli; Sonderegger, Andreas] Univ Fribourg, Dept Psychol, Fribourg, Switzerland.
   [Sonderegger, Andreas] Bern Univ Appl Sci, Inst New Work, Business Sch, Bern, Switzerland.
C3 University of Fribourg
RP Sonderegger, A (corresponding author), Univ Fribourg, Dept Psychol, Fribourg, Switzerland.; Sonderegger, A (corresponding author), Bern Univ Appl Sci, Inst New Work, Business Sch, Bern, Switzerland.
EM andreas.sonderegger@bfh.ch
OI Ochs, Carli/0000-0002-5348-2483
CR Abulrub A. G., 2011, 2011 IEEE Global Engineering Education Conference (EDUCON), P751, DOI 10.1109/EDUCON.2011.5773223
   Alhalabi WS, 2016, BEHAV INFORM TECHNOL, V35, P919, DOI 10.1080/0144929X.2016.1212931
   Altmann EM, 2014, J EXP PSYCHOL GEN, V143, P215, DOI 10.1037/a0030986
   Alvarez-Lopez F, 2020, J MED INTERNET RES, V22, DOI 10.2196/17491
   Fernandes LMA, 2016, BEHAV INFORM TECHNOL, V35, P907, DOI 10.1080/0144929X.2016.1232754
   Anderson L. W., 2001, A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives
   [Anonymous], 2010, ALT-J: Research in Learning Technology, DOI [10.1080/09687761003657598, DOI 10.1080/09687761003657598]
   Baños RM, 2011, INT J HUM-COMPUT ST, V69, P602, DOI 10.1016/j.ijhcs.2011.06.002
   Beck JG, 2007, BEHAV THER, V38, P39, DOI 10.1016/j.beth.2006.04.001
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   Birrenbach T, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29586
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bloom BS., 1984, Bloom taxonomy of educational objectives
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bryan S. J., 2018, 2018 IEEE GAM ENT ME, P1, DOI [10.1109/GEM.2018.8516456, DOI 10.1109/GEM.2018.8516456]
   Burdea G, 1996, INT J HUM-COMPUT INT, V8, P5, DOI 10.1080/10447319609526138
   Butler J., 1997, PSYCHIC LIFE POWER T
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Cadet LB, 2020, INT J HUM-COMPUT ST, V144, DOI 10.1016/j.ijhcs.2020.102506
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Cassidy G., 2007, Psychology of Music, V35, P517, DOI [10.1177/0305735607076444, DOI 10.1177/0305735607076444]
   Clarke E, 2021, ADV SIMUL, V6, DOI 10.1186/s41077-020-00153-x
   Cryer A, 2019, IEEE INT C EMERG, P784, DOI [10.1109/ETFA.2019.8869433, 10.1109/etfa.2019.8869433]
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   DAVIS TRV, 1984, ACAD MANAGE REV, V9, P271, DOI 10.2307/258440
   dela Cruz DR, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P20, DOI 10.1109/GEM.2018.8516467
   Dolezal M, 2017, INT CONF GAMES VIRTU, P272, DOI 10.1109/VS-GAMES.2017.8056613
   Fisher AV, 2014, PSYCHOL SCI, V25, P1362, DOI 10.1177/0956797614533801
   Freina L, 2015, PROC EUR CONF GAME, P195
   Fried CB, 2008, COMPUT EDUC, V50, P906, DOI 10.1016/j.compedu.2006.09.006
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325, DOI 10.1111/j.2044-8295.1975.tb01468.x
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Gruber A., 2020, Cognitive and affective perspectives on immersive technology in education, P235, DOI [10.4018/978-1-7998-3250-8, DOI 10.4018/978-1-7998-3250-8, 10.4018/978-1-7998-3250-8.ch012]
   Haines MM, 2001, PSYCHOL MED, V31, P1385, DOI 10.1017/S003329170100469X
   Hayes AT, 2013, INT J GAMING COMPUT-, V5, P20, DOI 10.4018/jgcms.2013040102
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Herz RS, 1997, MEM COGNITION, V25, P375, DOI 10.3758/BF03211293
   Huang YC, 2016, INT J TOUR RES, V18, P116, DOI 10.1002/jtr.2038
   Hupont Isabelle., 2015, 2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX), P1, DOI [DOI 10.1109/QOMEX.2015.7148110, 10.1109/QoMEX.2015.7148110]
   Hurault JC, 2021, ANN PSYCHOL, V121, P443
   Hutchinson L, 2003, BRIT MED J, V326, P810, DOI 10.1136/bmj.326.7393.810
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Khan A., 2003, Journal of Applied Mathematics and Decision Sciences, V7, P187, DOI 10.1155/S1173912603000178
   Kozhevnikov M, 2013, J SCI EDUC TECHNOL, V22, P952, DOI 10.1007/s10956-013-9441-0
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee EAL, 2014, COMPUT EDUC, V79, P49, DOI 10.1016/j.compedu.2014.07.010
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lohre R, 2020, J BONE JOINT SURG AM, V102, DOI 10.2106/JBJS.19.00982
   Lombard M., 2016, NEW AGE VR INVOLVING
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mayer R.E., 1982, Encyclopedia of educational research, P1040
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Moreno R, 2004, J EDUC PSYCHOL, V96, P165, DOI 10.1037/0022-0663.96.1.165
   Moro C, 2017, AUSTRALAS J EDUC TEC, V33, P1, DOI 10.14742/ajet.3840
   Mousavi M, 2013, ADV ENG FORUM, V10, P34, DOI 10.4028/www.scientific.net/AEF.10.34
   Mütterlein J, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P1407
   Nichols S, 1997, PRESENCE-TELEOP VIRT, V6, P667, DOI 10.1162/pres.1997.6.6.667
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pears M, 2022, INDIAN J SURG, V84, P281, DOI 10.1007/s12262-021-02998-6
   PIEDRA JA, 2016, GAM VIRT WORLDS SER, P1
   Polcar J., 2015, MM Science Journal, P613, DOI [DOI 10.17973/MMSJ.2015_06_201516, 10.17973/MMSJ.2015_06_201516]
   Potdevin D, 2021, INT J HUM-COMPUT ST, V150, DOI 10.1016/j.ijhcs.2021.102612
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rahm S, 2016, BMC SURG, V16, DOI 10.1186/s12893-016-0129-2
   Rasheed F., 2015, Proceedings of the 7th international conference on HCI, India HCI 2015, P154, DOI DOI 10.1145/2835966.2836288
   Ray AB, 2016, IEEE CONF TECHNOL ED, P68, DOI [10.1109/T4E.2016.022, 10.1109/T4E.2016.21]
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rizzo A, 2011, J CLIN PSYCHOL MED S, V18, P176, DOI 10.1007/s10880-011-9247-2
   Salzman M. C., 1995, PRESENCE TELEOP VIRT, P293
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Schofield D., 2012, APPL VIRTUAL REALITY, V8, P17
   Seo JH, 2018, ADV INTELL SYST, V596, P245, DOI 10.1007/978-3-319-60018-5_24
   Sharar Sam R, 2008, Expert Rev Neurother, V8, P1667, DOI 10.1586/14737175.8.11.1667
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Skarredghost, 2017, SENS TAST VIRT REAL
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Smith SM, 2001, PSYCHON B REV, V8, P203, DOI 10.3758/BF03196157
   Spira J.B., 2005, COST NOT PAYING ATTE
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Sutcliffe A, 2005, INT J HUM-COMPUT ST, V62, P307, DOI 10.1016/j.ijhcs.2004.11.010
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Veronez MR, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P715, DOI 10.1109/VR.2018.8446207
   Vogel JJ, 2006, J RES TECHNOL EDUC, V39, P105, DOI 10.1080/15391523.2006.10782475
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wyon DP, 2004, INDOOR AIR, V14, P92, DOI 10.1111/j.1600-0668.2004.00278.x
NR 96
TC 10
Z9 11
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 18
PY 2022
VL 3
AR 742509
DI 10.3389/frvir.2022.742509
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YU1
UT WOS:001019246600001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Lombardo, R
   Walther, N
   Young, S
   Gorbatkin, C
   Sletten, Z
   Kang, C
   Tran, O
   Couperus, K
AF Lombardo, Robyn
   Walther, Nicholas
   Young, Scott
   Gorbatkin, Chad
   Sletten, Zachary
   Kang, Christopher
   Tran, Oanh
   Couperus, Kyle
TI Ready Medic One: A Feasibility Study of a Semi-Autonomous Virtual
   Reality Trauma Simulator
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE medical training; telemedicine; training effectiveness; combat medic
   training; virtual reality; medical simulation
AB Introduction: Virtual reality (VR) technologies have rapidly advanced and offer increasingly higher fidelity visually immersive learning environments. Several studies have shown promise for using VR in medical education. This pilot study evaluates the feasibility of using a novel VR trauma simulator that can function without an instructor, assessing potential challenges with the technology, perceived realism of the simulation, side effects experienced while completing the simulations, and overall perception of training utility from end-users.Methods: This was a single-center prospective cohort study completed at Madigan Army Medical Center Emergency Department. Participants were enrolled using convenience sampling. They completed surveys before and after completing a trauma simulation. Each participant underwent a 10-min simulation orientation and subsequently completed a self-directed trauma simulation involving massive hemorrhage, tension pneumothorax, or airway obstruction case. The simulation utilized a gaming laptop and a Microsoft Mixed Reality & COPY; headset and controllers. Survey data was analyzed using descriptive statistics and subgroup analyses.Results: Seventeen participants were enrolled and completed pre-and post-surveys. Study participants were predominantly male and represented all clinical roles in the emergency department (ED). Overall, participants indicated the training environment felt realistic (AV 8.3/10, SD 1.4, 95% CI 7.6, 8.0) and supported further use of this technology in training (AV 9.3/10, SD 0.99, 95% CI 8.8, 9.8). There was a statistically significant correlation between participants who responded, "I would support further use of this technology in my training" (likert greater than 8/10) and several other responses. Individuals who supported further use of VR in training were more likely to have fewer years of clinical experience, have more experience with 2D (desktop) computer training, reported realistic clinical changes within the simulator, indicated the environment was realistic, and supported the addition of VR to mannequin-based training.Conclusion: The results indicate it may be possible to create realistic dynamic VR simulations that function without an instructor, and that medical personnel may be supportive of integrating VR technology into medical education. This seems most likely for younger individuals, with less experience, who have found computer based medical training helpful in the past. Future research could focus on methods to minimize side effects, and how VR technology can best augment current training techniques and curricula.
C1 [Lombardo, Robyn; Walther, Nicholas; Young, Scott; Gorbatkin, Chad; Kang, Christopher; Tran, Oanh; Couperus, Kyle] Madigan Army Med Ctr, Dept Emergency Med, Tacoma, WA 98433 USA.
   [Sletten, Zachary] San Antonio Mil Med Ctr, Dept Emergency Med, San Antonio, TX USA.
C3 Madigan Army Medical Center; San Antonio Military Medical Center
RP Tran, O (corresponding author), Madigan Army Med Ctr, Dept Emergency Med, Tacoma, WA 98433 USA.
EM tranot0495@gmail.com
FU AMEDD Advanced Medical Technology Initiative Rapid Innovation Funding
   (AAMTI RIF) [AAMTI 8509]
FX This study was supported by AMEDD Advanced Medical Technology Initiative
   Rapid Innovation Funding (AAMTI RIF) (Award number: AAMTI#8509).
CR Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Couperus K, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8062
   Davis DD., 2021, STATPEARLS
   Erlinger L., 2019, HIGH FIDELITY MANNEQ
   Gallagher AG, 2013, ANN SURG, V257, P1025, DOI 10.1097/SLA.0b013e318284f658
   Grantcharov TP, 2004, BRIT J SURG, V91, P146, DOI 10.1002/bjs.4407
   Huber T, 2017, SURG ENDOSC, V31, P4472, DOI 10.1007/s00464-017-5500-6
   Ingrassia PL, 2015, EUR J EMERG MED, V22, P121, DOI 10.1097/MEJ.0000000000000132
   Katz D, 2020, J MED INTERNET RES, V22, DOI 10.2196/17425
   Kaufmann C, 2001, STUD HEALTH TECHNOL, V81, P236
   Lewis CH, 1997, ST HEAL T, V44, P35
   McGrath JL, 2018, ACAD EMERG MED, V25, P186, DOI 10.1111/acem.13308
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Plechatá A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01330
   Pourmand A, 2017, GAMES HEALTH J, V6, P263, DOI 10.1089/g4h.2017.0046
   Pulijala Y, 2018, J ORAL MAXIL SURG, V76, P1065, DOI 10.1016/j.joms.2017.10.002
   Samadbeik Mahnaz, 2018, J Adv Med Educ Prof, V6, P123
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Vincent DS, 2008, ACAD EMERG MED, V15, P1160, DOI 10.1111/j.1553-2712.2008.00191.x
NR 19
TC 2
Z9 2
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 18
PY 2022
VL 2
AR 719656
DI 10.3389/frvir.2021.719656
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OE9
UT WOS:001021696200001
OA gold
DA 2024-07-18
ER

PT J
AU Degner, J
   Steep, L
   Schmidt, S
   Steinicke, F
AF Degner, Juliane
   Steep, Lea
   Schmidt, Susanne
   Steinicke, Frank
TI Assessing Automatic Approach-Avoidance Behavior in an Immersive Virtual
   Environment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; approach-avoidance; attitude-behavior research;
   empirical studies; human-computer interaction
ID REALITY; FEAR; TENDENCIES; DISTANCE
AB The use of virtual reality (VR) promises enormous potential for studying human behavior. While approach and avoidance tendencies have been explored in various areas of basic and applied psychology, such as attitude and emotion research, basic learning psychology, and behavior therapy, they have rarely been studied in VR. One major focus of this research is to understand the psychological mechanisms underlying automatic behavioral tendencies towards and away from positively or negatively evaluated stimuli. We implemented a whole-body movement stimulus-response compatibility task to explore approach-avoidance behavior in an immersive virtual environment. We chose attitudinal stimuli-spiders and butterflies-on which people widely agree in their general evaluations (in that people evaluate spiders negatively and butterflies positively), while there is still substantial inter-individual variance (i. e., the intensity in which people dislike spiders or like butterflies). We implemented two parallel approach-avoidance tasks, one in VR, one desktop-based. Both tasks revealed the expected compatibility effects that were positively intercorrelated. Interestingly, however, the compatibility effect in the VR measure was unrelated to participants' self-reported fear of spiders and stimulus evaluations. These results raise important implications about the usage of VR to study automatic behavioral tendencies.
C1 [Degner, Juliane] Univ Hamburg, Inst Psychol, Social Psychol, Hamburg, Germany.
   [Steep, Lea; Schmidt, Susanne; Steinicke, Frank] Univ Hamburg, Dept Informat, Human Comp Interact, Hamburg, Germany.
C3 University of Hamburg; University of Hamburg
RP Degner, J (corresponding author), Univ Hamburg, Inst Psychol, Social Psychol, Hamburg, Germany.; Steinicke, F (corresponding author), Univ Hamburg, Dept Informat, Human Comp Interact, Hamburg, Germany.
EM juliane.degner@uni-hamburg.de; frank.steinicke@uni-hamburg.de
RI Steinicke, Frank/AAC-2976-2020
OI Steinicke, Frank/0000-0001-9879-7414
CR Barsalou L.W., 2015, PERCEPTUAL EMOTIONAL, P19
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Beatty GF, 2016, EMOTION, V16, P237, DOI 10.1037/emo0000115
   Benito KG, 2015, J OBSESS-COMPULS REL, V6, P147, DOI 10.1016/j.jocrd.2015.01.006
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Chen M, 1999, PERS SOC PSYCHOL B, V25, P215, DOI 10.1177/0146167299025002007
   Davey G.C., 1992, Anxiety Research, V4, P299, DOI [10.1080/08917779208248798, DOI 10.1080/08917779208248798]
   De Houwer J, 2001, COGNITION EMOTION, V15, P189, DOI 10.1080/0269993004200051
   Degner J, 2016, EUR J SOC PSYCHOL, V46, P783, DOI 10.1002/ejsp.2234
   Dibbets P., 2015, Journal of Depression & Anxiety, V4, DOI [10.4172/2167-1044.1000182, DOI 10.4172/2167-1044.1000182]
   Eagly A. H., 1993, PSYCHOL ATTITUDES
   Eder AB, 2008, J EXP PSYCHOL GEN, V137, P262, DOI 10.1037/0096-3445.137.2.262
   Eder AB, 2021, MOTIV SCI, V7, P133, DOI 10.1037/mot0000205
   Eiler TJ, 2019, ADV INTELL SYST COMP, V1011, P151, DOI 10.1007/978-3-030-23762-2_14
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Ellwart T, 2006, EMOTION, V6, P18, DOI 10.1037/1528-3542.6.1.18
   FAZIO RH, 1986, J PERS SOC PSYCHOL, V50, P229, DOI 10.1037/0022-3514.50.2.229
   Garcia-Palacios A, 2002, BEHAV RES THER, V40, P983, DOI 10.1016/S0005-7967(01)00068-7
   Kakoschke N, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102626
   Klein AM, 2011, J CHILD FAM STUD, V20, P224, DOI 10.1007/s10826-010-9402-7
   Krieglmeyer R, 2013, EMOT REV, V5, P280, DOI 10.1177/1754073913477501
   Krieglmeyer R, 2010, COGNITION EMOTION, V24, P810, DOI 10.1080/02699930903047298
   Lindner P, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00116
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Moors A, 2006, PSYCHOL BULL, V132, P297, DOI 10.1037/0033-2909.132.2.297
   Mostajeran F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1471, DOI [10.1109/VR.2019.8797817, 10.1109/vr.2019.8797817]
   Nichols S, 1999, APPL ERGON, V30, P79, DOI 10.1016/S0003-6870(98)00045-3
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Phaf RH, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00378
   RATCLIFF R, 1993, PSYCHOL BULL, V114, P510, DOI 10.1037/0033-2909.114.3.510
   Reinecke A., 2015, Z PSYCHOL
   Rinck M, 2002, DIAGNOSTICA, V48, P141, DOI 10.1026//0012-1924.48.3.141
   Rinck M, 2007, J BEHAV THER EXP PSY, V38, P105, DOI 10.1016/j.jbtep.2006.10.001
   Rinck M, 2006, J ABNORM PSYCHOL, V115, P231, DOI 10.1037/0021-843X.115.2.231
   Rotteveel M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00335
   Rougier M, 2020, EUR J SOC PSYCHOL, V50, P857, DOI 10.1002/ejsp.2653
   Rougier M, 2018, J EXP SOC PSYCHOL, V76, P42, DOI 10.1016/j.jesp.2017.12.004
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Seibt B, 2008, J EXP SOC PSYCHOL, V44, P713, DOI 10.1016/j.jesp.2007.04.013
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   SOLARZ AK, 1960, J EXP PSYCHOL, V59, P239, DOI 10.1037/h0047274
   SZYMANSKI J, 1995, J BEHAV THER EXP PSY, V26, P31, DOI 10.1016/0005-7916(94)00072-T
   TurboSquid, 2019, 3D MOD PROF
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Wentura D, 2010, COGNITION EMOTION, V24, P609, DOI 10.1080/02699930902854587
   Wilson CJ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/151702
   ZAJONC RB, 1980, AM PSYCHOL, V35, P151, DOI 10.1037/0003-066X.35.2.151
NR 48
TC 5
Z9 5
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 20
PY 2021
VL 2
AR 761142
DI 10.3389/frvir.2021.761142
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TM5
UT WOS:001021834800001
OA gold
DA 2024-07-18
ER

PT J
AU Greenhalgh, M
   Fitzpatrick, C
   Rodabaugh, T
   Madrigal, E
   Timmerman, M
   Chung, J
   Ahuja, D
   Kennedy, Q
   Harris, OA
   Adamson, MM
AF Greenhalgh, Mark
   Fitzpatrick, Christian
   Rodabaugh, Timothy
   Madrigal, Esmeralda
   Timmerman, Molly
   Chung, Joyce
   Ahuja, Deeksha
   Kennedy, Quinn
   Harris, Odette A.
   Adamson, Maheen M.
TI Assessment of Task Demand and Usability of a Virtual Reality-Based
   Rehabilitation Protocol for Combat Related Traumatic Brain Injury From
   the Perspective of Veterans Affairs Healthcare Providers: A Pilot Study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE traumatic brain injury; virtual reality; veterans; task demand;
   cognitive performance
ID EXPOSURE THERAPY; CHRONIC PAIN; STRESS; ADULTS
AB The risk of traumatic brain injury (TBI) is significantly higher among Veterans compared to non- Veterans. Access to treatment for TBI and post concussive symptoms is sometimes difficult, because of barriers related to distance, finances, and public safety (i.e., COVID-19 infection). Virtual reality rehabilitation (VRR) offers an opportunity to incorporate a virtual space into a rehabilitation environment. To our knowledge, VRR has not been used to assist Veterans with TBI and related health problems with Instrumental Activities of Daily Living (iADLs). The purpose of this study is to investigate the usability of a novel VRR ADL and iADL training protocols, developed by the Gaming Research Integration for Learning Laboratory (GRILL(& REG;)) at the Air Force Research Laboratory, for cognitive rehabilitation for Veterans with a TBI. We deployed a prototype protocol among healthcare providers (n = 20) to obtain feedback on usability, task demand, and recommended adjustments. Our preliminary analysis shows that providers found the VRR protocol involved low physical demand and would likely recommend it to their patients. Although they had some concerns with vertigo-like symptoms from using a digital technology, they believed the protocol would improve iADL functioning and was a good addition to pre-existing rehabilitation protocols. These outcomes provide justification for more impactful studies investigating the effectiveness of this protocol among Veterans with TBI.
C1 [Greenhalgh, Mark; Harris, Odette A.; Adamson, Maheen M.] Stanford Univ, Sch Med, Dept Neurosurg, Stanford, CA 94305 USA.
   [Greenhalgh, Mark; Madrigal, Esmeralda; Chung, Joyce; Ahuja, Deeksha; Adamson, Maheen M.] VA Palo Alto Hlth Care Syst, Rehabil Serv, Palo Alto, CA 94304 USA.
   [Fitzpatrick, Christian; Kennedy, Quinn] Naval Postgrad Sch, Monterey, CA USA.
   [Rodabaugh, Timothy] Air Force Res Lab, Gaming Res Integrat Learning Lab, Dayton, OH USA.
   [Timmerman, Molly] VA Palo Alto Hlth Care Syst, Phys Med & Rehabil, Palo Alto, CA USA.
   [Harris, Odette A.] VA Palo Alto Hlth Care Syst, Rehabilitation, Palo Alto, CA USA.
C3 Stanford University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); VA Palo Alto Health Care System; United States
   Department of Defense; United States Navy; Naval Postgraduate School; US
   Department of Veterans Affairs; Veterans Health Administration (VHA); VA
   Palo Alto Health Care System; US Department of Veterans Affairs;
   Veterans Health Administration (VHA); VA Palo Alto Health Care System
RP Adamson, MM (corresponding author), Stanford Univ, Sch Med, Dept Neurosurg, Stanford, CA 94305 USA.; Adamson, MM (corresponding author), VA Palo Alto Hlth Care Syst, Rehabil Serv, Palo Alto, CA 94304 USA.
EM madamson@stanford.edu
OI Chung, Joyce/0000-0003-2831-9964
CR Alashram AR, 2020, J CLIN NEUROSCI, V72, P322, DOI 10.1016/j.jocn.2020.01.037
   [Anonymous], 2020, CHRON PAIN COVID 19
   Apkarian AV, 2004, PAIN, V108, P129, DOI 10.1016/j.pain.2003.12.015
   Bryson-Campbell M, 2013, WORK, V44, P57, DOI [10.3233/WOR-2012-01561, 10.3233/WOR-2012-1561]
   Carrougher GJ, 2009, J BURN CARE RES, V30, P785, DOI 10.1097/BCR.0b013e3181b485d3
   Dicianno BE, 2018, MIL MED, V183, pE518, DOI 10.1093/milmed/usy033
   Greenhalgh M, 2022, DISABIL REHABIL-ASSI, V17, P833, DOI 10.1080/17483107.2020.1818137
   Greenhalgh M, 2019, AM J PHYS MED REHAB, V98, P729, DOI 10.1097/PHM.0000000000001176
   Greenleaf W., 2017, VIRTUAL AUGMENTED RE
   Guest F., 2019, Surgery (Oxford), V37, P102
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Kirsch B, 2019, INFORM TECHNOL LIBR, V38, P4, DOI 10.6017/ital.v38i4.11847
   Kothgassner OD, 2019, EUR J PSYCHOTRAUMATO, V10, DOI 10.1080/20008198.2019.1654782
   Kulich HR, 2020, APPL ERGON, V88, DOI 10.1016/j.apergo.2020.103172
   Lackey SJ, 2016, ERGONOMICS, V59, P1060, DOI 10.1080/00140139.2015.1122234
   Levy CE, 2019, AM J PHYS MED REHAB, V98, P191, DOI 10.1097/PHM.0000000000001041
   Maggio MG, 2019, J CLIN NEUROSCI, V61, P1, DOI 10.1016/j.jocn.2018.12.020
   Mallari B, 2019, J PAIN RES, V12, P2053, DOI 10.2147/JPR.S200498
   McLay RN, 2011, CYBERPSYCH BEH SOC N, V14, P223, DOI 10.1089/cyber.2011.0003
   Mirelman A, 2010, GAIT POSTURE, V31, P433, DOI 10.1016/j.gaitpost.2010.01.016
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Nahin RL, 2017, J PAIN, V18, P247, DOI 10.1016/j.jpain.2016.10.021
   Ohl ME, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-3108-8
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Ronnie J., USING TELEHEALTH EXP
NR 29
TC 0
Z9 1
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 28
PY 2021
VL 2
AR 741578
DI 10.3389/frvir.2021.741578
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YQ1
UT WOS:001019242500001
OA gold
DA 2024-07-18
ER

PT J
AU Wilson, K
   Scorsone, G
AF Wilson, Kaylie
   Scorsone, Grace
TI The Use of Virtual Reality Technologies to Reduce Anxiety and Improve
   Experience in Chemotherapy Patients During Treatment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; nature; chemotherapy; anxiety; pain; distraction;
   attention restoration theory; cancer
ID EXPOSURE THERAPY; DISTRACTION INTERVENTION; DISORDERS; PILOT; ATTENTION;
   BENEFITS; PAIN
AB The study explored the potential benefits of virtual reality as a psychological intervention to induce positive emotions and reduce pain levels in participants receiving IV chemotherapy treatment. Participants in the study had the opportunity to select a nature theme of their choosing during their treatment session. The study provided a noninvasive solution that promoted relaxation to reduce anxiety by shifting an individual's mood positively during treatment. The objective was met by measuring participants' mood and pain levels before and after the virtual reality experience and participant satisfaction with the use of the technology. The study was conducted in the chemotherapy treatment area at the INTEGRIS Cancer Institute and consisted of a mixed demographic of cancer diagnosed patients. Results of this study showed that participants felt more calm, relaxed, and content, as well as less tense after the use of VR. Participants showed high ratings of feeling immersed and distracted by feeling like they were visiting the places displayed and paid more attention to the said environment than their own thoughts. There was no significant difference in blood pressure, pain levels, feeling upset, or worried. A majority of participants preferred to have VR as part of their future experiences during treatment time.
C1 [Wilson, Kaylie; Scorsone, Grace] INTEGRIS Hlth, Oklahoma City, OK 73112 USA.
RP Wilson, K (corresponding author), INTEGRIS Hlth, Oklahoma City, OK 73112 USA.
EM kwilson5121@yahoo.com
FU INTEGRIS Foundation [BG-2019-051, BG-2021-045, BG-2020-031]
FX INTEGRIS Foundation Grant BG-2021-045 for publication INTEGRIS
   Foundation Grant BG-2020-031 INTEGRIS Foundation Grant BG-2019-051.
CR AppliedVR, 2021, SOOTHVR 2 0 CONT LIB
   Baños RM, 2013, SUPPORT CARE CANCER, V21, P263, DOI 10.1007/s00520-012-1520-x
   Basu A, 2019, ENVIRON BEHAV, V51, P1055, DOI 10.1177/0013916518774400
   Berman MG, 2008, PSYCHOL SCI, V19, P1207, DOI 10.1111/j.1467-9280.2008.02225.x
   Berto R, 2014, BEHAV SCI-BASEL, V4, P394, DOI 10.3390/bs4040394
   Carrougher GJ, 2009, J BURN CARE RES, V30, P785, DOI 10.1097/BCR.0b013e3181b485d3
   Chen CH, 2009, J SPORT REHABIL, V18, P258, DOI 10.1123/jsr.18.2.258
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Flavian C., 2019, IMPACT VIRTUAL AUGME, DOI [10.1016/j.jbusres.2018.10.050, DOI 10.1016/J.JBUSRES.2018.10.050]
   Fodor LA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28113-6
   Gamble KR, 2014, EXP AGING RES, V40, P513, DOI 10.1080/0361073X.2014.956618
   Gerber SM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13153-1
   Gershon J, 2004, J AM ACAD CHILD PSY, V43, P1243, DOI 10.1097/01.chi.0000135621.23145.05
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Golding SE, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15020300
   Herrero R, 2014, CYBERPSYCH BEH SOC N, V17, P379, DOI 10.1089/cyber.2014.0052
   Hoffman HG, 2003, INT J HUM-COMPUT INT, V15, P469, DOI 10.1207/S15327590IJHC1503_10
   Jones T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167523
   Lorenz J., 2017, SUBJECTIVE AUTONOMIC
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   McCann RA, 2014, J ANXIETY DISORD, V28, P625, DOI 10.1016/j.janxdis.2014.05.010
   McGrath P. J., 2017, REFERENCE MODULE NEU, DOI [10.1016/B978-0-12-809324-5.04184-5, DOI 10.1016/B978-0-12-809324-5.04184-5]
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Ohly H, 2016, J TOXICOL ENV HEAL B, V19, P305, DOI 10.1080/10937404.2016.1196155
   Ong Triton L, 2020, Crit Care Explor, V2, pe0122, DOI 10.1097/CCE.0000000000000122
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Rubin R. B., 2009, ANXIETY STATE TRAIT, P463, DOI [10.4324/9780203871539-76, DOI 10.4324/9780203871539-76]
   Schneider SM, 2004, ONCOL NURS FORUM, V31, P81, DOI 10.1188/04.ONF.81-88
   Schneider SM, 2007, ONCOL NURS FORUM, V34, P39, DOI 10.1188/07.ONF.39-46
   Shah L. B. I., 2015, EFFICACY VIRTUAL REA, DOI [10.1016/j.apnu.2014.09.003, DOI 10.1016/J.APNU.2014.09.003]
   Sikka N, 2019, TELEMED E-HEALTH, V25, P1207, DOI 10.1089/tmj.2018.0273
   Spiegel B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219115
   Tanja-Dijkstra K, 2018, ENVIRON BEHAV, V50, P599, DOI 10.1177/0013916517710077
   Valtchanov D, 2015, J ENVIRON PSYCHOL, V43, P184, DOI 10.1016/j.jenvp.2015.07.001
NR 35
TC 8
Z9 8
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 30
PY 2021
VL 2
AR 695449
DI 10.3389/frvir.2021.695449
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TV7
UT WOS:001021844000001
OA gold
DA 2024-07-18
ER

PT J
AU Matsuda, Y
   Nakamura, J
   Amemiya, T
   Ikei, Y
   Kitazaki, M
AF Matsuda, Yusuke
   Nakamura, Junya
   Amemiya, Tomohiro
   Ikei, Yasushi
   Kitazaki, Michiteru
TI Enhancing Virtual Walking Sensation Using Self-Avatar in First-Person
   Perspective and Foot Vibrations
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE walking; self-motion; avatar; optic flow; tactile sensation;
   first-person perspective; third-person perspective
ID LOCOMOTION INTERFACE; BIOLOGICAL MOTION; VECTION; SICKNESS
AB Walking is a fundamental physical activity in humans. Various virtual walking systems have been developed using treadmill or leg-support devices. Using optic flow, foot vibrations simulating footsteps, and a walking avatar, we propose a virtual walking system that does not require limb action for seated users. We aim to investigate whether a full-body or hands-and-feet-only walking avatar with either the first-person (experiment 1) or third-person (experiment 2) perspective can convey the sensation of walking in a virtual environment through optic flows and foot vibrations. The viewing direction of the virtual camera and the head of the full-body avatar were linked to the actual user's head motion. We discovered that the full-body avatar with the first-person perspective enhanced the sensations of walking, leg action, and telepresence, either through synchronous or asynchronous foot vibrations. Although the hands-and-feet-only avatar with the first-person perspective enhanced the walking sensation and telepresence, compared with the no-avatar condition, its effect was less prominent than that of the full-body avatar. However, the full-body avatar with the third-person perspective did not enhance the sensations of walking and leg action; rather, it impaired the sensations of self-motion and telepresence. Synchronous or rhythmic foot vibrations enhanced the sensations of self-motion, waking, leg action, and telepresence, irrespective of the avatar condition. These results suggest that the full-body or hands-and-feet avatar is effective for creating virtual walking experiences from the first-person perspective, but not the third-person perspective, and that the foot vibrations simulating footsteps are effective, regardless of the avatar condition.
C1 [Matsuda, Yusuke; Nakamura, Junya; Kitazaki, Michiteru] Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Japan.
   [Amemiya, Tomohiro; Ikei, Yasushi] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
C3 Toyohashi University of Technology; University of Tokyo
RP Matsuda, Y; Nakamura, J (corresponding author), Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Japan.
EM matsuda.yusuke.vp@tut.jp; nakamuraj@real.cs.tut.ac.jp
OI Matsuda, Yusuke/0000-0002-5982-3971; Amemiya,
   Tomohiro/0000-0002-7079-9167; Kitazaki, Michiteru/0000-0003-0966-4842
FU JST ERATO [JPMJER1701]; JSPS KAKENHI [JP18H04118, JP19K20645,
   JP20H04489]
FX & nbsp;This research was supported in part by JST ERATO (JPMJER1701) to
   MK, JSPS KAKENHI JP18H04118 to YI, JP19K20645 to YM, and JP20H04489 to
   MK.
CR Aspell JE, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006488
   Bhandari N, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P939, DOI [10.1109/VR46266.2020.1580764402138, 10.1109/VR46266.2020.00119]
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   BRANDT T, 1975, PERCEPT PSYCHOPHYS, V17, P497, DOI 10.3758/BF03203301
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Denisova A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P145, DOI 10.1145/2702123.2702256
   Dichgans J., 1978, HDB SENSORY PHYSL, VVIII., P755
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Evin Inan, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P438, DOI 10.1145/3410404.3414239
   Farkhatdinov I, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P677, DOI 10.1109/WHC.2013.6548490
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Freiwald JP, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376574
   GEISSER S, 1958, ANN MATH STAT, V29, P885, DOI 10.1214/aoms/1177706545
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Haggard P, 2017, NAT REV NEUROSCI, V18, P197, DOI 10.1038/nrn.2017.14
   Haggard P, 2012, CURR BIOL, V22, pR390, DOI 10.1016/j.cub.2012.02.040
   Ikei Y, 2015, P IEEE VIRT REAL ANN, P195, DOI 10.1109/VR.2015.7223362
   Iwata H, 2005, P IEEE VIRT REAL ANN, P223, DOI 10.1109/VR.2005.11
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Iwata H, 1999, P IEEE VIRT REAL ANN, P286, DOI 10.1109/VR.1999.756964
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kitazaki M, 2003, PERCEPTION, V32, P475, DOI 10.1068/p5037
   Kitazaki M, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519882448
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kondo R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62121-9
   Kondo R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25951-2
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Lécuyer A, 2006, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2006.31
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   MacKay-Lyons M, 2002, PHYS THER, V82, P69, DOI 10.1093/ptj/82.1.69
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Matsuda Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P733, DOI [10.1109/VRW50115.2020.00-58, 10.1109/VRW50115.2020.00217]
   Medina Eliana, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P2102, DOI 10.1518/107118108X352490
   Monteiro D, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1830
   OHMI M, 1987, PERCEPTION, V16, P17, DOI 10.1068/p160017
   Palmisano S, 2003, PERCEPTION, V32, P97, DOI 10.1068/p3468
   Palmisano S, 2000, PERCEPTION, V29, P57, DOI 10.1068/p2990
   Palmisano S, 2007, AVIAT SPACE ENVIR MD, V78, P951, DOI 10.3357/ASEM.2079.2007
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Riecke BE, 2005, P IEEE VIRT REAL ANN, P131
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Riecke BE, 2011, VIRTUAL REALITY, P149
   Riecke BE, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498701
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schuurink EL, 2010, SIMULAT GAMING, V41, P724, DOI 10.1177/1046878110365515
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Terziman L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P19, DOI 10.1109/3DUI.2012.6184179
   Thompson J, 2012, NEUROIMAGE, V59, P4, DOI 10.1016/j.neuroimage.2011.05.044
   Tieri G, 2015, SCI REP-UK, V5, DOI 10.1038/srep17139
   Troje NF, 2008, The Senses: A Comprehensive Reference, V2, P231
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
NR 64
TC 14
Z9 14
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 21
PY 2021
VL 2
AR 654088
DI 10.3389/frvir.2021.654088
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XG3
UT WOS:001023304900001
OA gold
DA 2024-07-18
ER

PT J
AU Loizeau, Q
   Danglade, F
   Ababsa, F
   Merienne, F
AF Loizeau, Quentin
   Danglade, Florence
   Ababsa, Fakhreddine
   Merienne, Frederic
TI Methodology for the Field Evaluation of the Impact of Augmented Reality
   Tools for Maintenance Workers in the Aeronautic Industry
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; field evaluation; criteria; use-case selection;
   maintenance; aeronautic; industry; deploy
ID VIRTUAL-REALITY; COGNITIVE-LOAD; SUS
AB Augmented Reality (AR) enhances the comprehension of complex situations by making the handling of contextual information easier. Maintenance activities in aeronautics consist of complex tasks carried out on various high-technology products under severe constraints from the sector and work environment. AR tools appear to be a potential solution to improve interactions between workers and technical data to increase the productivity and the quality of aeronautical maintenance activities. However, assessments of the actual impact of AR on industrial processes are limited due to a lack of methods and tools to assist in the integration and evaluation of AR tools in the field. This paper presents a method for deploying AR tools adapted to maintenance workers and for selecting relevant evaluation criteria of the impact in an industrial context. This method is applied to design an AR tool for the maintenance workshop, to experiment on real use cases, and to observe the impact of AR on productivity and user satisfaction for all worker profiles. Further work aims to generalize the results to the whole maintenance process in the aeronautical industry. The use of the collected data should enable the prediction of the impact of AR for related maintenance activities.
C1 [Loizeau, Quentin; Danglade, Florence; Ababsa, Fakhreddine; Merienne, Frederic] HESAM Univ, Inst Technol, Arts & Metiers, LISPEN, Paris, France.
C3 heSam Universite; Conservatoire National Arts & Metiers (CNAM);
   Universite de Montpellier
RP Loizeau, Q (corresponding author), HESAM Univ, Inst Technol, Arts & Metiers, LISPEN, Paris, France.
EM quentin.loizeau.pro@gmail.com
OI Danglade, Florence/0000-0002-8281-1004
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Blaga AD, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P31, DOI 10.1109/ISMAR-Adjunct.2017.25
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Brünken R, 2003, EDUC PSYCHOL-US, V38, P53, DOI 10.1207/S15326985EP3801_7
   Caudell T. P., 1992, SYST SCI P 25 HAW IN
   Diota, 2019, SOL 4 0 IND
   easa, EASA REG
   Eschen H, 2018, PROCEDIA MANUF, V19, P156, DOI 10.1016/j.promfg.2018.01.022
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Fite-Georgel P., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P201, DOI 10.1109/ISMAR.2011.6092387
   Fuchs H., 2019, KEYNOTE
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hornbæk K, 2006, INT J HUM-COMPUT ST, V64, P79, DOI 10.1016/j.ijhcs.2005.06.002
   IATA, 2018, PRESS REL NO 62
   ISO, 1998, ISO 119241
   Jetter J, 2018, COMPUT HUM BEHAV, V87, P18, DOI 10.1016/j.chb.2018.04.054
   Kim S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P133
   Knoke MQB, 2018, PROC CIRP, V72, P1130, DOI 10.1016/j.procir.2018.03.061
   Lugan G., 2011, THESIS DUMAS
   Martinetti A, 2017, PROC CIRP, V59, P14, DOI 10.1016/j.procir.2016.10.130
   MRO Survey, 2017, GROWTH OUTP CAP
   Mura MD, 2016, PROC CIRP, V41, P340, DOI 10.1016/j.procir.2015.12.128
   PAAS FGWC, 1992, J EDUC PSYCHOL, V84, P429, DOI 10.1037/0022-0663.84.4.429
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Palmarini R, 2017, PROC CIRP, V59, P23, DOI 10.1016/j.procir.2016.10.001
   PWC, 2019, WILL PEOPL CREAT CON
   Renner P, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P176, DOI 10.1109/ISMAR-Adjunct.2017.59
   Rios H, 2013, PROCEDIA COMPUT SCI, V25, P161, DOI 10.1016/j.procs.2013.11.020
   Rubio S, 2004, APPL PSYCHOL-INT REV, V53, P61, DOI 10.1111/j.1464-0597.2004.00161.x
   Syberfeldt A, 2015, PROCEDIA MANUF, V1, P98, DOI 10.1016/j.promfg.2015.09.068
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Werrlich S., 2017, International Journal of Computer and Information Engineering, V11, P1068
NR 38
TC 4
Z9 4
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 25
PY 2021
VL 1
AR 603189
DI 10.3389/frvir.2020.603189
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OR0
UT WOS:001021708500001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Tromp, J
   Klotzsche, F
   Krohn, S
   Akbal, M
   Pohl, L
   Quinque, EM
   Belger, J
   Villringer, A
   Gaebler, M
AF Tromp, Johanne
   Klotzsche, Felix
   Krohn, Stephan
   Akbal, Mert
   Pohl, Leonardo
   Quinque, Eva M. M.
   Belger, Julia
   Villringer, Arno
   Gaebler, Michael
TI OpenVirtualObjects: An Open Set of Standardized and Validated 3D
   Household Objects for Virtual Reality-Based Research, Assessment, and
   Therapy
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; 3D objects database; stimuli; neuropsychology &
   neurology; virtual medicine; 3D objects
ID METAANALYSIS; PICTURES; SYSTEM; LIFE
AB Virtual reality (VR) technology provides clinicians, therapists, and researchers with new opportunities to observe, assess, and train behavior in realistic yet well-controlled environments. However, VR also comes with a number of challenges. For example, compared to more abstract experiments and tests on 2D computer screens, VR-based tasks are more complex to create, which can make it more expensive and time-consuming. One way to overcome these challenges is to create, standardize, and validate VR content and to make it openly available for researchers and clinicians. Here we introduce the OpenVirtualObjects (OVO), a set of 124 realistic 3D household objects that people encounter and use in their everyday lives. The objects were rated by 34 younger and 25 older adults for recognizability, familiarity, details (i.e., visual complexity), contact, and usage (i.e., frequency of usage in daily life). All participants also named and categorized the objects. We provide the data and the experiment- and analysis code online. With OVO, we hope to facilitate VR-based research and clinical applications. Easy and free availability of standardized and validated 3D objects can support systematic VR-based studies and the development of VR-based diagnostics and therapeutic tools.
C1 [Tromp, Johanne; Klotzsche, Felix; Akbal, Mert; Quinque, Eva M. M.; Belger, Julia; Villringer, Arno; Gaebler, Michael] Max Planck Inst Human Cognit & Brain Sci, Neurol Dept, Leipzig, Germany.
   [Tromp, Johanne; Klotzsche, Felix; Villringer, Arno; Gaebler, Michael] Humboldt Univ, MindBrainBody Inst, Fac Philosophy, Berlin Sch Mind & Brain, Berlin, Germany.
   [Krohn, Stephan] Charite Univ Med Berlin, Dept Neurol, Berlin, Germany.
   [Akbal, Mert] Hsch Bildenden Kunste Saar, Saarbrucken, Germany.
   [Pohl, Leonardo] Free Univ Berlin, Berlin, Germany.
   [Quinque, Eva M. M.; Belger, Julia] Univ Hosp Leipzig, Clin Cognit Neurol, Leipzig, Germany.
C3 Max Planck Society; Humboldt University of Berlin; Berlin Institute of
   Health; Free University of Berlin; Humboldt University of Berlin;
   Charite Universitatsmedizin Berlin; Free University of Berlin; Leipzig
   University
RP Tromp, J; Gaebler, M (corresponding author), Max Planck Inst Human Cognit & Brain Sci, Neurol Dept, Leipzig, Germany.; Tromp, J; Gaebler, M (corresponding author), Humboldt Univ, MindBrainBody Inst, Fac Philosophy, Berlin Sch Mind & Brain, Berlin, Germany.
EM trompjohanne@gmail.com; gaebler@cbs.mpg.de
RI Gaebler, Michael/C-1923-2014
OI Gaebler, Michael/0000-0002-4442-5778; Krohn,
   Stephan/0000-0003-0683-5386; Klotzsche, Felix/0000-0003-3985-2481
FU (BMBF grant) from the German Federal Ministry for Education and Research
   [13GW0206]
FX This project was funded by a grant (BMBF grant 13GW0206) from the German
   Federal Ministry for Education and Research for the research consortium
   VReha-Virtual worlds for digital diagnostics and cognitive
   rehabilitation.
CR Adlington RL, 2009, J CLIN EXP NEUROPSYC, V31, P731, DOI 10.1080/13803390802488103
   Aukstakalnis S., 1992, SILICON MIRAGE ART S
   Brady TF, 2016, P NATL ACAD SCI USA, V113, P7459, DOI 10.1073/pnas.1520027113
   Brodeur MB, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010773
   Frisch S, 2012, J NEUROPSYCHOL, V6, P257, DOI 10.1111/j.1748-6653.2012.02026.x
   Grühn D, 2008, BEHAV RES METHODS, V40, P512, DOI 10.3758/BRM.40.2.512
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124
   Moreno-Martínez FJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037527
   Josman N., 2008, Proceedings of the 7th International Conference on Disability, Virtual Reality and Associated Technologies With ArtAbilitation, P33
   Klotzsche F, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P605, DOI 10.1109/VR.2018.8446275
   Koening ST., 2011, International Journal of Design and Innovation Research, V6, P1
   Krohn S, 2020, J MED INTERNET RES, V22, DOI 10.2196/16724
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Osterrieth P.A., 1944, ARCH PSYCHOLOGIE, V30, P206
   Peeters D, 2018, BEHAV RES METHODS, V50, P1047, DOI 10.3758/s13428-017-0925-3
   Popic D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0238041
   Rey A, 1941, ARCH PSYCHOLOGIE, V28, P286
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Rizzo A, 2010, ANN NY ACAD SCI, V1208, P114, DOI 10.1111/j.1749-6632.2010.05755.x
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Singh A, 2014, IEEE INT CONF ROBOT, P509, DOI 10.1109/ICRA.2014.6906903
   Slyk S, 2019, EXPERT REV MED DEVIC, V16, P1035, DOI 10.1080/17434440.2019.1693892
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Tromp J, 2018, BEHAV RES METHODS, V50, P862, DOI 10.3758/s13428-017-0911-9
NR 25
TC 6
Z9 6
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 22
PY 2020
VL 1
AR 611091
DI 10.3389/frvir.2020.611091
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L6UH0
UT WOS:001024586800001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Khenak, N
   Vézien, J
   Bourdot, P
AF Khenak, Nawel
   Vezien, Jeanne
   Bourdot, Patrick
TI Effectiveness of Augmented Reality Guides for Blind Insertion Tasks
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality guidance; augmented reality-based assembly; blind
   insertion; occlusion issue; user experience (UX); subjective and
   objective evaluation
ID HAPTIC FEEDBACK; ACCURACY; BENEFITS; BEHAVIOR; PROJECTS; DESIGN
AB Although many augmented reality (AR)-based assembly support systems have been proposed in academic research and industry, the effectiveness of AR to resolve the occlusion issue in the context of a blind assembly process remains an unexplored topic. Therefore, the present work investigates how AR can assist operators during the execution of blind manual assembly tasks. Specifically, an AR research set-up was designed to provide assistance in occlusion situations during a peg-in-hole task. The set-up featured a see-through device (HoloLens), which provides operators with two modes of visual augmentations that directly overlay on the assembly objects. The first mode referred to as the "wireframe overlay" displays the inner part of the objects, providing an inside view of the occluded parts, and the second one referred to as the "axes overlay," displays the axes of the objects and their slots, indicating how to align the different parts during the assembly. The effectiveness of these AR visualizations was compared to a baseline augmentation-free situation in a controlled experiment. Thus, following a within-subject design, 30 participants performed a two-stages blind insertion task. Their performances represented by task completion time, insertion errors, and smoothness of the insertions were recorded. In addition, a post-questionnaire reported their subjective perception of task difficulty during the task and their preferences. Results indicated a strong acceptance of participants for AR visualizations that they rated as allowing them to perform the task more easily. However, no statistically significant differences in terms of objective performance measures were found. Yet, it was found that axes overlay produced smoother trajectories compared to the wireframe overlay, highlighting the potential effect of more abstract visualization aids.
C1 [Khenak, Nawel; Vezien, Jeanne; Bourdot, Patrick] Univ Paris Saclay, CNRS, LIMSI, VENISE Team, Orsay, France.
C3 Universite Paris Cite; Centre National de la Recherche Scientifique
   (CNRS); Universite Paris Saclay
RP Vézien, J (corresponding author), Univ Paris Saclay, CNRS, LIMSI, VENISE Team, Orsay, France.
EM vezien@limsi.fr
OI Vezien, Jeanne/0000-0003-1444-4289
FU RTA Digiteo and Labex DigiCosme [ANR-11-IDEX-0003-02]; French National
   Research Agency (ANR) [ANR-10-EQPX-26-01]; French National Research
   Agency (ANR)
FX This research was partially supported by RTA Digiteo and Labex DigiCosme
   (Idex Paris-Saclay ANR-11-IDEX-0003-02), and by EquipEx DIGISCOPE
   (ANR-10-EQPX-26-01) operated by the French National Research Agency
   (ANR), as part of the program Investissements d'Avenir.
CR Abdullah MW, 2015, IFAC PAPERSONLINE, V48, P1476, DOI 10.1016/j.ifacol.2015.06.295
   Arbeláez JC, 2019, INT J INTERACT DES M, V13, P673, DOI 10.1007/s12008-019-00532-3
   Ardito C, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682623
   Avery B., 2007, PROC ISMAR, P285, DOI DOI 10.1109/ISMAR.2007.4538869
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baird K. M., 1999, Virtual Reality, V4, P250, DOI 10.1007/BF01421808
   BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   Bashir A. M., 2004, P ACM SIGGRAPH INT C, P359, DOI [10.1145/1044588.1044666, DOI 10.1145/1044588.1044666]
   Blattgerste J, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P75, DOI 10.1145/3056540.3056547
   Khuong BM, 2014, 2014 IEEE VIRTUAL REALITY (VR), P57, DOI 10.1109/VR.2014.6802051
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chhatpar SR, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1465, DOI 10.1109/IROS.2001.977187
   Curtis D, 1999, AUGMENTED REALITY, P47
   Doil F., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P71, DOI 10.1145/769953.769962
   Evans G., 2017, Degraded Environments: Sensing, Processing, and Display
   Funk M., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments-PETRA '16, P1, DOI [DOI 10.1145/2910674.2910730, 10.1145/2910674.2910683, DOI 10.1145/2910674.2910683]
   Funk M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P934, DOI 10.1145/2971648.2971706
   Funk M, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P253, DOI 10.1145/2836041.2836067
   Furlan R, 2016, IEEE SPECTRUM, V53, P21, DOI 10.1109/MSPEC.2016.7473143
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Hillers B, 2004, VIRTUAL AND AUGMENTED REALITY APPLICATIONS IN MANUFACTURING, P361
   Horejsí P, 2015, PROCEDIA ENGINEER, V100, P699, DOI 10.1016/j.proeng.2015.01.422
   Hou L, 2013, AUTOMAT CONSTR, V32, P38, DOI 10.1016/j.autcon.2012.12.007
   Kitagawa M., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P133, DOI 10.1109/3DUI.2011.5759241
   Korn O., 2013, P 6 INT C PERVASIVE, P1, DOI [10.1145/2504335.2504356, DOI 10.1145/2504335.2504356]
   Lim T., 2007, Virtual Reality, V11, P241, DOI 10.1007/s10055-007-0072-8
   Livingston MA, 2005, IEEE COMPUT GRAPH, V25, P6, DOI 10.1109/MCG.2005.130
   Markov-Vetter D., 2013, Mixed and Augmented Reality (ISMAR), 2013 IEEE International Symposium on, P1, DOI DOI 10.1109/ISMAR.2013.6671832
   Nakanishi M, 2007, IEEE SYS MAN CYBERN, P89
   Navab N, 2010, IEEE T MED IMAGING, V29, P1412, DOI 10.1109/TMI.2009.2021947
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   Nilsson S., 2007, Proceedings of the 19th Australasian Conference on Computer-Human Interaction: Entertaining User Interfaces. OZCHI '07, P123, DOI [10.1145/1324892.1324915, DOI 10.1145/1324892.1324915]
   Nishihara A, 2015, 2015 SAI INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P400, DOI 10.1109/IntelliSys.2015.7361172
   Ojer M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030796
   Okamoto J, 2016, STUD COMPUT INTELL, V650, P281, DOI 10.1007/978-3-319-33386-1_14
   Ong SK, 2008, INT J PROD RES, V46, P2707, DOI 10.1080/00207540601064773
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Park H., 2013, IEEE ISR 2013, P1, DOI [10.1109/ISR.2013.6695699, DOI 10.1109/ISR.2013.6695699]
   Pathomaree N, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P500
   Perret J, 2013, ASSEMBLY AUTOM, V33, P214, DOI 10.1108/AA-03-2013-017
   Petzold B, 2004, PRESENCE-TELEOP VIRT, V13, P16, DOI 10.1162/105474604774048207
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Regenbrecht H, 2005, IEEE COMPUT GRAPH, V25, P48, DOI 10.1109/MCG.2005.124
   Reiners D, 1999, AUGMENTED REALITY, P31
   Reinhart G, 2003, CIRP ANN-MANUF TECHN, V52, P5, DOI 10.1016/S0007-8506(07)60517-4
   Robertson CM, 2008, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2008.4637328
   Schwald B., 2001, E WORK ECOMMERCENOVE, P196
   Seok KH, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P693, DOI 10.1109/ICCIT.2008.304
   Seth Abhishek., 2006, ASME 2006 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, P905, DOI DOI 10.1115/DETC2006-99476
   SIMS D, 1994, IEEE COMPUT GRAPH, V14, P91, DOI 10.1109/38.267487
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Syberfeldt A, 2015, PROCEDIA MANUF, V1, P98, DOI 10.1016/j.promfg.2015.09.068
   Tabrizi LB, 2015, J NEUROSURG, V123, P206, DOI 10.3171/2014.9.JNS141001
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI [10.1145/642611.642626, DOI 10.1145/642611.642626]
   Tching L, 2010, INT J INTERACT DES M, V4, P95, DOI 10.1007/s12008-010-0091-7
   Unger BJ, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P263, DOI 10.1109/HAPTIC.2002.998967
   Valentini PP, 2009, INT J INTERACT DES M, V3, P109, DOI 10.1007/s12008-009-0064-x
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Wildenbeest JGW, 2013, IEEE T HAPTICS, V6, P242, DOI [10.1109/TOH.2012.19, 10.1109/ToH.2012.19]
   Yuan ML, 2008, INT J PROD RES, V46, P1745, DOI 10.1080/00207540600972935
   Yuan ML, 2004, COMPUT ANIMAT VIRT W, V15, P425, DOI 10.1002/cav.46
   Zang X., 2009, 2009 INT C OPT INSTR
   Zauner J, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P237, DOI 10.1109/ISMAR.2003.1240707
   Zenati N, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), VOLS. 1- 3, P848
   Zhang KG, 2017, ASSEMBLY AUTOM, V37, P200, DOI 10.1108/AA-09-2016-120
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zhu J, 2013, INT J ADV MANUF TECH, V66, P1699, DOI 10.1007/s00170-012-4451-2
NR 73
TC 6
Z9 6
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 19
PY 2020
VL 1
AR 588217
DI 10.3389/frvir.2020.588217
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VS3
UT WOS:001023264700001
OA gold
DA 2024-07-18
ER

PT J
AU Ashtiani, O
   Guo, HJ
   Prabhakaran, B
AF Ashtiani, Omeed
   Guo, Hung-Jui
   Prabhakaran, Balakrishnan
TI Impact of motion cues, color, and luminance on depth perception in
   optical see-through AR displays
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; virtual reality; depth perception; motion cues; color
   perception
ID OBJECTS; PREDICTION; BRIGHTNESS; JUDGMENTS
AB Introduction: Augmented Reality (AR) systems are systems in which users view and interact with virtual objects overlaying the real world. AR systems are used across a variety of disciplines, i.e., games, medicine, and education to name a few. Optical See-Through (OST) AR displays allow users to perceive the real world directly by combining computer-generated imagery overlaying the real world. While perception of depth and visibility of objects is a widely studied field, we wanted to observe how color, luminance, and movement of an object interacted with each other as well as external luminance in OST AR devices. Little research has been done regarding the issues around the effect of virtual objects' parameters on depth perception, external lighting, and the effect of an object's mobility on this depth perception.Methods: We aim to perform an analysis of the effects of motion cues, color, and luminance on depth estimation of AR objects overlaying the real world with OST displays. We perform two experiments, differing in environmental lighting conditions (287 lux and 156 lux), and analyze the effects and differences on depth and speed perceptions.Results: We have found that while stationary objects follow previous research with regards to depth perception, motion and both object and environmental luminance play a factor in this perception.Discussion: These results will be significantly useful for developers to account for depth estimation issues that may arise in AR environments. Awareness of the different effects of speed and environmental illuminance on depth perception can be utilized when performing AR or MR applications where precision matters.
C1 [Ashtiani, Omeed; Guo, Hung-Jui; Prabhakaran, Balakrishnan] Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Dept Comp Sci, Richardson, TX 75083 USA.
C3 University of Texas System; University of Texas Dallas
RP Ashtiani, O (corresponding author), Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Dept Comp Sci, Richardson, TX 75083 USA.
EM omeed.ashtiani@utdallas.edu
FU DEVCOM Army Research Laboratory10.13039/100019923
FX No Statement Available
CR Adam Jones J., 2012, P ACM S APPL PERC, P11, DOI 10.1145/2338676.2338679
   Adams H, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P547, DOI [10.1109/VRW50115.2020.0-151, 10.1109/VRW50115.2020.00125]
   [Anonymous], 2022, Microsoft HoloLens 2
   Arefin MS, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P571, DOI [10.1109/VRW50115.2020.00137, 10.1109/VRW50115.2020.0-139]
   Ashley M. L., 1898, Vis. Res, V5, P595, DOI [DOI 10.1037/H0068517, 10.1037/h0068517]
   Bailey R.J., 2006, REAL EFFECT WARM COO
   Bayer B. E, 1975, Color imaging array, Patent No. [US05/555,477, 05555477]
   Bedell HE, 2003, VISION RES, V43, P2403, DOI 10.1016/S0042-6989(03)00436-X
   Berning M, 2014, INT SYM MIX AUGMENT, P93, DOI 10.1109/ISMAR.2014.6948413
   Cappello V, 2016, SCI REP-UK, V6, DOI 10.1038/s41598-016-0001-8
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   COULES J, 1955, J EXP PSYCHOL, V50, P19, DOI 10.1037/h0044343
   Cucchiara R, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P360, DOI 10.1109/ICIAP.2001.957036
   David H. A., 1988, The Method of Paired Comparisons
   DENGLER M, 1993, PERCEPT PSYCHOPHYS, V53, P150, DOI 10.3758/BF03211725
   Dey A, 2014, INT J HUM-COMPUT ST, V72, P704, DOI 10.1016/j.ijhcs.2014.04.001
   Dey A, 2012, INT SYM MIX AUGMENT, P187, DOI 10.1109/ISMAR.2012.6402556
   Diaz C, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P111, DOI 10.1109/ISMAR.2017.28
   Do TD, 2020, INT SYM MIX AUGMENT, P64, DOI 10.1109/ISMAR50242.2020.00026
   Dubuisson M.-P., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P471, DOI 10.1109/CVPR.1993.341088
   EKMAN G, 1959, J PSYCHOL, V47, P343, DOI 10.1080/00223980.1959.9916336
   Fujimura M., 2011, Proceedings of the 2011 International Conference on Complex, Intelligent and Software Intensive Systems (CISIS 2011), P639, DOI 10.1109/CISIS.2011.106
   Gabbard JL, 2013, P IEEE VIRT REAL ANN, P157, DOI 10.1109/VR.2013.6549410
   Gao B, 2022, SIGNAL PROCESS, V199, DOI 10.1016/j.sigpro.2022.108628
   Gomba L., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P1849, DOI DOI 10.1145/2851581.2892412
   Guibal CRC, 2004, PSYCHOL RES-PSYCH FO, V69, P30, DOI 10.1007/s00426-003-0167-0
   Johns EH, 1948, J PSYCHOL, V26, P25, DOI 10.1080/00223980.1948.9917393
   Kalia Megha, 2016, Medical Imaging and Augmented Reality. 7th International Conference, MIAR 2016. Proceedings: LNCS 9805, P221, DOI 10.1007/978-3-319-43775-0_20
   KJELLDAHL L, 1995, COMPUT GRAPH, V19, P199, DOI 10.1016/0097-8493(94)00143-M
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   Lee D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164394
   Li BR, 2021, IET INTELL TRANSP SY, V15, P235, DOI 10.1049/itr2.12017
   Li ZP, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545646
   Livingston MA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P55, DOI 10.1109/VR.2009.4810999
   Meng XF, 2010, MOVING OBJECTS MANAGEMENT: MODELS TECHNIQUES AND APPLICATIONS, P105
   Moller P, 1997, CURR BIOL, V7, P105, DOI 10.1016/S0960-9822(06)00054-6
   MORAN PAP, 1947, BIOMETRIKA, V34, P363, DOI 10.1093/biomet/34.3-4.363
   Morzy M, 2006, LECT NOTES COMPUT SC, V4263, P583
   OSHEA RP, 1994, VISION RES, V34, P1595, DOI 10.1016/0042-6989(94)90116-3
   Oueslati W, 2021, APPL ARTIF INTELL, V35, P2037, DOI 10.1080/08839514.2021.1998299
   PAYNE MC, 1964, PSYCHOL BULL, V61, P199, DOI 10.1037/h0046183
   Pillsbury WB, 1937, AM J PSYCHOL, V49, P126, DOI 10.2307/1416066
   Rosales CS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P237, DOI [10.1109/VR.2019.8798095, 10.1109/vr.2019.8798095]
   Ruofei Du, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P829, DOI 10.1145/3379337.3415881
   Self MW, 2005, CEREB CORTEX, V15, P1270, DOI 10.1093/cercor/bhi010
   Siegel Sidney, 1988, Nonparametric statistics for the behavioral sciences
   Singh G., 2009, Proceedings of the 6th symposium on applied perception in graphics and visualization (APGV '09), P127, DOI [10.1145/1620993.1621021, DOI 10.1145/1620993.1621021]
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   Swan JE, 2007, IEEE T VIS COMPUT GR, V13, P429, DOI 10.1109/TVCG.2007.1035
   TROSCIANKO T, 1991, VISION RES, V31, P1923, DOI 10.1016/0042-6989(91)90187-A
   Verghese A, 2013, J VISION, V13, DOI 10.1167/13.8.20
   Weiskopf D., 2002, A depth-cueing scheme based on linear transformations in tristimulus space
   Wu MQ, 2014, INT SYMP INTEGR CIRC, P372, DOI 10.1109/ISICIR.2014.7029538
NR 55
TC 0
Z9 0
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 6
PY 2023
VL 4
AR 1243956
DI 10.3389/frvir.2023.1243956
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CY4G7
UT WOS:001128773800001
OA gold
DA 2024-07-18
ER

PT J
AU Woo, OKL
   Lee, AM
AF Woo, Olive K. L.
   Lee, Antoinette M.
TI A perspective on potential psychological risks and solutions of using
   virtual reality in palliative care
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; palliative care; psychological risks; solutions;
   FLOW-VRT
ID SELF
AB Initial evidence suggests that virtual reality (VR) can effectively reduce palliative symptoms. While such findings shed a positive light on the ability of VR exposure to improve patients' physical and emotional symptoms, VR could have downsides with adverse effects. As most of the reported adverse effects are related to physical risks or technical challenges, there is a scarcity of reports on possible psychological risks posed by VR exposure in palliative care settings, an area with considerable concerns. This is an area that is likely to have a significant impact on the future of clinical practice and research on the use of VR in palliative care. Based on the clinical experience of a registered clinical psychologist who has delivered VR in a palliative care unit for 3 years, we put forward a perspective on the potential psychological complications of using VR in palliative care. Our clinical experiences show that exposure to a desirable virtual environment that is beneficial to patients might not always align with realistic expectations, and that should the use of VR be considered, special precautions are needed to minimize possible psychological harms. This perspective article further proposes three approaches aiming to minimize possible psychological hazards: incorporation of psychological assessment prior to VR administration, psychological interventions right after VR, and professional training of the VR facilitators. We hope that our personally witnessed concerns and perspectives can alert future VR facilitators to the potential psychological hazards of using VR for patients receiving palliative care and inspire future research to minimize psychological harms.
C1 [Woo, Olive K. L.; Lee, Antoinette M.] Univ Hong Kong, Dept Psychol, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Woo, OKL (corresponding author), Univ Hong Kong, Dept Psychol, Hong Kong, Peoples R China.
EM olivewookitling@gmail.com
RI kit, kit/JRW-3983-2023
OI Woo, Olive Kit Ling/0009-0001-5513-4140
CR Brungardt A, 2021, J PALLIAT MED, V24, P736, DOI 10.1089/jpm.2020.0403
   Carmont H, 2022, INT J PALLIAT NURS, V28, P132, DOI 10.12968/ijpn.2022.28.3.132
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   Deci EL, 2000, PSYCHOL INQ, V11, P227, DOI 10.1207/S15327965PLI1104_01
   Gershon J, 2004, J AM ACAD CHILD PSY, V43, P1243, DOI 10.1097/01.chi.0000135621.23145.05
   Johnson T, 2020, J PALLIAT MED, V23, P1233, DOI 10.1089/jpm.2019.0411
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kaplan S, 2001, ENVIRON BEHAV, V33, P480, DOI 10.1177/00139160121973106
   Klatte R, 2018, SYST REV-LONDON, V7, DOI 10.1186/s13643-018-0802-x
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Lazarus RS, 1984, Stress, appraisal, and coping
   Lee HW, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.753019
   Lloyd A, 2021, BMJ SUPPORT PALLIAT, V11, P344, DOI 10.1136/bmjspcare-2021-003173
   Lundin RM, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/43240
   McCreery MP, 2013, COMPUT HUM BEHAV, V29, P1635, DOI 10.1016/j.chb.2013.02.002
   McIntosh V, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.909984
   Niki K, 2019, J PALLIAT MED, V22, P702, DOI 10.1089/jpm.2018.0527
   Nwosu A. C., 2021, Virtual reality in specialist palliative care: A feasibility study to enable clinical practice adoption
   O'Philbin L, 2018, EXPERT REV NEUROTHER, V18, P715, DOI 10.1080/14737175.2018.1509709
   Oberdörfer S, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1200156
   Park K, 2019, INT PSYCHOGERIATR, V31, P1581, DOI 10.1017/S1041610218002168
   Park MJ, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00505
   Rizzo AS, 2021, TRANSL ISS PSYCH SCI, V7, P213, DOI 10.1037/tps0000316
   Rizzo A, 2010, ANN NY ACAD SCI, V1208, P114, DOI 10.1111/j.1749-6632.2010.05755.x
   van't Wout M, 2017, APPL PSYCHOPHYS BIOF, V42, P209, DOI 10.1007/s10484-017-9366-0
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weingarten K, 2020, J PALLIAT MED, V23, P147, DOI 10.1089/jpm.2019.0207
   Woo O. K. L., 2023, WHO 200 HLTH AG C 20
   Woo O. K. L., 2023, 15 AS PAC HOSP PALL
   Woo OKL, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1228781
   Wright C., 2019, BMJ Support. Palliat. Care, V9, pA71, DOI [10.1136/bmjspcare-2019-HUKNC.186, DOI 10.1136/BMJSPCARE-2019-HUKNC.186]
NR 31
TC 1
Z9 1
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 13
PY 2023
VL 4
AR 1256641
DI 10.3389/frvir.2023.1256641
PG 4
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA T0AI9
UT WOS:001074698300001
OA gold
DA 2024-07-18
ER

PT J
AU Kudry, P
   Cohen, M
AF Kudry, Peter
   Cohen, Michael
TI Development of a wearable force-feedback mechanism for free-range haptic
   immersive experience
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptic interface; wearable computer; virtual reality; human-computer
   interaction (HCI); ambulatory; force-feedback; perceptual overlay;
   tangible user interface (TUI)
AB The recent rise in popularity of head-mounted displays (HMDs) for immersion into virtual reality has resulted in demand for new ways to interact with virtual objects. Most solutions utilize generic controllers for interaction within virtual environments and provide limited haptic feedback. We describe the construction and implementation of an ambulatory (allowing walking) haptic feedback stylus with primary use in computer-aided design. Our stylus is a modified 3D Systems Touch force-feedback arm mounted on a wearable platform carried in front of a user. The wearable harness also holds a full-sized laptop, which drives the Meta Quest 2 HMD that is also worn by the user. This design provides six degrees-of-freedom without tethered limitations, while ensuring a high precision of force-feedback from virtual interaction. Our solution also provides an experience wherein a mobile user can explore different haptic feedback simulations and create, arrange, and deform general shapes.
C1 [Kudry, Peter; Cohen, Michael] Univ Aizu, Spatial Media Grp, Aizu Wakamatsu, Fukushima, Japan.
C3 University of Aizu
RP Kudry, P; Cohen, M (corresponding author), Univ Aizu, Spatial Media Grp, Aizu Wakamatsu, Fukushima, Japan.
EM peterkudry@protonmail.com; mcohen@u-aizu.ac.jp
RI Cohen, Michael/AAG-8852-2020
OI Cohen, Michael/0000-0001-8941-1575
FU Spatial Media Group University of Aizu
FX Creation of the wearable haptic device prototype was financially
   supported by the Spatial Media Group University of Aizu.
CR 3D System, 2022, HAPT DEV 3D SYST
   AREA: Augmented Reality for Enterprise Alliance, 2020, XR IND INS REP 2019
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Ben Lang, 2022, 13 MAJ NEW FEAT ADD
   Bernard M., 2020, 5 BIGGEST VIRTUAL AU
   Burdea GRIGORE, 1996, Force and touch feedback for virtual reality
   Choi I, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186505
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   Clark Estes A., 2021, FACEBOOKS NEW HAPTIC
   Controllers-Valve Index, 2022, CONTR VALV IND UPGR
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   Kang NK, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2018), P3, DOI 10.1145/3198910.3198911
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   Kreimeier J, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P122, DOI 10.1145/3197768.3201526
   Lawrence Michael A, 2016, CRAN
   MCAULEY E, 1989, RES Q EXERCISE SPORT, V60, P48, DOI 10.1080/02701367.1989.10607413
   Mixed Reality ToolKit, 2022, INTR MRTK UN MIX REA
   Natasha Mathur, 2018, WHATS NEW VR HAPT PA
   Oculus XR Plugin, 2020, OC XR PLUG OC XR PLU
   OpenHaptics, 2018, OPENHAPTICS TOOLK VE
   OpenHapticsa, 2018, OPENHAPTICS TOOLK V
   Polly Allcock P., 2021, BHAPTICS REVEALS TAC
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rosenberg L. B., 1997, FORCE FEEDBACK PROGR
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Scott Stein, 2022, HAPT GLOV QUEST 2 AR
   Shim Y. A., 2022, PROC CHI C HUMAN FAC, P1, DOI [10.1145/3491101.3519908, DOI 10.1145/3491101.3519908]
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Suzuki R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376523
   Tzemanaki A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00062
   VRgluv, 2021, VRGLUV FORC FEEDB HA
   Wang Dangxiao, 2019, Virtual Reality Intell. Hardware, V1, P136, DOI [DOI 10.3724/SP.J.2096-5796.2019.0008, 10.3724/sp.j.2096-5796.2019.0008]
   Whitmire E, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186515
NR 34
TC 3
Z9 3
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 14
PY 2022
VL 3
AR 824886
DI 10.3389/frvir.2022.824886
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YH7
UT WOS:001023332500001
OA gold
DA 2024-07-18
ER

PT J
AU Adhanom, I
   Halow, S
   Folmer, E
   MacNeilage, P
AF Adhanom, Isayas
   Halow, Savannah
   Folmer, Eelke
   MacNeilage, Paul
TI VR Sickness Adaptation With Ramped Optic Flow Transfers From Abstract To
   Realistic Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; VR sickness; simulator sickness; optic flow;
   cybersickness; adaptation
ID MOTION SICKNESS; VIRTUAL-REALITY; SIMULATOR SICKNESS; HEAD MOVEMENTS;
   HABITUATION; SYMPTOMS; IMMERSION; INDEX
AB VR sickness is a major concern for many users as VR continues its expansion towards widespread everyday use. VR sickness is thought to arise, at least in part, due to the user's intolerance of conflict between the visually simulated self-motion and actual physical movement. Many mitigation strategies involve consistently modifying the visual stimulus to reduce its impact on the user, but this individualized approach can have drawbacks in terms of complexity of implementation and non-uniformity of user experience. This study presents a novel alternative approach that involves training the user to better tolerate the adverse stimulus by tapping into natural adaptive perceptual mechanisms. In this study, we recruited users with limited VR experience that reported susceptibility to VR sickness. Baseline sickness was measured as participants navigated a rich and naturalistic visual environment. Then, on successive days, participants were exposed to optic flow in a more abstract visual environment, and strength of the optic flow was successively increased by increasing the visual contrast of the scene, because strength of optic flow and the resulting vection are thought to be major causes of VR sickness. Sickness measures decreased on successive days, indicating that adaptation was successful. On the final day, participants were again exposed to the rich and naturalistic visual environment, and the adaptation was maintained, demonstrating that it is possible for adaptation to transfer from more abstract to richer and more naturalistic environments. These results demonstrate that gradual adaptation to increasing optic flow strength in well-controlled, abstract environments allows users to gradually reduce their susceptibility to sickness, thereby increasing VR accessibility for those prone to sickness.
C1 [Adhanom, Isayas; Folmer, Eelke] Univ Nevada, Dept Comp Sci & Engn, Reno, NV 89512 USA.
   [Halow, Savannah; MacNeilage, Paul] Univ Nevada, Dept Psychol, Reno, NV USA.
C3 Nevada System of Higher Education (NSHE); University of Nevada Reno;
   Nevada System of Higher Education (NSHE); University of Nevada Reno
RP Adhanom, I (corresponding author), Univ Nevada, Dept Comp Sci & Engn, Reno, NV 89512 USA.
EM iadhanom@nevada.unr.edu
OI Halow, Savannah/0000-0002-1119-0570; Adhanom, Isayas/0000-0003-4798-7415
FU NSF [1911041]; NIH [P20 GM103650]; National Institute of General Medical
   Sciences [P20GM103650] Funding Source: NIH RePORTER
FX This work is supported by NSF grant 1911041 and NIH under Grant P20
   GM103650.
CR Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Al-Zayer M, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P263, DOI 10.1145/2982142.2982204
   [Anonymous], 1975, Motion sickness
   Arnold JT, 2019, DISPLAYS, V60, P18, DOI 10.1016/j.displa.2019.08.007
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Beadle SC, 2021, DISPLAYS, V66, DOI 10.1016/j.displa.2020.101985
   Braithwaite J.J., 2013, GUIDE ANALYSING ELEC, P1
   Bubka A, 2007, AVIAT SPACE ENVIR MD, V78, P383
   Budhiraja P, 2017, Arxiv, DOI arXiv:1710.02599
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Davis Simon., 2015, 11th Australasian Conference on Interactive Entertainment (IE 2015), P27, DOI DOI 10.17973/MMSJ.2015
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Domeyer JE, 2013, ACCIDENT ANAL PREV, V53, P127, DOI 10.1016/j.aap.2012.12.039
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Ebenholtz S.M., 1992, Teleoperators and Virtual Environments, V1, P302, DOI DOI 10.1162/PRES.1992.1.3.302
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fujii Y, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669519899108
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Gersak G, 2020, MULTIMED TOOLS APPL, V79, P14491, DOI 10.1007/s11042-018-6969-2
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Guo XR, 2021, EXP BRAIN RES, V239, P3507, DOI 10.1007/s00221-021-06214-5
   Hakkinen J., 2002, IEEE International Conference on Systems, Man and Cybernetics, V4, P147, DOI [DOI 10.1109/ICSMC.2002.1167964, 10.1109/ICSMC.2002.1167964]
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz Behrang, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P147, DOI 10.1007/978-3-319-39907-2_14
   Keshavarz B., 2014, HDB VIRTUAL ENV DESI, P648
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kingdon KellyS., 2001, PROCEEDINGS ofthe HUMANFACTORS AND ERGONOMICS SOCIETY 45th ANNUAL MEETING, P1906, DOI DOI 10.1177/154193120104502711
   Kinsella Amelia., 2018, ProQuest, P147
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   Lampton D.R., 2000, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V44, P530, DOI [DOI 10.1177/154193120004400512, 10.1177/154193120004400512]
   Magaki T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1072, DOI [10.1109/VR.2019.8797748, 10.1109/vr.2019.8797748]
   Monteiro Diego., 2021, 2021 IEEE Conference on Games (CoG), P1
   Mouloua M., 2005, Proceedings of the Human Factors and Ergonomics Society 49th Annual Meeting, P2206, DOI [10.1177/154193120504902519, DOI 10.1177/154193120504902519]
   Nelson N., 2015, NPR ALL TECH CONSIDE
   Newman MC, 2013, AVIAT SPACE ENVIR MD, V84, P104, DOI 10.3357/ASEM.3170.2013
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Peng YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376847
   Pöhlmann KMT, 2022, J COGN ENHANCE, V6, P3, DOI 10.1007/s41465-021-00215-6
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Regan EC, 1995, DISPLAYS, V16, P135, DOI 10.1016/0141-9382(96)81213-3
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Rine RM, 1999, PHYS THER, V79, P949, DOI 10.1093/ptj/79.10.949
   SAUVAN XM, 1993, PERCEPT PSYCHOPHYS, V53, P429, DOI 10.3758/BF03206786
   Seno T, 2017, I-PERCEPTION, V8, DOI [10.1177/2041669518774069, 10.1177/2041669517742176]
   Shi RK, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451255
   Sinitski EH, 2018, DISPLAYS, V52, P1, DOI 10.1016/j.displa.2018.01.001
   Smither JAA, 2008, INT J AVIAT PSYCHOL, V18, P326, DOI 10.1080/10508410802346921
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Takeda Noriaki, 2001, Journal of Medical Investigation, V48, P44
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   UnityTechnologies, 2021, WINDR CIT
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Yamamura Hiroo, 2020, UIST '20: 33rd Annual ACM Symposium on User Interface Software and Technology, P56, DOI 10.1145/3379350.3416184
   York Y, 2009, NAMRL0932 NAV AER ME, DOI DOI 10.12968/SECE.2009.4.1489
NR 68
TC 3
Z9 3
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 23
PY 2022
VL 3
AR 848001
DI 10.3389/frvir.2022.848001
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PQ8
UT WOS:001021734300001
PM 36873792
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Stallmann, L
   Dukes, D
   Tran, M
   de Gevigney, VD
   Rudrauf, D
   Samson, AC
AF Stallmann, Lina
   Dukes, Daniel
   Tran, Michel
   de Gevigney, Valentin Durand
   Rudrauf, David
   Samson, Andrea C.
TI Socially Supported by an Embodied Agent: The Development of a
   Virtual-Reality Paradigm to Study Social Emotion Regulation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; cyberball; virtual agent; social support; social
   exclusion; social emotion regulation
ID AUTISM; PROGRAM; SKILLS
AB Social emotion regulation, which can be understood as the intentional efforts by one person to regulate emotions of another person, is something we encounter and benefit from every day, and becomes especially important when a person is unable to handle an emotion or an emotional event by themselves. A paradigm that examines whether someone can perceive and benefit from regulatory efforts by another person, represented here by a virtual agent, would be highly relevant for experimental studies investigating social emotion regulation, as well as for interventions in the clinical and sub-clinical context. Virtual reality (VR) provides perhaps the ideal opportunity to test social interactions and difficulties with them, as it counters typical methodological problems of behavioral experiments, such as the trade-off between ecological validity and experimental control, as well as the difficulty of replicating social situations. The goal of the present methods paper is twofold: to provide a detailed description of the development of a novel paradigm consisting of two scenarios in VR designed to test the efficacy of social emotion regulation, and to present the anticipated results for the target populations of typically developing and autistic youth. Participants are presented with a virtual school environment and take part in two activities with a class of students and a teacher, all of whom are virtual agents. In both scenarios, participants experience a potentially stressful situation and are subsequently offered emotional support by a friendly student. Throughout the experiment, self-reports in the form of virtual smiley scales and psychophysiological measurements are collected as markers of the participants' emotional states. Pilot results will be discussed in line with anticipated outcomes, to indicate that the experiment will be able to show the efficacy of social support by a virtual agent and provide insight into social emotion regulation for different populations. The school environment and the character of the friendly student also have the potential to be adapted for follow-up experiments on additional aspects of social emotion regulation for a variety of contexts.
C1 [Stallmann, Lina; Dukes, Daniel; Tran, Michel; Samson, Andrea C.] Univ Fribourg, Inst Special Educ, Fribourg, Switzerland.
   [Stallmann, Lina; Dukes, Daniel; de Gevigney, Valentin Durand; Rudrauf, David; Samson, Andrea C.] Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
   [Tran, Michel; Samson, Andrea C.] Unidistance Suisse, Fac Psychol, Brig, Switzerland.
   [Rudrauf, David] Univ Geneva, Fac Psychol & Educ Sci, Geneva, Switzerland.
   [de Gevigney, Valentin Durand] Inst Rech Informat & Syst Aleatoires, Lannion, France.
C3 University of Fribourg; University of Geneva; University of Geneva
RP Samson, AC (corresponding author), Univ Fribourg, Inst Special Educ, Fribourg, Switzerland.; Samson, AC (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.; Samson, AC (corresponding author), Unidistance Suisse, Fac Psychol, Brig, Switzerland.
EM andrea.samson@unifr.ch
RI Samson, Andrea/HKW-3743-2023; Samson, Andrea C/K-3928-2017
OI Samson, Andrea C/0000-0001-6807-3132; Rudrauf,
   David/0000-0002-9621-1800; Dukes, Daniel/0000-0001-8360-849X; Stallmann,
   Lina/0000-0003-1549-9433
FU Swiss National Science Foundation (SNSF) [PP00P1_176,722]; Swiss Center
   for Affective Sciences; Research Fund of Unidistance Suisse
FX This project was supported by the Swiss National Science Foundation
   (SNSF; PP00P1_176,722 for AS), the Incentive Funding from the Swiss
   Center for Affective Sciences and the Research Fund of Unidistance
   Suisse.
CR Bernardo A, 2017, WORLD NEUROSURG, V106, P1015, DOI 10.1016/j.wneu.2017.06.140
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bombari D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00869
   Braithwaite J. J., 2013, PSYCHOPHYSIOLOGY, V1, P1017, DOI DOI 10.1111/J.1469-8986.2012.01384.X
   Bratec SM, 2020, SOC COGN AFFECT NEUR, V15, P561, DOI 10.1093/scan/nsaa068
   Burke SL, 2018, J AUTISM DEV DISORD, V48, P905, DOI 10.1007/s10803-017-3374-z
   Cai RY, 2019, AUTISM, V23, P737, DOI 10.1177/1362361318774558
   Chan SH, 2021, RELIG CHINESE SOC, V17, P1, DOI [10.1007/s10608-020-10185-2, 10.1163/9789004459373_002]
   Chevallier C, 2012, TRENDS COGN SCI, V16, P231, DOI 10.1016/j.tics.2012.02.007
   Coats AH, 2008, PSYCHOL AGING, V23, P39, DOI 10.1037/0882-7974.23.1.39
   Cohen S, 2004, AM PSYCHOL, V59, P676, DOI 10.1037/0003-066X.59.8.676
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Gross J. J., 1998, REV GEN PSYCHOL, P271, DOI [10.1037/1089-2680.2.3.271, DOI 10.1037/1089-2680.2.3.271]
   Gross J.J., 2015, HDB EMOTION REGULATI, DOI 10.5937/kultura1549229o
   Gross J. J., 2002, REGULATION EMOTION, V39, P281, DOI [10.1017/S0048577201393198, DOI 10.1017/S0048577201393198]
   Gulsrud AC, 2010, J AUTISM DEV DISORD, V40, P227, DOI 10.1007/s10803-009-0861-x
   Hallam GP, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00376
   Hofmann SG, 2016, COGNITIVE THER RES, V40, P341, DOI 10.1007/s10608-016-9756-2
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Iffland B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00956
   JBGarraza, 2021, TOON KIDS
   JBGarraza, 2021, TOON PEOPL
   Krämer NC, 2016, COMPUT EDUC, V99, P1, DOI 10.1016/j.compedu.2016.04.002
   Liddell BJ, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00999
   Lindsey EW, 2020, EMOTION, V20, P59, DOI 10.1037/emo0000666
   Lougheed JP, 2016, EMOTION, V16, P83, DOI 10.1037/emo0000105
   LYKKEN DT, 1966, PSYCHOL BULL, V66, P481, DOI 10.1037/h0023922
   Marroquín B, 2011, CLIN PSYCHOL REV, V31, P1276, DOI 10.1016/j.cpr.2011.09.005
   Martin RE, 2016, CURR OPIN BEHAV SCI, V10, P142, DOI 10.1016/j.cobeha.2016.06.006
   Mazefsky CA, 2014, CHILD ADOL PSYCH CL, V23, P15, DOI 10.1016/j.chc.2013.07.002
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Meuleman E. J. H., 2018, IEEE T AFFECTIVE COM, V12, P189, DOI [10.1109/TAFFC.2018.286473010.1007/978-90-368-2064-6_13, DOI 10.1109/TAFFC.2018.286473010.1007/978-90-368-2064-6_13]
   Niven K, 2009, EMOTION, V9, P498, DOI 10.1037/a0015962
   Nozaki Y, 2020, EMOTION, V20, P10, DOI 10.1037/emo0000636
   Nussinovitch U, 2011, ANN NONINVAS ELECTRO, V16, P117, DOI 10.1111/j.1542-474X.2011.00417.x
   Parsons S., 2011, European Journal of Special Needs Education, V26, P355, DOI DOI 10.1080/08856257.2011.593831
   Reeck C, 2016, TRENDS COGN SCI, V20, P47, DOI 10.1016/j.tics.2015.09.003
   Ring L, 2014, LECT NOTES ARTIF INT, V8637, P374, DOI 10.1007/978-3-319-09767-1_49
   Samson AC, 2015, J CHILD PSYCHOL PSYC, V56, P903, DOI 10.1111/jcpp.12370
   Samson AC, 2015, AUTISM RES, V8, P9, DOI 10.1002/aur.1387
   Samson AC, 2012, EMOTION, V12, P659, DOI 10.1037/a0027975
   Shang X., 2019, LECT NOTES NETWORS S, V69th ed, P482, DOI [10.1007/978-3-030-12388-8_34, DOI 10.1007/978-3-030-12388-8_34]
   Sheppes G, 2011, PSYCHOL SCI, V22, P1391, DOI 10.1177/0956797611418350
   Silkenbeumer J., 2016, J SELF REGULATION RE, V2, P17, DOI [DOI 10.11588/JOSAR.2016.2.34351, DOI 10.11588/JOSAT.2016.2]
   Stallmann L., 2021, SIMULATING SOC UNPUB
   Treichel N, 2022, HUMOR, V35, P113, DOI 10.1515/humor-2021-0038
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Volkaert B, 2020, COGNITIVE THER RES, V44, P678, DOI 10.1007/s10608-019-10073-4
   White SW, 2007, J AUTISM DEV DISORD, V37, P1858, DOI 10.1007/s10803-006-0320-x
   Williams KD, 2006, BEHAV RES METHODS, V38, P174, DOI 10.3758/BF03192765
   Zaki J, 2020, ANNU REV PSYCHOL, V71, P517, DOI 10.1146/annurev-psych-010419-050830
   Zaki J, 2013, EMOTION, V13, P803, DOI 10.1037/a0033839
NR 52
TC 1
Z9 1
U1 4
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 10
PY 2022
VL 3
AR 826241
DI 10.3389/frvir.2022.826241
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SR1
UT WOS:001021813400001
OA gold
DA 2024-07-18
ER

PT J
AU Sánchez-Margallo, JA
   de Miguel, CP
   Anzules, RF
   Sánchez-Margallo, FM
AF Sanchez-Margallo, Juan A.
   de Miguel, Carlos Plaza
   Anzules, Roberto Fernandez A.
   Sanchez-Margallo, Francisco M.
TI Application of Mixed Reality in Medical Training and Surgical Planning
   Focused on Minimally Invasive Surgery
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE mixed reality; medical training; surgical planning; minimally invasive
   surgery; laparoscopy
AB Introduction: Medical training is a long and demanding process, in which the first stages are usually based on two-dimensional, static, and unrealistic content. Conversely, advances in preoperative imaging have made it an essential part of any successful surgical procedure. However, access to this information often requires the support of an assistant and may compromise sterility in the surgical process. Herein, we present two solutions based on mixed reality that aim to improve both training and planning in minimally invasive surgery.
   Materials and Methods: Applications were developed for the use of the Microsoft HoloLens device. The urology training application provided access to a variety of anatomical and surgical training contents. Expert urological surgeons completed a questionnaire to evaluate its use. The surgical planning solution was used during laparoscopic renal tumorectomy in an experimental model and video-assisted right upper lobectomy in an adult patient. Surgeons reported their experience using this preoperative planning tool for surgery.
   Results: The solution developed for medical training was considered a useful tool for training in urological anatomy, facilitating the translation of this knowledge to clinical practice. Regarding the solution developed for surgical planning, it allowed surgeons to access the patient's clinical information in real-time, such as preoperative imaging studies, three-dimensional surgical planning models, or medical history, facilitating the surgical approach. The surgeon's view through the mixed reality device was shared with the rest of the surgical team.
   Conclusions: The mixed reality-based solution for medical training facilitates the transfer of knowledge into clinical practice. The preoperative planning tool for surgery provides real-time access to essential patient information without losing the sterility of the surgical field. However, further studies are needed to comprehensively validate its clinical application.
C1 [Sanchez-Margallo, Juan A.] Jesus Uson Minimally Invas Surg Ctr, Bioengn & Hlth Technol Unit, Caceres, Spain.
   [de Miguel, Carlos Plaza] Jesus Uson Minimally Invas Surg Ctr, TREMIRS Project, Caceres, Spain.
   [Anzules, Roberto Fernandez A.] Caceres Univ Hosp, Thorac Surg Unit, Caceres, Spain.
   [Sanchez-Margallo, Francisco M.] Jesus Uson Minimally Invas Surg Ctr, Sci Direct, Caceres, Spain.
RP Sánchez-Margallo, JA (corresponding author), Jesus Uson Minimally Invas Surg Ctr, Bioengn & Hlth Technol Unit, Caceres, Spain.
EM jasanchez@ccmijesususon.com
RI Sánchez Margallo, Francisco Miguel Miguel/I-5605-2019
OI Sánchez Margallo, Francisco Miguel Miguel/0000-0003-2138-988X; PLAZA DE
   MIGUEL, CARLOS/0009-0005-4757-4532
FU Spanish Ministry of Science and Innovation; European Regional
   Development Fund (FEDER) "A way to make Europe; Junta de Extremadura
   (Spain) [TA18023, GR18199, CPI-2019-33-1-TRE-14]
FX This work has been partially funded by the Spanish Ministry of Science
   and Innovation, the European Regional Development Fund (FEDER) "A way to
   make Europe" and the Junta de Extremadura (Spain) (TA18023, GR18199,
   CPI-2019-33-1-TRE-14).
CR Al Janabi HF, 2020, SURG ENDOSC, V34, P1143, DOI 10.1007/s00464-019-06862-3
   Al-Zu'bi S, 2017, PROCEDIA COMPUT SCI, V113, P531, DOI 10.1016/j.procs.2017.08.318
   Amparore D, 2022, MINERVA UROL NEPHROL, V74, P178, DOI 10.23736/S2724-6051.21.04131-X
   Cartucho J, 2020, INT J COMPUT ASS RAD, V15, P819, DOI 10.1007/s11548-020-02165-4
   Daly SC, 2014, J SURG EDUC, V71, P61, DOI 10.1016/j.jsurg.2013.06.017
   Deib G, 2018, J NEUROINTERV SURG, V10, P1187, DOI 10.1136/neurintsurg-2017-013649
   DeMasi Stephanie C, 2016, Edorium J Surg, V3, P24
   Forgione A, 2017, J RES MED SCI, V22, DOI 10.4103/jrms.JRMS_809_16
   Galati R, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8851964
   Goris J, 2014, PERSPECT MED EDUC, V3, P314, DOI 10.1007/s40037-013-0106-8
   Gregory TM, 2018, ACTA ORTHOP, V89, P480, DOI 10.1080/17453674.2018.1506974
   Heinrich F, 2019, HEALTHC TECHNOL LETT, V6, P165, DOI 10.1049/htl.2019.0062
   Hu HZ, 2019, INT J CLIN EXP MED, V12, P3107
   Hurson C, 2007, INJURY, V38, P1158, DOI 10.1016/j.injury.2007.05.020
   Jacobson S, 2009, MED TEACH, V31, P749, DOI 10.1080/01421590903124757
   Jayender J, 2018, LECT NOTES COMPUT SC, V11073, P72, DOI 10.1007/978-3-030-00937-3_9
   Kerr B, 1999, AM SURGEON, V65, P1101
   Lahanas V, 2015, SURG ENDOSC, V29, P2224, DOI 10.1007/s00464-014-3930-y
   Langridge B, 2018, J SURG EDUC, V75, P209, DOI 10.1016/j.jsurg.2017.06.033
   Lee SC, 2017, HEALTHC TECHNOL LETT, V4, P168, DOI 10.1049/htl.2017.0066
   Li G, 2020, CANCER MED-US, V9, P5480, DOI 10.1002/cam4.3189
   Liu H, 2020, J NEUROSURG-SPINE, V32, P542, DOI 10.3171/2019.10.SPINE19969
   Louis T, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P5, DOI 10.1145/3343055.3359710
   Maasthi MJ, 2020, INT CONF COMMUN SYST, DOI [10.1109/COMSNETS48256.2020.9027491, 10.1109/comsnets48256.2020.9027491]
   Perkins SL, 2020, ANN THORAC SURG, V110, P290, DOI 10.1016/j.athoracsur.2020.01.060
   Silva RRE, 2016, BRAZ J CARDIOVA SURG, V31, P449
   Rosenberg BH, 2005, J ENDOUROL, V19, P372, DOI 10.1089/end.2005.19.372
   Sadeghi AH, 2020, EUR HEART J-DIGIT HL, V1, P62, DOI 10.1093/ehjdh/ztaa011
   Sanchez-Margallo F. M., 2018, SURG ENDOSC, V32, pS655, DOI [10.1007/s00464-019-06728-8, DOI 10.1007/S00464-019-06728-8]
   Sanchez-Margallo F. M., 2015, COMPUTER ASSISTED SU, P43
   Sanchez-Margallo F. M., 2018, CIRUGIA ESPANOLA, V96, P1
   Sánchez-Margallo FM, 2021, J ENDOUROL, V35, P123, DOI 10.1089/end.2020.0284
   Sappenfield JW, 2018, ANESTH ANALG, V127, P83, DOI 10.1213/ANE.0000000000002572
   Scott DJ, 2008, J SURG RES, V147, P189, DOI 10.1016/j.jss.2008.02.014
   Smith RT, 2020, ADV EXP MED BIOL, V1260, P123, DOI 10.1007/978-3-030-47483-6_7
   Turini G, 2018, LECT NOTES COMPUT SC, V10851, P201, DOI 10.1007/978-3-319-95282-6_15
   Viglialoro RM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052338
   Williams MA, 2020, POSTGRAD MED J, V96, P537, DOI 10.1136/postgradmedj-2020-137600
   Zuckerman JD, 2009, AM J RHINOL ALLERGY, V23, P218, DOI 10.2500/ajra.2009.23.3297
NR 39
TC 18
Z9 19
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 28
PY 2021
VL 2
AR 692641
DI 10.3389/frvir.2021.692641
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PR0
UT WOS:001021734500001
OA gold
DA 2024-07-18
ER

PT J
AU Halbig, A
   Latoschik, ME
AF Halbig, Andreas
   Latoschik, Marc Erich
TI A Systematic Review of Physiological Measurements, Factors, Methods, and
   Applications in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; use cases; sesnsors; tools; biosignals;
   psychophyisology; HMD (Head-Mounted Display); systematic review
ID HEART-RATE-VARIABILITY; BODY OWNERSHIP; ELECTRODERMAL ACTIVITY; EMOTION
   RECOGNITION; AUGMENTED REALITY; EXPOSURE THERAPY; USER EXPERIENCE; BRAIN
   ACTIVITY; RATE FEEDBACK; STRESS
AB Measurements of physiological parameters provide an objective, often non-intrusive, and (at least semi-)automatic evaluation and utilization of user behavior. In addition, specific hardware devices of Virtual Reality (VR) often ship with built-in sensors, i.e. eye-tracking and movements sensors. Hence, the combination of physiological measurements and VR applications seems promising. Several approaches have investigated the applicability and benefits of this combination for various fields of applications. However, the range of possible application fields, coupled with potentially useful and beneficial physiological parameters, types of sensor, target variables and factors, and analysis approaches and techniques is manifold. This article provides a systematic overview and an extensive state-of-the-art review of the usage of physiological measurements in VR. We identified 1,119 works that make use of physiological measurements in VR. Within these, we identified 32 approaches that focus on the classification of characteristics of experience, common in VR applications. The first part of this review categorizes the 1,119 works by field of application, i.e. therapy, training, entertainment, and communication and interaction, as well as by the specific target factors and variables measured by the physiological parameters. An additional category summarizes general VR approaches applicable to all specific fields of application since they target typical VR qualities. In the second part of this review, we analyze the target factors and variables regarding the respective methods used for an automatic analysis and, potentially, classification. For example, we highlight which measurement setups have been proven to be sensitive enough to distinguish different levels of arousal, valence, anxiety, stress, or cognitive workload in the virtual realm. This work may prove useful for all researchers wanting to use physiological data in VR and who want to have a good overview of prior approaches taken, their benefits and potential drawbacks.
C1 [Halbig, Andreas; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
C3 University of Wurzburg
RP Halbig, A (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
EM andreas.halbig@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600
CR Ahmaniemi T, 2017, 2017 IEEE LIFE SCIENCES CONFERENCE (LSC), P206, DOI 10.1109/LSC.2017.8268179
   AL-Khalidi FQ, 2011, PEDIATR PULM, V46, P523, DOI 10.1002/ppul.21416
   Alchalabi B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P776, DOI [10.1109/VR.2019.8798263, 10.1109/vr.2019.8798263]
   Alian AA, 2014, BEST PRAC RES-CL ANA, V28, P395, DOI 10.1016/j.bpa.2014.08.006
   Almeida J, 2016, NEUROPSYCHOPHARMACOL, V41, pS460
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   [Anonymous], 2015, P 8 ACM SIGGRAPH C M
   Anusha AS, 2017, IEEE ENG MED BIO, P4549, DOI 10.1109/EMBC.2017.8037868
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   Athif M, 2020, IEEE ENG MED BIO, P3035, DOI 10.1109/EMBC44109.2020.9176022
   Balan O., 2019, 27 EUR C INF SYST IN
   Balan O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020496
   Barreda-Angeles M, 2020, VIRTUAL REAL-LONDON, V24, P289, DOI 10.1007/s10055-019-00400-1
   Barsade SG, 2009, RES ORGAN BEHAV, V29, P135, DOI 10.1016/j.riob.2009.06.008
   Bayan S, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P32, DOI 10.1109/COMAPP.2018.8460301
   Bekele E, 2016, P IEEE VIRT REAL ANN, P121, DOI 10.1109/VR.2016.7504695
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Betka S, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13564
   Bhoja R, 2020, SIMUL HEALTHC, V15, P39, DOI 10.1097/SIH.0000000000000402
   Bian YL, 2016, PERS UBIQUIT COMPUT, V20, P821, DOI 10.1007/s00779-016-0953-5
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Bilgin P, 2019, IEEE SYS MAN CYBERN, P2833, DOI 10.1109/SMC.2019.8914326
   Bin Suhaimi NS, 2020, IEEE 10TH SYMPOSIUM ON COMPUTER APPLICATIONS AND INDUSTRIAL ELECTRONICS (ISCAIE 2020), P12, DOI 10.1109/ISCAIE47305.2020.9108821
   Blanco JA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030499
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bozkir E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1834, DOI [10.1109/VR.2019.8797758, 10.1109/vr.2019.8797758]
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Braithwaite J. J., 2013, PSYCHOPHYSIOLOGY, V1, P1017, DOI DOI 10.1111/J.1469-8986.2012.01384.X
   Breuninger C, 2017, COGNITIVE THER RES, V41, P193, DOI 10.1007/s10608-016-9814-9
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Bruder LR, 2021, bioRxiv, DOI [10.1101/2020.08.07.237826, 10.1101/2020.08.07.237826, DOI 10.1101/2020.08.07.237826]
   Cairns P, 2008, RESEARCH METHODS FOR HUMAN-COMPUTER INTERACTION, P1
   Calabrò RS, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0268-4
   Campbell J, 2019, PROCEEDINGS OF THE 31ST EUROPEAN CONFERENCE ON COGNITIVE ERGONOMICS: DESIGN FOR COGNITION (ECCE 2019), P177, DOI 10.1145/3335082.3335087
   Carreiras C., 2015, BioSPPy: Biosignal processing in Python
   Castelvecchi D, 2016, NATURE, V533, P153, DOI 10.1038/533153a
   Cebeci B, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1893
   Chang TP, 2019, SIMUL HEALTHC, V14, P104, DOI 10.1097/SIH.0000000000000356
   Charles RL, 2019, APPL ERGON, V74, P221, DOI 10.1016/j.apergo.2018.08.028
   Cho D, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102435
   Christensen JC, 2012, NEUROIMAGE, V59, P57, DOI 10.1016/j.neuroimage.2011.07.091
   Clifford R. M. S., 2018, 2018 10 INT C VIRT W, DOI DOI 10.1109/VS-GAMES.2018.8493423
   Clifford RMS, 2021, VISUAL COMPUT, V37, P63, DOI 10.1007/s00371-020-01816-6
   Collins J, 2019, INT SYM MIX AUGMENT, P351, DOI 10.1109/ISMAR.2019.00033
   Corbetta P., 2003, SOCIAL RES THEORY ME
   Currie J, 2019, INT J COMPUT ASS RAD, V14, P645, DOI 10.1007/s11548-019-01918-0
   Czub M, 2019, CYBERPSYCH BEH SOC N, V22, P494, DOI 10.1089/cyber.2018.0700
   da Costa RT, 2018, REV BRAS PSIQUIATR, V40, P192
   Dash A., 2019, 2019 IEEE EMBS INT C, P1
   De Asis Karlo Miguel R., 2020, ICFET 2020: Proceedings of the 2020 6th International Conference on Frontiers of Educational Technologies, P155, DOI 10.1145/3404709.3404745
   De Luca C., 2006, Encyclopedia of Medical Devices and Instrumentation
   Debska M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16193673
   Delahaye Marcel, 2015, BMC Psychol, V3, P22, DOI 10.1186/s40359-015-0080-5
   Delvigne V., 2020, 2020 IEEE 8 INT C SE, P1
   Deniaud C, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P739, DOI 10.1109/SAI.2015.7237225
   Desnoyers-Stewart J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312845
   Detez L, 2019, J GAMBL STUD, V35, P929, DOI 10.1007/s10899-018-09822-z
   Dey A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P745, DOI [10.1109/VRW50115.2020.00-52, 10.1109/VRW50115.2020.00223]
   Dey A, 2019, INT SYM MIX AUGMENT, P248, DOI 10.1109/ISMAR.2019.00022
   Dey A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P220, DOI [10.1109/vr.2019.8797840, 10.1109/VR.2019.8797840]
   Dey A, 2018, INT SYM MIX AUGMENT, P165, DOI 10.1109/ISMAR.2018.00052
   Di Loreto C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P281, DOI 10.1109/VR.2018.8448292
   Ding J, 2019, J INT MED RES, V47, P4380, DOI 10.1177/0300060519857862
   Ding N, 2018, TELEMAT INFORM, V35, P1572, DOI 10.1016/j.tele.2018.04.003
   Ding XF, 2020, BRAIN BEHAV, V10, DOI 10.1002/brb3.1814
   Ding Y, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206750
   Döllinger N, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.644683
   Drolet M, 2020, IEEE INT CONF ROBOT, P9072, DOI [10.1109/ICRA40945.2020.9197536, 10.1109/icra40945.2020.9197536]
   Dunning David, 2004, Psychol Sci Public Interest, V5, P69, DOI 10.1111/j.1529-1006.2004.00018.x
   Ehrsson HH, 2007, P NATL ACAD SCI USA, V104, P9828, DOI 10.1073/pnas.0610011104
   Faller J, 2019, P NATL ACAD SCI USA, V116, P6482, DOI 10.1073/pnas.1817207116
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Felnhofer A, 2014, CYBERPSYCH BEH SOC N, V17, P310, DOI 10.1089/cyber.2013.0472
   Fernandez J. A., 2019, ACM SIGGRAPH 2019 VI
   Fominykh M., 2018, Journal of Interactive Learning Research, V29, P51
   Freire RC, 2020, J AFFECT DISORDERS, V264, P498, DOI 10.1016/j.jad.2019.11.081
   GAILLARD AWK, 1993, ERGONOMICS, V36, P991, DOI 10.1080/00140139308967972
   Gamito P, 2014, CYBERPSYCH BEH SOC N, V17, P556, DOI 10.1089/cyber.2013.0329
   Gao JQ, 2019, MED SCI MONITOR, V25, P3127, DOI 10.12659/MSM.914635
   García-Rodríguez O, 2013, ADDICT BEHAV, V38, P2551, DOI 10.1016/j.addbeh.2013.05.007
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Gersak G, 2020, MULTIMED TOOLS APPL, V79, P14491, DOI 10.1007/s11042-018-6969-2
   Gonzalez D. S., 2016, 2016 21 S SIGNAL PRO, P1, DOI DOI 10.1109/STSIVA.2016.7743323
   González-Franco M, 2014, EXP BRAIN RES, V232, P875, DOI 10.1007/s00221-013-3800-1
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   Granato M, 2020, MULTIMED TOOLS APPL, V79, P33657, DOI 10.1007/s11042-019-08585-y
   Greinacher R., 2020, 2020 12 INT C QUALIT, P1
   Grimm P., 2010, Wiley International encyclopedia of marketing, DOI 10.1002/9781444316568.wiem02057
   Grübel J, 2017, LECT NOTES ARTIF INT, V10523, P159, DOI 10.1007/978-3-319-68189-4_10
   Guna J, 2020, MOBILE NETW APPL, V25, P1436, DOI 10.1007/s11036-019-01373-w
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.000-5, 10.1109/VR46266.2020.1581313729558]
   Gupta K, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364276
   Haller JC, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290752
   Ham J, 2017, IEEE ENG MED BIO, P3989, DOI 10.1109/EMBC.2017.8037730
   HANCOCK PA, 1985, AVIAT SPACE ENVIR MD, V56, P1110
   HART S G, 1988, P139
   Herborn KA, 2015, PHYSIOL BEHAV, V152, P225, DOI 10.1016/j.physbeh.2015.09.032
   Herumurti D, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, ARTIFICIAL INTELLIGENCE, AND COMMUNICATIONS TECHNOLOGY (IAICT), P139, DOI [10.1109/ICIAICT.2019.8784846, 10.1109/iciaict.2019.8784846]
   Hildebrandt LK, 2016, PSYCHOPHYSIOLOGY, V53, P880, DOI 10.1111/psyp.12632
   Hofmann SM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P128, DOI 10.1109/AIVR.2018.00026
   Hogervorst MA, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00322
   Houzangbe S., 2018, P 13 INT C FOUND DIG, P1
   Houzangbe S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P982, DOI [10.1109/vr.2019.8797759, 10.1109/VR.2019.8797759]
   Hoxhallari E, 2019, PLAST RECONSTR SURG, V144, P408, DOI 10.1097/PRS.0000000000005831
   Hu F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SAFETY FOR ROBOTICS (ISR), P238, DOI 10.1109/IISR.2018.8535774
   Ishaque S, 2020, IEEE ENG MED BIO, P867, DOI 10.1109/EMBC44109.2020.9176110
   Janig W., 2008, Integrative action of the autonomic nervous system neurobiology of homeostasis
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/VR.2019.8798334, 10.1109/vr.2019.8798334]
   John B, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3322868
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Kakkos I, 2019, IEEE T NEUR SYS REH, V27, P1704, DOI 10.1109/TNSRE.2019.2930082
   Kaminskas V, 2019, INF TECHNOL CONTROL, V48, P250, DOI 10.5755/j01.itc.48.2.21667
   Kataoka H, 1998, P ANN INT IEEE EMBS, V20, P940, DOI 10.1109/IEMBS.1998.745598
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kerous B, 2020, J AMB INTEL HUM COMP, V11, P6033, DOI 10.1007/s12652-020-01858-7
   Khokhar Adil, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P1018, DOI 10.1109/VR.2019.8797896
   Kim HG, 2018, PSYCHIAT INVEST, V15, P235, DOI 10.30773/pi.2017.08.17
   Kirsch K., 2019, P MENSCH COMP 2019 M, P777
   Kishimoto T, 2019, BEHAV COGN PSYCHOTH, V47, P726, DOI 10.1017/S1352465819000377
   Kivelä O, 2019, INT CONF GAMES VIRTU, P250, DOI 10.1109/vs-games.2019.8864544
   Kocur M., 2020, ACM S EYE TRACK RES, P1
   Kojic T, 2019, IEEE INT SYM MULTIM, P307, DOI 10.1109/ISM46123.2019.00068
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kothgassner OD, 2019, J BEHAV THER EXP PSY, V63, P57, DOI 10.1016/j.jbtep.2018.11.003
   Kothgassner OD, 2016, COMPUT HUM BEHAV, V62, P124, DOI 10.1016/j.chb.2016.03.081
   Koticha Paloni, 2019, Int J Clin Pediatr Dent, V12, P297, DOI 10.5005/jp-journals-10005-1640
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kuriakose S., 2013, STEP VIRTUAL REALITY, P1
   Kurniawan H, 2013, COMP MED SY, P209, DOI 10.1109/CBMS.2013.6627790
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lai CQ, 2018, AIP CONF PROC, V2016, DOI 10.1063/1.5055472
   Laight D., 2013, Nurse Prescribing, V11, P448, DOI DOI 10.12968/NPRE.2013.11.9.448
   Latoschik M. E., 2021, ARXIV
   Lee SH, 2015, J PHYS THER SCI, V27, P2285, DOI 10.1589/jpts.27.2285
   Levy F, 2016, J TELEMED TELECARE, V22, P215, DOI 10.1177/1357633X15598243
   Li YY, 2017, INT CONF ENTERP SYST, P132, DOI 10.1109/ES.2017.28
   Lindal PallJ., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games), P1, DOI DOI 10.1109/VS-GAMES.2018.8493414
   Liszio S, 2018, ANN REV CYBERTHERAPY, V16, P87
   Liu YT, 2014, IEEE IJCNN, P4109, DOI 10.1109/IJCNN.2014.6889736
   Lotte F, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aab2f2
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Luck M, 2000, APPL ARTIF INTELL, V14, P3, DOI 10.1080/088395100117142
   Lugrin J.-L., 2019, 2019 CHI C HUMAN FAC, P1
   Lugrin J.-L., 2019, P 25 ACM C VIRTUAL R
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Ma K, 2015, CONSCIOUS COGN, V36, P277, DOI 10.1016/j.concog.2015.07.008
   Ma LL, 2018, 2018 3RD IEEE INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (IEEE ICARM), P497
   Macauda G, 2015, EUR J NEUROSCI, V41, P810, DOI 10.1111/ejn.12809
   Malta LS, 2021, VIRTUAL REAL-LONDON, V25, P293, DOI 10.1007/s10055-020-00455-5
   Maples-Keller JL, 2019, J ANXIETY DISORD, V68, DOI 10.1016/j.janxdis.2019.102147
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Vanderlei LCM, 2009, REV BRAS CIR CARDIOV, V24, P205, DOI 10.1590/S0102-76382009000200018
   Martens KAE, 2016, MOV DISORD CLIN PRAC, V3, P389, DOI 10.1002/mdc3.12298
   Martens KAE, 2015, EUR J NEUROSCI, V42, P2028, DOI 10.1111/ejn.12928
   Masaoka Y, 1997, INT J PSYCHOPHYSIOL, V27, P153, DOI 10.1016/S0167-8760(97)00052-4
   Mavridou I., 2018, 12 INT C DIS VIRT RE
   Mavridou I., P WORKSH HUM HAB HLT
   McDonough DJ, 2020, GAMES HEALTH J, V9, P290, DOI 10.1089/g4h.2019.0196
   Melillo P, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-96
   Melnyk R, 2021, J ENDOUROL, V35, P376, DOI 10.1089/end.2020.0445
   Mertens G, 2019, COMPUT HUM BEHAV, V91, P192, DOI 10.1016/j.chb.2018.10.006
   Mishra N, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281611
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Moon SE, 2017, IEEE T MULTIMEDIA, V19, P340, DOI 10.1109/TMM.2016.2614880
   Morii M., 2017, BEHAVIORMETRIKA, V44, P575, DOI [DOI 10.1007/S41237-017-0036-6, 10.1007/s41237-017-0036-6]
   Mosquera C, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'19), DOI 10.1145/3337722.3341821
   Mostajeran F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P303, DOI [10.1109/VR46266.2020.1581528155120, 10.1109/VR46266.2020.00-54]
   Müller E, 2017, PSYCHOPHYSIOLOGY, V54, pS2, DOI 10.1111/psyp.12921
   Munoz J. E., 2016, 2016 IEEE 18 INT C E, P1
   Murray EG, 2016, PSYCHOL SPORT EXERC, V22, P328, DOI 10.1016/j.psychsport.2015.09.007
   Ong Triton L, 2020, Crit Care Explor, V2, pe0122, DOI 10.1097/CCE.0000000000000122
   Orlosky J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P66, DOI 10.1109/AIVR46125.2019.00019
   Park Seung Kyu, 2016, J Phys Ther Sci, V28, P2055, DOI 10.1589/jpts.28.2055
   Patel J, 2017, DISABIL REHABIL, V39, P1515, DOI 10.1080/09638288.2016.1226419
   Patel J, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P215, DOI 10.1109/ICVR.2015.7358583
   Patibanda R, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P19, DOI 10.1145/3116595.3116621
   Plouzeau J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P661, DOI 10.1109/VR.2018.8446192
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Prachyabrued M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P671, DOI [10.1109/VR.2019.8797705, 10.1109/vr.2019.8797705]
   Preuss N, 2019, J EXP PSYCHOL HUMAN, V45, P209, DOI 10.1037/xhp0000597
   Pullman SL, 2000, NEUROLOGY, V55, P171, DOI 10.1212/WNL.55.2.171
   Quintero L, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P126, DOI 10.1109/AIVR46125.2019.00027
   Rahman Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P868, DOI [10.1109/VR46266.2020.1581300202881, 10.1109/VR46266.2020.00014]
   Ramdhani N., 2019, 2019 5 INT C SCI TEC, P1
   Rangelova Stanislava, 2019, INT C HUMAN COMPUTER, P601
   Rao Dhanu G, 2019, Int J Clin Pediatr Dent, V12, P510, DOI 10.5005/jp-journals-10005-1694
   Ravaja N, 2018, IEEE T AFFECT COMPUT, V9, P285, DOI 10.1109/TAFFC.2016.2601101
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Redline C. D., 2003, WORKSH IT NONR DAT Q
   Richard MO, 2009, J BUS RES, V62, P987, DOI 10.1016/j.jbusres.2008.10.016
   Robertson A, 2017, IEEE INT CONF SERIOU
   Robins R.W., 2007, HDB RES METHODS PERS
   Robitaille P, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317022
   Roth D., 2017, C HUM FACTORS COMPUT, VPart F1276, P2875, DOI DOI 10.1145/3027063.3053272
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Rowley J, 2014, MANAG RES REV, V37, P308, DOI 10.1108/MRR-02-2013-0027
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Saha Deba Pratim, 2018, 2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P609, DOI 10.1109/PERCOMW.2018.8480245
   Sakamoto K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P422, DOI [10.1109/VRW50115.2020.0-186, 10.1109/VRW50115.2020.00090]
   Salkevicius J, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8091039
   Salminen M, 2022, IEEE T AFFECT COMPUT, V13, P746, DOI 10.1109/TAFFC.2019.2958657
   Samson AC, 2016, COGNITION EMOTION, V30, P827, DOI 10.1080/02699931.2015.1031089
   Schroeder Ralph, 2010, Being There Together: Social interaction in shared virtual environments
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Shiban Y, 2017, BMC PSYCHIATRY, V17, DOI 10.1186/s12888-016-1181-2
   Shiban Y, 2016, INT J PSYCHOPHYSIOL, V110, P47, DOI 10.1016/j.ijpsycho.2016.10.008
   Shiban Y, 2016, J BEHAV THER EXP PSY, V51, P19, DOI 10.1016/j.jbtep.2015.11.002
   Shumailov I, 2017, INT CONF AFFECT, P164, DOI 10.1109/ACII.2017.8273595
   Simoes M, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/games.8428
   Singh H., 2012, Int. J. Sci. Res. Publ, V2, P1, DOI DOI 10.1371/J0URNAL.P0NE.0029319
   Siravenha Ana C. Q., 2019, 2019 8th Brazilian Conference on Intelligent Systems (BRACIS). Proceedings, P407, DOI 10.1109/BRACIS.2019.00078
   Sirois S, 2014, WIRES COGN SCI, V5, P679, DOI 10.1002/wcs.1323
   Skola F, 2016, VISUAL COMPUT, V32, P761, DOI 10.1007/s00371-016-1246-8
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Solanki D, 2020, IEEE ACCESS, V8, P88830, DOI 10.1109/ACCESS.2020.2994081
   Soyka F., 2016, P ACM S APPL PERC PR, P85, DOI [10.1145/2931002.2931017., DOI 10.1145/2931002.2931017, 10.1145/2931002.2931017]
   Spangler DP, 2021, IEEE T AFFECT COMPUT, V12, P648, DOI 10.1109/TAFFC.2020.2995769
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Streck A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P245, DOI 10.1109/AIVR46125.2019.00054
   Swidrak J, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P49, DOI 10.1145/3308532.3329467
   Syrjämäki AH, 2020, COMPUT HUM BEHAV, V112, DOI 10.1016/j.chb.2020.106454
   Szczurowski K., 2018, P 2017 23 INT C VIRT, DOI DOI 10.1109/VSMM.2017.8346261
   Tartarisco G, 2015, INTERACT COMPUT, V27, P521, DOI 10.1093/iwc/iwv010
   Tarvainen MP, 2014, COMPUT METH PROG BIO, V113, P210, DOI 10.1016/j.cmpb.2013.07.024
   Taylor S, 2015, IEEE ENG MED BIO, P1934, DOI 10.1109/EMBC.2015.7318762
   TEO J, 2018, 2018 INT C SMART COM, P1, DOI DOI 10.1109/ICSCEE.2018.8538382
   Thompson-Lake DGY, 2015, NICOTINE TOB RES, V17, P796, DOI 10.1093/ntr/ntu245
   Tieri G, 2017, EUR J NEUROSCI, V45, P1141, DOI 10.1111/ejn.13545
   Topalovic U, 2020, NEURON, V108, P322, DOI 10.1016/j.neuron.2020.08.021
   Tremmel C., 2020, THESIS DOMINION U NO
   Tremmel C, 2019, IEEE SYS MAN CYBERN, P2806, DOI 10.1109/SMC.2019.8914264
   Tremmel C, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00401
   Tsai CF, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/6357351
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Van Gent P., 2018, P 6 HUMANIST C HAG N, P173
   Vince John., 2004, INTRO VIRTUAL REALIT
   Vinkers CH, 2013, STRESS, V16, P520, DOI 10.3109/10253890.2013.807243
   Vogt J, 2006, J PSYCHOPHYSIOL, V20, P297, DOI 10.1027/0269-8803.20.4.297
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00210
   Wagner Johannes, 2013, P 21 ACM INT C MULT, P831, DOI [10.1145/2502081.2502223, DOI 10.1145/2502081.2502223]
   Wang QX, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P110, DOI 10.1109/ITME.2018.00034
   Wang XB, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16183263
   Wang Y, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0731-5
   Wang YG, 2019, J PSYCHIATR RES, V116, P88, DOI 10.1016/j.jpsychires.2019.06.007
   Wang YG, 2018, PSYCHIAT RES, V270, P382, DOI 10.1016/j.psychres.2018.10.009
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weibel RP, 2018, JOVE-J VIS EXP, DOI 10.3791/58318
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wong CL, 2021, CANCER NURS, V44, P435, DOI 10.1097/NCC.0000000000000844
   Xie B, 2018, IEEE T VIS COMPUT GR, V24, P1661, DOI 10.1109/TVCG.2018.2793618
   Xu Tianyuan, 2019, 2019 IEEE MTT S INT, V1, P1
   Yang S., 2019, 2019 16 ANN IEEE INT, P1
   Yeh SC, 2018, IEEE T NEUR SYS REH, V26, P1345, DOI 10.1109/TNSRE.2018.2844083
   Yoo S, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P307, DOI 10.1145/3267305.3267649
   Yoshimura Andrew, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P1255, DOI 10.1109/VR.2019.8798327
   Yu CP, 2018, URBAN FOR URBAN GREE, V35, P106, DOI 10.1016/j.ufug.2018.08.013
   Zeng N, 2017, CYBERPSYCH BEH SOC N, V20, P453, DOI 10.1089/cyber.2017.0042
   Zhang SQ, 2017, IEEE ENG MED BIO, P3957, DOI 10.1109/EMBC.2017.8037722
   Zhang WZ, 2017, I C VIRTUAL REALITY, P311, DOI 10.1109/ICVRV.2017.00072
   Zheng LJ, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00322-9
   Zhu L., 2019, 2019 IEEE MTT S INT, P1
   Ziegelman L., 2019, 2019 IEEE RAS 19 INT, P1
   Zimmer P, 2019, PSYCHONEUROENDOCRINO, V101, P186, DOI 10.1016/j.psyneuen.2018.11.010
NR 272
TC 31
Z9 31
U1 6
U2 19
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 14
PY 2021
VL 2
AR 694567
DI 10.3389/frvir.2021.694567
PG 32
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AN4
UT WOS:001019292200001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Jing, ALS
   May, K
   Lee, G
   Billinghurst, M
AF Jing, Allison
   May, Kieran
   Lee, Gun
   Billinghurst, Mark
TI Eye See What You See: Exploring How Bi-Directional Augmented Reality
   Gaze Visualisation Influences Co-Located Symmetric Collaboration
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality collaboration; gaze visualisation; human-computer
   interaction; CSCW; design and evaluation methods
ID ATTENTION; COGNITION; TRACKING
AB Gaze is one of the predominant communication cues and can provide valuable implicit information such as intention or focus when performing collaborative tasks. However, little research has been done on how virtual gaze cues combining spatial and temporal characteristics impact real-life physical tasks during face to face collaboration. In this study, we explore the effect of showing joint gaze interaction in an Augmented Reality (AR) interface by evaluating three bi-directional collaborative (BDC) gaze visualisations with three levels of gaze behaviours. Using three independent tasks, we found that all bi-directional collaborative BDC visualisations are rated significantly better at representing joint attention and user intention compared to a non-collaborative (NC) condition, and hence are considered more engaging. The Laser Eye condition, spatially embodied with gaze direction, is perceived significantly more effective as it encourages mutual gaze awareness with a relatively low mental effort in a less constrained workspace. In addition, by offering additional virtual representation that compensates for verbal descriptions and hand pointing, BDC gaze visualisations can encourage more conscious use of gaze cues coupled with deictic references during co-located symmetric collaboration. We provide a summary of the lessons learned, limitations of the study, and directions for future research.
C1 [Jing, Allison; May, Kieran; Lee, Gun; Billinghurst, Mark] Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Empath Comp Lab, STEM, Mawson Lakes, SA, Australia.
C3 University of South Australia
RP Jing, ALS (corresponding author), Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Empath Comp Lab, STEM, Mawson Lakes, SA, Australia.
EM allison.jing@mymail.unisa.edu.au
RI Billinghurst, Mark/AAJ-4236-2020; Lee, Gun/AAS-9903-2021
OI Billinghurst, Mark/0000-0003-4172-6759; Lee, Gun/0000-0002-1644-6934;
   Jing, Allison/0000-0002-0418-3217
CR Argyle M., 1976, Gaze and Mutual Gaze
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   BaronCohen S, 1997, VIS COGN, V4, P311, DOI 10.1080/713756761
   Brennan SE, 2008, COGNITION, V106, P1465, DOI 10.1016/j.cognition.2007.05.012
   D'Angelo S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173923
   D'Angelo S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6245, DOI 10.1145/3025453.3025573
   D'Angelo S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2492, DOI 10.1145/2858036.2858499
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Erickson A, 2020, J MULTIMODAL USER IN, V14, P353, DOI 10.1007/s12193-020-00330-2
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Hartson H. R., 1989, Computing Surveys, V21, P5, DOI 10.1145/62029.62031
   Higuch K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5180, DOI 10.1145/2858036.2858438
   Jing A, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365725
   Kim S., 2020, 9 INT C SMART MED AP, P1
   Kim S, 2020, IEEE ACCESS, V8, P224145, DOI 10.1109/ACCESS.2020.3043783
   Kraut RE, 2003, HUM-COMPUT INTERACT, V18, P13, DOI 10.1207/S15327051HCI1812_2
   Kuhn G, 2009, VIS COGN, V17, P925, DOI 10.1080/13506280902826775
   Lee G.A., 2017, ICAT EGVE 2017 INT C, P197, DOI DOI 10.2312/EGVE.20171359
   Lee Y, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P342, DOI 10.1109/ISMAR-Adjunct.2016.0112
   Li J, 2016, PROCEEDINGS OF THE 19TH ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING COMPANION, P325, DOI 10.1145/2818052.2869097
   Li Y, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357583
   Neider MB, 2010, PSYCHON B REV, V17, P718, DOI 10.3758/PBR.17.5.718
   Pan Y, 2016, INT J HUM-COMPUT ST, V86, P138, DOI 10.1016/j.ijhcs.2015.10.004
   Parisay M, 2020, C HUM SYST INTERACT, P74, DOI [10.1109/hsi49210.2020.9142677, 10.1109/HSI49210.2020.9142677]
   Piumsomboon T, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P218, DOI 10.1109/ISMAR-Adjunct.2017.72
   Rahman Y., 2020, EXPLORING EYE GAZE V, P868, DOI [10.1109/vr46266.2020.00009, DOI 10.1109/VR46266.2020.00009]
   Salvucci DD, 2008, PSYCHOL REV, V115, P101, DOI 10.1037/0033-295X.115.1.101
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Spakov O., 2004, P 3 NORDIC C HUMANCO, P203, DOI [DOI 10.1145/1028014.1028045DOI.ORG/10.1145/1028014.1028045, DOI 10.1145/1028014.1028045]
   Tang A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4501, DOI 10.1145/3025453.3025519
   VICKERS JN, 1995, STUD VIS INFORM PROC, V6, P527
   Wang P, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1219, DOI [10.1109/VR.2019.8798024, 10.1109/vr.2019.8798024]
   Wang Z, 2012, COMPUT HUM BEHAV, V28, P968, DOI 10.1016/j.chb.2011.12.018
   Whittaker S., 1997, ROLE VISION FACE FAC
   Yang H., 2002, P 4 INT C COLLABORAT, P135
   Zhang YX, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P559, DOI 10.1145/2632048.2636071
   Zhang YX, 2017, PERS UBIQUIT COMPUT, V21, P173, DOI 10.1007/s00779-016-0969-x
   Zhang YX, 2015, PERS UBIQUIT COMPUT, V19, P967, DOI 10.1007/s00779-015-0866-8
NR 38
TC 18
Z9 18
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 14
PY 2021
VL 2
AR 697367
DI 10.3389/frvir.2021.697367
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PH6
UT WOS:001021725100001
OA gold
DA 2024-07-18
ER

PT J
AU Croucher, C
   Powell, W
   Dicks, M
   Stevens, B
   Powell, V
AF Croucher, Charlotte
   Powell, Wendy
   Dicks, Matt
   Stevens, Brett
   Powell, Vaughan
TI The Use of Embedded Context-Sensitive Attractors for Clinical Walking
   Test Guidance in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE guidance; navigation; virtual reality; virtual environments; virtual
   rehabilitation; autonomy; self-determination theory; attractors
ID SELF-DETERMINATION THEORY; CURVED-PATH WALKING; EXTERNAL FOCUS; ROBOTIC
   GUIDE; PERFORMANCE; STROKE; OLDER; ENVIRONMENTS; PERCEPTION; MOTIVATION
AB Virtual reality is increasingly used in rehabilitation and can provide additional motivation when working toward therapeutic goals. However, a particular problem for patients regards their ability to plan routes in unfamiliar environments. Therefore, the aim of this study was to explore how visual cues, namely embedded context-sensitive attractors, can guide attention and walking direction in VR, for clinical walking interventions. This study was designed using a butterfly as the embedded context-sensitive attractor, to guide participant locomotion around the clinical figure of eight walk test, to limit the use of verbal instructions. We investigated the effect of varying the number of attractors for figure of eight path following, and whether there are any negative impacts on perceived autonomy or workload. A total of 24 participants took part in the study and completed six attractor conditions in a counterbalanced order. They also experienced a control VE (no attractors) at the beginning and end of the protocol. Each VE condition lasted a duration of 1 min and manipulated the number of attractors to either singular or multiple alongside, the placement of turning markers (virtual trees) used to represent the cones used in clinical settings for the figure of eight walk test. Results suggested that embedded context-sensitive attractors can be used to guide walking direction, following a figure of eight in VR without impacting perceived autonomy, and workload. However, there appears to be a saturation point, with regards to effectiveness of attractors. Too few objects in a VE may reduce feelings of intrinsic motivation, and too many objects in a VE may reduce the effectiveness of attractors for guiding individuals along a figure of eight path. We conclude by indicating future research directions, for attractors and their use as a guide for walking direction.
C1 [Croucher, Charlotte; Powell, Wendy; Powell, Vaughan] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
   [Dicks, Matt] Univ Portsmouth, Sch Sport Hlth & Exercise Sci, Portsmouth, England.
   [Stevens, Brett] Univ Portsmouth, Sch Creat Technol, Portsmouth, England.
C3 Tilburg University; University of Portsmouth; University of Portsmouth
RP Croucher, C (corresponding author), Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
EM c.s.croucher@tilburguniversity.edu
RI Miller-Dicks, Matt/O-7489-2016; Croucher, Charlotte/JDW-1448-2023
OI Miller-Dicks, Matt/0000-0001-6584-2733; Stevens,
   Brett/0000-0003-1822-489X; Croucher, Charlotte/0000-0002-1378-396X
FU Faculty of Creative and Cultural Industries at the University of
   Portsmouth
FX This work was funded by the Faculty of Creative and Cultural Industries
   at the University of Portsmouth.
CR Anglin JM, 2017, SCI REP-UK, V7, DOI 10.1038/srep45469
   Baird J, 2018, EXP BRAIN RES, V236, P59, DOI 10.1007/s00221-017-5107-0
   Barker KL, 2019, PHYSIOTHERAPY, V105, P76, DOI 10.1016/j.physio.2018.07.003
   Barnett CT, 2016, GAIT POSTURE, V44, P221, DOI 10.1016/j.gaitpost.2015.12.022
   Bonnette S, 2020, J SPORT SCI MED, V19, P84
   Borrego A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0174-1
   BOUMA H, 1970, NATURE, V226, P177, DOI 10.1038/226177a0
   Bruder G, 2013, DISPLAYS, V34, P132, DOI 10.1016/j.displa.2012.10.007
   Bustamante Ernesto A., 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P1522
   Buszard T, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01350
   Chen HM, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17082755
   Chuang TK, 2018, IEEE INT CONF ROBOT, P5849
   Cikajlo I, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00572
   Corbetta D, 2015, J PHYSIOTHER, V61, P117, DOI 10.1016/j.jphys.2015.05.017
   Cuperus AA, 2018, COMPUT HUM BEHAV, V79, P211, DOI 10.1016/j.chb.2017.10.037
   Dahms C, 2020, HUM BRAIN MAPP, V41, P270, DOI 10.1002/hbm.24793
   Davis R, 2017, ENVIRON BEHAV, V49, P1038, DOI 10.1177/0013916516677341
   Dawson DR, 2017, NEUROPSYCHOL REHABIL, V27, P599, DOI 10.1080/09602011.2017.1313379
   DECI EL, 1994, J PERS, V62, P119, DOI 10.1111/j.1467-6494.1994.tb00797.x
   Denneman RPM, 2018, GAIT POSTURE, V62, P206, DOI 10.1016/j.gaitpost.2018.03.008
   Foulsham T, 2011, VISION RES, V51, P1920, DOI 10.1016/j.visres.2011.07.002
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Furukawa M., 2011, P 2 AUGMENTED HUMAN, DOI [10.1145/1959826.1959845, DOI 10.1145/1959826.1959845]
   Gil-Gómez JA, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-30
   Gokeler A, 2019, SPORTS MED, V49, P853, DOI 10.1007/s40279-019-01058-0
   Grogorick S, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3238303
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Henry CA, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15386-7
   Hersh MA, 2010, APPL BIONICS BIOMECH, V7, P277, DOI 10.1080/11762322.2010.523626
   Hess RJ, 2010, PHYS THER, V90, P89, DOI 10.2522/ptj.20080121
   Ijaz K, 2020, INT J HUM-COMPUT INT, V36, P1195, DOI 10.1080/10447318.2020.1726107
   Jie LJ, 2018, JMIR RES PROTOC, V7, DOI 10.2196/resprot.9595
   Johnson L, 2019, JMIR RES PROTOC, V8, DOI 10.2196/14222
   Johnson L, 2013, PHYS THER, V93, P957, DOI 10.2522/ptj.20120300
   Keatley D, 2013, BRIT J HEALTH PSYCH, V18, P2, DOI 10.1111/j.2044-8287.2011.02063.x
   Kleynen M, 2019, CLIN REHABIL, V33, P619, DOI 10.1177/0269215518816359
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee J., 2018, AUGMENTED COGNITION, VVol. 10915, DOI [10.1007/978-3-319-91470-1_31, DOI 10.1007/978-3-319-91470-1_31]
   Lemos A, 2017, PSYCHOL SPORT EXERC, V31, P28, DOI 10.1016/j.psychsport.2017.03.009
   Liu TW, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214796
   Maeda T., 2005, ACM SIGGRAPH 2005 EM, P17, DOI DOI 10.1145/1187297.1187315
   Mak TCT, 2020, J GERONTOL B-PSYCHOL, V75, P274, DOI 10.1093/geronb/gby115
   Melnik N, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57277-y
   Miller H.J., 1992, Journal of Planning Literature, V7, P139, DOI [DOI 10.1177/088541229200700202, 10.1177/088541229200700202]
   Morris JH, 2017, PHYSIOTHERAPY, V103, P311, DOI 10.1016/j.physio.2016.05.001
   Nielsen LT, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P229, DOI 10.1145/2993369.2993405
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Norman D. A., 1999, Interactions, V6, P38, DOI 10.1145/301153.301168
   Ntoumanis N, 2021, HEALTH PSYCHOL REV, V15, P214, DOI 10.1080/17437199.2020.1718529
   Odonkor CA, 2013, J GERONTOL A-BIOL, V68, P1532, DOI 10.1093/gerona/glt060
   Palstam A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219513
   Parsons TD, 2017, NEUROPSYCHOL REHABIL, V27, P777, DOI 10.1080/09602011.2015.1109524
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Q LIN., 2012, P ACM S APPL PERCEPT, P7
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Rothe S, 2018, LECT NOTES COMPUT SC, V10850, P101, DOI 10.1007/978-3-319-95270-3_7
   Ryan RM, 2020, CONTEMP EDUC PSYCHOL, V61, DOI 10.1016/j.cedpsych.2020.101860
   RYAN RM, 1982, J PERS SOC PSYCHOL, V43, P450, DOI 10.1037/0022-3514.43.3.450
   Ryan RM, 2017, SELF-DETERMINATION THEORY: BASIC PSYCHOLOGICAL NEEDS IN MOTIVATION, DEVELOPMENT, AND WELLNESS, P1, DOI 10.1521/978.14625/28806
   Schack J, 2021, DISABIL REHABIL, V43, P1323, DOI 10.1080/09638288.2019.1662495
   Schmitz A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P63, DOI [10.1109/VR46266.2020.1581102716289, 10.1109/VR46266.2020.00-80]
   Self-Determination T., 2020, INTRINSIC MOTIVATION
   Sra M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P59, DOI 10.1145/3196709.3196792
   Sra M, 2017, P IEEE VIRT REAL ANN, P405, DOI 10.1109/VR.2017.7892348
   Sweet SN, 2012, CAN PSYCHOL, V53, P319, DOI 10.1037/a0030280
   Textures.com, 2017, BRANCHES0012 1 ALPH
   Textures.com, 2017, BRANCHES0013 1 ALPH
   Textures.com, 2017, 3D SCANN TREE BARK 1
   Textures.com, 2017, LEAVES0142 4 ALPH S
   Thorpert P, 2019, LANDSCAPE RES, V44, P88, DOI 10.1080/01426397.2017.1413177
   Tong MH, 2017, J VISION, V17, DOI 10.1167/17.1.28
   Vansteenkiste P, 2014, TRANSPORT RES F-TRAF, V23, P81, DOI 10.1016/j.trf.2013.12.019
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Vilar E, 2014, HUM FACTOR ERGON MAN, V24, P601, DOI 10.1002/hfm.20503
   Welch SA, 2016, PM&R, V8, P754, DOI 10.1016/j.pmrj.2015.12.004
   Whitney D, 2011, TRENDS COGN SCI, V15, P160, DOI 10.1016/j.tics.2011.02.005
   Wong SST, 2013, DISABIL REHABIL, V35, P1896, DOI 10.3109/09638288.2013.766274
   Wulf G, 2015, HUM MOVEMENT SCI, V40, P176, DOI 10.1016/j.humov.2014.11.015
   Yang YY, 2018, J ENVIRON PSYCHOL, V56, P20, DOI 10.1016/j.jenvp.2018.02.003
NR 79
TC 0
Z9 0
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2021
VL 2
AR 621965
DI 10.3389/frvir.2021.621965
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YC1
UT WOS:001023326800001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Skarbez, R
   Smith, M
   Whitton, MC
AF Skarbez, Richard
   Smith, Missie
   Whitton, Mary C.
TI Revisiting Milgram and Kishino's Reality-Virtuality Continuum
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; augmented reality; mixed reality; presence; immersion;
   coherence; taxonomy
ID MIXED REALITY
AB Since its introduction in 1994, Milgram and Kishino's reality-virtuality (RV) continuum has been used to frame virtual and augmented reality research and development. While originally, the RV continuum and the three dimensions of the supporting taxonomy (extent of world knowledge, reproduction fidelity, and extent of presence metaphor) were intended to characterize the capabilities of visual display technology, researchers have embraced the RV continuum while largely ignoring the taxonomy. Considering the leaps in technology made over the last 25 years, revisiting the RV continuum and taxonomy is timely. In reexamining Milgram and Kishino's ideas, we realized, first, that the RV continuum is actually discontinuous; perfect virtual reality cannot be reached. Secondly, mixed reality is broader than previously believed, and, in fact, encompasses conventional virtual reality experiences. Finally, our revised taxonomy adds coherence, accounting for the role of users, which is critical to assessing modern mixed reality experiences. The 3D space created by our taxonomy incorporates familiar constructs such as presence and immersion, and also proposes new constructs that may be important as mixed reality technology matures.
C1 [Skarbez, Richard] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
   [Whitton, Mary C.] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC USA.
C3 La Trobe University; University of North Carolina; University of North
   Carolina Chapel Hill
RP Skarbez, R (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
EM r.skarbez@latrobe.edu.au
RI Skarbez, Richard/S-7298-2019
OI Skarbez, Richard/0000-0002-2783-5257
CR Alexander A. L., 2005, INTERSERVICE IND TRA
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barba E, 2012, P IEEE, V100, P929, DOI 10.1109/JPROC.2011.2182070
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/VR.2019.8798074, 10.1109/vr.2019.8798074]
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   Flavián C, 2021, J BUS RES, V123, P289, DOI 10.1016/j.jbusres.2020.09.036
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Heilig M. L., 1962, HEILIG ML
   Insko B., 2001, THESIS U N CAROLINA
   Iwata H, 2004, P IEEE VIRT REAL ANN, P51, DOI 10.1109/VR.2004.1310055
   Koleva B., 1999, PROPERTIES MIXED REA, DOI [10.1007/978-94-011-4441-4_7, DOI 10.1007/978-94-011-4441-4_7]
   Kunert C, 2018, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR.2018.00023
   Lindeman RW, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P175
   Liu SG, 2021, Arxiv, DOI arXiv:2011.05538
   Mackay W.E., 1998, Proceedings of the working conference on Advanced visual interfaces, P13
   Mann S., 2018, arXiv
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Miyatake H, 2020, CLIN CASE REP, V8, P950, DOI [10.1002/ccr3.2633, 10.1145/3334480.3382984]
   Normand Jean-Marie., 2012, Proceedings of the 3rd Augmented Human International Conference, P18, DOI DOI 10.1145/2160125.2160143
   Pausch R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P193, DOI 10.1145/237170.237257
   Salisbury JK, 1997, IEEE COMPUT GRAPH, V17, P6, DOI 10.1109/MCG.1997.1626171
   Savioja L, 2015, J ACOUST SOC AM, V138, P708, DOI 10.1121/1.4926438
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez Richard T, 2016, PhD thesis
   Slater M., 2004, PRESENCE CONNECT, VVol. 3, P1
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Speiginer G, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P328, DOI 10.1109/ISMAR-Adjunct.2018.00097
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   State A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P439, DOI 10.1145/237170.237283
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stotko P., 2019, CVPR WORKSH COMP VIS, P3
   Stotko P, 2019, INT SYM MIX AUGMENT, P19, DOI 10.1109/ISMAR.2019.00018
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Yanagida Y, 2012, IEEE SENSOR, P1013
NR 37
TC 109
Z9 123
U1 2
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 24
PY 2021
VL 2
AR 647997
DI 10.3389/frvir.2021.647997
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RT7
UT WOS:001023161700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Hughes, CL
   Fidopiastis, C
   Stanney, KM
   Bailey, PS
   Ruiz, E
AF Hughes, Claire L.
   Fidopiastis, Cali
   Stanney, Kay M.
   Bailey, Peyton S.
   Ruiz, Ernesto
TI The Psychometrics of Cybersickness in Augmented Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; cybersickness; virtual reality; HoloLens; AR tablet
ID VIRTUAL-REALITY; SIMULATOR SICKNESS; EXPOSURE; ENVIRONMENTS; USERS
AB Augmented reality (AR) is rapidly being adopted by industry leaders and militaries around the globe. With the Defense Health Agency pushing AR as a solution to the distributed learning problem, along with AR applications being explored within primary care and operational medical settings, it is crucial for these immersive platforms to have a standardized, scientifically based paradigm on which they are designed and used. One area of particular concern is the potential for physiological maladaptation following prolonged AR exposure, which is expected to vary from that associated with virtual reality exposure. Such maladaptation is potentially driven by limitations that exist with regard to the types and extent of perceptual issues characteristic of AR head-worn displays (e.g., mismatches between visually displayed information and other senses, restricted field of view, mismatched interpupillary distance). Associated perceptual limitations can reduce training effectiveness or impose patient and/or trainee safety concerns. Thus, while AR technology has the potential to advance simulation training, there is a need to approach AR-based research-particularly that which relates to long-exposure-duration scenarios-from a bottom-up perspective, where its physiological impact is more fully understood. In the hopes of assisting this process, this study presents a comparison of cybersickness between two common forms of AR displays. Specifically, by comparing the Microsoft HoloLens, a head-worn display that has seen rapid adoption by the scientific community, with an AR Tablet-based platform within the context of long-duration AR training exposure, it will be possible to determine what differences, if any, exist between the two display platforms in terms of their physiological impact as measured via cybersickness severity and symptom profile. Results from this psychometric assessment will be used to evaluate the physiological impact of AR exposure and develop usage protocols to ensure AR is safe and effective to use for military medical training.
C1 [Hughes, Claire L.; Fidopiastis, Cali; Stanney, Kay M.; Bailey, Peyton S.; Ruiz, Ernesto] Design Interact, Orlando, FL 32817 USA.
RP Hughes, CL (corresponding author), Design Interact, Orlando, FL 32817 USA.
EM claire.hughes@designinteractive.net
FU Joint Program Committee-JPC-1 at Fort Detrick, MD [MTEC-W81XWH190005];
   U.S. Army Medical Research amp; Development Command (USAMRDC)
   [MTEC-W81XWH190005]
FX This research and development project/program/initiative was conducted
   by Design Interactive, Inc and is made possible by a contract that was
   awarded and administered by the U.S. Army Medical Research & Development
   Command (USAMRDC) and the Joint Program Committee-JPC-1 at Fort Detrick,
   MD under Contract Number: MTEC-W81XWH190005.
CR BELLAMY RF, 1984, MIL MED, V149, P55
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Buie E., 1999, Interactions, V6, P36, DOI 10.1145/296165.296177
   Butler FK, 2017, WILD ENVIRON MED, V28, pS12, DOI 10.1016/j.wem.2016.12.004
   Champion HR, 2003, J TRAUMA, V54, pS13, DOI 10.1097/01.TA.0000057151.02906.27
   Chang E, 2013, INT WINT WORKSH BR, P62, DOI 10.1109/IWW-BCI.2013.6506631
   Claypoole V. L., 2020, AM SOC NAV ENG ASNE
   Cohen I, 2015, COGN TECHNOL WORK, V17, P503, DOI 10.1007/s10111-015-0325-3
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Fang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051037
   Fidopiastis CM, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-11
   Garcia-Agundez A., 2019, IJVR, V19, P1, DOI DOI 10.20870/IJVR.2019.19.1.2907
   Garzón J, 2019, EDUC RES REV-NETH, V27, P244, DOI 10.1016/j.edurev.2019.04.001
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Hale KS, 2006, APPL ERGON, V37, P329, DOI 10.1016/j.apergo.2005.06.009
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1996, INT J HUM-COMPUT INT, V8, P25, DOI 10.1080/10447319609526139
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim YS, 2014, AM J ROENTGENOL, V203, P201, DOI 10.2214/AJR.13.11744
   Kotwal RS, 2011, ARCH SURG-CHICAGO, V146, P1349, DOI 10.1001/archsurg.2011.213
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Mazuryk T., 1999, VIRTUAL REALITY HIST
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   National Association of Emergency Medical Technicians [NAEMT], 2018, TACT COMB CAS CAR ME
   Ochanji S., 2020, VR TIMES
   Padmanaban N, 2017, P NATL ACAD SCI USA, V114, P2183, DOI 10.1073/pnas.1617251114
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reed N., 2007, P 1 INT S VIS IND MO, P156
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Stanney K. M., 2014, HDB VIRTUAL ENV DESI
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stanney K, 2013, HUM FACT DEFENCE, P169
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P447, DOI 10.1162/105474698565848
   Stanney KM, 1999, HUM FAC ERG SOC P, P1223
   Vovk A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173783
   Walker AD, 2010, AVIAT SPACE ENVIR MD, V81, P929, DOI 10.3357/ASEM.2735.2010
   Wann JP, 2015, HUM FACTORS ERGON, P811
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
NR 45
TC 19
Z9 23
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 9
PY 2020
VL 1
AR 602954
DI 10.3389/frvir.2020.602954
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L7BH1
UT WOS:001024769600001
OA gold
DA 2024-07-18
ER

PT J
AU Venkatesan, RK
   Banakou, D
   Slater, M
   M, M
AF Venkatesan, R. K.
   Banakou, Domna
   Slater, Mel
   M., Manivannan
TI Haptic feedback in a virtual crowd scenario improves the emotional
   response
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; haptic feedback; haptic display; 360-degree video;
   virtual collisions; virtual crowd; simulating emotions; multimodal
   virtual environment
ID NAVIGATION
AB Research has shown that incorporating haptics into virtual environments can increase sensory fidelity and provide powerful and immersive experiences. However, current studies on haptics in virtual interactions primarily focus on one-on-one scenarios, while kinesthetic haptic interactions in large virtual gatherings are underexplored. This study aims to investigate the impact of kinesthetic haptics on eliciting emotional responses within crowded virtual reality (VR) scenarios. Specifically, we examine the influence of type or quality of the haptic feedback on the perception of positive and negative emotions. We designed and developed different combinations of tactile and torque feedback devices and evaluated their effects on emotional responses. To achieve this, we explored different combinations of haptic feedback devices, including "No Haptic," "Tactile Stimulus" delivering tactile cues, and "Haptic Stimulus" delivering tactile and torque cues, in combination with two immersive 360-degree video crowd scenarios, namely, "Casual Crowd" and "Aggressive Crowd." The results suggest that varying the type or quality of haptic feedback can evoke different emotional responses in crowded VR scenarios. Participants reported increased levels of nervousness with Haptic Stimulus in both virtual scenarios, while both Tactile Stimulus and Haptic Stimulus were negatively associated with pleasantness and comfort during the interaction. Additionally, we observed that participants' sense of touch being real was enhanced in Haptic Stimulus compared to Tactile Stimulus. The "Haptic Stimulus" condition had the most positive influence on participants' sense of identification with the crowd.
C1 [Venkatesan, R. K.; M., Manivannan] IIT Madras, Dept Appl Mech & Biomed Engn, Touch Lab, Chennai, India.
   [Venkatesan, R. K.; M., Manivannan] IIT Madras, Experiential Technol Innovat Ctr XTIC, Chennai, India.
   [Banakou, Domna; Slater, Mel] Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.
   [Banakou, Domna; Slater, Mel] Univ Barcelona, Inst Neurosci, Barcelona, Spain.
   [Banakou, Domna] New York Univ Abu Dhabi, Arts & Humanities Div, Interact Media, Abu Dhabi, U Arab Emirates.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Madras; University of
   Barcelona; University of Barcelona; New York University Abu Dhabi
RP Banakou, D (corresponding author), Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.; Banakou, D (corresponding author), Univ Barcelona, Inst Neurosci, Barcelona, Spain.; Banakou, D (corresponding author), New York Univ Abu Dhabi, Arts & Humanities Div, Interact Media, Abu Dhabi, U Arab Emirates.
EM domna.banakou@nyu.edu
FU European Research Council (ERC) [742989]; Tamkeen NYU Abu Dhabi Funding
   Agency [76 71220 ADHPG VP211]; Government of India
FX This project was supported by the European Research Council (ERC)
   Advanced Grant MoTIVE (#742989) and the Tamkeen NYU Abu Dhabi Funding
   Agency (#76 71220 ADHPG VP211). MM and RKV were supported by Institutes
   of Eminence funded by the Government of India.
CR Adilkhanov A, 2022, IEEE ACCESS, V10, P91923, DOI 10.1109/ACCESS.2022.3202986
   Ahmed I, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P341, DOI 10.1145/2993148.2993171
   Amba R. R., 2017, Int. J. Yoga-Philos. Psychol. Parapsychol, V5, P48, DOI [10.4103/IJNY.IJOYPPP_4_17, DOI 10.4103/IJNY.IJOYPPP_4_17]
   Ando H., 2002, A wearable force display based on brake change in angular momentum
   Beacco A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/VR50410.2021.00078
   Berton F, 2022, IEEE T VIS COMPUT GR, V28, P2589, DOI 10.1109/TVCG.2020.3041341
   Biocca F., 2002, Int. Work. Presence, P1
   Cui DX, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2009
   Della Longa L, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.795283
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Endo T, 2011, IEEE T HAPTICS, V4, P14, DOI [10.1109/TOH.2010.62, 10.1109/ToH.2010.62]
   Gelman A., 2006, A default prior distribution for logistic and other regression models
   Giri GS, 2021, ROBOTICS, V10, DOI 10.3390/robotics10010029
   Goldenberg A, 2021, PSYCHOL SCI, V32, P437, DOI 10.1177/0956797620970561
   Hoppe M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI [10.1145/3313831.3376719, 10.1145/10.1145/3313831.3376719]
   Huisman G, 2017, IEEE T HAPTICS, V10, P391, DOI 10.1109/TOH.2017.2650221
   Koilias A, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1963
   Koilias A, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1928
   Kramer ADI, 2014, P NATL ACAD SCI USA, V111, P8788, DOI 10.1073/pnas.1320040111
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Lemoine NP, 2019, OIKOS, V128, P912, DOI 10.1111/oik.05985
   Loomis J., 2003, Tactual perception
   Massie T. H., 1994, P S HAPT INT VIRT EN, P295
   Monica R, 2023, DISPLAYS, V78, DOI 10.1016/j.displa.2023.102417
   Murtagh EM, 2021, SPORTS MED, V51, P125, DOI 10.1007/s40279-020-01351-3
   Nagai K, 2015, SIGGRAPH ASIA 2015 HAPTIC MEDIA AND CONTENTS DESIGN (SA'15), DOI 10.1145/2818384.2818403
   Nunez CM, 2020, IEEE HAPTICS SYM, P629, DOI 10.1109/HAPTICS45997.2020.ras.HAP20.35.f631355d
   Pelechano Nuria., 2008, P 7 INT JOINT C AUTO, V1, P136
   Romanishin JW, 2015, IEEE INT CONF ROBOT, P1925, DOI 10.1109/ICRA.2015.7139450
   Schirmer A, 2022, PHYSIOL BEHAV, V250, DOI 10.1016/j.physbeh.2022.113797
   Skola F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205851
   Slater M, 2023, VIRTUAL REAL-LONDON, V27, P651, DOI 10.1007/s10055-022-00685-9
   Somarathna R, 2023, IEEE T AFFECT COMPUT, V14, P2626, DOI 10.1109/TAFFC.2022.3181053
   Soni R, 2019, INT J YOGA, V12, P45, DOI 10.4103/ijoy.IJOY_27_17
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Todd S. L., 2008, Peoceedings 2008 Northeast. Recreat. Res. Symp, P72
   Wysiadecki G, 2014, FOLIA MORPHOL, V73, P216, DOI 10.5603/FM.2014.0032
   Zhu X, 2022, FRONT COMP SCI-SWITZ, V4, DOI 10.3389/fcomp.2022.826637
NR 39
TC 0
Z9 0
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 28
PY 2023
VL 4
AR 1242587
DI 10.3389/frvir.2023.1242587
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CA2G9
UT WOS:001122457300001
OA gold
DA 2024-07-18
ER

PT J
AU van der Meer, N
   van der Werf, V
   Brinkman, WP
   Specht, M
AF van der Meer, Nesse
   van der Werf, Vivian
   Brinkman, Willem-Paul
   Specht, Marcus
TI Virtual reality and collaborative learning: a systematic literature
   review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; collaborative learning; virtual reality education;
   collaborative virtual environment; virtual reality and collaborative
   learning; collaborative virtual reality; collaborative virtual reality
   systems; educational technologies
ID HIGHER-EDUCATION; 2ND LIFE; ENVIRONMENTS; DESIGN; REPRESENTATIONS;
   TECHNOLOGIES; CHILDREN; DISTANCE; PEDAGOGY; OUTCOMES
AB Background: While research on Virtual Reality's potential for education continues to advance, research on its support for Collaborative Learning is small in scope. With remote collaboration and distance learning becoming increasingly relevant for education (especially since the COVID-19 pandemic), an understanding of Virtual Reality's potential for Collaborative Learning is of importance. To establish how this immersive technology can support and enhance collaboration between learners, this systematic literature review analyses scientific research on Virtual Reality for Collaborative Learning with the intention to identify 1) skills and competences trained, 2) domains and disciplines addressed, 3) systems used and 4) empirical knowledge established.
   Method: Two scientific databases-Scopus and Web of Science-were used for this review. Following the PRISMA method, a total of 139 articles were analyzed. Reliability of this selection process was assessed using five additional coders. A taxonomy was used to classify these articles. Another coder was used to assess the reliability of the primary coder before this taxonomy was applied to the selected articles
   Results: Based on the literature reviewed, skills and competences developed are divided into five categories. Educational fields and domains seem interested in Virtual Reality for Collaborative Learning because of a need for innovation, communities and remote socialization and collaboration between learners. Systems primarily use monitor-based Virtual Reality and mouse-and-keyboard controls. A general optimism is visible regarding the use of Virtual Reality to support and enhance Collaborative Learning
   Conclusion: Five distinct affordances of Virtual Reality for Collaborative Learning are identified: it 1) is an efficient tool to engage and motivate learners, 2) supports distance learning and remote collaboration, 3) provides multi- and interdisciplinary spaces for both learning and collaborating, 4) helps develop social skills and 5) suits Collaborative Learning-related paradigms and approaches. Overall, the reviewed literature suggests Virtual Reality to be an effective tool for the support and enhancement of Collaborative Learning, though further research is necessary to establish pedagogies.
C1 [van der Meer, Nesse; Specht, Marcus] Delft Univ Technol, Ctr Educ & Learning, Delft, Netherlands.
   [van der Werf, Vivian] Leiden Univ, Leiden Inst Adv Comp Sci, Leiden, Netherlands.
   [Brinkman, Willem-Paul] Delft Univ Technol, Interact Intelligence, Delft, Netherlands.
C3 Delft University of Technology; Leiden University; Leiden University -
   Excl LUMC; Delft University of Technology
RP van der Meer, N (corresponding author), Delft Univ Technol, Ctr Educ & Learning, Delft, Netherlands.
EM nessevdmeer@gmail.com
OI van der Meer, Nesse/0000-0003-3893-7985; van der Werf,
   Vivian/0000-0002-6435-0531
FU Leiden-Delft-Erasmus Centre for Education and Learning (LDE-CEL)
FX & nbsp;This project has been funded by the Leiden-Delft-Erasmus Centre
   for Education and Learning (LDE-CEL).
CR Abdullah J, 2019, VIRTUAL REAL-LONDON, V23, P461, DOI 10.1007/s10055-019-00381-1
   Al-Hatem AI, 2018, J INF TECHNOL EDUC-R, V17, P285, DOI 10.28945/4110
   Amati M., 2012, J ED BUILT ENV, V7, P39, DOI [10.11120/jebe.2012.07010039, DOI 10.11120/JEBE.2012.07010039]
   [Anonymous], 2014, LECT NOTES BUS INF P, DOI DOI 10.1007/978-3-319-09546-2_6
   [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI DOI 10.1371/JOURNAL.PMED.1000097
   Arlati S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020261
   Ashley C., 2014, ATL MARK J, V3, P94
   Avanzato R., 2018, COMPUTERS ED J, V9
   Aydogan Hakan, 2022, International Journal of Electrical Engineering Education, V59, P266, DOI 10.1177/0020720919856249
   Bilyatdinova A, 2016, ADV INTELL SYST, V416, P371, DOI 10.1007/978-3-319-27478-2_26
   Bloom B., 1956, Taxonomy of educational objectives: the classification of educational goals, handbook 1, cognitive domain
   Bluemink J, 2010, INTERACT LEARN ENVIR, V18, P365, DOI 10.1080/10494820802602444
   Bonner E., 2018, TEACHING ENGLISH TEC, V18, P33
   Bouta H, 2013, EDUC INF TECHNOL, V18, P571, DOI 10.1007/s10639-012-9198-8
   Bower M, 2017, BRIT J EDUC TECHNOL, V48, P407, DOI 10.1111/bjet.12435
   Brna P., 1998, Education and Information Technologies, V3, P247, DOI 10.1023/A:1009649631868
   Carron Thibault, 2013, IADIS International Conference on Cognition and Exploratory Learning in the Digital Age (CELDA 2013). Proceedings, P133
   Champsas I., 2012, P EUR C GAM BAS LEAR
   Chang V, 2009, INT J EMERG TECHNOL, V4, P6, DOI 10.3991/ijet.v4s3.1112
   Chang Y., 2016, Computers in Education Journal, V16, P24, DOI [DOI 10.18260/P.24973, 10.18260/p.24973]
   Chavez Bayron, 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 746), P1345, DOI 10.1007/978-3-319-77712-2_129
   Cheng YF, 2010, COMPUT EDUC, V54, P1068, DOI 10.1016/j.compedu.2009.10.011
   Cheong YG, 2015, COMPUT SOC SCI, P449, DOI 10.1007/978-3-319-14081-0_21
   Cook M, 2019, INFORM TECHNOL LIBR, V38, P25, DOI 10.6017/ITAL.V38I4.11075
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Daphne E., 2000, Proceedings IEEE 9th International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WET ICE 2000), P12, DOI 10.1109/ENABL.2000.883698
   de Back TT, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00228-9
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   De Lucia A, 2009, SOFTWARE PRACT EXPER, V39, P1025, DOI 10.1002/spe.926
   De Pace F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00018
   Denoyelles A, 2012, COMPUT EDUC, V58, P21, DOI 10.1016/j.compedu.2011.07.007
   Desai K, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P376, DOI 10.1109/BigMM.2017.62
   Dich Y, 2018, LECT NOTES ARTIF INT, V10947, P98, DOI 10.1007/978-3-319-93843-1_8
   Dixon S., 2006, International Journal of Performance Arts and Digital Media, V2, P23, DOI [https://doi.org/10.1386/padm.2.1.23/1, DOI 10.1386/PADM.2.1.23/1, 10.1386/padm.2.1.23/1]
   Economou D., 2001, P VAST 2001 VIRT REA, P323, DOI [10.1145/584993.585052, DOI 10.1145/584993.585052]
   Edirisingha P, 2009, BRIT J EDUC TECHNOL, V40, P458, DOI 10.1111/j.1467-8535.2009.00962.x
   Franco J. F., 2009, ACM SIGGRAPH ASIA 20, DOI [10.1145/1666611.1666626, DOI 10.1145/1666611.1666626]
   Franco J. F., 2006, ACM SIGGRAPH 2006 ED, DOI DOI 10.1145/1179295.1179338
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gerhard M., 2001, Intelligent Virtual Agents. Third International Workshop, IVA 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2190), P137
   Girvan C, 2018, ETR&D-EDUC TECH RES, V66, P1087, DOI 10.1007/s11423-018-9577-y
   Girvan C, 2010, COMPUT EDUC, V55, P342, DOI 10.1016/j.compedu.2010.01.020
   Godin J J., 2019, Issues in Information Systems, V20, P104
   Griol D, 2014, J AMB INTEL SMART EN, V6, P237, DOI 10.3233/AIS-140255
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hwang WY, 2013, COMPUT EDUC, V62, P308, DOI 10.1016/j.compedu.2012.10.005
   Jackson RL., 1999, P ACM 1999 S APPL CO, P121, DOI DOI 10.1145/298151.298219
   Jarmon L, 2008, EDUC MEDIA INT, V45, P157, DOI 10.1080/09523980802283889
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jeong H, 2016, EDUC PSYCHOL-US, V51, P247, DOI 10.1080/00461520.2016.1158654
   Jeong J. Y., 2018, ICCE 2018 26 INT C C, P638
   Jing Y, 2018, INT J BIOL SCI, V14, P1, DOI 10.7150/ijbs.23165
   Joyner D. A., 2021, CONTENT NEUTRAL IMME, P47
   Juliano JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041204
   Ke FF, 2016, INTERACT LEARN ENVIR, V24, P1511, DOI 10.1080/10494820.2015.1040421
   Kleanthous S, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2996728
   Kong J. S. L., 2013, P PAC AS C INF SYST
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   Lattemann C., 2012, ECIS 2012 P 20 EUR C
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Li H, 2012, J COMPUT CIVIL ENG, V26, P638, DOI 10.1061/(ASCE)CP.1943-5487.0000170
   Liu Y, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674369
   Liu YQ, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA 2020), P188, DOI 10.1109/ICCIA49625.2020.00043
   López-Faican L, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2020.103814
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   McArdle G, 2012, INTERACT LEARN ENVIR, V20, P57, DOI 10.1080/10494821003714749
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mehrfard A, 2019, Arxiv, DOI arXiv:1912.02913
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Moll J, 2013, ACM T ACCESS COMPUT, V4, DOI 10.1145/2493171.2493172
   Moore AG, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5030029
   Morch A. I., 2019, COMPUTER SUPPORTED C, V1, P272
   Motejlek J., 2019, P 46 SEFI ANN C 2018, P1089
   Mystakidis S, 2017, EDULEARN PROC, P968
   Nadolny L, 2013, ETR&D-EDUC TECH RES, V61, P979, DOI 10.1007/s11423-013-9319-0
   Nikolic S, 2018, ADV INTELL SYST, V715, P48, DOI 10.1007/978-3-319-73210-7_6
   Nisiotis L, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P71, DOI 10.1145/3304221.3319743
   Núñez M, 2008, MATH COMPUT SCI ENG, P271
   Nur Affendy Nor'a Muhammad, 2019, IOP Conference Series: Materials Science and Engineering, V551, DOI 10.1088/1757-899X/551/1/012050
   Olmos E., 2018, Mobile and ubiquitous learning, P95, DOI DOI 10.1007/978-981-10-6144-86
   Parong J, 2021, J COMPUT ASSIST LEAR, V37, P226, DOI 10.1111/jcal.12482
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Pellas N., 2013, Balkan Conference in Informatics, BCI '13, P187
   Pellas N, 2015, OPEN SOURCE TECHNOLOGY: CONCEPTS, METHODOLOGIES, TOOLS, AND APPLICATIONS, P1223, DOI 10.4018/978-1-4666-7230-7.ch059
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rebelo F, 2012, HUM FACTORS, V54, P964, DOI 10.1177/0018720812465006
   Rogers L, 2011, BRIT J EDUC TECHNOL, V42, P608, DOI 10.1111/j.1467-8535.2010.01057.x
   Rueda J, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.506984
   Saldana D, 2020, AM J OCCUP THER, V74, DOI 10.5014/ajot.2020.041442
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Schreiber J.B., 2011, ED RES INTERRELATION
   Shawky D, 2014, 2014 INTERNATIONAL CONFERENCE ON INTERACTIVE COLLABORATIVE LEARNING (ICL), P633, DOI 10.1109/ICL.2014.7017846
   Shi YM, 2019, AUTOMAT CONSTR, V104, P197, DOI 10.1016/j.autcon.2019.04.015
   Sims R., 2022, P 2022 8 INT C IMM L, DOI [10.23919/iLRN55037.2022.9815936, DOI 10.23919/ILRN55037.2022.9815936]
   Smith SA, 2019, PSYCHON B REV, V26, P1213, DOI 10.3758/s13423-019-01605-w
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Srivastava P, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00050
   Stahl G, 2006, CAMB HANDB PSYCHOL, P409
   Sulbaran T., 2012, ASEE ANN C EXP C P T, DOI [10.18260/1-2--22208, DOI 10.18260/1-2--22208]
   Tan CSS, 2014, PRESENCE-TELEOP VIRT, V23, P90, DOI 10.1162/PRES_a_00168
   Terzidou T., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies (ICALT), P624, DOI 10.1109/ICALT.2012.55
   Tovar DF., 2020, VIRTUAL REALITY AUGM
   Tremmel C, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00401
   Tuzun H., 2019, International Electronic Journal of Elementary Education, V11, P221, DOI DOI 10.26822/IEJEE.2019349247
   Vallance M, 2015, COMM COM INF SC, V533, P268, DOI 10.1007/978-3-319-22629-3_22
   Vrellis Ioannis, 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P210, DOI 10.1109/ICALT.2010.65
   Wang AN, 2022, INTERACT LEARN ENVIR, V30, P677, DOI 10.1080/10494820.2019.1678489
   Wang C. J., 2014, 3D IMMERSIVE INTERAC, P93, DOI [10.1007/978-981-4021-90-6_7, DOI 10.1007/978-981-4021-90-6_7]
   Yeh S.-C., 2012, Transactions on Edutainment, VVIII, P101
   Yoon HJ, 2020, BMC OPHTHALMOL, V20, DOI 10.1186/s12886-020-01471-4
   Zheng L, 2018, 2018 INTERNATIONAL JOINT CONFERENCE ON INFORMATION, MEDIA AND ENGINEERING (ICIME), P6, DOI 10.1109/ICIME.2018.00011
NR 112
TC 8
Z9 8
U1 46
U2 107
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 19
PY 2023
VL 4
AR 1159905
DI 10.3389/frvir.2023.1159905
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WV8
UT WOS:001023294400001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Boban, L
   Strauss, L
   Decroix, H
   Herbelin, B
   Boulic, R
AF Boban, Loen
   Strauss, Lucas
   Decroix, Hugo
   Herbelin, Bruno
   Boulic, Ronan
TI Unintentional synchronization with self-avatar for upper- and lower-body
   movements
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; sense of embodiment; sense of ownership; sense of
   agency; self-avatar follower effect
ID SENSE; AGENCY; EMBODIMENT; GAIT; HAND
AB The subjective experience of embodying an avatar when immersed in virtual reality (VR) is known to support the sense of presence and to help with the interaction in a virtual environment. Virtual embodiment is often thought of as the consequence of replacement of the physical body by a virtual one, with a sense of agency for the avatar obtained by making the avatar's body follow the user's movements. This unidirectional motor link was, however, challenged by studies observing the opposite effect under different circumstances, for example, in a slow-motion context or when an arm movement was snapped on a predefined axis. These reports are, however, still rare or anecdotal. With the idea of a generalized bidirectional relationship between the user and the avatar in mind, we established a methodology to systematically provoke and study the circumstances under which participants follow the movements of their avatar during long repetitive movements without having been instructed to do so. A preliminary study confirmed that our virtual experimental setup, using full-body motion capture, avatar animation, and virtual mirrors, supports a strong sense of agency and body ownership for the avatar while enabling the experimental manipulation of the avatar's movement. In the main experimental study, where participants performed repetitive upper- and lower-body movements while their avatar animations were either congruent or out-of-phase, we observed that almost all participants synchronized with their avatar at least once, for & SIM; 47 % of trials for lower limb movements and & SIM; 38 % for upper limb movements. Participants still reported low agency and ownership for the avatar under the incongruent condition, but, most interestingly, some of them also reported that their movements were not influenced by the avatar despite the behavioral effect. Our methodological approach and results contribute to the characterization of the conditions of occurrence of the self-avatar follower effect and, thereby, to identifying an enriched interaction design for VR, involving complex avatar-user mutual interdependencies.
C1 [Boban, Loen; Strauss, Lucas; Decroix, Hugo; Boulic, Ronan] Ecole Polytech Fed Lausanne EPFL, Sch Comp & Commun Sci, Immers Interact Grp IIG, Lausanne, Switzerland.
   [Boban, Loen; Herbelin, Bruno] Ecole Polytech Fed Lausanne EPFL, Sch Life Sci, Lab Cognit Neurosci LNCO, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne
RP Boban, L (corresponding author), Ecole Polytech Fed Lausanne EPFL, Sch Comp & Commun Sci, Immers Interact Grp IIG, Lausanne, Switzerland.; Boban, L (corresponding author), Ecole Polytech Fed Lausanne EPFL, Sch Life Sci, Lab Cognit Neurosci LNCO, Lausanne, Switzerland.
EM loen.boban@epfl.ch
FU SNFS project "Immersive Embodied Interactions" [200020_207424]; Swiss
   National Science Foundation (SNF) [200020_207424] Funding Source: Swiss
   National Science Foundation (SNF)
FX Funding This work was supported by the SNFS project "Immersive Embodied
   Interactions" grant 200020_207424.
CR Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Burin D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209899
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Cheng M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227880
   Cohn BA, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P74, DOI 10.1109/AIVR50618.2020.00024
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Debarba HG, 2022, IEEE T VIS COMPUT GR, V28, P1880, DOI 10.1109/TVCG.2020.3025175
   Debarba HG, 2018, COMPUT GRAPH-UK, V76, P142, DOI 10.1016/j.cag.2018.09.001
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Farrer C, 2008, BEHAV NEUROL, V19, P53, DOI 10.1155/2008/425267
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fribourg R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P273, DOI 10.1109/VR.2018.8448293
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z
   Giroux M, 2021, ATTEN PERCEPT PSYCHO, V83, P2634, DOI 10.3758/s13414-021-02276-3
   Giroux M, 2019, NEUROSCIENCE, V416, P30, DOI 10.1016/j.neuroscience.2019.07.043
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Gorisse G., 2020, ICAT EGVE 2020 INT C, P9, DOI [10.2312/EGVE.20201261, DOI 10.2312/EGVE.20201261]
   Haggard P, 2012, CURR BIOL, V22, pR390, DOI 10.1016/j.cub.2012.02.040
   Herbelin B. SA, 2016, HUMAN COMPUTER CONFL
   Ito R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343139
   Jun J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174175
   Kalckert A, 2014, CONSCIOUS COGN, V30, P118, DOI 10.1016/j.concog.2014.08.022
   Kannape OA, 2013, J NEUROPHYSIOL, V110, P1837, DOI 10.1152/jn.01042.2012
   Kannape OA, 2012, INT J PSYCHOPHYSIOL, V83, P191, DOI 10.1016/j.ijpsycho.2011.12.006
   Kasahara S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6438, DOI 10.1145/3025453.3025962
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Koilias A, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020018
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Maselli A, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010095
   Maselli A, 2015, COGN PROCESS, V16, pS309, DOI 10.1007/s10339-015-0667-z
   McCabe CS, 2005, RHEUMATOLOGY, V44, P509, DOI 10.1093/rheumatology/keh529
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nguyen A., ACM S APPL PERC 2020, P1
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Porssut T, 2022, bioRxiv, DOI [10.1101/2022.08.10.502929, 10.1101/2022.08.10.502929, DOI 10.1101/2022.08.10.502929]
   Porssut T, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0255554
   Porssut T, 2022, IEEE T VIS COMPUT GR, V28, P3193, DOI 10.1109/TVCG.2021.3057797
   Porssut T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI [10.1109/vr.2019.8797716, 10.1109/VR.2019.8797716]
   Raafat RM, 2009, TRENDS COGN SCI, V13, P420, DOI 10.1016/j.tics.2009.08.002
   Rietzler M, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139145
   Sajid N, 2021, NEURAL COMPUT, V33, P674, DOI 10.1162/neco_a_01357
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Wegner DM, 2004, J PERS SOC PSYCHOL, V86, P838, DOI 10.1037/0022-3514.86.6.838
   Zhao JB, 2022, Arxiv, DOI [arXiv:2112.12466, 10.48550/ARXIV.2112.12466, DOI 10.48550/ARXIV.2112.12466]
NR 53
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 23
PY 2023
VL 4
AR 1073549
DI 10.3389/frvir.2023.1073549
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0HZ4
UT WOS:001020163400001
OA gold
DA 2024-07-18
ER

PT J
AU Personeni, G
   Savescu, A
AF Personeni, Gabin
   Savescu, Adriana
TI Ecological validity of virtual reality simulations in workstation health
   and safety assessment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE ergonomics; occupational safety; risk assesment; virtual reality;
   workstation design
ID EGOCENTRIC DISTANCE PERCEPTION; FIELD-OF-VIEW; SPEED PERCEPTION; FIRE
   EVACUATION; ENVIRONMENT; VALIDATION; DESIGN; IMPACT; PERFORMANCE;
   SYSTEMS
AB The last decade saw a rapid rise of interest in Virtual Reality (VR) technologies, driven by more mature hardware and software tools. Within the ongoing digitalization of industry, VR technologies see uses in workstation design, operator training and tele-operation. This article focuses on how VR can contribute to workstation design including health and safety assessment. VR allows the inclusion of the operator in the workstation design process, permitting evaluation of the design in a safe, interactive and immersive virtual environment. This systematic literature review aims to qualify the ecological validity of VR tools and identify the current obstacles to safe and successful workstation design transfer. A standard systematic literature review procedure is used, on a wide selection of experimental research articles studying the validity of VR, within or outside of industrial contexts. We aggregate results from fundamental research on VR ecological validity regarding user perceptions, movement, cognition and stress. These results are discussed with respect to their influence on workstation OSH assessment in VR. Furthermore, we identify current technological factors and upcoming developments that mediate the validity of VR assessments.
C1 [Personeni, Gabin; Savescu, Adriana] INRS French Res & Safety Inst Prevent Occupat Acc, Vandoeuvre Les Nancy, France.
RP Personeni, G (corresponding author), INRS French Res & Safety Inst Prevent Occupat Acc, Vandoeuvre Les Nancy, France.
EM gabin.personeni@inrs.fr
CR Agethen P, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3230648
   Ahmed F, 2010, P IEEE VIRT REAL ANN, P195, DOI 10.1109/VR.2010.5444791
   Arnold P, 2002, ERGONOMICS, V45, P348, DOI 10.1080/00140130110120510
   Assländer L, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241479
   Bell AK, 2007, IEEE SYS MAN CYBERN, P564
   Bergamasco M, 2006, ADV ROBOTICS, V20, P367, DOI 10.1163/156855306776014367
   Bernal G, 2016, IEEE SYS MAN CYBERN, P2896, DOI 10.1109/SMC.2016.7844679
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   Bhargava A, 2020, VIRTUAL REAL-LONDON, V24, P713, DOI 10.1007/s10055-020-00432-y
   Bodenheimer B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P35
   BORG G, 1970, Scandinavian Journal of Rehabilitation Medicine, V2, P92
   Branzi V, 2017, TRANSPORT RES F-TRAF, V49, P1, DOI 10.1016/j.trf.2017.06.001
   Campbell D.T., 1986, New Directions for Program Evaluation, V1986, P67, DOI DOI 10.1002/EV.1434
   Chessa M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1749, DOI [10.1109/vr.2019.8798155, 10.1109/VR.2019.8798155]
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Damiani L, 2018, IFAC PAPERSONLINE, V51, P624, DOI 10.1016/j.ifacol.2018.08.388
   Davis S, 2015, P 11 AUSTR C INT ENT, V27, P30
   del Cid DA, 2021, ERGONOMICS, V64, P69, DOI 10.1080/00140139.2020.1820083
   Deniaud Christophe., 2015, Journal of Interaction Science, V3, P1, DOI DOI 10.1186/S40166-015-0005-Z
   Dessing JC, 2004, ECOL PSYCHOL, V16, P1, DOI 10.1207/s15326969eco1601_1
   El-Shawa S., 2017, HUM PROXEMIC PREFER, P341, DOI [10.1109/IROS.2017.8202178, DOI 10.1109/IROS.2017.8202178]
   Feldstein IT, 2020, PERCEPTION, V49, P558, DOI 10.1177/0301006620914789
   Feldstein IT, 2020, ACCIDENT ANAL PREV, V137, DOI 10.1016/j.aap.2019.105356
   Feng Y, 2021, SAFETY SCI, V137, DOI 10.1016/j.ssci.2021.105158
   Figueroa JCM, 2018, ADV INTELL SYST, V591, P366, DOI 10.1007/978-3-319-60591-3_33
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Gamberini L, 2008, NEUROPSYCHOLOGIA, V46, P1298, DOI 10.1016/j.neuropsychologia.2007.12.016
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Geuss MN, 2012, J EXP PSYCHOL HUMAN, V38, P1242, DOI 10.1037/a0027524
   Ghinea M, 2018, LECT NOTES COMPUT SC, V10850, P148, DOI 10.1007/978-3-319-95270-3_10
   Giphart JE, 2007, PRESENCE-TELEOP VIRT, V16, P399, DOI 10.1162/pres.16.4.399
   Grassini S., 2020, P 30 EUR SAF REL C 1, P4964, DOI [10.3850/978-981-14-8593-03975-cd, DOI 10.3850/978-981-14-8593-03975-CD]
   Guo ZY, 2020, J MANUF SYST, V56, P525, DOI 10.1016/j.jmsy.2020.07.007
   Hameed A, 2021, INT WORK QUAL MULTIM, P219, DOI 10.1109/QoMEX51781.2021.9465407
   Han Y, 2021, ADV ENG INFORM, V48, DOI 10.1016/j.aei.2021.101298
   HART S G, 1988, P139
   Hatzipanayioti A, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11020204
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hiramoto K, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (IBIOMED), P60, DOI 10.1109/IBIOMED.2018.8534857
   Hofmann J., 2001, MEASURING ILLUSION I, P13, DOI [10.2312/EGVE/EGVE01/013-022, DOI 10.2312/EGVE/EGVE01/013-022]
   Hu B, 2011, INT J IND ERGONOM, V41, P64, DOI 10.1016/j.ergon.2010.10.001
   Hussain Q, 2020, PROCEDIA COMPUT SCI, V170, P18, DOI 10.1016/j.procs.2020.03.005
   Inoue K, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P73
   Janeh O, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3022731
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Kamide Hiroko, 2011, IEEE International Conference on Robotics and Automation, P599
   Karaman E, 2010, C HUM SYST INTERACT, P300, DOI 10.1109/HSI.2010.5514553
   Kawamura S, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P141, DOI 10.1109/3DUI.2016.7460044
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim H, 2018, PSYCHIAT INVEST, V15, P935, DOI 10.30773/pi.2018.06.28.3
   Kinateder M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00043
   Kinateder M, 2014, ACSIS-ANN COMPUT SCI, V2, P313
   KIRCHNER WK, 1958, J EXP PSYCHOL, V55, P352, DOI 10.1037/h0043688
   Kisker J, 2021, CURR PSYCHOL, V40, P3190, DOI 10.1007/s12144-019-00257-2
   Kisker J, 2021, PSYCHOL RES-PSYCH FO, V85, P68, DOI 10.1007/s00426-019-01244-9
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V3, P1
   Kobes M, 2010, PROCEDIA ENGINEER, V3, P37, DOI 10.1016/j.proeng.2010.07.006
   Konishi Y, 2016, ACM SIGGRAPH 2016 VR VILLAGE (SIGGRAPH '16), DOI 10.1145/2945078.2945149
   Lassagne A, 2018, IEEE T HAPTICS, V11, P119, DOI 10.1109/TOH.2017.2755653
   Legkov P, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139172
   Lidestam B, 2019, TRANSPORT RES F-TRAF, V65, P227, DOI 10.1016/j.trf.2019.07.016
   Lin CJ, 2017, APPL ERGON, V64, P66, DOI 10.1016/j.apergo.2017.05.007
   Lin QF, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2720020
   Lipton JI, 2018, IEEE ROBOT AUTOM LET, V3, P179, DOI 10.1109/LRA.2017.2737046
   Liu L, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P219, DOI 10.1109/VR.2009.4811026
   Maïano C, 2011, COMPUT HUM BEHAV, V27, P169, DOI 10.1016/j.chb.2010.07.020
   Makaremi M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188285
   Malone S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.647723
   Mania K, 2003, PRESENCE-TELEOP VIRT, V12, P296, DOI 10.1162/105474603765879549
   Martens MAG, 2019, J PSYCHOPHARMACOL, V33, P1264, DOI 10.1177/0269881119860156
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Mellet E, 2010, HUM BRAIN MAPP, V31, P1065, DOI 10.1002/hbm.20917
   Mottelson A, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139141
   Mullen G, 2021, TIMING TIME PERCEPT, V9, P377, DOI 10.1163/22134468-bja10034
   Muñoz-Saavedra L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010322
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Naceri A, 2009, 2009 COMPUTATION WORLD: FUTURE COMPUTING, SERVICE COMPUTATION, COGNITIVE, ADAPTIVE, CONTENT, PATTERNS, P460, DOI 10.1109/ComputationWorld.2009.91
   Napieralski PE, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010328
   Ng PPW, 2012, INT J PROD RES, V50, P161, DOI 10.1080/00207543.2011.571452
   Ng PPW, 2009, INT J COMPUT INTEG M, V22, P1154, DOI 10.1080/09511920903207456
   O'Malley MK, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P10, DOI 10.1109/HAPTIC.2002.998935
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Or CKL, 2009, INT J IND ERGONOM, V39, P807, DOI 10.1016/j.ergon.2009.01.003
   Paillé D, 2005, PROC SPIE, V5664, P596, DOI 10.1117/12.587744
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Peillard E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P227, DOI [10.1109/VR.2019.8797826, 10.1109/vr.2019.8797826]
   Perez L, 2019, COMPUT IND, V109, P114, DOI 10.1016/j.compind.2019.05.001
   Perry J.S., 2018, IBM developerWorks, P1
   Phillips L, 2012, PRESENCE-VIRTUAL AUG, V21, P119, DOI 10.1162/PRES_a_00100
   Piryankova IV, 2013, DISPLAYS, V34, P153, DOI 10.1016/j.displa.2013.01.001
   Podkosova I, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190845
   Pontonnier C, 2014, J MULTIMODAL USER IN, V8, P199, DOI 10.1007/s12193-013-0138-8
   Popp MM, 2004, PRESENCE-TELEOP VIRT, V13, P61, DOI 10.1162/105474604774048234
   Quertemont E, 2011, PSYCHOL BELG, V51, P109, DOI 10.5334/pb-51-2-109
   Radhakrishnan U, 2021, BEHAV INFORM TECHNOL, V40, P1310, DOI 10.1080/0144929X.2021.1954693
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke BE, 2005, PROC SPIE, V5666, P344, DOI 10.1117/12.610846
   Ryu J, 2005, 2005 International Conference on Cyberworlds, Proceedings, P43
   Schmuckler MA, 2001, INFANCY, V2, P419, DOI 10.1207/S15327078IN0204_02
   Schneider S, 2022, HUM FACTORS, V64, P1210, DOI 10.1177/0018720820987446
   Shen RY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P124, DOI 10.1109/ISMAR-Adjunct.2019.00-65
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Srivastava P, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00050
   Steinicke F, 2010, COMPUT GRAPH-UK, V34, P26, DOI 10.1016/j.cag.2009.12.003
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Sturz BR, 2010, ANIM COGN, V13, P341, DOI 10.1007/s10071-009-0283-3
   Sun J, 2015, SIMUL MODEL PRACT TH, V59, P1, DOI 10.1016/j.simpat.2015.08.003
   Sutcliffe A, 2005, BCS CONF SERIES, P347, DOI 10.1007/1-84628-062-1_22
   Tian RR, 2011, COMPUT IND ENG, V61, P1044, DOI 10.1016/j.cie.2011.06.018
   Tlauka M, 2008, APPL COGNITIVE PSYCH, V22, P69, DOI 10.1002/acp.1341
   van den Broek EL, 2008, LECT NOTES COMPUT SC, V5220, P1, DOI 10.1007/978-3-540-88011-0_1
   Vienne C, 2020, IEEE ACCESS, V8, P29099, DOI 10.1109/ACCESS.2020.2972122
   WATERS TR, 1993, ERGONOMICS, V36, P749, DOI 10.1080/00140139308967940
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Whitney D, 2020, SPR PROC ADV ROBOT, V10, P335, DOI 10.1007/978-3-030-28619-4_28
   Woldegiorgis BH, 2017, J SOC INF DISPLAY, V25, P701, DOI 10.1002/jsid.618
   Wu TH, 2012, HUM FACTOR ERGON MAN, V22, P256, DOI 10.1002/hfm.20267
   Yonelinas AP, 2002, J MEM LANG, V46, P441, DOI 10.1006/jmla.2002.2864
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zhang J, 2016, PSYCHOL RES-PSYCH FO, V80, P1020, DOI 10.1007/s00426-015-0698-1
   Zhang W., 2016, ELECTROMYOGRAPHY EMG, V489, P967, DOI [10.1007/978-3-319-41694-6_92, DOI 10.1007/978-3-319-41694-6_92]
   Zijlstra F.R.H., 1985, CONSTRUCTION SCALE M
   Zou H, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000679
NR 128
TC 0
Z9 0
U1 4
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 16
PY 2023
VL 4
AR 1058790
DI 10.3389/frvir.2023.1058790
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WI0
UT WOS:001023280600001
OA gold
DA 2024-07-18
ER

PT J
AU Wu, Z
   Shi, RK
   Li, ZM
   Jiang, MQ
   Li, Y
   Yu, LY
   Liang, HN
AF Wu, Zhen
   Shi, Rongkai
   Li, Ziming
   Jiang, Mengqi
   Li, Yue
   Yu, Lingyun
   Liang, Hai-Ning
TI Examining cross-modal correspondence between ambient color and taste
   perception in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; human-food interaction; cross-modal correspondence;
   visual perception; user study; tasting
ID FOOD; SWEETNESS; BEHAVIOR; CONTEXT; FLAVOR; IMPACT
AB This research explores the cross-modal correspondence effect of ambient color on people's taste perception in virtual reality (VR). To this end, we designed and conducted two experiments to investigate whether and how taste-congruent ambient colors in VR influence taste perception measured by four aspects: 1) taste ratings of a neutral drink; 2) taste association with virtual environments; 3) associated scenarios when immersed in these virtual environments; and 4) participants' liking of these environments. In Experiment 1, participants adjusted the ambient light with different cross-modal-related colors in the immersive environments and reported their scaling of the Virtual Reality Sickness Questionnaire (VRSQ). Comfortable light intensity for each ambient color was obtained and color recognition problems were observed. In Experiment 2, participants tasted black tea (as the neutral drink), after being exposed to eight different virtual environments with different ambient colors. Results showed that the pink ambient color significantly increased the sweetness ratings. Differences in the color-taste association and environment liking were also observed in the ambient color conditions. Our results provide new insights into the cross-modal correspondence effect on ambient color and taste perception not found in prior work in VR scenarios.
C1 [Wu, Zhen] Hong Kong Univ Sci & Technol, Div Integrat Syst & Design, Hong Kong, Peoples R China.
   [Shi, Rongkai; Li, Ziming; Li, Yue; Yu, Lingyun; Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
   [Jiang, Mengqi] Southern Univ Sci & Technol, Sch Syst Design & Intelligent Mfg, Shenzhen, Peoples R China.
C3 Hong Kong University of Science & Technology; Xi'an Jiaotong-Liverpool
   University; Southern University of Science & Technology
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
EM haining.liang@xjtlu.edu.cn
RI li, chunlin/KFS-0761-2024; Wang, Junzhe/KCK-4991-2024; Jiang,
   mengqi/IQW-5403-2023; Wang, Yitong/KBA-1959-2024
OI Li, Ziming/0009-0004-7529-7176; Li, Yue/0000-0003-3728-218X; Liang,
   Hai-Ning/0000-0003-3600-8955; Jiang, Mengqi/0000-0003-0344-9826
FU Xi'an Jiaotong-Liverpool University (XJTLU) Key Special Fund [KSF-A-03];
   XJTLU Research Development Fund [RDF-17-01-54]; Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [22KJB520038]
FX This work is funded in part by Xi'an Jiaotong-Liverpool University
   (XJTLU) Key Special Fund (KSF-A-03) and XJTLU Research Development Fund
   (RDF-17-01-54), and the Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China (22KJB520038).
CR Arnold Peter, 2017, P 2017 CHI C EXTENDE, P206
   Bangcuyo RG, 2015, FOOD QUAL PREFER, V41, P84, DOI 10.1016/j.foodqual.2014.11.017
   Bonato F, 2004, AVIAT SPACE ENVIR MD, V75, P306
   Cardello A.V., 1994, MEASUREMENT FOOD PRE, P253, DOI DOI 10.1007/978-1-4615-2171-6_10
   Carlson P, 2011, PROCEEDINGS OF THE ASME WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2011, P287
   Chen Y, 2020, FOODS, V9, DOI 10.3390/foods9040465
   CLYDESDALE FM, 1992, J FOOD QUALITY, V15, P19, DOI 10.1111/j.1745-4557.1992.tb00973.x
   Cook M, 2020, ADDICT BEHAV, V106, DOI 10.1016/j.addbeh.2020.106375
   Crisinel AS, 2010, ATTEN PERCEPT PSYCHO, V72, P1994, DOI 10.3758/APP.72.7.1994
   Crisinel AS, 2009, NEUROSCI LETT, V464, P39, DOI 10.1016/j.neulet.2009.08.016
   Crofton E, 2021, FOODS, V10, DOI 10.3390/foods10061154
   Delarue J, 2019, FOOD QUAL PREFER, V75, P78, DOI 10.1016/j.foodqual.2019.02.012
   Dong B, 2013, IEEE ENG MED BIO, P1186, DOI 10.1109/EMBC.2013.6609718
   Elliot AJ, 2007, J EXP PSYCHOL GEN, V136, P154, DOI 10.1037/0096-3445.136.1.154
   Essman M, 2021, BMC PUBLIC HEALTH, V21, DOI 10.1186/s12889-021-10460-1
   Fischler C, 2011, SOC SCI INFORM, V50, P528, DOI 10.1177/0539018411413963
   Gallace Alberto, 2012, Multiple sensorial media advances and applications, P1, DOI DOI 10.4018/978-1-60960-821-7.CH001
   Gotow N, 2021, FOOD QUAL PREFER, V92, DOI 10.1016/j.foodqual.2021.104204
   Grassini S, 2021, ERGONOMICS, V64, P1532, DOI 10.1080/00140139.2021.1941279
   Gusev Dmitri A., 2016, International Conference on Mobile and Wireless Technologies (ICMWT2016). LNEE 391, P197, DOI 10.1007/978-981-10-1409-3_22
   Gusev D. A., 2018, INT J CHILD HLTH HUM, V11, P177
   Halabi O, 2021, MULTIMED TOOLS APPL, V80, P36423, DOI 10.1007/s11042-021-11321-0
   Harrar V, 2011, PERCEPTION, V40, P880, DOI 10.1068/p7040
   Huang FX, 2019, COMPUT HUM BEHAV, V95, P168, DOI 10.1016/j.chb.2019.01.027
   JOHNSON J, 1982, J FOOD SCI, V47, P747, DOI 10.1111/j.1365-2621.1982.tb12706.x
   Keast SJR, 2003, FOOD QUAL PREFER, V14, P111, DOI 10.1016/S0950-3293(02)00110-6
   Kerruish E, 2019, SENSES SOC, V14, P31, DOI 10.1080/17458927.2018.1556952
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Knöferle K, 2012, PSYCHON B REV, V19, P992, DOI 10.3758/s13423-012-0321-z
   Koch C, 2003, J PSYCHOL, V137, P233, DOI 10.1080/00223980309600611
   Kuliga SF, 2015, COMPUT ENVIRON URBAN, V54, P363, DOI 10.1016/j.compenvurbsys.2015.09.006
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Ledoux T, 2013, APPETITE, V71, P396, DOI 10.1016/j.appet.2013.09.006
   Leung CY, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01103-x
   Lipson-Smith R, 2021, VIRTUAL REAL-LONDON, V25, P631, DOI 10.1007/s10055-020-00479-x
   MAGA JA, 1974, CHEM SENS FLAV, V1, P115, DOI 10.1093/chemse/1.1.115
   Magdin M, 2021, VIRTUAL REAL-LONDON, V25, P1029, DOI 10.1007/s10055-021-00506-5
   Moser Christiane., 2013, Proceedings of the 12th International Conference on Interaction Design and Children - IDC'13, P340, DOI 10.1145/2485760.2485828
   Narumi T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P93
   Nishizawa M, 2016, PROCEEDINGS OF THE 2016 WORKSHOP ON MULTIMODAL VIRTUAL AND AUGMENTED REALITY (MVAR 2016), DOI 10.1145/3001959.3001966
   Oberfeld D, 2011, HUM FACTORS, V53, P284, DOI 10.1177/0018720811407331
   Oberfeld D, 2009, J SENS STUD, V24, P797, DOI 10.1111/j.1745-459X.2009.00239.x
   Pan SB, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON DIGITAL PUBLIC HEALTH (DPH '19), P131, DOI 10.1145/3357729.3357759
   Parise C.V., 2013, Oxford library of psychology. The Oxford handbook of synaesthesia, P790
   Piqueras-Fiszman B, 2014, APPETITE, V75, P165, DOI 10.1016/j.appet.2014.01.004
   Piqueras-Fiszman B, 2012, J SENS STUD, V27, P324, DOI 10.1111/j.1745-459X.2012.00397.x
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   So RHY, 2007, LECT NOTES COMPUT SC, V4563, P386
   Spence C., 2014, FLAVOUR, V3, P8, DOI DOI 10.1186/2044-7248-3-8
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Spence Charles, 2021, Iperception, V12, p20416695211018223, DOI 10.1177/20416695211018223
   Spence C, 2020, FOOD QUAL PREFER, V80, DOI 10.1016/j.foodqual.2019.103802
   Spence C, 2019, EXP PSYCHOL, V66, P99, DOI 10.1027/1618-3169/a000439
   Spence C, 2019, FOOD QUAL PREFER, V71, P106, DOI 10.1016/j.foodqual.2018.06.010
   Spence C, 2018, FOOD QUAL PREFER, V68, P226, DOI 10.1016/j.foodqual.2018.03.008
   Spence C, 2016, WOODHEAD PUBL FOOD S, V298, P107, DOI 10.1016/B978-0-08-100350-3.00006-7
   Spence C, 2016, FOOD QUAL PREFER, V50, P117, DOI 10.1016/j.foodqual.2016.02.006
   Spence C, 2010, CHEMOSENS PERCEPT, V3, P68, DOI 10.1007/s12078-010-9067-z
   Stein B E, 1989, J Cogn Neurosci, V1, P12, DOI 10.1162/jocn.1989.1.1.12
   Stelick A, 2018, J FOOD SCI, V83, P2047, DOI 10.1111/1750-3841.14275
   Sugimori E, 2022, FOOD QUAL PREFER, V98, DOI 10.1016/j.foodqual.2022.104539
   Unity, 2019, GLOB ILL
   von Castell C, 2018, HUM FACTORS, V60, P1228, DOI 10.1177/0018720818789524
   Wan XA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01365
   Wang QJ, 2021, FOOD RES INT, V145, DOI 10.1016/j.foodres.2021.110410
   Wang QJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.595788
   Wang QJ, 2019, FOODS, V8, DOI 10.3390/foods8060211
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
NR 68
TC 6
Z9 6
U1 5
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 2
PY 2022
VL 3
AR 1056782
DI 10.3389/frvir.2022.1056782
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UX9
UT WOS:001023244200001
OA gold
DA 2024-07-18
ER

PT J
AU Huang, JR
   Jung, YB
AF Huang, Junru
   Jung, Younbo
TI Perceived authenticity of virtual characters makes the difference
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE artificial agents; virtual characters; perceived authenticity;
   human-machine communication; human-likeness; perceived realness; agency
ID COMPUTER-MEDIATED COMMUNICATION; FICTIONAL CHARACTERS; ROBOTS;
   CREDIBILITY; AVATARS; AGENTS; MODEL; ANTHROPOMORPHISM; EXPECTATION;
   MESSAGE
AB Conventionally, human-controlled and machine-controlled virtual characters are studied separately under different theoretical frameworks based on the ontological nature of the particular virtual character. However, in recent years, the technological advancement has made the boundaries between human and machine agency increasingly blurred. This manuscript proposes a theoretical framework that can explain how various virtual characters, regardless of their ontological agency, can be treated as unique social actors with a focus on perceived authenticity. Specifically, drawing on the authenticity model in computer-mediated communication proposed by Lee (2020) and a typology of virtual characters, a multi-layered perceived authenticity model is proposed to demonstrate how virtual characters do not have to be perceived as humans and yet can be perceived as authentic to their human interactants.
C1 [Huang, Junru; Jung, Younbo] Nanyang Technol Univ, Wee Kee Wee Sch Commun & Informat, Singapore, Singapore.
C3 Nanyang Technological University
RP Huang, JR; Jung, YB (corresponding author), Nanyang Technol Univ, Wee Kee Wee Sch Commun & Informat, Singapore, Singapore.
EM junru001@e.ntu.edu.sg; jungYB@ntu.edu.sg
OI Huang, Junru/0000-0001-8757-5824
CR [Anonymous], 2003, OXFORD HDB AESTHETIC
   [Anonymous], 2000, PRES 2000 3 INT WORK
   Appelman A, 2016, J MASS COMMUN Q, V93, P59, DOI 10.1177/1077699015606057
   Bandura A, 2001, ANNU REV PSYCHOL, V52, P1, DOI 10.1146/annurev.psych.52.1.1
   Bemelmans R, 2012, J AM MED DIR ASSOC, V13, P114, DOI 10.1016/j.jamda.2010.10.002
   Biocca F., 2006, Journal of Computer-Mediated Communication., V3, DOI DOI 10.1111/J.1083-6101.1997.TB00070.X
   Burmester M, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312821
   Busselle R, 2008, COMMUN THEOR, V18, P255, DOI 10.1111/j.1468-2885.2008.00322.x
   Conner T., 2013, THESIS U ILLINOIS CH
   Conner T., 2016, OXFORD HDB MUSIC VIR, DOI [10.1093/oxfordhb/9780199321285.013.8, DOI 10.1093/OXFORDHB/9780199321285.013.8]
   Dautenhahn K, 2003, ROBOTICA, V21, P443, DOI 10.1017/S0263574703004922
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   Davies B., 1991, Social Analysis: The International Journal of Social and Cultural Practice, P42
   de Borst AW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00576
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Deuze M, 2011, MEDIA CULT SOC, V33, P137, DOI 10.1177/0163443710386518
   Elaine Yau, 2020, S CHINA MORNING POST
   Emirbayer M, 1998, AM J SOCIOL, V103, P962, DOI 10.1086/231294
   Enli Gunn., 2014, Mediated authenticity
   Everett A, 2007, PHILOS PHENOMEN RES, V74, P56, DOI 10.1111/j.1933-1592.2007.00003.x
   Fischer K, 2011, INTERACT STUD, V12, P134, DOI 10.1075/is.12.1.06fis
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Franklin S., 1997, Intelligent Agents III. Agent Theories, Architectures, and Languages. ECAI '96 Workshop (ATAL) Proceedings, P21, DOI 10.1007/BFb0013570
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   Golomb J., 1995, SEARCH AUTHENTICITY, DOI [10.1017/CBO9781107415324.004, DOI 10.1017/CBO9781107415324.004]
   Green MC, 2000, J PERS SOC PSYCHOL, V79, P701, DOI 10.1037/0022-3514.79.5.701
   Guignon C, 2008, PHILOS COMPASS, V3, P277, DOI 10.1111/j.1747-9991.2008.00131.x
   Gulz A, 2005, J COMPUT ASSIST LEAR, V21, P405, DOI 10.1111/j.1365-2729.2005.00147.x
   Guzman A., 2018, HUMAN MACHINE COMMUN, P1, DOI DOI 10.3726/B14399
   Guzman AL, 2020, NEW MEDIA SOC, V22, P70, DOI 10.1177/1461444819858691
   Hartmann T., 2008, MEDIATED INTERPERSON, P177, DOI 10.4324/9780203926864
   Holz T, 2009, INT J SOC ROBOT, V1, P83, DOI 10.1007/s12369-008-0002-2
   Hoorn JF, 2003, JPN PSYCHOL RES, V45, P250, DOI 10.1111/1468-5884.00225
   Hossain MA, 2010, INTEGR SER INFORM SY, V28, P441, DOI 10.1007/978-1-4419-6108-2_21
   Jaderberg M, 2019, SCIENCE, V364, P859, DOI 10.1126/science.aau6249
   James E, 2019, POETICS TODAY, V40, P579, DOI 10.1215/03335372-7558164
   Jenkins M., 2018, WASHINGTON POST
   Kanda T, 2008, IEEE T ROBOT, V24, P725, DOI 10.1109/TRO.2008.921566
   Kang HS, 2006, INT J HUM-COMPUT ST, V64, P1173, DOI 10.1016/j.ijhcs.2006.07.003
   Keen S, 2011, NEW LITERARY HIST, V42, P295
   Kellems RO, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4030048
   Kiskola J., 2018, THESIS U TAMPERE
   Lam KY, 2016, J POP CULT, V49, P1107, DOI 10.1111/jpcu.12455
   Leavitt A., 2016, Media Convergence in Japan, P200
   Lee EJ, 2020, J COMPUT-MEDIAT COMM, V25, P60, DOI 10.1093/jcmc/zmz025
   Lee K.M., 2005, Journal of Cultural and Evolutionary Psychology, V3, P159, DOI 10.1556/jcep.3.2005.2.4
   Lee K.M., 2003, P SIGCHI C HUM FACT, P289, DOI DOI 10.1145/642611.642662
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Lee O, 2004, CYBERPSYCHOL BEHAV, V7, P417, DOI 10.1089/cpb.2004.7.417
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Luo XM, 2019, MARKET SCI, V38, P937, DOI 10.1287/mksc.2019.1192
   Marsh C., 2016, WE ATTENDED HATSUNE
   Maslej MM, 2017, PSYCHOL AESTHET CREA, V11, P487, DOI 10.1037/aca0000094
   McMurry E., 2018, ABC NEWS
   Metzger MJ, 2003, COMM YEARB, V27, P293, DOI 10.1207/s15567419cy2701_10
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mou Y, 2017, COMPUT HUM BEHAV, V72, P432, DOI 10.1016/j.chb.2017.02.067
   Muresan A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313084
   Nass C, 1996, INT J HUM-COMPUT ST, V45, P669, DOI 10.1006/ijhc.1996.0073
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703
   Newman GE, 2016, PHILOS COMPASS, V11, P609, DOI 10.1111/phc3.12343
   Nowak KL, 2005, J COMPUT-MEDIAT COMM, V11
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   OLIVER RL, 1977, J APPL PSYCHOL, V62, P480, DOI 10.1037/0021-9010.62.4.480
   OLIVER RL, 1980, J MARKETING RES, V17, P460, DOI 10.2307/3150499
   Park HW, 2017, ACMIEEE INT CONF HUM, P137, DOI 10.1145/2909824.3020213
   Chaves AP, 2020, Arxiv, DOI arXiv:1904.02743
   Peters C. E., 2019, USE MIXED REALITY HR, P1
   Pew Research Center, 2019, Surv. U. S. adults
   Pew Research Center, 2017, Nearly half of Americans use digital voice assistants, mostly on their smartphones
   Pfeifer Rolf, 2001, Understanding Intelligence
   Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Reynolds C. W., 2006, Steering behaviors for autonomous characters, P1
   Shechtman N., 2003, MEDIA INEQUALITY CON, P281, DOI DOI 10.1145/642659.642661
   Shen Xinmei, 2020, S. CHINA MORNING POST
   Shum H. Y., 2018, FRONT INFORM TECH EL
   Solon O., 2018, GOOGLES ROBOT ASSIST
   Sousa A.M., 2016, Post-screen: intermittence+ interference, P117
   Sundar S.S., 2008, Digital media, youth, and credibility, P73, DOI 10.1162/dmal.9780262562324.073
   Sundar SS, 2020, J COMPUT-MEDIAT COMM, V25, P74, DOI 10.1093/jcmc/zmz026
   Sundar SS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300768
   Thue David., 2011, Proceedings of the Seventh AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, P91
   Trivedi A., 2019, International Journal of Advance Research, Ideas and Innovations in Technology, V5, P1308
   Tsang M., 2019, COMMUNICATION
   Turing AM., 1950, MIND, VLIX, P433, DOI [DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/LIX.236.433]
   Turkle S., 2017, ALONE TOGETHER WHY W, DOI DOI 10.5613/RZS.41.3.7
   Turkle S, 2007, INTERACT STUD, V8, P501
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   van Oijen Joost, 2013, Cognitive Agents for Virtual Environments. First International Workshop, CAVE 2012 Held at AAMAS 2012. Revised Selected Papers, P37, DOI 10.1007/978-3-642-36444-0_3
   Varga Somogy., 2020, STANFORD ENCY PHILOS
   Vasalou A, 2009, COMPUT HUM BEHAV, V25, P510, DOI 10.1016/j.chb.2008.11.007
   Wang N, 1999, ANN TOURISM RES, V26, P349, DOI 10.1016/S0160-7383(98)00103-0
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wilson E. J., 1993, Journal of the Academy of Marketing Science, V21, P101, DOI [DOI 10.1007/BF02894421, 10.1007/BF02894421]
   Xue Y., 2020, S CHINA MORNING POST
   Yang H., 2020, 71 INT COMM ASS ANN
   Yao MZ, 2020, J COMPUT-MEDIAT COMM, V25, P4, DOI 10.1093/jcmc/zmz027
   Ye D., 2020, IEEE T NEURAL NETWOR
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yoonjeong Cha, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274299
   Zhang J., 2019, South China Morning Post9 May
   Zhou X., 2020, Virtual Youtuber Kizuna AI: Co -creating human -non -human interaction and celebrity -audience relationship
NR 106
TC 2
Z9 2
U1 9
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 25
PY 2022
VL 3
AR 1033709
DI 10.3389/frvir.2022.1033709
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XA5
UT WOS:001023299100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Cheng, BJ
   Wunderlich, A
   Gramann, K
   Lin, ER
   Fabrikant, SI
AF Cheng, Bingjie
   Wunderlich, Anna
   Gramann, Klaus
   Lin, Enru
   Fabrikant, Sara I. I.
TI The effect of landmark visualization in mobile maps on brain activity
   during navigation: A virtual reality study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cognitive load; assisted navigation; spatial learning; mobile maps;
   landmark visualization; virtual reality; EEG; visuospatial encoding
ID BILATERAL STIMULUS ARRAYS; INDEX FOCUSED ATTENTION; SHORT-TERM-MEMORY;
   ALPHA BAND POWER; WORKING-MEMORY; EEG ALPHA; INDIVIDUAL-DIFFERENCES;
   PEDESTRIAN NAVIGATION; SELECTIVE ATTENTION; COGNITIVE WORKLOAD
AB The frequent use of GPS-based navigation assistance is found to negatively affect spatial learning. Displaying landmarks effectively while providing wayfinding instructions on such services could facilitate spatial learning because landmarks help navigators to structure and learn an environment by serving as cognitive anchors. However, simply adding landmarks on mobile maps may tax additional cognitive resources and thus adversely affect cognitive load in mobile map users during navigation. To address this potential issue, we set up the present study experimentally to investigate how the number of landmarks (i.e., 3 vs. 5 vs. 7 landmarks), displayed on a mobile map one at a time at intersections during turn-by-turn instructions, affects spatial learning, cognitive load, and visuospatial encoding during map consultation in a virtual urban environment. Spatial learning of the environment was measured using a landmark recognition test, a route direction test, and Judgements of Relative Directions (JRDs). Cognitive load and visuospatial encoding were assessed using electroencephalography (EEG) by analyzing power modulations in distinct frequency bands as well as peak amplitudes of event-related brain potentials (ERPs). Behavioral results demonstrate that landmark and route learning improve when the number of landmarks shown on a mobile map increases from three to five, but that there is no further benefit in spatial learning when depicting seven landmarks. EEG analyses show that relative theta power at fronto-central leads and P3 amplitudes at parieto-occipital leads increase in the seven-landmark condition compared to the three- and five-landmark conditions, likely indicating an increase in cognitive load in the seven-landmark condition. Visuospatial encoding indicated by greater theta ERS and alpha ERD at occipital leads with a greater number of landmarks on mobile maps. We conclude that the number of landmarks visualized when following a route can support spatial learning during map-assisted navigation but with a potential boundary-visualizing landmarks on maps benefits users' spatial learning only when the number of visualized landmarks shown does not exceed users' cognitive capacity. These results shed more light on neuronal correlates underlying cognitive load and visuospatial encoding during spatial learning in map-assisted navigation. Our findings also contribute to the design of neuro-adaptive landmark visualization for mobile navigation aids that aim to adapt to users' cognitive load to optimize their spatial learning in real time.
C1 [Cheng, Bingjie; Lin, Enru; Fabrikant, Sara I. I.] Univ Zurich, Dept Geog & Digital Soc Initiat, Zurich, Switzerland.
   [Wunderlich, Anna; Gramann, Klaus] Tech Univ Berlin, Dept Biol Psychol & Neuroergon, Berlin, Germany.
C3 University of Zurich; Technical University of Berlin
RP Cheng, BJ (corresponding author), Univ Zurich, Dept Geog & Digital Soc Initiat, Zurich, Switzerland.
EM bingjie.cheng@geo.uzh.ch
RI sun, jiamin/JPY-2155-2023; liu, sha/JXL-6600-2024; zhang,
   lm/JWP-8874-2024
FU H2020 European Research Council (ERC) Advanced Grant GeoViSense
   [740426]; European Research Council (ERC) [740426] Funding Source:
   European Research Council (ERC)
FX This work was supported by the H2020 European Research Council (ERC)
   Advanced Grant GeoViSense (740426).
   https://cordis.europa.eu/project/id/740426. The funder had no role in
   the study design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Allen G. L., 2003, Human spatial memory, V1st, DOI [10.4324/9781410609984, DOI 10.4324/9781410609984]
   Alvarez GA, 2004, PSYCHOL SCI, V15, P106, DOI 10.1111/j.0963-7214.2004.01502006.x
   Anacta VJA, 2017, GEOJOURNAL, V82, P567, DOI 10.1007/s10708-016-9703-5
   [Anonymous], 2011, Package 'lme4'. Linear mixed-effects models using S4 classes. R package version
   Armougum A, 2019, J ENVIRON PSYCHOL, V65, DOI 10.1016/j.jenvp.2019.101338
   Awh E, 2000, J COGNITIVE NEUROSCI, V12, P840, DOI 10.1162/089892900562444
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Bohbot VD, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14415
   Brügger A, 2019, COGN RES, V4, DOI 10.1186/s41235-019-0156-5
   Bunch RL, 2006, PROF GEOGR, V58, P209, DOI 10.1111/j.1467-9272.2006.00527.x
   Capilla A, 2014, CEREB CORTEX, V24, P550, DOI 10.1093/cercor/bhs343
   Carp J, 2009, PSYCHOPHYSIOLOGY, V46, P336, DOI 10.1111/j.1469-8986.2008.00773.x
   Chrastil ER, 2013, J EXP PSYCHOL LEARN, V39, P1520, DOI 10.1037/a0032382
   Clemenson G. D., 2020, FRONT VIRTUAL REAL, V1, DOI [10.3389/frvir.2020.572122, DOI 10.3389/FRVIR.2020.572122]
   Clemenson GD, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87148-4
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   Colby C.L., 2009, Encyclopedia of Neuroscience, P165
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Credé S, 2020, J ENVIRON PSYCHOL, V67, DOI 10.1016/j.jenvp.2019.101369
   Credé S, 2019, SPAT COGN COMPUT, V19, P190, DOI 10.1080/13875868.2019.1569016
   Dahmani L, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62877-0
   Darken RP, 2002, HUM FAC ER, P493
   Delaux A, 2021, EUR J NEUROSCI, V54, P8256, DOI 10.1111/ejn.15190
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Do TTN, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92246-4
   Doesburg SM, 2009, BRAIN RES, V1303, P97, DOI 10.1016/j.brainres.2009.09.069
   Dong SS, 2015, BRAIN RES, V1616, P146, DOI 10.1016/j.brainres.2015.05.003
   Duckham M, 2010, J LOCAT BASED SERV, V4, P28, DOI 10.1080/17489721003785602
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   Farr AC, 2012, TRANSPORT REV, V32, P715, DOI 10.1080/01441647.2012.712555
   Fenech E.P., 2010, Human Factors and Ergonomics Society Annual Meeting Proceedings, V54, P1926, DOI [DOI 10.1177/154193121005402305, https://doi.org/10.1177/154193121005402305]
   Fischer LF, 2020, ELIFE, V9, DOI 10.7554/eLife.51458
   Fitzmaurice G., 2008, LONGITUDINAL DATA AN, P17, DOI [10.1201/9781420011579-9, DOI 10.1201/9781420011579-9]
   Frankenstein J, 2012, PSYCHOL SCI, V23, P120, DOI 10.1177/0956797611429467
   Fu S., 2006, NEUROERGONOMICS BRAI, P32, DOI [10.1093/acprof:oso/9780195177619.003.0003, DOI 10.1093/ACPROF:OSO/9780195177619.003.0003]
   Fukuda K, 2015, J NEUROSCI, V35, P14009, DOI 10.1523/JNEUROSCI.5003-14.2015
   Gardony AL, 2015, SPAT COGN COMPUT, V15, P246, DOI 10.1080/13875868.2015.1059432
   Gardony AL, 2013, SPAT COGN COMPUT, V13, P319, DOI 10.1080/13875868.2013.792821
   Garlandini S, 2009, LECT NOTES COMPUT SC, V5756, P195, DOI 10.1007/978-3-642-03832-7_12
   Gehrke L, 2018, LECT NOTES ARTIF INT, V11034, P293, DOI 10.1007/978-3-319-96385-3_20
   Gelman A, 2006, TECHNOMETRICS, V48, P432, DOI 10.1198/004017005000000661
   Gevins A., 2003, Theoretical Issues in Ergonomics Science, V4, P113, DOI [DOI 10.1080/14639220210159717, 10.1080/14639220210159717]
   Ghani U, 2020, NEUROSCI BIOBEHAV R, V118, P18, DOI 10.1016/j.neubiorev.2020.07.020
   Gladwin TE, 2005, BIOL PSYCHOL, V68, P309, DOI 10.1016/j.biopsycho.2004.06.004
   Gramann K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97749-8
   Gramann K, 2013, SPAT COGN COMPUT, V13, P1, DOI 10.1080/13875868.2011.589038
   Gramann K, 2010, J COGNITIVE NEUROSCI, V22, P2836, DOI 10.1162/jocn.2009.21369
   Handy TC, 2001, PSYCHOL SCI, V12, P213, DOI 10.1111/1467-9280.00338
   HART S G, 1988, P139
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Hegarty M, 2002, INTELLIGENCE, V30, P425, DOI 10.1016/S0160-2896(02)00116-2
   HEINZE HJ, 1990, ELECTROEN CLIN NEURO, V75, P511, DOI 10.1016/0013-4694(90)90138-A
   Hillyard SA, 1998, P NATL ACAD SCI USA, V95, P781, DOI 10.1073/pnas.95.3.781
   Huang HS, 2012, CARTOGR GEOGR INF SC, V39, P107, DOI 10.1559/15230406392107
   Huffman DJ, 2019, SPAT COGN COMPUT, V19, P93, DOI 10.1080/13875868.2018.1531869
   Ishikawa T, 2019, PROF GEOGR, V71, P197, DOI 10.1080/00330124.2018.1479970
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jensen O, 2002, EUR J NEUROSCI, V15, P1395, DOI 10.1046/j.1460-9568.2002.01975.x
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Kahana MJ, 1999, NATURE, V399, P781, DOI 10.1038/21645
   Kapaj A., 2021, P GISCIENCE 2021 SHO
   Klimesch W, 1998, NEUROSCI LETT, V244, P73, DOI 10.1016/S0304-3940(98)00122-0
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Klimesch W, 2008, BRAIN RES, V1235, P31, DOI 10.1016/j.brainres.2008.06.049
   Klug M, 2022, bioRxiv, DOI [10.1101/2022.09.29.510051, 10.1101/2022.09.29.510051, DOI 10.1101/2022.09.29.510051]
   Klug M, 2022, HUM BRAIN MAPP, V43, P2743, DOI 10.1002/hbm.25832
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Korporaal M, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00032
   KRAMER AF, 1991, PSYCHOPHYSIOLOGY, V28, P425, DOI 10.1111/j.1469-8986.1991.tb00726.x
   Krause CM, 2000, CLIN NEUROPHYSIOL, V111, P2071, DOI 10.1016/S1388-2457(00)00429-6
   Krejtz K, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203629
   Li R, 2020, ANN AM ASSOC GEOGR, V110, P421, DOI 10.1080/24694452.2019.1670611
   Liao H, 2017, CARTOGR GEOGR INF SC, V44, P474, DOI 10.1080/15230406.2016.1174886
   Ligonnière V, 2021, SPAT COGN COMPUT, V21, P320, DOI 10.1080/13875868.2021.1992410
   Liu J, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10855-z
   Lobben AK, 2004, PROF GEOGR, V56, P270
   LUCK SJ, 1990, ELECTROEN CLIN NEURO, V75, P528, DOI 10.1016/0013-4694(90)90139-B
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Maurer U, 2015, BRAIN TOPOGR, V28, P127, DOI 10.1007/s10548-014-0361-y
   McDermott TJ, 2017, NEUROIMAGE, V156, P277, DOI 10.1016/j.neuroimage.2017.05.014
   McKinlay R, 2016, NATURE, V531, P573, DOI 10.1038/531573a
   Meneghetti C, 2021, PSYCHOL RES-PSYCH FO, V85, P634, DOI 10.1007/s00426-019-01270-7
   Merhav M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47971-2
   Montello D.R., 2005, The Cambridge handbook of visuospatial thinking, P257, DOI [DOI 10.1017/CBO9780511610448.008, 10.1017/CBO9780511610448.008]
   Montello D. R., 2002, Cartography and Geographic Information Science, V29, P283, DOI [DOI 10.1559/152304002782008503, 10.1559/152304002782008503]
   Montello DR, 2017, KUNSTL INTELL, V31, P193, DOI 10.1007/s13218-016-0473-5
   Münzer S, 2020, J EXP PSYCHOL-APPL, V26, P73, DOI 10.1037/xap0000237
   Münzer S, 2012, J EXP PSYCHOL-APPL, V18, P18, DOI 10.1037/a0026553
   Naatanen R., 1992, Attention and Brain Function
   Nelli S, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02176-x
   Nishiyori R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82329-7
   Onton J, 2005, NEUROIMAGE, V27, P341, DOI 10.1016/j.neuroimage.2005.04.014
   Oostenveld R, 2002, HUM BRAIN MAPP, V17, P179, DOI 10.1002/hbm.10061
   Palmer J., 2011, TECHNICAL REPORT, P1
   Palva S, 2007, TRENDS NEUROSCI, V30, P150, DOI 10.1016/j.tins.2007.02.001
   PARKS TE, 1966, PSYCHOL REV, V73, P44, DOI 10.1037/h0022662
   Parush A, 2007, LECT NOTES COMPUT SC, V4736, P238
   Pastel S, 2022, VIRTUAL REAL-LONDON, V26, P91, DOI 10.1007/s10055-021-00539-w
   PENNEKAMP P, 1994, J PSYCHOPHYSIOL, V8, P131
   Pfurtscheller G, 1996, INT J PSYCHOPHYSIOL, V24, P39, DOI 10.1016/S0167-8760(96)00066-9
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pion-Tonachini L, 2019, NEUROIMAGE, V198, P181, DOI 10.1016/j.neuroimage.2019.05.026
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   PRESSON CC, 1988, BRIT J DEV PSYCHOL, V6, P378, DOI 10.1111/j.2044-835X.1988.tb01113.x
   Puma S, 2018, INT J PSYCHOPHYSIOL, V123, P111, DOI 10.1016/j.ijpsycho.2017.10.004
   Ramanoël S, 2023, CEREBELLUM, V22, P235, DOI 10.1007/s12311-022-01389-1
   Ratcliffe O, 2022, CURR BIOL, V32, P2121, DOI 10.1016/j.cub.2022.03.045
   Raubal M., 2002, Geographic Information Science. Second International Conference, GIScience 2002. Proceedings (Lecture Notes in Computer Science Vol.2478), P243
   Richter K.-F., 2014, LANDMARKS GISCIENCE
   Ruginski IT, 2019, J ENVIRON PSYCHOL, V64, P12, DOI 10.1016/j.jenvp.2019.05.001
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sauseng P, 2005, EUR J NEUROSCI, V22, P2917, DOI 10.1111/j.1460-9568.2005.04482.x
   Sauseng P, 2010, NEUROSCI BIOBEHAV R, V34, P1015, DOI 10.1016/j.neubiorev.2009.12.006
   Scharinger C, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00006
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Smith ME, 2001, HUM FACTORS, V43, P366, DOI 10.1518/001872001775898287
   Spencer KM, 1999, PSYCHOPHYSIOLOGY, V36, P220, DOI 10.1017/S0048577299971615
   Stipacek A, 2003, NEUROSCI LETT, V353, P193, DOI 10.1016/j.neulet.2003.09.044
   Sugimoto M, 2022, SPAT COGN COMPUT, V22, P161, DOI 10.1080/13875868.2021.1969401
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Tenbrink T, 2020, COGN PROCESS, V21, P287, DOI 10.1007/s10339-020-00952-0
   Uttal DH, 2012, PSYCHOL LEARN MOTIV, V57, P147, DOI 10.1016/B978-0-12-394293-7.00004-2
   Van der Stelt O, 1998, ALCOHOL, V15, P119, DOI 10.1016/S0741-8329(97)00106-7
   Wang Y, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00723
   Wang YK, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00003
   Wascher E, 2014, INT J PSYCHOPHYSIOL, V91, P3, DOI 10.1016/j.ijpsycho.2013.10.006
   Watter S, 2001, PSYCHOPHYSIOLOGY, V38, P998, DOI 10.1111/1469-8986.3860998
   Wei H, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13643
   Wen W, 2013, COGNITIVE SCI, V37, P176, DOI 10.1111/cogs.12005
   Wenig N, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098529
   Wunderlich A, 2021, J ENVIRON PSYCHOL, V77, DOI 10.1016/j.jenvp.2021.101677
   Wunderlich A, 2021, EUR J NEUROSCI, V54, P8336, DOI 10.1111/ejn.15095
   Yesiltepe D, 2021, COGN PROCESS, V22, P369, DOI 10.1007/s10339-021-01012-x
   Zenrin, 2017, SURV US MAPS 2017
   Zhang H, 2014, MEM COGNITION, V42, P1106, DOI 10.3758/s13421-014-0418-x
NR 136
TC 12
Z9 12
U1 8
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 15
PY 2022
VL 3
AR 981625
DI 10.3389/frvir.2022.981625
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WE5
UT WOS:001023277000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Moinnereau, MA
   Oliveira, AA
   Falk, TH
AF Moinnereau, Marc-Antoine
   Oliveira, Alcyr A.
   Falk, Tiago H.
TI Instrumenting a virtual reality headset for at-home gamer experience
   monitoring and behavioural assessment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE biosignals; virtual reality; remote experiment; games user research;
   human influential factors
ID PHYSIOLOGICAL SIGNALS; ENGAGEMENT; INDEX
AB Measuring a gamer's behaviour and perceived gaming experience in real-time can be crucial not only to assess game usability, but to also adjust the game play and content in real-time to maximize the experience per user. For this purpose, affective and physiological monitoring tools (e.g., wearables) have been used to monitor human influential factors (HIFs) related to quality of experience (QoE). Representative factors may include the gamer's level of engagement, stress, as well as sense of presence and immersion, to name a few. However, one of the major challenges the community faces today is being able to accurately transfer the results obtained in controlled laboratory settings to uncontrolled everyday settings, such as the gamer's home. In this paper, we describe an instrumented virtual reality (VR) headset, which directly embeds a number of dry ExG sensors (electroencephalography, EEG; electrocardiography, ECG; and electrooculography, EOG) to allow for gamer behaviour assessment in real-time. A protocol was developed to deliver kits (including the instrumented headset and controllers, laptop with the VR game Half-life Alyx, and a second laptop for data acquisition) to participants' homes during the COVID-19 lockdown. A brief videoconference session was made to provide the participants with instructions, but otherwise the experiment proceeded with minimal experimenter intervention. Eight participants consented to participate and each played the game for roughly 1.5 h. After each gaming session, participants reported their overall experience with an online questionnaire covering aspects of emotions, engagement, immersion, sense of presence, motion sickness, flow, skill, technology adoption, judgement and usability. Here, we describe our obtained findings, as well as report correlations between the subjective ratings and several QoE-related HIFs measured directly from the instrumented headset. Promising results are reported.
C1 [Moinnereau, Marc-Antoine; Falk, Tiago H.] Univ Quebec, Inst Natl Rech Sci INRS EMT, Montreal, PQ, Canada.
   [Oliveira, Alcyr A.] Fed Univ Hlth Sci Porto Alegre, Dept Psychol, Porto Alegre, Brazil.
C3 University of Quebec; Institut national de la recherche scientifique
   (INRS); University of Quebec Montreal
RP Moinnereau, MA (corresponding author), Univ Quebec, Inst Natl Rech Sci INRS EMT, Montreal, PQ, Canada.
EM marc-antoine.moinnereau@inrs.ca
FU Natural Sciences and Engineering Research Council of Canada
   [RGPIN-2021-03246]
FX Funding The authors acknowledge funding from the Natural Sciences and
   Engineering Research Council of Canada (RGPIN-2021-03246).
CR [Anonymous], 1991, J CLIN NEUROPHYSIOL, V8, P200, DOI 10.1097/00004691-199104000-00007
   [Anonymous], 2016, IEEE, DOI DOI 10.1109/QOMEX.2016.7498964
   Apostolopoulos JG, 2012, P IEEE, V100, P974, DOI 10.1109/JPROC.2011.2182069
   Arad E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197153
   Arndt S, 2018, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON MULTIMEDIA CONTENT ANALYSIS IN SPORTS (MMSPORTS'18), P45, DOI 10.1145/3265845.3265848
   Bitkina OV, 2021, INT J IND ERGONOM, V86, DOI 10.1016/j.ergon.2021.103193
   Burns CG, 2015, INT J HUM-COMPUT ST, V73, P107, DOI 10.1016/j.ijhcs.2014.09.002
   Cassani R, 2020, IEEE SYST MAN CYBERN, V6, P20, DOI 10.1109/MSMC.2019.2953627
   Chung J, 2012, INT J HUM-COMPUT INT, V28, P511, DOI 10.1080/10447318.2011.627298
   Clerico A, 2018, FRONT COMPUT NEUROSC, V11, DOI [10.3389/fncom.2017.00115, 10.3389/Thcom.2017.00115]
   Crowley Katie, 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P276, DOI 10.1109/ICALT.2010.81
   Dehais F, 2018, IEEE SYS MAN CYBERN, P544, DOI 10.1109/SMC.2018.00102
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   dos Santos EM, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101812
   Fischer NL, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00166
   Gautam A, 2018, EUR SIGNAL PR CONF, P1162, DOI 10.23919/EUSIPCO.2018.8553191
   Ju Y.S., 2019, Proceedings, V21, P446
   Kam JWY, 2019, NEUROIMAGE, V184, P119, DOI 10.1016/j.neuroimage.2018.09.012
   Kharoub H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224861
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kougioumtzidis G, 2022, IEEE ACCESS, V10, P19507, DOI 10.1109/ACCESS.2022.3149592
   Kuwahara A., 2022, Cognitive Robotics, V2, P50, DOI [10.1016/J.COGR.2022.01.003, DOI 10.1016/J.COGR.2022.01.003]
   Laghari KUR, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1300
   Lee S, 2019, IEEE T BIO-MED ENG, V66, P1055, DOI 10.1109/TBME.2018.2866550
   Lim S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071669
   López A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071505
   Martínez-Rodrigo A, 2019, INT J NEURAL SYST, V29, DOI 10.1142/S0129065718500387
   McMahan T, 2015, PROCEDIA MANUF, V3, P2303, DOI 10.1016/j.promfg.2015.07.376
   Metzger F., 2018, AUTONOMOUS CONTROL R
   Moinnereau M.-A., 2022, MEASURING HUMAN INFL
   Moinnereau Marc-Antoine, 2022, Qual User Exp, V7, P5, DOI 10.1007/s41233-022-00052-1
   Muñoz JE, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00683
   Murphy D, 2019, Arxiv, DOI arXiv:1910.01586
   Pallavicini F, 2019, SIMULAT GAMING, V50, P136, DOI 10.1177/1046878119831420
   Patrao B, 2016, INT J ONLINE ENG, V12, P37, DOI 10.3991/ijoe.v12i04.5098
   Perkis A, 2020, Arxiv, DOI arXiv:2007.07032
   POPE AT, 1995, BIOL PSYCHOL, V40, P187, DOI 10.1016/0301-0511(95)05116-3
   Poppelaars ES, 2021, BIOL PSYCHOL, V160, DOI 10.1016/j.biopsycho.2021.108043
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Regal G., 2018, 2018 Tenth international conference on quality of multimedia experience (QoMEX), P1, DOI DOI 10.1109/QOMEX.2018.8463296
   Rosanne O., 2019, 2019 9 INT IEEE EMBS, DOI [10.1109/NER, DOI 10.1109/NER]
   Sousa I, 2020, J NETW COMPUT APPL, V158, DOI 10.1016/j.jnca.2020.102594
   Tcha-Tokey K., 2016, Int. J. Virtual Real, V16, P33, DOI DOI 10.20870/IJVR.2016.16.1.2880
   Tiwari A, 2019, IEEE SYS MAN CYBERN, P4149, DOI 10.1109/SMC.2019.8914038
   Tobon DP, 2016, IEEE T BIO-MED ENG, V63, P1613, DOI 10.1109/TBME.2014.2355135
   Toivanen M, 2015, J EYE MOVEMENT RES, V8
   van Kessel C., 2020, J CURRICULUM STUD, V2, P1, DOI [https://doi.org/10.46303/jcsr.2020.7, DOI 10.9790/5728-1604010118]
   Wang Y, 2017, IEEE WIREL COMMUN, V24, P102, DOI 10.1109/MWC.2016.1500184WC
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wiederhold B.K., 2003, CYBERPSYCHOLOGY MIND, P176
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yong Min Kim, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P1274, DOI 10.1177/1071181319631080
   Zhang SF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110461
NR 54
TC 4
Z9 5
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 12
PY 2022
VL 3
AR 971054
DI 10.3389/frvir.2022.971054
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0HN9
UT WOS:001020151900001
OA gold
DA 2024-07-18
ER

PT J
AU Pratviel, Y
   Bouni, A
   Deschodt-Arsac, V
   Larrue, F
   Arsac, LM
AF Pratviel, Yvan
   Bouni, Alix
   Deschodt-Arsac, Veronique
   Larrue, Florian
   Arsac, Laurent M.
TI Avatar embodiment in VR: Are there individual susceptibilities to
   visuo-tactile or cardio-visual stimulations?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE multisensory integration; embodiment; virtual avatar; self location;
   self identification; perspective taking; interoception; mental rotation
ID HEARTBEAT AWARENESS; EMPATHY QUOTIENT; BODY-OWNERSHIP; SELF-LOCATION;
   EXPERIENCE; INTEGRATION; ILLUSIONS; ALTERS; BRAIN; EYE
AB Virtual reality has obvious potential to help humans developing/recovering brain functions, which operates through modulation of multisensory inputs. Some interventions using VR rely on the need to embody a virtual avatar, which stimulates cognitive-motor adaptations. Recent research has shown that embodiment can be facilitated by synchronizing natural sensory inputs with their visual redundancy on the avatar, e.g., the user's heartbeat flashing around its avatar (cardio-visual stimulation) or the user's body being physically stroked while the avatar is touched in synchronized conditions (visuo-tactile stimulation). While different full-body illusions have proven obvious interest in health and disease, it is unknown to date whether individual susceptibilities to illusion are equivalent with respect to cardio-visual or visuo-tactile stimulations. In fact, a number of factors like interoception, vestibular processing, a pronounced visual dependence, a specific cognitive ability for mental rotations, or user traits and habits like empathy and video games practice may interfere with the multifaceted construct of bodily self-consciousness, the conscious experience of owning a body in space from which the world is perceived. Here, we evaluated a number of dispositions in twenty-nine young and healthy participants submitted alternatively to cardio-visual and visuo-tactile stimulations to induce full-body illusions. Three components of bodily self-consciousness consensually identified in recent research, namely self-location, perspective taking and self-identification were quantified by self-reported feeling (questionnaires), and specific VR tasks used before and after multisensory stimulations. VR tasks allowed measuring self-location in reference to a virtual ball rolling toward the participant, perspective taking through visuomotor response times when mentally rotating an avatar suddenly presented at different angles, and self-identification through heart rate dynamics in response to a threatening stimulus applied to the (embodied) avatar. Full-body illusion was evidenced by self-reported quotations of self-identification to the avatar reaching scores in agreement with the literature, lower reaction times when taking the perspective of the avatar and a marked drop in heart rate showing obvious freezing reaction changes when the user saw the avatar being pierced by a spear. Changes in bodily self-consciousness components are not significantly dependent on the type of multisensory stimulation (visuo-tactile or cardio-visual). A principal component analysis demonstrated the lack of covariation between those components, pointing to the relative independence of self-location, perspective taking and self-identification measurements. Moreover, none of these components showed significant covariations with any of the individual dispositions. These results support the hypothesis that cardio-visual and visuo-tactile stimulations affect the main components of bodily self-consciousness in an extent that, in average, is mostly independent of individual perceptive-cognitive profiles, at least in healthy young people. Although this is an important observation at group level, which indicates a similar probability of inducing embodiment with either cardio-visual or visuo-tactile stimulations in VR, these results do not discard the fact that some individuals might have higher susceptibility to specific sensory inputs, which would represent a target to adapt efficient VR stimulations.
C1 [Pratviel, Yvan; Bouni, Alix; Deschodt-Arsac, Veronique; Arsac, Laurent M.] Univ Bordeaux, Lab IMS, CNRS, UMR 5218, Bordeaux, France.
   [Pratviel, Yvan; Bouni, Alix; Larrue, Florian] Ctr Aquitain Technol Informat & Elect, Talence, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Bordeaux; CNRS - Institute for Engineering & Systems Sciences (INSIS)
RP Arsac, LM (corresponding author), Univ Bordeaux, Lab IMS, CNRS, UMR 5218, Bordeaux, France.
EM laurent.arsac@u-bordeaux.fr
FU ANRT [2019/0682]
FX A CIFRE grant No. 2019/0682 was awarded by the ANRT to the Centre
   Aquitain des Technologies de l'Information et Electroniques, to support
   the work of graduate student YP.
CR Adenauer H, 2010, PSYCHOPHYSIOLOGY, V47, P315, DOI 10.1111/j.1469-8986.2009.00940.x
   AGLIOTI S, 1995, CURR BIOL, V5, P679, DOI 10.1016/S0960-9822(95)00133-3
   Ainley V, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00554
   Aspell JE, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006488
   Aspell JE, 2013, PSYCHOL SCI, V24, P2445, DOI 10.1177/0956797613498395
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Barra J, 2020, NEUROPHYSIOL CLIN, V50, P455, DOI 10.1016/j.neucli.2020.10.011
   Blanke O, 2005, J NEUROSCI, V25, P550, DOI 10.1523/JNEUROSCI.2612-04.2005
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Blefari ML, 2017, EUR J NEUROSCI, V45, P1300, DOI 10.1111/ejn.13567
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Bradley MM, 2001, EMOTION, V1, P276, DOI 10.1037//1528-3542.1.3.276
   Carey M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39168-4
   Deroualle D, 2015, NEUROPSYCHOLOGIA, V79, P175, DOI 10.1016/j.neuropsychologia.2015.08.022
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Falconer CJ, 2012, EXP PSYCHOL, V59, P332, DOI 10.1027/1618-3169/a000161
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   Fittipaldi S, 2020, NEUROIMAGE, V212, DOI 10.1016/j.neuroimage.2020.116677
   Georgiou E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00502
   Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x
   Hecht D, 2007, CYBERPSYCHOL BEHAV, V10, P243, DOI 10.1089/cpb.2006.9962
   Heydrich L, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.599429
   Heydrich L, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27698-2
   Keenaghan S, 2020, CONSCIOUS COGN, V78, DOI 10.1016/j.concog.2020.102882
   KENNEDY RS, 1975, AVIAT SPACE ENVIR MD, V46, P1349
   Kessler K, 2010, FRONT PSYCHOL, V1, DOI [10.3389/fphys.2010.00213, 10.3389/fpsyg.2010.00213]
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   Lochhead I, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.820237
   Longo MR, 2009, J NEUROSCI, V29, P12125, DOI 10.1523/JNEUROSCI.3072-09.2009
   Lopez C, 2015, NEUROPHYSIOL CLIN, V45, P241, DOI 10.1016/j.neucli.2015.09.001
   Macauda G, 2015, EUR J NEUROSCI, V41, P810, DOI 10.1111/ejn.12809
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   MATLAB, 2021, VERS 9 9 0 R2020B
   Murphy J, 2020, Q J EXP PSYCHOL, V73, P115, DOI 10.1177/1747021819879826
   Nakul E, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63643-y
   O'Kane SH, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0233243
   Pomés A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00908
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Pratviel Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79885-9
   Preuss N, 2019, J EXP PSYCHOL HUMAN, V45, P209, DOI 10.1037/xhp0000597
   Ronchi R, 2015, NEUROPSYCHOLOGIA, V70, P11, DOI 10.1016/j.neuropsychologia.2015.02.010
   Salomon R, 2017, COGNITION, V166, P174, DOI 10.1016/j.cognition.2017.05.028
   Salomon R, 2013, FRONT BEHAV NEUROSCI, V7, DOI 10.3389/fnbeh.2013.00065
   SCHANDRY R, 1981, PSYCHOPHYSIOLOGY, V18, P483, DOI 10.1111/j.1469-8986.1981.tb02486.x
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seiryte A, 2015, PERS INDIV DIFFER, V77, P112, DOI 10.1016/j.paid.2014.12.048
   Serino A, 2013, CONSCIOUS COGN, V22, P1239, DOI 10.1016/j.concog.2013.08.013
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Suzuki K, 2013, NEUROPSYCHOLOGIA, V51, P2909, DOI 10.1016/j.neuropsychologia.2013.08.014
   Tajadura-Jiménez A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040682
   Tsakiris M, 2007, CONSCIOUS COGN, V16, P645, DOI 10.1016/j.concog.2007.05.012
   Tsakiris M, 2011, P ROY SOC B-BIOL SCI, V278, P2470, DOI 10.1098/rspb.2010.2547
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   van Elk M, 2014, PSYCHOL RES-PSYCH FO, V78, P18, DOI 10.1007/s00426-013-0486-8
   Wallman-Jones A, 2021, INT J PSYCHOPHYSIOL, V166, P38, DOI 10.1016/j.ijpsycho.2021.05.002
   Wraga M, 2000, PERCEPTION, V29, P1361, DOI 10.1068/p2837
NR 61
TC 0
Z9 0
U1 2
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 6
PY 2022
VL 3
AR 954808
DI 10.3389/frvir.2022.954808
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XA6
UT WOS:001023299200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Grasse, KM
   Kreminski, M
   Wardrip-Fruin, N
   Mateas, M
   Melcer, EF
AF Grasse, Katelyn M.
   Kreminski, Max
   Wardrip-Fruin, Noah
   Mateas, Michael
   Melcer, Edward F.
TI Using Self-Determination Theory to Explore Enjoyment of Educational
   Interactive Narrative Games: A Case Study of <i>Academical</i>
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE interactive narrative; game-based learning; enjoyment;
   self-determination theory; case study
ID RESPONSIBLE CONDUCT; SATISFACTION; CHARACTER; DESIGN; MODEL
AB Choice-based interactive storytelling games such as Academical, our responsible conduct of research training game, show great promise as a novel way of providing efficacious ethics training. However, much work remains to determine what factors of such games contribute to their advantages over traditional text-based training tools, especially if we hope to further improve their enjoyment, engagement and efficacy. In this article, we present a case study exploring how the motivational factors of Self-Determination Theory (SDT) underlie players' perceived most and least enjoyable experiences arising from the design of Academical. Specifically, we discuss how certain elements of Academical's design influence different SDT factors and subsequently player experience, as well as how such elements can be changed to further improve the game. Furthermore, our work highlights potential limitations of existing conceptualizations for the relatedness factor of SDT-discussing ways that it can be extended to properly understand player enjoyment within single-player educational interactive narrative games.
C1 [Grasse, Katelyn M.; Melcer, Edward F.] Univ Calif Santa Cruz, Computat Media Dept, Alternat Learning Technol & Games Lab, Santa Cruz, CA 95060 USA.
   [Kreminski, Max; Wardrip-Fruin, Noah; Mateas, Michael] Univ Calif Santa Cruz, Computat Media Dept, Express Intelligence Studio, Santa Cruz, CA USA.
C3 University of California System; University of California Santa Cruz;
   University of California System; University of California Santa Cruz
RP Grasse, KM (corresponding author), Univ Calif Santa Cruz, Computat Media Dept, Alternat Learning Technol & Games Lab, Santa Cruz, CA 95060 USA.
EM katy@ucsc.edu
CR Adachi P.J.C., 2018, Motiv. Sci., V4, P78, DOI DOI 10.1037/MOT0000063
   Ainley M, 2011, CONTEMP EDUC PSYCHOL, V36, P4, DOI 10.1016/j.cedpsych.2010.08.001
   AlexanderZook StephenLee-Urban, 2012, P INT C FDN DIG GAM, P164, DOI DOI 10.1145/2282338.2282371
   Angeli C, 2004, ETR&D-EDUC TECH RES, V52, P23, DOI 10.1007/BF02504715
   [Anonymous], 2011, Glued to Games: How Video Games Draw Us, DOI DOI 10.4324/9781410602428
   Antes AL, 2010, ACAD MED, V85, P519, DOI 10.1097/ACM.0b013e3181cd1cc5
   Aylett RS, 2005, LECT NOTES ARTIF INT, V3661, P305
   Azadvar A., 2018, P 13 INT C FDN DIGIT
   Bopp JA, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P313, DOI 10.1145/3311350.3347169
   Busselle R, 2009, MEDIA PSYCHOL, V12, P321, DOI 10.1080/15213260903287259
   Camingue J., 2020, International Conference on the Foundations of Digital Games (FDG'20), P1, DOI DOI 10.1145/3402942.3403004
   Christopoulos D., 2011, Proceedings of the 2011 3rd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2011), P84, DOI 10.1109/VS-GAMES.2011.18
   Cuerdo MAM, 2021, IEEE CONF COMPU INTE, P217, DOI [10.1109/CoG52621.2021.9618894, 10.1109/COG52621.2021.9618894]
   Cuerdo MAM, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382863
   Danilicheva P, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P333, DOI 10.1109/CW.2009.57
   Dechering A., 2018, P 13 INT C FDN DIG G, P1
   Dickey MD, 2006, ETR&D-EDUC TECH RES, V54, P245, DOI 10.1007/s11423-006-8806-y
   Diez JDS, 2020, LECT NOTES COMPUT SC, V12434, P69, DOI 10.1007/978-3-030-61814-8_5
   Gobel S., 2013, Serious Games and Virtual Worlds in Education, Professional Development, and Healthcare, P74
   Gobel S., 2009, NARRATIVE, V14, P16
   Grasse K. M., 2022, GAMES NARRATIVE THEO, P173, DOI [10.1007/978-3-030-81538-7_12, DOI 10.1007/978-3-030-81538-7_12]
   Grasse KM, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451722
   Green M. C., 2021, TRANSPORTATION NARRA, V87
   Green MC, 2014, J COMMUN, V64, P479, DOI 10.1111/jcom.12093
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hodhod R, 2011, LECT NOTES COMPUT SC, V6530, P1, DOI 10.1007/978-3-642-18452-9_1
   Johnson D, 2018, INT J HUM-COMPUT ST, V118, P38, DOI 10.1016/j.ijhcs.2018.05.003
   Jui-Feng Weng, 2011, 2011 11th IEEE International Conference on Advanced Learning Technologies (ICALT 2011), P336, DOI 10.1109/ICALT.2011.104
   Kalichman M, 2016, ACAD MED, V91, pE10, DOI 10.1097/ACM.0000000000001442
   Kavli K., 2012, Proceeding of the 16th international academic mindtrek conference, P83, DOI [DOI 10.1145/2393132.2393150, 10.1145/2393132.2393150]
   Kickmeier-Rust M. D., 2008, P 1 INT WORKSH STOR
   Law ELC, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P257, DOI 10.1145/3242671.3242683
   Magerko Brian., 2007, J GAME DEV, V2, P25
   Mann K, 2009, ADV HEALTH SCI EDUC, V14, P595, DOI 10.1007/s10459-007-9090-2
   Melcer E., 2015, The Proceedings of the 10th International Conference on the Foundations of Digital Games (FDG 2015), June 22-25, 2015, Pacific Grove, CA, USA
   Melcer E.F., 2020, INT C FDN DIGITAL GA, V1-12, P78, DOI [10.1145/3402942.3403005, DOI 10.1145/3402942.3403005]
   Melcer EF, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382973
   Melcer EF, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173840
   Melcer EdwardF., 2020, GAME USER EXPERIENCE, P265, DOI DOI 10.1007/978-3-030-37643-7_12
   Mestre D., 2006, IMMERSION PRESENCE T
   Nguyen THD, 2018, ENTERTAIN COMPUT, V26, P88, DOI 10.1016/j.entcom.2018.02.002
   Oliver MB, 2016, PSYCHOL POP MEDIA CU, V5, P390, DOI 10.1037/ppm0000066
   Padilla-Zea N, 2014, COMPUT HUM BEHAV, V31, P461, DOI 10.1016/j.chb.2013.04.020
   Peng W, 2012, MEDIA PSYCHOL, V15, P175, DOI 10.1080/15213269.2012.673850
   Plemmons DK, 2013, J EMPIR RES HUM RES, V8, P95, DOI 10.1525/jer.2013.8.2.95
   Powell ST, 2007, SCI ENG ETHICS, V13, P249, DOI 10.1007/s11948-007-9012-y
   Przybylski AK, 2010, REV GEN PSYCHOL, V14, P154, DOI 10.1037/a0019440
   Riedl MO, 2008, International Transactions on Systems Science and Applications, V4, P23
   Roth Christian, 2016, Experiencing Interactive Storytelling
   Roth Christian., 2016, Proceedings of the 1st International Workshop on Multimedia Alternate Realities. AltMM'16, P31, DOI DOI 10.1145/2983298.2983302
   Rowe J., 2011, International Journal of Artificial Intelligence in Education, V21, P115, DOI [DOI 10.3233/JAI-2011-019, 10.3233/JAI-2011-019]
   Rowe J.P., 2010, 6 ART INT INT DIG EN
   RUBIN AM, 1987, HUM COMMUN RES, V14, P246, DOI 10.1111/j.1468-2958.1987.tb00129.x
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Ryan RM, 2017, SELF-DETERMINATION THEORY: BASIC PSYCHOLOGICAL NEEDS IN MOTIVATION, DEVELOPMENT, AND WELLNESS, P1, DOI 10.1521/978.14625/28806
   Dias LPS, 2018, TELEMAT INFORM, V35, P213, DOI 10.1016/j.tele.2017.11.002
   Schneider R, 2001, STYLE, V35, P607
   Schramm H, 2008, COMMUNICATIONS-GER, V33, P385, DOI 10.1515/COMM.2008.025
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   SMITH M, 1994, CINEMA J, V33, P34, DOI 10.2307/1225898
   Song QL, 2012, PHYSCS PROC, V33, P1798, DOI 10.1016/j.phpro.2012.05.287
   Spierling U, 2008, LECT NOTES COMPUT SC, V5080, P150
   Starks K, 2016, LECT NOTES COMPUT SC, V9894, P89, DOI 10.1007/978-3-319-45841-0_8
   Stavroulia KE, 2019, INT J EMERG TECHNOL, V14, P18, DOI 10.3991/ijet.v14i07.9946
   Tamborini R, 2010, J COMMUN, V60, P758, DOI 10.1111/j.1460-2466.2010.01513.x
   Tyack A., 2017, Proceedings of the 29th Australian Conference on Computer-Human Interaction, P422, DOI [10.1145/3152771.3156149, DOI 10.1145/3152771.3156149]
   Tyack A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376723
   Villareale J., 2020, INT C FDN DIG GAM, P1, DOI 10.1145/3402942.3403011
   Wang PC, 2016, LECT NOTES COMPUT SC, V10045, P270, DOI 10.1007/978-3-319-48279-8_24
   Watson S., 2007, Proceedings of AISB'07. The Society for the Study of Artificial Intelligence and the Simulation of Behaviour (AISB), P446
   Weiss SA, 2008, LECT NOTES COMPUT SC, V5093, P475
   Wolf Mark., 2003, The Video Game Theory Reader
   Zhang L, 2021, IEEE T CLOUD COMPUT, V9, P1117, DOI [10.1109/TCC.2019.2903254, 10.1109/vs-games.2019.8864531]
NR 74
TC 1
Z9 1
U1 3
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 16
PY 2022
VL 3
AR 847120
DI 10.3389/frvir.2022.847120
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZS3
UT WOS:001019271000001
OA gold
DA 2024-07-18
ER

PT J
AU Gnacek, M
   Broulidakis, J
   Mavridou, I
   Fatoorechi, M
   Seiss, E
   Kostoulas, T
   Balaguer-Ballester, E
   Kiprijanovska, I
   Rosten, C
   Nduka, C
AF Gnacek, Michal
   Broulidakis, John
   Mavridou, Ifigeneia
   Fatoorechi, Mohsen
   Seiss, Ellen
   Kostoulas, Theodoros
   Balaguer-Ballester, Emili
   Kiprijanovska, Ivana
   Rosten, Claire
   Nduka, Charles
TI emteqPRO-Fully Integrated Biometric Sensing Array for Non-Invasive
   Biomedical Research in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; biosensors; affect; electromyography;
   photoplethysmography; biomedical measurement; valence; arousal
ID PHOTOPLETHYSMOGRAPHY; RESPONSES
AB Virtual Reality (VR) enables the simulation of ecologically validated scenarios, which are ideal for studying behaviour in controllable conditions. Physiological measures captured in these studies provide a deeper insight into how an individual responds to a given scenario. However, the combination of the various biosensing devices presents several challenges, such as efficient time synchronisation between multiple devices, replication between participants and settings, as well as managing cumbersome setups. Additionally, important salient facial information is typically covered by the VR headset, requiring a different approach to facial muscle measurement. These challenges can restrict the use of these devices in laboratory settings. This paper describes a solution to this problem. More specifically, we introduce the emteqPRO system which provides an all-in-one solution for the collection of physiological data through a multi-sensor array built into the VR headset. EmteqPRO is a ready to use, flexible sensor platform enabling convenient, heterogenous, and multimodal emotional research in VR. It enables the capture of facial muscle activations, heart rate features, skin impedance, and movement data-important factors for the study of emotion and behaviour. The platform provides researchers with the ability to monitor data from users in real-time, in co-located and remote set-ups, and to detect activations in physiology that are linked to arousal and valence changes. The SDK (Software Development Kit), developed specifically for the Unity game engine enables easy integration of the emteqPRO features into VR environments.
C1 [Gnacek, Michal] Bournemouth Univ, Fac Media & Commun, Ctr Digital Entertainment, Poole, England.
   [Gnacek, Michal; Broulidakis, John; Mavridou, Ifigeneia; Fatoorechi, Mohsen; Kiprijanovska, Ivana; Nduka, Charles] Sussex Innovat Ctr, Emteq Labs, Brighton, England.
   [Broulidakis, John] Univ Southampton, Dept Psychiat, Southampton, England.
   [Broulidakis, John] Northeastern Univ, Coll Sci, Dept Psychol, Boston, MA USA.
   [Seiss, Ellen] Bournemouth Univ, Fac Sci Technol, Interdisciplinary Neurosci Res Ctr, Dept Psychol, Poole, England.
   [Kostoulas, Theodoros] Univ Aegean, Dept Informat & Commun Syst Engn, Samos, Greece.
   [Balaguer-Ballester, Emili] Bournemouth Univ, Fac Sci Technol, Interdisciplinary Neurosci Res Ctr, Dept Comp & Informat, Poole, England.
   [Rosten, Claire] Univ Brighton, Sch Sport & Hlth Sci, Brighton, England.
C3 Bournemouth University; University of Southampton; Northeastern
   University; Bournemouth University; University of Aegean; Bournemouth
   University; University of Brighton
RP Nduka, C (corresponding author), Sussex Innovat Ctr, Emteq Labs, Brighton, England.
EM info@emteqlabs.com
OI Mavridou, Ifigeneia/0000-0003-3800-6531; Rosten,
   Claire/0000-0002-1192-7552; Broulidakis, Manoussos/0000-0001-9314-9100;
   Gnacek, Michal/0000-0003-0935-4430
FU Bournemouth University; Emteq ltd. via the Centre for Digital
   Entertainment (EPSRC Grant) [EP/L016540/1]; NIHR Invention for
   Innovation (i4i) Programme [NIHR201283]; National Institutes of Health
   Research (NIHR) [NIHR201283] Funding Source: National Institutes of
   Health Research (NIHR)
FX This work is supported by Bournemouth University and Emteq ltd. via the
   Centre for Digital Entertainment (EPSRC Grant No. EP/L016540/1). This
   work was also partially funded by the NIHR Invention for Innovation
   (i4i) Programme (Grant No. NIHR201283).
CR Al-Rawhani MA, 2020, IEEE T BIO-MED ENG, V67, P614, DOI 10.1109/TBME.2019.2919192
   Alexandratos V, 2014, INT CONF ACOUST SPEE
   Araujo Ruy. Soprani. S., 2014, NEUROTECHNIX 2014 P, P49, DOI [10.5220/0005138900490055, DOI 10.5220/0005138900490055]
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Boxtel Anton. Van., 2010, P MEASURING BEHAV
   Branson Richard D, 2004, Respir Care Clin N Am, V10, P359, DOI 10.1016/j.rcc.2004.04.003
   CACIOPPO JT, 1988, J PERS SOC PSYCHOL, V54, P592, DOI 10.1037/0022-3514.54.4.592
   CACIOPPO JT, 1986, J PERS SOC PSYCHOL, V50, P260, DOI 10.1037/0022-3514.50.2.260
   Chee Siang, 2018, SCOPING REV EXPLORIN, DOI [10.2312/egve.20181325, DOI 10.2312/EGVE.20181325]
   Cig C, 2010, LECT NOTES COMPUT SC, V6459, P278
   Corr PJ, 2013, EMOT REV, V5, P285, DOI 10.1177/1754073913477507
   Critchley HD, 2002, NEUROSCIENTIST, V8, P132, DOI 10.1177/107385840200800209
   D'Mello S, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P31
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Dirican AC, 2012, COMPUT HUM BEHAV, V28, P1634, DOI 10.1016/j.chb.2012.04.002
   Du R., 2019, C HUM FACT COMP SYST, DOI [10.1145/3290605.3300915, DOI 10.1145/3290605.3300915]
   emteqlabs, 2021, IMP DEV STAND SAF SE
   emteqlabs, 2020, MEASURING WHAT MATTE
   emteqlabs, 2020, IMPROVING EMOTIONAL
   Fertleman C, 2018, FRONT PUBLIC HEALTH, V6, DOI 10.3389/fpubh.2018.00044
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   FRIDLUND AJ, 1984, PSYCHOPHYSIOLOGY, V21, P622, DOI 10.1111/j.1469-8986.1984.tb00249.x
   Girardi D, 2017, INT CONF AFFECT, P125, DOI 10.1109/ACII.2017.8273589
   Gnacek M, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P210, DOI 10.1145/3395035.3425323
   Governo R, 2020, PAIN MANAG, V10, P399, DOI 10.2217/pmt-2020-0005
   Gu SM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00781
   Guerreiro J., 2013, ICINCO, P500, DOI DOI 10.5220/0004594105000506
   HP Reverb G2 Omnicept Edition | HP&REG; Official Site, 2021, HP REV G2 OMN ED HP
   HS2 Passengers Use VR to Test HS2's New Station Design | BIM+, 2021, HS2 PASS US VR TEST
   Lee J, 2013, IEEE ENG MED BIO, P1724, DOI 10.1109/EMBC.2013.6609852
   Li A, 2020, SLEEP, V43, DOI 10.1093/sleep/zsaa120
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Magnée MJCM, 2007, NEUROREPORT, V18, P369, DOI 10.1097/WNR.0b013e32801776e6
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   Marín-Morales J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223881
   Martens MAG, 2019, J PSYCHOPHARMACOL, V33, P1264, DOI 10.1177/0269881119860156
   Martínez-Navarro J, 2019, J BUS RES, V100, P475, DOI 10.1016/j.jbusres.2018.10.054
   Mavridou I, 2017, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL 2017 (ACM VRIC), DOI 10.1145/3110292.3110302
   Mavridou I, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P152, DOI 10.1145/3131277.3134366
   Mavridou I., 2018, VALENCE DETECTION EM
   Mavridou I., 2019, VIRTUAL REALITY INT, P35
   Mavridou I, 2018, PROCEEDINGS OF THE WORKSHOP ON HUMAN-HABITAT FOR HEALTH (H3'18): HUMAN-HABITAT MULTIMODAL INTERACTION FOR PROMOTING HEALTH AND WELL-BEING IN THE INTERNET OF THINGS ERA, DOI 10.1145/3279963.3279969
   Mavridou I, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), P83, DOI 10.1109/ACIIW.2019.8925297
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   Menshikova G., 2020, VIRTUAL REALITY TECH
   Otsuka S, 2017, TENCON IEEE REGION, P1251, DOI 10.1109/TENCON.2017.8228049
   Peñate W, 2019, J CLIN MED, V8, DOI 10.3390/jcm8122139
   Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Seshadri DR, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0150-9
   Shuman V, 2013, FRONT PSYCHOL, V4, DOI [10.3389/fpsyg.2013.00922, 10.3389/fpsyg.2013.00261]
   Siegel E., 2021, HP Omnicept Cognitive Load Database (HPO-CLD)-Developing a Multimodal Inference Engine for Detecting Real-Time Mental Workload in VR
   Suyo M.V., 2016, European Psychiatry, V33, pS397, DOI DOI 10.1016/J.EURPSY.2016.01.1134
   Tan JW, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146691
   Teague CN, 2020, IEEE SENS J, V20, P10323, DOI 10.1109/JSEN.2020.2994552
   Thayer R. E., 1978, MOTIV EMOTION, V2, P1, DOI [10. 1007/bf00992729, DOI 10.1007/BF00992729]
   The Most Powerful Real-Time 3D Creation Tool-Unreal Engine, 2021, MOST POW REAL TIM 3D
   Toll R., 2020, SEE NOT SEE STUDY CA, VVol. 1732, DOI [10.3384/diss.diva-164907, DOI 10.3384/DISS.DIVA-164907]
   Unity Real-Time Development Platform | 3D 2D VR & AR Engine, 2020, UN REAL TIM DEV PLAT
   van Dooren M, 2012, PHYSIOL BEHAV, V106, P298, DOI 10.1016/j.physbeh.2012.01.020
   vanBoxtel A., 2010, 7 INT C METH TECHN B
   Wang CA, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.01029
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   What We Talk About When We Talk About Emotions, 2016, WHAT WE TALK WE TALK, DOI [10.1016/j.cell.2016.11.029, DOI 10.1016/J.CELL.2016.11.029]
   WINTER BB, 1983, IEEE T BIO-MED ENG, V30, P62, DOI 10.1109/TBME.1983.325168
   Zeile P., 2018, GI_Forum, V6, DOI [10.1553/giscience2018_01_s344, DOI 10.1553/GISCIENCE2018_01_S344, 10.1553/GISCIENCE2018_01_S344]
   Zhang J, 2011, INT J PSYCHOPHYSIOL, V79, P378, DOI 10.1016/j.ijpsycho.2010.12.005
   Zhang M., 2020, JPBR, V2, pp39, DOI [10.22158/jpbr.v2n2p39, DOI 10.22158/JPBR.V2N2P39]
NR 68
TC 6
Z9 6
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 11
PY 2022
VL 3
AR 781218
DI 10.3389/frvir.2022.781218
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YW0
UT WOS:001023346800001
OA gold
DA 2024-07-18
ER

PT J
AU Labbe, DR
   Kouakoua, K
   Aissaoui, R
   Nadeau, S
   Duclos, C
AF Labbe, David R.
   Kouakoua, Kean
   Aissaoui, Rachid
   Nadeau, Sylvie
   Duclos, Cyril
TI Proprioceptive Stimulation Added to a Walking Self-Avatar Enhances the
   Illusory Perception of Walking in Static Participants
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; proprioception; embodiment; agency; gait; muscle
   vibration
ID MUSCLE VIBRATION; BODY; OWNERSHIP; EMBODIMENT; MOVEMENT; FEEDBACK;
   SENSE; ILLUSIONS; TIME; LIMB
AB When immersed in virtual reality, users who view their body as a co-located virtual avatar that reflects their movements, generally develop a sense of embodiment whereby they perceive the virtual body to be their own. One aspect of the sense of embodiment is the feeling of agency over the avatar, i.e., the feeling that one is producing the movements of the avatar. In contexts such as physical rehabilitation, telepresence and gaming, it may be useful to induce a strong sense of agency in users who cannot produce movements or for whom it is not practical to do so. Being able to feel agency over a walking avatar without having to produce walking movements could be especially valuable. Muscle vibrations have been shown to produce the proprioceptive perception of movements, without any movement on the part of the user. The objectives of the current study were to: 1-determine if the addition of lower-limb muscle-vibrations with gait-like patterns to a walking avatar can increase the illusory perception of walking in healthy individuals who are standing still; 2-compare the effects of the complexity of the vibration patterns and of their synchronicity on the sense of agency and on the illusory perception of walking. Thirty participants viewed a walking avatar from a first-person perspective, either without muscle vibrations or with one of four different patterns of vibrations. These five conditions were presented pairwise in a two-alternative forced choice paradigm and individually presented, after which participants answered an embodiment questionnaire. The displacement of center of pressure of the participants was measured throughout the experiment. The results show that all patterns of proprioceptive stimulation increased the sense of agency to a similar degree. However, the condition in which the proprioceptive feedback was realistic and temporally aligned with the avatar's leg movements led to significantly larger anteroposterior sway of the center of pressure. The frequency of this sway matched the cadence of the avatar's gait. Thus, congruent and realistic proprioceptive stimulation increases the feeling of agency, the illusory perception of walking and the motor responses of the participants when viewing a walking avatar from a first-person perspective.
C1 [Labbe, David R.; Kouakoua, Kean; Aissaoui, Rachid] Ecole Technol Super ETS, Lab Rech Imagerie & Orthopedie LIO, Montreal, PQ, Canada.
   [Labbe, David R.; Kouakoua, Kean; Aissaoui, Rachid] Univ Montreal, CHUM Res Ctr, Montreal, PQ, Canada.
   [Nadeau, Sylvie; Duclos, Cyril] Univ Montreal, Ctr Rech Interdisciplinaire readaptat Montreal Met, Lab Pathokinesiol Montreal, Inst Univ Readaptat Deficience Phys Montreal, Montreal, PQ, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   Universite de Montreal; Universite de Montreal
RP Labbe, DR (corresponding author), Ecole Technol Super ETS, Lab Rech Imagerie & Orthopedie LIO, Montreal, PQ, Canada.; Labbe, DR (corresponding author), Univ Montreal, CHUM Res Ctr, Montreal, PQ, Canada.
EM david.labbe@etsmtl.ca
CR Alchalabi B, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abee51
   Asai T, 2015, EXP BRAIN RES, V233, P777, DOI 10.1007/s00221-014-4153-0
   Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Berti A, 2013, BRAIN, V136, P11, DOI 10.1093/brain/aws346
   Burin D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209899
   Carifio J, 2008, MED EDUC, V42, P1150, DOI 10.1111/j.1365-2923.2008.03172.x
   Dallaire-Côté M, 2016, P IEEE VIRT REAL ANN, P167, DOI 10.1109/VR.2016.7504706
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Duclos C, 2014, J REHABIL RES DEV, V51, P245, DOI 10.1682/JRRD.2013.04.0079
   Dummer T, 2009, PERCEPTION, V38, P271, DOI 10.1068/p5921
   Franck N, 2001, AM J PSYCHIAT, V158, P454, DOI 10.1176/appi.ajp.158.3.454
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   GOODWIN GM, 1972, SCIENCE, V175, P1382, DOI 10.1126/science.175.4028.1382
   GROOD ES, 1983, J BIOMECH ENG-T ASME, V105, P136, DOI 10.1115/1.3138397
   Hamzeheinejad N, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P382, DOI 10.1109/VR50410.2021.00061
   Hay L, 1996, EXP BRAIN RES, V108, P129
   Holmes Nicholas P, 2004, Cogn Process, V5, P94, DOI 10.1007/s10339-004-0013-3
   Ivanenko YP, 2000, J NEUROPHYSIOL, V84, P1737, DOI 10.1152/jn.2000.84.4.1737
   Iwata H., 2013, Human Walking in Virtual Environments SE-9, P199, DOI DOI 10.1007/978-1-4419-8432-6_9
   Jerald J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P211, DOI 10.1109/VR.2009.4811025
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Keshner EA, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.641650
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Leonardis D, 2014, PRESENCE-TELEOP VIRT, V23, P253, DOI 10.1162/PRES_a_00190
   Liu LY, 2020, IEEE T NEUR SYS REH, V28, P878, DOI 10.1109/TNSRE.2020.2979830
   Lopez S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300787
   Maister L, 2013, COGNITION, V128, P170, DOI 10.1016/j.cognition.2013.04.002
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   Matsuda Y., 2020, IEEE C VIRTUAL REALI
   Meehan M., 2002, EFFECT LATENCY PRESE, DOI [10.1145/566570.566630, DOI 10.1145/566570.566630]
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Moore JW, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01272
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   ROLL JP, 1982, EXP BRAIN RES, V47, P177
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Samaraweera G, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P23, DOI 10.1109/3DUI.2013.6550192
   Schulze S, 2019, LECT NOTES COMPUT SC, V11574, P361, DOI 10.1007/978-3-030-21607-8_28
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Sullivan Gail M, 2013, J Grad Med Educ, V5, P541, DOI 10.4300/JGME-5-4-18
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Tapin A., 2019, INT SOC POST GAIT RE
   Taylor MW, 2017, MULTISENS RES, V30, P25, DOI 10.1163/22134808-00002544
   Thyrion C, 2010, J NEUROPHYSIOL, V104, P949, DOI 10.1152/jn.00025.2010
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Vuillerme N, 2002, NEUROSCI LETT, V333, P131, DOI 10.1016/S0304-3940(02)00999-0
   Walsh LD, 2011, J PHYSIOL-LONDON, V589, P3009, DOI 10.1113/jphysiol.2011.204941
   Whitton MC, 2008, MORG KAUF SER INTER, P107, DOI 10.1016/B978-0-12-374017-5.00004-3
   Willaert I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P719, DOI [10.1109/VRW50115.2020.00210, 10.1109/VRW50115.2020.00-65]
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
NR 61
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 2
PY 2021
VL 2
AR 557783
DI 10.3389/frvir.2021.557783
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZS5
UT WOS:001019271200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Xie, B
   Liu, HM
   Alghofaili, R
   Zhang, YQ
   Jiang, YL
   Lobo, FD
   Li, CY
   Li, WW
   Huang, HK
   Akdere, M
   Mousas, C
   Yu, LF
AF Xie, Biao
   Liu, Huimin
   Alghofaili, Rawan
   Zhang, Yongqi
   Jiang, Yeling
   Lobo, Flavio Destri
   Li, Changyang
   Li, Wanwan
   Huang, Haikun
   Akdere, Mesut
   Mousas, Christos
   Yu, Lap-Fai
TI A Review on Virtual Reality Skill Training Applications
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; training; simulation; content creation; personalization
ID MOTOR FUNCTIONAL RECOVERY; AUGMENTED REALITY; STROKE SURVIVORS; SUBACUTE
   STROKE; XBOX KINECT; UPPER LIMBS; SIMULATION; SYSTEM; ENVIRONMENTS;
   EDUCATION
AB This study aimed to discuss the research efforts in developing virtual reality (VR) technology for different training applications. To begin with, we describe how VR training experiences are typically created and delivered using the current software and hardware. We then discuss the challenges and solutions of applying VR training to different application domains, such as first responder training, medical training, military training, workforce training, and education. Furthermore, we discuss the common assessment tests and evaluation methods used to validate VR training effectiveness. We conclude the article by discussing possible future directions to leverage VR technology advances for developing novel training experiences.
C1 [Xie, Biao; Alghofaili, Rawan; Zhang, Yongqi; Li, Changyang; Li, Wanwan; Huang, Haikun; Yu, Lap-Fai] George Mason Univ, Volgenau Sch Engn, Design Comp & Extended Real Grp, Comp Sci, Fairfax, VA 22030 USA.
   [Liu, Huimin; Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, Virtual Real Lab, W Lafayette, IN USA.
   [Jiang, Yeling; Lobo, Flavio Destri; Akdere, Mesut] Purdue Univ, Dept Technol Leadership & Innovat, Purdue Human Resource Dev Virtual Lab, W Lafayette, IN USA.
C3 George Mason University; Purdue University System; Purdue University;
   Purdue University System; Purdue University
RP Yu, LF (corresponding author), George Mason Univ, Volgenau Sch Engn, Design Comp & Extended Real Grp, Comp Sci, Fairfax, VA 22030 USA.
EM craigyu@gmu.edu
RI Li, Wanwan/Q-3692-2016; Huang, Haikun/AAL-2838-2021; Mousas,
   Christos/AGV-3533-2022
OI Huang, Haikun/0000-0002-5962-0533; Mousas, Christos/0000-0003-0955-7959;
   Alghofaili, Rawan/0000-0001-6510-4562; Li, Wanwan/0000-0002-9425-2633;
   Liu, Huimin/0000-0003-2620-9585
CR Aati K, 2020, TRANSPORT RES REC, V2674, P224, DOI 10.1177/0361198120953146
   Abidi MH, 2019, INT J ADV MANUF TECH, V105, P3743, DOI 10.1007/s00170-019-03801-3
   Akdere M, 2021, INT J INTERCULT REL, V82, P109, DOI 10.1016/j.ijintrel.2021.03.009
   Akdere M, 2020, HUM RESOUR DEV Q, V31, P393, DOI 10.1002/hrdq.21404
   Allmendinger K, 2010, EDUC PSYCHOL REV, V22, P41, DOI 10.1007/s10648-010-9117-8
   Ambron E, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00067
   Amin Ashfaq, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P269, DOI 10.1007/978-3-319-39907-2_25
   [Anonymous], 2016, P 11 INT C DISABILIT
   [Anonymous], 2016, 2016 IEEE Aerospace Conference, DOI 10.1109/AER0.2016.7500674
   [Anonymous], 1988, COGNITION PRACTICE M, DOI DOI 10.1017/CBO9780511609268
   Backlund P, 2007, IEEE INT CONF INF VI, P899
   BALDWIN TT, 1988, PERS PSYCHOL, V41, P63, DOI 10.1111/j.1744-6570.1988.tb00632.x
   Bao X, 2013, NEURAL REGEN RES, V8, P2904, DOI 10.3969/j.issn.1673-5374.2013.31.003
   Barkman S., 2001, NEWS VIEWS, V54, P3
   Baur T, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P220, DOI 10.1109/SocialCom.2013.39
   Bergstrom J.R., 2014, Eye Tracking in User Experience Design
   Bhoir S, 2015, AEI 2015: BIRTH AND LIFE OF THE INTEGRATED BUILDING, P457
   Biocca F., 1995, COMMUN AGE VIRTUAL R, V15, P10
   Bogatinov D, 2017, MULTIMED TOOLS APPL, V76, P1403, DOI 10.1007/s11042-015-3118-z
   Borba EZ, 2016, ACM SIGGRAPH 2016 VR VILLAGE (SIGGRAPH '16), DOI 10.1145/2929490.2929497
   Bossard Cyril, 2008, Virtual Reality, V12, P151, DOI 10.1007/s10055-008-0093-y
   Brahim Z., 2020, NHMEP OFFERS VIRTUAL
   Bryman Alan, 2006, Qualitative Research, V6, P97, DOI [10.1177/1468794106058877, DOI 10.1177/1468794106058877]
   Burke HutchinsH L., 2007, Human Resource Development Review, V6, P263, DOI DOI 10.1177/1534484307303035
   Cacioppo JT, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P1, DOI 10.2277/ 0521844711
   Cai SY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P248, DOI [10.1109/VR46266.2020.1580801081068, 10.1109/VR46266.2020.00-60]
   Caligiuri PM, 2000, INT J INTERCULT REL, V24, P27, DOI 10.1016/S0147-1767(99)00021-8
   Carroll J., 2000, Making Use: Scenario-based Design of Human-Computer Interactions
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Chao CJ, 2017, HUM FACTOR ERGON MAN, V27, P187, DOI 10.1002/hfm.20702
   Chellali A, 2011, INTERACT COMPUT, V23, P317, DOI 10.1016/j.intcom.2011.05.002
   Clark R.E., 1996, INT J EDUC RES, V25, P403, DOI DOI 10.1016/S0883-0355(97)81235-9
   Colbert A, 2016, ACAD MANAGE J, V59, P731, DOI 10.5465/amj.2016.4003
   Congès A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P87, DOI [10.1109/VRW50115.2020.0-254, 10.1109/VRW50115.2020.00022]
   Cordar A, 2017, P IEEE VIRT REAL ANN, P148, DOI 10.1109/VR.2017.7892242
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Daher S, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P99, DOI 10.1145/3267851.3267876
   Dalladaku Y., 2020, P 2020 ANN GEN DONAL
   de Ribaupierre S, 2015, P IEEE VIRT REAL ANN, P147, DOI 10.1109/VR.2015.7223338
   Deardorff D. K., 2006, Journal of Studies in International Education, V10, P241, DOI [DOI 10.1177/1028315306287002, https://doi.org/10.1177/1028315306287002, 10.1177/1028315306287002]
   Detterman D. K., 1993, Transfer on trial: Intelligence, cognition, and instruction, P1, DOI 10.1016/0010-8545(93)85032-Y
   Di Loreto C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P281, DOI 10.1109/VR.2018.8448292
   Dittmer J, 2010, INT RES GEOGR ENVIRO, V19, P139, DOI 10.1080/10382046.2010.482222
   Doneda ALC, 2020, SYMP VIRTUAL AUGMENT, P434, DOI 10.1109/SVR51698.2020.00071
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   Farmer E, 1999, HDB SIMULATOR BASED, DOI [10.4324/9781315253671, DOI 10.4324/9781315253671]
   Feelreal, 2020, FEELR MULT VR MASK
   Filigenzi M T, 2000, Appl Occup Environ Hyg, V15, P465
   Formosa NJ, 2018, AUST J PSYCHOL, V70, P57, DOI 10.1111/ajpy.12167
   Freeman JS., INT C EXPOSITION SAE, DOI DOI 10.4271/950174
   Freiknecht Jonas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040027
   Froehlich M.A., 2016, Proceedings of the 52nd Associated Schools of Construction Annual International Conference, P13
   Fukumori S, 2014, IEEE IND ELEC, P4034, DOI 10.1109/IECON.2014.7049106
   Gallagher AG, 1999, ENDOSCOPY, V31, P310
   Gilbreth F. B., 2013, CHEAPER DOZEN
   Gilyazova OS, 2019, TARIH KULT SANAT ARA, V8, P196, DOI 10.7596/taksad.v8i1.1921
   Girardi R, 2019, SYMP VIRTUAL AUGMENT, P25, DOI 10.1109/SVR.2019.00021
   Grajewski D, 2015, PROCEDIA COMPUT SCI, V75, P359, DOI 10.1016/j.procs.2015.12.258
   Grantcharov TP, 2004, BRIT J SURG, V91, P146, DOI 10.1002/bjs.4407
   Greene J. O., 2003, Handbook of communication and social interaction skills
   Greunke L, 2016, IEEE T VIS COMPUT GR, V22, P1482, DOI 10.1109/TVCG.2016.2518098
   Grossman R, 2011, INT J TRAIN DEV, V15, P103, DOI 10.1111/j.1468-2419.2011.00373.x
   Gurusamy KS, 2009, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006575.pub2
   Hafsia M., 2018, Proceedings of the Virtual Reality International Conference - Laval Virtual, P1
   Hamblin C. J., 2005, Transfer of training from virtual reality environments
   Hamilton EC, 2002, SURG ENDOSC, V16, P406, DOI 10.1007/s00464-001-8149-z
   Harrison A, 2002, DISABIL REHABIL, V24, P599, DOI 10.1080/09638280110111360
   Haskins J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P57, DOI [10.1109/VRW50115.2020.0-258, 10.1109/VRW50115.2020.00018]
   He Z. D., 2014, ADV MAT RES, V926-930, P2735, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AMR.926-930.2735
   Heirman J, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P266, DOI 10.1109/AIVR50618.2020.00055
   Herrlich M, 2010, LECT NOTES COMPUT SC, V6243, P286, DOI 10.1007/978-3-642-15399-0_29
   Hickman L, 2018, 2018 15TH LEARNING AND TECHNOLOGY CONFERENCE (L&T), P24, DOI 10.1109/LT.2018.8368506
   Hochreiter J, 2015, P IEEE VIRT REAL ANN, P69, DOI 10.1109/VR.2015.7223326
   Houtkamp JM, 2012, SIMULAT GAMING, V43, P778, DOI 10.1177/1046878112444564
   Howard MC, 2019, HUM-COMPUT INTERACT, V34, P205, DOI 10.1080/07370024.2018.1469408
   Huguet L, 2016, STUD HEALTH TECHNOL, V220, P146, DOI 10.3233/978-1-61499-625-5-146
   Hurd O, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P492, DOI [10.1109/VR.2019.8797997, 10.1109/vr.2019.8797997]
   Hussain T. S., 2009, INT IND TRAIN SIM ED, P1
   Ihemedu-Steinke Q, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P583, DOI 10.1109/VR.2018.8446076
   Inman DP, 1997, COMMUN ACM, V40, P53, DOI 10.1145/257874.257886
   Iosa M, 2015, TOP STROKE REHABIL, V22, P306, DOI 10.1179/1074935714Z.0000000036
   Issurin VB, 2013, SPORTS MED, V43, P675, DOI 10.1007/s40279-013-0049-6
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jiang YL, 2022, EUR J TRAIN DEV, V46, P434, DOI 10.1108/EJTD-12-2020-0178
   John NW, 2018, IEEE T VIS COMPUT GR, V24, P1867, DOI 10.1109/TVCG.2017.2700273
   Johnson M., 2010, GENERATIONS
   Karabiyik U, 2019, LECT NOTES COMPUT SC, V11845, P469, DOI 10.1007/978-3-030-33723-0_38
   Kenny PG, 2009, LECT NOTES COMPUT SC, V5613, P514, DOI 10.1007/978-3-642-02583-9_56
   Kirchbach K, 2011, IEEE INT CONF INF VI, P549, DOI 10.1109/IV.2011.11
   Kiss L, 2015, INT CONF COGN INFO, P215, DOI 10.1109/CogInfoCom.2015.7390593
   Koutitas G, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P299, DOI 10.1145/3316782.3321542
   Koutitas G, 2021, VIRTUAL REAL-LONDON, V25, P83, DOI 10.1007/s10055-020-00436-8
   Krösl K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P655, DOI [10.1109/VR.2019.8798239, 10.1109/vr.2019.8798239]
   Kyan M, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2735951
   Lacko J, 2020, PROCEEDINGS OF THE 2020 30TH INTERNATIONAL CONFERENCE CYBERNETICS & INFORMATICS (K&I '20), DOI 10.1109/ki48306.2020.9039854
   Lang, 2021, ROAD VR
   Lang YN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P297, DOI 10.1109/VR.2018.8448290
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Li H, 2012, J COMPUT CIVIL ENG, V26, P638, DOI 10.1061/(ASCE)CP.1943-5487.0000170
   Li WW, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P539, DOI [10.1109/VR46266.2020.00-29, 10.1109/VR46266.2020.1581008046739]
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Lin FH, 2002, INFORM SCIENCES, V140, P153, DOI 10.1016/S0020-0255(01)00185-2
   Lin Y.-H., 2013, INFORM TECHNOLOGY CO, P121, DOI [10.1007/978-94-007-6996-0_13, DOI 10.1007/978-94-007-6996-0_13]
   Linowes J., 2015, Unity virtual reality projects
   Liu HM, 2020, INT SYM MIX AUGMENT, P566, DOI 10.1109/ISMAR50242.2020.00084
   Lovreglio R, 2021, VIRTUAL REAL-LONDON, V25, P133, DOI 10.1007/s10055-020-00447-5
   Mann C.T., 2019, Recent trends in active-duty military deaths
   Martin G., 2009, P HUM FACT ERG SOC A, P1949, DOI [10.1177/154193120905302615, DOI 10.1177/154193120905302615]
   Martin G. A., 2010, P 2010 SPRING SIM MU, P1
   McGhee J. T., 2018, INT J CHILD HLTH HUM, V11, P243
   Mechlih H, 2016, 2016 13th Learning and Technology Conference (L&T), P33
   Melnick K., 2019, VR SCOUT 0514
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Moro C, 2017, AUSTRALAS J EDUC TEC, V33, P1, DOI 10.14742/ajet.3840
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   Nasios K., 2002, THESIS U NOTTINGHAM
   Niniss H., 2000, 3rd International Conference on Disability, Virtual Reality and Associated Technologies, P9
   Ostrowski S., 2018, PR NEWSWIRE, DOI [10.5592/co/cetra.2018.889, DOI 10.5592/CO/CETRA.2018.889]
   Papachristos NM, 2017, IEEE INT CONF ADV LE, P477, DOI 10.1109/ICALT.2017.145
   Papelis Y., 2018, P 50 COMP SIM C BORD, P16
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Park DS, 2017, J STROKE CEREBROVASC, V26, P2313, DOI 10.1016/j.jstrokecerebrovasdis.2017.05.019
   Pinto D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2019), P130, DOI 10.1109/ICGI47575.2019.8955091
   Prasolova-Forland E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P295, DOI [10.1109/vr.2019.8798179, 10.1109/VR.2019.8798179]
   Ramakrishna P, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P221, DOI [10.1109/ISMAR-Adjunct.2016.71, 10.1109/ISMAR-Adjunct.2016.0080]
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1731, DOI 10.1145/3025453.3025723
   Reichard AA, 2010, AM J IND MED, V53, P1, DOI 10.1002/ajim.20772
   Rizzo A, 2014, COMPUTER, V47, P31, DOI 10.1109/MC.2014.199
   Rodriguez N, 2015, 2015 3rd IEEE VR International Workshop on Virtual and Augmented Assistive Technology (VAAT), P19, DOI 10.1109/VAAT.2015.7155405
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Rosenthal R, 2013, SURG ENDOSC, V27, P222, DOI 10.1007/s00464-012-2424-z
   Rushmeier H., 2019, CONTENT GENERATION W
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Salas E, 2005, JT COMM J QUAL PATIE, V31, P363, DOI 10.1016/S1553-7250(05)31049-X
   Salmon P, 2010, THEOR ISS ERGON SCI, V11, P504, DOI 10.1080/14639220903165169
   Schraagen Jan Maarten, 2000, Cognitive Task Analysis
   Sekizuka R, 2019, IEEE INT C INT ROBOT, P3229, DOI [10.1109/IROS40897.2019.8968213, 10.1109/iros40897.2019.8968213]
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Shirk P., 2019, 1 WXGS VIRTUAL TRAIN
   Si WX, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P683, DOI 10.1109/VR.2018.8446450
   Lustosa EBS, 2018, SYMP VIRTUAL AUGMENT, P18, DOI 10.1109/SVR.2018.00016
   Sin H, 2013, AM J PHYS MED REHAB, V92, P871, DOI 10.1097/PHM.0b013e3182a38e40
   Siu KC, 2016, MIL MED, V181, P214, DOI 10.7205/MILMED-D-15-00164
   Smelik RM, 2011, COMPUT GRAPH-UK, V35, P352, DOI 10.1016/j.cag.2010.11.011
   Smelik R.M., 2009, P CASA WORKSHOP 3D A, V2009, P25
   Smelik RM, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12276
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Spitzberg B.H., 2009, Conceptualizing intercultural competence
   Stone DL, 2015, HUM RESOUR MANAGE R, V25, P216, DOI 10.1016/j.hrmr.2015.01.002
   Sweeney SK, 2018, TECHTRENDS, V62, P114, DOI 10.1007/s11528-017-0234-9
   Taffinder N, 1998, ST HEAL T, V50, P124
   Tarnowski Pawel, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P137, DOI 10.1109/IIPHDW.2018.8388342
   Taupiac JD, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P190, DOI [10.1109/VR.2019.8797854, 10.1109/vr.2019.8797854]
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Tolio T, 2010, CIRP ANN-MANUF TECHN, V59, P672, DOI 10.1016/j.cirp.2010.05.008
   Trainingxr@Ieeevr2020, 2020, WORKSH 3D CONT CREAT
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Våpenstad C, 2017, MINIM INVASIV THER, V26, P346, DOI 10.1080/13645706.2017.1319866
   Viar, 2019, RET TRAIN ROL VIRT R
   Wagner R.J., 1994, Journal of Management Development, V13, P4
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Wang Y, 2019, I C VIRTUAL REALITY, P277, DOI 10.1109/ICVRV47840.2019.00068
   Wang YW, 2003, J COUNS PSYCHOL, V50, P221, DOI 10.1037/0022-0167.50.2.221
   Wang ZR, 2017, NEURAL REGEN RES, V12, P1823, DOI 10.4103/1673-5374.219043
   Whiting N., 2014, OC CONN DEV C
   Wilkerson W, 2008, ACAD EMERG MED, V15, P1152, DOI 10.1111/j.1553-2712.2008.00223.x
   Williams DP, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00261
   Willis D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P484, DOI [10.1109/vr.2019.8798257, 10.1109/VR.2019.8798257]
   Xie H., 2006, Development of a virtual reality safety-training system for construction workers, P1
   Yang Zhang, 2019, CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3290605.3300285
   Yildiz E, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2019), P48, DOI [10.1109/ICGI47575.2019.8955033, 10.1109/icgi47575.2019.8955033]
   Yoo JW, 2017, NEUROREHABILITATION, V40, P175, DOI 10.3233/NRE-161402
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zhao D, 2015, INT J INJ CONTROL SA, V22, P57, DOI 10.1080/17457300.2013.861853
   Zikmund W. G., 2010, Business Research Methods, V8th ed.
   Zollmann S, 2014, P IEEE, V102, P137, DOI 10.1109/JPROC.2013.2294314
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 179
TC 93
Z9 101
U1 4
U2 22
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 30
PY 2021
VL 2
AR 645153
DI 10.3389/frvir.2021.645153
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZP5
UT WOS:001019268100001
OA gold
DA 2024-07-18
ER

PT J
AU Harvie, DS
AF Harvie, Daniel S.
TI Immersive Education for Chronic Condition Self-Management
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; chronic condition; chronic disease; self-management;
   health education (MeSH)
ID VIRTUAL-REALITY; ADHERENCE; KNOWLEDGE; BEHAVIOR; TRENDS; BODY
AB Chronic conditions represent a significant twenty first century challenge. Education and self-management training are the mainstay of clinical intervention for such conditions since care is dependent on health literacy and self-management. This intervention not only imparts the necessary understanding and skills for self-management, but also helps people to overcome personal barriers to positive behavioral change, such as low self-efficacy. Moreover, education maximizes dignity, by enabling shared decision-making. A plethora of research supports the role of education and self-management training in the management of chronic conditions, whilst at the same time highlighting that not all approaches lead to meaningful behavioral change. Immersive virtual reality (VR) offers a unique set of features and tools for delivering these interventions. For example, the immersive nature focuses attention and promotes engagement; the ability to simulate authentic and interactive real-world scenarios can be used to promote the benefits of active learning; and the ability to facilitate embodiment of avatars with distinct appearance and capability can be used to bias new perceptions and behaviors in-line with the avatar's characteristics. Moreover, the ability to use VR independent of a clinician renders a potential solution to instances where significant barriers to healthcare access exist. This short perspective paper will discuss how VR may be used to host education and self-management interventions in the domain of chronic condition management. Further, it will outline considerations for developers and conclude with a call for the co-creation of new VR-based education and self-management interventions.
C1 [Harvie, Daniel S.] Griffith Univ, Menzies Hlth Inst Queensland, Hopkins Ctr, Gold Coast, Qld, Australia.
   [Harvie, Daniel S.] Griffith Univ, Sch Allied Hlth Sci, Gold Coast, Qld, Australia.
   [Harvie, Daniel S.] Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Wearable Comp Lab, Adelaide, SA, Australia.
C3 Griffith University; Griffith University - Gold Coast Campus; Menzies
   Health Institute Queensland; Griffith University; Griffith University -
   Gold Coast Campus; University of South Australia
RP Harvie, DS (corresponding author), Griffith Univ, Menzies Hlth Inst Queensland, Hopkins Ctr, Gold Coast, Qld, Australia.; Harvie, DS (corresponding author), Griffith Univ, Sch Allied Hlth Sci, Gold Coast, Qld, Australia.; Harvie, DS (corresponding author), Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Wearable Comp Lab, Adelaide, SA, Australia.
EM d.harvie@griffith.edu.au
RI Harvie, Daniel/AAR-2678-2020
OI Harvie, Daniel/0000-0001-7693-4158
FU Early Career Research Fellowship from the National Health and Medical
   Research Council of Australia [GNT2204950]; Hopkins Centre seeding
   grant; Australian Centre for Interactive and Virtual Environments
   seeding grant
FX DH was supported by an Early Career Research Fellowship from the
   National Health and Medical Research Council of Australia (GNT2204950).
   This paper was the result of projects supported by a Hopkins Centre
   seeding grant and an Australian Centre for Interactive and Virtual
   Environments seeding grant.
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Allegrante JP, 2019, ANNU REV PUBL HEALTH, V40, P127, DOI 10.1146/annurev-publhealth-040218-044008
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banich MT., 2011, Generalization of knowledge: Multidisciplinary perspectives
   BRUNER J, 1991, CRIT INQUIRY, V18, P1, DOI 10.1086/448619
   Camerini L, 2012, PATIENT EDUC COUNS, V89, P337, DOI 10.1016/j.pec.2012.08.005
   Chan E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200987
   Colzato LS, 2015, CONSCIOUS COGN, V35, P110, DOI 10.1016/j.concog.2015.04.012
   Darnall BD, 2020, JMIR FORM RES, V4, DOI 10.2196/17293
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   Engle D.E., 2006, AMBIVALENCE PSYCHOTH
   Fox R, 2001, OXFORD REV EDUC, V27, P23, DOI 10.1080/03054980125310
   Goldin-Meadow S, 2011, WIRES COGN SCI, V2, P595, DOI 10.1002/wcs.132
   Gutiérrez F, 2007, STUD HEALTH TECHNOL, V125, P155
   Hajesmaeel Gohari Sadrieh, 2019, Med J Islam Repub Iran, V33, P67, DOI 10.34171/mjiri.33.67
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Harvie DS, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00013
   Hermanns N, 2020, DIABETIC MED, V37, P436, DOI 10.1111/dme.14256
   Inzlicht M, 2015, TRENDS COGN SCI, V19, P126, DOI 10.1016/j.tics.2015.01.004
   Jacobson J, 2017, SMART COMPUT INTELL, P35, DOI 10.1007/978-981-10-5490-7_3
   Jung T, 2020, J MED INTERNET RES, V22, DOI 10.2196/14178
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Krassmann A. L., 2020, INT C HUM COMP INT
   Liu DJ, 2017, SMART COMPUT INTELL, P105, DOI 10.1007/978-981-10-5490-7_7
   Louw A., 2019, Pain Rehab. J. Physio. Pain Assoc., V2019, P4
   Mahon BZ, 2015, LANG COGN NEUROSCI, V30, P420, DOI 10.1080/23273798.2014.987791
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   O'Hea EL, 2005, J HEALTH PSYCHOL, V10, P705, DOI 10.1177/1359105305055330
   Ockene IS, 2002, J AM COLL CARDIOL, V40, P630, DOI 10.1016/S0735-1097(02)02078-8
   Pandrangi VC, 2019, ANN VASC SURG, V59, P184, DOI 10.1016/j.avsg.2019.01.015
   PETRIE K, 1995, J PSYCHOSOM RES, V39, P31, DOI 10.1016/0022-3999(94)00071-C
   Pillen H, 2020, CRIT PUBLIC HEALTH, V30, P468, DOI 10.1080/09581596.2019.1591613
   Rich A, 2015, J BEHAV MED, V38, P673, DOI 10.1007/s10865-015-9644-3
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Safari R, 2020, J MED INTERNET RES, V22, DOI 10.2196/15365
   Serino S, 2016, CYBERPSYCH BEH SOC N, V19, P127, DOI 10.1089/cyber.2015.0229
   SHARKEY NE, 1993, ARTIF INTELL REV, V7, P313, DOI 10.1007/BF00849058
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2014, COMPUTER, V47, P24, DOI 10.1109/MC.2014.198
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Ventura S, 2020, CYBERPSYCH BEH SOC N, V23, P667, DOI 10.1089/cyber.2019.0681
   Waller K V, 1992, Am J Health Promot, V6, P302
   West R, 2013, ADDICT PRESS SER, P1, DOI 10.1002/9781118484890
   WHO, 2014, GLOBAL STATUS REPORT ON VIOLENCE PREVENTION 2014, P1
   Ziemke T, 2016, BIOSYSTEMS, V148, P4, DOI 10.1016/j.biosystems.2016.08.005
NR 47
TC 7
Z9 7
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 13
PY 2021
VL 2
AR 657761
DI 10.3389/frvir.2021.657761
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WV1
UT WOS:001023293700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Curry, C
   Peterson, N
   Li, RX
   Stoffregen, TA
AF Curry, Christopher
   Peterson, Nicolette
   Li, Ruixuan
   Stoffregen, Thomas A.
TI Postural Activity During Use of a Head-Mounted Display: Sex Differences
   in the "Driver-Passenger" Effect
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE motion sickness; cybersickness; virtual reality; head-mounted display;
   posture; sex differences
ID MOTION SICKNESS; BODY SWAY; DYNAMICS; INSTABILITY; STABILITY
AB Motion sickness is common in virtual environments. The risk of motion sickness varies widely between individuals and across situations. The subjective experience of motion sickness often is preceded by distinctive patterns of movement in the control of head and body posture. Previous research has documented reliable sex differences in the kinematics of postural activity, as well as reliable differences in postural activity between participants who were in control of a virtual vehicle and participants who were not. We asked whether postural precursors of motion sickness would simultaneously be influenced by individual and situational factors. We analyzed movement of the head and torso while seated participants were exposed to a driving video game presented through a head-mounted display. Half of the participants were women, and half were men. Using a yoked-control design, half of the participants controlled the virtual vehicle (Drivers), whereas half watched previously recorded vehicle trajectories (Passengers). The maximum exposure duration was 15 min, but participants were instructed to discontinue participation immediately if they experienced any symptoms of motion sickness, however mild. We analyzed movement kinematics not only in terms of sex and vehicle control but also in terms of participants who did or did not report motion sickness. Movement differed between Drivers and Passengers, in terms of both the spatial magnitude and multifractality of movement. The spatial magnitude of movement was simultaneously influenced by sex (men vs. women) and vehicle control (Drivers vs. Passengers). In addition, in statistically significant interactions, we identified postural precursors of motion sickness that differed between Drivers and Passengers and, separately, between Drivers and Passengers as a function of sex. The results are consistent with a prediction of the postural instability theory of motion sickness etiology and shed new light on the multifactorial origins of postural precursors of motion sickness in virtual environments.
C1 [Curry, Christopher; Peterson, Nicolette; Li, Ruixuan; Stoffregen, Thomas A.] Univ Minnesota, Sch Kinesiol, Affordance Percept Act Lab, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Stoffregen, TA (corresponding author), Univ Minnesota, Sch Kinesiol, Affordance Percept Act Lab, Minneapolis, MN 55455 USA.
EM tas@umn.edu
RI Li, Ruixuan/AAM-8203-2020
OI Li, Ruixuan/0000-0002-9800-7408
FU University of Minnesota Undergraduate Research Opportunities Program;
   NRT grant for translational sensory science [NRT-1734815]; 
   [NSF-1901423]
FX Elisheeva Savvateev was supported by the University of Minnesota
   Undergraduate Research Opportunities Program. CC was supported by the
   NRT grant for translational sensory science (NRT-1734815). TS was
   supported by NSF-1901423, CHS: Medium: Prediction, Early Detection, and
   Mitigation of Virtual Reality Simulator Sickness.
CR Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P1068, DOI 10.1109/TVCG.2011.274
   Chang CH, 2017, AEROSP MED HUM PERF, V88, P985, DOI 10.3357/AMHP.4893.2017
   Chen YC, 2012, ECOL PSYCHOL, V24, P279, DOI 10.1080/10407413.2012.726181
   COLLINS JJ, 1993, EXP BRAIN RES, V95, P308, DOI 10.1007/BF00229788
   Curry C, 2020, ERGONOMICS, V63, P1502, DOI 10.1080/00140139.2020.1808713
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Era P, 2006, GERONTOLOGY, V52, P204, DOI 10.1159/000093652
   Ihlen EAF, 2013, J BIOMECH, V46, P484, DOI 10.1016/j.jbiomech.2012.10.016
   Ihlen EAF, 2012, FRONT PHYSIOL, V3, DOI 10.3389/fphys.2012.00141
   Ihlen EAF, 2010, J EXP PSYCHOL GEN, V139, P436, DOI 10.1037/a0019098
   Kantelhardt JW, 2002, PHYSICA A, V316, P87, DOI 10.1016/S0378-4371(02)01383-3
   Kelty-Stephen DG, 2013, ECOL PSYCHOL, V25, P1, DOI 10.1080/10407413.2013.753804
   Kim JW, 2010, GERIATR GERONTOL INT, V10, P191, DOI 10.1111/j.1447-0594.2009.00582.x
   Koslucher F, 2016, EXP BRAIN RES, V234, P2709, DOI 10.1007/s00221-016-4675-8
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Koslucher F, 2015, AEROSP MED HUM PERF, V86, P787, DOI 10.3357/AMHP.4243.2015
   Koslucher FC, 2014, GAIT POSTURE, V39, P606, DOI 10.1016/j.gaitpost.2013.09.016
   LAWTHER A, 1988, AVIAT SPACE ENVIR MD, V59, P399
   Li RX, 2018, EXP BRAIN RES, V236, P1631, DOI 10.1007/s00221-018-5246-y
   Lin DD, 2008, GAIT POSTURE, V28, P337, DOI 10.1016/j.gaitpost.2008.01.005
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Munafo J, 2016, EXP BRAIN RES, V234, P2721, DOI 10.1007/s00221-016-4676-7
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   Palatinus Z, 2014, J EXP PSYCHOL HUMAN, V40, P1808, DOI 10.1037/a0037247
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   ROLNICK A, 1991, ERGONOMICS, V34, P867, DOI 10.1080/00140139108964831
   Shimizu Y, 2002, FRACTALS, V10, P103, DOI 10.1142/S0218348X02001130
   Slobounov S., 1994, GAIT POSTURE, V2, P85, DOI [10.1016/0966-6362(94)90097-3, DOI 10.1016/0966-6362(94)90097-3]
   Slowinski P, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2015.1093
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 1999, J EXP PSYCHOL HUMAN, V25, P1641
   Stoffregen TA, 2008, HUM FACTORS, V50, P322, DOI 10.1518/001872008X250755
   Stoffregen TA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187120
   Stoffregen TA, 2014, EXP BRAIN RES, V232, P1389, DOI 10.1007/s00221-014-3859-3
   Stoffregen TA, 2010, ECOL PSYCHOL, V22, P169, DOI 10.1080/10407413.2010.496645
   Thurner S, 2000, PHYS REV E, V62, P4018, DOI 10.1103/PhysRevE.62.4018
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Walter HJ, 2019, HUM MOVEMENT SCI, V64, P389, DOI 10.1016/j.humov.2019.03.006
NR 47
TC 5
Z9 5
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 23
PY 2020
VL 1
AR 581132
DI 10.3389/frvir.2020.581132
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XE7
UT WOS:001023303300001
OA gold
DA 2024-07-18
ER

PT J
AU MacQuarrie, A
   Steed, A
AF MacQuarrie, Andrew
   Steed, Anthony
TI Investigating the Perceived Strengths and Limitations of Free-Viewpoint
   Video
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE free-viewpoint video; virtual reality; augmented reality; content
   creation; VR; AR; XR
ID EXPERIENCE; BEHAVIOR; REALITY; GAZE
AB Free-viewpoint video (FVV) is a type of immersive content in which a character performance is filmed using an array of cameras and processed into a video-textured, animated 3D mesh. Although FVV content has a unique set of properties that differentiates it from other immersive media types, relatively little work explores the user experience of such content. As a preliminary investigation, we adopted an open-ended, qualitative approach to investigate these issues. Semi-structured interviews were conducted with six immersive content experts, exploring the perceived strengths and limitations of FVV as a content type. These interviews were analyzed using inductive thematic analysis. We identified five themes during our analysis: they don't look real, but that's okay; they can really move; they don't connect with me; encounter, legacy, and truth; no technology is an island. Our analysis reveals a wide range of future research directions and provides insight into which areas may produce the most benefit in relation to the user experience. We discuss, for example, the potential impact of difficulties in supporting user engagement, aspects related to visual quality such as the importance of responding realistically to environment lighting, and tensions between visual and behavioral quality. The analysis also highlights the complex interplay of factors related to the content itself, such as performance style and the use of creative production techniques to reduce the impact of potential limitations.
C1 [MacQuarrie, Andrew; Steed, Anthony] UCL, Dept Comp Sci, Virtual Environm & Comp Graph Grp, London, England.
C3 University of London; University College London
RP MacQuarrie, A (corresponding author), UCL, Dept Comp Sci, Virtual Environm & Comp Graph Grp, London, England.
EM andrew.macquarrie.13@ucl.ac.uk
OI Steed, Anthony/0000-0001-9034-3020; MacQuarrie,
   Andrew/0000-0003-1028-2710
FU UK Engineering and Physical Sciences Research Council (EPSRC)
   [EP/N509577/1]
FX This work was supported by grant EP/N509577/1 from the UK Engineering
   and Physical Sciences Research Council (EPSRC).
CR 4DViews (n.d.), 4DVIEWS VOL CAPT SYS
   8i (n.d.), ABOUT US
   Alcon, 2017, BLAD RUNN 2049 MEM L
   Alexiou E, 2017, IEEE INT WORKSH MULT
   Aneja D, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P69, DOI 10.1145/3340555.3353744
   [Anonymous], 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587758
   [Anonymous], 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, DOI DOI 10.1145/2503713.2503747
   ARGYLE M, 1965, SOCIOMETRY, V28, P289, DOI 10.2307/2786027
   Argyle M., 1976, Gaze and Mutual Gaze
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Bernard I., 1997, FILM TELEVISION ACTI, DOI [10.4324/9780080506364, DOI 10.4324/9780080506364]
   Braun V, 2013, Success Qual Res, V1st
   Bucher J, 2018, STORYTELLING FOR VIRTUAL REALITY: METHODS AND PRINCIPLES FOR CRAFTING IMMERSIVE NARRATIVES, P1
   Budd C, 2013, INT J COMPUT VISION, V102, P256, DOI 10.1007/s11263-012-0553-4
   Bye K., 2017, ELEMENTAL THEORY PRE
   Cagniart C, 2010, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2010.5539814
   Cagniart C, 2010, LECT NOTES COMPUT SC, V6314, P326, DOI 10.1007/978-3-642-15561-1_24
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Casas D, 2013, IEEE T VIS COMPUT GR, V19, P762, DOI 10.1109/TVCG.2012.314
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Cho S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P26, DOI [10.1109/VR46266.2020.1581170537418, 10.1109/VR46266.2020.00-84]
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Colyer SL, 2018, SPORTS MED-OPEN, V4, DOI 10.1186/s40798-018-0139-y
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Dimension Studio, 2019, WIMBL CHAMP RALL A M
   Dimension Studio (n.d.), WORLD LEAD VOL XR VI
   Dodds L., 2018, LIGHTING LEGEND ART
   Dolan Devon, 2016, REDEFINING AXIOM STO
   dos Anjos RK, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364244
   Eisert Peter, 2020, Real VR - Immersive Digital Reality: How to Import the Real World into Head-Mounted Immersive Displays. Lecture Notes in Computer Science (LNCS 11900), P167, DOI 10.1007/978-3-030-41816-8_7
   Garau M., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P309, DOI 10.1145/365024.365121
   Garau M., 2003, THESIS U LONDON LOND
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Gueguen N., 2009, EUROPEAN J SOCIAL SC, V8, P253, DOI DOI 10.1007/978-1-4419-1428-6_1798
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Hale J, 2020, J NONVERBAL BEHAV, V44, P63, DOI 10.1007/s10919-019-00320-3
   Hall Edward T., 1966, The Hidden Dimension
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Horry Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P225, DOI 10.1145/258734.258854
   Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319
   Jump Studio (n.d.), ABOUT US
   Kämpf MS, 2018, PSYCHOL SCI, V29, P131, DOI 10.1177/0956797617727121
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   Kätsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   Keskinen T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P423, DOI 10.1109/VR.2019.8797843
   Kovar L, 2008, ACM SIGGRAPH 2008 CL, DOI [DOI 10.1145/1401132.1401202, 10.1145/1401132.1401202]
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   MacQuarrie A., 2020, FREE VIEWPOINT VIDEO
   MacQuarrie A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P775, DOI [10.1109/VRW50115.2020.00-37, 10.1109/VRW50115.2020.00238]
   MacQuarrie A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P645, DOI [10.1109/VR.2019.8797852, 10.1109/vr.2019.8797852]
   Mangiante S, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P30, DOI 10.1145/3097895.3097901
   Mathur MB, 2016, COGNITION, V146, P22, DOI 10.1016/j.cognition.2015.09.008
   Metaspace, US
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Mustafa A, 2016, LECT NOTES COMPUT SC, V9905, P213, DOI 10.1007/978-3-319-46448-0_13
   Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694
   Novick DG, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1888, DOI 10.1109/ICSLP.1996.608001
   Oculus Story Studio, 2015, SWAYZ EFF
   Peng Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3473, DOI 10.1109/CVPR.2011.5995438
   Prada F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925967
   Pyett PM, 2003, QUAL HEALTH RES, V13, P1170, DOI 10.1177/1049732303255686
   Regateiro J, 2018, INT CONF 3D VISION, P514, DOI 10.1109/3DV.2018.00065
   Roberts DJ, 2013, IEEE T VIS COMPUT GR, V19, P681, DOI 10.1109/TVCG.2013.30
   Rothe S, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P25, DOI 10.1145/3317697.3323362
   Schreer O., 2019, P IBC C
   Sky UK Ltd, 2018, SKY VR HOLD WORLD
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2009, ANU PSICOL, V40, P193
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915
   Starck J., 2005, SCA 05, P49, DOI DOI 10.1145/1073368.1073375
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Start V. R., 2018, AW EP ON
   Steed A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00112
   Subramanyam S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P127, DOI [10.1109/VR46266.2020.1581260728335, 10.1109/VR46266.2020.00-73]
   SuperData, 2020, 2019 YEAR REV DIG GA
   Tung T, 2010, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2010.5539806
   Uva M., 2010, GRIP BOOK
   Vinayagamoorthy V., 2004, 7 ANN INT PRESENCE W, P148
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   volumegraphics, About us
   Xu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964927
   Zhao SY, 2003, PRESENCE-VIRTUAL AUG, V12, P445, DOI 10.1162/105474603322761261
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 91
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 21
PY 2020
VL 1
AR 11
DI 10.3389/frvir.2020.00011
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YH9
UT WOS:001023332700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Bonfert, M
   Hübinger, M
   Malaka, R
AF Bonfert, Michael
   Huebinger, Maiko
   Malaka, Rainer
TI Challenges of controlling the rotation of virtual objects with variable
   grip using force-feedback gloves
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE object manipulation; haptics; force feedback; virtual reality; XR;
   dexterity
ID FRICTION
AB Some virtual reality (VR) applications require true-to-life object manipulation, such as for training or teleoperation. We investigate an interaction technique that replicates the variable grip strength applied to a held object when using force-feedback gloves in VR. We map the exerted finger pressure to the rotational freedom of the virtual object. With a firm grip, the object's orientation is fixed to the hand. With a loose grip, the user can allow the object to rotate freely within the hand. A user study (N = 21) showed how challenging it was for participants to control the object's rotation with our prototype employing the SenseGlove DK1. Despite high action fidelity, the grip variability led to poorer performance and increased task load compared to the default fixed rotation. We suspect low haptic fidelity as an explanation as only kinesthetic forces but no cutaneous cues are rendered. We discuss the system design limitations and how to overcome them in future haptic interfaces for physics-based multi-finger object manipulation.
C1 [Bonfert, Michael; Malaka, Rainer] Univ Bremen, Digital Media Lab, Bremen, Germany.
   [Huebinger, Maiko] Univ Bremen, Bremen, Germany.
C3 University of Bremen; University of Bremen
RP Bonfert, M (corresponding author), Univ Bremen, Digital Media Lab, Bremen, Germany.
EM bonfert@uni-bremen.de
RI Malaka, Rainer/IXD-3800-2023
OI Malaka, Rainer/0000-0001-6463-4828; Bonfert, Michael/0000-0002-3605-6693
FU This research was partially funded by Klaus Tschira Stiftung by
   financing the scholarship of MB, and the German Federal Ministry of
   Education and Research (BMBF) as part of the project "Hydrogen for
   Bremen's Industrial Transformation." Staats- und Universi; Klaus Tschira
   Stiftung; German Federal Ministry of Education and Research (BMBF)
FX This research was partially funded by Klaus Tschira Stiftung by
   financing the scholarship of MB, and the German Federal Ministry of
   Education and Research (BMBF) as part of the project "Hydrogen for
   Bremen's Industrial Transformation." Staats- und Universitaetsbibliothek
   Bremen covered the open-access publication fees.r This research was
   partially funded by Klaus Tschira Stiftung by financing the scholarship
   of MB, and the German Federal Ministry of Education and Research (BMBF)
   as part of the project "Hydrogen for Bremen's Industrial
   Transformation." Staats- und Universitatsbibliothek Bremen covered the
   open-access publication fees.
CR Achibet M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P59, DOI 10.1109/3DUI.2014.6798843
   Alexandrovsky D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376260
   Augurelle AS, 2003, J NEUROPHYSIOL, V89, P665, DOI 10.1152/jn.00249.2002
   Blaga AD, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P749, DOI 10.1109/VR50410.2021.00102
   Bonfert M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P604, DOI [10.1109/VR.2019.8797824, 10.1109/vr.2019.8797824]
   Bouzit M, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P145, DOI 10.1109/HAPTIC.2002.998952
   Cadoret G, 1996, J NEUROPHYSIOL, V75, P1963, DOI 10.1152/jn.1996.75.5.1963
   Coquillart S., 2004, Proceedings of the tenth eurographics conference on virtual environments, DOI [10.2312/EGVE/EGVE04/105-112, DOI 10.2312/EGVE/EGVE04/105-112]
   ELLIOTT JM, 1984, DEV MED CHILD NEUROL, V26, P283, DOI 10.1111/j.1469-8749.1984.tb04445.x
   Endo T, 2011, IEEE T HAPTICS, V4, P14, DOI [10.1109/TOH.2010.62, 10.1109/ToH.2010.62]
   Girard Adrien., 2016, FRONT ROBOT AI, V3, P1, DOI DOI 10.3389/FICT.2016.00006
   HART S G, 1988, P139
   HIROTA K, 1995, IEEE COMPUT GRAPH, V15, P22, DOI 10.1109/38.403824
   Höll M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P175, DOI 10.1109/VR.2018.8448284
   Kim MJ, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517724
   Massie T. H., 1994, P S HAPT INT VIRT EN, P295
   Minamizawa K., 2007, ACM SIGGRAPH 2007 EM, P8, DOI DOI 10.1145/1278280.1278289
   Muender T, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501953
   Neung Ryu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1035, DOI 10.1145/3379337.3415862
   Pedersen A. K., 2023, 2 IEEE VR 2023 WORKS
   Quinn P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300504
   Salazar SV, 2020, IEEE T HAPTICS, V13, P167, DOI 10.1109/TOH.2020.2967389
   Schmitz M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501981
   SenseGlove, 2019, Getting started with the SenseGlove DK1
   SenseGlove, 2023, VR and haptic technology gloves
   Tsai HR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300450
   Wang DX, 2019, IEEE T HAPTICS, V12, P189, DOI 10.1109/TOH.2018.2879812
   WESTLING G, 1984, EXP BRAIN RES, V53, P277
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yabe S, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P557, DOI 10.1109/WHC.2017.7989962
   Zhai S., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P308, DOI 10.1145/238386.238534
NR 32
TC 0
Z9 0
U1 8
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 9
PY 2023
VL 4
AR 1190426
DI 10.3389/frvir.2023.1190426
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA U9GB3
UT WOS:001087803200001
OA gold
DA 2024-07-18
ER

PT J
AU Kilpelaeinen, M
   Haekkinen, J
AF Kilpelaeinen, Markku
   Haekkinen, Jukka
TI An effective method for measuring text legibility in XR devices reveals
   clear differences between three devices
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE XR; VR; legibility; readability; psychophysics; statistical power
ID FACTORS INFLUENCING SPEED; DISPLAY; RESOLUTION; CONTRAST; SIZE
AB Reading is a crucial aspect of the extended reality (XR) experience across various professional and recreational contexts. Legibility, which is defined as the ease with which a character can be recognized, is an essential determinant of readability. As legibility on a specific device cannot be deduced from technical specifications alone, an efficient perceptual method for measuring legibility is needed to measure the legibility of text presented in XR. In this study, we present a method for comparing the legibility limits of XR devices, where single letter legibility is measured with fast and precise psychophysical methods. We applied the method to compare the legibility in three commercial XR headsets (Varjo VR-2, HTC Vive Pro Eye, Oculus Quest 2) in experiments with human observers. Our results show that the single letter legibility methods presented here provide an effect size approximately ten times higher compared to the widely used method of reading speed. This allows for the use of fewer observers and the detection of smaller differences, making it a more efficient and effective approach for comparing the legibility limits of XR devices.
C1 [Kilpelaeinen, Markku; Haekkinen, Jukka] Univ Helsinki, Dept Psychol & Logoped, Helsinki, Finland.
C3 University of Helsinki
RP Haekkinen, J (corresponding author), Univ Helsinki, Dept Psychol & Logoped, Helsinki, Finland.
EM jukka.hakkinen@helsinki.fi
RI Hakkinen, Jukka/A-4122-2019; Kilpelainen, Markku/C-7613-2011
OI Hakkinen, Jukka/0000-0003-0215-2238; Kilpelainen,
   Markku/0000-0002-4112-7548
FU Business Finland [XR 3984/31/2019]; Kone Oyj; UkiArkkitehditOy; Varjo
   TechnologiesOy; Huawei Technologies Oy (Finland) Co. Ltd.
FX The research was funded by Business Finland (project Human Optimized XR
   3984/31/2019). The Business Finland project was also funded by: Kone
   Oyj, UkiArkkitehditOy, Varjo TechnologiesOy, and Huawei Technologies Oy
   (Finland) Co. Ltd. The funders were not involved in the study design,
   collection, analysis, interpretation of data, the writing of this
   article, or the decision to submit it for publication.
CR Arditi A, 2005, VISION RES, V45, P2926, DOI 10.1016/j.visres.2005.06.013
   Arfé B, 2023, READ WRIT, V36, P1743, DOI 10.1007/s11145-022-10362-7
   ATTNEAVE F, 1956, PSYCHOL BULL, V53, P452, DOI 10.1037/h0044049
   Baceviciute S, 2021, COMPUT EDUC, V164, DOI 10.1016/j.compedu.2020.104122
   Bates DW, 2015, BMJ QUAL SAF, V24, P1, DOI 10.1136/bmjqs-2014-003499
   Ben-Shachar MS., 2020, J OPEN SOURCE SOFTW, V5, P2815, DOI DOI 10.21105/JOSS.02815
   Besuijen K, 1998, DISPLAYS, V19, P67, DOI 10.1016/S0141-9382(98)00039-0
   Bigelow C, 2019, VISION RES, V165, P162, DOI 10.1016/j.visres.2019.05.003
   Brysbaert M, 2019, J MEM LANG, V109, DOI 10.1016/j.jml.2019.104047
   Büttner A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P663, DOI [10.1109/VRW50115.2020.00-93, 10.1109/VRW50115.2020.00182]
   Burova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376405
   Carrasco MDO, 2021, AUTOMAT CONSTR, V126, DOI 10.1016/j.autcon.2021.103677
   Cattell JamesMcKeen., 1885, PHILOS STUDIEN, V2, P635
   Chung STL, 2004, OPTOMETRY VISION SCI, V81, P525, DOI 10.1097/00006324-200407000-00014
   CORNSWEET TN, 1962, AM J PSYCHOL, V75, P485, DOI 10.2307/1419876
   Dingler T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188695
   ERDMANN RL, 1968, J APPL PSYCHOL, V52, P403, DOI 10.1037/h0026189
   Franken G, 2015, J EYE MOVEMENT RES, V8
   García-Pérez MA, 2011, J ACOUST SOC AM, V130, P2098, DOI 10.1121/1.3628334
   GINSBURG AP, 1978, AMRLTR78129 AER MED
   Google for Developers, 2017, Designing screen interfaces for VR (Google I/O '17)
   HIGGINS KE, 1988, J OPT SOC AM A, V5, P2173, DOI 10.1364/JOSAA.5.002173
   Hoffman DM, 2019, J SOC INF DISPLAY, V27, P207, DOI 10.1002/jsid.765
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329
   Kaakinen JK, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0274480
   Kim Sun Kyung, 2020, Journal of Multimedia Information System, V7, P277
   Kochurova O, 2015, DISPLAYS, V38, P38, DOI 10.1016/j.displa.2015.02.001
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Laming D, 2013, ATTEN PERCEPT PSYCHO, V75, P1774, DOI 10.3758/s13414-013-0544-8
   Leek MR, 2001, PERCEPT PSYCHOPHYS, V63, P1279, DOI 10.3758/BF03194543
   LEGGE GE, 1987, VISION RES, V27, P1165, DOI 10.1016/0042-6989(87)90028-9
   Legge GE, 2011, J VISION, V11, DOI 10.1167/11.5.8
   Lenth RV, 2022, Emmeans: estimated marginal means, aka least-squares means
   Luckiesh M, 1939, J APPL PSYCHOL, V23, P645, DOI 10.1037/h0055273
   Nanavati AnujA., 2005, Visible Language, V39, P121
   PASTOOR S, 1990, HUM FACTORS, V32, P157, DOI 10.1177/001872089003200204
   Paterson DG, 1929, J APPL PSYCHOL, V13, P120, DOI 10.1037/h0074167
   Paterson DG, 1932, J APPL PSYCHOL, V16, P388, DOI 10.1037/h0074988
   Pelli DG, 2006, VISION RES, V46, P4646, DOI 10.1016/j.visres.2006.04.023
   Pelli DG, 2003, NATURE, V423, P752, DOI 10.1038/nature01516
   Penczek J, 2017, J SOC INF DISPLAY, V25, P215, DOI 10.1002/jsid.537
   Pölönen M, 2012, DISPLAYS, V33, P157, DOI 10.1016/j.displa.2012.06.002
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Prins N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01250
   Rau PLP, 2021, INFORM LEARN SCI, V122, P464, DOI 10.1108/ILS-11-2020-0236
   Roufs JAJ, 1997, DISPLAYS, V18, P37, DOI 10.1016/S0141-9382(97)00003-6
   RStudio Team, 2022, RSTUDIO INT DEV ENV
   Sanford E. C., 1888, The American Journal of Psychology, V1, P402, DOI /-10.2307-/-1411012
   Sheedy J, 2002, OPTOMETRY VISION SCI, V79, P306, DOI 10.1097/00006324-200205000-00010
   Sheedy JE, 2005, HUM FACTORS, V47, P797, DOI 10.1518/001872005775570998
   Singmann H., 2021, afex: analysis of factorial experiments
   Solum H. H., 2019, Readability in virtual reality, an investigation into displaying text in a virtual environment
   Tarasov DA, 2015, PROCD SOC BEHV, V174, P1300, DOI 10.1016/j.sbspro.2015.01.751
   VAEGAN, 1982, BRIT J OPHTHALMOL, V66, P477, DOI 10.1136/bjo.66.8.477
   van Nes F. L., 1984, Behav. Inf. Technol, V3, P371, DOI [10.1080/01449298408901770, DOI 10.1080/01449298408901770]
   WATSON AB, 1990, PERCEPT PSYCHOPHYS, V47, P87, DOI 10.3758/BF03208169
   Weiss AP, 1917, J EXP PSYCHOL, V2, P106, DOI 10.1037/h0072089
   WETHERILL GB, 1965, BRIT J MATH STAT PSY, V18, P1, DOI 10.1111/j.2044-8317.1965.tb00689.x
   Wright S. L., 1999, J. Soc. Inf. Disp, V7, P253, DOI [10.1889/1.1985290, DOI 10.1889/1.1985290]
   Ziefle M, 1998, HUM FACTORS, V40, P554, DOI 10.1518/001872098779649355
NR 60
TC 1
Z9 1
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 7
PY 2023
VL 4
AR 1243387
DI 10.3389/frvir.2023.1243387
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA R9SR1
UT WOS:001067681400001
OA gold
DA 2024-07-18
ER

PT J
AU Lukacs, MJ
   Babin, M
   Dickey, JP
   Melling, CWJ
   Walton, DM
AF Lukacs, Michael J.
   Babin, Mathias
   Dickey, James P.
   Melling, C. W. James
   Walton, David M.
TI Development and tolerability of a novel virtual- and
   proprioception-based car crash simulator as a new research tool in motor
   vehicle trauma research
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE simulator sickness; stress; virtual reality; whiplash associated
   disorder; presence; pain
ID EXPOSURE THERAPY; REALITY; WHIPLASH; ENVIRONMENTS; ACCIDENT; SYMPTOMS;
   STRESS
AB Purpose: Investigations of causal theories of neck pain (NP) following motor vehicle crashes (MVC) has been difficult, as simulation is limited. Thus, we sought to evaluate tolerability to a novel virtual reality (VR)-based road collision simulator and screen for adverse reactions.
   Materials and Methods: Cross-sectional study. 25 healthy participants were exposed to a novel VR-based rear-end MVC with a small perturbation (0.2 g). The Simulator Sickness Questionnaire (SSQ) and Presence Questionnaire (PQ) were measured post-exposure and adverse reactions were recorded.
   Results: The system was well tolerated with no adverse reactions, however one participant reported NP the following day not lasting longer than 48 h. Participants reported low levels of simulator sickness (mean SSQ = 23.49 +/- 21.98, range = 0.00 to 89.76; max score = 235.62), while presence (mean PQ = 91.04 +/- 14.08, range = 54.00 to 112.00; max score = 133), was lower than literature recommendations.
   Conclusion: A VR-based road collision simulator can be safely used to explore the phenomenon of a motor vehicle crashes under controlled circumstances. Future work is needed to optimize the virtual reality environment and to investigate the effects of crash parameters.
C1 [Lukacs, Michael J.] Western Univ, Hlth & Rehabil Sci, London, ON, Canada.
   [Lukacs, Michael J.; Dickey, James P.; Walton, David M.] Western Univ, Bone & Joint Inst, London, ON, Canada.
   [Babin, Mathias] Western Univ, Comp Sci, London, ON, Canada.
   [Dickey, James P.; Melling, C. W. James] Western Univ, Kinesiol, London, ON, Canada.
   [Walton, David M.] Western Univ, Sch Phys Therapy, London, ON, Canada.
C3 Western University (University of Western Ontario); Western University
   (University of Western Ontario); Western University (University of
   Western Ontario); Western University (University of Western Ontario);
   Western University (University of Western Ontario)
RP Lukacs, MJ (corresponding author), Western Univ, Hlth & Rehabil Sci, London, ON, Canada.; Lukacs, MJ (corresponding author), Western Univ, Bone & Joint Inst, London, ON, Canada.
EM mlukacs2@uwo.ca
FU Bone and Joint Institute at Western University, Canada; Western
   Strategic Support for NSERC Success
FX ML was supported in part by a Transdisciplinary Training Award from the
   Bone and Joint Institute at Western University, Canada. This work was
   also supported by a Catalyst Grant from the Bone and Joint Institute at
   Western University, Canada awarded to DW and JD. Funding for the open
   access publication fees were received from a Western Strategic Support
   for NSERC Success awarded to DW.
CR ALLEN ME, 1994, SPINE, V19, P1285, DOI 10.1097/00007632-199405310-00017
   Balk S., 2013, SIMULATOR SICKNESS Q, DOI DOI 10.17077/DRIVINGASSESSMENT.1498
   Barrett JM, 2021, J BIOMECH ENG-T ASME, V143, DOI 10.1115/1.4050909
   Beck JG, 2007, BEHAV THER, V38, P39, DOI 10.1016/j.beth.2006.04.001
   Berglund A, 2003, ANN EPIDEMIOL, V13, P66, DOI 10.1016/S1047-2797(02)00252-1
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Brault JR, 1998, ARCH PHYS MED REHAB, V79, P72, DOI 10.1016/S0003-9993(98)90212-X
   Castro WHM, 2001, INT J LEGAL MED, V114, P316, DOI 10.1007/s004140000193
   Dabbour E, 2020, ACCIDENT ANAL PREV, V142, DOI 10.1016/j.aap.2020.105562
   Daniel J., 2012, Choosing the type of nonprobability sampling, DOI [10.4135/9781452272047, DOI 10.4135/9781452272047]
   Dickey JP, 2013, MINERALS-BASEL, V3, P145, DOI 10.3390/min3020145
   Fice J. B., 2019, THESIS U BRIT COLUMB
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lukacs M., 2018, HLTH SCI INQ, V9, P69, DOI [10.29173/hsi276, DOI 10.29173/HSI276]
   Morley D. C., 2016, ACM INT C P SERIES
   Pietra A, 2021, VIRTUAL REAL-LONDON, V25, P945, DOI 10.1007/s10055-021-00499-1
   Riches S, 2019, CYBERPSYCH BEH SOC N, V22, P288, DOI 10.1089/cyber.2018.0128
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Sharar Sam R, 2008, Expert Rev Neurother, V8, P1667, DOI 10.1586/14737175.8.11.1667
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Trappey A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010347
   UQO Cyberpsychology Lab, 2004, CYB REV WS QUEST
   Walshe D, 2005, CYBERPSYCHOL BEHAV, V8, P532, DOI 10.1089/cpb.2005.8.532
   Walton DM, 2017, J ORTHOP SPORT PHYS, V47, P462, DOI 10.2519/jospt.2017.7455
   Wang JL, 2023, IEEE T VIS COMPUT GR, V29, P2478, DOI 10.1109/TVCG.2023.3247057
   Webb CM, 2009, AVIAT SPACE ENVIR MD, V80, P541, DOI 10.3357/ASEM.2454.2009
   Wiederhold BK, 2010, CYBERPSYCH BEH SOC N, V13, P21, DOI 10.1089/cyber.2009.0394
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 29
TC 0
Z9 0
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 31
PY 2023
VL 4
AR 891423
DI 10.3389/frvir.2023.891423
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XZ2
UT WOS:001023323900001
OA gold
DA 2024-07-18
ER

PT J
AU Moosavi, MS
   Raimbaud, P
   Guillet, C
   Plouzeau, J
   Merienne, F
AF Moosavi, Mahdiyeh Sadat
   Raimbaud, Pierre
   Guillet, Christophe
   Plouzeau, Jeremy
   Merienne, Frederic
TI Weight perception analysis using pseudo-haptic feedback based on
   physical work evaluation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; pseudo-haptic feedback; multisensory integration;
   weight perception; illusion; individual-lifting behavior
ID OBJECTS; DESIGN
AB Introduction: Since kinesthetic cues are not present in virtual environments, users have difficulty feeling the heaviness of virtual objects. To address this issue, pseudo-haptic approaches have been proposed to illusorily induce the weight of virtual objects through the user's visual sensory system.Methods: In this paper, we used two methods to induce the impression of virtual objects' heaviness. One relies on the direct modification of the control-display (C/D) ratio when lifting objects, and the other depends on controlling this ratio based on a velocity restriction. We innovatively measured each approach's efficiency by analyzing physical work as an objective metric. In addition, we used Borg CR10 to measure users' hand fatigue during the experimental phases.Results: Our findings are discussed in terms of individual lifting behavior in different pseudo-haptic methods. Furthermore, different virtual weight-lifting behaviors were compared to the same real-world weight-lifting behaviors.Discussion: According to our results, the direct control of the C/D ratio method provides virtual reality users with a more accurate weight perception than the velocity restriction one. Furthermore, with this first method, users' lifting behavior was closer to the behavior when lifting real objects.
C1 [Moosavi, Mahdiyeh Sadat; Plouzeau, Jeremy; Merienne, Frederic] HESAM Univ, Arts & Metiers Inst Technol, LISPEN, Chalon Sur Saone, France.
   [Raimbaud, Pierre] Univ Rennes 1, INRIA, CNRS, IRISA, Rennes, France.
   [Guillet, Christophe] Univ Bourgogne, LISPEN, UBFC, Chalon Sur Saone, France.
C3 heSam Universite; Centre National de la Recherche Scientifique (CNRS);
   Inria; Universite de Rennes; Universite de Bourgogne
RP Moosavi, MS (corresponding author), HESAM Univ, Arts & Metiers Inst Technol, LISPEN, Chalon Sur Saone, France.
EM mahdiyehsadat.moosavi@ensam.eu
RI Raimbaud, Pierre/KDM-8260-2024
OI Raimbaud, Pierre/0000-0002-5584-8100
CR Aman J., 2010, Integration, V96, P98
   Andujar C, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P99
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   BORG G, 1990, SCAND J WORK ENV HEA, V16, P55, DOI 10.5271/sjweh.1815
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P75, DOI 10.1162/105474601750182333
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Burdea G. C., 1999, P INT WORKSH VIRT PR, V2, P17
   Burdea GRIGORE, 1996, Force and touch feedback for virtual reality
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   de Tinguy X, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P81, DOI 10.1109/VR.2018.8446280
   Dominjon L, 2005, P IEEE VIRT REAL ANN, P19
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Gibbs JK, 2022, INT J HUM-COMPUT ST, V157, DOI 10.1016/j.ijhcs.2021.102717
   Gillan D. J., 1990, SIGCHI Bulletin, P227
   Jáuregui DAG, 2014, IEEE T VIS COMPUT GR, V20, P654, DOI 10.1109/TVCG.2014.45
   Hagadorn K. T., 2004, THESIS ROCHESTER I T
   Huyen Nguyen, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P41, DOI 10.1007/978-3-030-62655-6_3
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lecuyer A., 2004, P SIGCHI C HUM FACT, P239, DOI DOI 10.1145/985692.985723
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee J, 2019, INT CONF BIG DATA, P339, DOI 10.1109/bigcomp.2019.8679400
   Lim WN, 2021, IEEE ACCESS, V9, P163253, DOI 10.1109/ACCESS.2021.3131525
   MacKenzie I. S., 1993, THESIS U TORONTO
   Maehigashi A., 2021, C CHI 21 CHI C HUMAN, P1
   Massie T. H., 1994, P S HAPT INT VIRT EN, P295
   Nakakoji K., 2011, P 3 IEEE VR2011 WORK, P23
   Nakakoji K., 2010, INT DES C, P1
   Nisar S, 2019, IEEE ROBOT AUTOM LET, V4, P351, DOI 10.1109/LRA.2018.2890198
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Palmerius KL, 2014, LECT NOTES COMPUT SC, V8618, P117, DOI 10.1007/978-3-662-44193-0_16
   Poupyrev I, 1999, J VISUAL LANG COMPUT, V10, P19, DOI 10.1006/jvlc.1998.0112
   Poupyrev I., 1998, STUDY TECHNIQUES SEL
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Ramsamy P, 2006, LECT NOTES COMPUT SC, V3992, P603, DOI 10.1007/11758525_81
   Rietzler M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173702
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Rosa N, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P327, DOI 10.1145/2818346.2820744
   RUNESON S, 1981, J EXP PSYCHOL HUMAN, V7, P733, DOI 10.1037/0096-1523.7.4.733
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Sciutti A, 2010, EXP BRAIN RES, V200, P259, DOI 10.1007/s00221-009-1996-x
   Ujitoko Y, 2021, IEEE T HAPTICS, V14, P699, DOI 10.1109/TOH.2021.3077619
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yu R, 2020, IEEE T VIS COMPUT GR, V26, P2094, DOI 10.1109/TVCG.2020.2973056
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
NR 46
TC 3
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 13
PY 2023
VL 4
AR 973083
DI 10.3389/frvir.2023.973083
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WP0
UT WOS:001023287600001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Oker, A
AF Oker, A.
TI Embodied social cognition investigated with virtual agents: The infinite
   loop between social brain and virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE embodied social cognition; virtual agents; social brain; social
   interaction; affective cognition
ID FACIAL EXPRESSIONS; EYE-TRACKING; MIRROR; RECOGNITION; MIMICRY; GAZE;
   SIMULATION; EMOTION; OTHERS; MIND
AB While the debate regarding the embodied nature of human cognition is still a research interest in cognitive science and epistemology, recent findings in neuroscience suggest that cognitive processes involved in social interaction are based on the simulation of others' cognitive states and ours as well. However, until recently most research in social cognition continues to study mental processes in social interaction deliberately isolated from each other following 19th century's scientific reductionism. Lately, it has been proposed that social cognition, being emerged in interactive situations, cannot be fully understood with experimental paradigms and stimuli which put the subjects in a passive stance towards social stimuli. Moreover, social neuroscience seems to concur with the idea that a simulation process of possible outcomes of social interaction occurs before the action can take place. In this "perspective" article, we propose that in the light of past and current research in social neuroscience regarding the implications of mirror neuron system and empathy altogether, these findings can be interpreted as a framework for embodied social cognition. We also propose that if the simulation process for the mentalization network works in ubiquity with the mirror neuron system, human experimentations for facial recognition and empathy need a new kind of stimuli. After a presentation of embodied social cognition, we will discuss the future of methodological prerequisites of social cognition studies in this area. On the matter, we will argue that the affective and reactive virtual agents are at the center in conducting such research.
C1 [Oker, A.] Univ Reims, France Lab C2S Cognit Sante Soc, EA6291, Reims, France.
C3 Universite de Reims Champagne-Ardenne
RP Oker, A (corresponding author), Univ Reims, France Lab C2S Cognit Sante Soc, EA6291, Reims, France.
EM ali.oker@univ-reims.fr
CR [Anonymous], 2014, P WORKSH ARCH STAND
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Barsalou LW, 2009, PHILOS T R SOC B, V364, P1281, DOI 10.1098/rstb.2008.0319
   Bastiaansen JACJ, 2009, PHILOS T R SOC B, V364, P2391, DOI 10.1098/rstb.2009.0058
   Beer JS, 2006, BRAIN RES, V1079, P98, DOI 10.1016/j.brainres.2006.01.002
   Berrada-Baby Z, 2016, PSYCHIAT RES, V242, P67, DOI 10.1016/j.psychres.2016.05.022
   Blakemore SJ, 2004, TRENDS COGN SCI, V8, P216, DOI 10.1016/j.tics.2004.03.012
   Bogart KR, 2010, SOC NEUROSCI-UK, V5, P241, DOI 10.1080/17470910903395692
   Brüne M, 2005, PSYCHIAT RES, V133, P135, DOI 10.1016/j.psychres.2004.10.007
   Buccino G, 2001, EUR J NEUROSCI, V13, P400, DOI 10.1111/j.1460-9568.2001.01385.x
   Cassell J, 2001, AI MAG, V22, P67
   Chaby L, 2009, PSYCHOL NEUROPSYCHIA, V7, P31, DOI 10.1684/pnv.2008.0154
   Chemero A., 2011, Radical embodied cognitive science
   Clark A., 1997, Being there
   Courgeon M, 2013, J MULTIMODAL USER IN, V7, P311, DOI 10.1007/s12193-013-0124-1
   Courgeon M., 2008, P 1 WORKSH AFF INT N
   Darwin C., 1872, P374
   De Gelder B., 2004, EXP BRAIN RES EXPT B, V10191, P16701176, DOI [10.1007/bf00230027, DOI 10.1007/BF00230027]
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   Egede JO, 2021, PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA), P52, DOI 10.1145/3472306.3478361
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Ekman P., 1978, APA PsycTests, DOI DOI 10.1037/T27734-000
   Ekman P, 2002, FACIAL ACTION CODING
   Fodor J. A., 1983, MODULARITY MIND
   Forbes PAG, 2016, J AUTISM DEV DISORD, V46, P3788, DOI 10.1007/s10803-016-2930-2
   Frith CD, 2012, ANNU REV PSYCHOL, V63, P287, DOI 10.1146/annurev-psych-120710-100449
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   Gallese V, 2007, PHILOS T R SOC B, V362, P659, DOI 10.1098/rstb.2006.2002
   Gallese V, 2011, TRENDS COGN SCI, V15, P512, DOI 10.1016/j.tics.2011.09.003
   Giraud T, 2021, PROCEEDINGS OF THE FIFTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, TEI 2021, DOI 10.1145/3430524.3440646
   Gratch J., 2014, OXFORD HDB COGNITIVE
   Grynszpan O., 2011, Journal of Physical Therapy Education, V25, P42, DOI DOI 10.1097/00001416-201110000-00008
   Heyes C., 2022, PROG BRAIN RES PROGR, V17107, P1533, DOI [10.1016/s0079-6123(08)61855-5, DOI 10.1016/S0079-6123(08)61855-5]
   Holstege G, 1996, PROG BRAIN RES, V107, P3
   Hone-Blanchet A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00844
   Iacoboni M, 2005, PLOS BIOL, V3, P529, DOI 10.1371/journal.pbio.0030079
   Iacoboni M, 2001, P NATL ACAD SCI USA, V98, P13995, DOI 10.1073/pnas.241474598
   Isaacowitz DM, 2011, J NONVERBAL BEHAV, V35, P261, DOI 10.1007/s10919-011-0113-6
   Izard CE, 2001, EMOTION, V1, P249, DOI 10.1037//1528-3542.1.3.249
   Keysers C, 2006, PROG BRAIN RES, V156, P379, DOI 10.1016/S0079-6123(06)56021-2
   Kilner JM, 2013, CURR BIOL, V23, pR1057, DOI 10.1016/j.cub.2013.10.051
   Kiser D., 2022, SENSORS-BASEL, V18, P401, DOI [10.3390/s18020401, DOI 10.3390/S18020401]
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kohler E, 2002, SCIENCE, V297, P846, DOI 10.1126/science.1070311
   Marcos-Pablos S, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00421
   Marmolejo-Ramos F, 2017, PRAGMAT COGN, V24, P164, DOI 10.1075/pc.17013.mar
   Misselhorn C, 2009, MIND MACH, V19, P345, DOI 10.1007/s11023-009-9158-2
   Mori M., 1970, IEEE SPECTRUM
   Morsella E, 2010, BEHAV BRAIN SCI, V33, P455, DOI 10.1017/S0140525X10001573
   Niedenthal PM, 2010, BEHAV BRAIN SCI, V33, P417, DOI 10.1017/S0140525X10000865
   Niedenthal PM, 2001, COGNITION EMOTION, V15, P853, DOI 10.1080/02699930143000194
   Oberman LM, 2007, SOC NEUROSCI-UK, V2, P167, DOI 10.1080/17470910701391943
   Oker A, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00133
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   PARSONS LM, 1995, NATURE, V375, P54, DOI 10.1038/375054a0
   Pavic K, 2021, Q J EXP PSYCHOL, V74, P1128, DOI 10.1177/1747021820982165
   Penn DL, 2008, SCHIZOPHRENIA BULL, V34, P408, DOI 10.1093/schbul/sbn014
   Pfeiffer UJ, 2013, NEUROSCI BIOBEHAV R, V37, P2516, DOI 10.1016/j.neubiorev.2013.07.017
   Rizzolatti G., 2001, COGN COMPUTCOGNITIVE, V26, P661351, DOI [10.1007/s12559-013-9244-x, DOI 10.1007/S12559-013-9244-X]
   Rodríguez LF, 2014, COGN COMPUT, V6, P351, DOI 10.1007/s12559-013-9244-x
   Ruch WF, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00928
   Scherer K.R., 1982, HDB METHODS NONVERBA, P1
   Schilbach L., 2013, BEHAV BRAIN SCI, V36160, P39343, DOI [10.1016/j.cognition.2016.12.010, DOI 10.1016/J.COGNITION.2016.12.010]
   Singer T, 2004, SCIENCE, V303, P1157, DOI 10.1126/science.1093535
   Stein JP, 2017, COGNITION, V160, P43, DOI 10.1016/j.cognition.2016.12.010
   van der Gaag C, 2007, SOC NEUROSCI-UK, V2, P179, DOI 10.1080/17470910701376878
   Van Overwalle F, 2009, NEUROIMAGE, V48, P564, DOI 10.1016/j.neuroimage.2009.06.009
   Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1
   Wang Y, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00133
   Wilms M, 2010, SOC COGN AFFECT NEUR, V5, P98, DOI 10.1093/scan/nsq024
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Zaki J, 2009, ANN NY ACAD SCI, V1167, P16, DOI 10.1111/j.1749-6632.2009.04601.x
   Ziaei M, 2016, NEUROBIOL AGING, V48, P182, DOI 10.1016/j.neurobiolaging.2016.08.026
NR 73
TC 0
Z9 0
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 13
PY 2022
VL 3
AR 962129
DI 10.3389/frvir.2022.962129
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VP3
UT WOS:001023261600001
OA gold
DA 2024-07-18
ER

PT J
AU Aufegger, L
   Elliott-Deflo, N
AF Aufegger, Lisa
   Elliott-Deflo, Natasha
TI Virtual Reality and Productivity in Knowledge Workers
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; team productivity; individual productivity; knowledge
   worker; design guidelines
ID ENGAGEMENT; BEHAVIOR; PERFORMANCE; LEADERSHIP; CONFLICT; TEAMS
AB Productivity has a significant impact on success and monetary wellbeing of every organisation. Over the past few years, the substantial developments of digital technologies have encouraged a shift in the way we work and produce, from an office-based environment to "virtual work". However, very little is known as to how virtual work and productivity can be supported by virtual reality (VR). We conducted two studies to extend previous productivity research in relation to VR: Study one examined the routes that connect the organisational context with the individual productivity position through the lens of remote working and distributed collaboration; Study two explored the nature of and connections between productivity in individuals and teams working in VR. Based on the findings we explored how the future of VR could enact in knowledge workers' daily productivity. This was done by developing a VR productivity framework that represents physical, environmental, cognitive, and behavioural needs to ensure productivity and organisational growth. Theoretical and practical implications of the findings are discussed.
C1 [Aufegger, Lisa; Elliott-Deflo, Natasha] Meta, Real Labs, London, England.
RP Aufegger, L (corresponding author), Meta, Real Labs, London, England.
EM laufegger@fb.com
CR Ahir Kunjal, 2019, Augmented Human Research, V5, P1, DOI [DOI 10.1007/S41133-019-0025-2, 10.1007/s41133-019-0025-2]
   Aimee C. S., 2020, RELATIONSHIP VIRTUAL
   Antonov S. I., 2020, INT C KNOWL BASED OR, V26, P1, DOI [10.2478/kbo-2020-0106, DOI 10.2478/KBO-2020-0106]
   Austin JT, 1996, PSYCHOL BULL, V120, P338, DOI 10.1037/0033-2909.120.3.338
   Ban Yuki, 2015, P 6 AUGMENTED HUMAN, P25, DOI [10.1145/2735711.2735791, DOI 10.1145/2735711.2735791]
   Butchibabu A, 2016, HUM FACTORS, V58, P595, DOI 10.1177/0018720816639712
   Carson JB, 2007, ACAD MANAGE J, V50, P1217, DOI 10.5465/20159921
   Chandrasekar K., 2011, International Journal of Enterprise Computing and Business Systems, V1, P1
   Cipresso P., 2018, PAST PRESENT FUTURE, DOI [10.3389/fpsyg.2018.02086, DOI 10.3389/FPSYG.2018.02086]
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Diewert W., 1992, B ECON RES, V44, P163, DOI DOI 10.1111/B0ER.1992.44.ISSUE-3
   DRISKELL JE, 1992, HUM FACTORS, V34, P277, DOI 10.1177/001872089203400303
   Eddleston KA, 2017, GROUP ORGAN MANAGE, V42, P346, DOI 10.1177/1059601115619548
   Edmondson A, 1999, ADMIN SCI QUART, V44, P350, DOI 10.2307/2666999
   Elsaied MM, 2019, AM J BUS, V34, P2, DOI 10.1108/AJB-01-2017-0004
   Gale NK, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-117
   Greenwald S W., 2017, Communications in Computer and Information Science, V725, DOI DOI 10.1007/978-3-319-60633-0_7
   Haluck RS, 2000, ARCH SURG-CHICAGO, V135, P786, DOI 10.1001/archsurg.135.7.786
   Haynes BP, 2007, J CORP REAL ESTATE, V9, P97, DOI 10.1108/14630010710828108
   Hernaus T, 2014, EUROMED J BUS, V9, P268, DOI 10.1108/EMJB-11-2013-0054
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Jehn KA, 2001, ACAD MANAGE J, V44, P238, DOI 10.5465/3069453
   Johnson RE, 2013, ORGAN PSYCHOL REV, V3, P62, DOI 10.1177/2041386612463836
   Kim JH, 2014, HUM FACTORS, V56, P1235, DOI 10.1177/0018720814531784
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Latini A, 2021, ENERG BUILDINGS, V253, DOI 10.1016/j.enbuild.2021.111508
   Li Jingyi, 2020, 12 INT C AUT US INT, DOI [10.1145/3409251.3411732, DOI 10.1145/3409251.3411732]
   Lilian SC, 2014, PROCD SOC BEHV, V110, P1251, DOI 10.1016/j.sbspro.2013.12.972
   Muttaqin B.I.A., 2019, AIP C P, V2217, DOI [10.1063/5.0000641, DOI 10.1063/5.0000641]
   Oh C. S., 2018, SYSTEMATIC REV SOCIA, DOI [10.3389/frobt.2018.00114, DOI 10.3389/FROBT.2018.00114]
   Parke MR, 2018, J APPL PSYCHOL, V103, P300, DOI 10.1037/apl0000278
   Ritchie J., 2003, QUALITATIVE RES PRAC, P353
   Schaufeli WB, 2004, J ORGAN BEHAV, V25, P293, DOI 10.1002/job.248
   Seo J., 2019, P CHI C HUM FACT COM, DOI [10.1145/3290605.3300845, DOI 10.1145/3290605.3300845]
   Stander FW, 2014, J PSYCHOL AFR, V24, P403, DOI 10.1080/14330237.2014.997007
   Stewart GL, 2005, PERS PSYCHOL, V58, P343, DOI 10.1111/j.1744-6570.2005.00480.x
   Tangen S., 2002, Proceedings of the 7th Asia-Pacific Industrial Engineering and Management Systems Conference, P18
   van Woerkom M, 2016, EUR J WORK ORGAN PSY, V25, P384, DOI 10.1080/1359432X.2015.1089862
   Vancouver JB, 2008, HUM RESOUR MANAGE R, V18, P1, DOI 10.1016/j.hrmr.2008.02.001
   Wang B, 2021, APPL PSYCHOL-INT REV, V70, P16, DOI 10.1111/apps.12290
   Watson-Manheim M. B., 2002, Information Technology & People, V15, P191, DOI 10.1108/09593840210444746
   Weiss P L, 1998, Work, V11, P277, DOI 10.3233/WOR-1998-11305
   Zhou J, 2003, RES PERS H, V22, P165
NR 43
TC 1
Z9 1
U1 1
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 31
PY 2022
VL 3
AR 890700
DI 10.3389/frvir.2022.890700
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AQ8
UT WOS:001019295600001
OA gold
DA 2024-07-18
ER

PT J
AU Gougeh, RA
   Falk, TH
AF Gougeh, Reza Amini
   Falk, Tiago H.
TI Head-Mounted Display-Based Virtual Reality and Physiological Computing
   for Stroke Rehabilitation: A Systematic Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE stroke rehabilitation; head-mounted display (HMD); immersive virtual
   reality; physiological computing; feedback
ID MOTOR IMAGERY PRACTICE; OF-THE-ART; FUNCTIONAL RECOVERY; NEURAL
   PLASTICITY; REWARD; INTERFACE; SCALE; EEG; EXCITABILITY; ENGAGEMENT
AB Virtual reality (VR)-mediated rehabilitation is emerging as a useful tool for stroke survivors to recover motor function. Recent studies are showing that VR coupled with physiological computing (i.e., real-time measurement and analysis of different behavioral and psychophysiological signals) and feedback can lead to 1) more engaged and motivated patients, 2) reproducible treatments that can be performed at the comfort of the patient's home, and 3) development of new proxies of intervention outcomes and success. While such systems have shown great potential for stroke rehabilitation, an extensive review of the literature is still lacking. Here, we aim to fill this gap and conduct a systematic review of the twelve studies that passed the inclusion criteria. A detailed analysis of the papers was conducted along with a quality assessment/risk of bias evaluation of each study. It was found that the quality of the majority of the studies ranked as either good or fair. Study outcomes also showed that VR-based rehabilitation protocols coupled with physiological computing can enhance patient adherence, improve motivation, overall experience, and ultimately, rehabilitation effectiveness and faster recovery times. Limitations of the examined studies are discussed, such as small sample sizes and unbalanced male/female participant ratios, which could limit the generalizability of the obtained findings. Finally, some recommendations for future studies are given.
C1 [Gougeh, Reza Amini; Falk, Tiago H.] Univ Quebec, INRS EMT, Montreal, PQ, Canada.
C3 University of Quebec; Institut national de la recherche scientifique
   (INRS); University of Quebec Montreal
RP Gougeh, RA (corresponding author), Univ Quebec, INRS EMT, Montreal, PQ, Canada.
EM amini.gougeh.reza@inrs.ca
FU Natural Sciences and Engineering Council (NSERC) of Canada
   [RGPIN-2021-03246]
FX & nbsp;This work was funded by the Natural Sciences and Engineering
   Council (NSERC) of Canada (RGPIN-2021-03246).
CR Abe M, 2011, CURR BIOL, V21, P557, DOI 10.1016/j.cub.2011.02.030
   Achanccaray D, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8832686
   Alimardani M., 2018, EVOLVING BCI THERAPY, DOI DOI 10.5772/INTECHOPEN.78695
   [Anonymous], 2021, P 21 C INT ERGONOMIC, P495
   ASHWORTH B, 1964, PRACTITIONER, V192, P540
   Balconi M, 2016, NEUROPSYCHOL TRENDS, P71, DOI 10.7358/neur-2016-019-balc
   Berenguer-Rocha M, 2020, NEUROL SCI, V41, P2591, DOI 10.1007/s10072-020-04350-4
   Berger DJ, 2017, BIOSYST BIOROBOT, V15, P965, DOI 10.1007/978-3-319-46669-9_156
   Besic I, 2019, 2019 IEEE 15TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATICS (INFORMATICS 2019), P351, DOI 10.1109/informatics47936.2019.9119323
   Blöchl M, 2019, J AFFECT DISORDERS, V247, P45, DOI 10.1016/j.jad.2018.12.082
   Bossenbroek R, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/16066
   Brett CE, 2017, NEUROPSYCHOL REHABIL, V27, P959, DOI 10.1080/09602011.2015.1090459
   Butler AA, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-31
   Caeiro-Rodríguez M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082667
   CARR JH, 1985, PHYS THER, V65, P175, DOI 10.1093/ptj/65.2.175
   Carvalho Erik, 2017, N C Med J, V78, P312, DOI 10.18043/ncm.78.5.312
   Casellato C, 2013, IEEE T NEUR SYS REH, V21, P474, DOI 10.1109/TNSRE.2012.2222445
   Cassani R, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00780-5
   Cassani R, 2020, IEEE SYST MAN CYBERN, V6, P20, DOI 10.1109/MSMC.2019.2953627
   Cassani R, 2018, INT WORK QUAL MULTIM, P246
   Chen XL, 2018, CURR OPIN BEHAV SCI, V20, P83, DOI 10.1016/j.cobeha.2017.11.011
   Cicinelli P, 2003, STROKE, V34, P2653, DOI 10.1161/01.STR.0000092122.96722.72
   Cikajlo I, 2013, IEEE ENG MED BIO, P4129, DOI 10.1109/EMBC.2013.6610454
   Comani S, 2015, IEEE T NEUR SYS REH, V23, P1106, DOI 10.1109/TNSRE.2015.2425474
   Coons Michael J, 2011, J Diabetes Sci Technol, V5, P340
   Corbetta D, 2015, J PHYSIOTHER, V61, P117, DOI 10.1016/j.jphys.2015.05.017
   Damush TM, 2007, REHABIL NURS, V32, P253, DOI 10.1002/j.2048-7940.2007.tb00183.x
   Danzl Megan M, 2012, J Allied Health, V41, P35
   Duncan PW, 2003, NEUROLOGY, V60, P291, DOI 10.1212/01.WNL.0000041493.65665.D6
   Eaves DL, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3382/fnins.2015.00514
   Elor A, 2018, ACM T ACCESS COMPUT, V11, DOI 10.1145/3265755
   Feigin VL, 2018, NEW ENGL J MED, V379, P2429, DOI 10.1056/NEJMoa1804492
   Frisoli Antonio, 2011, IEEE Int Conf Rehabil Robot, V2011, P5975512, DOI 10.1109/ICORR.2011.5975512
   FUGLMEYER AR, 1975, SCAND J REHABIL MED, V7, P13
   GAJDOSIK RL, 1987, PHYS THER, V67, P1867, DOI 10.1093/ptj/67.12.1867
   Carrasco DG, 2016, NEUROLOGIA, V31, P43, DOI 10.1016/j.nrl.2013.02.003
   Garry MI, 2004, J NEUROPHYSIOL, V91, P1570, DOI 10.1152/jn.00595.2003
   Gast Oliver, 2021, HCI in Business, Government and Organizations. 8th International Conference, HCIBGO 2021. Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12783), P562, DOI 10.1007/978-3-030-77750-0_36
   Gim MN, 2015, J PHYS THER SCI, V27, P109, DOI 10.1589/jpts.27.109
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Hao J, 2022, ARCH PHYS MED REHAB, V103, P523, DOI 10.1016/j.apmr.2021.06.024
   Hildebrand MW, 2012, AM J PHYS MED REHAB, V91, P715, DOI 10.1097/PHM.0b013e31824ad462
   Hochstenbach J, 1998, J CLIN EXP NEUROPSYC, V20, P503, DOI 10.1076/jcen.20.4.503.1471
   Huang XW, 2018, COMP M BIO BIO E-IV, V6, P678, DOI 10.1080/21681163.2017.1343687
   Jacucci G, 2015, COMPUTER, V48, P12, DOI 10.1109/MC.2015.291
   Juliano JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041204
   Jurewicz K, 2018, NEUROPSYCHOLOGIA, V108, P13, DOI 10.1016/j.neuropsychologia.2017.11.021
   Kaminski J, 2012, INT J PSYCHOPHYSIOL, V85, P125, DOI 10.1016/j.ijpsycho.2011.11.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khanna P, 2015, CURR OPIN NEUROBIOL, V32, P60, DOI 10.1016/j.conb.2014.11.010
   Kiliç A, 2021, ANN BEHAV MED, V55, P1062, DOI 10.1093/abm/kaab016
   Kim M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051141
   Kleim JA, 2008, J SPEECH LANG HEAR R, V51, pS225, DOI 10.1044/1092-4388(2008/018)
   Kristensen HK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157149
   Kritikos J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051244
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Kumru H, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/6087896
   Lee KB, 2015, INT J REHABIL RES, V38, P173, DOI 10.1097/MRR.0000000000000108
   Levin MF, 2012, NEUROL THER, V1, DOI 10.1007/s40120-012-0003-9
   Li M, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.602091
   Lin CT, 2001, ARCH INTERN MED, V161, P1437, DOI 10.1001/archinte.161.11.1437
   Lin JH, 2004, CLIN REHABIL, V18, P391, DOI 10.1191/0269215504cr737oa
   Lindsay MP, 2019, INT J STROKE, V14, P806, DOI 10.1177/1747493019881353
   Long YL, 2020, OPHTHALMIC GENET, V41, P390, DOI 10.1080/13816810.2020.1755986
   Lupu RG, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/4798359
   Magosso E, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7051079
   Marin-Pardo O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133754
   MILLER AEJ, 1993, EUR J APPL PHYSIOL O, V66, P254, DOI 10.1007/BF00235103
   Mizuguchi N, 2013, NEUROSCI RES, V76, P150, DOI 10.1016/j.neures.2013.03.012
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Moinnereau MA, 2020, IEEE SYS MAN CYBERN, P3494, DOI [10.1109/smc42975.2020.9283019, 10.1109/SMC42975.2020.9283019]
   Morone G, 2020, EXPERT REV MED DEVIC, V17, P223, DOI 10.1080/17434440.2020.1733408
   Mubin Omar, 2019, JMIR Rehabil Assist Technol, V6, pe12010, DOI 10.2196/12010
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   National Institutes of Health, 2022, STUD QUAL ASS TOOLS
   Neuper C, 1999, J CLIN NEUROPHYSIOL, V16, P373, DOI 10.1097/00004691-199907000-00010
   Nielsen Jakob, 1990, P SIGCHI C HUM FACT, P249, DOI [10.1145/97243.97281, DOI 10.1145/97243.97281]
   Nikooyan AA, 2015, J NEUROPHYSIOL, V113, P633, DOI 10.1152/jn.00032.2014
   Nissler C, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf35f
   Norman Don, 2013, The design of everyday things
   Papadopoulos S, 2022, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.824759
   Perez-Marcos D, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0461-0
   Pichiorri F, 2015, ANN NEUROL, V77, P851, DOI 10.1002/ana.24390
   Quattrocchi G, 2017, J NEUROL NEUROSUR PS, V88, P730, DOI 10.1136/jnnp-2016-314728
   Rajanen M., 2018, P 2 INT GAMIFIN C
   Read Tyler, 2021, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P913, DOI 10.1177/1071181321651337
   Real S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020523
   Resnick B, 2011, TOP STROKE REHABIL, V18, P611, DOI 10.1310/tsr18s01-611
   Richardson M, 2016, DISABIL REHABIL, V38, P1425, DOI 10.3109/09638288.2015.1102337
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Roberts R, 2008, J SPORT EXERCISE PSY, V30, P200, DOI 10.1123/jsep.30.2.200
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Ruffino C, 2017, NEUROSCIENCE, V341, P61, DOI 10.1016/j.neuroscience.2016.11.023
   SALTIN B, 1968, CIRCULATION, V38, P1104, DOI 10.1161/01.CIR.38.6.1104
   Sheng B, 2016, MED ENG PHYS, V38, P587, DOI 10.1016/j.medengphy.2016.04.004
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stanica IC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216045
   Sun JH, 2014, ANN TRANSL MED, V2, DOI 10.3978/j.issn.2305-5839.2014.08.05
   Suzuki K, 2017, P IEEE VIRT REAL ANN, P177, DOI 10.1109/VR.2017.7892245
   Szczepanska-Gieracha J, 2020, NEUROREHABILITATION, V47, P109, DOI 10.3233/NRE-203209
   Thiele A, 2018, NEURON, V97, P769, DOI 10.1016/j.neuron.2018.01.008
   Thiese MS, 2014, BIOCHEM MEDICA, V24, P199, DOI 10.11613/BM.2014.022
   Tollár J, 2021, ARCH PHYS MED REHAB, V102, P9, DOI 10.1016/j.apmr.2020.07.012
   Tondello GF, 2016, CHI PLAY 2016: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION, P315, DOI 10.1145/2968120.2987729
   Trombetta M, 2017, COMPUT METH PROG BIO, V151, P15, DOI 10.1016/j.cmpb.2017.08.008
   Tufanaru C., 2020, JBI MANUAL EVIDENCE, DOI [DOI 10.46658/JBIMES-20-04, 10.46658/JBIMES-20-04]
   Vassiliadis P, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102821
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00244
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00210
   Vourvopoulos A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0173-2
   Wedoff R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300371
   Widmer M, 2017, TRIALS, V18, DOI 10.1186/s13063-017-2328-2
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   You SH, 2005, STROKE, V36, P1166, DOI 10.1161/01.STR.0000162715.43417.91
   Yozbatiran N, 2008, NEUROREHAB NEURAL RE, V22, P78, DOI 10.1177/1545968307305353
   Zeiaee A, 2017, INT C REHAB ROBOT, P759, DOI 10.1109/ICORR.2017.8009339
   Zhang X, 2015, IEEE ENG MED BIO, P4582, DOI 10.1109/EMBC.2015.7319414
NR 119
TC 4
Z9 4
U1 2
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 3
PY 2022
VL 3
AR 889271
DI 10.3389/frvir.2022.889271
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VU5
UT WOS:001023266900001
OA gold
DA 2024-07-18
ER

PT J
AU Vallance, M
   Towndrow, PA
AF Vallance, Michael
   Towndrow, Phillip A.
TI Perspective: Narrative Storyliving in Virtual Reality Design
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE chronotope; design; storyliving; storytelling; virtual reality
AB The development and relative affordability of Virtual Reality in recent years have provided opportunities to experience representations of both concrete and abstract situations; from nuclear engineering to particle physics, art galleries to three-dimensional prehistoric paintings, person-to-person communication to artificial agent collaboration, and 360-degree journalism to animated movies. Yet, it still remains challenging for participants to create personal narratives within a virtual world beyond that structured by its original designers. Setting aside technological considerations, we attribute this limitation largely to a restricted conceptualization of time and space that is fixed to present events, emotions and experiences. Consequently, Virtual Reality scenarios, as immersive and plausible as they might be, are nonetheless prone to a thin and static view of the (virtual) world where growth and experiential learning are not always possible or privileged. In this Perspective we propose a recasting of Virtual Reality that combines novelistic storytelling in the physical world with "narrative storyliving" as a mechanism for meaning-making within and across large dialogic arenas. This involves us drawing on ideas from the Russian philosopher and theorist, Mikhail Bakhtin, relating to the literary artistic chronotope. Ultimately, we intend to advance the discourse about what Virtual Reality is at present, and where it could go as seen through a critical literary lens.
C1 [Vallance, Michael] Future Univ Hakodate, Dept Media Architecture, Hakodate, Japan.
   [Towndrow, Phillip A.] Nanyang Technol Univ, Natl Inst Educ, Ctr Res Pedag & Practice, Singapore, Singapore.
C3 Future University Hakodate; Nanyang Technological University; National
   Institute of Education (NIE) Singapore
RP Vallance, M (corresponding author), Future Univ Hakodate, Dept Media Architecture, Hakodate, Japan.
EM michael@fun.ac.jp
FU Grants-in-Aid for Scientific Research [22K02949] Funding Source: KAKEN
CR Astiz M.F., 2020, College Teaching, V68, P187
   Aylett R., 2003, Virtual Reality, V7, P2, DOI 10.1007/s10055-003-0114-9
   Aylett R, 2007, LECT NOTES COMPUT SC, V4871, P117
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bakhtin Mikhail., 1981, The Dialogic Imagination, P3
   Bemong N, 2010, BAKHTIN'S THEORY OF THE LITERARY CHRONOTOPE: REFLECTIONS, APPLICATIONS, PERSPECTIVES, P3
   Bucher J, 2018, STORYTELLING FOR VIRTUAL REALITY: METHODS AND PRINCIPLES FOR CRAFTING IMMERSIVE NARRATIVES, P1
   Cavazza M., 2003, LECT NOTES COMP SCI, VVol. 2792, DOI [10.1007/978-3-540-39396-2_39, DOI 10.1007/978-3-540-39396-2_39]
   Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096
   Clark D., 2020, ARTIF INTELL
   Damiani J., 2016, GREAT SEMANTIC DIVID
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Dostoyevsky Fyodor., 2001, Crime and Punishment
   Fox J, 2013, COMPUT HUM BEHAV, V29, P930, DOI 10.1016/j.chb.2012.12.027
   Gardiner W. L., 1995, International Journal of Virtual Reality, V1, P22
   Gayet M., 2020, XR MUST
   Greenwald M., 2017, STORYTELLING VRSTORY
   Kern Stephen., 2003, The Culture of Time and Space, 1880-1918: With a New Preface
   Kim G, 2018, LECT NOTES COMPUT SC, V10910, P94, DOI 10.1007/978-3-319-91584-5_8
   Koleva B., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P233, DOI 10.1145/332040.332437
   Lee M. J. W., 2021, The state of XR and immersive learning: Outlook report 2021
   Maschio T., 2017, Storyliving: An Ethnographic Study of how Audiences Experience VR and What That Means for Journalists
   Milk C., 2015, Clouds Over Sidra
   Murray JanetH., 2017, HAMLET HOLODECK, V2nd
   Nelson M.E., 2008, Self-presentation through multimedia: A Bakhtinian perspective on digital storytelling. Digital storytelling
   Rabelais Francois., 2006, GARGANTUA PANTAGRUEL
   Rubin M., 2016, Interdisciplinary Handbook of Trauma and Culture, DOI [10.1007/978-3-319-29404-9_18, DOI 10.1007/978-3-319-29404-9_18]
   Schechtman Marya., 2011, OXFORD HDB SELF, P394
   Silverstein Jake., 2015, The New York Times Magazine
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Sundar SS, 2017, CYBERPSYCH BEH SOC N, V20, P672, DOI 10.1089/cyber.2017.0271
   Wang M, 2020, COMPUT VIS MEDIA, V6, P3, DOI 10.1007/s41095-020-0162-z
   Weber S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.628298
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 34
TC 11
Z9 11
U1 11
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 31
PY 2022
VL 3
AR 779148
DI 10.3389/frvir.2022.779148
PG 5
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TF8
UT WOS:001021828100001
OA gold
DA 2024-07-18
ER

PT J
AU Alvarado, E
   Paliard, C
   Rohmer, D
   Cani, MP
AF Alvarado, Eduardo
   Paliard, Chloe
   Rohmer, Damien
   Cani, Marie-Paule
TI Real-Time Locomotion on Soft Grounds With Dynamic Footprints
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE character animation; kinematics; natural phenomenon; terrain
   deformation; real time
ID ANIMATING SAND
AB When we move on snow, sand, or mud, the ground deforms under our feet, immediately affecting our gait. We propose a physically based model for computing such interactions in real time, from only the kinematic motion of a virtual character. The force applied by each foot on the ground during contact is estimated from the weight of the character, its current balance, the foot speed at the time of contact, and the nature of the ground. We rely on a standard stress-strain relationship to compute the dynamic deformation of the soil under this force, where the amount of compression and lateral displacement of material are, respectively, parameterized by the soil's Young modulus and Poisson ratio. The resulting footprint is efficiently applied to the terrain through procedural deformations of refined terrain patches, while the addition of a simple controller on top of a kinematic character enables capturing the effect of ground deformation on the character's gait. As our results show, the resulting footprints greatly improve visual realism, while ground compression results in consistent changes in the character's motion. Readily applicable to any locomotion gait and soft soil material, our real-time model is ideal for enhancing the visual realism of outdoor scenes in video games and virtual reality applications.
C1 [Alvarado, Eduardo; Rohmer, Damien; Cani, Marie-Paule] Inst Polytech Paris, Ecole Polytech, LIX, CNRS, Palaiseau, France.
   [Paliard, Chloe] Inst Polytech Paris, LTCI, Telecom Paris, Palaiseau, France.
C3 Institut Polytechnique de Paris; Ecole Polytechnique; Centre National de
   la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris
RP Alvarado, E (corresponding author), Inst Polytech Paris, Ecole Polytech, LIX, CNRS, Palaiseau, France.
EM eduardo.alvarado-pinero@polytechnique.edu
RI Alvarado, Eduardo/JAD-1927-2023
OI Alvarado, Eduardo/0000-0003-3395-5674; Rohmer,
   Damien/0000-0002-3302-5197
FU European Union's Horizon 2020 Research and Innovation Programme under
   the Marie Sklodowska-Curie Grant [860768]; Marie Curie Actions (MSCA)
   [860768] Funding Source: Marie Curie Actions (MSCA)
FX This work received funding from the European Union's Horizon 2020
   Research and Innovation Programme under the Marie Sklodowska-Curie Grant
   Agreement n. 860768 (CLIPE project).
CR [Anonymous], 1956, THEORY LAND LOCOMOTI
   Benes B., 2004, WSCG INT C COMP GRAP
   Bermudez L, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274515
   Carensac S., 2016, ACM SIGGRAPH C MOT I
   Cordonnier G, 2018, COMPUT GRAPH FORUM, V37, P497, DOI 10.1111/cgf.13379
   Cordonnier G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073667
   Daviet G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925877
   Ecormier-Nocca Pierre, 2021, ACM Transactions on Graphics, V40, DOI 10.1145/3476576.3476668
   Galin E, 2019, COMPUT GRAPH FORUM, V38, P553, DOI 10.1111/cgf.13657
   Garcia A. L., 2012, ACM SIGGRAPH 2012 CO, DOI DOI 10.1145/2343483.2343496
   Gerling B, 2017, GEOPHYS RES LETT, V44, P11088, DOI 10.1002/2017GL075110
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Ihmsen M, 2013, COMPUT GRAPH-UK, V37, P800, DOI 10.1016/j.cag.2013.04.010
   Klár G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925906
   Kwon T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392432
   Kwon Taesoo, 2010, P 2010 ACM SIGGRAPHE, P129
   Lenaerts T, 2009, COMPUT GRAPH FORUM, V28, P213, DOI 10.1111/j.1467-8659.2009.01360.x
   Mitake H, 2009, COMPUT GRAPH FORUM, V28, P279, DOI 10.1111/j.1467-8659.2009.01367.x
   Narain R, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866195
   Onoue K, 2005, COMPUT GRAPH FORUM, V24, P51, DOI 10.1111/j.1467-8659.2005.00828.x
   Paliard C., 2021, EUROGRAPHICS 2021 SH, DOI [10.2312/egs.20211019, DOI 10.2312/EGS.20211019]
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311
   Ren L, 2008, J BIOMECH, V41, P2750, DOI 10.1016/j.jbiomech.2008.06.001
   Shahabpoor E, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092085
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Sumner RW, 1999, COMPUT GRAPH FORUM, V18, P17, DOI 10.1111/1467-8659.00299
   Sun HC, 2001, COMP GRAPH, P261, DOI 10.1145/383259.383288
   Wang JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778810
   Won J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392381
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
   Ying Zhu, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P431
   Zeng YL, 2007, COMPUT ANIMAT VIRT W, V18, P289, DOI 10.1002/cav.209
   Zhu KX, 2021, IEEE T VIS COMPUT GR, V27, P2073, DOI 10.1109/TVCG.2019.2944172
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 34
TC 2
Z9 2
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 28
PY 2022
VL 3
AR 801856
DI 10.3389/frvir.2022.801856
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2UK8
UT WOS:001021859100001
OA Green Published, gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Rivas, AIB
   Navarro, X
   Banakou, D
   Oliva, R
   Orvalho, V
   Slater, M
AF Rivas, Anna I. Bellido I.
   Navarro, Xavi
   Banakou, Domna
   Oliva, Ramon
   Orvalho, Veronica
   Slater, Mel
TI The Influence of Embodiment as a Cartoon Character on Public Speaking
   Anxiety
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE embodiment; virtual reality; body ownership; fear of public speaking;
   cartoon
ID OWNERSHIP; SELF; VALIDATION; ILLUSION; HAND
AB Virtual Reality can be used to embody people in different types of body-so that when they look towards themselves or in a mirror they will see a life-sized virtual body instead of their own, and that moves with their own movements. This will typically give rise to the illusion of body ownership over the virtual body. Previous research has focused on embodiment in humanoid bodies, albeit with various distortions such as an extra limb or asymmetry, or with a body of a different race or gender. Here we show that body ownership also occurs over a virtual body that looks like a cartoon rabbit, at the same level as embodiment as a human. Furthermore, we explore the impact of embodiment on performance as a public speaker in front of a small audience. Forty five participants were recruited who had public speaking anxiety. They were randomly partitioned into three groups of 15, embodied as a Human, as the Cartoon rabbit, or from third person perspective (3PP) with respect to the rabbit. In each condition they gave two talks to a small audience of the same type as their virtual body. Several days later, as a test condition, they returned to give a talk to an audience of human characters embodied as a human. Overall, anxiety reduced the most in the Human condition, the least in the Cartoon condition, and there was no change in the 3PP condition, taking into account existing levels of trait anxiety. We show that embodiment in a cartoon character leads to high levels of body ownership from the first person perspective and synchronous real and virtual body movements. We also show that the embodiment influences outcomes on the public speaking task.
C1 [Rivas, Anna I. Bellido I.; Navarro, Xavi; Banakou, Domna; Oliva, Ramon; Slater, Mel] Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.
   [Banakou, Domna; Slater, Mel] Univ Barcelona, Inst Neurosci, Barcelona, Spain.
   [Orvalho, Veronica] Univ Porto, Inst Telecominicacoes, Porto, Portugal.
   [Rivas, Anna I. Bellido I.] Netquest, Barcelona, Spain.
C3 University of Barcelona; University of Barcelona; Universidade do Porto
RP Slater, M (corresponding author), Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.; Slater, M (corresponding author), Univ Barcelona, Inst Neurosci, Barcelona, Spain.
EM melslater@ub.edu
RI Navarro, Xavi/KEE-5474-2024
OI Banakou, Domna/0000-0002-0974-6971
CR Abuín Manuel R., 2014, Clínica y Salud, V25, P131
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   [Anonymous], 1995, SOCIAL PHOBIA DIAGNO
   Aymerich-Franch L, 2020, INT J SOC ROBOT, V12, P217, DOI 10.1007/s12369-019-00556-5
   Aymerich-Franch L, 2017, INT J SOC ROBOT, V9, P479, DOI 10.1007/s12369-017-0397-8
   Aymerich-Franch L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00944
   AYRES J, 1990, COMMUN EDUC, V39, P283, DOI 10.1080/03634529009378810
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Barberia I, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203358
   Bedder RL, 2019, COGNITION, V184, P1, DOI 10.1016/j.cognition.2018.11.010
   Blanke O, 2015, NEURON, V88, P145, DOI 10.1016/j.neuron.2015.09.029
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Charbonneau P., 2017, INT C VIRT REH, V2017, P1, DOI [10.1109/ICVR.2017.8007535, DOI 10.1109/ICVR.2017.8007535]
   Chesham RK, 2018, BEHAV CHANGE, V35, P152, DOI 10.1017/bec.2018.15
   Clark D.M., 2001, INT HDB SOCIAL ANXIE, P405, DOI 10.1016/S0006-3223(97)87445-8
   Ebrahimi OV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00488
   Ehrsson H.H., 2012, HDB MULTISENSORY PRO, P775, DOI DOI 10.1126/SCIENCE.1097011
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Marinho ACF, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2015.12.012
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Gelkopf M., 1996, J COGN PSYCHOTHER, V10, P235, DOI DOI 10.1891/0889-8391.10.4.235
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Guterstam A, 2013, J COGNITIVE NEUROSCI, V25, P1078, DOI 10.1162/jocn_a_00393
   Guterstam A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017208
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   JACKSON JM, 1981, J PERS SOC PSYCHOL, V40, P73, DOI 10.1037/0022-3514.40.1.73
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Gallego MJ, 2009, BEHAV PSYCHOL, V17, P413
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Krekhov A., 2019, IEEE CONF COMPU INTE, P1
   Kross E, 2017, ADV EXP SOC PSYCHOL, V55, P81, DOI 10.1016/bs.aesp.2016.10.002
   Kruschke JK, 2011, PERSPECT PSYCHOL SCI, V6, P272, DOI 10.1177/1745691611406926
   Lemoine NP, 2019, OIKOS, V128, P912, DOI 10.1111/oik.05985
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   North M. M., 1998, International Journal of Virtual Reality, V3, P2
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Paul G.L., 1966, INSIGHT VS DESENSITI
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Perez-Marcos D, 2012, COGN NEURODYNAMICS, V6, P295, DOI 10.1007/s11571-011-9178-5
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Seisdedos N., 1988, Spanish adaptation of the STAI, state-trait anxiety inventory
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Spielberger CD, 2010, The Corsini Encyclopedia of Psychology, DOI [DOI 10.1002/9780470479216.CORPSY0943, 10.1002/9780470479216.corpsy0943]
   Stan Development Team, 2011, STAN MOD LANG US GUI
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Tagalidou N, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2075-x
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Tieri G, 2015, EXP BRAIN RES, V233, P1247, DOI 10.1007/s00221-015-4202-3
   van de Schoot R, 2017, PSYCHOL METHODS, V22, P217, DOI 10.1037/met0000100
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Vanni F, 2013, EUR REV MED PHARMACO, V17, P1561
   Vehtari A, 2017, STAT COMPUT, V27, P1413, DOI 10.1007/s11222-016-9696-4
   Won A S., 2015, Emerging Trends in the Social and Behavioral Sciences: An Interdisciplinary, Searchable, and Linkable Resource, P1
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 64
TC 3
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 22
PY 2021
VL 2
AR 695673
DI 10.3389/frvir.2021.695673
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZI7
UT WOS:001019261300001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Rogers, K
   Karaosmanoglu, S
   Wolf, D
   Steinicke, F
   Nacke, LE
AF Rogers, Katja
   Karaosmanoglu, Sukran
   Wolf, Dennis
   Steinicke, Frank
   Nacke, Lennart E.
TI A Best-Fit Framework and Systematic Review of Asymmetric Gameplay in
   Multiplayer Virtual Reality Games
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE VR; virtual reality; asymmetry; games; systematic review; asymmetric
   games
ID SELF-DETERMINATION THEORY; VIDEO GAMES; EXPERIENCE; ENVIRONMENTS;
   FRIENDS; SCALES; FAMILY
AB Increasingly, virtual reality (VR) design and research leverages gameplay asymmetries, flattening discrepancies of interface, abilities, information or other aspects between players. A common goal is to induce social interactions that draw players without head-mounted displays into a shared game world. Exploring these asymmetries resulted in many artifacts, creating an innovative yet disparate research landscape that showcases points for improvement in coverage of the field and theoretical underpinnings. In this article, we present a literature review of asymmetry in multiplayer VR games, using a framework synthesis method to assess the field through a lens of existing literature on asymmetries in gameplay. We provide an overview of this emerging subfield and identify gaps and opportunities for future research. Moreover, we discuss how research artifacts address prior theoretical work and present a "best fit" framework of asymmetric multiplayer VR games for the community to build upon.
C1 [Rogers, Katja; Nacke, Lennart E.] Univ Waterloo, Games Inst, HCI Games Grp, Waterloo, ON, Canada.
   [Rogers, Katja; Nacke, Lennart E.] Univ Waterloo, Dept Commun Arts, Waterloo, ON, Canada.
   [Rogers, Katja; Nacke, Lennart E.] Univ Waterloo, Stratford Sch Interact Design & Business, Waterloo, ON, Canada.
   [Karaosmanoglu, Sukran; Steinicke, Frank] Univ Hamburg, Human Comp Interact, Hamburg, Germany.
   [Wolf, Dennis] Ulm Univ, Inst Media Informat, Ulm, Germany.
C3 University of Waterloo; University of Waterloo; University of Waterloo;
   University of Hamburg; Ulm University
RP Rogers, K (corresponding author), Univ Waterloo, Games Inst, HCI Games Grp, Waterloo, ON, Canada.; Rogers, K (corresponding author), Univ Waterloo, Dept Commun Arts, Waterloo, ON, Canada.; Rogers, K (corresponding author), Univ Waterloo, Stratford Sch Interact Design & Business, Waterloo, ON, Canada.
EM katja.rogers@acm.org
RI Nacke, Lennart/O-1785-2019; Wolf, Dennis/S-9217-2018; Steinicke,
   Frank/AAC-2976-2020
OI Nacke, Lennart/0000-0003-4290-8829; Wolf, Dennis/0000-0003-1525-4348;
   Steinicke, Frank/0000-0001-9879-7414; Karaosmanoglu,
   Sukran/0000-0002-9624-4258
CR Abuhamdeh S, 2015, MOTIV EMOTION, V39, P1, DOI 10.1007/s11031-014-9425-2
   [Anonymous], 2009, OBSERVATORIO OBS, DOI DOI 10.15847/OBSOBS312009243
   [Anonymous], 2004, Standard quality assessment criteria for evaluating primary research papers from a variety of fields. (HTA Initiative #13), DOI DOI 10.7939/R37M04F16
   Aromataris E, 2020, Synth, DOI [10.46658/JBIMES-20-01, DOI 10.46658/JBIMES-20-01, DOI 10.46658/JBIMES-20-11, 10.46658/JBIMES-20-02]
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Benford Steve, 2012, P SIGCHI C HUM FACT, P2005, DOI [DOI 10.1145/2207676.2208347, 10.1145/2207676.2208347, 10.1145/2207676.2208347event-place:Austin,Texas,USA, DOI 10.1145/2207676.2208347EVENT-PLACE:AUSTIN,TEXAS,USA]
   Berger R, 2015, QUAL RES, V15, P219, DOI 10.1177/1468794112468475
   Beznosyk Anastasiia, 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P243, DOI 10.1007/978-3-642-33542-6_21
   Boland Daniel., 2015, XRDS: Crossroads, The ACM Magazine for Students, V22, P40, DOI [10.1145/2810046, DOI 10.1145/2810046]
   Bopp JA, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2996, DOI 10.1145/2858036.2858227
   Borderie J, 2017, R ADV GAME STUD, P32
   Bortolaso C, 2019, LECT NOTES COMPUT SC, V11863, P250, DOI 10.1007/978-3-030-34644-7_20
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Braun V, 2021, QUAL RES PSYCHOL, V18, P328, DOI 10.1080/14780887.2020.1769238
   Brudy F., 2019, CROSS DEVICE TAXONOM, P1
   Burtscher Sabrina, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P431, DOI 10.1145/3404983.3405510
   Buscemi N, 2006, J CLIN EPIDEMIOL, V59, P697, DOI 10.1016/j.jclinepi.2005.11.010
   Cairns P, 2021, GAMES CULT, V16, P262, DOI 10.1177/1555412019893877
   Carroll C, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-37
   Carroll C, 2011, BMC MED RES METHODOL, V11, DOI 10.1186/1471-2288-11-29
   Cechanowicz JaredE., 2014, Proceedings of the First ACM SIGCHI Annual Symposium on Computer-human Interaction in Play, CHI PLAY'14, P47, DOI DOI 10.1145/2658537.2658701
   Cheng LP, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3463, DOI 10.1145/2556288.2557101
   CIOLEK TM, 1983, J NONVERBAL BEHAV, V8, P55, DOI 10.1007/BF00986330
   Coleman B, 2009, IEEE PERVAS COMPUT, V8, P16, DOI 10.1109/MPRV.2009.60
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   de Kort YAW, 2007, P 10 ANN INT WORKSHO, P195
   Deci E. L., 2012, HDB THEORIES SOCIAL, V1, P416, DOI [DOI 10.4135/9781446249215.N21, 10.4135/9781446201022]
   Depping AE, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1040, DOI 10.1145/3025453.3025648
   Depping AE, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P116, DOI 10.1145/2967934.2968097
   Deterding Sebastian, 2015, P 33 ANN ACM C EXT A, P2365, DOI DOI 10.1145/2702613.2702647
   Dixon-Woods M, 2011, BMC MED, V9, DOI 10.1186/1741-7015-9-39
   Dourish P., 2004, ACTION IS FDN EMBODI
   Efstratios G, 2018, LECT NOTES COMPUT SC, V11196, P518, DOI 10.1007/978-3-030-01762-0_45
   Eklund L, 2015, J GAMING VIRTUAL WOR, V7, P259, DOI 10.1386/jgvw.7.3.259_1
   El-Nasr MS, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P253
   Fitterer D., 2016, AUDIOSHIELD
   Furukawa T., 2019, SIGGRAPH 19 ACM SIGG, DOI [10.1145/3305367.3335040, DOI 10.1145/3305367.3335040]
   Gamer M., 2012, PACKAGE IRRVARIOUS C
   George C, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P497, DOI 10.1145/3322276:3322363
   Gerling KM, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2201, DOI 10.1145/2556288.2556963
   Goncalves D., 2021, ASS COMPUTING MACHIN, DOI [10.1145/3411764.3445494, DOI 10.1145/3411764.3445494]
   Graf R, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P31, DOI 10.1145/3311350.3347161
   GUGENHEIMER J, 2017, P 2017 CHI C HUM FAC, P369, DOI DOI 10.1145/3027063.3052962
   Gugenheimer J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173628
   Gugenheimer J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P755, DOI 10.1109/VR.2018.8446551
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Gutwin C., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P207, DOI 10.1145/289444.289495
   Hall E. T., 1966, HIDDEN DIMENSION 196
   Hansen A, 2020, LECT NOTES COMPUT SC, V12242, P22, DOI 10.1007/978-3-030-58465-8_2
   Harms C., 2004, Seventh Annual International Workshop: Presence 2004
   Harper Richard., 2013, CSCW TM, V13, P167
   Harris J., 2019, Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI, V19, P1, DOI DOI 10.1145/3290605.3300239
   Harris J., 2014, CHI PLAY 14, P417, DOI [10.1145/2658537.2661311, DOI 10.1145/2658537.2661311]
   Harris J, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P350, DOI 10.1145/2967934.2968113
   Hornecker E, 2005, ECSCW 2005: PROCEEDINGS OF THE NINTH EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK, P23, DOI 10.1007/1-4020-4023-7_2
   Hudson M., 2014, INTERACTING PRESENCE, P83, DOI [10.2478/9783110409697.6, DOI 10.2478/9783110409697.6]
   Hunicke R., 2004, Proc. AAAI Wksp. Challenges in Game AI, V4, P1722
   IJsselsteijn WA., 2013, GAME EXPERIENCE QUES, P3
   Jeong K, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010053
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Johnson D, 2018, INT J HUM-COMPUT ST, V118, P38, DOI 10.1016/j.ijhcs.2018.05.003
   Karaosmanoglu Sukran, 2021, P 2021 CHI C HUMAN F
   Kaye LK, 2016, COMPUT HUM BEHAV, V55, P286, DOI 10.1016/j.chb.2015.09.023
   Kendon Adam, 2009, Development of Multimodal Interfaces: Active Listening and Synchrony. Second COST 2102 International Training School. Revised Selected Papers, P1
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kerure A. A., 2018, AUDIO ENG SOC CONVEN, P144
   Kim E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376280
   Kiourt C., 2020, APPL INNOVATIVE TECH, P85, DOI [10.4018/978-1-7998-2871-6.ch005, DOI 10.4018/978-1-7998-2871-6.CH005]
   Klimmt C., 2008, MEDIATED INTERPERSON, V309, P323, DOI [10.4324/9780203926864-26, DOI 10.4324/9780203926864-26]
   Knierim P, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2996747
   Law ELC, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P257, DOI 10.1145/3242671.3242683
   Leavitt A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4337, DOI 10.1145/2858036.2858132
   Lee J, 2020, MULTIMED TOOLS APPL, V79, P979, DOI 10.1007/s11042-019-08220-w
   Li J., 2017, CHI PLAY 17, P585, DOI [10.1145/3130859.3130860, DOI 10.1145/3130859.3130860]
   Li J., 2017, CHI PLAY 17, P431, DOI [10.1145/3130859.3131341, DOI 10.1145/3130859.3131341]
   Lifton JH., 2007, THESIS MIT
   Liszio S, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102086
   Liszio S, 2016, LECT NOTES COMPUT SC, V9926, P235, DOI 10.1007/978-3-319-46100-7_23
   MacArthur C, 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445701
   Manninen T., 2005, DIGRA C SELECTED PAP, P233
   Marquardt N, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P13
   Marquez Segura Elena, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445592
   Martinez-Ruiz Francisco J., 2020, Human Interaction and Emerging Technologies. Proceedings of the 1st International Conference on Human Interaction and Emerging Technologies (IHIET 2019). Advances in Intelligent Systems and Computing (AISC 1018), P489, DOI 10.1007/978-3-030-25629-6_76
   McDonald Nora, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359174
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Morris M. R., 2004, Computer Supported Cooperative Work Conference Proceedings, P262, DOI 10.1145/1031607.1031648
   Murray JH, 2017, HAMLET ON THE HOLODECK: THE FUTURE OF NARRATIVE IN CYBERSPACE, P1
   Mutterlein J., 2017, 23 AM C INF SYST AMC
   Nakagawa R, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P6, DOI 10.1145/3355355.3361886
   Nestler S, 2011, DIAGNOSTICA, V57, P57, DOI 10.1026/0012-1924/a000032
   Newton BJ, 2012, J HEALTH PSYCHOL, V17, P866, DOI 10.1177/1359105311427615
   Nowell LS, 2017, INT J QUAL METH, V16, DOI 10.1177/1609406917733847
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P19, DOI 10.1145/3393712.3395339
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Odd Raven Studios, 2019, CARL REAP ESC UND
   Olin Patrick Aggergaard, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P112, DOI 10.1145/3441000.3441070
   Osmanovic S, 2016, GAMES CULT, V11, P130, DOI 10.1177/1555412015602819
   Othlinghaus J., 2011, WORKSH P MENSCH COMP
   Ouverson Kaitlyn M., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449079
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Perry R, 2018, COMPUT HUM BEHAV, V79, P202, DOI 10.1016/j.chb.2017.10.032
   Pinelle D., 2003, ACM Transactions on Computer-Human Interaction, V10, P281, DOI 10.1145/966930.966932
   Piumsomboon Thammathip., 2018, Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI'18, P1, DOI DOI 10.1145/3173574.3173620
   Pope C, 2000, BMJ-BRIT MED J, V320, P114, DOI 10.1136/bmj.320.7227.114
   Reeves Stuart, 2005, P SIGCHI C HUM FACT, P741, DOI [10.1145/1054972.1055074, DOI 10.1145/1054972.1055074, DOI 10.1145/1054972.1055074147Q]
   Reilly D. F, 2010, PROC UIST, DOI [10.1145/1866029.1866050, DOI 10.1145/1866029.1866050]
   Resolution Games, 2019, ACR ATT SQUIRR
   Rigby S, 2007, The player experience of need satisfaction (PENS) model
   Ritchie J., 1994, Analyzing qualitative data, DOI DOI 10.4324/9780203413081_CHAPTER_9
   Rogers K., 2019, CHI 19 P 2019 CHI C, P1, DOI [10.1145/3290605.3300644, DOI 10.1145/3290605.3300644]
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   RUSSELL D, 1978, J PERS ASSESS, V42, P290, DOI 10.1207/s15327752jpa4203_11
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Sajjadi P., 2014, P 1 ACM SIGCHI ANN S, P227, DOI [10.1145/2658537.2658690, DOI 10.1145/2658537.2658690]
   Salen Katie, 2004, RULES PLAY GAME DESI
   Schmidt S, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357591
   Schmitz M., 2015, CHI PLAY 15, P427, DOI [10.1145/2793107.2810306, DOI 10.1145/2793107.2810306]
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Scott SD, 2003, ECSCW 2003: PROCEEDINGS OF THE EIGHTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P159
   Serubugo S, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141774
   Serubugo S, 2018, L N INST COMP SCI SO, V229, P64, DOI 10.1007/978-3-319-76908-0_7
   Serubugo S, 2018, L N INST COMP SCI SO, V229, P194, DOI 10.1007/978-3-319-76908-0_19
   Sigitov A, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00128
   Simeone AL, 2020, ISS '20 COMPANION: COMPANION PROCEEDINGS OF THE 2020 CONFERENCE ON INTERACTIVE SURFACES AND SPACES, P111, DOI 10.1145/3380867.3424551
   Simon B., 2009, SSRN J, DOI [10.2139/ssrn.1354043, DOI 10.2139/SSRN.1354043]
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Smilovitch M, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P307, DOI 10.1145/3341215.3358246
   Sra M., 2017, VRST 17, DOI [10.1145/3139131.3141219, DOI 10.1145/3139131.3141219]
   Sra M., 2016, P 29 ANN S US INT SO, P221
   Steel Crate Games, 2015, KEEP TALK NOB EXPL
   Streck A, 2019, IEEE CONF COMPU INTE
   Streck A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P245, DOI 10.1109/AIVR46125.2019.00054
   Striner A, 2019, LECT NOTES COMPUT SC, V11869, P214, DOI 10.1007/978-3-030-33894-7_23
   Sykownik P., 2017, INT C ADV COMP ENT L, P847, DOI [10.1007/978-3-319-76270-8_57, DOI 10.1007/978-3-319-76270-8_57]
   Team Panoptes, 2019, PAN
   Tse E., 2004, Computer Supported Cooperative Work Conference Proceedings, P252, DOI 10.1145/1031607.1031647
   Vanden Abeele V, 2020, INT J HUM-COMPUT ST, V135, DOI 10.1016/j.ijhcs.2019.102370
   Vella K, 2020, BEHAV INFORM TECHNOL, V39, P917, DOI 10.1080/0144929X.2019.1625442
   Vicencio-Moreira R, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P937, DOI 10.1145/2556288.2557308
   Voida A, 2012, UNIVERSAL ACCESS INF, V11, P45, DOI 10.1007/s10209-011-0232-1
   Walther J.B., 2015, The International Encyclopedia of Interpersonal Communication, P1, DOI [10.1002/9781118540190.wbeic192, DOI 10.1002/9781118540190.WBEIC192]
   Wang MJ, 2020, INTERACT LEARN ENVIR, V28, P539, DOI 10.1080/10494820.2019.1696845
   Want R, 2009, IEEE PERVAS COMPUT, V8, P2
   Wells JD, 2010, DECISION SCI, V41, P813, DOI 10.1111/j.1540-5915.2010.00292.x
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wohlin C., 2014, INT C EVALUATION ASS, P1
   Woodworth JW, 2017, P IEEE VIRT REAL ANN, P471, DOI 10.1109/VR.2017.7892384
   Yassemi A, 2020, PHARM DEV TECHNOL, V25, P397, DOI 10.1080/10837450.2019.1703739
   Zagal JP, 2006, SIMULAT GAMING, V37, P24, DOI 10.1177/1046878105282279
   Zhou ZM, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P5, DOI 10.1145/3311350.3347152
NR 155
TC 8
Z9 10
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 27
PY 2021
VL 2
AR 694660
DI 10.3389/frvir.2021.694660
PG 23
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AH1
UT WOS:001019285900001
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Schuch, CP
   Balbinot, G
   Bonilla, MN
   Machado, AG
   de Oliveira, AA
AF Schuch, Clarissa Pedrini
   Balbinot, Gustavo
   Bonilla, Marilley Nohely
   Machado, Andrea Guedes
   de Oliveira, Alcyr Alves
TI Feasibility of a Short-Term Virtual Reality Balance Intervention to
   Improve Mobility Smoothness in Parkinson's Disease
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Parkinson's disease; mobility; smoothness; virtual reality; cognitive
   function; spectral arc length
ID GAIT; PEOPLE; STROKE
AB Parkinson's disease (PD) is a neurodegenerative condition that is often associated with movement impairments, such as reduced balance and gait control. Virtual reality (VR) is a promising intervention for enhancing rehabilitation efficiency and may assist in overcoming functional limitations imposed by the disability. The objective of this study was to evaluate the feasibility, safety, and efficacy of a 5-weeks VR intervention in increasing mobility smoothness in participants with PD. Participants were assessed using functional mobility tasks-Timed Up and Go (TUG) and 10-m walking test (10MWT) and cognitive function tests. A total of 23 participants with a diagnosis of PD were randomly assigned to groups of VR or control interventions. In the VR group, for each session, participants received a VR-based balance training, i.e., tightrope simulator, for 20 min, preceded by 8 min of total body warm-up (total of 10 sessions over 5 weeks). Participants in the control group received 20 min of psychoeducation without a structured exercise program (twice a week). All screened participants engaged and completed a total of 10 VR-based intervention sessions. VR-based balance training caused no significant improvement in mobility smoothness for TUG or 10MWT (p > 0.05). Similarly, cognitive function was not affected by the VR intervention (p > 0.05). The outcomes of this study suggest that 10-20 min of VR-based intervention is a feasible and safe rehabilitation activity. However, it was insufficient to promote improvement in mobility smoothness and cognitive function in participants with PD. A combination of task-specific training in the virtual and physical environments in a more intensive approach is warranted for future study designs.
C1 [Schuch, Clarissa Pedrini; Bonilla, Marilley Nohely; Machado, Andrea Guedes; de Oliveira, Alcyr Alves] Fed Univ Hlth Sci Porto Alegre UFCSPA, Grad Program Rehabil Sci, Neurosci & Expt Virtual Real Lab, Porto Alegre, Brazil.
   [Balbinot, Gustavo] Univ Hlth Network, Toronto Rehabil Inst, KITE, Toronto, ON, Canada.
   [de Oliveira, Alcyr Alves] Fed Univ Hlth Sci Porto Alegre UFCSPA, Dept Psychol, Porto Alegre, Brazil.
C3 Universidade Federal de Ciencias da Saude de Porto Alegre; University of
   Toronto; University Health Network Toronto; Toronto Rehabilitation
   Institute; Universidade Federal de Ciencias da Saude de Porto Alegre
RP Schuch, CP (corresponding author), Fed Univ Hlth Sci Porto Alegre UFCSPA, Grad Program Rehabil Sci, Neurosci & Expt Virtual Real Lab, Porto Alegre, Brazil.
EM clarissaps@ufcspa.edu.br
RI Oliveira, Alcyr/D-2991-2014
OI Oliveira, Alcyr/0000-0002-0747-7835; Pedrini Schuch,
   Clarissa/0000-0001-5487-4780
FU CAPES-Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior,
   Brazil
FX This work was supported by CAPES-Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior, Brazil.
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Balasubramanian S, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0090-9
   Balasubramanian S, 2012, IEEE T BIO-MED ENG, V59, P2126, DOI 10.1109/TBME.2011.2179545
   Batten HR, 2019, PROSTHET ORTHOT INT, V43, P196, DOI 10.1177/0309364618792723
   Beck Y, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0398-3
   Beckerman H, 2001, QUAL LIFE RES, V10, P571, DOI 10.1023/A:1013138911638
   Bellou V, 2016, PARKINSONISM RELAT D, V23, P1, DOI 10.1016/j.parkreldis.2015.12.008
   Birkenmeier RL, 2010, NEUROREHAB NEURAL RE, V24, P620, DOI 10.1177/1545968310361957
   Clare L., 2008, Rivermead behavioural memory test
   Dockx K, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010760.pub2
   Doniger Glen M, 2018, Alzheimers Dement (N Y), V4, P118, DOI 10.1016/j.trci.2018.02.005
   El-Gohary M, 2014, SENSORS-BASEL, V14, P356, DOI 10.3390/s140100356
   Figueiredo AI, 2020, FRONT PHYSIOL, V11, DOI 10.3389/fphys.2020.00540
   Flores A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00531
   Fox SH, 2018, MOVEMENT DISORD, V33, P1248, DOI 10.1002/mds.27372
   Fuchs Philippe., 2017, VIRTUAL REALITY HEAD
   Ghai S, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00236
   Gulde P, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00615
   Hogan N, 2009, J MOTOR BEHAV, V41, P529, DOI 10.3200/35-09-004-RC
   Imam B, 2014, REHABIL RES PRACT, V2014, DOI 10.1155/2014/594540
   Jones F, 2011, DISABIL REHABIL, V33, P797, DOI 10.3109/09638288.2010.511415
   Kassubek J, 2014, BASAL GANGLIA, V4, P15, DOI 10.1016/j.baga.2014.02.001
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Koltai D. C., 1996, ASSESSMENT, V3, P443, DOI [10.1177/107319119600300410, DOI 10.1177/107319119600300410]
   Koop MM, 2018, IBRO REP, V5, P10, DOI 10.1016/j.ibror.2018.06.002
   Lee NY, 2015, J PHYS THER SCI, V27, P145, DOI 10.1589/jpts.27.145
   Liao YY, 2015, NEUROREHAB NEURAL RE, V29, P658, DOI 10.1177/1545968314562111
   Maggio MG, 2019, J CLIN NEUROSCI, V65, P106, DOI 10.1016/j.jocn.2019.03.017
   Maggio MG, 2018, J GERIATR PSYCH NEUR, V31, P312, DOI 10.1177/0891988718807973
   Mancini M, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00018
   Mancini M, 2012, IEEE ENG MED BIO, P1198, DOI 10.1109/EMBC.2012.6346151
   Mirek E, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00102
   Fioravanti-Bastos ACM, 2011, PSICOL-REFLEX CRIT, V24, P485, DOI 10.1590/S0102-79722011000300009
   Patel M, 2020, GAIT POSTURE, V76, P110, DOI 10.1016/j.gaitpost.2019.10.039
   Peterson DS, 2016, PHYS THER, V96, P659, DOI 10.2522/ptj.20140603
   Pinto C, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0579-8
   Ravi DK, 2017, PHYSIOTHERAPY, V103, P245, DOI 10.1016/j.physio.2016.08.004
   Rizos A, 2014, PARKINSONISM RELAT D, V20, P1231, DOI 10.1016/j.parkreldis.2014.09.013
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Salarian A, 2010, IEEE T NEUR SYS REH, V18, P303, DOI 10.1109/TNSRE.2010.2047606
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Shah J, 2018, PARKINSONISM RELAT D, V53, P58, DOI 10.1016/j.parkreldis.2018.04.032
   Sofuwa O, 2005, ARCH PHYS MED REHAB, V86, P1007, DOI 10.1016/j.apmr.2004.08.012
   Souza Barbosa de L., 2011, ACTA FISI TRICA, V18, P217, DOI [10.5935/0104-7795.20110010, DOI 10.5935/0104-7795.20110010]
   Stack E, 2004, DISABIL REHABIL, V26, P478, DOI 10.1080/09638280410001663085
   van den Heuvel MRC, 2014, PARKINSONISM RELAT D, V20, P1352, DOI 10.1016/j.parkreldis.2014.09.022
   Walton CC, 2018, NPJ PARKINSONS DIS, V4, DOI 10.1038/s41531-018-0052-6
   Wang B, 2019, CLIN REHABIL, V33, P1130, DOI 10.1177/0269215519843174
   Weiss P.L., 2014, Virtual Reality for Physical and Motor Rehabilitation
   Zariffa J, 2018, J REHABIL ASSIST TER, V5, DOI 10.1177/2055668318788036
NR 50
TC 3
Z9 3
U1 8
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 26
PY 2020
VL 1
AR 7
DI 10.3389/frvir.2020.00007
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L6UC1
UT WOS:001024581800001
OA gold
DA 2024-07-18
ER

PT J
AU Leleve, A
   McDaniel, T
   Rossa, C
AF Leleve, Arnaud
   McDaniel, Troy
   Rossa, Carlos
TI Haptic Training Simulation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptics; hands-on training; simulation; tactile; kinaesthetic
ID TACTILE FEEDBACK; DESIGN; SYSTEM; INTERFACE; DEVICE; SKILL
AB Immersive virtual environments combined with kinaesthetic and/or tactile haptic feedback are becoming an essential building block of simulator training in a variety of applications. This paper aims to illustrate the interest of hands-on training simulation with haptic feedback. We review the recent application domains and we expose the progress and open challenges in the medical domain which is particularly demonstrative. The paper then addresses two aspects of haptic feedback that could help enhance modern haptic training simulators' performance, namely transparent and efficient actuation for kinaesthetic feedback and tactile feedback. This research topic, beyond technological progress, should help design kinaesthetic and tactile haptic interfaces and motivate the use of new actuation techniques for more realistic and effective feedback in simulations as soon as users are immersed in virtual environments.
C1 [Leleve, Arnaud] Univ Lyon, Univ Claude Bernard Lyon 1, INSA Lyon, CNRS,Ampere UMR 5005, Villeurbanne, France.
   [McDaniel, Troy] Arizona State Univ, Polytech Sch, Mesa, AZ USA.
   [Rossa, Carlos] Ontario Tech Univ, Fac Engn & Appl Sci, Oshawa, ON, Canada.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Claude Bernard Lyon 1; Centre National de la Recherche
   Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences
   (INSIS); Arizona State University
RP Leleve, A (corresponding author), Univ Lyon, Univ Claude Bernard Lyon 1, INSA Lyon, CNRS,Ampere UMR 5005, Villeurbanne, France.
EM arnaud.leleve@insa-lyon.fr
RI Leleve, Arnaud/I-9523-2012
OI Leleve, Arnaud/0000-0001-5550-9072; Rossa, Carlos/0000-0002-5879-1752;
   McDaniel, Troy/0000-0003-0284-8921
CR Abidi MH, 2019, INT J ADV MANUF TECH, V105, P3743, DOI 10.1007/s00170-019-03801-3
   Adams H, 2019, PROC SPIE, V10951, DOI 10.1117/12.2506178
   Arbeláez JC, 2019, INT J INTERACT DES M, V13, P673, DOI 10.1007/s12008-019-00532-3
   Bernardoni F, 2019, INT C REHAB ROBOT, P760, DOI [10.7892/boris.131921, 10.1109/ICORR.2019.8779420]
   Bholat OS, 1999, J AM COLL SURGEONS, V189, P349, DOI 10.1016/S1072-7515(99)00184-2
   Biddle E, 2019, LECT NOTES COMPUT SC, V11597, P15, DOI 10.1007/978-3-030-22341-0_2
   Chapuis D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1553, DOI 10.1109/IROS.2006.282040
   Conti F, 2009, INT J ROBOT RES, V28, P834, DOI [10.1177/027836490809795, 10.1177/0278364908097958]
   Culjat M, 2008, IND ROBOT, V35, P449, DOI 10.1108/01439910810893617
   DeBoon B, 2019, IEEE INT CONF ROBOT, P1507, DOI [10.1109/ICRA.2019.8793586, 10.1109/icra.2019.8793586]
   Du HW, 2018, J CLEAN PROD, V184, P511, DOI 10.1016/j.jclepro.2018.02.117
   Edwards D. A., 2020, COMPREHENSIVE HEALTH, P117, DOI [10.1007/978-3-030-26849-7_12, DOI 10.1007/978-3-030-26849-7_12]
   Fagard J, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00267
   Hamza-Lup FG, 2019, Arxiv, DOI [arXiv:1903.03272, 10.48550/arXiv.1903.03272]
   Garbaya S, 2019, ASSEMBLY AUTOM, V39, P931, DOI 10.1108/AA-10-2018-0147
   Gerry, 2019, 16 SOUND MUS COMP C, P241
   Gonenc B., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P451, DOI 10.1109/HAPTIC.2012.6183830
   Hooshiar A, 2020, IEEE REV BIOMED ENG, V13, P32, DOI 10.1109/RBME.2019.2907458
   James J, 2019, SOLDER SURF MT TECH, V31, P133, DOI 10.1108/SSMT-01-2018-0001
   KLATZKY RL, 1985, PERCEPT PSYCHOPHYS, V37, P299, DOI 10.3758/BF03211351
   KONTARINIS DA, 1995, PRESENCE-TELEOP VIRT, V4, P387, DOI 10.1162/pres.1995.4.4.387
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959
   Lacki M, 2020, IEEE T HAPTICS, V13, P720, DOI 10.1109/TOH.2020.2983037
   Lacki M, 2020, IEEE T HAPTICS, V13, P219, DOI 10.1109/TOH.2020.2970906
   Lacki M, 2019, IEEE INT C INT ROBOT, P7288, DOI [10.1109/IROS40897.2019.8968164, 10.1109/iros40897.2019.8968164]
   Li Z., 2019, ADV COMPUTER GRAPHIC
   Loch F, 2018, INTERACT DES ARCHIT, P46
   Ma J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132960.1132961
   Nahavandi S., 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 997), P11, DOI 10.1007/978-3-030-22871-2_2
   Neges M, 2018, PROCEDIA MANUF, V19, P171, DOI 10.1016/j.promfg.2018.01.024
   Nestel D, 2019, Healthc Simul Res, P9, DOI [10.1007/978-3-030-26837-4_2, DOI 10.1007/978-3-030-26837-4_2]
   Noda Y, 2019, SHOCK VIB, V2019, DOI 10.1155/2019/3060457
   Norkhairani AR, 2011, LECT NOTES COMPUT SC, V7066, P125, DOI 10.1007/978-3-642-25191-7_13
   Numfu M, 2019, PROC CIRP, V84, P1069, DOI 10.1016/j.procir.2019.04.268
   Okamura AM, 2009, CURR OPIN UROL, V19, P102, DOI 10.1097/MOU.0b013e32831a478c
   Overtoom EM, 2019, J SURG EDUC, V76, P242, DOI 10.1016/j.jsurg.2018.06.008
   Panait L, 2009, J SURG RES, V156, P312, DOI 10.1016/j.jss.2009.04.018
   Pinzon D, 2016, SURG INNOV, V23, P415, DOI 10.1177/1553350616628680
   Quanser Inc., 2020, GLOB STAND TRANSF EN
   Rossa C, 2014, IEEE T HAPTICS, V7, P442, DOI 10.1109/TOH.2014.2346501
   Rossa C, 2014, IEEE-ASME T MECH, V19, P1669, DOI 10.1109/TMECH.2013.2291966
   Sainsbury B, 2020, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00145
   Sénac T, 2019, CONTROL ENG PRACT, V90, P231, DOI 10.1016/j.conengprac.2019.07.005
   Shima H, 2019, PROCEDIA COMPUT SCI, V159, P2015, DOI 10.1016/j.procs.2019.09.374
   Stevens P., 2003, INT HDB EC ED, DOI [10.4337/9781845421694.00009, DOI 10.4337/9781845421694.00009]
   Sugar TG, 2007, IEEE T NEUR SYS REH, V15, P336, DOI 10.1109/TNSRE.2007.903903
   Talasaz A, 2017, IEEE T HAPTICS, V10, P276, DOI 10.1109/TOH.2016.2616874
   Umemura Atushi, 2009, 2009 IEEE International Conference on Rehabilitation Robotics: Reaching Users & the Community (ICORR), P451, DOI 10.1109/ICORR.2009.5209512
   Walker DS, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2885, DOI 10.1109/IROS.2009.5354689
   Wei L, 2019, VIRTUAL REAL-LONDON, V23, P217, DOI 10.1007/s10055-018-0349-0
   Weik D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1227, DOI [10.1109/vr.2019.8798287, 10.1109/VR.2019.8798287]
   Wolbrecht ET, 2010, INT J ROBOT RES, V29, P23, DOI 10.1177/0278364909103787
   Yang YF, 2019, NEUROCOMPUTING, V348, P74, DOI 10.1016/j.neucom.2018.05.120
NR 54
TC 17
Z9 18
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 8
PY 2020
VL 1
AR 3
DI 10.3389/frvir.2020.00003
PG 6
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RQ4
UT WOS:001023158400001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Pavanatto, L
   Davari, S
   Badea, C
   Stoakley, R
   Bowman, DA
AF Pavanatto, Leonardo
   Davari, Shakiba
   Badea, Carmen
   Stoakley, Richard
   Bowman, Doug A.
TI Virtual monitors vs. physical monitors: an empirical comparison for
   productivity work
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual monitors; virtual displays; productivity work; virtual reality;
   user studies; performance; user experience
ID INFORMATION VISUALIZATION; REALITY
AB Virtual monitors can display information through a head-worn display when a physical monitor is unavailable or provides insufficient space. Low resolution and restricted field of view are common issues of these displays. Such issues reduce readability and peripheral vision, leading to increased head movement when we increase the display size. This work evaluates the performance and user experience of a virtual monitor setup that combines software designed to minimize graphical transformations and a high-resolution virtual reality head-worn display. Participants performed productivity work across three approaches: Workstation, which is often used at office locations and consists of three side-by-side physical monitors; Laptop, which is often used in mobile locations and consists of a single physical monitor expanded with multiple desktops; and Virtual, our prototype with three side-by-side virtual monitors. Results show that participants deemed Virtual faster, easier to use, and more intuitive than Laptop, evidencing the advantages of head and eye glances over full content switches. They also confirm the existence of a gap between Workstation and Virtual, as Workstation achieved the highest user experience. We conclude with design guidelines obtained from the lessons learned in this study.
C1 [Pavanatto, Leonardo; Davari, Shakiba; Bowman, Doug A.] Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.
   [Pavanatto, Leonardo; Davari, Shakiba; Badea, Carmen; Stoakley, Richard] Microsoft Corp, Microsoft Res, Redmond, WA 98052 USA.
C3 Virginia Polytechnic Institute & State University; Microsoft
RP Pavanatto, L (corresponding author), Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.; Pavanatto, L (corresponding author), Microsoft Corp, Microsoft Res, Redmond, WA 98052 USA.
EM lpavanat@vt.edu
OI Pavanatto Soares, Leonardo/0000-0003-1028-8549
FU Microsoft Corporation
FX This study was funded by Microsoft Corporation.
CR Andrews C, 2011, INFORM VISUAL, V10, P341, DOI 10.1177/1473871611415997
   Bellec Matthieu, 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8087804
   Biener V, 2022, IEEE T VIS COMPUT GR, V28, P3810, DOI 10.1109/TVCG.2022.3203103
   Biener V, 2020, IEEE T VIS COMPUT GR, V26, P3490, DOI 10.1109/TVCG.2020.3023567
   Büttner A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P663, DOI [10.1109/VRW50115.2020.00-93, 10.1109/VRW50115.2020.00182]
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Cockburn A., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P434, DOI 10.1145/365024.365309
   Czerwinski M., 2003, P INT, V3, P9
   Davari S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P324, DOI [10.1109/VRW50115.2020.00072, 10.1109/VRW50115.2020.0-204]
   Dingler T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188695
   Dittrich Elisabeth, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P149, DOI 10.1007/978-3-642-39405-8_18
   Eiberger A, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357588
   Ens B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3171
   Erickson A, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3456874
   Falk J, 2021, INT WORK QUAL MULTIM, P231, DOI 10.1109/QoMEX51781.2021.9465455
   Feiner S., 1993, Sixth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P145, DOI 10.1145/168642.168657
   Fereydooni N., 2020, MICROSOFT NEW FUTURE, P1
   Gabbard JL, 2006, PRESENCE-TELEOP VIRT, V15, P16, DOI 10.1162/pres.2006.15.1.16
   Gabbard JL, 2019, IEEE T VIS COMPUT GR, V25, P2228, DOI 10.1109/TVCG.2018.2832633
   Gattullo M, 2015, IEEE T VIS COMPUT GR, V21, P638, DOI 10.1109/TVCG.2014.2385056
   Grout Cameron., 2015, P 15 NZ C HUMAN COMP, P9, DOI DOI 10.1145/2808047.2808055
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Hoppe AH, 2018, COMM COM INF SC, V851, P266, DOI 10.1007/978-3-319-92279-9_36
   Jankowski J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1321
   Le KD, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P283, DOI 10.1145/3461778.3462076
   Kim K, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357584
   Knierim P, 2021, IEEE PERVAS COMPUT, V20, P71, DOI 10.1109/MPRV.2021.3119378
   Kobayashi D., 2021, S SPATIAL USER INTER, P1
   Kojic T., 2020, 2020 12 INT C QUALIT, P1
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee J. H., 2018, P 2018 CHI C HUMAN F, P1
   Li Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300917
   Lu FY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P930, DOI [10.1109/VR46266.2020.00118, 10.1109/VR46266.2020.1581100361198]
   Lu Feiyu, 2021, S SPAT US INT VIRT E, DOI DOI 10.1145/3485279.3485286
   Mahmud T., 2018, 2018 INT S BIG DAT V, P1, DOI DOI 10.1109/BDVA.2018.8533893
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   Medeiros D, 2022, IEEE T VIS COMPUT GR, V28, P3640, DOI 10.1109/TVCG.2022.3203002
   Ng A, 2021, INT SYM MIX AUGMENT, P265, DOI 10.1109/ISMAR52148.2021.00042
   Ofek Eyal, 2020, arXiv
   Orlosky Jason, 2013, P 2013 INT C INT US, P363, DOI [DOI 10.1145/2449396.2449443, 10.1145/2449396, DOI 10.1145/2449396]
   Pavanatto L, 2021, INT SYM MIX AUGMENT, P459, DOI 10.1109/ISMAR-Adjunct54149.2021.00107
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Raskar Ramesh., 1998, Proceedings of the 25th annual conference on Computer graphics and interactive techniques, P179, DOI [10.1145/280814.280861, DOI 10.1145/280814.280861]
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Ruvimova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376724
   Rzayev R., 2021, P 2021 CHI C HUM FAC, P1
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Waldner M., 2011, P ACM INT C INT TABL, P222, DOI [10.1145/2076354.2076394, DOI 10.1145/2076354.2076394]
   Wei CX, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P721, DOI [10.1109/VR46266.2020.000-9, 10.1109/VR46266.2020.1581590322523]
NR 51
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 5
PY 2023
VL 4
AR 1215820
DI 10.3389/frvir.2023.1215820
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DA6D2
UT WOS:001129342500001
OA gold
DA 2024-07-18
ER

PT J
AU Franklin, DM
   Silvestro, C
   Carrillo, RA
   Yang, YW
   Annadurai, D
   Ganesan, S
   Vasantham, DSJ
   Mettu, S
   Patel, M
   Patil, MS
   Akurathi, ND
AF Franklin, D. Michael
   Silvestro, Charles
   Carrillo, Robert A.
   Yang, Yewon
   Annadurai, Dharani
   Ganesan, Sangavai
   Vasantham, Divya Sai Jyothi
   Mettu, Soujanya
   Patel, Mehal
   Patil, Manasi S.
   Akurathi, Nandini Devi
TI The impact of meditation aided by VR technology as an emerging
   therapeutic to ease cancer related anxiety, stress, and fatigue
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; guided meditation; therapeutic; anxiety; stress;
   fatigue; guided therapy
ID HEALTH; SYSTEM
AB Patients diagnosed with cancer experience a high degree of stress as well as side effects from treatments that can greatly impact their quality of life. Many patients experience long-term side effects such as pain, fatigue, anxiety, depression, and cognitive dysfunction. Several studies have reported that the use of virtual reality (VR) interventions show substantial benefits in reducing symptoms of anxiety, depression, pain, and cognitive functions in cancer patients undergoing therapy. In this study we analyzed the acceptability, feasibility, and tolerance of PNI Thrive, a 10-min VR guided meditation application, as an adjuvant digital therapeutic aid for cancer patients in a clinical setting. Patients diagnosed with various cancers, and at different stages of therapy, participated in this study. Our data suggests that the adjuvant VR treatment was successful in making patients feel calmer, more relaxed, refreshed, and more empowered. We propose that routine exposure of patients to VR interventions will help improve their response to anti-cancer therapies and quality of life.
C1 [Franklin, D. Michael] Kennesaw State Univ, Coll Comp & Software Engn, Kennesaw, GA 30144 USA.
   [Silvestro, Charles] PNI Therapeut, New York, NY USA.
   [Carrillo, Robert A.] Canc Doctor LLC, Kennesaw, GA USA.
   [Yang, Yewon; Annadurai, Dharani; Ganesan, Sangavai; Vasantham, Divya Sai Jyothi; Mettu, Soujanya; Patel, Mehal; Patil, Manasi S.; Akurathi, Nandini Devi] Northeastern Univ, Boston, MA USA.
C3 University System of Georgia; Kennesaw State University; Northeastern
   University
RP Franklin, DM (corresponding author), Kennesaw State Univ, Coll Comp & Software Engn, Kennesaw, GA 30144 USA.
EM mfranklin@trulyintegrated.com
CR Ahmad S., 2022, FRONT PSYCHOL, V13, P107
   Brownstein DJ, 2018, AUST NZ J PSYCHIAT, V52, P24, DOI 10.1177/0004867417721654
   Chirico A, 2020, J CELL PHYSIOL, V235, P5353, DOI 10.1002/jcp.29422
   Chirico A, 2016, J CELL PHYSIOL, V231, P275, DOI 10.1002/jcp.25117
   Conley CC, 2016, HEALTHCARE-BASEL, V4, DOI 10.3390/healthcare4030056
   Drugs, 2021, LEV SID EFF COMM SEV
   Drugs, 2021, LIS US DOS SID EFF W
   Drugs, 2021, DRUGS AML DRUG US SI
   Drugs, 2021, DRUGS AZ MED SID EFF
   Glaser R., 2000, PSYCHOL BULL, V126, P363, DOI [10.1146/annurev.psych.53.100901.1352, DOI 10.1146/ANNUREV.PSYCH.53.100901.1352]
   Kemp A. S., 2019, J AFFECT DISORDERS, V249, P107
   Kiecolt-Glaser JK, 2002, ANNU REV PSYCHOL, V53, P83, DOI 10.1146/annurev.psych.53.100901.135217
   Maindet C, 2019, SUPPORT CARE CANCER, V27, P3119, DOI 10.1007/s00520-019-04829-7
   Mcleod S., 2021, VALUE STAT SIGNIFICA
   Serra D, 2012, CLIN J ONCOL NURS, V16, P617, DOI 10.1188/12.CJON.617-623
   Smyth JM, 2009, CURR OPIN PSYCHIATR, V22, P205, DOI 10.1097/YCO.0b013e3283252d6d
   Statistics Solutions, 2021, PAIR SAMPL T TEST
   US Department of Health and Human Services, 2021, HIGH BLOOD PRESS OLD
   Walsh NA, 2022, J SLEEP RES, V31, DOI 10.1111/jsr.13442
   Zion SR, 2018, INT REV NEUROBIOL, V138, P137, DOI 10.1016/bs.irn.2018.02.002
NR 20
TC 0
Z9 0
U1 5
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 25
PY 2023
VL 4
AR 1195196
DI 10.3389/frvir.2023.1195196
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA O5QA1
UT WOS:001044341600001
OA gold
DA 2024-07-18
ER

PT J
AU Kildahl-Andersen, A
   Hofstad, EF
   Sorger, H
   Amundsen, T
   Lango, T
   Leira, HO
   Kiss, G
AF Kildahl-Andersen, Arne
   Hofstad, Erlend Fagertun
   Sorger, Hanne
   Amundsen, Tore
   Lango, Thomas
   Leira, Hakon Olav
   Kiss, Gabriel
TI Bronchoscopy using a head-mounted mixed reality device-a phantom study
   and a first in-patient user experience
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE bronchoscopy; head-mounted display; HoloLens; mixed reality; augmented
   reality; electromagnetic navigation bronchoscopy; mixed reality
   bronchoscopy
ID NAVIGATION DIAGNOSTIC BRONCHOSCOPY; AUGMENTED REALITY; PLATFORM
AB Background: Bronchoscopy for peripheral lung lesions may involve image sources such as computed tomography (CT), fluoroscopy, radial endobronchial ultrasound (R-EBUS), and virtual/electromagnetic navigation bronchoscopy. Our objective was to evaluate the feasibility of replacing these multiple monitors with a head-mounted display (HMD), always providing relevant image data in the line of sight of the bronchoscopist.Methods: A total of 17 pulmonologists wearing a HMD (Microsoft((R)) HoloLens 2) performed bronchoscopy with electromagnetic navigation in a lung phantom. The bronchoscopists first conducted an endobronchial inspection and navigation to the target, followed by an endobronchial ultrasound bronchoscopy. The HMD experience was evaluated using a questionnaire. Finally, the HMD was used in bronchoscopy inspection and electromagnetic navigation of two patients presenting with hemoptysis.Results: In the phantom study, the perceived quality of video and ultrasound images was assessed using a visual analog scale, with 100% representing optimal image quality. The score for video quality was 58% (95% confidence interval [CI] 48%-68%) and for ultrasound image quality, the score was 43% (95% CI 30%-56%). Contrast, color rendering, and resolution were all considered suboptimal. Despite adjusting the brightness settings, video image rendering was considered too dark. Navigation to the target for biopsy sampling was accomplished by all participants, with no significant difference in procedure time between experienced and less experienced bronchoscopists. The overall system latency for the image stream was 0.33-0.35 s. Fifteen of the pulmonologists would consider using HoloLens for navigation in the periphery, and two would not consider using HoloLens in bronchoscopy at all. In the human study, bronchoscopy inspection was feasible for both patients.Conclusion: Bronchoscopy using an HMD was feasible in a lung phantom and in two patients. Video and ultrasound image quality was considered inferior to that of video monitors. HoloLens 2 was suboptimal for airway and mucosa inspection but may be adequate for virtual bronchoscopy navigation.
C1 [Kildahl-Andersen, Arne; Amundsen, Tore; Leira, Hakon Olav] Trondheim Reg & Univ Hosp, St Olavs Hosp, Dept Thorac Med, Trondheim, Norway.
   [Kildahl-Andersen, Arne; Sorger, Hanne; Amundsen, Tore; Leira, Hakon Olav] Norwegian Univ Sci & Technol NTNU, Fac Med, Dept Circulat & Med Imaging, Trondheim, Norway.
   [Hofstad, Erlend Fagertun; Lango, Thomas] SINTEF Digital, Dept Hlth Res, Trondheim, Norway.
   [Sorger, Hanne] Levanger Hosp, Nord Trondelag Hlth Trust, Dept Med, Levanger, Norway.
   [Lango, Thomas; Kiss, Gabriel] Trondheim Reg & Univ Hosp, St Olavs Hosp, Dept Res, Trondheim, Norway.
   [Kiss, Gabriel] Norwegian Univ Sci & Technol NTNU, Fac Informat Technol & Elect Engn IE, Dept Comp Sci IDI, Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU); Norwegian
   University of Science & Technology (NTNU); SINTEF; Norwegian University
   of Science & Technology (NTNU); Norwegian University of Science &
   Technology (NTNU)
RP Leira, HO (corresponding author), Trondheim Reg & Univ Hosp, St Olavs Hosp, Dept Thorac Med, Trondheim, Norway.; Leira, HO (corresponding author), Norwegian Univ Sci & Technol NTNU, Fac Med, Dept Circulat & Med Imaging, Trondheim, Norway.
EM hakon.o.leira@ntnu.no
FU joint research committee, St. Olavs hospital and Faculty of Medicine,
   Norwegian University of Science and Technology (NTNU); SINTEF;
   Department of Research, St. Olavs hospital
FX The study was funded by the joint research committee, St. Olavs hospital
   and Faculty of Medicine, Norwegian University of Science and Technology
   (NTNU), SINTEF and Department of Research, St. Olavs hospital.
CR Al Janabi HF, 2020, SURG ENDOSC, V34, P1143, DOI 10.1007/s00464-019-06862-3
   Askeland C, 2016, INT J COMPUT ASS RAD, V11, P505, DOI 10.1007/s11548-015-1292-0
   Bakeng JBL, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211772
   Brun H, 2019, EUR HEART J-CARD IMG, V20, P883, DOI 10.1093/ehjci/jey184
   Burks AC, 2020, CLIN CHEST MED, V41, P129, DOI 10.1016/j.ccm.2019.11.002
   Chen CP, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8120557
   Condino S, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/5435097
   Costa N, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23041838
   Doughty M, 2022, J IMAGING, V8, DOI 10.3390/jimaging8070203
   Eberhardt R, 2007, CHEST, V131, P1800, DOI 10.1378/chest.06-3016
   Flandes J, 2020, RESP RES, V21, DOI 10.1186/s12931-020-01576-w
   Gan A, 2019, J INTENSIVE CARE MED, V34, P153, DOI 10.1177/0885066618791952
   García-Vázquez V, 2018, INNOV SURG SCI, V3, P167, DOI 10.1515/iss-2018-2001
   Gildea TR, 2006, AM J RESP CRIT CARE, V174, P982, DOI 10.1164/rccm.200603-344OC
   Hofstad EF, 2014, MED PHYS, V41, DOI 10.1118/1.4866884
   Iqbal H, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103841
   Johnson AA, 2022, SURG INNOV, V29, P353, DOI 10.1177/1553350620987978
   Johnson M, 2022, IEEE INT SYMP M AU R, P477, DOI 10.1109/ISMAR-Adjunct57072.2022.00100
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   Li CR, 2021, ANN THORAC SURG, V112, P1624, DOI 10.1016/j.athoracsur.2020.10.037
   Li Y, 2019, J NEUROSURG, V131, P1599, DOI 10.3171/2018.4.JNS18124
   Microsoft, 2022, HOLOLENS 2 TECHN SPE
   Okachi S, 2022, SURG INNOV, V29, P811, DOI 10.1177/15533506211068928
   Qian L, 2017, INT J COMPUT ASS RAD, V12, P901, DOI 10.1007/s11548-017-1564-y
   Sorger H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171841
   Sorger H, 2016, INT J COMPUT ASS RAD, V11, P1431, DOI 10.1007/s11548-015-1326-7
   Stewart CL, 2022, J ROBOT SURG, V16, P1019, DOI 10.1007/s11701-021-01335-z
   Nguyen T, 2022, INT J COMPUT ASS RAD, V17, P385, DOI 10.1007/s11548-021-02526-7
   Wellens LM, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.2633
NR 29
TC 1
Z9 1
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 27
PY 2023
VL 4
AR 940536
DI 10.3389/frvir.2023.940536
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YI5
UT WOS:001023333300001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Sanford, S
   Collins, B
   Liu, MX
   Dewil, S
   Nataraj, R
AF Sanford, Sean
   Collins, Brian
   Liu, Mingxiao
   Dewil, Sophie
   Nataraj, Raviraj
TI Investigating features in augmented visual feedback for virtual reality
   rehabilitation of upper-extremity function through isometric muscle
   control
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality (VR); visual feedback; electromyography (EMG);
   rehabilitation; motor performance
ID UPPER-LIMB REHABILITATION; SPINAL-CORD-INJURY; EMG PATTERN-RECOGNITION;
   COGNITIVE LOAD; MYOELECTRIC CONTROL; TERMINAL FEEDBACK; SENSORY
   FEEDBACK; JOINT ANGLES; MOTOR; POINT
AB Previous studies have demonstrated how augmented feedback can accelerate motor learning. Still, how specific feedback features of complexity and intermittency can influence learning a challenging, force-driven motor task remains largely unknown. This study is an initial investigation of how variations in the complexity and intermittency of augmented visual guidance affect the performance of an isometric muscle control task with a computerized platform. This novel platform has been developed to rehabilitate upper-extremity function after neuromuscular dysfunction (e.g., spinal cord injury, stroke) while utilizing: 1) a position-adjustable arm brace for gravity support; 2) a myoelectric command interface; 3) virtual reality (VR) for motor training. Results from this study elucidate new motor control principles and suggest how augmented guidance may be leveraged in designing VR motor rehabilitation programs, which are highly flexible and customizable to individual users. This study demonstrated that simpler and more intermittent feedback typically resulted in better performance (i.e., shorter computerized motion pathlengths). Supplementary results suggested these feedback modes also reduced cognitive loading (i.e., alpha/beta band magnitudes in electroencephalography) but increased physical arousal (i.e., higher skin conductance). In sum, this study indicates that for complex, force-driven tasks, augmented guidance must be presented selectively to accelerate gains in motor performance. This study suggests that simple and intermittent feedback avoids cognitively overwhelming the user while encouraging physical engagement that supports better performance.
C1 [Sanford, Sean; Collins, Brian; Liu, Mingxiao; Dewil, Sophie; Nataraj, Raviraj] Altorfer Complex Stevens Inst Technol, Movement Control Rehabil MOCORE Lab, Hoboken, NJ 07030 USA.
   [Sanford, Sean; Liu, Mingxiao; Dewil, Sophie; Nataraj, Raviraj] Stevens Inst Technol, Dept Biomed Engn, Hoboken, NJ 07030 USA.
   [Collins, Brian] Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ USA.
C3 Stevens Institute of Technology; Stevens Institute of Technology
RP Nataraj, R (corresponding author), Altorfer Complex Stevens Inst Technol, Movement Control Rehabil MOCORE Lab, Hoboken, NJ 07030 USA.; Nataraj, R (corresponding author), Stevens Inst Technol, Dept Biomed Engn, Hoboken, NJ 07030 USA.
EM rnataraj@stevens.edu
RI Nataraj, Raviraj/HNI-4887-2023
OI Nataraj, Raviraj/0000-0002-5261-3031; Liu, Mingxiao/0009-0008-0473-9386
FU Charles V. Schaefer, Jr. School of Engineering and Science, Stevens
   Institute of Technology; VA SPiRE [RX003582]; Stevens Institute of
   Technology Provost Office
FX Charles V. Schaefer, Jr. School of Engineering and Science, Stevens
   Institute of Technology provided funds to support the fundamental
   development of this research. VA SPiRE Grant RX003582 supported the
   translation of the described platform for use with persons having spinal
   cord injury. Stevens Institute of Technology Provost Office provided the
   Excellence Doctoral Fellowship support for SS's final year of
   dissertation study culminating in the work presented in this study.
CR Ajiboye AB, 2005, IEEE T NEUR SYS REH, V13, P280, DOI 10.1109/TNSRE.2005.847357
   Akima H, 1999, MED SCI SPORT EXER, V31, P588, DOI 10.1097/00005768-199904000-00016
   Alavi N, 2015, IEEE ENG MED BIO, P4643, DOI 10.1109/EMBC.2015.7319429
   Antfolk C, 2010, J MED BIOL ENG, V30, P399, DOI 10.5405/jmbe.767
   Aoyagi K, 2019, IEEE ENG MED BIO, P118, DOI [10.1109/EMBC.2019.8856796, 10.1109/embc.2019.8856796]
   Bank PJM, 2017, BEHAV BRAIN RES, V329, P205, DOI 10.1016/j.bbr.2017.04.056
   Bannert M, 2002, LEARN INSTR, V12, P139, DOI 10.1016/S0959-4752(01)00021-4
   Berger DJ, 2017, BIOSYST BIOROBOT, V15, P965, DOI 10.1007/978-3-319-46669-9_156
   Berger DJ, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00046
   Blana D, 2016, J ELECTROMYOGR KINES, V29, P21, DOI 10.1016/j.jelekin.2015.06.010
   Carmeli E, 2009, 2009 VIRTUAL REHABILITATION INTERNATIONAL CONFERENCE, P220, DOI 10.1109/ICVR.2009.5174258
   Celik O, 2010, IEEE T NEUR SYS REH, V18, P433, DOI 10.1109/TNSRE.2010.2047600
   Cho KH, 2015, TOHOKU J EXP MED, V236, P273, DOI 10.1620/tjem.236.273
   Cirstea AC, 2007, NEUROREHAB NEURAL RE, V21, P398, DOI 10.1177/1545968306298414
   Critchley HD, 2002, NEUROSCIENTIST, V8, P132, DOI 10.1177/107385840200800209
   Dipietro L, 2009, CORTEX, V45, P318, DOI 10.1016/j.cortex.2008.02.008
   Ferris D.P., 2017, Kinesiology Review, V6, P70, DOI [10.1123/kr.2016-0040, DOI 10.1123/KR.2016-0040]
   Fitts P. M., 1967, Human performance
   Folland JP, 2005, J SPORT SCI, V23, P817, DOI 10.1080/02640410400021783
   Fox IK, 2015, PLAST RECONSTR SURG, V136, P780, DOI 10.1097/PRS.0000000000001641
   Garcia-Hernandez N, 2019, INT J HUM-COMPUT ST, V124, P44, DOI 10.1016/j.ijhcs.2018.11.010
   Ghafouri M, 2001, EXP BRAIN RES, V137, P411
   Gordon K, 2004, EXP BRAIN RES, V159, P478, DOI 10.1007/s00221-004-1970-6
   Gu YK, 2018, EXPERT SYST APPL, V96, P208, DOI 10.1016/j.eswa.2017.11.049
   Guadagnoli MA, 2004, J MOTOR BEHAV, V36, P212, DOI 10.3200/JMBR.36.2.212-224
   Hakim RM, 2017, DISABIL REHABIL-ASSI, V12, P765, DOI 10.1080/17483107.2016.1269211
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Huang S, 2016, IEEE T NEUR SYS REH, V24, P573, DOI 10.1109/TNSRE.2015.2441061
   Johnson WD, 2017, LANCET NEUROL, V16, P949, DOI 10.1016/S1474-4422(17)30362-9
   Kearney E, 2019, DISABIL REHABIL, V41, P995, DOI 10.1080/09638288.2017.1419292
   KEENAN MAE, 1988, CLIN ORTHOP RELAT R, P116
   Kern F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P500, DOI [10.1109/VR.2019.8797828, 10.1109/vr.2019.8797828]
   Kiefer AW., 2014, J Nov Physiother, V4, DOI DOI 10.4172/2165-7025.1000198
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kucuk Serdar, 2006, Robot Kinematics: Forward and Inverse Kinematics, Industrial Robotics: Theory, Modelling and Control
   Kumar N, 2016, PROCEDIA COMPUT SCI, V84, P70, DOI 10.1016/j.procs.2016.04.068
   Lee S, 2016, OCCUP THER INT, V23, P357, DOI 10.1002/oti.1437
   Levin MF, 2015, PHYS THER, V95, P415, DOI 10.2522/ptj.20130579
   Liarokapis MV, 2013, IEEE J BIOMED HEALTH, V17, P915, DOI 10.1109/JBHI.2013.2259594
   Lim DY, 2020, ANN REHABIL MED-ARM, V44, P311, DOI 10.5535/arm.19181
   Liu MX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041173
   Magosso E, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7051079
   McIntyre J, 1996, EXP BRAIN RES, V110, P248
   Minkel JL, 2000, PHYS THER, V80, P701, DOI 10.1093/ptj/80.7.701
   Molier BI, 2010, DISABIL REHABIL, V32, P1799, DOI 10.3109/09638281003734359
   Moore JW, 2012, CONSCIOUS COGN, V21, P546, DOI 10.1016/j.concog.2011.12.002
   Morone G, 2021, EXPERT REV MED DEVIC, V18, P513, DOI 10.1080/17434440.2021.1927704
   Nataraj R, 2022, ACTA PSYCHOL, V223, DOI 10.1016/j.actpsy.2022.103494
   Nataraj R, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233175
   Nataraj R, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00126
   Nesbitt K., 2003, Designing multi-sensory displays for abstract data
   Nieuwboer A, 2009, PARKINSONISM RELAT D, V15, pS53, DOI 10.1016/S1353-8020(09)70781-3
   Noorkoiv M, 2015, J SPORT SCI, V33, P1952, DOI 10.1080/02640414.2015.1020843
   Oranchuk DJ, 2019, SCAND J MED SCI SPOR, V29, P484, DOI 10.1111/sms.13375
   Parajuli N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204596
   Park JH, 2000, J MOTOR BEHAV, V32, P287, DOI 10.1080/00222890009601379
   Perry BN, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00785
   Prasad S, 2018, ASIAN SPINE J, V12, P927, DOI 10.31616/asj.2018.12.5.927
   Proteau L., 1992, ADV PSYCHOL, V85, P67, DOI [10.1016/S0166-4115(08)62011-7, DOI 10.1016/S0166-4115(08)62011-7]
   Rabin N, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113281
   Reinold MM, 2007, J ATHL TRAINING, V42, P464
   Ronsse R, 2011, CEREB CORTEX, V21, P1283, DOI 10.1093/cercor/bhq209
   Sadowski J, 2013, J HUM KINET, V37, P183, DOI 10.2478/hukin-2013-0039
   Saeed RM, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00004
   SALMONI AW, 1984, PSYCHOL BULL, V95, P355, DOI 10.1037/0033-2909.95.3.355
   Sanford S, 2021, J SPORT REHABIL, V30, P794, DOI 10.1123/jsr.2020-0234
   Sanford S, 2021, J MOTOR BEHAV, V53, P243, DOI 10.1080/00222895.2020.1770670
   Schiffman JM, 2006, CLIN BIOMECH, V21, P1042, DOI 10.1016/j.clinbiomech.2006.05.009
   SCHMIDT RA, 1989, J EXP PSYCHOL LEARN, V15, P352, DOI 10.1037/0278-7393.15.2.352
   Selkowitz DM, 2007, J ORTHOP SPORT PHYS, V37, P694, DOI 10.2519/jospt.2007.2467
   SEWALL LP, 1988, PERCEPT MOTOR SKILL, V67, P715, DOI 10.2466/pms.1988.67.3.715
   Shender Avila Sansores., 2013, Converging Clinical and Engineering Research on Neurorehabilitation, Biosystems Biorobotics, P879, DOI DOI 10.1007/978-3-642-34546-3_143
   Sigrist R, 2013, J MOTOR BEHAV, V45, P455, DOI 10.1080/00222895.2013.826169
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   Smith SA, 2019, PSYCHON B REV, V26, P1213, DOI 10.3758/s13423-019-01605-w
   Soderstrom NC, 2015, PERSPECT PSYCHOL SCI, V10, P176, DOI 10.1177/1745691615569000
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Tiboni M, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814018754590
   Toledo-Pérez DC, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204402
   Utley A., 2018, Motor Control, Learning and Development: Instant Notes, V2nd
   van Dijk H, 2005, J REHABIL MED, V37, P202, DOI 10.1080/16501970510030165
   Walsh KA, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102487
   WANNSTEDT GT, 1978, PHYS THER, V58, P553, DOI 10.1093/ptj/58.5.553
   Weaver J, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002313
   WON J, 1995, EXP BRAIN RES, V107, P125
   Wulf G, 2002, PSYCHON B REV, V9, P185, DOI 10.3758/BF03196276
   Wulf G, 2013, INT REV SPORT EXER P, V6, P77, DOI 10.1080/1750984X.2012.723728
   Wyndaele M, 2006, SPINAL CORD, V44, P523, DOI 10.1038/sj.sc.3101893
   YOUNG DE, 1992, J MOTOR BEHAV, V24, P261, DOI 10.1080/00222895.1992.9941621
   Yue SG, 2002, ROBOTICA, V20, P269, DOI 10.1017/S0263574701003861
   Zhou SH, 2013, P AMER CONTR CONF, P5923
   Zimmerli L, 2013, ARCH PHYS MED REHAB, V94, P1737, DOI 10.1016/j.apmr.2013.01.029
NR 92
TC 1
Z9 1
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 3
PY 2022
VL 3
AR 943693
DI 10.3389/frvir.2022.943693
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XP1
UT WOS:001023313700001
OA gold
DA 2024-07-18
ER

PT J
AU Ashida, H
   Fujimoto, K
AF Ashida, Hiroshi
   Fujimoto, Kanon
TI Comparing measurements of head motion and centre of pressure for body
   sway induced by optic flow on a head-mounted display
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE optic flow; postural control; head motion; centre of pressure; HMD;
   (Min.5-max. 8) 7
AB We compared two measures of visually induced body sway-head motion and centre of pressure (CoP)-that were simultaneously measured while observing optic flow on a head-mounted display (HMD). Head motion can be conveniently tracked with HMDs, but may have some features different from those of conventional CoP measurements, because of the complex joint structures of the human body. In this analysis, the responses were very similar (except for response gain), and we did not find any significant differences in time or frequency domains. Our results support the use of head motion as a potential predictor of variability in body sway, at least in studies of visually guided postural control.
C1 [Ashida, Hiroshi; Fujimoto, Kanon] Kyoto Univ, Grad Sch Letters, Kyoto, Japan.
C3 Kyoto University
RP Ashida, H (corresponding author), Kyoto Univ, Grad Sch Letters, Kyoto, Japan.
EM ashida@psy.bun.kyoto-u.ac.jp
FU JSPS grant-in-aid for scientific research [19K03367]
FX Supported by JSPS grant-in-aid for scientific research (19K03367 for
   HA).
CR Audiffren J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081208
   Bertenthal BI, 1997, J EXP PSYCHOL HUMAN, V23, P1631, DOI 10.1037/0096-1523.23.6.1631
   Chowdhury NS, 2021, APPL ERGON, V92, DOI 10.1016/j.apergo.2021.103355
   Clark RA, 2011, GAIT POSTURE, V34, P288, DOI 10.1016/j.gaitpost.2011.04.010
   Dichgans J., 1978, HDB SENSORY PHYSL, VVIII., P755
   Duarte M, 2001, PHYS LETT A, V283, P124, DOI 10.1016/S0375-9601(01)00188-8
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fujimoto K, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.577305
   Fujimoto K, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519886903
   Horiuchi K, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0257212
   Imaizumi LFI, 2020, NEUROSCI LETT, V737, DOI 10.1016/j.neulet.2020.135333
   JASP Team, 2022, JASP VERS 0 16 3
   Kim J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00248
   Kobayashi K, 2005, ACTA OTO-LARYNGOL, V125, P858, DOI 10.1080/00016480510031498
   Lafond D, 2004, J BIOMECH, V37, P1421, DOI 10.1016/S0021-9290(03)00251-3
   Lubetzky AV, 2022, J MOTOR BEHAV, V54, P466, DOI 10.1080/00222895.2021.2013768
   MURRAY MP, 1967, J APPL PHYSIOL, V23, P831, DOI 10.1152/jappl.1967.23.6.831
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2014, EXP BRAIN RES, V232, P1185, DOI 10.1007/s00221-014-3835-y
   PENG CK, 1995, CHAOS, V5, P82, DOI 10.1063/1.166141
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   RStudio Team, 2022, RSTUDIO INT DEV ENV
   Saldana SJ, 2017, CLIN INTERV AGING, V12, DOI 10.2147/CIA.S141251
   Sugiura A., 2015, FORMA, V30, P43, DOI [10.5047/forma.2015.006, DOI 10.5047/FORMA.2015.006]
   VANASTEN WNJC, 1988, EXP BRAIN RES, V73, P371, DOI 10.1007/BF00248230
   Wenye G., 2020, DETRENDED FLUCTUATIO
NR 27
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 14
PY 2022
VL 3
AR 1026718
DI 10.3389/frvir.2022.1026718
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RO9
UT WOS:001023156900001
OA gold
DA 2024-07-18
ER

PT J
AU Hadadi, A
   Guillet, C
   Chardonnet, JR
   Langovoy, M
   Wang, YY
   Ovtcharova, J
AF Hadadi, Azadeh
   Guillet, Christophe
   Chardonnet, Jean-Remy
   Langovoy, Mikhail
   Wang, Yuyang
   Ovtcharova, Jivka
TI Prediction of cybersickness in virtual environments using topological
   data analysis and machine learning
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; cybersickness; navigation; TDA; persistent homology;
   machine learing
ID MOTION SICKNESS; TIME-SERIES; EEG
AB Recent significant progress in Virtual Reality (VR) applications and environments raised several challenges. They proved to have side effects on specific users, thus reducing the usability of the VR technology in some critical domains, such as flight and car simulators. One of the common side effects is cybersickness. Some significant commonly reported symptoms are nausea, oculomotor discomfort, and disorientation. To mitigate these symptoms and consequently improve the usability of VR systems, it is necessary to predict the incidence of cybersickness. This paper proposes a machine learning approach to VR's cybersickness prediction based on physiological and subjective data. We investigated combinations of topological data analysis with a range of classifier algorithms and assessed classification performance. The highest performance of Topological Data Analysis (TDA) based methods was achieved in combination with SVMs with Gaussian RBF kernel, indicating that Gaussian RBF kernels provide embeddings of physiological time series data into spaces that are rich enough to capture the essential geometric features of this type of data. Comparing several combinations with feature descriptors for physiological time series, the performance of the TDA + SVM combination is in the top group, statistically being on par or outperforming more complex and less interpretable methods. Our results show that heart rate does not seem to correlate with cybersickness.
C1 [Hadadi, Azadeh; Chardonnet, Jean-Remy] HESAM Univ, Arts & Metiers Inst Technol, LISPEN, UBFC, Chalon Sur Saone, France.
   [Hadadi, Azadeh; Langovoy, Mikhail; Ovtcharova, Jivka] Karlsruhe Inst Technol, Inst Informat Management Engn, Karlsruhe, Germany.
   [Guillet, Christophe] Univ Bourgogne, LISPEN, UBFC, Chalon Sur Saone, France.
   [Wang, Yuyang] Hong Kong Univ Sci & Technol, Computat Media & Arts Thrust, Hong Kong, Peoples R China.
C3 Universite de Bourgogne; heSam Universite; Helmholtz Association;
   Karlsruhe Institute of Technology; Universite de Bourgogne; Hong Kong
   University of Science & Technology
RP Hadadi, A (corresponding author), HESAM Univ, Arts & Metiers Inst Technol, LISPEN, UBFC, Chalon Sur Saone, France.; Hadadi, A (corresponding author), Karlsruhe Inst Technol, Inst Informat Management Engn, Karlsruhe, Germany.
EM azadeh.hadadi@ensam.eu
RI Chardonnet, Jean-Rémy/W-4502-2019
OI Chardonnet, Jean-Rémy/0000-0002-8926-1359
FU French-German University (UFA-DFH) [CDFA 0319]
FX This work was supported in part by a grant from the French-German
   University (UFA-DFH) No. CDFA 03-19.
CR Adams H, 2017, J MACH LEARN RES, V18
   [Anonymous], 1981, DYNAMICAL SYSTEMS TU, DOI DOI 10.1007/BFB0091924
   Berrar D, 2019, Cross-validation
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Bouchard S, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.739742
   Bubenik P, 2015, J MACH LEARN RES, V16, P77
   Carlsson G, 2009, B AM MATH SOC, V46, P255, DOI 10.1090/S0273-0979-09-01249-X
   Chardonnet JR, 2021, VIRTUAL REAL-LONDON, V25, P565, DOI 10.1007/s10055-020-00474-2
   Chardonnet JR, 2017, INT J HUM-COMPUT INT, V33, P771, DOI 10.1080/10447318.2017.1286767
   Dempster A, 2020, DATA MIN KNOWL DISC, V34, P1454, DOI 10.1007/s10618-020-00701-z
   Diersch N, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.187252
   Frank L., 1983, 882 EOTR ESSEX CORP
   Garcia-Agundez A, 2019, GAMES HEALTH J, V8, P439, DOI 10.1089/g4h.2019.0045
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Hatcher A., 2003, ALGEBRAIC TOPOLOGY
   Hausmann JC, 1995, ANN MATH STUD, P175
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/VR.2019.8798334, 10.1109/vr.2019.8798334]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2019, IEEE I CONF COMP VIS, P10579, DOI 10.1109/ICCV.2019.01068
   Langovoy M, 2007, ARXIV
   Lee S, 2019, IEEE IMAGE PROC, P440, DOI [10.1109/icip.2019.8802983, 10.1109/ICIP.2019.8802983]
   Liao CY, 2020, IEEE ACCESS, V8, P126784, DOI 10.1109/ACCESS.2020.3008165
   Lin CT, 2013, IEEE T NEUR NET LEAR, V24, P1689, DOI 10.1109/TNNLS.2013.2275003
   Lin J, 2012, J INTELL INF SYST, V39, P287, DOI 10.1007/s10844-012-0196-5
   Merienne F., 2017, ENCY COMPUTER SCI TE
   Moroni D, 2021, PATTERN RECOGN IMAGE, V31, P443, DOI 10.1134/S1054661821030184
   Niu Y., 2020, ELECT IMAGING, V2020, P60413
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Pereira CMM, 2015, EXPERT SYST APPL, V42, P6026, DOI 10.1016/j.eswa.2015.04.010
   Pincus Steven M., 1994, American Journal of Physiology, V266, pH1643
   Plouzeau J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P661, DOI 10.1109/VR.2018.8446192
   Porcino T, 2022, ENTERTAIN COMPUT, V41, DOI 10.1016/j.entcom.2021.100473
   Porcino T, 2020, IEEE INT CONF SERIOU, DOI 10.1109/segah49190.2020.9201649
   Rao J. S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P243
   Rucco M, 2017, SIGNAL PROCESS, V134, P130, DOI 10.1016/j.sigpro.2016.12.006
   Schäfer P, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P637, DOI 10.1145/3132847.3132980
   Scholkopf B., 2018, LEARNING KERNELS SUP
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Strang G., 2006, Linear Algebra and Its Applications, V4th edn.
   Wen F., 2009, P 2 INT C IM SIGN PR, P1
   West D.B., 2001, INTRO GRAPH THEORY
   Zomorodian A, 2005, DISCRETE COMPUT GEOM, V33, P249, DOI 10.1007/s00454-004-1146-y
NR 45
TC 6
Z9 6
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 11
PY 2022
VL 3
AR 973236
DI 10.3389/frvir.2022.973236
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XE4
UT WOS:001023303000001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Sadowski, I
   Khoury, B
AF Sadowski, Isabel
   Khoury, Bassam
TI Nature-based mindfulness-compassion programs using virtual reality for
   older adults: A narrative literature review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE compassion; mindfulness; nature; virtual reality; gerontechnology;
   well-being; mental health; older adults
ID COGNITIVE-BEHAVIORAL THERAPY; MENTAL-HEALTH INTERVENTIONS; RANDOMIZED
   CONTROLLED-TRIAL; SELF-COMPASSION; STRESS REDUCTION; PHYSICAL-ACTIVITY;
   COST-EFFECTIVENESS; IMPROVE ADHERENCE; SOCIAL-ISOLATION; USER ACCEPTANCE
AB The global population is aging at an unprecedented rate, increasing the necessity for effective interventions targeting the mental health needs of older adults. Technology addressing the aging process of older adults (i.e., gerontechnology) is an avenue for the efficient delivery of programs that enhance adult well-being. Virtual reality (VR) is a type of gerontechnology with the potential to improve mental health and well-being (e.g., by increasing resilience, mindfulness, compassion, connection with nature, and decreasing stress, depression, anxiety); however, evidence in this area is currently lacking and more rigorous research on the acceptability, feasibility, and effectiveness of mental health programming via VR for older adults, such as nature, mindfulness, or compassion-based interventions, is necessary. The present literature review: 1) explores, synthesizes, and critically evaluates the literature on older adult mental health, well-being and gerontechnology, with a focus on virtual reality-based nature, mindfulness, and compassion-based interventions; 2) examines research to date on the relationship between virtual reality technology and nature, mindfulness, and self-compassion; 3) identifies gaps, contradictions, and limitations of existing research; 4) identifies areas for further investigation; and 5) discusses implications for research and clinical practice.
C1 [Sadowski, Isabel; Khoury, Bassam] McGill Univ, Dept Educ & Counselling Psychol, Montreal, PQ, Canada.
C3 McGill University
RP Sadowski, I (corresponding author), McGill Univ, Dept Educ & Counselling Psychol, Montreal, PQ, Canada.
EM isabel.sadowski@mail.mcgill.ca
FU Social Sciences and Humanities Research Council of Canada; Mitacs
   Accelerate [IT24016]
FX Funding IS is supported in part by funding from the Social Sciences and
   Humanities Research Council of Canada [Canada Graduate
   Scholarships-Doctoral] and Mitacs Accelerate [grant number IT24016].
CR Aarts S, 2015, INT J GERIATR PSYCH, V30, P942, DOI 10.1002/gps.4241
   Aerts R, 2018, BRIT MED BULL, V127, P5, DOI 10.1093/bmb/ldy021
   Allen AB, 2012, SELF IDENTITY, V11, P428, DOI 10.1080/15298868.2011.595082
   Analayo Ven., 2003, Satipatthana; The direct path to realization
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Annerstedt M, 2013, PHYSIOL BEHAV, V118, P240, DOI 10.1016/j.physbeh.2013.05.023
   [Anonymous], 2021, Google Scholar
   [Anonymous], 2008, EVIDENCE REPORT TECH
   [Anonymous], 2012, MENTAL HLTH SUBSTANC
   Baez M, 2017, PEERJ, V5, DOI 10.7717/peerj.3150
   Baghaei Nilufar, 2021, EICS '21: Companion of the 2021 SIGCHI Symposium on Engineering Interactive Computing Systems, P6, DOI 10.1145/3459926.3464761
   Baghaei Nilufar, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382932
   Baghaei N., IEEE INT S MIXED AUG, P404
   Baker S, 2018, AUSTRALAS J AGEING, V37, P184, DOI 10.1111/ajag.12572
   Ball K, 2002, JAMA-J AM MED ASSOC, V288, P2271, DOI 10.1001/jama.288.18.2271
   Ballesteros S, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00045
   Baltes PB, 2003, GERONTOLOGY, V49, P123, DOI 10.1159/000067946
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Baños RM, 2012, INTERACT COMPUT, V24, P131, DOI 10.1016/j.intcom.2012.04.002
   Barlow J, 2007, J TELEMED TELECARE, V13, P172, DOI 10.1258/135763307780908058
   Bartels SJ, 2003, AM J GERIAT PSYCHIAT, V11, P648, DOI 10.1176/appi.ajgp.11.6.648
   Bartels SJ, 2013, NEW ENGL J MED, V368, P493, DOI 10.1056/NEJMp1211456
   Benham S, 2019, OTJR-OCCUP PART HEAL, V39, P90, DOI 10.1177/1539449218817291
   Benoit M, 2015, NEUROPSYCH DIS TREAT, V11, P557, DOI 10.2147/NDT.S73179
   Bercovitz K., 2016, Integrating Technology in Positive Psychology Practice, P214, DOI [10.4018/978-1-4666-9986-1.ch009, DOI 10.4018/978-1-4666-9986-1.CH009]
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bisson E, 2007, CYBERPSYCHOL BEHAV, V10, P16, DOI 10.1089/cpb.2006.9997
   Bixler R.D., 1999, J ENVIRON EDUC, V30, P4, DOI DOI 10.1080/00958969909601871
   Bodhi B, 2011, CONTEMP BUDDHISM, V12, P19, DOI 10.1080/14639947.2011.564813
   Bogner HR, 2009, AM J GERIAT PSYCHIAT, V17, P706, DOI 10.1097/JGP.0b013e3181aad5c5
   Bornioli A, 2019, TRANSPORT RES A-POL, V123, P200, DOI 10.1016/j.tra.2018.12.006
   Bornioli A, 2018, J TRANSP HEALTH, V9, P105, DOI 10.1016/j.jth.2018.02.003
   Bouma Herman, 2009, Gerontechnology, V8, P68, DOI 10.4017/gt.2009.08.02.004.00
   Brimelow RE, 2020, CYBERPSYCH BEH SOC N, V23, P165, DOI 10.1089/cyber.2019.0286
   Brion JM, 2014, J HEALTH PSYCHOL, V19, P218, DOI 10.1177/1359105312467391
   Brito-Pons G, 2018, MINDFULNESS, V9, P1494, DOI 10.1007/s12671-018-0898-z
   Broadbent E, 2014, LECT NOTES ARTIF INT, V8755, P64, DOI 10.1007/978-3-319-11973-1_7
   Brown KW, 2007, PSYCHOL INQ, V18, P211, DOI 10.1080/10478400701598298
   Brown L, 2019, GERONTOLOGIST, V59, pE311, DOI 10.1093/geront/gny108
   Brown P, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64957-7
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Browning MHEM, 2017, ENVIRON EDUC RES, V23, P1291, DOI 10.1080/13504622.2016.1177713
   Bruun-Pedersen JR, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P216, DOI 10.1109/ICHI.2016.31
   Bruun-Pedersen JR, 2014, 2014 2ND WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P23, DOI 10.1109/VAAT.2014.6799464
   Buyl R, 2020, SYST REV-LONDON, V9, DOI 10.1186/s13643-020-01385-8
   Byers AL, 2010, ARCH GEN PSYCHIAT, V67, P489, DOI 10.1001/archgenpsychiatry.2010.35
   Calogiuri G, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02321
   Calvo RA, 2013, IEEE TECHNOL SOC MAG, V32, P19, DOI 10.1109/MTS.2013.2286429
   Cangelosi PR, 2014, J PSYCHOSOC NURS MEN, V52, P17, DOI 10.3928/02793695-20140721-01
   Capaldi CA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00976
   Carrière K, 2018, OBES REV, V19, P164, DOI 10.1111/obr.12623
   Casey DA, 2012, ASIA-PAC PSYCHIAT, V4, P160, DOI 10.1111/j.1758-5872.2012.00191.x
   Cebolla A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01521
   Chan JSY, 2019, GERONTOLOGIST, V59, pE782, DOI 10.1093/geront/gnz022
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Chang SJ, 2014, GERIATR NURS, V35, P137, DOI 10.1016/j.gerinurse.2013.11.005
   Chen YRR, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.4596
   Cherniack EP, 2011, DISABIL REHABIL-ASSI, V6, P283, DOI 10.3109/17483107.2010.542570
   Chung K, 2018, J MED INTERNET RES, V20, DOI 10.2196/11152
   Ciechanowski P, 2004, JAMA-J AM MED ASSOC, V291, P1569, DOI 10.1001/jama.291.13.1569
   Cikajlo Imre, 2016, Third IASTED International Conference on Telehealth and Assistive Technology (TAT 2016). Proceedings, P11, DOI 10.2316/P.2016.846-008
   Cleare S, 2018, MINDFULNESS, V9, P618, DOI 10.1007/s12671-017-0803-1
   Cocosila M, 2009, INT J MED INFORM, V78, P230, DOI 10.1016/j.ijmedinf.2008.07.011
   Coon JT, 2011, ENVIRON SCI TECHNOL, V45, P1761, DOI 10.1021/es102947t
   Coroiu A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190771
   Cotten SR, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2306
   Crabb RM, 2012, GERONTOLOGY, V58, P164, DOI 10.1159/000329340
   Davidson R., 2002, Visions of Compassion: Western Scientists and Tibetan Buddhists Examine Human Nature
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Day S, 2004, MEMORY, V12, P416, DOI 10.1080/09658210444000034
   Dear Blake F., 2015, Internet Interventions, V2, P17, DOI 10.1016/j.invent.2014.11.002
   Dear BF, 2015, BEHAV THER, V46, P206, DOI 10.1016/j.beth.2014.09.007
   Depledge MH, 2011, ENVIRON SCI TECHNOL, V45, P4660, DOI 10.1021/es103907m
   Dermody G, 2020, J MED INTERNET RES, V22, DOI 10.2196/17331
   Dikaios E, 2020, INT J GERIATR PSYCH, V35, P1228, DOI 10.1002/gps.5360
   Drozd F, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5670
   Dudley D., 2018, VIRTUAL REALITY USED
   Dunne John., 2015, Handbook of Mindfulness and Self-Regulation
   Falconer CJ, 2016, BJPSYCH OPEN, V2, P74, DOI 10.1192/bjpo.bp.115.002147
   Falconer CJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111933
   Fang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051037
   Farrer L, 2008, BMC PUBLIC HEALTH, V8, DOI 10.1186/1471-2458-8-125
   Ferrari M, 2019, MINDFULNESS, V10, P1455, DOI 10.1007/s12671-019-01134-6
   Fiocco AJ, 2015, J EVID-BASED INTEGR, V20, P35, DOI 10.1177/2156587214553940
   Firth J, 2017, WORLD PSYCHIATRY, V16, P287, DOI 10.1002/wps.20472
   Firth J, 2017, J AFFECT DISORDERS, V218, P15, DOI 10.1016/j.jad.2017.04.046
   Fokkema T, 2007, AGING MENT HEALTH, V11, P496, DOI 10.1080/13607860701366129
   Foulk MA, 2014, J GERONTOL SOC WORK, V57, P498, DOI 10.1080/01634372.2013.869787
   Fozard J. L., 2012, CONT ISSUES GERONTOL, P241
   Fozard JL, 2000, EDUC GERONTOL, V26, P331, DOI 10.1080/036012700407820
   Franco C, 2017, TER PSICOL, V35, P71
   Gallegos AM, 2013, J ALTERN COMPLEM MED, V19, P787, DOI 10.1089/acm.2012.0028
   Ganguli M, 2004, J AM GERIATR SOC, V52, P1668, DOI 10.1111/j.1532-5415.2004.52459.x
   Garrett B, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/10839
   Geiger PJ, 2016, MINDFULNESS, V7, P296, DOI 10.1007/s12671-015-0444-1
   Gerber SM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13153-1
   Gethin R, 2011, CONTEMP BUDDHISM, V12, P263, DOI 10.1080/14639947.2011.564843
   Gilbert P., 2006, COMPASSION CONCEPTUA
   Goldberg SB, 2018, CLIN PSYCHOL REV, V59, P52, DOI 10.1016/j.cpr.2017.10.011
   Gouin JP, 2008, NEUROIMMUNOMODULAT, V15, P251, DOI 10.1159/000156468
   GRAAFMANS JAM, 1989, PROC HUM FACT SOC AN, P187
   Gum Amber M, 2009, Am J Geriatr Psychiatry, V17, P769, DOI 10.1097/JGP.0b013e3181ad4f5a
   Hank K, 2011, J GERONTOL B-PSYCHOL, V66, P230, DOI 10.1093/geronb/gbq089
   Hart R, 2013, REV GEN PSYCHOL, V17, P453, DOI 10.1037/a0035212
   Hartig T., 1997, Further development of a measure of perceived environmental restorativeness
   Hartig T, 2014, ANNU REV PUBL HEALTH, V35, P207, DOI 10.1146/annurev-publhealth-032013-182443
   Hasan H, 2016, EDUC GERONTOL, V42, P749, DOI 10.1080/03601277.2016.1205425
   Hazlett-Stevens H, 2019, CLIN GERONTOLOGIST, V42, P347, DOI 10.1080/07317115.2018.1518282
   Hedblom M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46099-7
   Henrich J, 2010, NATURE, V466, P29, DOI 10.1038/466029a
   Higgins JPT, 2011, BMJ-BRIT MED J, V343, DOI 10.1136/bmj.d5928
   Hiraoka R, 2015, J TRAUMA STRESS, V28, P127, DOI 10.1002/jts.21995
   Hofmann SG, 2010, J CONSULT CLIN PSYCH, V78, P169, DOI 10.1037/a0018555
   Howarth A, 2019, MINDFULNESS, V10, P1957, DOI 10.1007/s12671-019-01163-1
   Hughes Sally, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040023
   Jerdan SW, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/games.9226
   Joranson N, 2015, J AM MED DIR ASSOC, V16, P867, DOI 10.1016/j.jamda.2015.05.002
   Kabat-Zinn J., 1994, WHEREVER YOU GO THER, P688
   Kabat-Zinn J., 2013, Full catastrophe living: Using the wisdom of your body and mind to face stress, pain, and illness, DOI DOI 10.1002/SHI.88
   Kahlbaugh PE, 2011, ACT ADAPT AGING, V35, P331, DOI 10.1080/01924788.2011.625218
   Kang HG, 2010, J AM GERIATR SOC, V58, P1579, DOI 10.1111/j.1532-5415.2010.02959.x
   Kaplan R., 1989, EXPERIENCE NATURE PS, DOI [10.1111/j.1523-1739.2008.01010.x, DOI 10.1111/J.1523-1739.2008.01010.X]
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kaplan S, 2001, ENVIRON BEHAV, V33, P480, DOI 10.1177/00139160121973106
   Karel MJ, 2012, AM PSYCHOL, V67, P184, DOI 10.1037/a0025393
   Karlin B.E., 2008, Psychological Services, V5, P275, DOI DOI 10.1037/1541-1559.5.3.275
   Kell PA, 2020, PSYCHOSOM MED, V82, pA5, DOI 10.1097/PSY.0000000000000819
   Khoury B, 2019, MINDFULNESS, V10, P2363, DOI 10.1007/s12671-019-01211-w
   Khoury B, 2018, MINDFULNESS, V9, P1037, DOI 10.1007/s12671-017-0858-z
   Khoury B, 2017, MINDFULNESS, V8, P1160, DOI 10.1007/s12671-017-0700-7
   Khoury B, 2015, J PSYCHOSOM RES, V78, P519, DOI 10.1016/j.jpsychores.2015.03.009
   Khoury B, 2013, CLIN PSYCHOL REV, V33, P763, DOI 10.1016/j.cpr.2013.05.005
   Kim GH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123251
   Kim KI, 2017, EXP GERONTOL, V88, P25, DOI 10.1016/j.exger.2016.11.013
   Kirby JN, 2017, BEHAV THER, V48, P778, DOI 10.1016/j.beth.2017.06.003
   Kirby JN, 2017, PSYCHOL PSYCHOTHER-T, V90, P432, DOI 10.1111/papt.12104
   Kjellgren A, 2010, J ENVIRON PSYCHOL, V30, P464, DOI 10.1016/j.jenvp.2010.01.011
   Klap R, 2003, AM J GERIAT PSYCHIAT, V11, P517, DOI 10.1176/appi.ajgp.11.5.517
   Kong Saoane Thach, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P303, DOI 10.1145/3441000.3441003
   Kugler L, 2021, COMMUN ACM, V64, P15, DOI 10.1145/3441290
   Kvedar J, 2014, HEALTH AFFAIR, V33, P194, DOI 10.1377/hlthaff.2013.0992
   Kwon S., 2016, GERONTECHNOLOGY RES
   Labbé M, 2016, CAN GERIATR J, V19, P127, DOI 10.5770/cgj.19.215
   Laidlaw K., 2003, COGNITIVE BEHAV THER
   Lampit A, 2014, PLOS MED, V11, DOI 10.1371/journal.pmed.1001756
   Langer E.J., 1989, MINDFULNESS
   Langer EJ, 2000, J SOC ISSUES, V56, P1, DOI 10.1111/0022-4537.00148
   Lapane KL, 2012, INT J MED INFORM, V81, P852, DOI 10.1016/j.ijmedinf.2012.09.007
   Lattanzio F, 2014, J AM MED DIR ASSOC, V15, P457, DOI 10.1016/j.jamda.2014.04.003
   Lee LN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173556
   Lenze EJ, 2014, INT J GERIATR PSYCH, V29, P991, DOI 10.1002/gps.4086
   Levy F, 2016, NEUROPSYCH DIS TREAT, V12, P877, DOI 10.2147/NDT.S97809
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Ludden GDS, 2019, MATURITAS, V128, P10, DOI 10.1016/j.maturitas.2019.06.011
   MacBeth A, 2012, CLIN PSYCHOL REV, V32, P545, DOI 10.1016/j.cpr.2012.06.003
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Marsh IC, 2018, MINDFULNESS, V9, P1011, DOI 10.1007/s12671-017-0850-7
   Martini M, 2014, EUR J PAIN, V18, P1040, DOI 10.1002/j.1532-2149.2014.00451.x
   Martinson M, 2015, GERONTOLOGIST, V55, P58, DOI 10.1093/geront/gnu037
   Mayer FS, 2009, ENVIRON BEHAV, V41, P607, DOI 10.1177/0013916508319745
   McAuley E, 2013, J GERONTOL A-BIOL, V68, P1076, DOI 10.1093/gerona/glt014
   McCausland L, 2012, J PSYCHOSOC NURS MEN, V50, P22, DOI 10.3928/02793695-20120410-01
   McMahan EA, 2015, J POSIT PSYCHOL, V10, P507, DOI 10.1080/17439760.2014.994224
   McMahon S, 2014, TRANSL BEHAV MED, V4, P95, DOI 10.1007/s13142-013-0221-4
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mental Health Foundation, 2018, MENT HLTH STAT OLD P
   Mewton L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071825
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Millward P., 2003, First Monday, V8, DOI 10.5210/fm.v8i7.1066
   Modrego-Alarcón M, 2021, BEHAV RES THER, V142, DOI 10.1016/j.brat.2021.103866
   Mohr DC, 2013, AM J PREV MED, V45, P517, DOI 10.1016/j.amepre.2013.06.006
   Molina KI, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-156
   Montana JI, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020500
   Morgan C, 2017, INTERNET INTERV, V10, P47, DOI 10.1016/j.invent.2017.10.003
   Moyle W, 2018, GERONTOLOGIST, V58, P478, DOI 10.1093/geront/gnw270
   Moyle W, 2013, J GERONTOL NURS, V39, P46, DOI 10.3928/00989134-20130313-03
   Moynihan JA, 2013, NEUROPSYCHOBIOLOGY, V68, P34, DOI 10.1159/000350949
   Muller Ludmila, 2019, Subcell Biochem, V91, P21, DOI 10.1007/978-981-13-3681-2_2
   Muris P, 2016, MINDFULNESS, V7, P787, DOI 10.1007/s12671-016-0509-9
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Neff K.D., 2004, Constructivism in the Human Sciences, V9, P27, DOI DOI 10.1037/E633942013-240
   Neff K, 2003, SELF IDENTITY, V2, P85, DOI 10.1080/15298860390129863
   Neff KD, 2009, J PERS, V77, P23, DOI 10.1111/j.1467-6494.2008.00537.x
   Ng TKS, 2020, TRANSL PSYCHIAT, V10, DOI 10.1038/s41398-020-0696-y
   Nielsen A., 2014, MOBILE MILLENNIALS 8
   Nielsen M, 2017, J EXP CHILD PSYCHOL, V162, P31, DOI 10.1016/j.jecp.2017.04.017
   Nisbet EK, 2011, J HAPPINESS STUD, V12, P303, DOI 10.1007/s10902-010-9197-7
   Optale G, 2010, NEUROREHAB NEURAL RE, V24, P348, DOI 10.1177/1545968309353328
   Orians G. H., 1980, EVOL HUM SOC BEHAV
   Parijat P, 2015, ANN BIOMED ENG, V43, P958, DOI 10.1007/s10439-014-1128-z
   Parijat P, 2015, IEEE T BIO-MED ENG, V62, P593, DOI 10.1109/TBME.2014.2361324
   Pearson DG, 2013, CLIN PSYCHOL REV, V33, P1, DOI 10.1016/j.cpr.2012.09.001
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Perez-Blasco J, 2016, CLIN GERONTOLOGIST, V39, P90, DOI 10.1080/07317115.2015.1120253
   Peterson BN, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.742290
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Piau A, 2014, J NUTR HEALTH AGING, V18, P97, DOI 10.1007/s12603-013-0356-5
   Poissant H, 2019, BEHAV NEUROL, V2019, DOI 10.1155/2019/5682050
   PRATT DR, 1995, COMPUTER, V28, P17
   Preschl B., 2011, Journal of CyberTherapy and Rehabilitation, V3, P371, DOI DOI 10.5167/UZH-67320
   Preschl B, 2012, AGING MENT HEALTH, V16, P964, DOI 10.1080/13607863.2012.702726
   Pruchno R, 2017, J GERONTOL B-PSYCHOL, V72, P201, DOI 10.1093/geronb/gbw214
   Pywell J, 2020, DIGIT HEALTH, V6, DOI 10.1177/2055207620905422
   Reardon C., 2012, SOC WORK TODAY, V12, P10
   Reeder B, 2013, INFORM HEALTH SOC CA, V38, P211, DOI 10.3109/17538157.2012.741084
   Rendon AA, 2012, AGE AGEING, V41, P549, DOI 10.1093/ageing/afs053
   Reynolds L, 2018, J HOUS ELDER, V32, P176, DOI 10.1080/02763893.2018.1431583
   Riboni FV, 2022, INTEGR PSYCHOL BEHAV, V56, P739, DOI 10.1007/s12124-020-09580-x
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Riva G, 2020, CYBERPSYCH BEH SOC N, V23, P277, DOI 10.1089/cyber.2020.29183.gri
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Riva G, 2015, HBK COMMUN MEDIA, P528
   Robertson CE, 2016, CURR BIOL, V26, P2463, DOI 10.1016/j.cub.2016.07.002
   Rodda J, 2011, BMJ-BRIT MED J, V343, DOI 10.1136/bmj.d5219
   Roe J, 2011, HEALTH PLACE, V17, P103, DOI 10.1016/j.healthplace.2010.09.003
   Rost T, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7662
   Rowe JW, 2015, J GERONTOL B-PSYCHOL, V70, P593, DOI 10.1093/geronb/gbv025
   ROWE JW, 1987, SCIENCE, V237, P143, DOI 10.1126/science.3299702
   Rowe JW, 1997, GERONTOLOGIST, V37, P433, DOI 10.1093/geront/37.4.433
   Sadowski I, 2022, CURR PSYCHOL, V41, P5358, DOI 10.1007/s12144-020-01056-w
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sbarra DA, 2012, PSYCHOL SCI, V23, P261, DOI 10.1177/0956797611429466
   Schmitter-Edgecombe M., 2013, POSITIVE NEUROPSYCHO, V15, P143, DOI [10.1007/978-1-4614-6605-5_8, DOI 10.1007/978-1-4614-6605-5_8]
   Schutte NS, 2017, ECOPSYCHOLOGY, V9, P1, DOI 10.1089/eco.2016.0042
   Schutte NS, 2018, PERS INDIV DIFFER, V127, P10, DOI 10.1016/j.paid.2018.01.034
   Seabrook E, 2020, J MED INTERNET RES, V22, DOI 10.2196/16106
   Segal R, 2011, CYBERPSYCH BEH SOC N, V14, P29, DOI 10.1089/cyber.2009.0398
   Seifert A, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00568
   Shatil E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101472
   Shonin E, 2014, PSYCHOL RELIG SPIRIT, V6, P123, DOI 10.1037/a0035859
   Silva PA, 2015, P ANN HICSS, P3237, DOI 10.1109/HICSS.2015.390
   Silveira P, 2013, J MED INTERNET RES, V15, DOI [10.2196/jmir.2579, 10.2196/jmir.3055]
   Skurla MD, 2022, INT PSYCHOGERIATR, V34, P143, DOI 10.1017/S104161022100017X
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Smith Aaron, 2014, Older adults and technology use
   Smith JW, 2015, INT J ENV RES PUB HE, V12, P11486, DOI 10.3390/ijerph120911486
   Spek V, 2007, PSYCHOL MED, V37, P1797, DOI 10.1017/S0033291707000542
   Strauss C, 2016, CLIN PSYCHOL REV, V47, P15, DOI 10.1016/j.cpr.2016.05.004
   Taha J, 2014, J APPL GERONTOL, V33, P416, DOI 10.1177/0733464812447283
   Tavares LR, 2023, INT PSYCHOGERIATR, V35, P179, DOI 10.1017/S1041610220001222
   Thompson HJ, 2011, TELEMED E-HEALTH, V17, P794, DOI 10.1089/tmj.2011.0059
   Titov N, 2016, BJPSYCH OPEN, V2, P50, DOI 10.1192/bjpo.bp.115.002139
   Titov N, 2015, BEHAV THER, V46, P193, DOI 10.1016/j.beth.2014.09.008
   Tong X, 2015, LECT NOTES COMPUT SC, V9179, P388, DOI 10.1007/978-3-319-21067-4_40
   Torres-Platas SG, 2019, PSYCHOTHER PSYCHOSOM, V88, P254, DOI 10.1159/000501214
   Triberti S, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02052
   Tsai HH, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1678
   Tsai HH, 2010, AGING MENT HEALTH, V14, P947, DOI 10.1080/13607863.2010.501057
   Tuena C, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00093
   United Nations Department of Economic and Social Affairs Population Division, 2013, World population ageing 2013
   United Nations Department of Economic and Social Affairs Population Division, 2019, WORLD POPULATION PRO
   Unützer J, 2006, PSYCHIAT SERV, V57, P37, DOI 10.1176/appi.ps.57.1.37
   Vailati Riboni Francesco, 2018, Pervasive Computing Paradigms for Mental Health. 7th International Conference, MindCare 2018. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 253), P115, DOI 10.1007/978-3-030-01093-5_15
   Riboni FV, 2020, BMC GERIATR, V20, DOI 10.1186/s12877-020-01594-9
   Valtchanov D., 2010, THESIS U WATERLOO WA
   van den Berg AE, 2003, J ENVIRON PSYCHOL, V23, P135, DOI 10.1016/S0272-4944(02)00111-1
   Van Houwelingen-Snippe Josca, 2021, J Technol Behav Sci, V6, P464, DOI 10.1007/s41347-021-00195-6
   Vaportzis E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01687
   Wagner LS, 2003, GERONTOLOGIST, V43, P318, DOI 10.1093/geront/43.3.318
   Wang PS, 2005, ARCH GEN PSYCHIAT, V62, P629, DOI 10.1001/archpsyc.62.6.629
   Wetherell JL, 2017, J CLIN PSYCHIAT, V78, pE734, DOI 10.4088/JCP.16m10947
   White MP, 2018, NEUROPSYCH DIS TREAT, V14, P3001, DOI 10.2147/NDT.S179038
   WHO, 2017, Other common mental disorders: global health estimates
   Wilson E.O., 1984, P1
   Winstein CJ, 2016, STROKE, V47, pE98, DOI 10.1161/STR.0000000000000098
   Wong CKM, 2014, J APPL GERONTOL, V33, P316, DOI 10.1177/0733464812463430
   Wong CCY, 2016, MINDFULNESS, V7, P1385, DOI 10.1007/s12671-016-0580-2
   Wootton R, 2012, J TELEMED TELECARE, V18, P211, DOI 10.1258/jtt.2012.120219
   Xie B, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1880
   Xrhealth, 2020, AUSTR HLTH PROV BUP
   Yen HY, 2021, J AM MED DIR ASSOC, V22, P995, DOI 10.1016/j.jamda.2021.03.009
   Young LA, 2010, J EVID-BASED INTEGR, V15, P59, DOI 10.1177/1533210110387687
   Yu CP, 2018, URBAN FOR URBAN GREE, V35, P106, DOI 10.1016/j.ufug.2018.08.013
   Zainal N. H., 2020, PREPRINT, DOI [10.31234/OSF.IO/VZXW7, DOI 10.31234/OSF.IO/VZXW7]
   Zelenski JM, 2014, ENVIRON BEHAV, V46, P3, DOI 10.1177/0013916512451901
   Zeng XL, 2016, J RELIG HEALTH, V55, P1996, DOI 10.1007/s10943-016-0205-z
   Zessin U, 2015, APPL PSYCHOL-HLTH WE, V7, P340, DOI 10.1111/aphw.12051
   Zhou JN, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12072864
   Zou JB, 2012, J ANXIETY DISORD, V26, P650, DOI 10.1016/j.janxdis.2012.04.002
NR 283
TC 4
Z9 4
U1 9
U2 20
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 30
PY 2022
VL 3
AR 892905
DI 10.3389/frvir.2022.892905
PG 30
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0FT6
UT WOS:001020105500001
OA gold
DA 2024-07-18
ER

PT J
AU Nunez, OJA
   Zenner, A
   Steinicke, F
   Daiber, F
   Krüger, A
AF Nunez, Oscar Javier Ariza
   Zenner, Andre
   Steinicke, Frank
   Daiber, Florian
   Krueger, Antonio
TI Holitouch: Conveying Holistic Touch Illusions by Combining
   Pseudo-Haptics With Tactile and Proprioceptive Feedback During Virtual
   Interaction With 3DUIs
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptics; proprioceptive feedback; stiffness; virtual reality; tactile
   feedback; pseudo-haptics
ID INFORMATION; PERCEPTION; VISION
AB Virtual reality technology and immersive virtual environments often support realistic hand representations via hand-posture-sensing controllers or hand tracking for natural hand-based interaction. However, one limiting factor remains as the lack of realistic haptic feedback including tactile and proprioceptive cues; even for simple haptic interactions like touching a virtual object. This paper introduces the Holitouch technique to improve the haptic realism of essential 3D user interface elements such as buttons. Holitouch is a feedback technique based on a wearable device that combines different types of haptic feedback (i.e., 1) pseudo-haptic, 2) tactile, and 3) proprioceptive) to convey the holistic sensation of stiffness, contact, and activation while interacting with 3D buttons. Our approach provides these sensations by utilizing redundant multisensory cues, i.e., congruent feedback, to create plausible illusions of touch. The results of two experiments show that the proposed feedback combination contributes to delivering a holistic sensation when interacting with buttons in VR while having high user acceptance.
C1 [Nunez, Oscar Javier Ariza; Steinicke, Frank] Univ Hamburg, HCI Grp, Hamburg, Germany.
   [Zenner, Andre; Daiber, Florian; Krueger, Antonio] Saarland Univ, German Res Ctr Artificial Intelligence DFKI, Saarbrucken, Germany.
C3 University of Hamburg; Saarland University; German Research Center for
   Artificial Intelligence (DFKI)
RP Nunez, OJA (corresponding author), Univ Hamburg, HCI Grp, Hamburg, Germany.; Zenner, A (corresponding author), Saarland Univ, German Res Ctr Artificial Intelligence DFKI, Saarbrucken, Germany.
EM oscar.javier.ariza.nunez@uni-hamburg.de; andre.zenner@dfki.de
RI Steinicke, Frank/AAC-2976-2020
OI Steinicke, Frank/0000-0001-9879-7414; Kruger,
   Antonio/0000-0002-8055-8367
FU German Research Foundation (DFG) [450247716]
FX This research was funded by the German Research Foundation (DFG), under
   the project number 450247716.
CR Abtahi P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173724
   Achibet M, 2017, IEEE SYMP 3D USER, P103, DOI 10.1109/3DUI.2017.7893325
   Achibet M, 2015, P IEEE VIRT REAL ANN, P63, DOI 10.1109/VR.2015.7223325
   Achibet M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P59, DOI 10.1109/3DUI.2014.6798843
   Adilkhanov A, 2020, IEEE ROBOT AUTOM LET, V5, P2785, DOI 10.1109/LRA.2020.2972793
   [Anonymous], 2019, Virtual Reality Intell. Harde
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Ariza O, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P327, DOI 10.1109/VR.2018.8446317
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Bergström J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1175, DOI 10.1145/3332165.3347939
   Bermejo Carlos, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3457141
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Bowman DA, 2005, P IEEE VIRT REAL ANN, P312, DOI 10.1109/VR.2005.58
   Bratt M, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P2716
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Di Luca M, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P67, DOI [10.1109/WHC.2019.8816173, 10.1109/whc.2019.8816173]
   Dominjon L, 2005, P IEEE VIRT REAL ANN, P19
   Duente T, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098546
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Faeth A, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2535923
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985
   Georgiou Theodoros., 2014, Human haptic perception in virtual environments: An investigation of the interrelationship between physical stiffness and perceived roughness
   Gomi H, 2008, CURR OPIN NEUROBIOL, V18, P558, DOI 10.1016/j.conb.2008.11.002
   Gonçalves G, 2020, IEEE T VIS COMPUT GR, V26, P3231, DOI 10.1109/TVCG.2019.2926978
   Gonzalez EJ, 2019, ADJUNCT PUBLICATION OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'19 ADJUNCT), P4, DOI 10.1145/3332167.3357096
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   Harwin W. S., 2002, P EUR C, P82
   Helbig HB, 2007, EXP BRAIN RES, V179, P595, DOI 10.1007/s00221-006-0814-y
   Jacob R.J. K., 1994, ACM Transactions Computer-Human Interaction, V1, P3, DOI [DOI 10.1145/174630.174631, 10.1145/174630.174631]
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   Kammermeier P, 2004, PRESENCE-VIRTUAL AUG, V13, P1, DOI 10.1162/105474604774048199
   Khamis M, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364250
   Kim H, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3694, DOI 10.1145/2858036.2858196
   Kim J, 2022, IEEE ACCESS, V10, P5129, DOI 10.1109/ACCESS.2022.3140438
   Kim S., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P553
   Kim S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174145
   Kim Sunjun., 2013, Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology, UIST'13, P91, DOI [10.1145/2501988.2502041, DOI 10.1145/2501988.2502041]
   Kim W, 2021, Arxiv, DOI arXiv:2112.11007
   Kohli L., 2013, REDIRECTED TOUCHING
   Kuroki S, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P121
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee Byungjoo., 2017, Proceedings of the 19th ACM International Conference on Multimodal Interaction. ICMI'17, P252, DOI DOI 10.1145/3136755.3136761
   Lee Y, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P19, DOI 10.1109/WHC.2015.7177685
   Liao YC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376262
   Liao YC, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P111, DOI 10.1145/3266037.3266118
   Lo JY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P839, DOI 10.1145/3242587.3242627
   Lopes P., 2013, P SIGCHI C HUM FACT, P2577, DOI [10.1145/2470654.2481355, DOI 10.1145/2470654.2481355]
   Lopes P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1471, DOI 10.1145/3025453.3025600
   Lopes P, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P11, DOI 10.1145/2807442.2807443
   Lubos P, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P13, DOI 10.1145/2983310.2985753
   Maereg AT, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00042
   Marchal M., 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P297, DOI 10.1007/978-3-030-58147-3_33
   Martinez PC, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2426, DOI 10.1145/3025453.3025457
   Metzger A, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P75, DOI 10.1109/WHC.2015.7177694
   Miyamoto N., 2015, AIR TAP SENSATION TA, P285, DOI [10.1007/978-4-431-55690-9_52, DOI 10.1007/978-4-431-55690-9_52]
   Napier J., 1993, Hands
   Nilsson NC, 2021, IEEE COMPUT GRAPH, V41, P104, DOI 10.1109/MCG.2021.3097671
   Oulasvirta A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174082
   Parise CV, 2016, MULTISENS RES, V29, P7, DOI 10.1163/22134808-00002502
   Pezent Evan, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3383151
   Pezent E, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P1, DOI [10.1109/whc.2019.8816098, 10.1109/WHC.2019.8816098]
   Pfeiffer M., 2014, P 5 AUGM HUM INT C, P1, DOI [10.1145/2582051.2582099, DOI 10.1145/2582051.2582099]
   Reed C.L., 2018, CURATED REFERENCE CO, DOI [10.1016/B978-0-12-809324-5.03182-5, DOI 10.1016/B978-0-12-809324-5.03182-5]
   Rietzler M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174034
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Schorr SB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3115, DOI 10.1145/3025453.3025744
   Sinclair M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P815, DOI 10.1145/3332165.3347891
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strasnick E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174218
   Sun YQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300682
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Takahashi A, 2018, LECT NOTES ELECTR EN, V432, P233, DOI 10.1007/978-981-10-4157-0_40
   Takahashi Akifumi, 2021, Increasing Electrical Muscle Stimulation's Dexterity by Means of Back of the Hand Actuation, DOI [10.1145/3411764.3445761, DOI 10.1145/3411764.3445761]
   Tamaki E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P543
   Verschoor M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392398
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Yang J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P889, DOI 10.1145/3242587.3242643
   Yem V, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P89, DOI 10.1109/VR.2018.8446403
   Yu R, 2020, IEEE T VIS COMPUT GR, V26, P2094, DOI 10.1109/TVCG.2020.2973056
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 90
TC 3
Z9 3
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 8
PY 2022
VL 3
AR 879845
DI 10.3389/frvir.2022.879845
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RA5
UT WOS:001023141900001
OA gold
DA 2024-07-18
ER

PT J
AU Xia, XX
   Guan, FY
   Cai, YY
   Thalmann, NM
AF Xia, Xinxing
   Guan, Frank Yunqing
   Cai, Yiyu
   Thalmann, Nadia Magnenat
TI Challenges and Advancements for AR Optical See-Through Near-Eye
   Displays: A Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE near-eye display; head-mounted display; augmented reality; optical
   see-through; review
ID HEAD-MOUNTED DISPLAY; AUGMENTED REALITY; HOLOGRAM GENERATION;
   MAXWELLIAN-VIEW; PLANAR OPTICS; OCCLUSION; SYSTEM; EFFICIENCY;
   RESOLUTION; COMBINER
AB Optical see-through near-eye display (NED) technologies for augmented reality (AR) have achieved significant advancements recently with investments from both academia and industry. Although various AR NED products have been successfully commercialized and even deployed into applications, there are still challenges with present AR NED technologies (e.g., limited eyebox, fixed focus, bulky form factors). In this review, we present a brief overview of leading AR NED technologies and then focus on the state-of-the-art research works to counter the respective key challenges with each of the leading AR NED technologies. We also introduce a number of emerging technologies that are worthy of close study.
C1 [Xia, Xinxing] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
   [Guan, Frank Yunqing] Singapore Inst Technol, ICT Cluster, Singapore, Singapore.
   [Cai, Yiyu] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore, Singapore.
   [Thalmann, Nadia Magnenat] Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
C3 Shanghai University; Singapore Institute of Technology; Nanyang
   Technological University; Nanyang Technological University
RP Guan, FY (corresponding author), Singapore Inst Technol, ICT Cluster, Singapore, Singapore.
EM frank.guan@singaporetech.edu.sg
FU National Natural Science Foundation of China [62005154]; Natural Science
   Foundation of Shanghai [20ZR1420500]; National Key Research and
   Development Program of China [2021YFF0307803]; MOE TIF Grant
   [MOE2019-TIF-0011]
FX Funding This work is supported by the National Natural Science
   Foundation of China (Grant No. 62005154), the Natural Science Foundation
   of Shanghai (Grant No. 20ZR1420500), National Key Research and
   Development Program of China (No. 2021YFF0307803) and MOE TIF Grant
   (MOE2019-TIF-0011).
CR Arbabi E, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03155-6
   Askari M, 2017, OPT EXPRESS, V25, P25867, DOI 10.1364/OE.25.025867
   Barten PGJ, 2004, P SOC PHOTO-OPT INS, V5294, P231, DOI 10.1117/12.537476
   Bayati E, 2021, APPL OPTICS, V60, P844, DOI 10.1364/AO.410895
   Benton S.A., 2008, Holographic imaging
   Boo H., 2021, P C LASERS ELECTRO O, V2021, pSTu4D.5, DOI [10.1364/cleo_si.2021.stu4d.5, DOI 10.1364/CLEO_SI.2021.STU4D.5]
   Brooker G., 2003, MODERN CLASSICAL OPT
   Cakmakci O, 2006, J DISP TECHNOL, V2, P199, DOI 10.1109/JDT.2006.879846
   Chae Minseok, 2021, Opt Lett, V46, P4554, DOI 10.1364/OL.430478
   Chang C, 2020, OPTICA, V7, P1563, DOI 10.1364/OPTICA.406004
   Chang CL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55346-w
   Chen CP, 2021, DISPLAYS, V67, DOI 10.1016/j.displa.2021.101998
   Chen JS, 2015, OPT EXPRESS, V23, P18143, DOI 10.1364/OE.23.018143
   Chiam BSW, 2021, INT SYM MIX AUGMENT, P195, DOI 10.1109/ISMAR-Adjunct54149.2021.00047
   Choi J, 2020, VISUAL COMPUT, V36, P2039, DOI 10.1007/s00371-020-01902-9
   Choi MH, 2020, J INFORM DISPLAY, V21, P33, DOI 10.1080/15980316.2019.1674196
   Choi M, 2020, OPT EXPRESS, V28, P533, DOI 10.1364/OE.381277
   Cui W, 2020, OPT LETT, V45, P2808, DOI 10.1364/OL.393550
   de Galarreta CR, 2020, OPTICA, V7, P476, DOI 10.1364/OPTICA.384138
   DROESSLER JG, 1990, OPT ENG, V29, P849, DOI 10.1117/12.55669
   Dunn D, 2017, IEEE T VIS COMPUT GR, V23, P1275, DOI 10.1109/TVCG.2017.2657058
   Eisen L, 2006, OPT LETT, V31, P1522, DOI 10.1364/OL.31.001522
   Gao QK, 2017, OPT EXPRESS, V25, P8412, DOI 10.1364/OE.25.008412
   Gao QK, 2016, OPT EXPRESS, V24, P17372, DOI 10.1364/OE.24.017372
   Genevet P, 2017, OPTICA, V4, P139, DOI 10.1364/OPTICA.4.000139
   Gilles A, 2016, APPL OPTICS, V55, P5459, DOI 10.1364/AO.55.005459
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hong C, 2017, APPL OPTICS, V56, P8822, DOI 10.1364/AO.56.008822
   Horisaki R, 2018, APPL OPTICS, V57, P3859, DOI 10.1364/AO.57.003859
   Hoshii H, 1996, P SOC PHOTO-OPT INS, V2653, P234, DOI 10.1117/12.237443
   Hu XD, 2014, OPT EXPRESS, V22, P13896, DOI 10.1364/OE.22.013896
   Hua H, 2014, OPT EXPRESS, V22, P13484, DOI 10.1364/OE.22.013484
   Jang CG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417762
   Jang C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275069
   Jang C, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130889
   Jeong J, 2019, OPT EXPRESS, V27, P38006, DOI 10.1364/OE.382190
   Ju YG, 2020, OPT LETT, V45, P3361, DOI 10.1364/OL.393194
   Kim N., 2017, Holographic Optical Elements and Application, Holographic Materials and Optical Systems, DOI [10.5772/67297, DOI 10.5772/67297]
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Koulieris GA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073622
   Krajancich B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417820
   Kress B. C., 2020, Optical architectures for augmented-, virtual-, and mixed-reality headsets, DOI [DOI 10.1117/3.2559304, 10.1117/3.2559304]
   Kress B, 2013, PROC SPIE, V8720, DOI 10.1117/12.2015654
   Lan SF, 2019, ACS PHOTONICS, V6, P864, DOI 10.1021/acsphotonics.9b00180
   Lee B, 2020, PROC SPIE, V11551, DOI 10.1117/12.2573605
   Lee CK, 2016, OPT EXPRESS, V24, P19531, DOI 10.1364/OE.24.019531
   Lee GY, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07011-5
   Lee JS, 2019, OPT EXPRESS, V27, P689, DOI 10.1364/OE.27.000689
   Lee J, 2020, OPT EXPRESS, V28, P27137, DOI 10.1364/OE.402317
   Lee YH, 2017, OPT LETT, V42, P4732, DOI 10.1364/OL.42.004732
   Levola T, 2007, SID INT SYMP DIG TEC, V38, P1158, DOI 10.1889/1.2785514
   Levola T, 2008, J SOC INF DISPLAY, V16, P857, DOI 10.1889/1.2966447
   Lin TG, 2020, OPT EXPRESS, V28, P38616, DOI 10.1364/OE.413471
   Liu S, 2008, INT SYM MIX AUGMENT, P33, DOI 10.1109/ISMAR.2008.4637321
   Maimone A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073624
   Maimone A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601141
   Makey G, 2012, APPL OPTICS, V51, P7877, DOI 10.1364/AO.51.007877
   McQuaide SC, 2003, DISPLAYS, V24, P65, DOI 10.1016/S0141-9382(03)00016-7
   Monnai Y., 2014, P 27 ANN ACM S US IN, P663, DOI [DOI 10.1145/2642918.2647407, https://doi.org/10.1145/2642918.2647407]
   Moon S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42979-0
   Morishima H., 1995, 20 OPTICAL S, P53
   Mukawa H, 2008, SID INT SYMP DIG TEC, V39, P89, DOI 10.1889/1.3069819
   Neshev D, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0058-1
   Nikolov DK, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abe5112
   Olbrich M, 2013, VISUAL COMPUT, V29, P1093, DOI 10.1007/s00371-013-0840-2
   Ong D.X., 2021, P 15 IEEE INT C SERV, P1, DOI DOI 10.1109/SOLI54607.2021.9672391
   Otao K, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149425
   Padmanaban N, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356517
   Park JH, 2018, OPT EXPRESS, V26, P27076, DOI 10.1364/OE.26.027076
   Park S.-g., 2020, P SPIE, DOI [10.1117/12.2566389, DOI 10.1117/12.2566389]
   Peng YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417802
   Piao JA, 2013, J OPT SOC KOREA, V17, P242, DOI 10.3807/JOSK.2013.17.3.242
   Piskunov DE, 2020, PROC SPIE, V11350, DOI 10.1117/12.2565635
   Rolland JP, 2021, OPTICA, V8, P161, DOI 10.1364/OPTICA.413762
   ROLLAND JP, 1994, P SOC PHOTO-OPT INS, V2351, P293
   ROTIER DJ, 1989, P SOC PHOTO-OPT INS, V1116, P14
   Shen ZW, 2017, IEEE PHOTONICS J, V9, DOI 10.1109/JPHOT.2017.2767606
   Shi R, 2012, APPL OPTICS, V51, P4703, DOI 10.1364/AO.51.004703
   Shin CW, 2021, OPT EXPRESS, V29, P1175, DOI 10.1364/OE.413370
   Snyder A.W., 1983, Optical Waveguide Theory
   Song WT, 2021, OPT EXPRESS, V29, P8098, DOI 10.1364/OE.421439
   Song WT, 2019, OPT EXPRESS, V27, P23763, DOI 10.1364/OE.27.023763
   Stevens RE, 2018, PROC SPIE, V10676, DOI 10.1117/12.2318397
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tan GJ, 2018, OPT LETT, V43, P5651, DOI 10.1364/OL.43.005651
   Wang JH, 2015, J OPT SOC KOREA, V19, P614, DOI 10.3807/JOSK.2015.19.6.614
   Wei H, 2016, APPL OPTICS, V55, P9255, DOI 10.1364/AO.55.009255
   Weng YS, 2016, OPT EXPRESS, V24, P17746, DOI 10.1364/OE.24.017746
   Wheelwright B, 2018, PROC SPIE, V10676, DOI 10.1117/12.2307303
   Wilson A, 2018, PROC SPIE, V10676, DOI 10.1117/12.2315771
   Wilson A, 2017, OPT EXPRESS, V25, P30539, DOI 10.1364/OE.25.030539
   Xia X., 2020, IEEE ISMAR 2020
   Xia XX, 2019, IEEE T VIS COMPUT GR, V25, P3114, DOI 10.1109/TVCG.2019.2932238
   Xiong JH, 2021, PROC SPIE, V11765, DOI 10.1117/12.2577856
   Xiong JH, 2021, OPT LETT, V46, P1760, DOI 10.1364/OL.422559
   Yamazaki S, 1999, P SOC PHOTO-OPT INS, V3639, P453, DOI 10.1117/12.349411
   Yano S, 2002, DISPLAYS, V23, P191, DOI 10.1016/S0141-9382(02)00038-0
   Yaras F, 2010, J DISP TECHNOL, V6, P443, DOI 10.1109/JDT.2010.2045734
   Yoo C, 2020, OPT LETT, V45, P2870, DOI 10.1364/OL.391965
   Yoo C, 2019, OPT LETT, V44, P1920, DOI 10.1364/OL.44.001920
   Yu K, 2020, VISUAL COMPUT, V36, P2051, DOI 10.1007/s00371-020-01911-8
   Yu NF, 2011, SCIENCE, V334, P333, DOI 10.1126/science.1210713
   Yuuki A, 2012, J SOC INF DISPLAY, V20, P581, DOI 10.1002/jsid.122
   Zabels R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153147
   Zhan T, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101397
   Zhan T, 2019, J OPT SOC AM B, V36, pD52, DOI 10.1364/JOSAB.36.000D52
   Zhang Y, 2021, OPT EXPRESS, V29, P42751, DOI 10.1364/OE.444904
   Zhang Y, 2019, PRECIS ENG, V60, P482, DOI 10.1016/j.precisioneng.2019.09.009
   Zschau E, 2010, P SOC PHOTO-OPT INS, V7690, DOI 10.1117/12.851015
NR 110
TC 4
Z9 4
U1 8
U2 14
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 14
PY 2022
VL 3
AR 838237
DI 10.3389/frvir.2022.838237
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZB8
UT WOS:001019254400001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Pavic, K
   Vergilino-Perez, D
   Gricourt, T
   Chaby, L
AF Pavic, Katarina
   Vergilino-Perez, Dorine
   Gricourt, Thierry
   Chaby, Laurence
TI Because I'm Happy-An Overview on Fostering Positive Emotions Through
   Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; well-being; aging; mood induction; emotion;
   physiological measure; positive technologies
ID STRESS RECOVERY; NEGATIVE AFFECT; ENVIRONMENTS; PSYCHOLOGY; HAPPINESS;
   HEALTH; MOOD; INDUCTION; PEOPLE; ATTENTION
AB In recent years, an increased demand for improving mental health and well-being led to developing procedures capable of enhancing positive experiences. One highly attractive candidate for evoking positive experiences is Virtual Reality (VR), as VR enables users to experience various situations in controlled and safe environments. This overview first investigates how positive emotions, well-being and VR are interconnected. Then, an overview about how and why to induce positive emotions in adult users is provided. Methodological and ethical considerations about VR technology, measurements of VR's efficacy and user characteristics are reviewed. It emerges that VR is efficient in inducing positive emotions across the adult lifespan and in various settings. Levels of immersion, interactivity, Virtual environment contents, sensory modalities involved and users' characteristics emerged as key determinants for successfully inducing positive emotions with VR. The main applications of positive VR experiences consist in using VR for relaxation, stress and pain management, motivation for physical activities, and gives promising results for apathy treatment in elderly users. Although VR is efficient in eliciting positive emotions and experiences, the underlying operating mechanisms remain unclear and are yet to be further investigated. Finally, the need for a user-centered approach when designing positive VR experiences, clear guidelines for the use of VR, and a better documentation of its potential adverse effects are addressed.
C1 [Pavic, Katarina; Vergilino-Perez, Dorine] Univ Paris, Vis Act Cognit, Paris, France.
   [Pavic, Katarina; Chaby, Laurence] Sorbonne Univ, Inst Syst Intelligents & Robot, CNRS, ISIR, Paris, France.
   [Pavic, Katarina; Gricourt, Thierry] SocialDream, Res & Dev Dept, Bourg De Peage, France.
   [Chaby, Laurence] Univ Paris, UFR Psychol, Boulogne Billancourt, France.
C3 Universite Paris Cite; Sorbonne Universite; Centre National de la
   Recherche Scientifique (CNRS); Universite Paris Cite
RP Pavic, K (corresponding author), Univ Paris, Vis Act Cognit, Paris, France.; Pavic, K (corresponding author), Sorbonne Univ, Inst Syst Intelligents & Robot, CNRS, ISIR, Paris, France.; Pavic, K (corresponding author), SocialDream, Res & Dev Dept, Bourg De Peage, France.
EM katarina.pavic@u-paris.fr
RI Pavic, Katarina/AGG-7756-2022; Chaby, Laurence/B-7830-2013
OI Pavic, Katarina/0000-0002-5660-1265; Chaby, Laurence/0000-0002-2241-412X
FU French Research and Technology Association (ANRT, Association Nationale
   de la Recherche et de la Technologie); Universite de Paris [2019/0715];
   Sorbonne Universite [2019/0715]; SocialDream [2019/0715]
FX This work was supported by the French Research and Technology
   Association (ANRT, Association Nationale de la Recherche et de la
   Technologie) exclusively for a doctorate scholarship and program between
   Universite de Paris, Sorbonne Universite and SocialDream from 2020 to
   2023 (Grant Number 2019/0715). The funder had no role in study design,
   data collection and analysis, decision to publish, or preparation of the
   manuscript.
CR Akobeng AK, 2016, ACTA PAEDIATR, V105, P605, DOI 10.1111/apa.13384
   Alexander R., 2020, NEUROSCI BIOBEHAV R
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Annerstedt M, 2013, PHYSIOL BEHAV, V118, P240, DOI 10.1016/j.physbeh.2013.05.023
   Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Baker S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102105
   Baltes M.M., 2003, Understanding human development: Dialogues with lifespan psychology, P81, DOI [10.1007/978-1-4615-0357-6_5, DOI 10.1007/978-1-4615-0357-6_5]
   Baltes P.B., 1990, SUCCESSFUL AGING PER, P1, DOI DOI 10.1017/CBO9780511665684.003
   Baños RM, 2012, INTERACT COMPUT, V24, P131, DOI 10.1016/j.intcom.2012.04.002
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Benoit M, 2015, NEUROPSYCH DIS TREAT, V11, P557, DOI 10.2147/NDT.S73179
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Bittner L., 2018, BIORXIV, P451245, DOI [10.1101/451245, DOI 10.1101/451245]
   Blair KS, 2007, NEUROIMAGE, V35, P430, DOI 10.1016/j.neuroimage.2006.11.048
   Bos EH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150867
   Botella C, 2012, CYBERPSYCH BEH SOC N, V15, P78, DOI 10.1089/cyber.2011.0140
   Botella J, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.581910
   Brimelow RE, 2020, CYBERPSYCH BEH SOC N, V23, P165, DOI 10.1089/cyber.2019.0286
   Britton JC, 2006, EMOTION, V6, P150, DOI 10.1037/1528-3542.6.1.150
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Brockman R, 2017, COGN BEHAV THERAPY, V46, P91, DOI 10.1080/16506073.2016.1218926
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Castilla D, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17145153
   Castilla D, 2013, INT J HUM-COMPUT ST, V71, P350, DOI 10.1016/j.ijhcs.2012.10.017
   Chan JYC, 2020, INT J GERIATR PSYCH, V35, P926, DOI 10.1002/gps.5314
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chirico A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0233628
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Chirico A, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02351
   Chirico A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01242-0
   Cho BH, 2002, CYBERPSYCHOL BEHAV, V5, P129, DOI 10.1089/109493102753770516
   Cohen AO, 2016, J COGNITIVE NEUROSCI, V28, P446, DOI 10.1162/jocn_a_00906
   Colden A, 2008, MOTIV EMOTION, V32, P260, DOI 10.1007/s11031-008-9107-z
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   D'Cunha NM, 2019, GERONTOLOGY, V65, P430, DOI 10.1159/000500040
   Desmet PMA, 2012, INT J DES, V6, P1
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Diener E, 1999, PSYCHOL BULL, V125, P276, DOI 10.1037//0033-2909.125.2.276
   Diener E, 2011, APPL PSYCHOL-HLTH WE, V3, P1, DOI 10.1111/j.1758-0854.2010.01045.x
   Diniz BernardoP., 2020, Journal of Technology in Behavioral Science, V6, P3, DOI [10.1007/s41347-020-00152-9, DOI 10.1007/S41347-020-00152-9]
   Dolan RJ, 2002, SCIENCE, V298, P1191, DOI 10.1126/science.1076358
   Droit-Volet S, 2020, ACTA PSYCHOL, V210, DOI 10.1016/j.actpsy.2020.103170
   Ekkekakis P., 2012, Measurement in Sport and Exercise Psychology, P321, DOI DOI 10.5040/9781492596332.CH-028
   Elor A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.585993
   Etchemendy E, 2011, COMPUT EDUC, V56, P275, DOI 10.1016/j.compedu.2010.07.022
   Evans CP, 2020, CYBERPSYCH BEH SOC N, V23, P134, DOI 10.1089/cyber.2019.0241
   Fagernäs S, 2021, INTERNET INTERV, V24, DOI 10.1016/j.invent.2021.100370
   Fauville G., 2020, Technology and Health, P91, DOI DOI 10.1016/B978-0-12-816958-2.00005-8
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Ford B.Q., 2014, POSITIVE EMOTION INT, P363, DOI [10.1093/acprof:oso/9780199926725.003.0020, DOI 10.1093/ACPROF:OSO/9780199926725.003.0020]
   Fredrickson B.L., 2006, J POSIT PSYCHOL, V1, P57, DOI [DOI 10.1080/17439760500510981, 10.1080/17439760500510981]
   Fredrickson BL, 2003, AM SCI, V91, P330, DOI 10.1511/2003.4.330
   Fredrickson BL, 2005, COGNITION EMOTION, V19, P313, DOI 10.1080/02699930441000238
   Fredrickson BL, 2004, PHILOS T R SOC B, V359, P1367, DOI 10.1098/rstb.2004.1512
   Fredrickson BL, 2002, PSYCHOL SCI, V13, P172, DOI 10.1111/1467-9280.00431
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Gallace Alberto, 2012, Multiple sensorial media advances and applications, P1, DOI DOI 10.4018/978-1-60960-821-7.CH001
   Ganesan B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.565190
   Garland EL, 2010, CLIN PSYCHOL REV, V30, P849, DOI 10.1016/j.cpr.2010.03.002
   Gordon NS, 2011, COMPUT HUM BEHAV, V27, P2123, DOI 10.1016/j.chb.2011.06.006
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Gruber J, 2008, EMOTION, V8, P23, DOI 10.1037/1528-3542.8.1.23
   Gupta R, 2019, PROG BRAIN RES, V247, P23, DOI 10.1016/bs.pbr.2019.02.001
   Held BS, 2018, J HUMANIST PSYCHOL, V58, P313, DOI 10.1177/0022167817739409
   Henderson L.W., 2012, International Journal of Wellbeing, V2, DOI [DOI 10.5502/IJW.V2I3.3, https://doi.org/10.5502/ijw.v2i3.3]
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P61, DOI 10.1017/S0140525X0999152X
   Henrich J, 2010, NATURE, V466, P29, DOI 10.1038/466029a
   Hofman K, 2022, J SUSTAIN TOUR, V30, P742, DOI 10.1080/09669582.2021.1884690
   Holland AC, 2010, PHYS LIFE REV, V7, P88, DOI 10.1016/j.plrev.2010.01.006
   Hsu WC, 2018, EDUC TECHNOL SOC, V21, P187
   Huang JW, 2021, INT J GEOGR INF SCI, V35, P1155, DOI 10.1080/13658816.2020.1830997
   Huntsinger JR, 2012, J EXP PSYCHOL GEN, V141, P595, DOI 10.1037/a0027709
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Jerdan SW, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/games.9226
   Joshanloo M, 2014, J HAPPINESS STUD, V15, P717, DOI 10.1007/s10902-013-9489-9
   Kaplan R., 1989, EXPERIENCE NATURE PS
   Kashdan T. B., 2008, The Journal of Positive Psychology, V3, P219, DOI [DOI 10.1080/17439760802303044, 10.1080/17439760802303044]
   Kellmeyer P, 2019, NAT MED, V25, P1185, DOI 10.1038/s41591-019-0543-y
   Kellmeyer P, 2018, CAMB Q HEALTHC ETHIC, V27, P610, DOI 10.1017/S0963180118000129
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kenwright B, 2018, IEEE TECHNOL SOC MAG, V37, P20, DOI 10.1109/MTS.2018.2876104
   Kern A. C., 2020, P 15 INT C AUD MOSTL, P233, DOI [10.1145/3411109.3411129, DOI 10.1145/3411109.3411129]
   Killgore WDS, 2020, PSYCHIAT RES, V290, DOI 10.1016/j.psychres.2020.113117
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Kitson A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01354
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Kuppens P, 2008, J PERS SOC PSYCHOL, V95, P66, DOI 10.1037/0022-3514.95.1.66
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lakens D, 2017, SOC PSYCHOL PERS SCI, V8, P875, DOI 10.1177/1948550617693058
   Lang P. J., 1997, NIMH CTR STUDY EMOTI, V1, P39
   LaValle S.M., 2016, Virtual Reality
   Lent RW, 2004, J COUNS PSYCHOL, V51, P482, DOI 10.1037/0022-0167.51.4.482
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Li G, 2020, J COGNITIVE NEUROSCI, V32, P1438, DOI 10.1162/jocn_a_01560
   Liszio S, 2019, ANN REV CYBERTHERAPY, V17, P65
   Liszio S, 2018, ANN REV CYBERTHERAPY, V16, P87
   Liu Q, 2020, CYBERPSYCH BEH SOC N, V23, P157, DOI 10.1089/cyber.2019.0273
   Lyubomirsky S, 2005, PSYCHOL BULL, V131, P803, DOI 10.1037/0033-2909.131.6.803
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Baños RM, 2017, SPAN J PSYCHOL, V20, DOI 10.1017/sjp.2017.42
   Baños RM, 2014, J POSIT PSYCHOL, V9, P482, DOI 10.1080/17439760.2014.927906
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   MARTIN M, 1990, CLIN PSYCHOL REV, V10, P669, DOI 10.1016/0272-7358(90)90075-L
   Mattila O, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106295
   McMahan EA, 2015, J POSIT PSYCHOL, V10, P507, DOI 10.1080/17439760.2014.994224
   McRae K, 2012, EMOTION, V12, P250, DOI 10.1037/a0026351
   Miragall M, 2021, CURR PSYCHOL, V40, P2390, DOI 10.1007/s12144-019-00175-3
   Mosadeghi S, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.5801
   Moseley GL, 2012, NEUROSCI BIOBEHAV R, V36, P34, DOI 10.1016/j.neubiorev.2011.03.013
   Moss SA, 2015, EXPLORE-NY, V11, P40, DOI 10.1016/j.explore.2014.10.006
   Moyle W, 2018, GERONTOLOGIST, V58, P478, DOI 10.1093/geront/gnw270
   Nelson KM, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0223631
   Nelson LD, 2018, ANNU REV PSYCHOL, V69, P511, DOI 10.1146/annurev-psych-122216-011836
   Nickerson C., 2007, J HAPPINESS STUD, V8, P537, DOI [DOI 10.1007/S10902-006-9030-5, 10.1007/s10902-006-9030-5]
   Nosek BA, 2014, SOC PSYCHOL-GERMANY, V45, P137, DOI 10.1027/1864-9335/a000192
   Ong AD, 2010, CURR DIR PSYCHOL SCI, V19, P358, DOI 10.1177/0963721410388805
   Pérez-Alvarez M, 2016, J THEOR PHILOS PSYCH, V36, P1, DOI 10.1037/teo0000030
   Phillips LH, 2002, EMOTION, V2, P12, DOI 10.1037/1528-3542.2.1.12
   Pimentel D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627059
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Riva G, 2018, ANN REV CYBERTHERAPY, V16, P3
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Riva G, 2012, CYBERPSYCH BEH SOC N, V15, P69, DOI 10.1089/cyber.2011.0139
   Roberts AR, 2019, CLIN GERONTOLOGIST, V42, P27, DOI 10.1080/07317115.2018.1442380
   Rockstroh C, 2019, INT J HUM-COMPUT ST, V130, P209, DOI 10.1016/j.ijhcs.2019.06.011
   Rowe G, 2007, P NATL ACAD SCI USA, V104, P383, DOI 10.1073/pnas.0605198104
   Rowe JW, 2015, J GERONTOL B-PSYCHOL, V70, P593, DOI 10.1093/geronb/gbv025
   ROWE JW, 1987, SCIENCE, V237, P143, DOI 10.1126/science.3299702
   RYFF CD, 1989, J PERS SOC PSYCHOL, V57, P1069, DOI 10.1037/0022-3514.57.6.1069
   Sander D, 2005, NEURAL NETWORKS, V18, P317, DOI 10.1016/j.neunet.2005.03.001
   Saredakis D, 2020, J MED INTERNET RES, V22, DOI 10.2196/17632
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Seabrook E, 2020, J MED INTERNET RES, V22, DOI 10.2196/16106
   Seligman MEP, 2000, AM PSYCHOL, V55, P5, DOI 10.1037/0003-066X.55.1.5
   Serino S, 2016, CYBERPSYCH BEH SOC N, V19, P127, DOI 10.1089/cyber.2015.0229
   Serrano B, 2016, COMPUT HUM BEHAV, V55, P1, DOI 10.1016/j.chb.2015.08.007
   Sharar SR, 2016, GAMES HEALTH J, V5, P197, DOI 10.1089/g4h.2015.0046
   Shiota MN, 2011, EMOTION, V11, P1368, DOI 10.1037/a0024278
   Siess A, 2019, COMPUT GRAPH-UK, V81, P20, DOI 10.1016/j.cag.2019.03.018
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Steptoe A, 2015, LANCET, V385, P640, DOI 10.1016/S0140-6736(13)61489-0
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Suardi A, 2016, COGN AFFECT BEHAV NE, V16, P383, DOI 10.3758/s13415-016-0414-7
   Taylor A., 2017, J EXP PSYCHOL, V8, P521
   Thompson T, 2011, INT J CLIN EXP HYP, V59, P122, DOI 10.1080/00207144.2011.522917
   Twohig-Bennett C, 2018, ENVIRON RES, V166, P628, DOI 10.1016/j.envres.2018.06.030
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   Västfjäll D, 2001, MUSIC SCI, V5, P173
   VELTEN E, 1968, BEHAV RES THER, V6, P473, DOI 10.1016/0005-7967(68)90028-4
   Villani D, 2012, CYBERPSYCH BEH SOC N, V15, P24, DOI 10.1089/cyber.2011.0141
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Yeo NL, 2020, J ENVIRON PSYCHOL, V72, DOI 10.1016/j.jenvp.2020.101500
   Yu CP, 2020, URBAN FOR URBAN GREE, V56, DOI 10.1016/j.ufug.2020.126863
   Yu CP, 2018, URBAN FOR URBAN GREE, V35, P106, DOI 10.1016/j.ufug.2018.08.013
NR 160
TC 3
Z9 4
U1 2
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 1
PY 2022
VL 3
AR 788820
DI 10.3389/frvir.2022.788820
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PJ2
UT WOS:001021726700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Vayssiere, P
   Constanthin, PE
   Baticam, NS
   Herbelin, B
   Degremont, C
   Blanke, O
   Schaller, K
   Bijlenga, P
AF Vayssiere, Pia
   Constanthin, Paul E.
   Baticam, Nalla Silva
   Herbelin, Bruno
   Degremont, Christine
   Blanke, Olaf
   Schaller, Karl
   Bijlenga, Philippe
TI Use of Virtual Reality to Improve the Quality of the Hospital Stay for
   Patients in Neurosurgery
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; satisfaction; pain improvement; patients' selection;
   neurosurgery
ID PAIN-CONTROL; NECK PAIN; ANXIETY; MANAGEMENT; DISTRACTION; FEEDBACK;
   THERAPY
AB Background: Virtual Reality (VR) technologies have numerous beneficial applications for patients during hospitalization (through complete immersion in a virtual, distant place allowing to "escape" from the context of hospitalization). Their positive effects in pain and anxiety management, neurorehabilitation and psychotherapy have been demonstrated. Here, we evaluated the effects of VR on the quality of hospitalization and postoperative pain after neurosurgery.Methods: Patients hospitalized in our department between 2019 and 2020 were prospectively enrolled and divided into a group that received a personal, 30-minutes-long, VR session using an Oculus Go & TRADE; VR headset (VR group) or not (non-VR group). Surgeries were classified in simple or complex spinal and simple or complex cranial. Patient's overall satisfaction was considered as primary outcome, with secondary outcomes encompassing duration of hospitalization, pain reduction and patients' opinion regarding VR.Results: 161 patients were enrolled (77 in the VR group and 84 in the non-VR group). There was no statistical difference between the two groups regarding satisfaction. The VR group presented with a significantly longer duration of hospitalization and higher maximal pain. Interestingly, pain reduction during hospitalization was significantly higher in the VR group, particularly in simple surgeries and spine surgeries. A vast majority of the VR group patients appreciated their VR experience (89.2%) and advocated for its systematic use (83.8%).Conclusion: VR can improve pain reduction during hospitalization after neurosurgery, particularly for simple spine surgeries. Furthermore, patients experiencing VR appear to appreciate it and advocate for its systematic use in neurosurgery. Further research is warranted to identify patients for whom addition of VR during hospitalization might bring the most benefit.
C1 [Vayssiere, Pia; Constanthin, Paul E.; Baticam, Nalla Silva; Degremont, Christine; Schaller, Karl; Bijlenga, Philippe] Hop Univ Geneve HUG, Dept Neurosurg, Geneva, Switzerland.
   [Vayssiere, Pia; Schaller, Karl; Bijlenga, Philippe] Univ Geneve UNIGE, Fac Med, Geneva, Switzerland.
   [Herbelin, Bruno; Blanke, Olaf] Ecole Polytech Fed Lausanne EPFL, Ctr Neuroprosthet, Lab Cognit Neurosci, Geneva, Switzerland.
   [Herbelin, Bruno; Blanke, Olaf] Ecole Polytech Fed Lausanne EPFL, Brain Mind Inst, Geneva, Switzerland.
C3 University of Geneva; University of Geneva; Swiss Federal Institutes of
   Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss
   Federal Institutes of Technology Domain; Ecole Polytechnique Federale de
   Lausanne
RP Vayssiere, P (corresponding author), Hop Univ Geneve HUG, Dept Neurosurg, Geneva, Switzerland.; Vayssiere, P (corresponding author), Univ Geneve UNIGE, Fac Med, Geneva, Switzerland.
EM pia.vayssiere@hcuge.ch
FU neurosurgical department of University Hospitals of Geneva
FX This research was funded by funds of the neurosurgical department of
   University Hospitals of Geneva dedicated to research.
CR Ahern MM, 2020, PAIN PRACT, V20, P656, DOI 10.1111/papr.12885
   [Anonymous], 1976, J Clin Ultrasound, V4, P378
   Arning K., 2006, WHAT OLDER USERS EXP
   Bailey Laila, 2010, AORN J, V92, P445, DOI 10.1016/j.aorn.2010.04.017
   Carrougher GJ, 2009, J BURN CARE RES, V30, P785, DOI 10.1097/BCR.0b013e3181b485d3
   Chen KB, 2017, IEEE T NEUR SYS REH, V25, P1240, DOI 10.1109/TNSRE.2016.2621886
   Chua SL, 1999, COMPUT HUM BEHAV, V15, P609, DOI 10.1016/S0747-5632(99)00039-4
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Citrome L, 2014, INT J CLIN PRACT, V68, P931, DOI 10.1111/ijcp.12496
   Coulter ID, 2018, SPINE J, V18, P866, DOI 10.1016/j.spinee.2018.01.013
   Fugate Jennifer E, 2015, Continuum (Minneap Minn), V21, P1425, DOI 10.1212/CON.0000000000000227
   Furman E, 2009, J AM DENT ASSOC, V140, P1508, DOI 10.14219/jada.archive.2009.0102
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gold JI, 2006, CYBERPSYCHOL BEHAV, V9, P207, DOI 10.1089/cpb.2006.9.207
   Helfand M, 2009, PAIN MED, V10, P1183, DOI 10.1111/j.1526-4637.2009.00718.x
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Hoffman HG, 2008, CLIN J PAIN, V24, P299, DOI 10.1097/AJP.0b013e318164d2cc
   Hu HT, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011225
   Karanci AN, 2003, J PSYCHOSOM RES, V55, P363, DOI 10.1016/S0022-3999(02)00631-1
   Kiecolt-Glaser JK, 1998, AM PSYCHOL, V53, P1209, DOI 10.1037/0003-066X.53.11.1209
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Moon JS, 2001, J ADV NURS, V35, P407, DOI 10.1046/j.1365-2648.2001.01855.x
   Morris LD, 2010, BURNS, V36, P659, DOI 10.1016/j.burns.2009.09.005
   Ni CH, 2012, J CLIN NURS, V21, P620, DOI 10.1111/j.1365-2702.2010.03466.x
   Okifuji A, 2007, MED CLIN N AM, V91, P45, DOI 10.1016/j.mcna.2006.10.008
   Pozeg P, 2017, NEUROLOGY, V89, P1894, DOI 10.1212/WNL.0000000000004585
   Pritchard Michael John, 2009, Nurs Stand, V23, P35, DOI 10.7748/ns.23.51.35.s46
   Sarig-Bahat H, 2010, SPINE, V35, pE105, DOI 10.1097/BRS.0b013e3181b79358
   Sato K, 2010, PAIN MED, V11, P622, DOI 10.1111/j.1526-4637.2010.00819.x
   Solcà M, 2018, NEUROLOGY, V91, pE479, DOI 10.1212/WNL.0000000000005905
   Turk DC, 2011, LANCET, V377, P2226, DOI 10.1016/S0140-6736(11)60402-9
   Vadivelu N, 2016, J PAIN RES, V9, P37, DOI 10.2147/JPR.S85782
   Volkow ND, 2021, MOL PSYCHIATR, V26, P218, DOI 10.1038/s41380-020-0661-4
   Ziefle K. Aa. M., 2012, ASK YOU WILL RECEIVE
   ZMUD RW, 1979, MANAGE SCI, V25, P966, DOI 10.1287/mnsc.25.10.966
NR 38
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 6
PY 2021
VL 2
AR 736122
DI 10.3389/frvir.2021.736122
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TV4
UT WOS:001021843700001
OA gold
DA 2024-07-18
ER

PT J
AU Kisker, J
   Lange, L
   Flinkenflügel, K
   Kaup, M
   Labersweiler, N
   Tetenborg, F
   Ott, P
   Gundler, C
   Gruber, T
   Osinsky, R
   Schöne, B
AF Kisker, Joanna
   Lange, Leon
   Flinkenfluegel, Kira
   Kaup, Michael
   Labersweiler, Nils
   Tetenborg, Falk
   Ott, Paula
   Gundler, Christopher
   Gruber, Thomas
   Osinsky, Roman
   Schoene, Benjamin
TI Authentic Fear Responses in Virtual Reality: A Mobile EEG Study on
   Affective, Behavioral and Electrophysiological Correlates of Fear
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE authentic fear; virtual reality; mixed reality; mobile EEG; frontal
   alpha asymmetry; fear behavior
ID REINFORCEMENT SENSITIVITY THEORY; DISGUST SENSITIVITY; EMOTION
   REGULATION; AVOIDANCE; ACTIVATION; INHIBITION; ENVIRONMENTS;
   ASYMMETRIES; ANXIETY; STARTLE
AB Fear is an evolutionary adaption to a hazardous environment, linked to numerous complex behavioral responses, e.g., the fight-or-flight response, suiting their respective environment. However, for the sake of experimental control, fear is mainly investigated under rather artificial laboratory conditions. The latter transform these evolutionary adaptions into artificial responses, like keystrokes. The immersive, multidimensional character of virtual reality (VR) enables realistic behavioral responses, overcoming aforementioned limitations. To investigate authentic fear responses from a holistic perspective, participants explored either a negative or a neutral VR cave. To promote real-life behavior, we built a physical replica of the cave, providing haptic sensations. Electrophysiological correlates of fear-related approach and avoidance tendencies, i.e., frontal alpha asymmetries (FAA) were evaluated. To our knowledge, this is the first study to simultaneously capture complex behavior and associated electrophysiological correlates under highly immersive conditions. Participants in the negative condition exhibited a broad spectrum of realistic fear behavior and reported intense negative affect as opposed to participants in the neutral condition. Despite these affective and behavioral differences, the groups could not be distinguished based on the FAAs for the greater part of the cave exploration. Taking the specific behavioral responses into account, the obtained FAAs could not be reconciled with well-known FAA models. Consequently, putting laboratory-based models to the test under realistic conditions shows that they may not unrestrictedly predict realistic behavior. As the VR environment facilitated nonmediated and realistic emotional and behavioral responses, our results demonstrate VR's high potential to increase the ecological validity of scientific findings (video abstract: https://www.youtube.com/watch?v=qROsPOp87l4&feature=youtu.be).
C1 [Kisker, Joanna; Gruber, Thomas; Schoene, Benjamin] Osnabruck Univ, Inst Psychol, Expt Psychol 1, Osnabruck, Germany.
   [Lange, Leon; Osinsky, Roman] Osnabruck Univ, Inst Psychol, Differential Psychol & Personal Res, Osnabruck, Germany.
   [Flinkenfluegel, Kira; Kaup, Michael; Labersweiler, Nils; Tetenborg, Falk; Ott, Paula] Osnabruck Univ, Inst Psychol, Osnabruck, Germany.
   [Gundler, Christopher] Osnabruck Univ, Inst Cognit Sci, Osnabruck, Germany.
C3 University Osnabruck; University Osnabruck; University Osnabruck;
   University Osnabruck
RP Kisker, J (corresponding author), Osnabruck Univ, Inst Psychol, Expt Psychol 1, Osnabruck, Germany.
EM joanna.kisker@uni-osnabrueck.de
RI Schöne, Benjamin/GXW-1484-2022
OI Schöne, Benjamin/0000-0001-7926-7426; Kisker,
   Joanna/0000-0002-5826-264X; Lange, Leon/0000-0002-6215-6815; Gundler,
   Christopher/0000-0001-9301-8872; Osinsky, Roman/0000-0002-4282-4281
FU Deutsche Forschungsgemeinschaft (DFG); Open Access Publishing Fund of
   Osnabruck University
FX & nbsp;We acknowledge support by Deutsche Forschungsgemeinschaft (DFG)
   and Open Access Publishing Fund of Osnabruck University.
CR Adolphs R, 2013, CURR BIOL, V23, pR79, DOI 10.1016/j.cub.2012.11.055
   Asjad N. S., 2018, P SAP 2018 ACM S APP, VAugust, DOI [10.1145/3225153.3225171, DOI 10.1145/3225153.3225171]
   Bamford S, 2015, BIOL PSYCHOL, V105, P115, DOI 10.1016/j.biopsycho.2015.01.009
   Bastiaansen M., 2011, Oxford Handbook of Event-Related Potential Components, P31
   Berking M, 2008, Z PSYCHIATR PSYCH PS, V56, P141, DOI 10.1024/1661-4747.56.2.141
   BERNSTEIN DA, 1973, J CONSULT CLIN PSYCH, V41, P165, DOI 10.1037/h0035170
   Biedermann SV, 2017, BMC BIOL, V15, DOI 10.1186/s12915-017-0463-6
   BLANCHAR.RJ, 1969, J COMP PHYSIOL PSYCH, V68, P129, DOI 10.1037/h0027676
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Bouchard Stephane, 2006, Technol Health Care, V14, P19
   Brouwer A., 2011, Journal of Cybertherapy and Rehabilitation, V4, P27
   BROWN JS, 1951, J EXP PSYCHOL, V41, P317, DOI 10.1037/h0060166
   Cabeza R, 2007, TRENDS COGN SCI, V11, P219, DOI 10.1016/j.tics.2007.02.005
   Cannon W. B., 1929, BODILY CHANGES PAIN, P360
   Carboni A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07249-x
   Carretié L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037082
   CARVER CS, 1994, J PERS SOC PSYCHOL, V67, P319, DOI 10.1037/0022-3514.67.2.319
   Castaldo R, 2015, BIOMED SIGNAL PROCES, V18, P370, DOI 10.1016/j.bspc.2015.02.012
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Cisler JM, 2010, J PSYCHOPATHOL BEHAV, V32, P68, DOI 10.1007/s10862-009-9161-1
   Coan JA, 2006, BIOL PSYCHOL, V72, P198, DOI 10.1016/j.biopsycho.2005.10.003
   Coelho CM, 2009, J ANXIETY DISORD, V23, P563, DOI 10.1016/j.janxdis.2009.01.014
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   Corr PJ, 2016, PSYCHOL ASSESSMENT, V28, P1427, DOI 10.1037/pas0000273
   Dan A, 2017, INT J PSYCHOPHYSIOL, V122, P75, DOI 10.1016/j.ijpsycho.2016.08.013
   DAVIDSON RJ, 1990, J PERS SOC PSYCHOL, V58, P330, DOI 10.1037/0022-3514.58.2.330
   Davidson RJ, 1998, PSYCHOPHYSIOLOGY, V35, P607, DOI 10.1017/S0048577298000134
   de la Rosa S, 2018, BRIT J PSYCHOL, V109, P427, DOI 10.1111/bjop.12302
   Deacon B, 2007, BEHAV RES THER, V45, P2110, DOI 10.1016/j.brat.2007.03.008
   Debener S, 2012, PSYCHOPHYSIOLOGY, V49, P1617, DOI 10.1111/j.1469-8986.2012.01471.x
   Debiec J, 2004, SOC RES, V71, P807
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dibbets P, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00681
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Diniz BernardoP., 2020, Journal of Technology in Behavioral Science, V6, P3, DOI [10.1007/s41347-020-00152-9, DOI 10.1007/S41347-020-00152-9]
   FANSELOW MS, 1994, PSYCHON B REV, V1, P429, DOI 10.3758/BF03210947
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Gable P, 2008, PSYCHOPHYSIOLOGY, V45, P275, DOI 10.1111/j.1469-8986.2007.00627.x
   Gorini A, 2010, ANN GEN PSYCHIATR, V9, DOI 10.1186/1744-859X-9-30
   GRAY JA, 1982, BEHAV BRAIN SCI, V5, P469, DOI 10.1017/S0140525X00013066
   Grillon C, 2001, PSYCHOPHYSIOLOGY, V38, P807, DOI 10.1111/1469-8986.3850807
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Gromer D, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00372
   Harmon-Jones E, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.12879
   Harmon-Jones E, 2010, BIOL PSYCHOL, V84, P451, DOI 10.1016/j.biopsycho.2009.08.010
   Hermann A, 2009, SOC COGN AFFECT NEUR, V4, P257, DOI 10.1093/scan/nsp013
   Hertweck S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P970, DOI [10.1109/VR.2019.8798369, 10.1109/vr.2019.8798369]
   Heuer K, 2007, BEHAV RES THER, V45, P2990, DOI 10.1016/j.brat.2007.08.010
   Hofmann W, 2009, SOC PSYCHOL-GERMANY, V40, P73, DOI 10.1027/1864-9335.40.2.73
   Jarius S, 2015, J NEUROL, V262, P2177, DOI 10.1007/s00415-015-7858-5
   Kisker J, 2021, PSYCHOL RES-PSYCH FO, V85, P2485, DOI 10.1007/s00426-020-01417-x
   Kisker J, 2021, CURR PSYCHOL, V40, P3190, DOI 10.1007/s12144-019-00257-2
   Kisker J, 2021, PSYCHOL RES-PSYCH FO, V85, P68, DOI 10.1007/s00426-019-01244-9
   Koch MD, 2002, J ANXIETY DISORD, V16, P511, DOI 10.1016/S0887-6185(02)00170-6
   Krieglmeyer R, 2010, COGNITION EMOTION, V24, P810, DOI 10.1080/02699930903047298
   Krohne HW, 1996, DIAGNOSTICA, V42, P139
   Kvavilashvili L, 2004, History and Philosophy of Psychology, V6, P59
   Lacey MF, 2020, INT J PSYCHOPHYSIOL, V147, P18, DOI 10.1016/j.ijpsycho.2019.09.013
   Lange L, 2021, EUR J NEUROSCI, V54, P8214, DOI 10.1111/ejn.14977
   Lanius RA, 2010, EUR J PSYCHOTRAUMATO, V1, DOI 10.3402/ejpt.v1i0.5467
   Laux L., 1981, Das State-Trait-Angstinventar. Theoretische Grundlagen und Handanweisung
   LeDoux J, 1998, BIOL PSYCHIAT, V44, P1229, DOI 10.1016/S0006-3223(98)00282-0
   LeDoux J. E., 1996, EMOTIONAL BRAIN SIMO
   LEDOUX JE, 1995, ANNU REV PSYCHOL, V46, P209, DOI 10.1146/annurev.ps.46.020195.001233
   LeDoux JE, 2014, P NATL ACAD SCI USA, V111, P2871, DOI 10.1073/pnas.1400335111
   Leibetseder M, 2007, PERS INDIV DIFFER, V42, P547, DOI 10.1016/j.paid.2006.08.002
   Lin J. H. T., 2020, INT ENCY MEDIA PSYCH, V9, P1, DOI 10.1002/9781119011071.iemp0286
   Lin JHT, 2018, NEW MEDIA SOC, V20, P3223, DOI 10.1177/1461444817744850
   Lin JHT, 2017, COMPUT HUM BEHAV, V72, P350, DOI 10.1016/j.chb.2017.02.057
   Higuera-Trujillo JL, 2017, APPL ERGON, V65, P398, DOI 10.1016/j.apergo.2017.05.006
   Lynch T, 2015, J BROADCAST ELECTRON, V59, P298, DOI 10.1080/08838151.2015.1029128
   Madsen KE, 2016, COMPUT HUM BEHAV, V56, P142, DOI 10.1016/j.chb.2015.11.041
   Makeig S, 2009, INT J PSYCHOPHYSIOL, V73, P95, DOI 10.1016/j.ijpsycho.2008.11.008
   McLean CP, 2009, CLIN PSYCHOL REV, V29, P496, DOI 10.1016/j.cpr.2009.05.003
   Nathan K, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00708
   Nolan H, 2010, J NEUROSCI METH, V192, P152, DOI 10.1016/j.jneumeth.2010.07.015
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Parsons TD, 2019, ETHICAL CHALLENGES IN DIGITAL PSYCHOLOGY AND CYBERPSYCHOLOGY, P1, DOI 10.1017/9781108553384
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Parsons TD, 2013, J CLIN EXP NEUROPSYC, V35, P812, DOI 10.1080/13803395.2013.824556
   Phosphor Games, 2016, BROOKH EXP VR GAM PR
   Pugnaghi G, 2018, J INDIVID DIFFER, V39, P182, DOI 10.1027/1614-0001/a000262
   Ragan ED, 2010, PRESENCE-TELEOP VIRT, V19, P527, DOI 10.1162/pres_a_00016
   Rauschnabel P. A., 2020, IMPACT VIRTUAL EMBOD, DOI [10.1007/978-3-030-37869-1, DOI 10.1007/978-3-030-37869-1_17]
   Rinck M, 2007, J BEHAV THER EXP PSY, V38, P105, DOI 10.1016/j.jbtep.2006.10.001
   Rinck M, 2010, COGNITION EMOTION, V24, P1199, DOI 10.1080/02699930903135945
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Rodrigues J, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.12908
   Schöne B, 2023, CURR PSYCHOL, V42, P5366, DOI 10.1007/s12144-021-01841-1
   Schöne B, 2021, VIRTUAL REAL-LONDON, V25, P209, DOI 10.1007/s10055-020-00450-w
   Schöne B, 2019, CURR PSYCHOL, V38, P715, DOI 10.1007/s12144-017-9648-y
   Schöne B, 2016, EXP BRAIN RES, V234, P559, DOI 10.1007/s00221-015-4483-6
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith EE, 2017, INT J PSYCHOPHYSIOL, V111, P98, DOI 10.1016/j.ijpsycho.2016.11.005
   Smith SA, 2019, PSYCHON B REV, V26, P1213, DOI 10.3758/s13423-019-01605-w
   Strobel A., 2001, Zeitschrift Fur Differentielle Und Diagnostische Psychologie, V22, P216, DOI [DOI 10.1024//0170-1789.22.3.216, 10.1024//0170-1789.22.3.216]
   Teatero M. L., 2015, FIGHT OR FLIGHT RESP, P179
   Tobacyk J.J., 2004, INT J TRANSPERSONAL, V23, P94, DOI [10.1037/t14015-000, DOI 10.24972/IJTS.2004.23.1.94, http://dx.doi.org/10.24972/ijts.2004.23.1.94]
   Wacker J, 2008, EMOTION, V8, P232, DOI 10.1037/1528-3542.8.2.232
   Wacker J, 2003, EMOTION, V3, P167, DOI 10.1037/1528-3542.3.2.167
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Williams LA, 2008, J PERS SOC PSYCHOL, V94, P1007, DOI 10.1037/0022-3514.94.6.1007
   Zuckerman M, 1996, PERS INDIV DIFFER, V20, P515, DOI 10.1016/0191-8869(95)00195-6
NR 111
TC 14
Z9 14
U1 3
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 16
PY 2021
VL 2
AR 716318
DI 10.3389/frvir.2021.716318
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RZ8
UT WOS:001023167800001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Price, S
   Jewitt, C
   Chubinidze, D
   Barker, N
   Yiannoutsou, N
AF Price, Sara
   Jewitt, Carey
   Chubinidze, Dimitri
   Barker, Ned
   Yiannoutsou, Nikoleta
TI Taking an Extended Embodied Perspective of Touch:
   Connection-Disconnection in iVR
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE touch; virtual reality; embodied; connection; presence
ID VIRTUAL ENVIRONMENTS; ETHNOGRAPHY; EXPERIENCES; HAPTICS; SENSE; FEEL
AB Bringing touch into VR experiences through haptics is considered increasingly important for user engagement and fostering feelings of presence and immersion, yet few qualitative studies have explored users' iVR touch experiences. This paper takes an embodied approach-bringing attention to the tactile-kinaesthetic body-to explore users' wholistic experiences of touch in iVR, moving beyond the cutaneous and tactile elements of "feeling" to elaborate upon themes of movement and kinetics. Our findings show how both touch connections and disconnections emerged though material forms of tactility (the controller, body positioning, tactile expectations) and through "felt proximities" and the tactile-kinaesthetic experience thus shaping the sense of presence. The analysis shows three key factors that influence connection and disconnection, and how connection is re-navigated or sought at moments of experienced disconnection: a sense of control or agency; identity; and bridging between the material and virtual. This extended notion of touch deepens our understanding of its role in feelings of presence by providing insight into a range of factors related to notions of touch - both physical and virtual-that come into play in creating a sense of connection or presence (e.g., histories, expectations), and highlights the potential for iVR interaction to attend to the body beyond the hands in terms of touch.
C1 [Price, Sara; Jewitt, Carey; Barker, Ned; Yiannoutsou, Nikoleta] UCL, Univ Coll London Knowledge Lab, Inst Educ, London, England.
   [Chubinidze, Dimitri] Ivane Javakhishvili Tbilisi State Univ, Psychol Dept, Tbilisi, Georgia.
C3 University of London; University College London; UCL Institute of
   Education; Ivane Javakhishvili Tbilisi State University
RP Price, S (corresponding author), UCL, Univ Coll London Knowledge Lab, Inst Educ, London, England.
EM sara.price@ucl.ac.uk
OI Barker, Edmund/0000-0001-6969-4547; Jewitt, Carey/0000-0002-2971-984X;
   Price, Sara/0000-0002-5092-1663; Chubinidze, Dimitri/0000-0003-3253-8991
FU InTouch project, a European Research Council Consolidator Award [681489]
FX & nbsp;This research was undertaken as a part of the InTouch project, a
   European Research Council Consolidator Award (Award Number: 681489).
CR [Anonymous], 2000, PRES 2000 3 INT WORK
   Bailenson JN, 2008, MULTIMED TOOLS APPL, V37, P5, DOI 10.1007/s11042-007-0171-2
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Candy B., 2019, KEEPING VIRTUAL REAL
   Chatterjee H, 2013, MUSEUMS, HEALTH AND WELL-BEING, P1
   Cranny-Francis A, 2009, SENSES SOC, V4, P163, DOI 10.2752/174589309X425111
   CSORDAS TJ, 1990, ETHOS, V18, P5, DOI 10.1525/eth.1990.18.1.02a00010
   Dourish P., 2001, ACTION IS FDN EMBODI
   Farmer H, 2012, CONSCIOUS COGN, V21, P1242, DOI 10.1016/j.concog.2012.04.011
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gallace A., 2014, In touch with the future: The sense of touch from cognitive neuroscience to virtual reality
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Gregersen Andreas., 2009, VIDEO GAME THEORY RE
   Hollett T, 2020, E-LEARNING DIGITAL M, V17, P56, DOI 10.1177/2042753019876043
   Jewitt C, 2021, DISCOURSE CONTEXT ME, V41, DOI 10.1016/j.dcm.2021.100483
   Jewitt C, 2019, SENSES SOC, V14, P221, DOI 10.1080/17458927.2019.1619316
   Jewitt C, 2019, QUAL RES, V19, P90, DOI 10.1177/1468794118796992
   Jewitt Carey, 2017, Advancing multimodal and critical discourse studies: Interdisciplinary research, P79
   Jewitt Carey., 2020, INTERDISCIPLINARY IN, DOI [10.1007/978-3-030-24564-1, DOI 10.1007/978-3-030-24564-1]
   Kaneko S, 2018, LECT NOTES COMPUT SC, V10893, P49, DOI 10.1007/978-3-319-93445-7_5
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim G, 2018, LECT NOTES COMPUT SC, V10910, P94, DOI 10.1007/978-3-319-91584-5_8
   KOZEL S, 1994, DANCE THEAT J, V11, P12
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Mackley KL, 2013, SENSES SOC, V8, P335, DOI 10.2752/174589313X13712175020596
   Marsh T, 2003, EMERG COMMUNICAT, V5, P85
   Merleau-Ponty, 2012, Phenomenology of Perception, DOI DOI 10.4324/9780203720714
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Parisi D., 2018, FINGERBOMBING TOUCHI
   Parisi D., 2020, EXPANDING UNIVERSE H
   Parisi D, 2014, ANIMATION, V9, P228, DOI 10.1177/1746847714527195
   Paterson M, 2006, ENVIRON PLANN D, V24, P691, DOI 10.1068/d394t
   Paterson M, 2009, PROG HUM GEOG, V33, P766, DOI 10.1177/0309132509103155
   Perez-Marcos D, 2012, COGN NEURODYNAMICS, V6, P295, DOI 10.1007/s11571-011-9178-5
   Price S, 2021, VIRTUAL REAL-LONDON, V25, P863, DOI 10.1007/s10055-020-00494-y
   Ramsamy P, 2006, LECT NOTES COMPUT SC, V3992, P603, DOI 10.1007/11758525_81
   Sheets-Johnstone M., 2018, SURPRISE EMOTION, P83, DOI [10.1007/978-3-319-98657-9_5, DOI 10.1007/978-3-319-98657-9_5]
   Sheets-Johnstone M, 1999, The primacy of movement
   Sheets-Johnstone Maxine., 1992, Giving the Body Its Due
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Stone B., HAPTICS VR AR ARE WE
   The Hold the World, 2018, HOLD WORLD
NR 44
TC 5
Z9 5
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 30
PY 2021
VL 2
AR 642782
DI 10.3389/frvir.2021.642782
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XH1
UT WOS:001023305700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Doggett, R
   Sander, EJ
   Birt, J
   Ottley, M
   Baumann, O
AF Doggett, Rachel
   Sander, Elizabeth J.
   Birt, James
   Ottley, Matthew
   Baumann, Oliver
TI Using Virtual Reality to Evaluate the Impact of Room Acoustics on
   Cognitive Performance and Well-Being
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; acoustics; psychoacoustics; cognitive performance;
   well-being; heartrate; working memory; noise
ID HEART-RATE-VARIABILITY; CLASSROOM ACOUSTICS; WORKING-MEMORY;
   REVERBERATION TIME; BACKGROUND SPEECH; NEGATIVE AFFECT; ENVIRONMENTS;
   METAANALYSIS; NOISE; DISTRACTION
AB Irrelevant ambient noise can have profound effects on human performance and wellbeing. Acoustic interventions (e.g., installation of sound absorbing materials) that reduce intelligible noise (i.e., sound unrelated to the relevant speech, including noise from other talkers within the space) by reducing room reverberation, have been found to be an effective means to alleviate the negative effects of noise on cognitive performance. However, these interventions are expensive, and it is difficult to evaluate their impact in the field. Virtual reality (VR) provides a promising simulation platform to evaluate the likely impact of varied acoustic interventions before they are chosen and installed. This study employed a virtual classroom environment to evaluate whether an intervention to reduce reverberation can be simulated successfully in VR and mitigate the effects of ambient noise on cognitive performance, physiological stress, and mood. The repeated-measures experimental design consisted of three acoustic conditions: no ambient noise, typical open-plan classroom ambient noise without acoustic treatment, and the same ambient noise with acoustic treatment to reduce reverberation. Results revealed that ambient noise negatively affected participants' cognitive performance but had no measurable effect on physiological stress or self-reported mood. Importantly, the negative effect of ambient noise was completely ameliorated by the acoustic treatment (i.e. indistinguishable from performance in the no noise condition). The study shows that VR provides an effective and efficient means to evaluate the cognitive effects of acoustic interventions.
C1 [Doggett, Rachel; Birt, James; Baumann, Oliver] Bond Univ, Fac Soc & Design, Gold Coast, Qld, Australia.
   [Sander, Elizabeth J.] Bond Univ, Business Sch, Gold Coast, Qld, Australia.
   [Ottley, Matthew] Marshall Day Acoust, Sydney, Vic, Australia.
C3 Bond University; Bond University
RP Baumann, O (corresponding author), Bond Univ, Fac Soc & Design, Gold Coast, Qld, Australia.
EM obaumann@bond.edu.au
RI Birt, James Richard/ABD-6953-2021; Baumann, Oliver/C-8296-2009
OI Birt, James Richard/0000-0002-0422-4867; Sander, Elizabeth
   (Libby)/0000-0002-3171-0529; Baumann, Oliver/0000-0003-3976-5855
CR Astolfi A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02736
   Ballou G., 2013, Handbook for sound engineers
   Beaman CP, 2007, APPL COGNITIVE PSYCH, V21, P1077, DOI 10.1002/acp.1315
   Begault D.R., 2000, 3 D SOUND VIRTUAL RE
   Berglund B., 1995, ACHIEVES CTR SENSORY, V2, P1
   Birenboim A, 2019, PROF GEOGR, V71, P449, DOI 10.1080/00330124.2018.1547978
   Braat-Eggen E, 2019, APPL ACOUST, V154, P148, DOI 10.1016/j.apacoust.2019.04.038
   Bradley JS, 1999, APPL ACOUST, V58, P99, DOI 10.1016/S0003-682X(98)00075-9
   Brinkmann F, 2019, J ACOUST SOC AM, V145, P2746, DOI 10.1121/1.5096178
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Clark C, 2012, NOISE HEALTH, V14, P292, DOI 10.4103/1463-1741.104896
   Di Blasio S, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16020280
   Dockrell JE, 2006, BRIT EDUC RES J, V32, P509, DOI 10.1080/01411920600635494
   Fontanella L, 2012, METRIKA, V75, P287, DOI 10.1007/s00184-010-0327-3
   Heinzel S, 2014, J NEUROSCI, V34, P1224, DOI 10.1523/JNEUROSCI.2463-13.2014
   Imran M., 2019, P DAGA 2019 45 JAHRE, P18
   Ising H, 2004, Noise Health, V6, P5
   Jaeggi SM, 2010, MEMORY, V18, P394, DOI 10.1080/09658211003702171
   Kim HG, 2018, PSYCHIAT INVEST, V15, P235, DOI 10.30773/pi.2017.08.17
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Klatte M, 2010, ENVIRON BEHAV, V42, P659, DOI 10.1177/0013916509336813
   Kuschpel MS, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01683
   Leue A, 2011, ASSESSMENT, V18, P487, DOI 10.1177/1073191110374917
   Ljung R, 2009, BUILD ACOUST, V16, P301, DOI 10.1260/135101009790291273
   Meule A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00352
   Monk AF, 2011, BEHAV RES METHODS, V43, P888, DOI 10.3758/s13428-011-0074-z
   Muhammad I, 2019, J ACOUST SOC AM, V146, pEL310, DOI 10.1121/1.5126598
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Prodi N, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02166
   Rantala LM, 2015, BUILD ACOUST, V22, P243, DOI 10.1260/1351-010X.22.3-4.243
   Reeves JP, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01840
   Reinten J, 2017, BUILD ENVIRON, V123, P315, DOI 10.1016/j.buildenv.2017.07.005
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Scannell L, 2016, ENVIRON BEHAV, V48, P769, DOI 10.1177/0013916514567127
   Schlittmeier SJ, 2008, ERGONOMICS, V51, P719, DOI 10.1080/00140130701745925
   Seddigh A, 2014, J ENVIRON PSYCHOL, V38, P167, DOI 10.1016/j.jenvp.2014.01.009
   Serafin S, 2018, IEEE COMPUT GRAPH, V38, P31, DOI 10.1109/MCG.2018.193142628
   Solhjoo S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50280-3
   Stapelberg NJC, 2018, ANN NONINVAS ELECTRO, V23, DOI 10.1111/anec.12483
   Thayer JF, 2012, NEUROSCI BIOBEHAV R, V36, P747, DOI 10.1016/j.neubiorev.2011.11.009
   Tiesler G, 2015, ENRGY PROCED, V78, P3108, DOI 10.1016/j.egypro.2015.11.765
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Zhang X, 2017, PHYSIOL BEHAV, V174, P27, DOI 10.1016/j.physbeh.2017.02.043
   Zhang YX, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103311
   Ziemus B, 2007, NEUROPSYCHOLOGIA, V45, P2016, DOI 10.1016/j.neuropsychologia.2007.02.012
NR 45
TC 6
Z9 6
U1 3
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 12
PY 2021
VL 2
AR 620503
DI 10.3389/frvir.2021.620503
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AZ0
UT WOS:001019303900001
OA Green Published, gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Kuhne, C
   Kecelioglu, ED
   Maltby, S
   Hood, RJ
   Knott, B
   Ditton, E
   Walker, FR
   Kluge, MG
AF Kuhne, Caroline
   Kecelioglu, Eda D.
   Maltby, Steven
   Hood, Rebecca J.
   Knott, Brendon
   Ditton, Elizabeth
   Walker, Frederick Rohan
   Kluge, Murielle G.
TI Direct comparison of virtual reality and 2D delivery on sense of
   presence, emotional and physiological outcome measures
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; 2D comparison; sense of presence; physiological
   response; emotional responses; confrontational; relaxing
ID STRESS; RELAXATION; EXPERIENCE; IMMERSION; EDUCATION
AB Introduction: Virtual-reality (VR) technology has, over the last decade, quickly expanded from gaming into other sectors including training, education, and wellness. One of the most popular justifications for the use of VR over 2D is increased immersion and engagement. However, very little fundamental research has been produced evaluating the comparative impact of immersive VR on the user's cognitive, physiological, and emotional state. Methods: A within-subject cross-over study design was used to directly compare VR and 2D screen delivery of different subject matter content. Both physiological and self-report data were collected for scenes containing calming nature environments, aggressive social confrontations, and neutral content. Results: Compared to 2D, the VR delivery resulted in a higher sense of presence, higher ratings of engagement, fun, and privacy. Confrontational scenes were rated as more tense whilst calming scenes were rated as more relaxing when presented in VR compared to 2D. Physiological data indicated that the scenes promoted overall states of arousal and relaxation in accordance with the scene subject matter (both VR and 2D). However, heart rate (HR) and galvanic skin response (GSR) were consistently higher throughout the VR delivery condition compared to 2D, including responses during scenes of neutral and calming subject matter. Discussion: This discrepancy between emotional and physiological responses for calming and neutral content in VR suggest an elevated arousal response driven by VR immersion that is independent of the emotional and physiological responses to the subject matter itself. These findings have important implications for those looking to develop and utilize VR technology as a training and educational tool as they provide insights into the impact of immersion on the user.
C1 [Kuhne, Caroline; Kecelioglu, Eda D.; Maltby, Steven; Knott, Brendon; Ditton, Elizabeth; Walker, Frederick Rohan; Kluge, Murielle G.] Univ Newcastle, Coll Hlth Med & Wellbeing, Ctr Adv Training Syst, Callaghan, NSW, Australia.
   [Kuhne, Caroline; Kecelioglu, Eda D.; Maltby, Steven; Hood, Rebecca J.; Walker, Frederick Rohan; Kluge, Murielle G.] Univ Newcastle, Coll Hlth Med & Wellbeing, Sch Biomed Sci & Pharm, Callaghan, NSW, Australia.
   [Hood, Rebecca J.; Ditton, Elizabeth] Hunter Med Res Inst, New Lambton Hts, NSW, Australia.
   [Knott, Brendon] Contextual Intervent, Newcastle, NSW, Australia.
   [Ditton, Elizabeth] Univ Newcastle, Coll Hlth Med & Wellbeing, Sch Med & Publ Hlth, Callaghan, NSW, Australia.
C3 University of Newcastle; University of Newcastle; Hunter Medical
   Research Institute; University of Newcastle; University of Newcastle
RP Kluge, MG (corresponding author), Univ Newcastle, Coll Hlth Med & Wellbeing, Ctr Adv Training Syst, Callaghan, NSW, Australia.; Kluge, MG (corresponding author), Univ Newcastle, Coll Hlth Med & Wellbeing, Sch Biomed Sci & Pharm, Callaghan, NSW, Australia.
EM Murielle.kluge@newcastle.edu.au
RI Kluge, Murielle/JXY-1319-2024; Maltby, Steven/JRZ-1654-2023
OI Kuhne, Caroline/0000-0002-5391-2316
FU We would like to acknowledge the software developers at JumpGate for
   creating a mp4 video file of existing VR content that was used in the
   study.
FX We would like to acknowledge the software developers at JumpGate for
   creating a mp4 video file of existing VR content that was used in the
   study.
CR Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Antley A, 2011, IEEE T VIS COMPUT GR, V17, P255, DOI 10.1109/TVCG.2010.26
   Arpaia P, 2022, MINDFULNESS, V13, P556, DOI 10.1007/s12671-021-01783-6
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Barrett RCA, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0275119
   BENSON H, 1983, TRENDS NEUROSCI, V6, P281, DOI 10.1016/0166-2236(83)90120-0
   Berkman M.I., 2019, ENCY COMPUTER GRAPHI, P1, DOI DOI 10.1007/978-3-319-08234-9_162-1
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Cadet LB, 2020, INT J HUM-COMPUT ST, V144, DOI 10.1016/j.ijhcs.2020.102506
   Cao RC, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P729, DOI 10.1109/VR50410.2021.00100
   Cho BH, 2002, CYBERPSYCHOL BEHAV, V5, P129, DOI 10.1089/109493102753770516
   Dawson ME., 2017, Handbook of Psychophysiology, V4, P217, DOI [DOI 10.1017/9781107415782, 10.1017/9781107415782.010]
   de Kort YAW, 2006, J ENVIRON PSYCHOL, V26, P309, DOI 10.1016/j.jenvp.2006.09.001
   Dickinson P, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445401
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Eghbali P, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3365647
   EYSENCK MW, 1976, PSYCHOL BULL, V83, P389, DOI 10.1037/0033-2909.83.3.389
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Frost S, 2022, J ENVIRON PSYCHOL, V80, DOI 10.1016/j.jenvp.2022.101765
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Hejtmánek L, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.1033708
   Houzangbe S, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.958223
   Huang W, 2021, J COMPUT ASSIST LEAR, V37, P745, DOI 10.1111/jcal.12520
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Johnson D, 2020, VIRTUAL REAL-LONDON, V24, P303, DOI 10.1007/s10055-019-00388-8
   Kim G, 2018, LECT NOTES COMPUT SC, V10910, P94, DOI 10.1007/978-3-319-91584-5_8
   Kluge MG, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245068
   Knaust T, 2022, VIRTUAL REAL-LONDON, V26, P925, DOI 10.1007/s10055-021-00595-2
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Lemmens JS, 2022, VIRTUAL REAL-LONDON, V26, P223, DOI 10.1007/s10055-021-00555-w
   Liu Q, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.573673
   Chávez OL, 2020, INT J MED INFORM, V141, DOI 10.1016/j.ijmedinf.2020.104226
   Lorenz M, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0283565
   Ma JN, 2023, EXPLORE-NY, V19, P310, DOI 10.1016/j.explore.2022.08.001
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Malmberg J, 2022, METACOGN LEARN, V17, P793, DOI 10.1007/s11409-022-09320-z
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Maples-Keller JL, 2017, NEUROTHERAPEUTICS, V14, P554, DOI 10.1007/s13311-017-0534-y
   Masaoka Y, 1997, INT J PSYCHOPHYSIOL, V27, P153, DOI 10.1016/S0167-8760(97)00052-4
   Notzon S, 2015, BIOL PSYCHOL, V112, P66, DOI 10.1016/j.biopsycho.2015.10.003
   Ochadleus C, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1096283
   Park SA, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14091087
   Pascoe MC, 2017, J PSYCHIATR RES, V95, P156, DOI 10.1016/j.jpsychires.2017.08.004
   Richards D, 2015, COMPUT EDUC, V86, P157, DOI 10.1016/j.compedu.2015.03.009
   Riches S, 2021, SOC PSYCH PSYCH EPID, V56, P1707, DOI 10.1007/s00127-021-02110-z
   Rizzo A, 2014, COMPUTER, V47, P31, DOI 10.1109/MC.2014.199
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Servotte JC, 2020, CLIN SIMUL NURS, V38, P35, DOI 10.1016/j.ecns.2019.09.006
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Song CR, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15020213
   Teplan M, 2014, MEAS SCI REV, V14, P237, DOI 10.2478/msr-2014-0032
   Tian F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256211
   Toussaint L, 2021, EVID-BASED COMPL ALT, V2021, DOI 10.1155/2021/5924040
   Tsutsumi M, 2017, JPN J NURS SCI, V14, P3, DOI 10.1111/jjns.12131
   Tyng CM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01454
   Widjaja D, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/451857
   Wiederhold Brenda, 2008, Virtual Reality, V12, P259, DOI 10.1007/s10055-008-0100-3
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Zaccaro A, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00353
NR 63
TC 2
Z9 2
U1 7
U2 14
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 17
PY 2023
VL 4
AR 1211001
DI 10.3389/frvir.2023.1211001
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Q7FW5
UT WOS:001059153700001
OA gold
DA 2024-07-18
ER

PT J
AU Harrington, MCR
AF Harrington, Maria C. R.
TI Virtual nature makes knowledge beautiful
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE beauty; digital twin; embodied; fidelity; Immersive; informal learning;
   metaverse
ID REAL
AB This is a perspective that presents a viewpoint on immersive informal learning applications built as digital twins of the natural world. Such applications provide multimodal, interactive, immersive, embodied, and sensory experiences unique and different from typical game art environments because they are geospatial visualizations of data and information derived from ecological field plot studies, geographical information systems, drone images, and botanically correct 3D plant models visualized in real-time interactive game engines. Since they are constructed from geometric objects, they can programmatically self-express semantic data and connect to knowledge stores on the Internet to create a web of knowledge for both exploration of a virtual environment as a natural landscape and for exploration of connected knowledge stores for informal learning at the moment of curiosity. This design is exceptionally powerful for informal learning as it supports the innate human desire to understand the world. This paper summarizes the construction methods used for creating three digital twins of natural environments and the informal learning applications created and distributed, namely, augmented reality (AR), virtual reality (VR), and virtual field trips. Informal learning outcomes and emotional reactions are evaluated using mixed-methods research studies to understand the impact of design factors. Visual fidelity and navigational freedom are combined to increase learning outcomes and many effective and emotional outcomes as well. Access to facts and story increase learning outcomes, and applications evaluated as beautiful are correlated with emotional reactions of awe and wonder, and awe and wonder are correlated with higher learning gains. Beauty is correlated with other system-wide subjective evaluations largely accepted as important to create a context conducive to support learning outcomes, such as calmness, excitement, and curiosity, a desire to share, and a desire to create. This paper summarizes the highlights of the author's prior work to give the reader a perspective on the body of work.
C1 [Harrington, Maria C. R.] Univ Cent Florida, Nicholson Sch Commun & Media, Games & Interact Media Program, Harrington Lab, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Harrington, MCR (corresponding author), Univ Cent Florida, Nicholson Sch Commun & Media, Games & Interact Media Program, Harrington Lab, Orlando, FL 32816 USA.
EM maria.harrington@ucf.edu
OI Harrington, Maria/0000-0002-1899-4977
FU Epic MegaGrant program 2020; University of Central Florida Research
   Foundation GAP Fund Award, Orlando, FL; Artist in Residence Powdermill
   Nature Reserve, Carnegie Museum of Natural History, Pittsburgh, PA;
   Richard King Mellon Foundation; State Government of Salzburg, Austria;
   Idea Foundry Grant-The Entertainment; Ed Tech Business Accelerator
   Program, Pittsburgh, PA
FX The Virtual UCF Arboretum development was partly funded by the Epic
   MegaGrant program 2020 and supported by the University of Central
   Florida Research Foundation GAP Fund Award, Orlando, FL, 2022. The AR
   Perpetual Garden App was partly funded by the Artist in Residence
   Powdermill Nature Reserve, Carnegie Museum of Natural History,
   Pittsburgh, PA 2018. This work was funded in part by the Richard King
   Mellon Foundation and the State Government of Salzburg, Austria, under
   project contract "Ecomedicine VR Physiology Lab.". The Virtual Trillium
   Trail was partly funded by the Idea Foundry Grant-The Entertainment and
   Ed Tech Business Accelerator Program, Pittsburgh, PA 2010. The Virtual
   UCF Arboretum project is under the direction MH. It is an augmented
   reality (AR) and virtual reality (VR) collaboration between the
   Harrington Lab in the Nicholson School of Communication and Media and
   the UCF Arboretum and Department of Biology and the Landscape and
   Natural Resources team at the University of Central Florida.
CR [Anonymous], 2008, THESIS
   Ash Doris, 2004, Curator, V47, P84
   Bentley M., 1995, Science, V32, P23, DOI DOI 10.1080/00368121.1995.10113190
   Blackshark.ai, 2023, ABOUT US
   Cameron J. D., 2009, AVATAR FILM 20 CENTU
   Cameron James., 2022, Avatar: The Way of Water
   Cesium, 2023, ABOUT US
   Epic Games, 2023, ABOUT US
   ESRI, 2023, ABOUT US
   Gritz J. R., 2022, SMITHSONIAN MAGAZINE
   Harrington M. C., 2022, ACM SPECIAL INTEREST, P4, DOI [10.1145/3532720.3535663, DOI 10.1145/3532720.3535663]
   Harrington M. C. R., 2020, P ACM SPECIAL INTERE, P2
   Harrington M. C. R., 2021, P ACM SPEC INT GROUP
   Harrington M.C.R., 2009, Children, Youth and Environments, V19, P74
   Harrington M. C. R., 2020, P ACM SIG CHI ACM IN, P276, DOI [10.1145/3397617.3402036, DOI 10.1145/3397617.3402036]
   Harrington MCR, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P70, DOI [10.23919/iLRN47897.2020.9155202, 10.23919/ilrn47897.2020.9155202]
   Harrington MCR, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040018
   Harrington MCR, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P813, DOI [10.1109/VRW50115.2020.00-18, 10.1109/VRW50115.2020.00257]
   Harrington MCR, 2019, CURATOR, V62, P177, DOI 10.1111/cura.12308
   Harrington MCR, 2012, VIRTUAL REAL-LONDON, V16, P105, DOI 10.1007/s10055-011-0189-7
   Harrington MCR, 2011, IEEE T LEARN TECHNOL, V4, P175, DOI 10.1109/TLT.2010.20
   Köster M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207113
   Martin F. E., 2023, THESIS U CTR FLORIDA
   McCauley DJ, 2017, SCIENCE, V358, P298, DOI 10.1126/science.aao1919
   REED ES, 1977, ACTA BIOTHEOR, V26, P153, DOI 10.1007/BF00048424
NR 25
TC 1
Z9 1
U1 3
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 13
PY 2023
VL 4
AR 1100540
DI 10.3389/frvir.2023.1100540
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RY8
UT WOS:001023166800001
OA gold
DA 2024-07-18
ER

PT J
AU Lachmair, M
   Fischer, MH
   Gerjets, P
AF Lachmair, Martin
   Fischer, Martin H.
   Gerjets, Peter
TI Action-control mappings of interfaces in virtual reality: A study of
   embodied interaction
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE embodied interaction; grounded cognition; virtual reality;
   action-control mapping; zooming; valence; user interface; embodiment
ID NUMBER MAGNITUDE; PREDISPOSITIONS; PERCEPTION; MECHANISMS
AB The development of interface technologies is driven by the goal of making interaction more positive through natural action-control mappings. In Virtual Reality (VR), the entire body is potentially involved for interaction, using such mappings with a maximum of degrees of freedom. The downside is the increase in interaction complexity, which can dramatically influence interface design. A cognitive perspective on detailed aspects of interaction patterns is lacking in common interface design guidelines, although it can be helpful to make this complexity controllable and, thus, make interaction behavior predictable. In the present study, the distinction between grounding, embodiment, and situatedness (the GES framework) is applied to organize aspects of interactions and to compare them with each other. In two experiments, zooming into or out of emotional pictures through changes of arm span was examined in VR. There are qualitatively different aspects during such an interaction: i) perceptual aspects caused by zooming are fundamental for human behavior (Grounding: closer objects appear bigger) and ii) aspects of gestures correspond to the physical characteristics of the agents (Embodiment: little distance of hands signals little or, in contrast, "creating more detail"). The GES-framework sets aspects of Grounding against aspects of Embodiment, thus allowing to predict human behavior regarding these qualitatively different aspects. For the zooming procedure, the study shows that Grounding can overrule Embodiment in interaction design. Thus, we propose GES as a cognitive framework that can help to inform interaction guidelines for user interface design in VR.
C1 [Lachmair, Martin] Baden Wuerttemberg Cooperat State Univ, Villingen Schwenningen, Germany.
   [Fischer, Martin H.] Univ Potsdam, Div Cognit Sci, Potsdam, Germany.
   [Gerjets, Peter] Leibniz Inst Wissensmedien, Tubingen, Germany.
   [Gerjets, Peter] LEAD Grad Sch & Res Network, Tubingen, Germany.
C3 University of Potsdam; Leibniz Institut fur Wissensmedien
RP Lachmair, M (corresponding author), Baden Wuerttemberg Cooperat State Univ, Villingen Schwenningen, Germany.
EM lachmair@dhbw-vs.de
RI Lachmair, Martin/KMA-7309-2024
OI Lachmair, Martin/0009-0006-4728-9042
CR Abrams RA, 2008, COGNITION, V107, P1035, DOI 10.1016/j.cognition.2007.09.006
   and Wixon, 2011, BRAV NUI WORLD
   Andres M, 2004, NEUROREPORT, V15, P2773
   Andres M, 2008, CORTEX, V44, P414, DOI 10.1016/j.cortex.2007.08.007
   Ap Dijksterhuis, 2002, EMOTION, V2, P203, DOI 10.1037/1528-3542.2.3.203
   Bailey JO, 2016, PRESENCE-TELEOP VIRT, V25, P222, DOI 10.1162/PRES_a_00263
   Bamford S, 2008, EMOTION, V8, P174, DOI 10.1037/1528-3542.8.2.174
   Bay S., 2013, INT C HUM INT MAN IN, P22
   Brockmole JR, 2013, CURR DIR PSYCHOL SCI, V22, P38, DOI 10.1177/0963721412465065
   Cannon PR, 2010, COGNITION EMOTION, V24, P681, DOI 10.1080/02699930902927698
   Carr EW, 2016, EMOTION, V16, P540, DOI 10.1037/emo0000146
   Casasanto D., 2014, METAPHOR RES SOCIAL, P249, DOI DOI 10.1037/14278-011
   Torres SC, 2020, PSYCHOL RES-PSYCH FO, V84, P23, DOI 10.1007/s00426-018-0971-1
   Cervera-Torres S, 2021, EMOTION, V21, P220, DOI 10.1037/emo0000651
   Chen M, 1999, PERS SOC PSYCHOL B, V25, P215, DOI 10.1177/0146167299025002007
   de Gelder B, 2006, NAT REV NEUROSCI, V7, P242, DOI 10.1038/nrn1872
   Fischer M, 2009, EXP BRAIN RES, V192, P149, DOI 10.1007/s00221-008-1622-3
   Fischer MH, 2013, CONT TOP COGN NEUROS, P225
   Fischer MH, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00260
   Garcia-Bonete MJ, 2019, BIOCHEM MOL BIOL EDU, V47, P16, DOI 10.1002/bmb.21188
   Hoggan E., 2013, P SIGCHI C HUMAN FAC, DOI [10.1145/2512349.2512817, DOI 10.1145/2512349.2512817, 10.1145/2470654.2481423, DOI 10.1145/2470654.2481423]
   Holmes K. J., 2011, P ANN M COGN SCI SOC, V33
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103
   Hommel B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01318
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Lachmair M, 2019, PSYCHOL RES-PSYCH FO, V83, P894, DOI 10.1007/s00426-017-0898-y
   LAKOFF G, 1980, COGNITIVE SCI, V4, P195, DOI 10.1016/S0364-0213(80)80017-6
   Lang P. J., 1997, NIMH CTR STUDY EMOTI, V1, P39
   Leventhal AM, 2007, MOTIV EMOTION, V31, P145, DOI 10.1007/s11031-007-9059-8
   Masson MEJ, 2011, BEHAV RES METHODS, V43, P679, DOI 10.3758/s13428-010-0049-5
   Mauney D., 2010, P UPA ATL
   Myachykov A, 2014, TOP COGN SCI, V6, P442, DOI 10.1111/tops.12024
   NIELSEN J, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P152, DOI 10.1145/191666.191729
   Norouzi N, 2021, IEEE T VIS COMPUT GR, V27, P4321, DOI 10.1109/TVCG.2021.3106490
   Parise CV, 2014, P NATL ACAD SCI USA, V111, P6104, DOI 10.1073/pnas.1322705111
   Pezzulo G, 2013, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00612
   Pezzulo G, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00005
   Picard R.W., 2000, Affective Computing
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Sui J, 2015, TRENDS COGN SCI, V19, P719, DOI 10.1016/j.tics.2015.08.015
   Sutcliffe A, 2004, INTERACT COMPUT, V16, P831, DOI 10.1016/j.intcom.2004.05.001
   Sutcliffe AG, 2019, INT J HUM-COMPUT INT, V35, P168, DOI 10.1080/10447318.2018.1443898
   Terrizzi BF, 2019, DEV PSYCHOL, V55, P793, DOI 10.1037/dev0000657
   Winkielman P, 2018, PHILOS T R SOC B, V373, DOI 10.1098/rstb.2017.0127
   Winter B, 2017, METAPHOR: EMBODIED COGNITION AND DISCOURSE, P99
   Wood G, 2006, CORTEX, V42, P1069, DOI 10.1016/S0010-9452(08)70219-3
   Woodin G, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242142
   Zech HG, 2020, BEHAV RES METHODS, V52, P2085, DOI 10.3758/s13428-020-01379-3
NR 50
TC 1
Z9 1
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 4
PY 2022
VL 3
AR 976849
DI 10.3389/frvir.2022.976849
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WL6
UT WOS:001023284200001
OA gold
DA 2024-07-18
ER

PT J
AU Hoffmann, S
   Mai, R
AF Hoffmann, Stefan
   Mai, Robert
TI Consumer behavior in augmented shopping reality. A review, synthesis,
   and research agenda
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE augmented reality; retailing; e-commerce; m-commerce; consumer behavior
ID VIRTUAL TRY-ON; IMPACT; TECHNOLOGY; RETAIL; INFORMATION; EXPERIENCE;
   ADOPTION; DECISION; WORLD; MEDIA
AB The application of augmented reality (AR) is receiving great interest in e-commerce, m-commerce, and brick-and-mortar-retailing. A growing body of literature has explored several different facets of how consumers react to the upcoming augmented shopping reality. This systematic literature review summarizes the findings of 56 empirical papers that analyzed consumers' experience with AR, acceptance of AR, and behavioral reactions to AR in various online and offline environments. The review synthesizes current knowledge and critically discusses the empirical studies conceptually and methodologically. Finally, the review outlines the theoretical basis as well as the independent, mediating, moderating, and dependent variables analyzed in previous AR research. Based on this synthesis, the paper develops an integrative framework model, which helps derive directives for future research on augmented shopping reality.
C1 [Hoffmann, Stefan] Univ Kiel, Dept Mkt, Kiel, Germany.
   [Mai, Robert] Grenoble Ecole Management, Grenoble, France.
C3 University of Kiel; Grenoble Ecole Management
RP Hoffmann, S (corresponding author), Univ Kiel, Dept Mkt, Kiel, Germany.
EM stefan.hoffmann@bwl.uni-kiel.de
OI Mai, Robert/0000-0002-8364-9328
FU Deutsche Forschungsgemeinschaft (DFG)
FX We acknowledge financial support by the Deutsche Forschungsgemeinschaft
   (DFG) within the funding programme Open Access-Publikationskosten.
CR ADAMS JS, 1963, J ABNORM PSYCHOL, V67, P422, DOI 10.1037/h0040968
   Aluri A, 2017, J HOSP TOUR TECHNOL, V8, P55, DOI 10.1108/JHTT-12-2016-0087
   [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI DOI 10.1371/JOURNAL.PMED.1000097
   Arghashi V, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102756
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baek TH, 2018, INT J ADVERT, V37, P421, DOI 10.1080/02650487.2016.1244887
   Barhorst JB, 2021, J BUS RES, V122, P423, DOI 10.1016/j.jbusres.2020.08.041
   Baytar F, 2020, J FASH MARK MANAG, V24, P667, DOI 10.1108/JFMM-05-2018-0077
   Beck M, 2018, J RETAIL CONSUM SERV, V40, P279, DOI 10.1016/j.jretconser.2016.08.006
   Berryman Donna R., 2012, Medical Reference Services Quarterly, V31, P212, DOI 10.1080/02763869.2012.670604
   Bonetti F, 2018, PROGR IS, P119, DOI 10.1007/978-3-319-64027-3_9
   Bonnin G, 2020, J RETAIL CONSUM SERV, V52, DOI 10.1016/j.jretconser.2019.101938
   Botella CM, 2005, CYBERPSYCHOL BEHAV, V8, P162, DOI 10.1089/cpb.2005.8.162
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   Boyd DE, 2019, J BUS RES, V100, P590, DOI 10.1016/j.jbusres.2018.06.007
   Brito PQ, 2018, INT J HUM-COMPUT INT, V34, P819, DOI 10.1080/10447318.2017.1393974
   Caboni F, 2019, INT J RETAIL DISTRIB, V47, P1125, DOI 10.1108/IJRDM-12-2018-0263
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Castillo SMJ, 2021, INT J RETAIL DISTRIB, V49, P875, DOI 10.1108/IJRDM-09-2020-0380
   Chae HJ, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P45, DOI 10.1145/3242587.3242631
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Choi U, 2020, CYBERPSYCH BEH SOC N, V23, P800, DOI 10.1089/cyber.2020.0057
   Chuah S. H. W., 2019, INT J TECHNOL MARK, V13, P1, DOI [10.1504/ijtmkt.2019.10021794, DOI 10.1504/IJTMKT.2019.10021794]
   Chung N, 2018, J TRAVEL RES, V57, P627, DOI 10.1177/0047287517708255
   Csikszentmihalyi M, 1997, FINDING FLOW PSYCHOL, DOI 10.5860/choice.35-1828
   Culnan MJ, 1999, ORGAN SCI, V10, P104, DOI 10.1287/orsc.10.1.104
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Ruyter K, 2020, J ADVERTISING, V49, P109, DOI 10.1080/00913367.2020.1740123
   Deliza R, 1996, J SENS STUD, V11, P103, DOI 10.1111/j.1745-459X.1996.tb00036.x
   DeLone WH, 1992, INFORM SYST RES, V3, P60, DOI 10.1287/isre.3.1.60
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   Dieck MCT, 2018, CURR ISSUES TOUR, V21, P154, DOI 10.1080/13683500.2015.1070801
   Dwivedi YK, 2021, INT J INFORM MANAGE, V59, DOI 10.1016/j.ijinfomgt.2020.102168
   Fan XJ, 2020, J RETAIL CONSUM SERV, V53, DOI 10.1016/j.jretconser.2019.101986
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Geissler G., 2001, J ASSOC INF SYST, V2, P1, DOI DOI 10.17705/1jais.00014
   Gilovich T, 2015, J CONSUM PSYCHOL, V25, P152, DOI 10.1016/j.jcps.2014.08.004
   Girard T, 2010, J BUS RES, V63, P1079, DOI 10.1016/j.jbusres.2008.12.011
   Hacker J, 2020, EUR J INFORM SYST, V29, P563, DOI 10.1080/0960085X.2020.1814680
   Hamari J, 2019, INT J HUM-COMPUT INT, V35, P804, DOI 10.1080/10447318.2018.1497115
   Harley JM, 2016, ETR&D-EDUC TECH RES, V64, P359, DOI 10.1007/s11423-015-9420-7
   Heller J, 2019, J RETAILING, V95, P219, DOI 10.1016/j.jretai.2019.10.008
   Heller J, 2019, J RETAILING, V95, P94, DOI 10.1016/j.jretai.2019.03.005
   Hennig M., 2012, Studying Social Networks. A Guide to Empirical Research
   Herz M, 2019, TECHNOL FORECAST SOC, V138, P228, DOI 10.1016/j.techfore.2018.09.008
   Higgins ET, 2003, ADV EXP SOC PSYCHOL, V35, P293, DOI 10.1016/S0065-2601(03)01005-0
   Hilken T, 2020, J ACAD MARKET SCI, V48, P143, DOI 10.1007/s11747-019-00688-0
   Hilken T, 2018, J RES INTERACT MARK, V12, P509, DOI 10.1108/JRIM-01-2018-0023
   Hilken T, 2017, J ACAD MARKET SCI, V45, P884, DOI 10.1007/s11747-017-0541-x
   Hinsch C, 2020, J RETAIL CONSUM SERV, V53, DOI 10.1016/j.jretconser.2019.101987
   Hoffmann NC, 2020, J MARKET MANAG-UK, V36, P888, DOI 10.1080/0267257X.2020.1773514
   Hoffmann Stefan, 2022, HMD Praxis der Wirtschaftsinformatik, P23, DOI 10.1365/s40702-021-00822-z
   Hoffmann S, 2022, J ACAD MARKET SCI, V50, P743, DOI 10.1007/s11747-022-00855-w
   Hopp T., 2016, J CURRENT ISSUES RES, V37, P113
   Hsu SHY, 2021, J RETAIL CONSUM SERV, V62, DOI 10.1016/j.jretconser.2021.102649
   Huang TL, 2017, INTERNET RES, V27, P449, DOI 10.1108/IntR-11-2015-0321
   Huang TL, 2015, ELECTRON COMMER RES, V15, P269, DOI 10.1007/s10660-014-9163-2
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Huynh B, 2019, INT J SEMANT COMPUT, V13, P289, DOI 10.1142/S1793351X19400129
   Inman JJ, 2017, J RETAILING, V93, P7, DOI 10.1016/j.jretai.2016.12.006
   Javornik A, 2016, J MARKET MANAG-UK, V32, P987, DOI 10.1080/0267257X.2016.1174726
   Javornik A, 2016, J RETAIL CONSUM SERV, V30, P252, DOI 10.1016/j.jretconser.2016.02.004
   Jessen A, 2020, J BUS RES, V116, P85, DOI 10.1016/j.jbusres.2020.05.002
   Jiang Y, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2021.102720
   Joerss T, 2021, J BUS RES, V128, P510, DOI 10.1016/j.jbusres.2021.02.019
   Jung Y, 2014, J BUS RES, V67, P2231, DOI 10.1016/j.jbusres.2014.01.002
   Kaasinen E, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.01.052
   Kalantari Mahdokht, 2017, International Journal of Technology Marketing, V12, P274
   Kim HC, 2016, COMPUT HUM BEHAV, V59, P28, DOI 10.1016/j.chb.2016.01.001
   Kim J, 2008, J INTERACT MARK, V22, P45, DOI 10.1002/dir.20113
   Kourouthanassis P, 2015, PERVASIVE MOB COMPUT, V18, P71, DOI 10.1016/j.pmcj.2014.08.009
   Kowalczuk P, 2021, J BUS RES, V124, P357, DOI 10.1016/j.jbusres.2020.10.050
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Lavoye V, 2021, INT REV RETAIL DISTR, V31, P299, DOI 10.1080/09593969.2021.1901765
   Lee H, 2021, J FASH MARK MANAG, V25, P45, DOI 10.1108/JFMM-05-2019-0092
   Mai R, 2021, J ACAD MARKET SCI, V49, P1151, DOI 10.1007/s11747-021-00787-x
   Mai R, 2014, J INTERACT MARK, V28, P101, DOI 10.1016/j.intmar.2013.10.001
   Marr B., 2020, Forbes
   Masood T, 2019, ROBOT CIM-INT MANUF, V58, P181, DOI 10.1016/j.rcim.2019.02.003
   Mauroner O., 2016, World Academy of Science, Engineering and Technology, International Journal of Social, Behavioral, Educational, Economic, Business and Industrial Engineering, V10, P422
   McLean G, 2019, COMPUT HUM BEHAV, V101, P210, DOI 10.1016/j.chb.2019.07.002
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Mishra A, 2021, PSYCHOL MARKET, V38, P385, DOI [10.1002/mar.21436, 10.1016/j.procir.2020.04.049]
   Nagele AN, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.610320
   Narumi T, 2011, P IEEE VIRT REAL ANN, P265, DOI 10.1109/VR.2011.5759500
   Narvar, 2017, MAK RET COMP ADV
   Nikhashemi SR, 2021, J RETAIL CONSUM SERV, V60, DOI 10.1016/j.jretconser.2021.102464
   Olsson T, 2013, PERS UBIQUIT COMPUT, V17, P287, DOI 10.1007/s00779-011-0494-x
   Palmatier RW, 2018, J ACAD MARKET SCI, V46, P1, DOI 10.1007/s11747-017-0563-4
   Pantano E, 2017, J RETAIL CONSUM SERV, V38, P81, DOI 10.1016/j.jretconser.2017.05.011
   Park M, 2020, J RETAIL CONSUM SERV, V52, DOI 10.1016/j.jretconser.2019.101912
   Plotkina D, 2019, J RETAIL CONSUM SERV, V51, P362, DOI 10.1016/j.jretconser.2019.07.002
   Poushneh A, 2018, J RETAIL CONSUM SERV, V41, P169, DOI 10.1016/j.jretconser.2017.12.010
   Poushneh A, 2017, J RETAIL CONSUM SERV, V34, P229, DOI 10.1016/j.jretconser.2016.10.005
   Qasem Z, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102254
   Qin H, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2021.102680
   Qin H, 2021, J RETAIL CONSUM SERV, V58, DOI 10.1016/j.jretconser.2020.102337
   Rauschnabel PA, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102279
   Rauschnabel PA, 2019, J RETAIL CONSUM SERV, V49, P43, DOI 10.1016/j.jretconser.2019.03.004
   Rauschnabel PA, 2018, J BUS RES, V92, P374, DOI 10.1016/j.jbusres.2018.08.008
   Rauschnabel PA, 2018, PSYCHOL MARKET, V35, P557, DOI 10.1002/mar.21106
   Rauschnabel PA, 2017, COMPUT HUM BEHAV, V76, P276, DOI 10.1016/j.chb.2017.07.030
   Reitmayr Gerhard, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P109, DOI 10.1109/ISMAR.2006.297801
   Rese A, 2017, TECHNOL FORECAST SOC, V124, P306, DOI 10.1016/j.techfore.2016.10.010
   Rese A, 2014, J RETAIL CONSUM SERV, V21, P869, DOI 10.1016/j.jretconser.2014.02.011
   Robbins P., 2009, CAMBRIDGE HDB SITUAT
   ROGERS TB, 1977, J PERS SOC PSYCHOL, V35, P677, DOI 10.1037/0022-3514.35.9.677
   Romano B, 2021, AUSTRALAS MARK J, V29, P354, DOI 10.1016/j.ausmj.2020.06.010
   Ruggiero T. E., 2000, MASS COMMUNICATION S, V3, P3, DOI [DOI 10.1207/S15327825MCS0301_02, 10.1207/s15327825mcs0301_02]
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Saleem M, 2022, J INTERNET COMMER, V21, P497, DOI 10.1080/15332861.2021.1975427
   Samsung Business Insights, 2020, 5 RET TECHN TRENDS W
   Schifferstein H.N. J., 2009, Imagination, Cognition and Personality, V28, P371, DOI DOI 10.2190/IC.28.4.G
   Scholz J, 2018, J RETAIL CONSUM SERV, V44, P11, DOI 10.1016/j.jretconser.2018.05.004
   Skarbez R., 2021, FRONT VIRTUAL REAL, V2, P647997, DOI [DOI 10.3389/FRVIR.2021.647997, 10.3389/frvir.2021.647997]
   Smink AR, 2020, J BUS RES, V118, P474, DOI 10.1016/j.jbusres.2020.07.018
   Smink AR, 2019, ELECTRON COMMER R A, V35, DOI 10.1016/j.elerap.2019.100854
   Snyder H, 2019, J BUS RES, V104, P333, DOI 10.1016/j.jbusres.2019.07.039
   Song HK, 2020, INFORM TECHNOL PEOPL, V33, P1214, DOI 10.1108/ITP-02-2019-0092
   Spreer P., 2014, Transactions on Marketing Research, V1, P20, DOI [10.15764/MR.2014.01002, DOI 10.15764/MR.2014.01002]
   Sundar SS, 2015, HBK COMMUN MEDIA, P47
   Tan YC, 2022, J MARKETING, V86, P48, DOI 10.1177/0022242921995449
   Teas RK, 2000, J ACAD MARKET SCI, V28, P278, DOI 10.1177/0092070300282008
   van Berlo ZMC, 2021, J BUS RES, V122, P458, DOI 10.1016/j.jbusres.2020.09.006
   van Esch P, 2019, J RETAIL CONSUM SERV, V49, P35, DOI 10.1016/j.jretconser.2019.03.002
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Vávra P, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4574172
   vXchange, 2020, TOP 7 AUGM REAL STAT
   Vynz Research, 2020, AUGMENTED REALITY VI
   Wang YN, 2022, ASIA PAC J MARKET LO, V34, P110, DOI 10.1108/APJML-11-2019-0684
   Ward R. J., 2021, J. Percept. Imaging, V4, P1, DOI [10.2352/j.percept.imaging.2021.4.2.020402, DOI 10.2352/J.PERCEPT.IMAGING.2021.4.2.020402]
   Ward RJ, 2021, IEEE SENS J, V21, P6784, DOI 10.1109/JSEN.2020.3040114
   Watson A, 2020, INT J RETAIL DISTRIB, V48, P433, DOI 10.1108/IJRDM-06-2017-0117
   WBR, 2020, NEW TECH IS CREAT SE
   Wedel M, 2020, INT J RES MARK, V37, P443, DOI 10.1016/j.ijresmar.2020.04.004
   Westbrook G., 2021, Top 10 global consumer trends
   Whang JB, 2021, J BUS RES, V133, P275, DOI 10.1016/j.jbusres.2021.04.057
   Yaoyuneyong G., 2016, J INTERACTIVE ADVERT, V16, P16
   Yim MYC, 2019, J BUS RES, V100, P581, DOI 10.1016/j.jbusres.2018.10.041
   Yim MYC, 2017, J INTERACT MARK, V39, P89, DOI 10.1016/j.intmar.2017.04.001
   Yoo J, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7020014
   Yuan CL, 2021, INT J ADVERT, V40, P922, DOI 10.1080/02650487.2020.1869387
   Zhang TT, 2019, INTERNET RES, V29, P529, DOI 10.1108/IntR-12-2017-0540
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 145
TC 2
Z9 2
U1 6
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 14
PY 2022
VL 3
AR 961236
DI 10.3389/frvir.2022.961236
PG 24
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VV4
UT WOS:001023267800001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Witte, K
   Droste, M
   Ritter, Y
   Emmermacher, P
   Masik, S
   Buerger, D
   Petri, K
AF Witte, Kerstin
   Droste, Melina
   Ritter, Yvonne
   Emmermacher, Peter
   Masik, Steffen
   Buerger, Dan
   Petri, Katharina
TI Sports training in virtual reality to improve response behavior in
   karate kumite with transfer to real world
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality training; exercise; response behavior; karate kumite;
   headmounted display; transfer
AB Virtual reality (VR) training has become valuable in sports to improve motor behavior and train specific situations under standardized conditions. However, studies comparing conventional training with VR training are rare, especially for advanced athletes. Furthermore, it remains unclear whether the performance improvement achieved through VR training can be transferred to the real world (RW). Therefore, we present a study analyzing sports-specific response training using a head-mounted display (HMD) combined with conventional training and its transfer to RW. In ten training sessions over 6 weeks, a VR training group (VRG, n = 15) performed virtual karate training (10 min) combined with a conventional training (80 min), while a conventional training group (CG, n = 12) conducted only conventional training (90 min) at the same time. The VR training consisted of the athlete responding to various karate attacks performed by a virtual opponent in a karate-specific manner. The study design included a pretest, an intermediate test (after 5 training sessions), and a posttest. We analyzed sports-specific response behavior concerning the competition-relevant karate attacks Gyaku-Zuki jodan (GZj) and Kizami-Zuki (KZ) using the parameters 'response time', and the "response quality" when the athletes had to react to attacks of a virtual opponent in VR and a real opponent in RW. For the parameter "response time," improvements were detected only for the VRG in VR concerning GZj and KZ. For the parameter "response quality" for both groups, no improvements could be found. Furthermore, athletes provided positive feedback regarding the integration of VR training into conventional training.
C1 [Witte, Kerstin; Droste, Melina; Ritter, Yvonne; Emmermacher, Peter; Buerger, Dan; Petri, Katharina] Otto von Guericke Univ, Inst Sports Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
   [Masik, Steffen] Fraunhofer Inst Factory Operat & Automat, Elbedome, Magdeburg, Germany.
C3 Otto von Guericke University; Fraunhofer Gesellschaft
RP Witte, K (corresponding author), Otto von Guericke Univ, Inst Sports Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
EM Kerstin.witte@ovgu.de
OI Witte, Kerstin/0000-0001-8711-9335
FU German Reserach Foundation (DFG) [WI 1456/22-1]
FX This work was supported by the German Reserach Foundation (DFG) (WI
   1456/22-1).
CR Burns A.-M., 2011, BIO Web of Conferences, V1, DOI DOI 10.1051/BIOCONF/20110100012
   Cohen J., 1988, STAT POWER ANAL BEHA
   Covaci A, 2015, IEEE COMPUT GRAPH, V35, P55, DOI 10.1109/MCG.2015.95
   Craig C., 2013, SPORTS TECHNOLOGY, V6, P161, DOI [DOI 10.1080/19346182.2013.855224, 10.1080/19346182.2013, DOI 10.1080/19346182.2013, 10.1080/19346182.2013.855224]
   Dorner R., 2016, Serious Games: Foundations, Concepts and Practice, DOI [10.1007/978-3-319-40612-1, DOI 10.1007/978-3-319-40612-1]
   Florkiewicz B., 2015, J KINESIOL EXERC SCI, V69, P25
   Gierczuk D, 2017, PERCEPT MOTOR SKILL, V124, P200, DOI 10.1177/0031512516672126
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Harris DJ, 2020, PSYCHOL SPORT EXERC, V50, DOI 10.1016/j.psychsport.2020.101721
   Hülsmann F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00043
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Lammfromm R., 2011, BIOWEB C, V1, P00054, DOI [10.1051/bioconf/20110100054, DOI 10.1051/BIOCONF/20110100054]
   Le Naour T., 2020, INT J VIRTUAL REAL, V20, P36, DOI [10.20870/IJVR.2020.20.2.4576, DOI 10.20870/IJVR.2020.20.2.4576]
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Miles HC, 2012, COMPUT GRAPH-UK, V36, P714, DOI 10.1016/j.cag.2012.04.007
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Oagaz H, 2022, IEEE T VIS COMPUT GR, V28, P4332, DOI 10.1109/TVCG.2021.3086403
   Pan LA, 2012, ADV MATER RES-SWITZ, V472-475, P3117, DOI 10.4028/www.scientific.net/AMR.472-475.3117
   Petri K., 2018, International Journal of Computer Science in Sport, V17, P1, DOI 10.2478/ijcss-2018-0001
   Petri K., 2020, AM J BIOMED SCI, DOI [10.5099/aj2002001, DOI 10.5099/AJ200200107]
   Petri K., 2018, BIOMED J SCI TECH RE, V1, P5699, DOI DOI 10.26717/BJSTR.2018.07.001453
   Petri K., 2019, INT J PHYS ED, V8, P55, DOI [10.26524/ijpefs1946, DOI 10.26524/IJPEFS1946]
   Petri K, 2019, SPORTS ENG, V22, DOI 10.1007/s12283-019-0299-0
   Petri K, 2018, ADV INTELL SYST, V663, P124, DOI 10.1007/978-3-319-67846-7_13
   Rauter G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082145
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Tirp J., 2015, Psychol Test Assess Model, V57, P57, DOI DOI 10.3389/FPSYG.2017.02183
   Wang JZ, 2012, PROCEDIA ENGINEER, V29, P3659, DOI 10.1016/j.proeng.2012.01.548
   Yanovich E., 2015, ADV PHYS ED, V5, P188, DOI [10.4236/ape.2015.53023, DOI 10.4236/APE.2015.53023]
   Zaal FTJM, 2011, PRESENCE-TELEOP VIRT, V20, P93, DOI 10.1162/pres_a_00037
NR 32
TC 7
Z9 7
U1 6
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 29
PY 2022
VL 3
AR 903021
DI 10.3389/frvir.2022.903021
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WN9
UT WOS:001023286500001
OA gold
DA 2024-07-18
ER

PT J
AU Simon, J
   Grogna, D
   Rivard, MC
   Heck, M
   Bouchard, S
   Quertemont, E
AF Simon, Jessica
   Grogna, David
   Rivard, Marie-Christine
   Heck, Michelle
   Bouchard, Stephane
   Quertemont, Etienne
TI Assessing attentional bias for alcohol-related cues using eye tracking
   in a virtual reality environment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; eye tracking; cue exposure; craving; immersion
ID INCENTIVE-SENSITIZATION THEORY; NATIONAL EPIDEMIOLOGIC SURVEY;
   COMPULSIVE DRINKING SCALE; IDENTIFICATION TEST AUDIT;
   RESPONSE-INHIBITION; ADDICTIVE BEHAVIORS; CLINICAL-RELEVANCE; SOCIAL
   DRINKERS; STROOP PARADIGM; HEAVY DRINKERS
AB Several experimental paradigms were developed to measure attentional biases towards alcohol-related cues. However, most of them are based on reaction times to two-dimensional stimuli displayed on a computer screen, such that their ecological validity has been questioned. To address this, we integrated an eye tracking system into a virtual reality headset (ET-VR) and measured attentional biases in a subclinical population of alcohol users. In this exploratory study, forty social drinkers were recruited and immersed in a virtual bar including alcohol-related stimuli. Attentional focus was assessed using dwell time and number of fixations for these alcohol-related stimuli as well as for neutral stimuli unrelated to alcohol consumption. The results show that the number of fixations and, to a lesser extent, the dwell time for alcohol-related cues were positively correlated with the drinking motivation of the participants. In contrast, no significant correlation was found for neutral stimuli. In conclusion, the present study shows that alcohol-induced attentional biases can be studied using an ET-VR device in a subclinical population of alcohol users.
C1 [Simon, Jessica; Heck, Michelle; Quertemont, Etienne] Univ Liege, Psychol & Neurosci Cognit Res Unit PsyNCog, Liege, Belgium.
   [Grogna, David] Univ Liege, Montefiore Inst, Fac Appl Sci, Liege, Belgium.
   [Rivard, Marie-Christine; Bouchard, Stephane] Univ Quebec Outaouais, Cyberpsychol Lab, Gatineau, PQ, Canada.
C3 University of Liege; University of Liege; University of Quebec;
   University Quebec Outaouais
RP Simon, J (corresponding author), Univ Liege, Psychol & Neurosci Cognit Res Unit PsyNCog, Liege, Belgium.
EM j.simon@uliege.be
OI Bouchard, Stephane/0000-0002-5995-340X; Simon,
   Jessica/0000-0002-5966-2063
FU University of Liege; Commission mixte permanente
   Quebec/Wallonie-Bruxelles; Canada research Chairs program; European
   Regional Development Fund and Wallonia
FX This work was supported by the University of Liege, a grant from the
   Commission mixte permanente Quebec/Wallonie-Bruxelles, the Canada
   research Chairs program, the European Regional Development Fund and
   Wallonia.
CR Abroms BD, 2004, EXP CLIN PSYCHOPHARM, V12, P243, DOI 10.1037/1064-1297.12.4.243
   [Anonymous], 1964, BMJ-BRIT MED J, V2, P177
   Ansseau M, 2000, EUR ADDICT RES, V6, P51, DOI 10.1159/000019010
   ANTON RF, 1995, ALCOHOL CLIN EXP RES, V19, P92, DOI 10.1111/j.1530-0277.1995.tb01475.x
   Babor T.F., 2001, The Alcohol Use Disorders Identification Test. Guidelines for Use in Primary Care
   Berridge KC, 2016, AM PSYCHOL, V71, P670, DOI 10.1037/amp0000059
   Billieux J, 2012, COMPR PSYCHIAT, V53, P609, DOI 10.1016/j.comppsych.2011.09.001
   Bing-Canar H, 2021, ADDICT BEHAV, V112, DOI 10.1016/j.addbeh.2020.106596
   Bollen Z, 2020, J PSYCHOPHARMACOL, V34, P636, DOI 10.1177/0269881120913131
   Bordnick P. S., 2019, Virtual reality for psychological and neurocognitive interventions, P131
   Bordnick PS, 2008, ADDICT BEHAV, V33, P743, DOI 10.1016/j.addbeh.2007.12.010
   Brown CRH, 2018, PSYCHOPHARMACOLOGY, V235, P2087, DOI 10.1007/s00213-018-4906-8
   Bruce G, 2004, J PSYCHOPHARMACOL, V18, P527, DOI 10.1177/0269881104047280
   Choi YJ, 2015, VIRTUAL REAL-LONDON, V19, P111, DOI 10.1007/s10055-015-0264-6
   Christiansen P, 2015, DRUG ALCOHOL DEPEN, V155, P170, DOI 10.1016/j.drugalcdep.2015.07.672
   Christiansen P, 2015, ADDICT BEHAV, V44, P43, DOI 10.1016/j.addbeh.2014.10.005
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Clerkin EM, 2016, BEHAV RES THER, V87, P58, DOI 10.1016/j.brat.2016.08.010
   Coskunpinar A, 2013, DRUG ALCOHOL DEPEN, V133, P1, DOI 10.1016/j.drugalcdep.2013.05.008
   Cox WM, 2006, PSYCHOL BULL, V132, P443, DOI 10.1037/0033-2909.132.3.443
   Cox WM, 2002, DRUG ALCOHOL DEPEN, V68, P237, DOI 10.1016/S0376-8716(02)00219-3
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Drummond DC, 2001, ADDICTION, V96, P33, DOI 10.1046/j.1360-0443.2001.961333.x
   Ehrman RN, 2002, DRUG ALCOHOL DEPEN, V67, P185, DOI 10.1016/S0376-8716(02)00065-0
   Emery NN, 2015, ADDICT BEHAV, V50, P1, DOI 10.1016/j.addbeh.2015.06.007
   Fadardi J.S., 2006, Handbook of Implicit Cognition and Addiction, P121, DOI DOI 10.4135/9781412976237
   Fadardi JS, 2009, DRUG ALCOHOL DEPEN, V101, P137, DOI 10.1016/j.drugalcdep.2008.11.015
   Fadardi JS, 2006, PSYCHOPHARMACOLOGY, V185, P169, DOI 10.1007/s00213-005-0268-0
   Field M, 2008, DRUG ALCOHOL DEPEN, V97, P1, DOI 10.1016/j.drugalcdep.2008.03.030
   Field M, 2007, PSYCHOPHARMACOLOGY, V192, P593, DOI 10.1007/s00213-007-0760-9
   Field M, 2016, HEALTH PSYCHOL, V35, P767, DOI 10.1037/hea0000405
   Field M, 2014, CNS SPECTRUMS, V19, P225, DOI 10.1017/S1092852913000321
   Field M, 2009, EXP CLIN PSYCHOPHARM, V17, P312, DOI 10.1037/a0017090
   Field M, 2009, PSYCHOL BULL, V135, P589, DOI 10.1037/a0015843
   Flaudias V, 2019, AM J ADDICTION, V28, P489, DOI 10.1111/ajad.12944
   Flaudias V, 2019, PSYCHIAT RES, V272, P569, DOI 10.1016/j.psychres.2018.12.118
   FUHRER R, 1989, Psychiatrie and Psychobiologie, V4, P163
   Gache P, 2005, ALCOHOL CLIN EXP RES, V29, P2001, DOI 10.1097/01.alc.0000187034.58955.64
   Garland EL, 2012, PSYCHOPHARMACOLOGY, V222, P17, DOI 10.1007/s00213-011-2618-4
   Ghita A, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.543586
   Ghita A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00074
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Grant BF, 2015, JAMA PSYCHIAT, V72, P757, DOI 10.1001/jamapsychiatry.2015.0584
   Grant VV, 2007, ADDICT BEHAV, V32, P2226, DOI 10.1016/j.addbeh.2007.02.012
   Groefsema M, 2016, ALCOHOL CLIN EXP RES, V40, DOI 10.1111/acer.13165
   Hallgren Kevin A, 2013, J Behav Health, V2, P112
   Hasin DS, 2007, ARCH GEN PSYCHIAT, V64, P830, DOI 10.1001/archpsyc.64.7.830
   Heitmann J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228272
   Hernández-Serrano O, 2020, J CLIN MED, V9, DOI 10.3390/jcm9093018
   Hertel PT, 2011, PERSPECT PSYCHOL SCI, V6, P521, DOI 10.1177/1745691611421205
   Hobson J, 2013, J PSYCHOPHARMACOL, V27, P93, DOI 10.1177/0269881112447990
   Jones BC, 2002, PSYCHOPHARMACOLOGY, V165, P93, DOI 10.1007/s00213-002-1264-2
   Khosravani V, 2017, ADDICT BEHAV, V71, P75, DOI 10.1016/j.addbeh.2017.02.029
   Kilian C, 2021, ADDICTION, V116, P3369, DOI 10.1111/add.15530
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kreusch F, 2017, PSYCHIAT RES, V249, P232, DOI 10.1016/j.psychres.2017.01.019
   Kreusch F, 2013, ADDICT BEHAV, V38, P2520, DOI 10.1016/j.addbeh.2013.04.007
   Laforest M., 2016, Frontiers in ICT, V3, DOI DOI 10.3389/FICT.2016.00018
   Lee S, 2015, ADDICT BEHAV, V46, P58, DOI 10.1016/j.addbeh.2015.03.010
   Loranger C, 2017, J TRAUMA STRESS, V30, P157, DOI 10.1002/jts.22170
   Lusher J, 2004, DRUG ALCOHOL DEPEN, V75, P225, DOI 10.1016/j.drugalcdep.2004.03.004
   Manchery L, 2017, ADDICT BEHAV, V70, P14, DOI 10.1016/j.addbeh.2017.01.035
   Manor BR, 2003, J NEUROSCI METH, V128, P85, DOI 10.1016/S0165-0270(03)00151-1
   Martingano AJ, 2021, SOC PERSONAL PSYCHOL, V15
   McAteer AM, 2018, PSYCHOPHARMACOLOGY, V235, P2387, DOI 10.1007/s00213-018-4935-3
   McAteer AM, 2015, PSYCHOPHARMACOLOGY, V232, P3183, DOI 10.1007/s00213-015-3969-z
   McHugh RK, 2019, ALCOHOL RES-CURR REV, V40, P3, DOI 10.35946/arcr.v40.1.01
   Miller MA, 2010, ADDICTION, V105, P883, DOI 10.1111/j.1360-0443.2009.02860.x
   Monem RG, 2017, EXP CLIN PSYCHOPHARM, V25, P496, DOI 10.1037/pha0000157
   Monk RL, 2014, ALCOHOL CLIN EXP RES, V38, P2454, DOI 10.1111/acer.12504
   Mühlberger A, 2008, CYBERPSYCHOL BEHAV, V11, P425, DOI 10.1089/cpb.2007.0084
   Pabst A, 2021, PROG NEURO-PSYCHOPH, V110, DOI 10.1016/j.pnpbp.2021.110282
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pennington CR, 2019, PSYCHOPHARMACOLOGY, V236, P3465, DOI 10.1007/s00213-019-05313-0
   Pericot-Valverde I, 2016, NICOTINE TOB RES, V18, P538, DOI 10.1093/ntr/ntv216
   Porras-Garcia B, 2019, INT J EAT DISORDER, V52, P1181, DOI 10.1002/eat.23136
   RADLOFF L S, 1977, Applied Psychological Measurement, V1, P385, DOI 10.1177/014662167700100306
   Ramirez JJ, 2015, EXP CLIN PSYCHOPHARM, V23, P159, DOI 10.1037/pha0000018
   Reichenberger J, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00035
   Renaud P, 2002, CYBERPSYCHOL BEHAV, V5, P1, DOI 10.1089/109493102753685836
   Revelle W, 2009, PSYCHOMETRIKA, V74, P145, DOI 10.1007/s11336-008-9102-z
   Rinck M, 2018, J CONSULT CLIN PSYCH, V86, P1005, DOI 10.1037/ccp0000321
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robillard G., 2002, VALIDATION CANADIENN
   ROBINSON TE, 1993, BRAIN RES REV, V18, P247, DOI 10.1016/0165-0173(93)90013-P
   Rodebaugh TL, 2016, J ABNORM PSYCHOL, V125, P840, DOI 10.1037/abn0000184
   Roy-Charland A, 2017, AM J DRUG ALCOHOL AB, V43, P332, DOI 10.1080/00952990.2016.1209511
   SAUNDERS JB, 1993, ADDICTION, V88, P791, DOI 10.1111/j.1360-0443.1993.tb02093.x
   Schoenmakers TM, 2010, DRUG ALCOHOL DEPEN, V109, P30, DOI 10.1016/j.drugalcdep.2009.11.022
   Segawa T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01409
   Simon J, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00124
   Sinclair JMA, 2016, HUM PSYCHOPHARM CLIN, V31, P395, DOI 10.1002/hup.2549
   Smith GT, 2001, ADOLESCENTS, ALCOHOL, AND SUBSTANCE ABUSE: REACHING TEENS THROUGH BRIEF INTERVENTIONS, P109
   Soleymani A, 2020, ADDICT BEHAV, V100, DOI 10.1016/j.addbeh.2019.106117
   Thomsen KR, 2018, J BEHAV ADDICT, V7, P317, DOI 10.1556/2006.7.2018.22
   Thorberg FA, 2019, SUBST USE MISUSE, V54, P2380, DOI 10.1080/10826084.2019.1650773
   Townshend JM, 2001, PSYCHOPHARMACOLOGY, V157, P67, DOI 10.1007/s002130100764
   van Duijvenbode N, 2017, J INTELL DISABIL RES, V61, P255, DOI 10.1111/jir.12335
   van Hemel-Ruiter ME, 2016, DRUG ALCOHOL DEPEN, V159, P133, DOI 10.1016/j.drugalcdep.2015.12.005
   Vanderbruggen N, 2020, EUR ADDICT RES, V26, P309, DOI 10.1159/000510822
   von Hammerstein C, 2020, INT J METH PSYCH RES, V29, DOI 10.1002/mpr.1815
   White M.J., 2014, Personality and Individual Differences, V60, pS13, DOI [DOI 10.1016/J.PAID.2013.07.358, 10.1016/j.paid.2013.07.358]
   Wiers RW, 2007, PHARMACOL BIOCHEM BE, V86, P263, DOI 10.1016/j.pbb.2006.09.021
   Wiers RW, 2011, PSYCHOL SCI, V22, P490, DOI 10.1177/0956797611400615
   Wilcockson TDW, 2019, ADDICT BEHAV, V88, P175, DOI 10.1016/j.addbeh.2018.09.001
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   World Health Organization, 2018, Global status report on alcohol and health 2018
NR 108
TC 0
Z9 0
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 15
PY 2022
VL 3
AR 849840
DI 10.3389/frvir.2022.849840
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RP5
UT WOS:001023157500001
OA Green Published, gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Gardony, AL
   Okano, K
   Hughes, GI
   Kim, AJ
   Renshaw, KT
   Sipolins, A
AF Gardony, Aaron L.
   Okano, Kana
   Hughes, Gregory I.
   Kim, Alex J.
   Renshaw, Kai T.
   Sipolins, Aldis
TI Aided target recognition visual design impacts on cognition in simulated
   augmented reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE aided target recognition; augmented reality; virtual reality; target
   acquisition; decision making; situational awareness; eye tracking
ID CAD; PERFORMANCE; UNCERTAINTY
AB Aided target recognition (AiTR) systems, implemented in head-mounted and in-vehicle augmented reality (AR) displays, can enhance human performance in military operations. However, the visual appearance and delivery of AiTR may impact other important critical aspects of human performance like decision making and situational awareness (SA). Previous research suggests salient visual AR cueing, such as found in Computer-Aided Detection diagnostic systems, orient attention strongly toward cued targets leading to missed uncued targets, an effect which may be lessened by providing analog information about classification uncertainty and using less visually salient cueing techniques, such as soft highlighting. The objective of this research was to quantify the human performance impacts of two different types of AR AiTR visualizations in a simulated virtual reality defensive security task. Participants engaged in a visual camouflage discrimination task and a secondary SA Task in which participants observed and reported a peripheral human target. Critically, we manipulated the type of AiTR visualization used: 1) a traditional salient bounding box, 2) a softly glowing soft highlight, and 3) a baseline no-AiTR condition. Results revealed minimal impacts of the visual appearance of AiTR on target acquisition, target categorization, and SA but an observable reduction in user experience associated with soft highlight AiTR. Future research is needed to explore novel AiTR designs that effectively cue attention, intuitively and interpretably visualize uncertainty, and deliver acceptable user experience.
C1 [Gardony, Aaron L.; Hughes, Gregory I.] US Army Combat Capabil Dev Command DEVCOM Soldier, Natick, MA 01760 USA.
   [Gardony, Aaron L.; Okano, Kana; Hughes, Gregory I.; Kim, Alex J.] Ctr Appl Brain & Cognit Sci CABCS, Medford, MA 02155 USA.
   [Renshaw, Kai T.] Tufts Univ, Medford, MA USA.
   [Sipolins, Aldis] Draper, Cambridge, MA USA.
C3 Tufts University
RP Gardony, AL (corresponding author), US Army Combat Capabil Dev Command DEVCOM Soldier, Natick, MA 01760 USA.; Gardony, AL (corresponding author), Ctr Appl Brain & Cognit Sci CABCS, Medford, MA 02155 USA.
EM aaron.gardony.civ@army.mil
FU United States Army Combat Capabilities Development Command Soldier
   Center (DEVCOM SC); Tufts University [W911QY-19-02-0003]; Draper
   [W911QY-20-C-0078]
FX This work was supported by the United States Army Combat Capabilities
   Development Command Soldier Center (DEVCOM SC) under a cooperative
   agreement with Tufts University (W911QY-19-02-0003) and Draper
   (W911QY-20-C-0078). The views expressed in this article are solely those
   of the authors and do not reflect the official policies or positions of
   the Department of Army, the Department of Defense, or any other
   department or agency of the United States Government.
CR Army.mil, 2022, AI EN GROUND COMB VE
   Astrom U., 2011, CAMOUFLAGE GENERATOR
   Bailey R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559757
   Brunye T. T., 2017, FRONT VIRTUAL REAL
   Brunyé TT, 2017, INT J PSYCHOPHYSIOL, V120, P60, DOI 10.1016/j.ijpsycho.2017.07.008
   Cain MS, 2013, VIS COGN, V21, P899, DOI 10.1080/13506285.2013.843627
   Chen J. Y. C., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P279, DOI 10.1109/WIIAT.2008.52
   Cotter SA, 1999, OPTOMETRY VISION SCI, V76, P631, DOI 10.1097/00006324-199909000-00020
   Cunningham CA, 2017, ATTEN PERCEPT PSYCHO, V79, P679, DOI 10.3758/s13414-016-1250-0
   Dixon BJ, 2013, SURG ENDOSC, V27, P454, DOI 10.1007/s00464-012-2457-3
   Drew T, 2020, J EXP PSYCHOL-APPL, V26, P659, DOI 10.1037/xap0000277
   Drew T, 2012, ACAD RADIOL, V19, P1260, DOI 10.1016/j.acra.2012.05.013
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Entin EB, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P233
   Fenton JJ, 2007, NEW ENGL J MED, V356, P1399, DOI 10.1056/NEJMoa066099
   Fenton JJ, 2011, J NATL CANCER I, V103, P1152, DOI 10.1093/jnci/djr206
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Gardony AL, 2020, PROC SPIE, V11310, DOI 10.1117/12.2542699
   Geuss M. N., 2019, INTELLIGENT SQUAD WE, P11006, DOI [10.1117/12.2518405, DOI 10.1117/12.2518405]
   HART S G, 1988, P139
   Htc, 2021, VIV VR HEADS GAM MET
   Kapp S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062234
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kneusel RT, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3129669
   Kronnect, 2021, HIGHL PLUS PART EFF
   KRUPINSKI EA, 1993, PERCEPT PSYCHOPHYS, V53, P519, DOI 10.3758/BF03205200
   Larkin G. B., 2019, EMERGING RECOMMENDAT, DOI [10.31234/osf.io/w9qge, DOI 10.31234/OSF.IO/W9QGE]
   Lenth Russell V, 2024, CRAN
   Lu WQ, 2014, PROCEEDINGS OF CHINESE CHI 2014: SECOND INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2014), P5, DOI 10.1145/2592235.2592237
   Lu WQ, 2012, INT SYM MIX AUGMENT, P161, DOI 10.1109/ISMAR.2012.6402553
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   Matzen L. E., 2020, SAND202011021C SAND
   McNamara A, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P51
   Padilla L., 2023, WILEY STATSREF STAT, DOI [10.1002/9781118445112.stat08296, DOI 10.1002/9781118445112.STAT08296]
   Philpotts LE, 2009, RADIOLOGY, V253, P17, DOI 10.1148/radiol.2531090689
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Ratches JA, 2011, OPT ENG, V50, DOI 10.1117/1.3601879
   Reiner AJ, 2017, HUM FACTORS, V59, P242, DOI 10.1177/0018720816670768
   Sam.gov, 2022, ARTIF INTELL
   Schurgin MW, 2018, ATTEN PERCEPT PSYCHO, V80, P1035, DOI 10.3758/s13414-018-1522-y
   Singmann Henrik, 2024, CRAN
   Sultana F., 2020, Intelligent Computing: Image Processing Based Applications. Advances in Intelligent Systems and Computing (AISC 1157), P1, DOI 10.1007/978-981-15-4288-6_1
   Tombu M., 2016, DRDCRDDC2016R036
   Unity Technologies, 2021, Unity Real-Time Development Platform | 3D, 2D VR and AR Engine
   US Army TRADOC, 2018, TRADOC PAMPHL 525 3
   Valve Corporation, 2021, Steam VR
   Varjo, 2021, MOST ADV VIRT MIX RE
   Wickens C. D., 2005, Tech. Rep. AHFD-05-23/NASA
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [10.1007/978-3-319-24277-4, DOI 10.1007/978-3-319-24277-4]
   Yeh M, 2001, HUM FACTORS, V43, P355, DOI 10.1518/001872001775898269
NR 50
TC 0
Z9 1
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 6
PY 2022
VL 3
AR 982010
DI 10.3389/frvir.2022.982010
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XP2
UT WOS:001023313800001
OA gold
DA 2024-07-18
ER

PT J
AU Elor, A
   Conde, S
   Powell, M
   Robbins, A
   Chen, NN
   Kurniawan, S
AF Elor, Aviv
   Conde, Samantha
   Powell, Michael
   Robbins, Ash
   Chen, Nancy N.
   Kurniawan, Sri
TI Physical Therapist Impressions of Telehealth and Virtual Reality Needs
   Amidst a Pandemic
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE physical rehabilitation; physical therapy; immersive virtual reality;
   extended reality; metaverse; telehealth; remote care; COVID19
ID TELEREHABILITATION
AB Most physical therapists would agree that physical rehabilitation is difficult to perform remotely. Consequently, the global COVID-19 pandemic has forced many physical therapists and their clients to adapt to telehealth, especially with video conferencing. In this article, we ask: How has telehealth for physical rehabilitation evolved with the global pandemic and what are the largest technological needs, treatment methodologies, and patient barriers? With the increased widespread use of telehealth for physical therapy, we present a qualitative study towards examining the shortcomings of current physical therapy mediums and how to steer future virtual reality technologies to promote remote patient evaluation and rehabilitation. We interviewed 130 physical rehabilitation professionals across the United States through video conferencing during the COVID19 pandemic from July-August 2020. Interviews lasted 30-45 min using a semi-structured template developed from an initial pilot of 20 interviews to examine potential barriers, facilitators, and technological needs. Our findings suggest that physical therapists utilizing existing telehealth solutions have lost their ability to feel their patients' injuries, easily assess range of motion and strength, and freely move about to examine their movements when using telehealth. This makes it difficult to fully evaluate a patient and many feel that they are more of a "life coach" giving advice to a patient rather than a traditional in-person rehabilitation session. The most common solutions that emerged during the interviews include: immersive technologies which allow physical therapists and clients 1) to remotely walk around each other in 3D, 2) enable evidence-based measures, 3) automate documentation, and 4) provider clinical practice operation through the cloud. We conclude with a discussion on opportunities for immersive virtual reality towards telehealth for physical rehabilitation.
C1 [Elor, Aviv; Conde, Samantha; Kurniawan, Sri] Univ Calif Santa Cruz, Dept Computat Media, Santa Cruz, CA 95064 USA.
   [Elor, Aviv; Powell, Michael; Robbins, Ash] Immergo Labs, Dept Immers Res, Santa Cruz, CA 95060 USA.
   [Powell, Michael; Robbins, Ash] Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA USA.
   [Chen, Nancy N.] Univ Calif Santa Cruz, Dept Anthropol, Santa Cruz, CA USA.
C3 University of California System; University of California Santa Cruz;
   University of California System; University of California Santa Cruz;
   University of California System; University of California Santa Cruz
RP Elor, A (corresponding author), Univ Calif Santa Cruz, Dept Computat Media, Santa Cruz, CA 95064 USA.; Elor, A (corresponding author), Immergo Labs, Dept Immers Res, Santa Cruz, CA 95060 USA.
EM aelor@ucsc.edu
RI Elor, Aviv/AAR-3282-2020
OI Elor, Aviv/0000-0001-5356-3948
FU National Science Foundation [2037917]; CITRIS [2020-0000000044]; Banatao
   Institute at the University of California; University of California;
   Santa Cruz Global Community Health Wellbeings 2020 Fellows Program
FX & nbsp;This article is based upon work supported by the National Science
   Foundation under Grant No #2037917. Such work was also supported by the
   2020 Seed Fund Award 2020-0000000044 from CITRIS and the Banatao
   Institute at the University of California, a statewide research
   institute operated by the University of California to facilitate the
   real-world application of technological research. Additionally, AE was
   supported by the University of California, Santa Cruz Global Community
   Health Wellbeings 2020 Fellows Program. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of the National
   Science Foundation, University of California, and or the ARCS
   Foundation.
CR Albanese S., 2021, TELEHEALTH MED TODAY, V6, P299, DOI [10.30953/tmt.v6.299, DOI 10.30953/TMT.V6.299]
   APTA, 2019, POS TEL
   Axelsson E, 2020, JAMA PSYCHIAT, V77, P915, DOI 10.1001/jamapsychiatry.2020.0940
   Bland KA, 2020, PHYS THER, V100, P1713, DOI 10.1093/ptj/pzaa141
   Braunschweiger P., 2010, J CLIN RES BEST PRAC, V6, P1
   Chen CY, 1999, AM J OCCUP THER, V53, P171, DOI 10.5014/ajot.53.2.171
   Dantas LO, 2020, BRAZ J PHYS THER, V24, P381, DOI 10.1016/j.bjpt.2020.04.006
   Elor A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.585993
   Fram SM, 2013, QUAL REP, V18
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Hoffman HG, 2011, ANN BEHAV MED, V41, P183, DOI 10.1007/s12160-010-9248-7
   Kuether J, 2019, HSS J, V15, P221, DOI 10.1007/s11420-019-09715-w
   Lee AC, 2020, PHYS THER, V100, P1054, DOI 10.1093/ptj/pzaa079
   Moral-Muñoz JA, 2015, J STRENGTH COND RES, V29, P2661, DOI 10.1519/JSC.0000000000000896
   Ndumbe-Eyoh S, 2021, GLOB HEALTH PROMOT, V28, P7, DOI 10.1177/17579759211000975
   Nnakwe CC, 2018, TECHNOL INNOV, V19, P773, DOI 10.21300/19.4.2018.773
   Palacín-Marín F, 2013, SPINE, V38, P947, DOI 10.1097/BRS.0b013e318281a36c
   Powell MO, 2022, IEEE ACCESS, V10, P25621, DOI 10.1109/ACCESS.2022.3155179
   Reed ME, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.5873
   Schröder J, 2019, DISABIL REHABIL-ASSI, V14, P2, DOI 10.1080/17483107.2018.1503738
   Shaw Donald K, 2009, Cardiopulm Phys Ther J, V20, P13
   SIUIJS EM, 1993, PHYS THER, V73, P771, DOI 10.1093/ptj/73.11.771
   Smith AC, 2020, J TELEMED TELECARE, V26, P309, DOI 10.1177/1357633X20916567
   VandenBos GR, 2000, PROF PSYCHOL-RES PR, V31, P490, DOI 10.1037/0735-7028.31.5.490
   Wikipedia, 2021, COVID 19 PAND
   Yonter SJ, 2020, ARCH PHYS MED REHAB, V101, P2233, DOI 10.1016/j.apmr.2020.09.368
   Zischke C, 2021, J GLOB HEALTH, V11, DOI 10.7189/jogh.11.04072
NR 27
TC 1
Z9 1
U1 2
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 15
PY 2022
VL 3
AR 915332
DI 10.3389/frvir.2022.915332
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SK7
UT WOS:001021806900001
OA gold
DA 2024-07-18
ER

PT J
AU Drai-Zerbib, V
   Bernigaud, L
   Gaston-Bellegarde, A
   Boucheix, JM
   Baccino, T
AF Drai-Zerbib, Veronique
   Bernigaud, Lea
   Gaston-Bellegarde, Alexandre
   Boucheix, Jean-Michel
   Baccino, Thierry
TI Eye Movements During Comprehension in Virtual Reality: The Influence of
   a Change in Point of View Between Auditory and Visual Information in the
   Activation of a Mental Model
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; eye tracking; comprehension; multimodality; shift in
   narrative perspective
ID CONSTRUCTION; MEMORY; SHIFT
AB This paper provides new research perspectives in the field of multimodal comprehension (auditory crossing visual information) by using immersion and incorporating eye tracking in a virtual reality environment. The objective is to investigate the influence of a change in narrative perspective (point of view) during the activation of a mental model underlying comprehension between visual and auditory modalities. Twenty-eight participants, equipped with a headset SMI HMD HTC eye-tracking 250 Hz watched 16 visual scenes in virtual reality accompanied by their corresponding auditory narration. The change in perspective may occur either in the visual scenes or in listening. Mean fixations durations on typical objects of the visual scenes (Area of Interest) that were related to the perspective shift were analyzed as well as the free recall of narratives. We split each scene into three periods according to different parts of the narration (Before, Target, After), the target was where a shift in perspective could occur. Results shown that when a visual change of perspective occurred, mean fixation duration was shorter (compared to no change) for both Target and After. However, when auditory change of perspective occurred, no difference was found on Target, although during After, mean fixation duration was longer (compared to no change). In the context of 3D video visualization, it seems that auditory processing prevails over visual processing of verbal information: The visual change of perspective induces less visual processing of the Area of Interest (AOIs) included in the visual scene, but the auditory change in perspective leads to increased visual processing of the visual scene. Moreover, the analysis showed higher recall of information (verbatim and paraphrase) when an auditory change in perspective was coupled with no visual change of perspective. Thus, our results indicate a more effective integration of information when there is an inconsistency between the narration heard and viewed. A change in perspective, instead of creating comprehension and integration difficulties, seems to effectively raise the attention and induce a shorter visual inspection. These results are discussed in the context of cross-modal comprehension.
C1 [Drai-Zerbib, Veronique; Bernigaud, Lea; Gaston-Bellegarde, Alexandre; Boucheix, Jean-Michel] Univ Bourgogne, Lab LEAD CNRS, UMR5022, Dijon, France.
   [Baccino, Thierry] Univ Paris 08, LUTIN, Paris, France.
C3 Universite de Bourgogne; Centre National de la Recherche Scientifique
   (CNRS); CNRS - National Institute for Biology (INSB); Universite
   Paris-VIII
RP Drai-Zerbib, V (corresponding author), Univ Bourgogne, Lab LEAD CNRS, UMR5022, Dijon, France.
EM Veronique.Drai-Zerbib@u-bourgogne.fr
OI Drai-Zerbib, Veronique/0000-0002-5623-6229
FU Region Bourgogne Franche-Comte [G039]
FX Funding This work was partly supported by the Region Bourgogne
   Franche-Comte. ANER ReQuiem Grant G039.
CR ALBRECHT JE, 1993, J EXP PSYCHOL LEARN, V19, P1061, DOI 10.1037/0278-7393.19.5.1061
   Baccino T, 1998, EUR PSYCHOL, V3, P51, DOI 10.1027/1016-9040.3.1.51
   Baceviciute S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376872
   Baceviciute S, 2021, COMPUT EDUC, V164, DOI 10.1016/j.compedu.2020.104122
   Ballenghein U, 2019, COGN PROCESS, V20, P371, DOI 10.1007/s10339-018-0894-1
   BLACK JB, 1979, J VERB LEARN VERB BE, V18, P187, DOI 10.1016/S0022-5371(79)90118-X
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Cowan N., 1995, ATTENTION MEMORY INT
   Drai-Zerbib V, 2017, PSYCHOL FR, V62, P233, DOI 10.1016/j.psfr.2014.12.002
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fayol M., 2003, EDITIONS HACHETTE ED
   FLETCHER CR, 1990, J EXP PSYCHOL LEARN, V16, P233, DOI 10.1037/0278-7393.16.2.233
   Genette G., 1972, DISCOURS RECIT MODE, VVol. III, P183
   Gernsbacher M., 1990, Language comprehension as structure building
   Gernsbacher M.A., 1996, MODELS UNDERSTANDING, P289, DOI DOI 10.1162/0898929053747658
   GERNSBACHER MA, 1995, CAN PSYCHOL, V36, P49, DOI 10.1037/h0084720
   Graesser AC, 1997, ANNU REV PSYCHOL, V48, P163, DOI 10.1146/annurev.psych.48.1.163
   Gu X, 2016, CONSCIOUS COGN, V45, P159, DOI 10.1016/j.concog.2016.09.001
   Guichon N, 2008, SYSTEM, V36, P85, DOI 10.1016/j.system.2007.11.005
   HYONA J, 1994, READ RES QUART, V29, P77
   HYONA J, 1995, J EXP PSYCHOL LEARN, V21, P1365, DOI 10.1037/0278-7393.21.5.A
   HYONA J, 1990, ACTA PSYCHOL, V73, P259, DOI 10.1016/0001-6918(90)90026-C
   Hyona J., 1998, STRATEGIES PROCESSIN
   Johansson R, 2012, PSYCHOL MUSIC, V40, P339, DOI 10.1177/0305735610387777
   Johnson-Laird P. N., 1993, MODELES MENTAUX APPR
   JOHNSONLAIRD PN, 1980, COGNITIVE SCI, V4, P71, DOI 10.1207/s15516709cog0401_4
   Jungnickel E, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00306
   Kahneman D., 1973, Attention and effort
   KINTSCH W, 1988, PSYCHOL REV, V95, P163, DOI 10.1037/0033-295X.95.2.163
   KINTSCH W, 1978, PSYCHOL REV, V85, P363, DOI 10.1037/0033-295X.85.5.363
   Kintsch W., 1998, COMPREHENSION PARADI
   Kintsch W, 2011, TOP COGN SCI, V3, P346, DOI 10.1111/j.1756-8765.2010.01107.x
   LORCH RF, 1987, DISCOURSE PROCESS, V10, P63, DOI 10.1080/01638538709544659
   Lordanescu L, 2008, PSYCHON B REV, V15, P548, DOI 10.3758/PBR.15.3.548
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Makransky G, 2020, BRIT J EDUC TECHNOL, V51, P2079, DOI 10.1111/bjet.12954
   Makransky G, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214944
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mayer RE, 2014, COMPUTER GAMES FOR LEARNING: AN EVIDENCE-BASED APPROACH, P1
   Mayer RE, 2020, ETR&D-EDUC TECH RES, V68, P837, DOI 10.1007/s11423-020-09749-6
   Meyerhoff HS, 2016, MEM COGNITION, V44, P390, DOI 10.3758/s13421-015-0575-6
   MILLIS KK, 1995, DISCOURSE PROCESS, V20, P29, DOI 10.1080/01638539509544930
   Petersen GB, 2022, COMPUT EDUC, V179, DOI 10.1016/j.compedu.2021.104429
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Senkowski D, 2008, TRENDS NEUROSCI, V31, P401, DOI 10.1016/j.tins.2008.05.002
   Van der Burg E, 2008, J EXP PSYCHOL HUMAN, V34, P1053, DOI 10.1037/0096-1523.34.5.1053
NR 47
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 22
PY 2022
VL 3
AR 874054
DI 10.3389/frvir.2022.874054
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AG3
UT WOS:001019285100001
OA gold
DA 2024-07-18
ER

PT J
AU Khanal, S
   Medasetti, US
   Mashal, M
   Savage, B
   Khadka, R
AF Khanal, Shishir
   Medasetti, Uma Shankar
   Mashal, Mustafa
   Savage, Bruce
   Khadka, Rajiv
TI Virtual and Augmented Reality in the Disaster Management Technology: A
   Literature Review of the Past 11 years
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE disaster management; emergency response; virtual reality; augmented
   reality; mixed reality
ID BUILDING DAMAGE; RISK; EVACUATION; SYSTEM; VISUALIZATION; PREPAREDNESS;
   EARTHQUAKE; SIMULATION
AB This study presents a systematic review of the literature on virtual reality (VR), augmented reality (AR) and Mixed Reality (MR) used in disaster management. We consider the factors such as publication type, publication year, application domain, and technology used. We surveyed papers from 2009 to 2019 available in the Web of Science and Google Scholar database, and 84 research articles were selected for the review study. After an extensive review of the literature, it was found that the XR technology is applied extensively in computer simulation modeling, interaction techniques, training, infrastructure assessment and reconnaissance, and public awareness areas of disaster management. We found diverse advantages, opportunities, and challenges of XR usage for disaster management, which are discussed in detail. Furthermore, current research gaps in the field of XR technology for disaster management technology, which are needed to better support disaster management, are identified and discussed in an effort to provide direction to the future research.
C1 [Khanal, Shishir; Medasetti, Uma Shankar; Mashal, Mustafa; Savage, Bruce] Idaho State Univ, Dept Civil & Environm Engn, Gaming & Visualizat Lab, Pocatello, ID USA.
   [Khadka, Rajiv] Idaho State Univ, Dept Comp Sci, Pocatello, ID 83209 USA.
C3 Idaho; Idaho State University; Idaho; Idaho State University
RP Khadka, R (corresponding author), Idaho State Univ, Dept Comp Sci, Pocatello, ID 83209 USA.
EM rajivkhadka@isu.edu
CR Albayrak O., 2006, 2006 TECHNOLOGY MANA, P1742, DOI [10.1109/picmet.2006.296748, DOI 10.1109/PICMET.2006.296748]
   Alharthi S. A., 2018, P INT ISCRAM C
   Alharthi SA, 2018, PROCEEDINGS OF THE TECHNOLOGY, MIND, AND SOCIETY CONFERENCE (TECHMINDSOCIETY'18), DOI 10.1145/3183654.3183662
   Anderson A, 2021, VIRTUAL REAL-LONDON, V25, P147, DOI 10.1007/s10055-020-00448-4
   [Anonymous], 2020, Web of Science
   [Anonymous], 2020, Google Scholar
   Azhar S., 2011, LEADERSHIP MANAGEMEN, V11, P241, DOI [10.1061/(ASCE)LM.1943-5630.0000127, DOI 10.1061/(ASCE)LM.1943-5630.0000127]
   Bailie T, 2016, LECT NOTES ARTIF INT, V9744, P135, DOI 10.1007/978-3-319-39952-2_14
   Bang J, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P470, DOI 10.1109/ISMAR-Adjunct.2019.00126
   Behzadan AH, 2015, ADV ENG INFORM, V29, P252, DOI 10.1016/j.aei.2015.03.005
   Berberich M., 2009, MTS IEEE BILOXI MARI, DOI [10.23919/oceans.2009.5422170, DOI 10.23919/OCEANS.2009.5422170]
   Bernhardt J, 2019, B AM METEOROL SOC, V100, P1897, DOI 10.1175/BAMS-D-17-0326.1
   Borrego M, 2014, J ENG EDUC, V103, P45, DOI 10.1002/jee.20038
   Borrego M, 2009, J ENG EDUC, V98, P53, DOI 10.1002/j.2168-9830.2009.tb01005.x
   Brewster S., 2003, P CHINZ 2003 4 ANN C, P3, DOI [10.1145/2331829.2331830, DOI 10.1145/2331829.2331830]
   Brown J., 1989, Educational Researcher, V18, P32, DOI [DOI 10.3102/0013189X018001032, 10.3102/0013189X018001032, DOI 10.2307/1176008]
   Caballero AR, 2019, PROCEEDINGS OF THE 2019 4TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (INCIT), P60, DOI 10.1109/incit.2019.8912094
   Caballero AR, 2018, PROCEEDINGS OF 4TH INTERNATIONAL CONFERENCE ON HCI AND UX (CHIUXID 2018), P31, DOI 10.1145/3205946.3205950
   Cao LJ, 2019, COMPUT HUM BEHAV, V90, P37, DOI 10.1016/j.chb.2018.08.041
   Carlson G, 2019, ADV INTELL SYST, V785, P108, DOI 10.1007/978-3-319-93882-0_11
   Caroca J, 2016, J E-LEARN KNOWL SOC, V12, P81
   Chen YF, 2014, SIMULAT GAMING, V45, P732, DOI 10.1177/1046878113495354
   Chengyun H., 2018, 7 INT C ADV MAT COMP
   Choi G, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI 2019), P1558, DOI 10.1109/CSCI49370.2019.00295
   Chrastil ER, 2013, J EXP PSYCHOL LEARN, V39, P1520, DOI 10.1037/a0032382
   Chrastil ER, 2012, PSYCHON B REV, V19, P1, DOI 10.3758/s13423-011-0182-x
   Cimellaro GP, 2019, ADVANCES IN ENGINEERING MATERIALS, STRUCTURES AND SYSTEMS: INNOVATIONS, MECHANICS AND APPLICATIONS, P1921
   Dai F, 2011, J NONDESTRUCT EVAL, V30, P201, DOI 10.1007/s10921-011-0108-6
   Danial SN, 2019, FIRE TECHNOL, V55, P1057, DOI 10.1007/s10694-019-00819-7
   Davis I., 2003, Proceedings of the 4th International Conference on Seismology and Earthquake Engineering (SEE 4), IIEES, P1
   de Jong T., 2008, Handbook of Research on Educational Communications and Technology, V3rd, P457
   del Amo IF, 2018, COMPUT IND, V103, P47, DOI 10.1016/j.compind.2018.08.007
   Demir F., 2017, J USABILITY STUD
   Dhanasree KS, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P924, DOI 10.1109/ICCONS.2018.8662900
   Dong SY, 2013, AUTOMAT CONSTR, V33, P24, DOI 10.1016/j.autcon.2012.09.005
   Dorozhkin D, 2017, SURG ENDOSC, V31, P3527, DOI 10.1007/s00464-016-5379-7
   Farra S, 2019, DISASTER MED PUBLIC, V13, P301, DOI 10.1017/dmp.2018.58
   Fischer Joel E., 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P572, DOI 10.1007/978-3-642-33542-6_75
   Girau E, 2019, IEEE ENG MED BIO, P5690, DOI [10.1109/embc.2019.8856777, 10.1109/EMBC.2019.8856777]
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P944, DOI [10.1109/vr.2019.8797895, 10.1109/VR.2019.8797895]
   Haynes P, 2018, ENVIRON MODELL SOFTW, V109, P380, DOI 10.1016/j.envsoft.2018.05.012
   Hays R., 2012, Simulation fidelity in training system design: Bridging the gap between reality and training
   Hsu Edbert B, 2013, PLoS Curr, V5, DOI 10.1371/currents.dis.1ea2b2e71237d5337fa53982a38b2aff
   Iguchi K, 2016, INT CONF INFORM COMM, P158
   Ilmi N, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON DATA AND SOFTWARE ENGINEERING (ICODSE)
   Inclusion Made Easy, 2012, TECH REP
   Ingels Don M., 1985, What Every Engineer Should Know about Computer Modeling and Simulation, DOI 10.1201/9781003209997
   Iuppa N.V., 2006, STORY SIMULATIONS SE
   Jaiswal RK, 2009, NAT HAZARDS, V48, P245, DOI 10.1007/s11069-008-9261-3
   Jeon SG, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364268
   Juang J-N, 1992, ARC, DOI [10.2514/6.1992-4386, DOI 10.2514/6.1992-4386]
   Kankaanranta M.H., 2008, Design and Use of Serious Games
   Kawai J, 2016, INTERACT TECHNOL SMA, V13, P186, DOI 10.1108/ITSE-01-2016-0001
   Khadka R., 2022, HUMAN COMPUTER INTER, P1, DOI [10.2174/9789815036398122010004, DOI 10.2174/9789815036398122010004]
   Kim W, 2016, NAT HAZARD EARTH SYS, V16, P287, DOI 10.5194/nhess-16-287-2016
   Koutitas G, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P299, DOI 10.1145/3316782.3321542
   LaLone N, 2019, HALFWAY TO THE FUTURE SYMPOSIUM (HTTF 2019), DOI 10.1145/3363384.3363466
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Leonard H.B., 2009, Managing crisis: Responses to large-scale emergencies
   Lettieri E, 2009, DISASTER PREV MANAG, V18, P117, DOI 10.1108/09653560910953207
   Li Y, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P321, DOI 10.1109/ISMAR-Adjunct.2019.00-20
   Liang H, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284417
   Liang ZP, 2019, IEEE ACCESS, V7, P118639, DOI 10.1109/ACCESS.2019.2934990
   Lochhead I, 2019, INT J DIGIT EARTH, V12, P190, DOI 10.1080/17538947.2018.1425489
   Longo F, 2019, COMPUT IND, V105, P99, DOI 10.1016/j.compind.2018.12.003
   Lourdeaux D., 2019, IVA 2019 P 19 ACM IN, DOI [10.1145/3308532.3329418, DOI 10.1145/3308532.3329418]
   Lovreglio R, 2018, ADV ENG INFORM, V38, P670, DOI 10.1016/j.aei.2018.08.018
   Luchetti G, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6020041
   Luk BL, 2018, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON NUCLEAR ENGINEERING, 2018, VOL 8
   Lusk S. M., 1993, TIME PRESSURE STRESS
   Lutz RR, 2018, PROC INT SYMP SOFTW, P70, DOI 10.1109/ISSRE.2018.00018
   Macchione F, 2019, ENVIRON MODELL SOFTW, V111, P510, DOI 10.1016/j.envsoft.2018.11.005
   MacLean K.E., 2008, REV HUMAN FACTORS ER, V4, P149, DOI [DOI 10.1518/155723408X342826, 10.1518/155723408X342826]
   Markwart H, 2019, INT J DISAST RISK RE, V38, DOI 10.1016/j.ijdrr.2019.101235
   Massaâbi M, 2018, COMM COM INF SC, V840, P69, DOI 10.1007/978-3-319-93596-6_5
   Matsas E, 2017, INT J INTERACT DES M, V11, P139, DOI 10.1007/s12008-015-0259-2
   Molka-Danielsen J, 2018, PR IEEE INT CONF TEA, P408, DOI 10.1109/TALE.2018.8615147
   Nguyen VT, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P199, DOI 10.1109/AIVR46125.2019.00042
   Nilsson D, 2018, FIRE SAFETY J, V97, P119, DOI 10.1016/j.firesaf.2017.07.001
   Oh K, 2019, J MECH SCI TECHNOL, V33, P1381, DOI 10.1007/s12206-019-0239-8
   Ono Kinji, 2008, Progress in Informatics, P99, DOI 10.2201/NiiPi.2008.5.10
   Oyama E, 2016, ADV ROBOTICS, V30, P151, DOI 10.1080/01691864.2015.1113888
   Park S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112239
   Passos C, 2016, CHEM ENGINEER TRANS, V53, P217, DOI 10.3303/CET1653037
   Phillips B., 2012, Introduction to emergency management
   Phillips BrendaD., 2009, Disaster Recovery
   Pierdicca R, 2016, COMPUT GEOSCI-UK, V95, P67, DOI 10.1016/j.cageo.2016.06.018
   Preece J., 2015, Interaction Design: Beyond Human Computer Interaction, V4th
   Rodríguez JL, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030355
   Rojahn C., 2005, ATC 20 FIELD MANUAL
   Ronchi E, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1873
   Rossler KL, 2019, NURS EDUC, V44, P88, DOI 10.1097/NNE.0000000000000551
   Sampaio AZ, 2010, AUTOMAT CONSTR, V19, P819, DOI 10.1016/j.autcon.2010.05.006
   Sermet Y, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338550
   Sermet Y, 2019, EARTH SCI INFORM, V12, P541, DOI 10.1007/s12145-019-00398-9
   Shaluf I.M., 2007, Disaster Prev. Manag., V16, P704, DOI [DOI 10.1111/gcb.12581, 10.1108/09653560710837019, DOI 10.1108/09653560710837019]
   Sharma S, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR HUMAN-LIKE INTELLIGENCE (CIHLI), P1
   Shewaga R, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180660
   Shi Y., 2019, COMPUTING CIVIL ENG, DOI [10.1061/9780784482421.020, DOI 10.1061/9780784482421.020]
   Sinha R., 2012, 15 WORLD C EARTHQ EN
   Stipani D., 2010, 6 INT C FOR FIR RES
   Structural Engineers Association of Hawaii, 2006, ATC 20 POST BUILD SA
   Subhedar S., 2019, COMMUN COMPUT INF SC, V2019, P521, DOI [10.1007/978-3-030-23528-4_71, DOI 10.1007/978-3-030-23528-4_71]
   Suhail M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1415, DOI 10.1109/vr.2019.8798280
   Taster, 2022, GOOGL SCHOL WEB SCI
   Tena-Chollet F, 2017, SAFETY SCI, V97, P144, DOI 10.1016/j.ssci.2016.03.025
   Tian P, 2019, 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P422, DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00090
   Tsai MK, 2013, J ENVIRON RADIOACTIV, V118, P15, DOI 10.1016/j.jenvrad.2012.11.001
   Vassell Mark, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P976, DOI 10.1109/CCNC.2016.7444921
   Veas E, 2013, PERS UBIQUIT COMPUT, V17, P1515, DOI 10.1007/s00779-012-0597-z
   Wang C, 2019, INT J DISAST RISK RE, V39, DOI 10.1016/j.ijdrr.2019.101139
   Wani A. R., 2013, INT C REC TRENDS COM
   Wasson C.S., 2016, SYSTEM ENG ANAL DESI
   Wendler J., 2019, Research for All, V3, P18, DOI DOI 10.18546/RFA.03.1
   Xiong C, 2020, AUTOMAT CONSTR, V109, DOI 10.1016/j.autcon.2019.102994
   Xu JX, 2018, ENTERTAIN COMPUT, V27, P23, DOI 10.1016/j.entcom.2018.03.002
   Yu MZ, 2018, GEOSCIENCES, V8, DOI 10.3390/geosciences8050165
   Zhang YH, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8050209
NR 118
TC 17
Z9 17
U1 11
U2 24
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 11
PY 2022
VL 3
AR 843195
DI 10.3389/frvir.2022.843195
PG 21
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZW0
UT WOS:001019274700001
OA gold
DA 2024-07-18
ER

PT J
AU Leonardis, D
   Gabardi, M
   Barsotti, M
   Frisoli, A
AF Leonardis, Daniele
   Gabardi, Massimiliano
   Barsotti, Michele
   Frisoli, Antonio
TI Discrete Cutaneous Feedback for Reducing Dimensions of Wearable Haptic
   Devices
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptic; cutaneous; feedback; touch; virtual; manipulation; discrete;
   wearable
ID FORCE; REALITY; GRIP
AB In this article, we explore alternative cutaneous haptic feedback for rendering modulation of the grasping force. The aim of the study was to reduce power requirements and in turn dimensions of the actuators, in wearable devices applied to virtual or teleoperated manipulation. This is critical in certain rehabilitation or training scenarios where haptics should not interfere with dexterity of the user. In the study, we experimented discrete, pulsed cutaneous force feedback and compared it with conventional continuous proportional feedback, in a virtual pick and place task. We made use of wearable thimbles based on voice coil actuators in order to provide high-quality, low-noise haptic feedback to the participants. The evaluation was performed on the basis of both objective measurements of task performance (measured virtual forces and correct ratio) and a questionnaire evaluating participants' preferences for the different feedback conditions. On the basis of the obtained results, in the article, we discuss the possibility of providing high-frequency, discretized cutaneous feedback only, driven by modulation of the grasping force. The opportunity is to reduce volume and mass of the actuators and also to consider alternative design solutions, due to the different requirements in terms of static and high-frequency components of the output force.
C1 [Leonardis, Daniele; Gabardi, Massimiliano; Barsotti, Michele; Frisoli, Antonio] Scuola Super Sant Anna, Inst Mech Intelligence, Percro Lab, Pisa, Italy.
C3 Scuola Superiore Sant'Anna
RP Leonardis, D (corresponding author), Scuola Super Sant Anna, Inst Mech Intelligence, Percro Lab, Pisa, Italy.
EM d.leonardis@santannapisa.it
FU project "TELOS-Tailored neurorehabilitation thErapy via multidomain data
   anaLytics and adapative seriOus games for children with cerebral palSy"
   [CUP J52F20001040002]
FX This work was supported by the project "TELOS-Tailored
   neurorehabilitation thErapy via multidomain data anaLytics and adapative
   seriOus games for children with cerebral palSy", which is funded under
   the call "Bando Ricerca Salute 2018" of Tuscany Region, Italy (CUP
   J52F20001040002).
CR Basdogan C, 2002, HUM FAC ER, P117
   Bensmaïa SJ, 2000, J ACOUST SOC AM, V108, P1236, DOI 10.1121/1.1288937
   Bergamasco M, 2006, ADV ROBOTICS, V20, P367, DOI 10.1163/156855306776014367
   Bortone I, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00771-6
   Bortone I, 2017, INT C REHAB ROBOT, P1094, DOI 10.1109/ICORR.2017.8009395
   Caldwell DG, 1997, IEEE INT CONF ROBOT, P2491, DOI 10.1109/ROBOT.1997.619335
   Cappello L, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00736-9
   Chinello F, 2015, IEEE ASME INT C ADV, P293, DOI 10.1109/AIM.2015.7222547
   Cipriani C, 2014, EXP BRAIN RES, V232, P3421, DOI 10.1007/s00221-014-4024-8
   Clemente F, 2016, IEEE T NEUR SYS REH, V24, P1314, DOI 10.1109/TNSRE.2015.2500586
   COLE KJ, 1988, J NEUROPHYSIOL, V60, P1513, DOI 10.1152/jn.1988.60.4.1513
   Fani S, 2018, IEEE T HAPTICS, V11, P304, DOI 10.1109/TOH.2017.2708717
   Gabardi M, 2018, LECT NOTES COMPUT SC, V10894, P313, DOI 10.1007/978-3-319-93399-3_28
   Gabardi M, 2016, IEEE HAPTICS SYM, P140, DOI 10.1109/HAPTICS.2016.7463168
   Gallo S, 2015, FRONT ROBOT AI, DOI 10.3389/frebt.2015.DDD25
   Gutiérrez A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062476
   Kildal J., INT C MULTIMODAL INT, DOI DOI 10.1145/1891903.1891931
   Klamt T, 2020, J FIELD ROBOT, V37, P889, DOI 10.1002/rob.21895
   Kuchenbecker KJ, 2010, LECT NOTES COMPUT SC, V6191, P189, DOI 10.1007/978-3-642-14064-8_28
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   Kurihara Y, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P187, DOI 10.1109/WHC.2013.6548406
   Leonardis Daniele, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P389, DOI 10.1007/978-3-030-58147-3_43
   Leonardis D, 2021, ACTUATORS, V10, DOI 10.3390/act10090211
   Leonardis D, 2017, IEEE T HAPTICS, V10, P305, DOI 10.1109/TOH.2016.2640291
   Leonardis D, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P388, DOI 10.1109/WHC.2015.7177743
   Maisto M, 2017, IEEE T HAPTICS, V10, P511, DOI 10.1109/TOH.2017.2691328
   Niemeyer G, 2005, SPR TRA ADV ROBOT, V18, P41
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Pacchierotti C, 2016, IEEE T BIO-MED ENG, V63, P278, DOI 10.1109/TBME.2015.2455932
   Prattichizzo D, 2012, IEEE T HAPTICS, V5, P289, DOI [10.1109/TOH.2012.15, 10.1109/ToH.2012.15]
   Robles-De-La-Torre G, 2001, NATURE, V412, P445, DOI 10.1038/35086588
   Schorr SB, 2013, IEEE INT CONF ROBOT, P2341, DOI 10.1109/ICRA.2013.6630894
   Solazzi Massimiliano, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P129, DOI 10.1109/HAPTIC.2010.5444667
   Stepp CE, 2012, IEEE T NEUR SYS REH, V20, P31, DOI 10.1109/TNSRE.2011.2170856
   Stronski Paul., 2018, Carnegie Endowment for International Peace
   Visell Y, 2014, LECT NOTES COMPUT SC, V8618, P478, DOI 10.1007/978-3-662-44193-0_60
   Wang DX, 2020, IEEE T IND ELECTRON, V67, P610, DOI 10.1109/TIE.2019.2920602
   WESTLING G, 1987, EXP BRAIN RES, V66, P128
   Wiertlewski M, 2011, IEEE T ROBOT, V27, P461, DOI 10.1109/TRO.2011.2132830
   Yau JM, 2009, CURR BIOL, V19, P561, DOI 10.1016/j.cub.2009.02.013
NR 40
TC 1
Z9 1
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 2
PY 2022
VL 3
AR 820266
DI 10.3389/frvir.2022.820266
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TZ8
UT WOS:001021848100001
OA gold
DA 2024-07-18
ER

PT J
AU Kim, J
   Palmisano, S
   Luu, W
   Iwasaki, S
AF Kim, Juno
   Palmisano, Stephen
   Luu, Wilson
   Iwasaki, Shinichi
TI Effects of Linear Visual-Vestibular Conflict on Presence, Perceived
   Scene Stability and Cybersickness in the Oculus Go and Oculus Quest
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual-reality; presence; cybersickness; motion sickness; vestibular;
   head mounted displays
ID TORSO ROTATION EXPERIMENTS; MOTION SICKNESS; VIRTUAL-REALITY; MYOGENIC
   POTENTIALS; ADAPTATION; RESPONSES; LATENCY; NEURONS; RIFT
AB Humans rely on multiple senses to perceive their self-motion in the real world. For example, a sideways linear head translation can be sensed either by lamellar optic flow of the visual scene projected on the retina of the eye or by stimulation of vestibular hair cell receptors found in the otolith macula of the inner ear. Mismatches in visual and vestibular information can induce cybersickness during head-mounted display (HMD) based virtual reality (VR). In this pilot study, participants were immersed in a virtual environment using two recent consumer-grade HMDs: the Oculus Go (3DOF angular only head tracking) and the Oculus Quest (6DOF angular and linear head tracking). On each trial they generated horizontal linear head oscillations along the interaural axis at a rate of 0.5 Hz. This head movement should generate greater sensory conflict when viewing the virtual environment on the Oculus Go (compared to the Quest) due to the absence of linear tracking. We found that perceived scene instability always increased with the degree of linear visual-vestibular conflict. However, cybersickness was not experienced by 7/14 participants, but was experienced by the remaining participants in at least one of the stereoscopic viewing conditions (six of whom also reported cybersickness in monoscopic viewing conditions). No statistical difference in spatial presence was found across conditions, suggesting that participants could tolerate considerable scene instability while retaining the feeling of being there in the virtual environment. Levels of perceived scene instability, spatial presence and cybersickness were found to be similar between the Oculus Go and the Oculus Quest with linear tracking disabled. The limited effect of linear coupling on cybersickness, compared with its strong effect on perceived scene instability, suggests that perceived scene instability may not always be associated with cybersickness. However, perceived scene instability does appear to provide explanatory power over the cybersickness observed in stereoscopic viewing conditions.
C1 [Kim, Juno; Luu, Wilson] Univ New South Wales, Sch Optometry & Vis Sci, Sydney, NSW, Australia.
   [Palmisano, Stephen] Univ Wollongong, Sch Psychol, Wollongong, NSW, Australia.
   [Iwasaki, Shinichi] Nagoya City Univ, Grad Sch Med Sci, Dept Otolaryngol, Nagoya, Japan.
C3 University of New South Wales Sydney; University of Wollongong; Nagoya
   City University
RP Kim, J (corresponding author), Univ New South Wales, Sch Optometry & Vis Sci, Sydney, NSW, Australia.
EM juno.kim@unsw.edu.au
RI ; Palmisano, Stephen/O-1553-2018
OI Kim, Juno/0000-0003-1300-9875; Palmisano, Stephen/0000-0002-9140-5681
FU Australian Research Council (ARC) Discovery Project [DP210101475];
   Grants-in-Aid for Scientific Research [21H03088] Funding Source: KAKEN
FX This work was supported by Australian Research Council (ARC) Discovery
   Project (DP210101475).
CR Adelstein B. D., 2003, P HUMAN FACTORS ERGO, V47, P2083, DOI [DOI 10.1177/1541931203047020, DOI 10.1177/154193120304702001]
   Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   [Anonymous], 1975, Motion sickness
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Ash A, 2011, PERCEPTION, V40, P155, DOI 10.1068/p6837
   Bokare P. S., 2016, WORLD C TRANSP RES W, P10
   Bouyer LJG, 1996, J VESTIBUL RES-EQUIL, V6, P367, DOI 10.1016/0957-4271(96)00068-7
   Bouyer LJG, 1996, J VESTIBUL RES-EQUIL, V6, P387, DOI 10.1016/0957-4271(96)00070-5
   Bouyer LJG, 1996, J VESTIBUL RES-EQUIL, V6, P377, DOI 10.1016/0957-4271(96)00069-9
   BRONSTEIN AM, 1988, EXP BRAIN RES, V71, P406
   Chen E, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00004
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   COLEBATCH JG, 1994, J NEUROL NEUROSUR PS, V57, P190, DOI 10.1136/jnnp.57.2.190
   Collewijn H, 2000, J NEUROPHYSIOL, V84, P376, DOI 10.1152/jn.2000.84.1.376
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Curthoys IS, 2006, EXP BRAIN RES, V175, P256, DOI 10.1007/s00221-006-0544-1
   Fujimoto C, 2018, CLIN NEUROPHYSIOL, V129, P238, DOI 10.1016/j.clinph.2017.11.006
   Fujimoto K, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.581920
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Honson V, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00485
   Ijsselsteijn W, 2001, PRESENCE-TELEOP VIRT, V10, P298, DOI 10.1162/105474601300343621
   Iwasaki S, 2007, NEUROLOGY, V68, P1227, DOI 10.1212/01.wnl.0000259064.80564.21
   Iwasaki S, 2015, ANN OTO RHINOL LARYN, V124, P458, DOI 10.1177/0003489414564997
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kim J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00248
   Kim J, 2014, J VISION, V14, DOI 10.1167/14.5.5
   Kim J, 2010, EXP BRAIN RES, V202, P355, DOI 10.1007/s00221-009-2137-2
   Kim J, 2008, BRAIN RES BULL, V77, P335, DOI 10.1016/j.brainresbull.2008.09.011
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Luu W., 2019, P SIGGRAPH AS SIGGRA, DOI [10.1145/3355056.3364590, DOI 10.1145/3355056.3364590]
   Mania Katerina., 2004, Proceedings of the 1st Symposium on Applied Perception in Graphics and Visualization, APGV '04, P39, DOI [10.1145/1012551.1012559, DOI 10.1145/1012551.1012559]
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   MUROFUSHI T, 1995, EXP BRAIN RES, V103, P174
   Ohara M, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520982317
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Polcar J., 2015, MM Science Journal, P613, DOI [DOI 10.17973/MMSJ.2015_06_201516, 10.17973/MMSJ.2015_06_201516]
   Prothero J.D., 1998, The role of rest frames in vection, presence and motion sickness
   REASON J, 1978, APPL ERGON, V9, P163, DOI 10.1016/0003-6870(78)90008-X
   Riva G, 2000, TELEMED J E-HEALTH, V6, P327, DOI 10.1089/153056200750040183
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   VOGEL H, 1982, EUR J APPL PHYSIOL, V48, P399, DOI 10.1007/BF00430230
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wilke C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054925
   Xie CH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P53, DOI 10.1145/3307650.3322247
   Xie CH, 2019, INT S HIGH PERF COMP, P609, DOI 10.1109/HPCA.2019.00013
NR 53
TC 8
Z9 8
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2021
VL 2
AR 582156
DI 10.3389/frvir.2021.582156
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XD7
UT WOS:001023302300001
OA gold
DA 2024-07-18
ER

PT J
AU Rockstroh, C
   Blum, J
   Hardt, V
   Göritz, AS
AF Rockstroh, Christoph
   Blum, Johannes
   Hardt, Veronique
   Goeritz, Anja S.
TI Design and Evaluation of a Virtual Restorative Walk With Room-Scale
   Virtual Reality and Impossible Spaces
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; mental health; perceived restorativeness; attention
   restoration; walking; room-scale; nature walk
ID IMMERSIVE TECHNOLOGY; STRESS; ENVIRONMENTS; ATTENTION; RECOVERY;
   EXERCISE; BENEFITS; ENHANCE
AB Nature walks are an effective and popular means to replenish fatigued mental resources. Alas, nature walks are not always accessible due to a lack of time or limited availability. We report on the design and pilot test of a room-scale virtual reality (VR) application that makes use of actual walking and impossible spaces to simulate dynamic restorative walks. We conducted a randomized controlled experiment in VR using a between-subjects design. Thirty-one participants went for an 8-min virtual walk either in a fixed virtual restorative environment (control condition) or in the proposed dynamic virtual restorative environment (treatment condition). The treatment condition with the proposed room-scale approach yielded increased user involvement, higher present moment awareness, increased perceived restorativeness of the experience, better subjective restoration, and an improved positive affect. Behavioral analysis showed that the proposed approach led to a reduced walking speed over the course of the walking exercise. The results suggest that room-scale VR in conjunction with virtual restorative environments and impossible spaces can be used to create sophisticated virtual restorative walks in confined spaces. Future research and development are needed to further establish the effects, to identify moderating and mediating factors and to investigate such VR applications in relevant real-world contexts.
C1 [Rockstroh, Christoph; Blum, Johannes; Hardt, Veronique; Goeritz, Anja S.] Albert Ludwigs Univ Freiburg, Dept Occupat & Consumer Psychol, Freiburg, Germany.
C3 University of Freiburg
RP Rockstroh, C (corresponding author), Albert Ludwigs Univ Freiburg, Dept Occupat & Consumer Psychol, Freiburg, Germany.
EM christoph.rockstroh@psychologie.uni-freiburg.de
OI Blum, Johannes/0000-0003-1368-1573
FU Baden-Wuerttemberg Ministry of Science, Research and Art; University of
   Freiburg
FX The article processing charge was funded by the Baden-Wuerttemberg
   Ministry of Science, Research and Art and the University of Freiburg in
   the funding programme Open Access Publishing.
CR Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Annerstedt M, 2013, PHYSIOL BEHAV, V118, P240, DOI 10.1016/j.physbeh.2013.05.023
   Aspinall P, 2015, BRIT J SPORT MED, V49, P272, DOI 10.1136/bjsports-2012-091877
   Berman MG, 2008, PSYCHOL SCI, V19, P1207, DOI 10.1111/j.1467-9280.2008.02225.x
   Berto R, 2014, BEHAV SCI-BASEL, V4, P394, DOI 10.3390/bs4040394
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Bodin M, 2003, PSYCHOL SPORT EXERC, V4, P141, DOI 10.1016/S1469-0292(01)00038-3
   Bowler DE, 2010, BMC PUBLIC HEALTH, V10, DOI 10.1186/147-2458-10-456
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Calogiuri G, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02321
   Calogiuri G, 2016, WORK, V53, P99, DOI 10.3233/WOR-152219
   Calogiuri G, 2015, PERCEPT MOTOR SKILL, V121, P350, DOI 10.2466/06.PMS.121c17x0
   Capaldi Colin A., 2015, International Journal of Wellbeing, V5, P1, DOI DOI 10.5502/IJW.V5I4.449
   Chung K, 2018, J MED INTERNET RES, V20, DOI 10.2196/11152
   Coon JT, 2011, ENVIRON SCI TECHNOL, V45, P1761, DOI 10.1021/es102947t
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   de Kort YAW, 2006, J ENVIRON PSYCHOL, V26, P309, DOI 10.1016/j.jenvp.2006.09.001
   Field A., 2013, DISCOVERING STAT USI
   Gidlow CJ, 2016, J ENVIRON PSYCHOL, V45, P22, DOI 10.1016/j.jenvp.2015.11.003
   Hanson S, 2015, BRIT J SPORT MED, V49, P710, DOI 10.1136/bjsports-2014-094157
   Hartig T, 1997, SCAND HOUS PLAN RES, V14, P175, DOI 10.1080/02815739708730435
   Hug S., 2008, International Journal of Fitness, V4, P25
   Hug SM, 2009, HEALTH PLACE, V15, P971, DOI 10.1016/j.healthplace.2009.03.002
   Janeh O., 2019, P 2019 ACM S APPL PE, P9, DOI DOI 10.1145/3343036.3343119
   Kaplan R., 1989, EXPERIENCE NATURE PS
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kaplan S, 2010, PERSPECT PSYCHOL SCI, V5, P43, DOI 10.1177/1745691609356784
   Korpela K.M., 2016, Ecopsychology, V8, P8, DOI DOI 10.1089/ECO.2015.0070
   Korpela KM, 2008, HEALTH PLACE, V14, P636, DOI 10.1016/j.healthplace.2007.10.008
   Lahart I, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16081352
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Li DY, 2016, LANDSCAPE URBAN PLAN, V148, P149, DOI 10.1016/j.landurbplan.2015.12.015
   Liszio S, 2018, ANN REV CYBERTHERAPY, V16, P87
   Marselle M.R., 2014, Ecopsychology, V6, P134, DOI [DOI 10.1089/ECO.2014.0027, 10.1089/eco.2014.0027]
   Mattila O, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106295
   Mayer FS, 2009, ENVIRON BEHAV, V41, P607, DOI 10.1177/0013916508319745
   McMahan Ryan P., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P59, DOI 10.1007/978-3-319-39907-2_6
   Ohly H, 2016, J TOXICOL ENV HEAL B, V19, P305, DOI 10.1080/10937404.2016.1196155
   Pretty J, 2005, INT J ENVIRON HEAL R, V15, P319, DOI 10.1080/09603120500155963
   Pretty J., 2005, COUNTRYSIDE HLTH WEL
   Pritchard A, 2020, J HAPPINESS STUD, V21, P1145, DOI 10.1007/s10902-019-00118-6
   Rockstroh C, 2020, J MEDIA PSYCHOL-GER, V32, P176, DOI 10.1027/1864-1105/a000270
   Rockstroh C, 2019, INT J HUM-COMPUT ST, V130, P209, DOI 10.1016/j.ijhcs.2019.06.011
   Roe J, 2011, HEALTH PLACE, V17, P103, DOI 10.1016/j.healthplace.2010.09.003
   Sakuragi Sokichi, 2006, Journal of Physiological Anthropology, V25, P281, DOI 10.2114/jpa2.25.281
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Tinwell A, 2015, UNCANNY VALLEY IN GAMES AND ANIMATION, P1
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Villani D, 2012, CYBERPSYCH BEH SOC N, V15, P24, DOI 10.1089/cyber.2011.0141
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
NR 54
TC 1
Z9 1
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 20
PY 2020
VL 1
AR 598282
DI 10.3389/frvir.2020.598282
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YU9
UT WOS:001023345700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Seesjärvi, E
   Laine, M
   Kasteenpohja, K
   Salmi, J
AF Seesjarvi, Erik
   Laine, Matti
   Kasteenpohja, Kaisla
   Salmi, Juha
TI Assessing goal-directed behavior in virtual reality with the
   neuropsychological task EPELI: children prefer head-mounted display but
   flat screen provides a viable performance measure for remote testing
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE prospective memory; ecological validity; executive functions; online
   testing; naturalistic task; serious gaming
ID MULTIPLE ERRANDS TEST; CLINICAL NEUROPSYCHOLOGY; EXECUTIVE FUNCTION;
   AMERICAN ACADEMY; VALIDITY; MEMORY; RELIABILITY; POSITION
AB Background and objective: EPELI (Executive Performance of Everyday LIving) is a Virtual Reality (VR) task that was developed to study goal-directed behavior in everyday life contexts in children. In this study, we had 72 typically developing 9- to 13-year-old children to play EPELI with an immersive version implemented with a head-mounted display (HMD) and a non-immersive version employing a flat screen display (FSD) in a counterbalanced order to see if the two versions yield similar results. The children's everyday executive functions were assessed with the parent-rated Behavior Rating Inventory for Executive Functions (BRIEF) questionnaire. To assess the applicability of EPELI for online testing, half of the flat screen display version gameplays were conducted remotely and the rest in the laboratory.Results: All EPELI performance measures were correlated across the versions. The children's performance was mostly similar in the two versions, but small effects reflecting higher performance in FSD-EPELI were found in the measures of Total score, Task efficacy, and Time-based prospective memory score. The children engaged in more active time monitoring in FSD-EPELI. While the children evaluated the feeling of presence and usability of both versions favorably, most children preferred HMD-EPELI, and evaluated its environment to be more involving and realistic. Both versions showed only negligible problems with the interface quality. No differences in task performance or subjective evaluations were found between the home-based and laboratory-based assessments of FSD-EPELI. In both EPELI versions, the efficacy measures were correlated with BRIEF on the first assessment, but not on the second. This raises questions about the stability of the associations reported between executive function tasks and questionnaires.Conclusions: Both the HMD and FSD versions of EPELI are viable tools for the naturalistic assessment of goal-directed behavior in children. While the HMD version provides a more immersive user experience and naturalistic movement tracking, the FSD version can maximize scalability, reachability, and cost efficacy, as it can be used with common hardware and remotely. Taken together, the findings highlight similarities between the HMD and FSD versions of a cognitively complex VR task, but also underline the specific advantages of these common presentation modes.
C1 [Seesjarvi, Erik; Kasteenpohja, Kaisla] Univ Helsinki, Dept Psychol & Logoped, Helsinki, Finland.
   [Seesjarvi, Erik] Univ Helsinki, Child Neurol, Helsinki, Finland.
   [Seesjarvi, Erik] Helsinki Univ Hosp, Helsinki, Finland.
   [Laine, Matti] Abo Akad Univ, Dept Psychol, Turku, Finland.
   [Salmi, Juha] Aalto Univ, Dept Neurosci & Biomed Engn, Espoo, Finland.
   [Salmi, Juha] Aalto Univ, MAGICS, Espoo, Finland.
   [Salmi, Juha] Aalto Univ, Aalto Behav Lab, AMI Ctr, Espoo, Finland.
C3 University of Helsinki; University of Helsinki; University of Helsinki;
   Helsinki University Central Hospital; Abo Akademi University; Aalto
   University; Aalto University; Aalto University
RP Seesjärvi, E (corresponding author), Univ Helsinki, Dept Psychol & Logoped, Helsinki, Finland.; Seesjärvi, E (corresponding author), Univ Helsinki, Child Neurol, Helsinki, Finland.; Seesjärvi, E (corresponding author), Helsinki Univ Hosp, Helsinki, Finland.
EM erik.seesjarvi@helsinki.fi
RI Salmi, Juha/G-7049-2012
OI Salmi, Juha/0000-0001-5623-6598; Seesjarvi, Erik/0000-0002-8130-7148
FU Academy of Finland [325981, 328954, 353518, 323251]; Finnish Cultural
   Foundation [00201002]; Arvo and Lea Ylppo Foundation [202010005];
   Instrumentarium Science Foundation [200005]
FX The study was supported by the Academy of Finland (grants #325981,
   #328954, and #353518 to JS, grant #323251 to ML). ES received support
   from the Finnish Cultural Foundation (grant #00201002), the Arvo and Lea
   Ylppo Foundation (grant #202010005), and the Instrumentarium Science
   Foundation (grant #200005).
CR Armstrong CM, 2013, J CLIN EXP NEUROPSYC, V35, P113, DOI 10.1080/13803395.2012.740002
   Auguie Baptiste, 2017, CRAN
   Backx R, 2020, J MED INTERNET RES, V22, DOI 10.2196/16792
   Barnett MD, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11050571
   Barrett RCA, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0275119
   Barrett Tyson, 2024, CRAN
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bauer RM, 2012, ARCH CLIN NEUROPSYCH, V27, P362, DOI 10.1093/arclin/acs027
   Ben-Shachar MS., 2020, J OPEN SOURCE SOFTW, V5, P2815, DOI DOI 10.21105/JOSS.02815
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Brooks James, 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P1514, DOI 10.1177/1541931213601863
   Burgess PW, 2006, J INT NEUROPSYCH SOC, V12, P194, DOI 10.1017/S1355617706060310
   Campbell Z, 2009, APPL NEUROPSYCHOL, V16, P295, DOI 10.1080/09084280903297891
   Caroux L, 2023, APPL ERGON, V107, DOI 10.1016/j.apergo.2022.103936
   Chan RCK, 2008, ARCH CLIN NEUROPSYCH, V23, P201, DOI 10.1016/j.acn.2007.08.010
   Chang CW, 2020, IEEE ACCESS, V8, P69566, DOI 10.1109/ACCESS.2020.2966564
   Giglioli IAC, 2021, CYBERPSYCH BEH SOC N, V24, P673, DOI 10.1089/cyber.2020.0560
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Cipresso P, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00405
   Conner NO, 2022, Virtual Worlds, V1, P130, DOI DOI 10.3390/VIRTUALWORLDS1020008
   Constantinou M, 2005, ARCH CLIN NEUROPSYCH, V20, P191, DOI 10.1016/j.acn.2004.06.002
   Crump MJC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057410
   Delis DC, 2004, J INT NEUROPSYCH SOC, V10, P301, DOI 10.1017/S1355617704102191
   Di Natale AF, 2020, BRIT J EDUC TECHNOL, V51, P2006, DOI 10.1111/bjet.13030
   Díaz-Orueta U, 2014, CHILD NEUROPSYCHOL, V20, P328, DOI 10.1080/09297049.2013.792332
   Duff K, 2012, ARCH CLIN NEUROPSYCH, V27, P248, DOI 10.1093/arclin/acr120
   Feenstra HEM, 2017, CLIN NEUROPSYCHOL, V31, P59, DOI 10.1080/13854046.2016.1190405
   Gagolewski M., 2019, R package stringi: Character string processing facilities
   Germine L, 2012, PSYCHON B REV, V19, P847, DOI 10.3758/s13423-012-0296-9
   Gioia GA, 2000, CHILD NEUROPSYCHOL, V6, P235, DOI 10.1076/chin.6.3.235.3152
   Govindarajan MAA, 2022, J REHABIL ASSIST TER, V9, DOI 10.1177/20556683211067174
   Hatfield G, 2002, MIND LANG, V17, P207, DOI 10.1111/1468-0017.00196
   Heilbronner RL, 2010, CLIN NEUROPSYCHOL, V24, P1267, DOI 10.1080/13854046.2010.526785
   Jovanovski D, 2012, APPL NEUROPSYCH-ADUL, V19, P171, DOI 10.1080/09084282.2011.643955
   Jylkkä J, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0280717
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khan A, 2008, J PSYCHOL, V142, P517, DOI 10.3200/JRLP.142.5.517-532
   Kim S, 2015, COMMUN STAT APPL MET, V22, P665, DOI 10.5351/CSAM.2015.22.6.665
   Kothgassner O. D., 2020, Annals of the International Communication Association, V44, P210, DOI [DOI 10.1080/23808985.2020.1792790, https://doi.org/10.1080/23808985.2020.1792790]
   Kourtesis P, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100151
   Kourtesis P, 2021, J INT NEUROPSYCH SOC, V27, P181, DOI 10.1017/S1355617720000764
   Kourtesis P, 2020, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00012
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   Krohn S, 2020, J MED INTERNET RES, V22, DOI 10.2196/16724
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Li G, 2020, J COGNITIVE NEUROSCI, V32, P1438, DOI 10.1162/jocn_a_01560
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Merzon L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-24552-4
   Mioni G, 2015, NEUROPSYCHOL REHABIL, V25, P419, DOI 10.1080/09602011.2014.941295
   Muldner K, 2015, FDG, P1
   Mullen G, 2021, TIMING TIME PERCEPT, V9, P377, DOI 10.1163/22134468-bja10034
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Ouellet É, 2018, J NEUROSCI METH, V303, P126, DOI 10.1016/j.jneumeth.2018.03.010
   Pallavicini F, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P195, DOI 10.1145/3341215.3355736
   Pallavicini F, 2018, LECT NOTES COMPUT SC, V10908, P87, DOI 10.1007/978-3-319-92052-8_8
   Pallavicini F, 2019, SIMULAT GAMING, V50, P136, DOI 10.1177/1046878119831420
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Parsons TD, 2017, J ALZHEIMERS DIS, V59, P1227, DOI 10.3233/JAD-170295
   Parsons TD, 2017, NEUROPSYCHOL REHABIL, V27, P777, DOI 10.1080/09602011.2015.1109524
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pedersen Thomas Lin, 2024, CRAN
   Pieri L, 2023, J NEUROPSYCHOL, V17, P382, DOI 10.1111/jnp.12304
   Porffy LA, 2022, J MED INTERNET RES, V24, DOI 10.2196/27641
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rabbitt P., 2004, METHODOLOGY FRONTAL, V1st, P9, DOI [10.4324/9780203344187-5, DOI 10.4324/9780203344187-5]
   Rand D, 2009, NEUROPSYCHOL REHABIL, V19, P583, DOI 10.1080/09602010802469074
   Raspelli S, 2012, PRESENCE-TELEOP VIRT, V21, P31, DOI 10.1162/PRES_a_00077
   Rendell PG, 2000, APPL COGNITIVE PSYCH, V14, pS43, DOI 10.1002/acp.770
   Repovs G, 2006, NEUROSCIENCE, V139, P5, DOI 10.1016/j.neuroscience.2005.12.061
   Revelle William, 2024, CRAN
   Rizzo A. S., 2019, Virtual reality for psychological and neurocognitive interventions
   Rotenberg S, 2020, ARCH PHYS MED REHAB, V101, P1628, DOI 10.1016/j.apmr.2020.01.019
   Ruse Stacy A, 2014, Schizophr Res Cogn, V1, pe21
   Seesjärvi E, 2023, PSYCHOL RES-PSYCH FO, V87, P1899, DOI 10.1007/s00426-022-01770-z
   Seesjärvi E, 2022, J ATTEN DISORD, V26, P1394, DOI 10.1177/10870547211044214
   SHALLICE T, 1991, BRAIN, V114, P727, DOI 10.1093/brain/114.2.727
   Shelstad William J., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2072, DOI 10.1177/1541931213602001
   Shengjie Yao, 2019, HCI in Games. First International Conference, HCI-Games 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11595), P234, DOI 10.1007/978-3-030-22602-2_18
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Stevens A, 2008, PSYCHIAT RES, V157, P191, DOI 10.1016/j.psychres.2007.01.003
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Tan C.T., 2015, P CHI PLAY 15, P253
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Ventura S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02509
   Walch M, 2017, P 2017 CHI C HUM FAC, P2982, DOI [DOI 10.1145/3027063.3053202, 10.1145/3027063.3053202]
   Webb SS, 2022, NEUROPSYCHOL REHABIL, V32, P1007, DOI 10.1080/09602011.2020.1862679
   Wechsler D, 1997, WAIS 3 WECHSLER ADUL
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   West LK, 2011, J NEUROPSYCHOL, V5, P114, DOI 10.1348/174866410X521434
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [10.1007/978-3-319-24277-4, DOI 10.1007/978-3-319-24277-4]
   Wickham H., 2019, J OPEN SOURCE SOFTW, V4, P1686, DOI [10.21105/joss.01686, DOI 10.21105/JOSS.01686]
   Wickham Hadley, 2023, CRAN
   Wickham Hadley, 2023, CRAN
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Woods SP, 2006, ARCH CLIN NEUROPSYCH, V21, P413, DOI 10.1016/j.acn.2006.06.002
   World Health Organization, 1992, ICD 10 CLASS MENT BE
   Zuber S, 2022, MEMORY, V30, P117, DOI 10.1080/09658211.2021.1995435
NR 99
TC 1
Z9 1
U1 3
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 26
PY 2023
VL 4
AR 1138240
DI 10.3389/frvir.2023.1138240
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YG7
UT WOS:001023331400001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Camardella, C
   Chiaradia, D
   Bortone, I
   Frisoli, A
   Leonardis, D
AF Camardella, Cristian
   Chiaradia, Domenico
   Bortone, Ilaria
   Frisoli, Antonio
   Leonardis, Daniele
TI Introducing wearable haptics for rendering velocity feedback in VR
   serious games for neuro-rehabilitation of children
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptic; rehabilitation; virtual; serious games; cerebral palsy;
   immersive; wearable; haptics
ID VIRTUAL-REALITY; SYSTEM; HAND
AB Rehabilitation in virtual reality offers advantages in terms of flexibility and parametrization of exercises, repeatability, and continuous data recording and analysis of the progress of the patient, also promoting high engagement and cognitive challenges. Still, most of the proposed virtual settings provide a high quality, immersive visual and audio feedback, without involving the sense of touch. In this paper, we show the design, implementation, and first evaluation of a gaming scenario for upper limb rehabilitation of children with cerebral palsy. In particular, we took care to introduce haptic feedback as a useful source of sensory information for the proposed task, considering-at the same time-the strict constraints for haptic wearable devices to comply with patient's comfort, residual motor abilities, and with the embedded tracking features of the latest VR technologies. To show the potential of haptics in a rehabilitation setup, the proposed device and rendering method have been used to improve the velocity control of upper limb movements during the VR exercise, given its importance as a motor recovery metric. Eight healthy participants were enrolled, and results showed that haptic feedback can lead to lower speed tracking errors and higher movement smoothness, making the proposed setup suitable to be used in a rehabilitation context as a way to promote movement fluidity during exercises.
C1 [Camardella, Cristian; Chiaradia, Domenico; Frisoli, Antonio; Leonardis, Daniele] Scuola Super Sant Anna, Inst Mech Intelligene, Pisa, Italy.
   [Camardella, Cristian; Chiaradia, Domenico; Frisoli, Antonio; Leonardis, Daniele] Scuola Super Sant Anna, Dept Excellence Robot & Al, Pisa, Italy.
   [Bortone, Ilaria] Natl Res Council CNR, Inst Clin Phisiol IFC, Pisa, Italy.
C3 Scuola Superiore Sant'Anna; Scuola Superiore Sant'Anna
RP Camardella, C (corresponding author), Scuola Super Sant Anna, Inst Mech Intelligene, Pisa, Italy.; Camardella, C (corresponding author), Scuola Super Sant Anna, Dept Excellence Robot & Al, Pisa, Italy.
EM c.camardella@santannapisa.it
OI Camardella, Cristian/0000-0002-3856-5731
FU "Bando Ricerca Salute 2018" of the Tuscany region, Italy [CUP
   J52F20001040002]; European Union-FSE-REACT-EU; PON Research and
   Innovation 2014-2020 [DM1062/2021]
FX This work was supported by the Project "TELOS-Tailored
   neurorehabilitation therapy via multi-domain data analytics and adaptive
   serious games for children with cerebral palSy," which is funded under
   the call "Bando Ricerca Salute 2018" of the Tuscany region, Italy (CUP
   J52F20001040002). The publication was created with the co-financing of
   the European Union-FSE-REACT-EU, PON Research and Innovation 2014-2020
   DM1062/2021.
CR [Anonymous], 2015, EFFECTS VIRTUAL REAL
   Basalp E, 2021, IEEE T HAPTICS, V14, P722, DOI 10.1109/TOH.2021.3104518
   Booth ATC, 2019, FRONT PHYSIOL, V10, DOI 10.3389/fphys.2019.01208
   Bortone I, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00771-6
   Bortone I, 2018, IEEE T NEUR SYS REH, V26, P1469, DOI 10.1109/TNSRE.2018.2846814
   Bosecker C, 2010, NEUROREHAB NEURAL RE, V24, P62, DOI 10.1177/1545968309343214
   Bossenbroek R, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/16066
   Camardella C, 2022, LECT NOTES COMPUT SC, V13235, P274, DOI 10.1007/978-3-031-06249-0_31
   Chinello F, 2015, IEEE ASME INT C ADV, P293, DOI 10.1109/AIM.2015.7222547
   Choi JY, 2021, DEV MED CHILD NEUROL, V63, P480, DOI 10.1111/dmcn.14762
   Culbertson H, 2014, IEEE HAPTICS SYM, P319, DOI 10.1109/HAPTICS.2014.6775475
   Demain S, 2013, DISABIL REHABIL-ASSI, V8, P181, DOI 10.3109/17483107.2012.697532
   Deutsch JE, 2017, PEDIATR PHYS THER, V29, pS23, DOI 10.1097/PEP.0000000000000387
   Fani S, 2018, IEEE T HAPTICS, V11, P304, DOI 10.1109/TOH.2017.2708717
   Gabardi M, 2018, LECT NOTES COMPUT SC, V10894, P313, DOI 10.1007/978-3-319-93399-3_28
   Gallo S, 2015, FRONT ROBOT AI, DOI 10.3389/frebt.2015.DDD25
   Gutiérrez A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030963
   Jarrassé N, 2010, IEEE T NEUR SYS REH, V18, P389, DOI 10.1109/TNSRE.2010.2056388
   Kerns KA, 2017, APPL NEUROPSYCH-CHIL, V6, P120, DOI 10.1080/21622965.2015.1109513
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   King G, 2020, DEV NEUROREHABIL, V23, P18, DOI 10.1080/17518423.2019.1604580
   Krebs HI, 2012, NEUROREHAB NEURAL RE, V26, P855, DOI 10.1177/1545968311433427
   Kuriakose S, 2015, IEEE T NEUR SYS REH, V23, P665, DOI 10.1109/TNSRE.2015.2393891
   Langhorne P, 2011, LANCET, V377, P1693, DOI 10.1016/S0140-6736(11)60325-5
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Leonardis D, 2017, IEEE T HAPTICS, V10, P305, DOI 10.1109/TOH.2016.2640291
   Martin-Niedecken AL, 2017, LECT NOTES COMPUT SC, V10622, P32, DOI 10.1007/978-3-319-70111-0_4
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Patton J, 2006, ASSIST TECHNOL, V18, P181, DOI 10.1080/10400435.2006.10131917
   Qiu QY, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-40
   Rand Debbie, 2008, J Neurol Phys Ther, V32, P155, DOI 10.1097/NPT.0b013e31818ee779
   Romano JM, 2012, IEEE T HAPTICS, V5, P109, DOI [10.1109/TOH.2011.38, 10.1109/ToH.2011.38]
   Romano JM, 2010, IEEE INT CONF ROBOT, P1815, DOI 10.1109/ROBOT.2010.5509853
   Simoes M, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/games.8428
   Stroppa F, 2017, BIOSYST BIOROBOT, V15, P501, DOI 10.1007/978-3-319-46669-9_83
   Veerbeek JM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087987
   VERCHER JL, 1992, EXP BRAIN RES, V90, P599
   Wade J, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2892636
   Wiertlewski M, 2011, IEEE T ROBOT, V27, P461, DOI 10.1109/TRO.2011.2132830
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
   Zoccolillo L, 2015, EUR J PHYS REHAB MED, V51, P669
NR 41
TC 0
Z9 0
U1 4
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 6
PY 2023
VL 3
AR 1019302
DI 10.3389/frvir.2022.1019302
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XW3
UT WOS:001023321000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Kent, JA
   Hughes, CE
AF Kent, Julie A.
   Hughes, Charles E.
TI Law enforcement training using simulation for locally customized
   encounters
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE social interaction simulator; autism spectrum disorder; law enforcement
   training; social skills practice; virtual reality police training;
   de-escalation training in virtual reality; police scenarios in virtual
   reality
AB Law enforcement professionals require up to date training for interacting with individuals on the autism spectrum in a manner that facilitates positive citizen response. Although these officers interact with the public regularly, they may only have sporadic interactions with citizens who are not neurotypical. The timing of these interactions is not easy to predict; therefore, it is important to provide regular opportunities to practice contacts with special needs communities. However, in much the same way that it can be difficult to provide regular sessions with other protected groups of people, it is not practical to pull individuals on the autism spectrum to participate in law enforcement training. Role play with neurotypical individuals and classroom training presenting facts about autism do little to prepare these officers for their real-world encounters. Virtual interactions with people on the autism spectrum allow officers to practice techniques without compromising the health and safety of the communities they serve. This paper presents results of a study comparing police training through experiences in virtual reality (VR) with video training regarding police interactions with individuals on the autism spectrum. Police officers in a municipal police department who participated in the study were divided into three groups for continuing training purposes. One group received video training, one group received practice in VR, and one group received training through both video and VR. The differences in training method did not result in significant differences in training effectiveness. However, subjective data did support the efficacy of practice in a virtual setting. This project addressed three important challenges with training in VR. First, the team needed to define the specifics of behavior and language that the simulated individuals would exhibit. Second, the VR had to be tailored to be relevant to the officers participating. Third and finally, the schedule for training delivery had to minimize the time that officers were away from their assigned duties. Officer feedback on their training experiences indicated the approach to these challenges was well-received. The primary research question is whether training in VR is any more effective that watching a training video.
C1 [Kent, Julie A.; Hughes, Charles E.] Univ Cent Florida, Coll Grad Studies, Sch Modeling Simulat & Training, Synthet Real Lab, Orlando, FL 32816 USA.
   [Kent, Julie A.] MITRE Corp, Orlando, FL 32817 USA.
   [Hughes, Charles E.] Univ Cent Florida, Coll Engn & Comp Sci, Dept Comp Sci, Orlando, FL USA.
C3 State University System of Florida; University of Central Florida; MITRE
   Corporation; State University System of Florida; University of Central
   Florida
RP Kent, JA (corresponding author), Univ Cent Florida, Coll Grad Studies, Sch Modeling Simulat & Training, Synthet Real Lab, Orlando, FL 32816 USA.; Kent, JA (corresponding author), MITRE Corp, Orlando, FL 32817 USA.
EM jakent@knights.ucf.edu
FU I/ITSEC conference; National Science Foundation [2120240, 2114808,
   1725554]; U.S. Department of Education [P116S210001, H327S210005,
   H327S200009H]
FX & nbsp;This research was supported in part by a scholarship from the
   I/ITSEC conference and by grants from the National Science Foundation
   Grants # 2120240, 2114808, 1725554, and from the U.S. Department of
   Education Grants #P116S210001, H327S210005, H327S200009H Any opinions,
   findings, and conclusions or recommendations expressed in this material
   are those of the authors and do not necessarily reflect the views of the
   sponsors.
CR [Anonymous], 2012, Critical issues in policing series: Improving the police response to sexual assault
   Apex Officer, 2021, POL TRAIN REQ
   Armstrong J., 2014, Western Criminology Review, V15, P51
   Atkins V, 2012, POLICE ORGANIZATION AND TRAINING: INNOVATIONS IN RESEARCH AND PRACTICE, P45, DOI 10.1007/978-1-4614-0745-4_4
   Bennell C, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.818009
   Bennell C, 2021, POLICING, V44, P377, DOI 10.1108/PIJPSM-06-2020-0092
   Bhandari S., 2019, LEVERAGING EMOTIONAL
   Carnell S, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.810797
   Compton MT, 2011, SCHIZOPHRENIA BULL, V37, P737, DOI 10.1093/schbul/sbp146
   Dieker LA, 2019, INT J GAMING COMPUT-, V11, P1, DOI 10.4018/IJGCMS.2019100101
   Ellis R., 1999, BANG YOURE SORTA DEA
   Engel RS, 2022, CRIMINOL PUBLIC POL, V21, P199, DOI 10.1111/1745-9133.12574
   Engel RS, 2020, CRIMINOL PUBLIC POL, V19, P721, DOI 10.1111/1745-9133.12467
   Giacomantonio C, 2020, POLICE PRACT RES, V21, P401, DOI 10.1080/15614263.2019.1589472
   HART S G, 1988, P139
   IACP, 2020, NAT CONS DISC PAP US
   Keyes KM, 2012, INT J EPIDEMIOL, V41, P495, DOI 10.1093/ije/dyr193
   King M, 2009, INT J EPIDEMIOL, V38, P1224, DOI 10.1093/ije/dyp261
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Murphy R., 2011, Law Order, V59, P46
   Norouzi N, 2021, IEEE T VIS COMPUT GR, V27, P4321, DOI 10.1109/TVCG.2021.3106490
   ONeill L., 1995, LOS ANGELES TIMES
   Peterson Jillian., 2019, The Police Journal, DOI DOI 10.1177/0032258X19864997
   Seibert M.K., 2012, Addressing Army aviation collective training challenges with simulators and simulation capabilities
   Todak N, 2018, POLICE Q, V21, P509, DOI 10.1177/1098611118784007
NR 25
TC 2
Z9 2
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 6
PY 2022
VL 3
AR 960146
DI 10.3389/frvir.2022.960146
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XC2
UT WOS:001023300800001
OA gold
DA 2024-07-18
ER

PT J
AU Maddali, D
   Brun, H
   Kiss, G
   Hjelmervik, JM
   Elle, OJ
AF Maddali, Dharani
   Brun, Henrik
   Kiss, Gabriel
   Hjelmervik, Jon Mikkelsen
   Elle, Ole Jakob
TI Spatial Orientation in Cardiac Ultrasound Images Using Mixed Reality:
   Design and Evaluation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE ultrasound; mixed reality; 3D echocardiography; orientation; medical
   visualization
AB Spatial orientation is an important skill in structural cardiac imaging. Until recently, 3D cardiac ultrasound has been visualized on a flat screen by using volume rendering. Mixed reality devices enhance depth perception, spatial awareness, interaction, and integration in the physical world, which can prove advantageous with 3D cardiac ultrasound images. In this work, we describe the design of a system for rendering 4D (3D + time) cardiac ultrasound data as virtual objects and evaluate it for ease of spatial orientation by comparing it with a standard clinical viewing platform in a user study. The user study required eight participants to do timed tasks and rate their experience. The results showed that virtual objects in mixed reality provided easier spatial orientation and morphological understanding despite lower perceived image quality. Participants familiar with mixed reality were quicker to orient in the tasks. This suggests that familiarity with the environment plays an important role, and with improved image quality and increased use, mixed reality applications may perform better than conventional 3D echocardiography viewing systems.
C1 [Maddali, Dharani] Univ Oslo, Dept Informat, Digital Signal Proc & Image Anal, Oslo, Norway.
   [Brun, Henrik; Elle, Ole Jakob] Oslo Univ Hosp, Intervent Ctr, Oslo, Norway.
   [Brun, Henrik] Oslo Univ Hosp, Dept Pediat Cardiol, Div Pediat & Adolescent Med, Oslo, Norway.
   [Kiss, Gabriel] Norwegian Univ Sci & Technol, Dept Comp Sci, Trondhiem, Norway.
   [Hjelmervik, Jon Mikkelsen] SINTEF Digital, Math & Cybernet, Oslo, Norway.
   [Elle, Ole Jakob] Univ Oslo, Dept Informat, Robot & Intelligent Syst, Oslo, Norway.
C3 University of Oslo; University of Oslo; University of Oslo; Norwegian
   University of Science & Technology (NTNU); SINTEF; University of Oslo
RP Maddali, D (corresponding author), Univ Oslo, Dept Informat, Digital Signal Proc & Image Anal, Oslo, Norway.
EM dharandm@ifi.uio.no
OI Hjelmervik, Jon/0000-0001-7727-7479
CR Bruckheimer E, 2016, EUR HEART J-CARD IMG, V17, P845, DOI 10.1093/ehjci/jew087
   Brun H, 2019, EUR HEART J-CARD IMG, V20, P883, DOI 10.1093/ehjci/jey184
   Deng SJ, 2021, J IMAGING, V7, DOI 10.3390/jimaging7080151
   Gehrsitz P, 2021, FRONT CARDIOVASC MED, V8, DOI 10.3389/fcvm.2021.633611
   Hamacher A, 2016, INT NEUROUROL J, V20, P172, DOI 10.5213/inj.1632714.357
   Kasprzak JD, 2020, EUR HEART J, V41, P801, DOI 10.1093/eurheartj/ehz127
   Kiss Gabriel, 2010, 2010 International Ultrasonics Symposium, P193, DOI 10.1109/ULTSYM.2010.0047
   Lai W. W., 2021, ECHOCARDIOGRAPHY PED, P47, DOI [10.1002/9781119612858.ch4, DOI 10.1002/9781119612858.CH4]
   Narang A, 2020, J AM SOC ECHOCARDIOG, V33, P1306, DOI 10.1016/j.echo.2020.06.018
   Pelanis E, 2020, MINIM INVASIV THER, V29, P154, DOI 10.1080/13645706.2019.1616558
   Perkins SL, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P269, DOI 10.1109/ISMAR-Adjunct.2017.92
   Pham TQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P454, DOI 10.1109/ICME.2005.1521458
   Pratt P, 2018, EUR RADIOL EXP, V2, DOI 10.1186/s41747-017-0033-2
   Pushparajah K, 2021, JTCVS TECHNIQUES, V7, P269, DOI 10.1016/j.xjtc.2021.02.044
   Shi S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2719921
NR 15
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 25
PY 2022
VL 3
AR 881338
DI 10.3389/frvir.2022.881338
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TC4
UT WOS:001021824700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Fisher, JA
AF Fisher, Joshua A. A.
TI Epistemic Rhetoric in Virtual Reality Interactive Factual Narratives
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; non-fiction; rhetoric; complexity; interactive digital
   narrative
ID EXPERIENCE; PARADIGM
AB The turn to Interactive Digital Narratives to understand complexity offers a new model for creating, developing, and maintaining knowledge. At the same time, storytellers have turned their attention to Virtual Reality (VR). The confluence of these trends draws attention to how non-fiction practitioners can use the technical and aesthetic affordances of VR to create knowledge about complex subjects through the IDN form. This article explores the epistemic rhetorical nature of using narrative discourse in VR to create knowledge about a non-fiction subject. The IDN community has not addressed this rhetorical aspect in their proposed epistemological process. Clarifying the epistemic rhetorical aspect inherent in producing knowledge on complex subjects through IDN provides insights into practitioners' persuasive and political design and development choices. These intentional choices, in turn, impact the kind of knowledge produced. This rhetorical approach to knowledge production can be grounded in a Neo-sophist epistemic tradition wherein aesthetic choices are used rhetorically. I will present and discuss the Sophist rhetorical tactics of antithesis, the rhetoric of the possible; enargeia, the rhetoric of vivid details; kairos, the rhetoric of opportune timing; and metis, the rhetoric of the body. Their implementation by practitioners, how these aesthetic choices rhetorically create knowledge in the System-Process-Product model is presented. The article clarifies these rhetorical processes and choices and analyzes the 2021 Tribeca Film Festival's Best Immersive Narrative, The Changing Same: An American Pilgrimage: Episode 1. This VR factual IDN allows interactors to experience historical moments of racial injustice in the United States. The production team was interviewed about how they used the technical and aesthetic qualities of VR and IDN rhetorically to produce knowledge about the complex and violent history of racial injustice in the United States. Their responses indicate their active use of epistemic rhetorical tactics that capitalize on the technical and aesthetic affordances of VR and IDN to create knowledge.
C1 [Fisher, Joshua A. A.] Columbia Coll Chicago, Dept Interact Arts & Media, Chicago, IL 60605 USA.
RP Fisher, JA (corresponding author), Columbia Coll Chicago, Dept Interact Arts & Media, Chicago, IL 60605 USA.
EM jofisher@colum.edu
OI Fisher, Joshua A/0000-0001-5628-5138
CR Bailey J., 2011, P INT SOC PRESENCE R
   Ballif Michelle., 1998, Rhetoric Society Quarterly, V28, P51
   Barrett LF, 2004, J PERS SOC PSYCHOL, V87, P684, DOI 10.1037/0022-3514.87.5.684
   Bernstein M, 2018, LECT NOTES COMPUT SC, V11318, P50, DOI 10.1007/978-3-030-04028-4_4
   Bevan C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300736
   Bohrod J. B., 2021, VIRTUAL DOCUMENTARY
   Brooke CollinGifford., 2009, LINGUA FRACTA RHETOR
   Clune M. W., 2016, VIRTUAL REALITY REMI
   Coyle H, 2015, AM J GERIAT PSYCHIAT, V23, P335, DOI 10.1016/j.jagp.2014.04.009
   Crick N, 2010, Q J SPEECH, V96, P25, DOI 10.1080/00335630903512705
   Crowley Sharon., 1989, Rhetoric Review, V7, P318, DOI DOI 10.1080/07350198909388864
   De la Pena N., 2014, Digital Rethoric and Global Literacies: Communicaction Modes and Digital Practices in the Networked World, P312, DOI [10.4018/978-1-4666-4916, DOI 10.4018/978-1-4666-4916]
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Dolmage J, 2009, RHETOR REV, V28, P1, DOI 10.1080/07350190802540690
   Eladhari MP, 2018, LECT NOTES COMPUT SC, V11318, P65, DOI 10.1007/978-3-030-04028-4_5
   Engberg M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P324, DOI 10.1109/ISMAR-Adjunct.2018.00096
   Euteneuer J., 2019, LUDIC GARDEN WORK PL, DOI [10.1145/3132847.3132886, DOI 10.1145/3132847.3132886]
   de Andrade ENF, 2020, STUD PHILOS EDUC, V39, P85, DOI 10.1007/s11217-019-09683-y
   Fisher J. A., 2019, INTERACTIVE NONFICTI
   Fisher JA, 2018, LECT NOTES COMPUT SC, V11318, P577, DOI 10.1007/978-3-030-04028-4_68
   Fisher JA, 2017, LECT NOTES COMPUT SC, V10690, P233, DOI 10.1007/978-3-319-71027-3_19
   Fisher WalterR., 2021, Human Communication as Narration: �Toward a Philosophy of Reason, Value, and Action
   FISHER WR, 1984, COMMUN MONOGR, V51, P1, DOI 10.1080/03637758409390180
   FISHER WR, 1985, J COMMUN, V35, P74, DOI 10.1111/j.1460-2466.1985.tb02974.x
   Fledderjohann M., 2020, ENCULTURATION, V1, P1
   Grethlein J, 2017, J HELLENIC STUD, V137, P67, DOI 10.1017/S0075426917000064
   Hall Stuart., 2007, CCCS selected working papers, P402
   Hameed A, 2018, LECT NOTES COMPUT SC, V11318, P323, DOI 10.1007/978-3-030-04028-4_35
   Haraway D., 2006, THEORY CULT SOC, V23, P189, DOI [10.1177/0263276406069231, DOI 10.1177/0263276406069231]
   Hawhee Debra., 2004, Bodily Arts: Rhetoric and Athletics in Ancient Greece, DOI DOI 10.7560/705845
   Holmes S, 2019, RHETORICAL SPECULATIONS: THE FUTURE OF RHETORIC, WRITING, AND TECHNOLOGY, P174, DOI 10.7330/9781607328315.c008
   Jarratt S. C., 1991, REREADING SOPHIST CL, V1st ed.
   Jenkins Henry., 2004, 1 PERSON, P118
   Johnstone CL, 2006, PHILOS RHETORIC, V39, P265, DOI 10.1353/par.2007.0004
   Jorash R. J. C., 2020, WHAT HAS BEEN WILL B, P1
   Karhulahti V.-M., 2012, P 4 INT C FUN GAMES, DOI DOI 10.1145/2367616.2367619
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Knoller N., 2020, COMPLEXITY TRIAD 2 S
   Knoller N, 2021, LECT NOTES COMPUT SC, V13138, P478, DOI 10.1007/978-3-030-92300-6_48
   Knoller N, 2019, FRONT NARRAT, P98
   Koenitz H., 2015, INTERACTIVE DIGITAL, P91
   Koenitz H., 2019, PLAYING UTOPIA, P253, DOI [10.14361/9783839450505-00910.1515/9783839450505-009, DOI 10.14361/9783839450505-00910.1515/9783839450505-009]
   Koenitz H, 2021, LECT NOTES COMPUT SC, V13138, P488, DOI 10.1007/978-3-030-92300-6_49
   Koenitz H, 2020, Arxiv, DOI arXiv:2010.10135
   Koenitz H, 2016, LECT NOTES COMPUT SC, V10045, P51, DOI 10.1007/978-3-319-48279-8_5
   Koenitz H, 2010, LECT NOTES COMPUT SC, V6432, P176, DOI 10.1007/978-3-642-16638-9_22
   Koenitz Hartmut, 2021, Trans. Digit. Games Res. Assoc., V5, P3
   Lindhe C., 2013, DIGITAL EKPHRASIS, V7
   Lunde Ingunn., 2004, Journal of Historical Pragmatics, V5, P49
   Mateas M., 2001, Digital Creativity, V12, P140, DOI 10.1076/digc.12.3.140.3224
   McComiskey Bruce., 1994, RHETOR SOC Q, V24, P16, DOI DOI 10.1080/02773949409391015
   Menon V, 2010, BRAIN STRUCT FUNCT, V214, P655, DOI 10.1007/s00429-010-0262-0
   Montfort Nick, 2005, Twisty Little Passages: An Approach to Interactive Fiction
   Murray JH, 2018, LECT NOTES COMPUT SC, V11318, P3, DOI 10.1007/978-3-030-04028-4_1
   Murray JH, 2017, HAMLET ON THE HOLODECK: THE FUTURE OF NARRATIVE IN CYBERSPACE, P1
   Nash K, 2018, STUD DOC FILM, V12, P119, DOI 10.1080/17503280.2017.1340796
   Nitsche M., 2008, Video Game Spaces: Image, Play, and Structure in 3D Worlds
   Nitsche Michael, 2007, DIGRA C
   Ong WJ, 2012, NEW ACCENT, P1
   POULAKOS J, 1983, PHILOS RHETORIC, V16, P35
   POULAKOS J, 1990, PHILOS RHETORIC, V23, P218
   Rada Studios, 2019, CHANG SAM
   Rita-Procter S., 2018, NARRATOLOGY RHETORIC
   Rose Mandy., 2018, World Records, V1, P1
   Roth C, 2018, LECT NOTES COMPUT SC, V11318, P93, DOI 10.1007/978-3-030-04028-4_7
   Rouse R, 2017, LECT NOTES COMPUT SC, V10690, P245, DOI 10.1007/978-3-319-71027-3_20
   Rouse Rebecca, 2021, P AUGM MIX REAL COMM, P3
   SCHIAPPA E, 1990, PHILOS RHETORIC, V23, P192
   Schiappa Edward., 1991, Rhetoric Review, V10, P5
   Schlembach R, 2021, INT J CULTURAL STUD, V24, P827, DOI 10.1177/13678779211007863
   Seth AK, 2013, TRENDS COGN SCI, V17, P565, DOI 10.1016/j.tics.2013.09.007
   Sharpling GP, 2002, RHETORICA, V20, P173, DOI 10.1525/rh.2002.20.2.173
   Shibolet Y., 2019, FRAMEWORK EMBODIED N
   Sicart M., 2011, The International Journal of Computer Game Research, V11
   Stone RT, 2011, HUM FACTORS, V53, P558, DOI 10.1177/0018720811413389
   Sundar SS, 2017, CYBERPSYCH BEH SOC N, V20, P672, DOI 10.1089/cyber.2017.0271
   Yasmin E., 2021, CHANGING SAME EPISOD
NR 77
TC 0
Z9 0
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 17
PY 2022
VL 3
AR 845489
DI 10.3389/frvir.2022.845489
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SZ3
UT WOS:001021821600001
OA gold
DA 2024-07-18
ER

PT J
AU Lamb, M
   Brundin, M
   Luque, EP
   Billing, E
AF Lamb, Maurice
   Brundin, Malin
   Luque, Estela Perez
   Billing, Erik
TI Eye-Tracking Beyond Peripersonal Space in Virtual Reality: Validation
   and Best Practices
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE eye tracking; virtual reality; gaze depth; vergence; validation
ID DEPTH-PERCEPTION; EVENT-DETECTION; DISTANCE; MOVEMENTS; VERGENCE;
   DISPLAY; IMPACT
AB Recent developments in commercial virtual reality (VR) hardware with embedded eye-tracking create tremendous opportunities for human subjects researchers. Accessible eye-tracking in VR opens new opportunities for highly controlled experimental setups in which participants can engage novel 3D digital environments. However, because VR embedded eye-tracking differs from the majority of historical eye-tracking research, in both providing for relatively unconstrained movement and stimulus presentation distances, there is a need for greater discussion around methods for implementation and validation of VR based eye-tracking tools. The aim of this paper is to provide a practical introduction to the challenges of, and methods for, 3D gaze-tracking in VR with a focus on best practices for results validation and reporting. Specifically, first, we identify and define challenges and methods for collecting and analyzing 3D eye-tracking data in VR. Then, we introduce a validation pilot study with a focus on factors related to 3D gaze tracking. The pilot study provides both a reference data point for a common commercial hardware/software platform (HTC Vive Pro Eye) and illustrates the proposed methods. One outcome of this study was the observation that accuracy and precision of collected data may depend on stimulus distance, which has consequences for studies where stimuli is presented on varying distances. We also conclude that vergence is a potentially problematic basis for estimating gaze depth in VR and should be used with caution as the field move towards a more established method for 3D eye-tracking.
C1 [Lamb, Maurice; Brundin, Malin; Billing, Erik] Univ Skovde, Sch Informat, Skovde, Sweden.
   [Lamb, Maurice; Luque, Estela Perez] Univ Skovde, Dept Engn, Skovde, Sweden.
C3 University of Skovde; University of Skovde
RP Lamb, M (corresponding author), Univ Skovde, Sch Informat, Skovde, Sweden.; Lamb, M (corresponding author), Univ Skovde, Dept Engn, Skovde, Sweden.
EM Maurice.Lamb@his.se
OI Lamb, Maurice/0000-0003-2254-1396
FU Knowledge Foundation as a part of both the Recruitment and Strategic
   Knowledge Reinforcement initiative and within the Synergy Virtual
   Ergonomics (SVE) project [20180167]
FX & nbsp;Funding of this project was provided through the Knowledge
   Foundation as a part of both the Recruitment and Strategic Knowledge
   Reinforcement initiative and within the Synergy Virtual Ergonomics (SVE)
   project (#20180167).
CR Aksit K, 2019, IEEE T VIS COMPUT GR, V25, P1928, DOI 10.1109/TVCG.2019.2898781
   Alghofaili R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P464, DOI [10.1109/vr.2019.8797816, 10.1109/VR.2019.8797816]
   Andersson R, 2017, BEHAV RES METHODS, V49, P616, DOI 10.3758/s13428-016-0738-9
   Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   [Anonymous], 2012, P S EYE TRACK RES AP
   [Anonymous], 2011, P ACM SIGGRAPH S APP, DOI [10.1145/2077451.2077454, DOI 10.1145/2077451.2077454]
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Aw ST, 1996, J NEUROPHYSIOL, V76, P4009, DOI 10.1152/jn.1996.76.6.4009
   Binaee K, 2019, J VISION, V19, DOI 10.1167/19.12.3
   BLAKEMORE C, 1970, J PHYSIOL-LONDON, V211, P599, DOI 10.1113/jphysiol.1970.sp009296
   Blignaut P, 2009, ATTEN PERCEPT PSYCHO, V71, P881, DOI 10.3758/APP.71.4.881
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Callahan-Flintoft C, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.650693
   Carter BT, 2020, INT J PSYCHOPHYSIOL, V155, P49, DOI 10.1016/j.ijpsycho.2020.05.010
   Chang CL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55346-w
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Collewijn H, 2000, J NEUROPHYSIOL, V84, P376, DOI 10.1152/jn.2000.84.1.376
   Deb S, 2017, APPL ERGON, V65, P449, DOI 10.1016/j.apergo.2017.03.007
   Duchowski A, 2002, BEHAV RES METH INS C, V34, P573, DOI 10.3758/BF03195486
   Duchowski A.T., 2014, P S EYE TRACK RES AP, P103, DOI DOI 10.1145/2578153.2578168
   Elmadjian C, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206351
   ERKELENS CJ, 1989, PROC R SOC SER B-BIO, V236, P441, DOI 10.1098/rspb.1989.0031
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Feldman AG, 2020, J NEUROPHYSIOL, V124, P115, DOI 10.1152/jn.00076.2020
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Gutierrez Mlot Esteban, 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: HealthInf, P125
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Held RT, 2012, CURR BIOL, V22, P426, DOI 10.1016/j.cub.2012.01.033
   Hennessey C, 2009, IEEE T BIO-MED ENG, V56, P790, DOI 10.1109/TBME.2008.2005943
   Hessels RS, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.180502
   Hessels RS, 2015, BEHAV RES METHODS, V47, P848, DOI 10.3758/s13428-014-0507-6
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Holmqvist K, 2017, 7 SCAND WORKSH EYE T
   Holzwarth Valentin, 2021, ICVARS 2021: 2021 the 5th International Conference on Virtual and Augmented Reality Simulations, P42, DOI 10.1145/3463914.3463921
   Hooge ITC, 2019, VISION RES, V156, P1, DOI 10.1016/j.visres.2019.01.004
   Inoue T, 1997, APPL OPTICS, V36, P4509, DOI 10.1364/AO.36.004509
   Iorizzo DB, 2011, VISION RES, V51, P1173, DOI 10.1016/j.visres.2011.03.006
   Iskander J, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102883
   Johnsson J., 2011, ACCURACY PRECISION T
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   King AJ, 2019, COMMUN METHODS MEAS, V13, P149, DOI 10.1080/19312458.2018.1558194
   Kothari R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59251-5
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kowler E, 2011, VISION RES, V51, P1457, DOI 10.1016/j.visres.2010.12.014
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Kwon Y.-M., 2006, IJVR, V5, P41
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Land M. F., 1993, Conference Proceedings. 1993 International Conference on Systems, Man and Cybernetics. Systems Engineering in the Service of Humans (Cat. No.93CH3242-5), P490, DOI 10.1109/ICSMC.1993.385060
   LAND MF, 1994, NATURE, V369, P742, DOI 10.1038/369742a0
   Lanman D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508366
   Larsson L, 2016, J NEUROSCI METH, V274, P13, DOI 10.1016/j.jneumeth.2016.09.005
   Lee S. H., 2019, P 20 BRIT MACH VIS C
   Li R, 2020, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR50242.2020.00033
   Luckett E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1711, DOI [10.1109/vr.2019.8798374, 10.1109/VR.2019.8798374]
   Mardanbegi D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300842
   Marmitt G., 2002, P EUR SHORT PRES SAA
   Munn SM, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P181, DOI 10.1145/1344471.1344517
   Naceri A, 2011, PRESENCE-TELEOP VIRT, V20, P254, DOI 10.1162/PRES_a_00048
   Niehorster DC, 2020, BEHAV RES METHODS, V52, P1140, DOI 10.3758/s13428-019-01307-0
   Niehorster DC, 2018, BEHAV RES METHODS, V50, P213, DOI 10.3758/s13428-017-0863-0
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nyström M, 2013, BEHAV RES METHODS, V45, P272, DOI 10.3758/s13428-012-0247-4
   Olsen A., 2012, ENTHE TOBII I VT FIX
   Orquin JL, 2018, BEHAV RES METHODS, V50, P1645, DOI 10.3758/s13428-017-0998-z
   Pieszala J, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P201, DOI 10.1145/2857491.2857545
   Previc FH, 1998, PSYCHOL BULL, V124, P123, DOI 10.1037/0033-2909.124.2.123
   Reichelt S, 2010, PROC SPIE, V7690, DOI 10.1117/12.850094
   Salvucci DD, 2000, 2000 S EYE TRACKING, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028]
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Steil J, 2018, 20TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2018), DOI 10.1145/3229434.3229439
   Tresilian JR, 1999, P ROY SOC B-BIOL SCI, V266, P39, DOI 10.1098/rspb.1999.0601
   van der Veen SM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173632
   Verstraten FAJ, 2001, VISION RES, V41, P3505, DOI 10.1016/S0042-6989(01)00205-X
   Vienne C, 2020, IEEE ACCESS, V8, P29099, DOI 10.1109/ACCESS.2020.2972122
   Vienne C, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00973
   Viguier A, 2001, PERCEPTION, V30, P115, DOI 10.1068/p3119
   Vinnikov M, 2016, INT J HUM-COMPUT ST, V91, P37, DOI 10.1016/j.ijhcs.2016.03.001
   Vinnikov Margarita, 2014, P S EYE TRACK RES AP, P119, DOI DOI 10.1145/2578153.2578170
   Wang RI, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2593689
   Wang X, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.4.2
   Wang X, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275094
   Weber S, 2018, BEHAV RES METHODS, V50, P2004, DOI 10.3758/s13428-017-0969-4
   Wexler M, 2005, TRENDS COGN SCI, V9, P431, DOI 10.1016/j.tics.2005.06.018
   Wibirama S, 2017, ENTERTAIN COMPUT, V21, P11, DOI 10.1016/j.entcom.2017.04.003
   Wu R, 2020, IEEE POSITION LOCAT, P1311, DOI [10.1109/plans46316.2020.9110225, 10.1109/PLANS46316.2020.9110225]
   Yates Alan, 2016, Patent, Patent No. [US20160131761A1, 20160131761]
   Zhao HY, 2019, J VISION, V19, DOI 10.1167/19.14.11
NR 91
TC 6
Z9 6
U1 5
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 8
PY 2022
VL 3
AR 864653
DI 10.3389/frvir.2022.864653
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YO8
UT WOS:001023339600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Weistroffer, V
   Keith, F
   Bisiaux, A
   Andriot, C
   Lasnier, A
AF Weistroffer, Vincent
   Keith, Francois
   Bisiaux, Arnaud
   Andriot, Claude
   Lasnier, Antoine
TI Using Physics-Based Digital Twins and Extended Reality for the Safety
   and Ergonomics Evaluation of Cobotic Workstations
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE digital twin; cobotics; safety; ergonomics; virtual reality; mixed
   reality; physics
ID ROBOT; IDENTIFICATION
AB Cobotic workstations in industrial plants involve a new kind of collaborative robots that can interact with operators. These cobots enable more flexibility and they can reduce the cycle time and the floor space of the workstation. However, cobots also introduce new safety concerns with regard to operators, and they may have an impact on the workstation ergonomics. For those reasons, introducing cobots in a workstation always require additional studies on safety and ergonomics before being applied and certified. Certification rules are often complex to understand. We present the SEEROB framework for the Safety and Ergonomics Evaluation of ROBotic workstations. The SEEROB framework simulates a physics-based digital twin of the cobotic workstation and computes a large panel of criteria used for safety and ergonomics. These criteria may be processed for the certification of the workstation. The SEEROB framework also uses extended reality technologies to display the digital twin and its associated data: users can use virtual reality headsets for the design of non-existing workstations, and mixed reality devices to better understand safety and ergonomics constraints on existing workstations. The SEEROB framework was tested on various laboratory and industrial use cases, involving different kinds of robots.
C1 [Weistroffer, Vincent; Keith, Francois; Bisiaux, Arnaud; Andriot, Claude] Univ Paris Saclay, CEA, List, Palaiseau, France.
   [Lasnier, Antoine] Light & Shadows, Suresnes, France.
C3 Universite Paris Cite; Universite Paris Saclay; CEA
RP Weistroffer, V (corresponding author), Univ Paris Saclay, CEA, List, Palaiseau, France.
EM vincent.weistroffer@cea.fr
OI Weistroffer, Vincent/0000-0002-2441-8458
CR Albert JA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185104
   Alexopoulos K, 2013, INT J COMPUT INTEG M, V26, P440, DOI 10.1080/0951192X.2012.731610
   [Anonymous], 2016, International Organization for Standardization
   Bernhardt R., 1994, Intelligent Manufacturing Systems 1994 (IMS'94). A Postprint Volume from the IFAC Workshop, P321
   Bernhardt R., 2000, AUTOMATION TRANSPORT, P115
   Castro PR, 2019, ADV INTELL SYST, V822, P250, DOI 10.1007/978-3-319-96077-7_26
   Chiacchio P, 1997, J ROBOTIC SYST, V14, P613, DOI 10.1002/(SICI)1097-4563(199708)14:8<613::AID-ROB3>3.0.CO;2-P
   DRILLIS R, 1964, Artif Limbs, V8, P44
   Dröder K, 2018, PROC CIRP, V76, P187, DOI 10.1016/j.procir.2018.02.010
   Eichler P, 2021, IEEE ROMAN, P1003, DOI 10.1109/RO-MAN50785.2021.9515437
   Ferraguti F, 2020, IEEE ROBOT AUTOM LET, V5, P5921, DOI 10.1109/LRA.2020.3010494
   Filipenko M., 2020, ARXIV, V2001, P08166
   Glogowski P, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P205, DOI 10.1109/ICAR46387.2019.8981635
   Guo J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P443, DOI [10.1109/VR46266.2020.1581306543750, 10.1109/VR46266.2020.00-39]
   Haddadin S, 2012, INT J ROBOT RES, V31, P1578, DOI 10.1177/0278364912462256
   Hignett S, 2000, APPL ERGON, V31, P201, DOI 10.1016/S0003-6870(99)00039-3
   Joseph L., 2020, INT C INT ROB SYST L
   Jubien A., 2014, IFAC P VOLUMES, V47, P8391, DOI DOI 10.3182/20140824-6-ZA-1003.01079
   KHATIB O, 1995, INT J ROBOT RES, V14, P19, DOI 10.1177/027836499501400103
   Kirschner RJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SAFETY FOR ROBOTICS (ISR), P6, DOI 10.1109/ISR50024.2021.9419495
   Kousi N, 2019, PROCEDIA MANUF, V28, P121, DOI 10.1016/j.promfg.2018.12.020
   Lacevic B, 2020, IEEE ROMAN, P1190, DOI 10.1109/RO-MAN47096.2020.9223342
   Lachner J, 2021, INT J ROBOT RES, V40, P968, DOI 10.1177/02783649211011639
   Lynch K. M., 2019, MODERN ROBOTICS MECH
   Malik AA, 2021, ROBOT CIM-INT MANUF, V68, DOI 10.1016/j.rcim.2020.102092
   Mansfeld Nico, 2018, IEEE Robotics and Automation Letters, V3, P1880, DOI 10.1109/LRA.2018.2801477
   Marvel JA, 2017, ROBOT CIM-INT MANUF, V44, P144, DOI 10.1016/j.rcim.2016.08.001
   Matsas E, 2018, ROBOT CIM-INT MANUF, V50, P168, DOI 10.1016/j.rcim.2017.09.005
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   Merlhiot X., 2007, P MULT DYN 2007 ECCO
   OPCFoundation, 2019, OPC UA ROB COMP SP 1
   Orsolino R, 2018, IEEE ROBOT AUTOM LET, V3, P3363, DOI 10.1109/LRA.2018.2836441
   Pavlou M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.646415
   Saenz J., 2021, COVR USING ROBOTICS
   Saenz J, 2020, INT J ADV MANUF TECH, V107, P2313, DOI 10.1007/s00170-020-05076-5
   Scalera L., 2020, INT J MECH CONTROL, V21, P41
   Schaub Karlheinz G., 2012, International Journal of Human Factors Modelling and Simulation, V3, P398
   Skuric A., 2020, ON LINE FORCE CAPABI, V2011, P05226
   Stürz YR, 2017, IFAC PAPERSONLINE, V50, P6863, DOI 10.1016/j.ifacol.2017.08.1208
   Svarny P., 2020, ABS2009 CORR, P01036
   Tika A, 2020, IEEE INT C INT ROBOT, P7300, DOI 10.1109/IROS45743.2020.9341518
   Vemula B, 2018, INT J INTELL ROBOT, V2, P226, DOI 10.1007/s41315-018-0055-9
   Weistroffer V, 2014, IEEE ROMAN, P377, DOI 10.1109/ROMAN.2014.6926282
   Wojtynek M., 2020, ISR 2020 52 INT S RO, P1
   Zanchettin AM, 2016, IEEE T AUTOM SCI ENG, V13, P882, DOI 10.1109/TASE.2015.2412256
   Zatsiorsky V., 1979, Voprosy Antropologii, V62, P91
NR 46
TC 10
Z9 10
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 9
PY 2022
VL 3
AR 781830
DI 10.3389/frvir.2022.781830
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YB9
UT WOS:001019228100001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Bagher, MM
   Sajjadi, P
   Wallgrün, JO
   La Femina, PC
   Klippel, A
AF Bagher, Mahda M.
   Sajjadi, Pejman
   Wallgrun, Jan Oliver
   La Femina, Peter C.
   Klippel, Alexander
TI Move The Object or Move The User: The Role of Interaction Techniques on
   Embodied Learning in VR
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; embodied learning; embodiment; bodily engagement;
   interaction technique; virtual learning environments; penetrative
   thinking; 3D visualization
ID VIRTUAL ENVIRONMENTS; SPATIAL PRESENCE; SOCIAL PRESENCE; REALITY;
   COPRESENCE; EDUCATION; OUTCOMES; FRAMES; SENSE
AB To incorporate immersive technologies as part of the educational curriculum, this article is an endeavor to investigate the role of two affordances that are crucial in designing embodied interactive virtual learning environments (VLEs) to enhance students' learning experience and performance: 1) the sense of presence as a subjective affordance of the VR system, and 2) bodily engagement as an embodied affordance and the associated sense of agency that is created through interaction techniques with three-dimensional learning objects. To investigate the impact of different design choices for interaction, and how they would affect the associated sense of agency, learning experience and performance, we designed two VLEs in the context of penetrative thinking in a critical 3D task in geosciences education: understanding the cross-sections of earthquakes' depth and geometry in subduction zones around the world. Both VLEs were web-based desktop VR applications containing 3D data that participants ran remotely on their own computers using a normal screen. In the drag and scroll condition, we facilitated bodily engagement with the 3D data through object manipulation, object manipulation. In the first-person condition, we provided the ability for the user to move in space. In other words, we compared moving the objects or moving the user in space as the interaction modalities. We found that students had a better learning experience in the drag and scroll condition, but we could not find a significant difference in the sense of presence between the two conditions. Regarding learning performance, we found a positive correlation between the sense of agency and knowledge gain in both conditions. In terms of students with low prior knowledge of the field, exposure to the VR experience in both conditions significantly improved their knowledge gain. In the matter of individual differences, we investigated the knowledge gain of students with a low penetrative thinking ability. We found that they benefited from the type of bodily engagement in the first-person condition and had a significantly higher knowledge gain than the other condition. Our results encourage in-depth studies of embodied learning in VR to design more effective embodied virtual learning environments.
C1 [Bagher, Mahda M.; Sajjadi, Pejman; Wallgrun, Jan Oliver; Klippel, Alexander] Penn State Univ PSU, Ctr Immers Experiences, Dept Geog, University Pk, PA 16802 USA.
   [La Femina, Peter C.] Penn State Univ, Dept Geosci, University Pk, PA USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park
RP Bagher, MM; Sajjadi, P (corresponding author), Penn State Univ PSU, Ctr Immers Experiences, Dept Geog, University Pk, PA 16802 USA.
EM mmm6749@psu.edu; sfs5919@psu.edu
FU Penn State Strategic Planning award [1685_TE_Cycle2]
FX & nbsp;This work was supported through a Penn State Strategic Planning
   award (proposal #1685_TE_Cycle2).
CR Bagher MM, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P132, DOI [10.23919/iLRN47897.2020.9155123, 10.23919/ilrn47897.2020.9155123]
   Bagher MM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P537, DOI [10.1109/VRW50115.2020.0-156, 10.1109/VRW50115.2020.00120]
   Bailey J., 2012, Proceedings of the International Society for Presence Research Annual Conference, P24
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147
   Biocca F, 1999, HUM FAC INF, V13, P113, DOI 10.1016/S0923-8433(99)80011-2
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Clifton PG, 2016, COGN RES, V1, DOI 10.1186/s41235-016-0032-5
   Coffin M. F., 1997, PRESENT DAY PLATE BO
   Community B., 2018, Blender-A 3D Modelling and Rendering Package, Stichting Blender Foundation
   Czerwinski E., 2020, P 7 ACM C LEARN SCAL, P221, DOI [10.1145/3386527.3405934, DOI 10.1145/3386527.3405934]
   Dalgarno B, 2011, AUSTRALAS J EDUC TEC, V27, P1
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Hannula K.A., 2019, J GEOSCIENCE ED, V67, P143, DOI DOI 10.1080/10899995.2018.1548004
   Hedges LV., 2014, STAT METHODS META AN
   Hegarty M, 2006, INTELLIGENCE, V34, P151, DOI 10.1016/j.intell.2005.09.005
   Hostetter AB, 2008, PSYCHON B REV, V15, P495, DOI 10.3758/PBR.15.3.495
   Jerald J., 2016, VR BOOK HUMAN CENTER
   Johnson-Glenberg MC, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P24, DOI [10.23919/ilrn47897.2020.9155155, 10.23919/iLRN47897.2020.9155155]
   Johnson-Glenberg MC, 2021, J COMPUT ASSIST LEAR, V37, P1263, DOI 10.1111/jcal.12567
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Johnson-Glenberg MC, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01819
   Johnson-Glenberg MC, 2014, J EDUC PSYCHOL, V106, P86, DOI 10.1037/a0034008
   Kelly JW, 2008, PSYCHON B REV, V15, P322, DOI 10.3758/PBR.15.2.322
   Kelly JW, 2010, COGNITION, V116, P409, DOI 10.1016/j.cognition.2010.06.002
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Klippel A, 2019, J EDUC COMPUT RES, V57, P1745, DOI 10.1177/0735633119854025
   Lages W. S., 2018, Frontiers in ICT, V5, P1, DOI [DOI 10.3389/FICT.2018.00015, 10.3389/fict.2018.00015]
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Legault J, 2019, LANGUAGES-BASEL, V4, DOI 10.3390/languages4010013
   Lindgren R, 2016, COMPUT EDUC, V95, P174, DOI 10.1016/j.compedu.2016.01.001
   Lindgren R, 2013, EDUC RESEARCHER, V42, P445, DOI 10.3102/0013189X13511661
   Mathewson JH, 1999, SCI EDUC, V83, P33, DOI 10.1002/(SICI)1098-237X(199901)83:1<33::AID-SCE2>3.3.CO;2-Q
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Mou WM, 2002, J EXP PSYCHOL LEARN, V28, P162, DOI 10.1037//0278-7393.28.1.162
   Newcombe N.S., 2015, STUDYING VISUAL SPAT, P179, DOI DOI 10.1007/978-94-017-9297-4_10
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Ormand C.J., 2014, J GEOSCIENCE ED, V62, P146, DOI DOI 10.5408/13-027.1
   Paas F, 2012, EDUC PSYCHOL REV, V24, P27, DOI 10.1007/s10648-011-9179-2
   Plummer JD, 2016, INT J SCI EDUC, V38, P345, DOI 10.1080/09500693.2016.1140921
   Pohontsch NJ, 2019, REHABILITATION, V58, P413, DOI 10.1055/a-0801-5465
   Repetto C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01839
   Ritzwoller MH, 2002, TECTONOPHYSICS, V358, P39, DOI 10.1016/S0040-1951(02)00416-X
   Ruscella J., 2021, 2021 7 INT C IMM LEA, P1, DOI [10.23919/ilrn52045.2021.9459328, DOI 10.23919/ILRN52045.2021.9459328]
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Shapiro L, 2007, PHILOS COMPASS, V2, P338, DOI 10.1111/j.1747-9991.2007.00064.x
   Shapiro L, 2014, ROUTLEDGE HBK PHILOS, P1
   Skulmowski A, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0092-9
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smyrnaiou Z., 2016, Inspiring Science Education, VVol. 31, P31
   Southgate E, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P38, DOI [10.23919/iLRN47897.2020.9155121, 10.23919/ilrn47897.2020.9155121]
   Stolz SA, 2015, EDUC PHILOS THEORY, V47, P474, DOI 10.1080/00131857.2013.879694
   Tarbuck EdwardJ., 1997, Earth Science
   Venzke E., 2013, Volcanoes of the World, DOI DOI 10.5479/SI.GVP.VOTW4-2013
   Vorderer P., 2004, Mec spatial presence questionnaire
   Waller D, 2007, PSYCHOL RES-PSYCH FO, V71, P322, DOI 10.1007/s00426-006-0087-x
   Weise M., 2019, P MENSCH COMP IEEE, P321, DOI [10.1145/3340764.3340777, DOI 10.1145/3340764.3340777]
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yeonhee C., 2018, THESIS SYRACUSE U SY
   Yuan L, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00128
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 71
TC 3
Z9 3
U1 1
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 25
PY 2021
VL 2
AR 695312
DI 10.3389/frvir.2021.695312
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PM5
UT WOS:001021730000001
OA gold
DA 2024-07-18
ER

PT J
AU Neidhardt, A
   Zerlik, AM
AF Neidhardt, Annika
   Zerlik, Anna Maria
TI The Availability of a Hidden Real Reference Affects the Plausibility of
   Position-Dynamic Auditory AR
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE auditory augmented reality; binaural synthesis; six degrees of freedom;
   perceptual evaluation; plausibility; authenticity; internal reference
ID AUTHENTICITY; REPRODUCTION; HEADPHONES
AB This study examines the plausibility of Auditory Augmented Reality (AAR) realized with position-dynamic binaural synthesis over headphones. An established method to evaluate the plausibility of AAR asks participants to decide whether they are listening to the virtual or real version of the sound object. To date, this method has only been used to evaluate AAR systems for seated listeners. The AAR realization examined in this study instead allows listeners to turn to arbitrary directions and walk towards, past, and away from a real loudspeaker that reproduced sound only virtually. The experiment was conducted in two parts. In the first part, the subjects were asked whether they are listening to the real or the virtual version, not knowing that it was always the virtual version. In the second part, the real versions of the scenes where the loudspeaker actually reproduced sound were added. Two different source positions, three different test stimuli, and two different sound levels were considered. Seventeen volunteers, including five experts, participated. In the first part, none of the participants noticed that the virtual reproduction was active throughout the different test scenes. The inexperienced listeners tended to accept the virtual reproduction as real, while experts distributed their answers approximately equally. In the second part, experts could identify the virtual version quite reliably. For inexperienced listeners, the individual results varied enormously. Since the presence of the headphones influences the perception of the real sound field, this shadowing effect had to be considered in the creation of the virtual sound source as well. This requirement still limits test methods considering the real version in its ecological validity. Although the results indicate that the availability of a hidden real reference leads to a more critical evaluation, it is crucial to be aware that the presence of the headphones slightly distorts the reference. This issue seems more vital to the plausibility estimates achieved with this evaluation method than the increased freedom in motion.
C1 [Neidhardt, Annika; Zerlik, Anna Maria] Tech Univ Ilmenau, Inst Media Technol, Ilmenau, Germany.
C3 Technische Universitat Ilmenau
RP Neidhardt, A (corresponding author), Tech Univ Ilmenau, Inst Media Technol, Ilmenau, Germany.
EM annika.neidhardt@tu-ilmenau.de
OI Neidhardt, Annika/0000-0002-4243-5737
CR [Anonymous], 2009, 126 INT AES CONV MUN
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Blauert J., 2020, TECHNOLOGY BINAURAL, DOI [10.1007/978-3-030-00386-9, DOI 10.1007/978-3-030-00386-9]
   Blauert J., 1997, SPATIAL HEARING PSYC
   Brinkmann F, 2017, J ACOUST SOC AM, V142, P1784, DOI 10.1121/1.5005606
   Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.1093/biomet/26.4.404
   Enge K., 2020, 46 ANN M AC DAGA HAN
   Erbes V., 2012, 38 ANN M AC DAGA DAR
   Gari S., 2019, EAA C SPAT AUD SIGN
   Hartmann WM, 1996, J ACOUST SOC AM, V99, P3678, DOI 10.1121/1.414965
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   Heller F, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P278, DOI 10.1145/2935334.2935365
   Herzog M., 2019, LEARNING MAT BIOSCIE
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI [10.3389/frvir.2020.00002, DOI 10.3389/FRVIR.2020.00002]
   Jot JM, 2016, 2016 AES INTERNATIONAL CONFERENCE ON AUDIO FOR VIRTUAL AND AUGMENTED REALITY
   Kamandi S., 2019, THESIS TU ILMENAU GE
   Kuhn-Rahloff C., 2011, THESIS TU BERLIN GER
   Langendijk EHA, 2000, J ACOUST SOC AM, V107, P528, DOI 10.1121/1.428321
   Latoschick M., 2021, ARXIV
   Lindau A., 2007, 122 CONV AUD ENG SOC
   Lindau A., 2009, NAG DAGA INT C AC RO
   Lindau A, 2012, ACTA ACUST UNITED AC, V98, P804, DOI 10.3813/AAA.918562
   Macmillan N. A., 2004, DETECTION THEORY USE, DOI [DOI 10.4324/9781410611147, 10.4324/9781410611147]
   Maseiro B., 2012, THESIS RWTH AACHEN G
   Moore AH, 2010, J AUDIO ENG SOC, V58, P36
   Nagele AN, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.610320
   Neidhardt A., 2019, 5 INT C SPAT AUD ICS
   Neidhardt A., 2017, 43 ANN C AC KIEL GER
   Neidhardt A., 2017, 142 INT AES CONV BER
   Neidhardt Annika, 2018, 144 INT AES CONV MIL, P1
   Oberem J, 2016, APPL ACOUST, V114, P71, DOI 10.1016/j.apacoust.2016.07.009
   Pike C., 2014, 55 INT AES C HELS FI
   PLENGE G, 1972, ACUSTICA, V26, P241
   Porschmann C., 2019, 1 EAA SPATIAL AUDIO
   Remaggi L., 2019, PERCEIVED QUALITY SP
   Russell S, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875247
   Satongar D, 2015, J AUDIO ENG SOC, V63, P799, DOI 10.17743/jaes.2015.0072
   Schneiderwind C., 2021, 150 INT AES CONV MAY
   Sicaru I., 2018, J INF SYST OPERATION, V11, P355
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stecker G., 2018, AES INT C AUD VIRT A
   Wefers F, 2018, VIRTUAL REAL-LONDON, V22, P281, DOI 10.1007/s10055-018-0332-9
   Wickens T. D., 2001, Elementary signal detection theory
   Wirler S., 2020, AES INT C AUD VIRT A
   Zielinski S, 2008, J AUDIO ENG SOC, V56, P427
NR 47
TC 6
Z9 6
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 6
PY 2021
VL 2
AR 678875
DI 10.3389/frvir.2021.678875
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8UO8
UT WOS:001019135500001
OA gold
DA 2024-07-18
ER

PT J
AU Oberdörfer, S
   Heidrich, D
   Birnstiel, S
   Latoschik, ME
AF Oberdoerfer, Sebastian
   Heidrich, David
   Birnstiel, Sandra
   Latoschik, Marc Erich
TI Enchanted by Your Surrounding? Measuring the Effects of Immersion and
   Design of Virtual Environments on Decision-Making
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual environments; immersion; decision-making; iowa
   gambling task
ID SOMATIC MARKER HYPOTHESIS; IOWA GAMBLING TASK; TIME CONSTRAINTS;
   PERFORMANCE; REALITY; RISK; OWNERSHIP; BEHAVIOR; ILLUSION; FUTURE
AB Impaired decision-making leads to the inability to distinguish between advantageous and disadvantageous choices. The impairment of a person's decision-making is a common goal of gambling games. Given the recent trend of gambling using immersive Virtual Reality it is crucial to investigate the effects of both immersion and the virtual environment (VE) on decision-making. In a novel user study, we measured decision-making using three virtual versions of the Iowa Gambling Task (IGT). The versions differed with regard to the degree of immersion and design of the virtual environment. While emotions affect decision-making, we further measured the positive and negative affect of participants. A higher visual angle on a stimulus leads to an increased emotional response. Thus, we kept the visual angle on the Iowa Gambling Task the same between our conditions. Our results revealed no significant impact of immersion or the VE on the IGT. We further found no significant difference between the conditions with regard to positive and negative affect. This suggests that neither the medium used nor the design of the VE causes an impairment of decision-making. However, in combination with a recent study, we provide first evidence that a higher visual angle on the IGT leads to an effect of impairment.
C1 [Oberdoerfer, Sebastian; Birnstiel, Sandra; Latoschik, Marc Erich] Univ Wurzburg, Chair Human Comp Interact, Wurzburg, Germany.
   [Heidrich, David] German Aerosp Ctr DLR, Inst Software Technol, Wessling, Germany.
C3 University of Wurzburg; Helmholtz Association; German Aerospace Centre
   (DLR)
RP Oberdörfer, S (corresponding author), Univ Wurzburg, Chair Human Comp Interact, Wurzburg, Germany.
EM sebastian.oberdoerfer@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600
CR Armstrong T, 2017, J GAMBL STUD, V33, P735, DOI 10.1007/s10899-016-9644-4
   Baird R, 2000, FILM QUART, V53, P12, DOI 10.1525/fq.2000.53.3.04a00030
   BARON RA, 1992, MOTIV EMOTION, V16, P1, DOI 10.1007/BF00996485
   Bechara A, 2002, NEUROPSYCHOLOGIA, V40, P1690, DOI 10.1016/S0028-3932(02)00016-7
   Bechara A, 2000, BRAIN, V123, P2189, DOI 10.1093/brain/123.11.2189
   Bechara A, 2005, TRENDS COGN SCI, V9, P159, DOI 10.1016/j.tics.2005.02.002
   Bechara A, 1998, J NEUROSCI, V18, P428
   Bechara A, 2005, GAME ECON BEHAV, V52, P336, DOI 10.1016/j.geb.2004.06.010
   BECHARA A, 1994, COGNITION, V50, P7, DOI 10.1016/0010-0277(94)90018-3
   Bechara A, 1997, SCIENCE, V275, P1293, DOI 10.1126/science.275.5304.1293
   Betz LT, 2019, SCHIZOPHR RES, V204, P7, DOI 10.1016/j.schres.2018.09.009
   Botkin D.B., 1997, Urban Ecosystems, V1, P3, DOI 10.1023/A:1014354923367
   Bowman CH, 2005, BRAIN COGNITION, V57, P21, DOI 10.1016/j.bandc.2004.08.015
   Brevers D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00665
   Brevers D, 2012, PSYCHIAT RES, V200, P568, DOI 10.1016/j.psychres.2012.03.053
   Caler K., 2016, CURR ADDICT REP, V3, P437, DOI DOI 10.1007/S40429-016-0118-7
   Cauffman E, 2010, DEV PSYCHOL, V46, P193, DOI 10.1037/a0016128
   Cella M, 2007, BRAIN COGNITION, V64, P164, DOI 10.1016/j.bandc.2007.02.003
   Chiu YC, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02353
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   DAMASIO AR, 1991, FRONTAL LOBE FUNCTION AND DYSFUNCTION, P217
   de Vries M, 2008, JUDGM DECIS MAK, V3, P42
   DeDonno MA, 2008, JUDGM DECIS MAK, V3, P636
   Dijkstra K, 2006, J ADV NURS, V56, P166, DOI 10.1111/j.1365-2648.2006.03990.x
   Dinis Susana, 2013, Design, User Experience, and Usability. User Experience in Novel Technological Environments. Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8014, P475, DOI 10.1007/978-3-642-39238-2_52
   Dunn BD, 2006, NEUROSCI BIOBEHAV R, V30, P239, DOI 10.1016/j.neubiorev.2005.07.001
   Ellsworth P.C., 1988, Cognition and Emotion, V2, P301, DOI [DOI 10.1080/02699938808412702, 10.1080/02699938808412702]
   Ernst M, 2003, AM J PSYCHIAT, V160, P33, DOI 10.1176/appi.ajp.160.1.33
   Ferris J., 2001, CANADIAN PROBLEM GAM
   Flores-Torres J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02538
   Franken IHA, 2005, PERS INDIV DIFFER, V39, P991, DOI 10.1016/j.paid.2005.04.004
   Gainsbury SM, 2014, PSYCHIAT RES, V217, P220, DOI 10.1016/j.psychres.2014.03.033
   Gall D, 2020, COMPUT HUM BEHAV, V109, DOI 10.1016/j.chb.2020.106346
   Gall D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P73, DOI 10.1109/VR.2018.8446153
   Graydon C, 2017, INT GAMBL STUD, V17, P442, DOI 10.1080/14459795.2017.1355404
   Griffiths M., 2017, Casino Gaming International, P51
   Griffiths MD, 2005, J GAMBLING ISSUES, P13, DOI DOI 10.4309/JGI.2005.13.8
   Grillon C, 1997, BIOL PSYCHIAT, V42, P453, DOI 10.1016/S0006-3223(96)00466-0
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Heidrich D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P793, DOI [10.1109/vr.2019.8798021, 10.1109/VR.2019.8798021]
   Heilman RM, 2010, EMOTION, V10, P257, DOI 10.1037/a0018489
   HTC Corporation, 2021, HTC VIVE
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Iyilikci EA, 2018, MOTIV EMOTION, V42, P1, DOI 10.1007/s11031-017-9643-5
   Kahneman D, 2007, TRENDS COGN SCI, V11, P45, DOI 10.1016/j.tics.2006.11.007
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Knez I, 2008, CYBERPSYCHOL BEHAV, V11, P129, DOI 10.1089/cpb.2007.0006
   Latoschik M. E., 2016, P ACM S VIRT REAL SO
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Lee WK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101878
   Lugrin J.-L., 2015, ICAT EGVE 2015 INT C, P1, DOI DOI 10.2312/EGVE.20151303
   Lynch T, 2015, J BROADCAST ELECTRON, V59, P298, DOI 10.1080/08838151.2015.1029128
   MacKerron G, 2013, GLOBAL ENVIRON CHANG, V23, P992, DOI 10.1016/j.gloenvcha.2013.03.010
   Maia TV, 2004, P NATL ACAD SCI USA, V101, P16075, DOI 10.1073/pnas.0406666101
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   McGonical Jane., 2011, REALITY IS BROKEN WH
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Miu AC, 2008, BIOL PSYCHOL, V77, P353, DOI 10.1016/j.biopsycho.2007.11.010
   Molde H, 2017, INT GAMBL STUD, V17, P349, DOI 10.1080/14459795.2017.1333130
   MORONEY WF, 1992, PROC NAECON IEEE NAT, P734, DOI 10.1109/NAECON.1992.220513
   Niedenthal S., 2007, WORLDS PLAY
   Oberdorfer S., 2018, P 10 INT C VIRT WORL, DOI [10.1109/VS-Games.2018.8493425, DOI 10.1109/VS-GAMES.2018.8493425]
   Oberdorfer S., 2013, GI-Jahrestagung, P2346
   Oberdorfer S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P483, DOI [10.1109/VR46266.2020.00-35, 10.1109/VR46266.2020.1581410387205]
   Pittig A, 2014, J ANXIETY DISORD, V28, P326, DOI 10.1016/j.janxdis.2014.03.001
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   Preston SD, 2007, BEHAV NEUROSCI, V121, P257, DOI 10.1037/0735-7044.121.2.257
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Reeves B., 1997, The Media equation: how people treat computers, television, and new media
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rockloff MJ, 2011, J GAMBL STUD, V27, P443, DOI 10.1007/s10899-010-9213-1
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Singh V., 2009, Mind Soc, V8, P43, DOI [10.1007/s11299-008-0050-1, DOI 10.1007/S11299-008-0050-1]
   Singh V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00628
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steinmetz KF, 2018, CRIME MEDIA CULT, V14, P265, DOI 10.1177/1741659017699045
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Toet A, 2009, CYBERPSYCHOL BEHAV, V12, P363, DOI 10.1089/cpb.2008.0293
   Ulrich R.S., 2001, DESIGN HLTH P 2 INT, P49
   Unity, 2021, UN 2019 3 10F1
   Valve Coorperation, 2015, STEAMVR PLUG
   van den Bos R, 2006, BIOL PSYCHOL, V71, P155, DOI 10.1016/j.biopsycho.2005.05.003
   van den Bos R, 2013, BEHAV BRAIN RES, V238, P95, DOI 10.1016/j.bbr.2012.10.002
   Vanhille S, 2018, J BEHAV DECIS MAKING, V31, P686, DOI 10.1002/bdm.2083
   Verdejo-Garcia A, 2007, DRUG ALCOHOL DEPEN, V90, P2, DOI 10.1016/j.drugalcdep.2007.02.004
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 97
TC 6
Z9 6
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 6
PY 2021
VL 2
AR 679277
DI 10.3389/frvir.2021.679277
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WQ5
UT WOS:001019190000001
OA gold, Green Published, Green Accepted
DA 2024-07-18
ER

PT J
AU Dagenais, M
   Brun, C
   Ohayon, A
   Mercier, C
AF Dagenais, Marion
   Brun, Clementine
   Ohayon, Alice
   Mercier, Catherine
TI Virtual Reality in Fibromyalgia: Does Altering Visual Feedback Impact on
   Pain and Movement During Reaching?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE upper limb; motor adaptation; altered feedback; chronic pain;
   kinesiophobia
ID PRIMARY SOMATOSENSORY CORTEX; SENSORIMOTOR INTEGRATION; TAMPA SCALE;
   NECK PAIN; FEAR; ADAPTATION; PEOPLE; KINESIOPHOBIA; EXCITABILITY;
   ACQUISITION
AB People with fibromyalgia (FM) have movement-related fear impacting on daily activities. While virtual reality has been used as a distractor to promote exercise, it can be used to manipulate visual feedback (VF) about movement, potentially influencing pain and movement. Objectives: A. To determine whether altered VF modulates pain during movement; B. To compare adaptation to an altered VF between FM participants and healthy controls (HC); C. To explore relationships between adaptation, limb position sense, kinesiophobia and pain. 20 FM participants and 20 HC performed a reaching task during two sessions in a KINARM exoskeleton including a virtual reality interface allowing to replace their arm with a virtual arm. In one session, VF was altered to show GREATER movements while in the other it showed SMALLER movements (randomized order). Pain was assessed periodically using a numerical rating scale. Movement amplitude was assessed during exposure to altered VF (adaptation) and pre-/post-exposure (without VF; after-effects). Limb position sense was assessed with a KINARM task, and kinesiophobia was assessed with the Tampa Scale for Kinesiophobia (TSK-11). Pain intensity increased slightly with movement repetitions (p < 0.001), but did not differ between the VF conditions (GREATER vs. SMALLER). Both groups exhibited visuomotor adaptation, as shown by VF-dependent changes in movement amplitude and speed during exposure to altered VF, and by the presence of VF-dependent after-effects (p < 0.001 for all variables). However, no differences were observed across groups for any of these variables, despite the fact that FM had significantly more difficulty to correctly detect VF conditions than HC (p = 0.046). No clear limb position sense deficits were observed in FM participants, and no significant relationships were found between TSK-11 scores and changes in pain intensity during exposure to altered VF. Altering VF did not influence pain during a reaching task in the FM group. Surprisingly, both groups adapted similarly to altered VF. Visuomotor adaptation is therefore preserved in FM, despite impairments in sensory perception and the poor ability to detect VF alterations in the present study. Further research is warranted to clarify the relationship between sensory perceptions and motor control in FM.
C1 [Dagenais, Marion; Brun, Clementine; Ohayon, Alice; Mercier, Catherine] Ctr Interdisciplinary Res Rehabil & Social Integra, Quebec City, PQ, Canada.
   [Dagenais, Marion; Ohayon, Alice; Mercier, Catherine] Laval Univ, Dept Rehabil, Quebec City, PQ, Canada.
C3 Laval University
RP Mercier, C (corresponding author), Ctr Interdisciplinary Res Rehabil & Social Integra, Quebec City, PQ, Canada.; Mercier, C (corresponding author), Laval Univ, Dept Rehabil, Quebec City, PQ, Canada.
EM catherine.mercier@rea.ulaval.ca
CR Akyol Y, 2013, TURK FIZ TIP REHAB D, V59, P292, DOI 10.4274/tftr.22230
   Asmundson GJG, 1999, CLIN PSYCHOL REV, V19, P97, DOI 10.1016/S0272-7358(98)00034-8
   Bagce HF, 2013, J NEUROPHYSIOL, V109, P1097, DOI 10.1152/jn.00304.2012
   Bank PJM, 2013, J PAIN, V14, P1460, DOI 10.1016/j.jpain.2013.07.009
   Bilodeau MC, 2016, EXP BRAIN RES, V234, P475, DOI 10.1007/s00221-015-4478-3
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Brun C, 2020, NEUROSCIENCE, V434, P55, DOI 10.1016/j.neuroscience.2020.03.017
   Brun C, 2019, EUR J PAIN, V23, P483, DOI 10.1002/ejp.1322
   Brun C, 2019, J PAIN, V20, P17, DOI 10.1016/j.jpain.2018.07.008
   Brun C, 2017, FRONT INTEGR NEUROSC, V11, DOI 10.3389/fnint.2017.00014
   Bultitude JH, 2021, BEHAV BRAIN RES, V397, DOI 10.1016/j.bbr.2020.112922
   Bultitude JH, 2010, EXP BRAIN RES, V204, P409, DOI 10.1007/s00221-009-2107-8
   Busch AJ, 2008, J RHEUMATOL, V35, P1130
   Celenay ST, 2019, RHEUMATOL INT, V39, P2087, DOI 10.1007/s00296-019-04399-1
   Chen KB, 2017, IEEE T NEUR SYS REH, V25, P1240, DOI 10.1109/TNSRE.2016.2621886
   Chen LM, 2003, SCIENCE, V302, P881, DOI 10.1126/science.1087846
   Christophe L, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/1694256
   Claeys K, 2011, EUR J APPL PHYSIOL, V111, P115, DOI 10.1007/s00421-010-1637-x
   Cressman EK, 2015, J NEUROPHYSIOL, V114, P354, DOI 10.1152/jn.00415.2014
   Dancey E, 2016, J NEUROPHYSIOL, V116, P2210, DOI 10.1152/jn.00337.2016
   Dancey E, 2016, PAIN, V157, P1682, DOI 10.1097/j.pain.0000000000000570
   Dancey E, 2014, EXP BRAIN RES, V232, P2879, DOI 10.1007/s00221-014-3966-1
   Di Pietro F, 2013, J PAIN, V14, P1001, DOI 10.1016/j.jpain.2013.04.001
   Dukelow SP, 2010, NEUROREHAB NEURAL RE, V24, P178, DOI 10.1177/1545968309345267
   French DJ, 2002, CAN J BEHAV SCI, V34, P28, DOI 10.1037/h0087152
   George SZ, 2012, CLIN J PAIN, V28, P73, DOI 10.1097/AJP.0b013e31822363f4
   Ghahramani Z, 1996, J NEUROSCI, V16, P7085
   Goldenberg DL, 2004, JAMA-J AM MED ASSOC, V292, P2388, DOI 10.1001/jama.292.19.2388
   Harden RN, 2010, PAIN, V150, P268, DOI 10.1016/j.pain.2010.04.030
   Harvie DS, 2016, PHYS THER, V96, P671, DOI 10.2522/ptj.20150210
   Harvie DS, 2015, PSYCHOL SCI, V26, P385, DOI 10.1177/0956797614563339
   Hayashi T, 2016, ENEURO, V3, DOI 10.1523/ENEURO.0032-16.2016
   Heinrich M, 2020, PHYSIOTHER THEOR PR, V36, P1220, DOI [10.1080/09593985.2019.1571140, 10.1109/CLEOE-EQEC.2019.8871746]
   Heuer H, 2008, J MOTOR BEHAV, V40, P368, DOI 10.3200/JMBR.40.5.368-379
   Ingham D, 2011, EUR J PAIN, V15, P1028, DOI 10.1016/j.ejpain.2011.04.006
   Jones T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167523
   Karsdorp PA, 2009, PAIN, V147, P29, DOI 10.1016/j.pain.2009.07.019
   Keefe FJ, 2012, PAIN, V153, P2163, DOI 10.1016/j.pain.2012.05.030
   Kim J, 2015, ARTHRITIS RHEUMATOL, V67, P1395, DOI 10.1002/art.39043
   Kragting M, 2021, PAIN PRACT, V21, P428, DOI 10.1111/papr.12971
   Krakauer JW, 2000, J NEUROSCI, V20, P8916, DOI 10.1523/jneurosci.20-23-08916.2000
   Lamothe M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099159
   Lewis JS, 2010, PAIN, V149, P463, DOI 10.1016/j.pain.2010.02.007
   Mannerkorpi K, 2003, BEST PRACT RES CL RH, V17, P629, DOI 10.1016/S1521-6942(03)00038-X
   Martínez E, 2019, CLIN J PAIN, V35, P887, DOI 10.1097/AJP.0000000000000754
   Martínez E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194534
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   Mavromatis N, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7020015
   McCabe Candida S, 2009, Curr Rheumatol Rep, V11, P461
   McDermid AJ, 1996, PAIN, V66, P133, DOI 10.1016/0304-3959(96)03059-X
   McLoughlin MJ, 2011, J PAIN, V12, P640, DOI 10.1016/j.jpain.2010.12.004
   McNally J Dayre, 2006, Chronic Dis Can, V27, P9
   Mercier C, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6040045
   Moseley GL, 2008, CURR BIOL, V18, pR1047, DOI 10.1016/j.cub.2008.09.031
   Parker RS, 2017, CLIN J PAIN, V33, P222, DOI 10.1097/AJP.0000000000000392
   Queiroz LP, 2013, CURR PAIN HEADACHE R, V17, DOI 10.1007/s11916-013-0356-5
   Roelofs J, 2007, PAIN, V131, P181, DOI 10.1016/j.pain.2007.01.008
   Roosink M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120251
   Salomoni SE, 2019, MED SCI SPORT EXER, V51, P2334, DOI 10.1249/MSS.0000000000002059
   Turk DC, 2004, J PAIN, V5, P483, DOI 10.1016/j.jpain.2004.08.002
   Turton AJ, 2007, PAIN, V127, P270, DOI 10.1016/j.pain.2006.08.021
   Vlaeyen JWS, 1995, J OCCUP REHABIL, V5, P235, DOI 10.1007/BF02109988
   Vuralli D., 2019, CLIN NEUROPHYSIOL, V130, pe107, DOI [10.1016/j.clinph.2019.04.580, DOI 10.1016/J.CLINPH.2019.04.580]
   Wiederhold BK, 2014, CYBERPSYCH BEH SOC N, V17, P346, DOI 10.1089/cyber.2014.0207
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wittkopf PG, 2018, EUR J PAIN, V22, P647, DOI 10.1002/ejp.1162
   WOLFE F, 1990, ARTHRITIS RHEUM-US, V33, P160, DOI 10.1002/art.1780330203
   Wolfe F, 2016, SEMIN ARTHRITIS RHEU, V46, P319, DOI 10.1016/j.semarthrit.2016.08.012
NR 68
TC 4
Z9 4
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 30
PY 2021
VL 2
AR 681034
DI 10.3389/frvir.2021.681034
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8XT1
UT WOS:001019219200001
OA gold
DA 2024-07-18
ER

PT J
AU Brown, P
   Powell, W
AF Brown, Phillip
   Powell, Wendy
TI Pre-Exposure Cybersickness Assessment Within a Chronic Pain Population
   in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; cybersickness; chronic pain; self-report; baseline;
   pre-exposure
ID MOTION SICKNESS; POSTURAL INSTABILITY; QUESTIONNAIRE
AB Virtual Reality (VR) is being increasingly explored as an adjunctive therapy for distraction from symptoms of chronic pain. However, using VR often causes cybersickness; a condition with symptoms similar to those of motion and simulator sickness. Cybersickness is commonly assessed using self-report questionnaires, such as the Simulator Sickness Questionnaire (SSQ), and is traditionally conducted post-exposure. It's usually safe to assume a zero baseline of cybersickness as participants are not anticipated to be exhibiting any sickness symptoms pre-exposure. However, amongst populations such as chronic pain patients, it's not unusual to experience symptoms of their condition or medication which could have a confounding influence on cybersickness symptom reporting. Therefore, in population groups where illness and medication use is common, assuming baseline is not necessarily desirable. This study aimed to investigate cybersickness baseline recordings amongst a chronic pain population, and highlights how deviations from an assumed baseline may incorrectly infer adverse effects arising from VR exposure. A repeated measures study design was used, in which twelve participants were assessed pre and post VR exposure via SSQ. Significant differences were found between actual and assumed pre-exposure baseline scores. Furthermore, we found significant differences between actual and assumed increases in cybersickness scores from baseline to post exposure. This study highlights that clinical sub-populations cannot be assumed to have a zero baseline SSQ score, and this should be taken into consideration when evaluating the usability of VR systems or interventions for participants from different demographics.
C1 [Brown, Phillip; Powell, Wendy] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
C3 Tilburg University
RP Brown, P (corresponding author), Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
EM p.c.brown@tilburguniversity.edu
OI Brown, Phillip/0000-0002-3775-8101; Powell, Wendy/0000-0002-7234-5628
FU Faculty of Creative and Cultural Industries at the University of
   Portsmouth
FX & nbsp;This work was funded by the Faculty of Creative and Cultural
   Industries at the University of Portsmouth.
CR Allen KD, 2009, OSTEOARTHR CARTILAGE, V17, P1275, DOI 10.1016/j.joca.2009.03.021
   Ames SL, 2005, OPTOMETRY VISION SCI, V82, P168, DOI 10.1097/01.OPX.0000156307.95086.6
   Bahat HS, 2015, MANUAL THER, V20, P68, DOI 10.1016/j.math.2014.06.008
   Bartley EJ, 2018, J PAIN, V19, P372, DOI 10.1016/j.jpain.2017.11.014
   Benyamin R, 2008, PAIN PHYSICIAN, V11, pS105
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Crofford Leslie J, 2015, Trans Am Clin Climatol Assoc, V126, P167
   CRONBACH LJ, 1970, PSYCHOL BULL, V74, P68, DOI 10.1037/h0029382
   Davis S., 2015, 11 AUSTR C INT ENT I
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Garrett B, 2017, JMIR MED INF, V5, P17, DOI 10.2196/medinform.7271
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Kennedy R. S., 1965, EFFECTS VISUAL DEPRI, DOI [10.1037/e430802004-001, DOI 10.1037/E430802004-001]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kruk R. V., 1992, FLIGHT SIMULATION TE, DOI [10.2514/6.1992-4135, DOI 10.2514/6.1992-4135]
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lubetzky AV, 2018, PHYSIOTHER THEOR PR, V34, P935, DOI 10.1080/09593985.2018.1431344
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   MOORE PA, 1979, PAIN, V6, P375, DOI 10.1016/0304-3959(79)90055-1
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stoffregen TA, 2000, HUM FACTORS, V42, P458, DOI 10.1518/001872000779698097
   Valmaggia LR, 2016, PSYCHIAT RES, V236, P189, DOI 10.1016/j.psychres.2016.01.015
   Vaughan N, 2016, MED ENG PHYS, V38, P59, DOI 10.1016/j.medengphy.2015.11.021
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wiederhold BK, 2014, CYBERPSYCH BEH SOC N, V17, P346, DOI 10.1089/cyber.2014.0207
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolfe F, 2010, ARTHRIT CARE RES, V62, P600, DOI 10.1002/acr.20140
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Young SD, 2006, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2006.44
NR 42
TC 7
Z9 7
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 4
PY 2021
VL 2
AR 672245
DI 10.3389/frvir.2021.672245
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OK1
UT WOS:001021701500001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Glémarec, Y
   Lugrin, JL
   Bosser, AG
   Jackson, AC
   Buche, C
   Latoschik, ME
AF Glemarec, Yann
   Lugrin, Jean-Luc
   Bosser, Anne-Gwenn
   Jackson, Aryana Collins
   Buche, Cedric
   Latoschik, Marc Erich
TI <i>Indifferent or Enthusiastic</i>? Virtual Audiences Animation and
   Perception in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; perception; nonverbal behavior; interaction; virtual
   agent; virtual audience
ID PUBLIC-SPEAKING ANXIETY; EXPOSURE THERAPY; PERFORMANCE
AB In this paper, we present a virtual audience simulation system for Virtual Reality (VR). The system implements an audience perception model controlling the nonverbal behaviors of virtual spectators, such as facial expressions or postures. Groups of virtual spectators are animated by a set of nonverbal behavior rules representing a particular audience attitude (e.g., indifferent or enthusiastic). Each rule specifies a nonverbal behavior category: posture, head movement, facial expression and gaze direction as well as three parameters: type, frequency and proportion. In a first user-study, we asked participants to pretend to be a speaker in VR and then create sets of nonverbal behaviour parameters to simulate different attitudes. Participants manipulated the nonverbal behaviours of single virtual spectator to match a specific levels of engagement and opinion toward them. In a second user-study, we used these parameters to design different types of virtual audiences with our nonverbal behavior rules and evaluated their perceptions. Our results demonstrate our system's ability to create virtual audiences with three types of different perceived attitudes: indifferent, critical, enthusiastic. The analysis of the results also lead to a set of recommendations and guidelines regarding attitudes and expressions for future design of audiences for VR therapy and training applications.
C1 [Glemarec, Yann; Bosser, Anne-Gwenn; Jackson, Aryana Collins] Lab STICC, ENIB, CNRS, UMR 6285, Brest, France.
   [Glemarec, Yann; Lugrin, Jean-Luc; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
   [Buche, Cedric] CROSSING, ENIB, CNRS IRL, Adelaide, SA 2010, Australia.
C3 Ecole Nationale d'Ingenieurs de Brest (ENIB); Universite de Bretagne
   Occidentale; Centre National de la Recherche Scientifique (CNRS);
   University of Wurzburg
RP Glémarec, Y (corresponding author), Lab STICC, ENIB, CNRS, UMR 6285, Brest, France.; Glémarec, Y (corresponding author), Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
EM yann.glemarec@uni-wuerzburg.de
RI Lugrin, Jean-Luc/KMA-1030-2024; Latoschik, Marc Erich/HLG-5348-2023
OI Lugrin, Jean-Luc/0000-0002-2725-2123; Latoschik, Marc
   Erich/0000-0002-9340-9600; Glemarec, Yann/0000-0003-1717-6048
FU ENIB, French Ministry of Higher Education, Research and Innovation;
   VIRTUALTIMES project by European Union [ID-824128]; University of
   Wuerzburg
FX YG is funded by the ENIB, French Ministry of Higher Education, Research
   and Innovation. This work is PARTIALLY funded by the VIRTUALTIMES
   project (ID-824128) funded by the European Union under the Horizon 2020
   program. This publication was supported by the Open Access Publication
   Fund of the University of Wuerzburg.
CR Anderson PL, 2013, J CONSULT CLIN PSYCH, V81, P751, DOI 10.1037/a0033559
   Anderson PL, 2005, DEPRESS ANXIETY, V22, P156, DOI 10.1002/da.20090
   ARTHUR KW, 1993, ACM T INFORM SYST, V11, P239, DOI 10.1145/159161.155359
   Barmaki R, 2018, P AAAI C ART INT, V32
   Batrinca Ligia, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P116, DOI 10.1007/978-3-642-40415-3_10
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Chollet M, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1800
   Chollet M, 2017, IEEE COMPUT GRAPH, V37, P50, DOI 10.1109/MCG.2017.3271465
   Chollet M, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1657
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Delamarre A, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P78, DOI 10.1109/ISMAR-Adjunct51615.2020.00036
   Ekman P., 2000, Handbook of cognition and emotion pp, P45, DOI 10.1002/0470013494.ch3
   Fukuda M, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P11, DOI 10.1145/3125739.3125776
   Gebhard P, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P497
   Glemarec Y., 2020, MENSCH COMPUTER 2020, DOI [10.18420/muc2020-ws134-337, DOI 10.18420/MUC2020-WS134-337]
   Guimaraes M, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423879
   Hale KS, 2006, APPL ERGON, V37, P329, DOI 10.1016/j.apergo.2005.06.009
   Harris SR, 2002, CYBERPSYCHOL BEHAV, V5, P543, DOI 10.1089/109493102321018187
   Hayes A. T., 2013, PROCEEDINGS, P142, DOI [10.1007/978-3-642-39420-1_16, DOI 10.1007/978-3-642-39420-1_16]
   Heudin J.-C., 2007, INT C VIRT SYST MULT, P154
   Heudin JC, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P93, DOI 10.1109/IAT.2004.1342929
   Hosseinpanah A, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P184, DOI 10.1145/3284432.3284442
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Kang N, 2016, COMPUT HUM BEHAV, V55, P680, DOI 10.1016/j.chb.2015.10.008
   Kistler F, 2012, J MULTIMODAL USER IN, V6, P39, DOI 10.1007/s12193-011-0087-z
   Laslett R., 2002, EFFECTIVE CLASSROOM, DOI [10.4324/9780203130087, DOI 10.4324/9780203130087]
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Lee C, 2010, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2010.5444820
   Lugrin J.L., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, P49, DOI [10.1145/2503713.2503730, DOI 10.1145/2503713.2503730]
   Lugrin J-L., 2016, FRONTIERS ICT, V3, P26, DOI [10.3389/fict.2016.00026, DOI 10.3389/FICT.2016.00026]
   Marsella S., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P334
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Messinis I, 2010, 2010 INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING: IC4E 2010, PROCEEDINGS, P428, DOI 10.1109/IC4E.2010.137
   Narayan M., 2005, P ACM S VIRT REAL SO, P78, DOI DOI 10.1145/1101616.1101632
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Poppe R, 2010, LECT NOTES ARTIF INT, V6356, P146, DOI 10.1007/978-3-642-15892-6_16
   ROSEMAN IJ, 1991, COGNITION EMOTION, V5, P161, DOI 10.1080/02699939108411034
   Rothbaum BO, 2000, J CONSULT CLIN PSYCH, V68, P1020, DOI 10.1037/0022-006X.68.6.1020
   Shernoff ES, 2020, ETR&D-EDUC TECH RES, V68, P3235, DOI 10.1007/s11423-020-09819-9
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Slater M, 2009, ANU PSICOL, V40, P193
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Wiederhold B., 2012, ANN REV CYBERTHERAPY, V181, P218, DOI [10.3233/978-1-61499-121-2-218, DOI 10.3233/978-1-61499-121-2-218]
NR 44
TC 11
Z9 11
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 1
PY 2021
VL 2
AR 666232
DI 10.3389/frvir.2021.666232
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TT4
UT WOS:001021841700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Pimentel, D
   Kalyanaraman, S
   Fillingim, R
   Halan, S
AF Pimentel, Daniel
   Kalyanaraman, Sri
   Fillingim, Roger
   Halan, Shiva
TI The Effects of VR Use on Pain Experienced During a Tattoo Procedure: A
   Pilot Study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; pain; tattoo; body modification; analgesia
ID IMMERSIVE VIRTUAL-REALITY; INTERACTIVITY; PERCEPTIONS; MANAGEMENT;
   ANALGESIA; RESPONSES; THERAPY; STRESS; BUFFER
AB One of the most socially impactful applications of virtual reality (VR) is its use as a non-pharmacological remedy for both acute and chronic pain. Yet, despite robust findings establishing the analgesic effects of VR, use cases almost exclusively involve (a) patients with acute/chronic pain, which are often difficult to access and vary widely in terms of pain location/severity, or (b) experimentally induced pain, which can have low lab-to-life generalizability. One understudied pain context that may reconcile these limitations is body modification, specifically tattoo procedures. Examining the use of VR during a tattoo offers several benefits to VR and pain research. First, tattoo recipients as a participant pool are more accessible. Second, tattoo pain is presumably more standardized and uniform as it is administered by a machine at a consistent force. Thus, to test these assumptions and expand the scope of VR applications in this domain, we present a mixed-methods investigation testing the effects of VR on pain experienced during a tattoo. Leveraging qualitative interviews with tattoo artists and customers, a 3-month on-site field experiment at a tattoo parlor was conducted. Customers' self-reported pain ratings (N = 16) were collected during 1-h tattooing sessions and compared between a treatment (VR) and control group. As expected, VR significantly reduced pain ratings during the procedure, and increased pain resilience. By suggesting that the analgesic effects of VR extend to volitional pain during a tattoo, we argue that tattoo pain warrants attention by both VR content developers and researchers interested in studying how immersive content influences real-world pain perception. The study also yields specific guidelines to help designers create and deploy VR experiences for this context. Overall, the results suggest that tattoo sessions present a promising context worthy of further investigation across a variety of VR research programs.
C1 [Pimentel, Daniel] Univ Oregon, Sch Journalism & Commun, Oregon Real Lab, Portland, OR 97211 USA.
   [Kalyanaraman, Sri; Halan, Shiva] Univ Florida, Sch Journalism & Commun, Media Effects & Technol Lab, Gainesville, FL USA.
   [Fillingim, Roger] Univ Florida, Coll Dent, Pain Res & Intervent Ctr Excellence, Gainesville, FL USA.
   [Halan, Shiva] Facebook, Menlo Pk, CA USA.
C3 University of Oregon; State University System of Florida; University of
   Florida; State University System of Florida; University of Florida;
   Facebook Inc
RP Pimentel, D (corresponding author), Univ Oregon, Sch Journalism & Commun, Oregon Real Lab, Portland, OR 97211 USA.
EM pimend@uoregon.edu
OI Pimentel, Daniel/0000-0002-7512-4484
CR Ahmadpour N, 2019, INT J BIOCHEM CELL B, V114, DOI 10.1016/j.biocel.2019.105568
   Ankawi B, 2020, PSYCHOSOM MED, V82, P593, DOI 10.1097/PSY.0000000000000823
   Babiloni C, 2006, J PAIN, V7, P709, DOI 10.1016/j.jpain.2006.03.005
   Beasley M., 2011, SOUTH CALIF LAW REV, V85, P1238
   Berkley KJ, 1997, BEHAV BRAIN SCI, V20, P371, DOI 10.1017/S0140525X97221485
   Bingel U, 2011, SCI TRANSL MED, V3, DOI 10.1126/scitranslmed.3001244
   Breuner CC, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2017-1962
   Chapman CR, 2008, J PAIN, V9, P122, DOI 10.1016/j.jpain.2007.09.006
   Chen Q, 2016, COMPUT HUM BEHAV, V54, P34, DOI 10.1016/j.chb.2015.07.047
   Chi B., 2019, VIRTUAL AUGMENTED RE, P221, DOI [10.4018/978-1-7998-1680-5.ch013, DOI 10.4018/978-1-7998-1680-5.CH013]
   Chow H, 2021, J PAIN SYMPTOM MANAG, V61, P384, DOI 10.1016/j.jpainsymman.2020.08.016
   Dann C, 2019, SOC PERSONAL PSYCHOL, V13, DOI 10.1111/spc3.12438
   Dascal Julieta, 2017, Innov Clin Neurosci, V14, P14
   Davies AN, 2006, BRIT J HOSP MED, V67, P414, DOI 10.12968/hmed.2006.67.8.21960
   FISCHER AA, 1987, PAIN, V30, P115, DOI 10.1016/0304-3959(87)90089-3
   Gerin W, 2000, J PSYCHOSOM RES, V48, P369, DOI 10.1016/S0022-3999(99)00095-1
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Guillory JE, 2014, J PUBLIC RELAT RES, V26, P44, DOI 10.1080/1062726X.2013.795866
   Gupta A, 2018, PAIN MED, V19, P151, DOI 10.1093/pm/pnx109
   Hayes A.F., 2021, PROCESS: A versatile computational tool for observed variable mediation, moderation
   Hayes AF, 2015, MULTIVAR BEHAV RES, V50, P1, DOI 10.1080/00273171.2014.962683
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2008, CLIN J PAIN, V24, P299, DOI 10.1097/AJP.0b013e318164d2cc
   Hoffman HG, 2014, CYBERPSYCH BEH SOC N, V17, P397, DOI 10.1089/cyber.2014.0058
   Hurst W., 2016, 2016 IEEE INT C MULT, P1, DOI [10.1109/IC- MEW.2016.7574692, DOI 10.1109/ICMEW.2016.7574692]
   Indovina P, 2018, CLIN J PAIN, V34, P858, DOI 10.1097/AJP.0000000000000599
   Kalyanaraman S, 2015, HBK COMMUN MEDIA, P425
   Kenny V, 2009, CONSTR FOUND, V4, P100
   Kipping B, 2012, BURNS, V38, P650, DOI 10.1016/j.burns.2011.11.010
   Kolodny A, 2017, JAMA-J AM MED ASSOC, V318, P1537, DOI 10.1001/jama.2017.14567
   Lauwens Y, 2020, CHILDREN-BASEL, V7, DOI 10.3390/children7110194
   Law EF, 2011, J PEDIATR PSYCHOL, V36, P84, DOI 10.1093/jpepsy/jsq063
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Liu YP, 2009, J ADVERTISING, V38, P53, DOI 10.2753/JOA0091-3367380204
   Lunde SJ, 2019, PAIN, V160, P989, DOI 10.1097/j.pain.0000000000001452
   Lyapustina T., 2015, PHARM J
   Mahrer NE, 2009, CURR PAIN HEADACHE R, V13, P100, DOI 10.1007/s11916-009-0019-8
   Oliver MB, 2007, J BROADCAST ELECTRON, V51, P596, DOI 10.1080/08838150701626446
   Park S, 2019, EUR J APPL PHYSIOL, V119, P771, DOI 10.1007/s00421-018-04068-4
   Patterson DR, 2010, INT J CLIN EXP HYP, V58, P288, DOI 10.1080/00207141003760595
   Phelan I, 2019, J BURN CARE RES, V40, P85, DOI 10.1093/jbcr/iry052
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Rennefeld C, 2010, PAIN, V148, P503, DOI 10.1016/j.pain.2009.12.014
   Sapp J L., 2019, JMIR Dermatol, vol, V2, n, DOI DOI 10.2196/14151
   Scheffler M, 2018, BURNS, V44, P1709, DOI 10.1016/j.burns.2017.11.019
   Schmitt YS, 2011, BURNS, V37, P61, DOI 10.1016/j.burns.2010.07.007
   Slepian PM, 2016, J PAIN, V17, P462, DOI 10.1016/j.jpain.2015.12.010
   Spiegel Brennan., 2020, VRx: How Virtual Therapeutics Will Revolutionize Medicine
   Stone AA, 2000, J PAIN, V1, P212, DOI 10.1054/jpai.2000.7568
   Sweetman P., 1999, BODY SOC, V5, P51
   Tashjian VC, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7387
   Technalysis Research, 2018, VR AR HEADS AV SESS
   Trost Z, 2021, PAIN, V162, P325, DOI 10.1097/j.pain.0000000000002060
   Uman Lindsay S., 2006, Cognitive Behaviour Therapy, V35, P189, DOI 10.1080/16506070600898512
   van den Berg AE, 2010, SOC SCI MED, V70, P1203, DOI 10.1016/j.socscimed.2010.01.002
   WEISS R, 1994, EVALUATION REV, V18, P651, DOI 10.1177/0193841X9401800601
   Wells NM, 2003, ENVIRON BEHAV, V35, P311, DOI 10.1177/0013916503035003001
   Wender Regina, 2009, J Cyber Ther Rehabil, V2, P27
   Won AS, 2017, CHILDREN-BASEL, V4, DOI 10.3390/children4070052
   Wright Jonathan L, 2005, Urology, V66, P1320
NR 61
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 23
PY 2021
VL 2
AR 643938
DI 10.3389/frvir.2021.643938
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YU1
UT WOS:001023344900001
OA gold
DA 2024-07-18
ER

PT J
AU Lamers, MH
   Lanen, M
AF Lamers, Maarten H.
   Lanen, Maik
TI Changing Between Virtual Reality and Real-World Adversely Affects Memory
   Recall Accuracy
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; memory; context-dependency; recall; transfer
ID CONTEXT-DEPENDENT MEMORY; ENVIRONMENTS; SICKNESS; TASK
AB Context-dependency effects on memory exist, whereby people's context influences their ability to accurately recall items from memory. This effect was not previously studied when considering virtual reality as an environmental context. We show that adverse effects on recall of memorized items exist when changing between virtual and real environments. The effect was not present when memorizing and recall were both done in VR; it appears to be caused by the change of environmental context. This previously unknown effect may impact how we use VR for memorization tasks, particularly when accurate recall of memorized information in a real environment is important. In a memory-recall experiment (n = 51) participants that underwent a context change involving VR after memorizing performed significantly worse on 24-h later item recall than those who did not change context (17% lower accuracy, p < 0.001). In particular memorizing in VR as opposed to a real environment lowers accuracy of recall in a real environment (24% lower, p = 0.001).
C1 [Lamers, Maarten H.; Lanen, Maik] Leiden Univ, Leiden Inst Adv Comp Sci, Leiden, Netherlands.
C3 Leiden University - Excl LUMC; Leiden University
RP Lamers, MH (corresponding author), Leiden Univ, Leiden Inst Adv Comp Sci, Leiden, Netherlands.
EM m.h.lamers@liacs.leidenuniv.nl
OI Lamers, Maarten/0000-0003-2672-5475
CR Attree E.A., 1996, P 1 EUROPEAN C DISAB, P117
   BOWER GH, 1978, J VERB LEARN VERB BE, V17, P573, DOI 10.1016/S0022-5371(78)90348-1
   Burke D. M., 1987, SOCIAL BEHAV SCI DOC, V17
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   European Commission, 2012, DESCR DEF LEV EUR QU
   GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325, DOI 10.1111/j.2044-8295.1975.tb01468.x
   GOODWIN DW, 1969, SCIENCE, V163, P1358, DOI 10.1126/science.163.3873.1358
   Gould NF, 2007, AM J PSYCHIAT, V164, P516, DOI 10.1176/appi.ajp.164.3.516
   Johnson AJ, 2008, BRIT J PSYCHOL, V99, P293, DOI 10.1348/000712607X228474
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Lanen M., 2018, THESIS LEIDEN U LEID
   Lanen M, 2018, LECT NOTES COMPUT SC, V11162, P177, DOI 10.1007/978-3-030-01790-3_11
   Mania K, 2003, PRESENCE-TELEOP VIRT, V12, P296, DOI 10.1162/105474603765879549
   MARKS LE, 1964, J VERB LEARN VERB BE, V3, P1, DOI 10.1016/S0022-5371(64)80052-9
   Matheis RJ, 2007, CLIN NEUROPSYCHOL, V21, P146, DOI 10.1080/13854040601100668
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   PGA Group Consulting Psychologists, 2018, STANDARDIZED SURVEY
   Plancher G, 2010, NEUROPSYCHOLOGY, V24, P379, DOI 10.1037/a0018680
   Smith SA, 2019, PSYCHON B REV, V26, P1213, DOI 10.3758/s13423-019-01605-w
   Smith SM, 2001, PSYCHON B REV, V8, P203, DOI 10.3758/BF03196157
   Sweeney S, 2010, NEUROPSYCHOL REHABIL, V20, P239, DOI 10.1080/09602010903080531
NR 22
TC 2
Z9 2
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 18
PY 2021
VL 2
AR 602087
DI 10.3389/frvir.2021.602087
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TW9
UT WOS:001021845200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Dilgul, M
   Hickling, LM
   Antonie, D
   Priebe, S
   Bird, VJ
AF Dilgul, Merve
   Hickling, Lauren M.
   Antonie, Daniela
   Priebe, Stefan
   Bird, Victoria J.
TI Virtual Reality Group Therapy for the Treatment of Depression: A
   Qualitative Study on Stakeholder Perspectives
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; digital intervention; depression; qualitative;
   treatment
ID COGNITIVE-BEHAVIORAL THERAPY; METAANALYSIS; PSYCHOTHERAPY; TECHNOLOGY;
   ANXIETY; DROPOUT
AB Background: Cognitive behavioral group therapy alleviates depression by teaching patients to think and behave in more positive ways. Teletherapy (e.g., Zoom) is becoming more widely used, especially during the COVID-19 pandemic (where meeting in person is not safe). The current study explores the acceptability of taking teletherapy to the next level: Virtual Reality Group Therapy (VRGT).Methods: Semistructured interviews were conducted to explore stakeholder views on VRGT. Ten depressed patients and ten therapists watched a demonstration video of the proposed VRGT intervention and tested the VR application using a stand-alone VR headset. In VRGT, patients will use an avatar to interact with each other and with their therapist via networked multiparticipant VR.Results: Therapists and patients generally responded favorably to the idea of doing group therapy sessions in VR. Patients especially liked the idea of remaining anonymous via an avatar. Patients and therapists both indicated that the anonymity provided by avatars could increase patient's willingness to make disclosures (to talk more freely and honestly), which could increase participation and could lead to better group cohesion.Conclusion: Although the findings suggested that VRGT may be more acceptable for some patients than for others, overall, the response of the patients and therapists was largely positive. Recommendations from this study could be used during the COVID-19 pandemic to deliver VRGTs. Finally, design ideas for creating a group VR world custom-designed for group therapy are discussed.
C1 [Dilgul, Merve; Hickling, Lauren M.; Priebe, Stefan; Bird, Victoria J.] Queen Mary Univ London, Inst Populat Hlth Sci, Unit Social & Community Psychiat, London, England.
   [Dilgul, Merve; Hickling, Lauren M.; Priebe, Stefan; Bird, Victoria J.] East London NHS Fdn Trust, London, England.
   [Antonie, Daniela] Newham Talking Therapies, London, England.
   [Dilgul, Merve; Hickling, Lauren M.; Priebe, Stefan; Bird, Victoria J.] Newham Ctr Mental Hlth, Unit Social & Community Psychiat, London, England.
   [Antonie, Daniela] Vicarage Lane Hlth Ctr, London, England.
C3 University of London; Queen Mary University London
RP Dilgul, M (corresponding author), Queen Mary Univ London, Inst Populat Hlth Sci, Unit Social & Community Psychiat, London, England.; Dilgul, M (corresponding author), East London NHS Fdn Trust, London, England.; Dilgul, M (corresponding author), Newham Ctr Mental Hlth, Unit Social & Community Psychiat, London, England.
EM m.dilgul@qmul.ac.uk
CR Ågerfalk PJ, 2010, EUR J INFORM SYST, V19, P251, DOI 10.1057/ejis.2010.22
   [Anonymous], 2018, Depression in adults: recognition and management
   Arthur S., 2014, QUALITATIVE RES PRAC, V10th, P147
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Braun V, 2013, Success Qual Res, V1st
   Bucci S, 2019, PSYCHOL PSYCHOTHER-T, V92, P277, DOI 10.1111/papt.12222
   Carr CE, 2017, TRIALS, V18, DOI 10.1186/s13063-017-1893-8
   Clark DM, 2011, INT REV PSYCHIATR, V23, P318, DOI 10.3109/09540261.2011.606803
   Cuijpers P, 2008, EUR J PSYCHIAT, V22, P38, DOI 10.4321/s0213-61632008000100005
   Dilgul Merve, 2020, Consort Psychiatr, V1, P30, DOI 10.17650/2712-7672-2020-1-1-30-46
   Dilgul M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208448
   Dobson C., 2008, CONDUCTING RES PEOPL
   Fairburn CG, 2017, BEHAV RES THER, V88, P19, DOI 10.1016/j.brat.2016.08.012
   Fenn K., 2013, INNOVAIT, V6, P579, DOI DOI 10.1177/1755738012471029
   Fernandez E, 2015, J CONSULT CLIN PSYCH, V83, P1108, DOI 10.1037/ccp0000044
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Hans E, 2013, J CONSULT CLIN PSYCH, V81, P75, DOI 10.1037/a0031080
   Huntley AL, 2012, BRIT J PSYCHIAT, V200, P184, DOI 10.1192/bjp.bp.111.092049
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI 10.1145/2792790
   Knowles LM, 2017, COMPUT HUM BEHAV, V73, P650, DOI 10.1016/j.chb.2017.04.005
   Kösters M, 2006, GROUP DYN-THEOR RES, V10, P146, DOI 10.1037/1089-2699.10.2.146
   Limited H., 2020, VTIME SOC NETW
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   McDermut W, 2001, CLIN PSYCHOL-SCI PR, V8, P98, DOI 10.1093/clipsy/8.1.98
   NHS Improvement, 2018, PSYCH THER ANN REP U, P1
   NHS Mental Health Taskforce, 2016, 5 YEAR FORW VIEW MEN, P1
   Norcross JC, 2013, PROF PSYCHOL-RES PR, V44, P363, DOI 10.1037/a0034633
   Nosek MA, 2016, REHABIL PSYCHOL, V61, P358, DOI 10.1037/rep0000107
   O'Brien BC, 2014, ACAD MED, V89, P1245, DOI 10.1097/ACM.0000000000000388
   Patton MQ., 2002, QUALITATIVE RES EVAL, V3
   Price M, 2014, CLIN PSYCHOL PSYCHOT, V21, P427, DOI 10.1002/cpp.1855
   Queen Mary University of London, 2020, UN SOC COMM PSYCH
   Ralston AL, 2019, CLIN PSYCHOL-SCI PR, V26, DOI 10.1111/cpsp.12277
   Riessman C.K., 1993, Narrative analysis (Qualitative Research Methods Volume 30), V30
   Sampaio M, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.576421
   Sekhon M, 2017, BMC HEALTH SERV RES, V17, DOI 10.1186/s12913-017-2031-8
   Simpson A, 2014, J PSYCHOSOC NURS MEN, V52, P22, DOI 10.3928/02793695-20131126-04
   Suler J, 2004, CYBERPSYCHOL BEHAV, V7, P321, DOI 10.1089/1094931041291295
   Tucker M, 2007, BEHAV COGN PSYCHOTH, V35, P77, DOI 10.1017/S1352465806003134
   Watson Alice J, 2008, J Diabetes Sci Technol, V2, P697
   Williams M., 2016, KEY CONCEPTS PHILOS, V1st Edn, P170
   Wykes T, 1999, BRIT J PSYCHIAT, V175, P180, DOI 10.1192/bjp.175.2.180
   Yalom I., 1975, THEORY PRACTICE GROU
   Yardley L, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4055
   Yeo A., 2014, QUALITATIVE RES PRAC, V2nd, P177
NR 45
TC 7
Z9 9
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 25
PY 2021
VL 1
AR 609545
DI 10.3389/frvir.2020.609545
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8XI0
UT WOS:001019208000001
OA gold
DA 2024-07-18
ER

PT J
AU Wu, YJ
   Lukosch, S
   Lukosch, H
   Lindeman, RW
   Mckee, RD
   Fukuden, S
   Ross, C
   Collins, D
AF Wu, Yuanjie
   Lukosch, Stephan
   Lukosch, Heide
   Lindeman, Robert W.
   Mckee, Ryan Douglas
   Fukuden, Shunsuke
   Ross, Cameron
   Collins, Dave
TI Training mental imagery skills of elite athletes in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality (VR); mental imagery; positive and negative affect;
   sports training; elite athletes
ID SPORT; RESPONSES; PRESSURE; PETTLEP
AB Mental imagery practice is widely used to help athletes prepare for competitions, as it can produce motor actions that enhance performance. The goal of imagery training for athletes is to create realistic images in their minds and to familiarize them with certain procedures, environments, and other aspects related to competition. Traditional imagery training methods use still images or videos, and athletes study the pictures or watch the videos in order to mentally rehearse. However, factors such as distractions and low realism can affect the training quality. In this paper, we present a Virtual Reality (VR) solution and a study that explores our hypotheses that H (1): high-fidelity VR systems improve mental imagery skills, that H- 2: the presence of elements such as virtual onlookers or photographers in the VR environment arouse stronger emotional reactions and affect, and that H (3): the presence of elements such as onlookers or photographers in the VR environment results in better mental imagery skill improvement. For that purpose, seven elite snow sports athletes were exposed to three training methods, Video, VR-Empty, and VR-Crowded. Our results show that a VR simulation with virtual onlookers (VR-Crowded) can significantly increase heart rate, which can induce increased emotional arousal. The results from validated questionnaires show no significant difference for the three training methods in terms of mental imagery and affect, but the results show an ascending trend for the athlete's arousal from Video to the VR-Crowded condition. Gaze detection heat maps of interest areas for the two VR conditions support hypothesis H (2) that environmental factors such as the presence of photographers, staff, and onlookers can increase head and eye movement, possibly indicating an increase in emotional arousal during imagery training. According to verbal feedback and interviews, athletes are more likely to use innovative training methods (e.g., the high-fidelity VR method) than traditional video-training methods.
C1 [Wu, Yuanjie; Lukosch, Stephan; Lukosch, Heide; Lindeman, Robert W.; Mckee, Ryan Douglas; Fukuden, Shunsuke] Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
   [Ross, Cameron] Snow Sports New Zealand, Wanaka, New Zealand.
   [Ross, Cameron] High Performance Sport New Zealand, Auckland, New Zealand.
   [Collins, Dave] Grey Matters Performance Ltd, Stratford Upon Avon, England.
   [Collins, Dave] Univ Edinburgh, Sch Educ & Sport, Edinburgh, Scotland.
C3 University of Canterbury; University of Edinburgh
RP Lukosch, S (corresponding author), Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
EM stephan.lukosch@canterbury.ac.nz
FU The development of the VR system used in this study was funded by High
   Performance Sports NZ.; High Performance Sports NZ
FX We would like to thank the participants of our user studies for their
   help and feedback on our work. We would also like to thank the reviewers
   of our submission for their detailed and constructive feedback on
   earlier drafts.r The development of the VR system used in this study was
   funded by High Performance Sports NZ.
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Akbas A, 2019, J HUM KINET, V69, P5, DOI 10.2478/hukin-2019-0023
   Barber T. X., 1975, AM J CLIN HYPN, V17, P279, DOI [10.1080/00029157.1975.10403760, DOI 10.1080/00029157.1975.10403760]
   Bedir D, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02073
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Budnik-Przybylska D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29811-6
   Calabrò RS, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0268-4
   Collins D, 2017, CURR OPIN PSYCHOL, V16, P12, DOI 10.1016/j.copsyc.2017.03.007
   Critchley HD, 2002, NEUROSCIENTIST, V8, P132, DOI 10.1177/107385840200800209
   Crookall D, 2014, SIMULAT GAMING, V45, P416, DOI 10.1177/1046878114559879
   Cumming J, 2002, J SPORT SCI, V20, P137, DOI 10.1080/026404102317200846
   Cumming J., 2012, ROLE IMAGERY PERFORM
   DESCHAUMESMOLINARO C, 1992, PHYSIOL BEHAV, V51, P1021, DOI 10.1016/0031-9384(92)90086-H
   Ehrlenspiel F., 2006, THESIS U POTSDAM POT
   Farnsworth B., 2018, What is GSR (galvanic skin response) and how does it work?
   Frank C, 2023, INT REV SPORT EXER P, DOI 10.1080/1750984X.2023.2167225
   Frank C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095175
   Gregg M, 2006, J APPL SPORT PSYCHOL, V18, P363, DOI 10.1080/10413200600944140
   Hall C. R., 2001, IMAGERY SPORT EXERCI, V2nd edn, P529
   Holmes PS, 2001, J APPL SPORT PSYCHOL, V13, P60, DOI 10.1080/10413200109339004
   JONES GE, 1980, PSYCHOPHYSIOLOGY, V17, P339, DOI 10.1111/j.1469-8986.1980.tb00160.x
   Jordan C. S., 1979, J MENT IMAG
   Kriz WC, 2010, SIMULAT GAMING, V41, P663, DOI 10.1177/1046878108319867
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LANG PJ, 1980, PSYCHOPHYSIOLOGY, V17, P179, DOI 10.1111/j.1469-8986.1980.tb00133.x
   LANG PJ, 1979, PSYCHOPHYSIOLOGY, V16, P495, DOI 10.1111/j.1469-8986.1979.tb01511.x
   Lindsay RS, 2023, PHYS EDUC SPORT PEDA, V28, P444, DOI 10.1080/17408989.2021.1991297
   Martin KA, 1999, SPORT PSYCHOL, V13, P245, DOI 10.1123/tsp.13.3.245
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Nozawa T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1341, DOI [10.1109/VR.2019.8797717, 10.1109/vr.2019.8797717]
   Olsson CJ, 2008, SCAND J PSYCHOL, V49, P133, DOI 10.1111/j.1467-9450.2008.00625.x
   Ouadahi N, 2016, PROCEDIA ENGINEER, V147, P532, DOI 10.1016/j.proeng.2016.06.233
   Pereira M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00527
   Rhodes J, 2022, INT J SPORT EXERC PS, V20, P1556, DOI 10.1080/1612197X.2021.1987959
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Ross-Stewart L., 2018, J SPORTS SCI, V6, P20, DOI [DOI 10.1017/JLG.2018.3, DOI 10.17265/2332-7839/2018.01.003]
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Sanz FA, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00010
   Simonsmeier BA, 2021, INT REV SPORT EXER P, V14, P186, DOI 10.1080/1750984X.2020.1780627
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   WANG YD, 1992, BEHAV BRAIN RES, V52, P167, DOI 10.1016/S0166-4328(05)80227-X
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weinberg R, 2003, J APPL SPORT PSYCHOL, V15, P26, DOI 10.1080/10413200305398
   Wellner M, 2010, P I MECH ENG P-J SPO, V224, P117, DOI 10.1243/17543371JSET33
   Williams SE, 2011, J SPORT EXERCISE PSY, V33, P416, DOI 10.1123/jsep.33.3.416
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yoo HJ, 2005, SUPPORT CARE CANCER, V13, P826, DOI 10.1007/s00520-005-0806-7
NR 48
TC 0
Z9 1
U1 15
U2 22
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 14
PY 2023
VL 4
AR 1189717
DI 10.3389/frvir.2023.1189717
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Q4EP6
UT WOS:001057069400001
OA gold
DA 2024-07-18
ER

PT J
AU van den Berg, A
   de Vries, B
   Breedveld, Z
   van Mierlo, A
   Tijhuis, M
   Marchal-Crespo, L
AF van den Berg, Alex
   de Vries, Bart
   Breedveld, Zoe
   van Mierlo, Annelouk
   Tijhuis, Marnix
   Marchal-Crespo, Laura
TI Embodiment of virtual feet correlates with motor performance in a
   target-stepping task: a pilot study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE embodiment; gait training; virtual reality; avatar; locomotion; motor
   perfomance; rehabilitation
ID BODY OWNERSHIP; REALITY; AVATAR; REHABILITATION; SYSTEM; SENSE; HAND
AB Immersive Virtual Reality (IVR) has gained popularity in neurorehabilitation for its potential to increase patients' motivation and engagement. A crucial yet relatively unexplored aspect of IVR interfaces is the patients' representation in the virtual world, such as with an avatar. A higher level of embodiment over avatars has been shown to enhance motor performance during upper limb training and has the potential to be employed to enhance neurorehabilitation. However, the relationship between avatar embodiment and gait performance remains unexplored. In this work, we present the results of a pilot study with 12 healthy young participants that evaluates the effect of different virtual lower limb representations on foot placement accuracy while stepping over a trail of 16 virtual targets. We compared three levels of virtual representation: i) a full-body avatar, ii) only feet, and iii) no representation. Full-body tracking is computed using standard VR trackers to synchronize the avatar with the participants' motions. Foot placement accuracy is measured as the distance between the foot's center of mass and the center of the selected virtual target. Additionally, we evaluated the level of embodiment over each virtual representation through a questionnaire. Our findings indicate that foot placement accuracy increases with some form of virtual representation, either full-body or foot, compared to having no virtual representation. However, the foot and full-body representations do not show significant differences in accuracy. Importantly, we found a negative correlation between the level of embodiment of the foot representation and the distance between the placed foot and the target. However, no such correlation was found for the full-body representation. Our results highlight the importance of embodying a virtual representation of the foot when performing a task that requires accurate foot placement. However, showing a full-body avatar does not appear to further enhance accuracy. Moreover, our results suggest that the level of embodiment of the virtual feet might modulate motor performance in this stepping task. This work motivates future research on the effect of embodiment over virtual representations on motor control to be exploited for IVR gait rehabilitation.
C1 [van den Berg, Alex; de Vries, Bart; Breedveld, Zoe; van Mierlo, Annelouk; Tijhuis, Marnix; Marchal-Crespo, Laura] Delft Univ Technol, Cognit Robot Dept, Motor Learning & Neurorehabil Lab, Delft, Netherlands.
   [Marchal-Crespo, Laura] Erasmus MC, Dept Rehabil Med, Rotterdam, Netherlands.
C3 Delft University of Technology; Erasmus University Rotterdam; Erasmus MC
RP van den Berg, A (corresponding author), Delft Univ Technol, Cognit Robot Dept, Motor Learning & Neurorehabil Lab, Delft, Netherlands.
EM a.vandenberg-2@tudelft.nl
RI de Vries, Bart/KBB-8561-2024
FU Dutch Research Council (NWO) [18934]
FX This work was partially supported by the Dutch Research Council (NWO)
   under the VIDI 2020 grant 18934, titled "Hyper-Realistic Personalized
   Multisensory Robotic Neurorehabilitation".
CR [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   Bates DW, 2015, BMJ QUAL SAF, V24, P1, DOI 10.1136/bmjqs-2014-003499
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Bonfert M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P711, DOI 10.1109/VR51125.2022.00092
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Cho S, 2014, COMPUT METH PROG BIO, V113, P258, DOI 10.1016/j.cmpb.2013.09.006
   EA MCMANUS., 2011, P ACM SIGGRAPH S APP, P37, DOI DOI 10.1145/2077451.2077458
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Ferreira B, 2020, INFORMATION, V11, DOI 10.3390/info11020088
   Flueratoru L, 2020, INT C ULTRA MOD TELE, P214, DOI [10.1109/icumt51630.2020.9222439, 10.1109/ICUMT51630.2020.9222439]
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gonzalez-Franco M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P941, DOI [10.1109/VR.2019.8798348, 10.1109/vr.2019.8798348]
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Grechuta K, 2017, SCI REP-UK, V7, DOI [10.1038/s41598-017-15016-1, 10.1038/s41598-017-03488-0]
   Kashif M., 2022, MEDICINE, V101, DOI [10.1097/MD.0000000000029212, DOI 10.1097/MD.0000000000029212]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim A, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0584-y
   Kim SI, 2013, IEEE ENG MED BIO, P4621, DOI 10.1109/EMBC.2013.6610577
   Kosmalla F., 2020, 2020 CHI C HUM FACT, V1-8
   Lee JH, 2003, CYBERPSYCHOL BEHAV, V6, P383, DOI 10.1089/109493103322278763
   Massetti T, 2018, J CENT NERV SYST DIS, V10, DOI 10.1177/1179573518813541
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Odermatt IA, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.678909
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Porras DC, 2018, NEUROLOGY, V90, P1017, DOI 10.1212/WNL.0000000000005603
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   Tsakiris M, 2007, CEREB CORTEX, V17, P2235, DOI 10.1093/cercor/bhl131
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
NR 35
TC 1
Z9 1
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 18
PY 2023
VL 4
AR 1104638
DI 10.3389/frvir.2023.1104638
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA O0YD2
UT WOS:001041155000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Bente, G
   Schmaelzle, R
   Jahn, NT
   Schaaf, A
AF Bente, Gary
   Schmaelzle, Ralf
   Jahn, Nolan T.
   Schaaf, Andrea
TI Measuring the effects of co-location on emotion perception in shared
   virtual environments: An ecological perspective
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual enviornment; emotion perception; virtual reality; co-presence;
   avatars; non-verbal communication
ID SOCIAL PRESENCE; PERFORMANCE; TECHNOLOGY; BEHAVIOR; REALISM; AVATAR;
   TASK
AB Inferring emotions from others' non-verbal behavior is a pervasive and fundamental task in social interactions. Typically, real-life encounters imply the co-location of interactants, i.e., their embodiment within a shared spatial-temporal continuum in which the trajectories of the interaction partner's Expressive Body Movement (EBM) create mutual social affordances. Shared Virtual Environments (SVEs) and Virtual Characters (VCs) are increasingly used to study social perception, allowing to reconcile experimental stimulus control with ecological validity. However, it remains unclear whether display modalities that enable co-presence have an impact on observers responses to VCs' expressive behaviors. Drawing upon ecological approaches to social perception, we reasoned that sharing the space with a VC should amplify affordances as compared to a screen display, and consequently alter observers' perceptions of EBM in terms of judgment certainty, hit rates, perceived expressive qualities (arousal and valence), and resulting approach and avoidance tendencies. In a between-subject design, we compared the perception of 54 10-s animations of VCs performing three daily activities (painting, mopping, sanding) in three emotional states (angry, happy, sad)-either displayed in 3D as a co-located VC moving in shared space, or as a 2D replay on a screen that was also placed in the SVEs. Results confirm the effective experimental control of the variable of interest, showing that perceived co-presence was significantly affected by the display modality, while perceived realism and immersion showed no difference. Spatial presence and social presence showed marginal effects. Results suggest that the display modality had a minimal effect on emotion perception. A weak effect was found for the expression "happy," for which unbiased hit rates were higher in the 3D condition. Importantly, low hit rates were observed for all three emotion categories. However, observers judgments significantly correlated for category assignment and across all rating dimensions, indicating universal decoding principles. While category assignment was erroneous, though, ratings of valence and arousal were consistent with expectations derived from emotion theory. The study demonstrates the value of animated VCs in emotion perception studies and raises new questions regarding the validity of category-based emotion recognition measures.
C1 [Bente, Gary; Schmaelzle, Ralf; Jahn, Nolan T.; Schaaf, Andrea] Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA.
C3 Michigan State University
RP Bente, G (corresponding author), Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA.
EM gabente@msu.edu
FU National Science Foundation [1907807]
FX Funding This work was supported by the National Science Foundation
   (grant number 1907807).
CR [Anonymous], 2002, P 5 INT WORKSH PRES
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Aviezer H, 2012, SCIENCE, V338, P1225, DOI 10.1126/science.1224313
   Axelsson AS, 2001, CYBERPSYCHOL BEHAV, V4, P279, DOI 10.1089/109493101300117956
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Basori AH, 2013, PROCD SOC BEHV, V97, P700, DOI 10.1016/j.sbspro.2013.10.290
   Bente G, 2001, J NONVERBAL BEHAV, V25, P151, DOI 10.1023/A:1010690525717
   Bente G., 2019, Reflections on interpersonal communication, P161
   Bente G., 2001, INTELLIGENT INTERACT, P67
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Blascovich J., 2011, Infinite Reality: Avatars, Eternal Life, New Worlds, and the Dawn of the Virtual Revolution
   BUCK R, 1985, PSYCHOL REV, V92, P389
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P435, DOI 10.1162/105474699566323
   Casanueva J., 2001, THESIS U OF CAPE TOW
   Crane EA, 2013, J NONVERBAL BEHAV, V37, P91, DOI 10.1007/s10919-013-0144-2
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   de Gelder B, 2015, WIRES COGN SCI, V6, P149, DOI 10.1002/wcs.1335
   de Gelder B, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00181
   Dings R, 2018, PHENOMENOL COGN SCI, V17, P681, DOI 10.1007/s11097-017-9534-y
   Fabri M., 2004, Virtual Reality, V7, P66, DOI 10.1007/s10055-003-0116-7
   Felton WM, 2022, INT J HUM-COMPUT INT, V38, P1, DOI 10.1080/10447318.2021.1921368
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Goffman Erving, 1963, BEHAV PUBLIC PLACES
   Grabarczyk P, 2016, AVANT, V7, P25, DOI 10.26913/70202016.0112.0002
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Hepperle D, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2020), P41, DOI 10.1109/CW49994.2020.00014
   Hepperle D, 2022, VISUAL COMPUT, V38, P1227, DOI 10.1007/s00371-021-02151-0
   Huijsmans MK, 2022, J EXP PSYCHOL HUMAN, V48, P1, DOI 10.1037/xhp0000974
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Lammers S, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00094
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lombard M., 2011, 2011 ANN C INT SOC P
   Martinez L, 2016, COGNITION EMOTION, V30, P939, DOI 10.1080/02699931.2015.1035229
   Matsumoto D., 2012, Nonverbal communication: Science and applications
   MCARTHUR LZ, 1983, PSYCHOL REV, V90, P215, DOI 10.1037/0033-295X.90.3.215
   McGloin R, 2011, PRESENCE-TELEOP VIRT, V20, P309, DOI 10.1162/PRES_a_00053
   Minsky M., 1980, Omni, V2, P44
   Noel S., 2009, HUMAN COMPUTER INTER, V5742, DOI [10.1007/978-3-642-03655-2_11, DOI 10.1007/978-3-642-03655-2_11]
   Normoyle Aline, 2013, P ACM S APPL PERC, P91, DOI [DOI 10.1145/2492494.2492500, 10.1145/2492494.2492500]
   Nowak K., 2001, 4 ANN INT WORKSH COM, P686
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Poeschl S, 2013, STUD HEALTH TECHNOL, V191, P33, DOI 10.3233/978-1-61499-282-0-33
   Reynolds RM, 2019, J NONVERBAL BEHAV, V43, P529, DOI 10.1007/s10919-019-00312-3
   Rogers SL, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.750729
   Schroeder R, 2006, PRESENCE-VIRTUAL AUG, V15, P438, DOI 10.1162/pres.15.4.438
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Sun YL, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694453
   Thie S., 1998, 1 INT WORKSH PRES LP
   Visch VT, 2014, COGNITION EMOTION, V28, P936, DOI 10.1080/02699931.2013.865595
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Worldviz, 2021, WE BUILD VR LABS
   Zebrowitz L A, 1997, Pers Soc Psychol Rev, V1, P204, DOI 10.1207/s15327957pspr0103_2
   Zebrowitz LA, 2002, PSYCHOL INQ, V13, P143
NR 63
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 13
PY 2023
VL 4
AR 1032510
DI 10.3389/frvir.2023.1032510
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0FR6
UT WOS:001020103500001
OA gold
DA 2024-07-18
ER

PT J
AU Barhorst-Cates, EM
   Isaacs, MW
   Buxbaum, LJ
   Wong, AL
AF Barhorst-Cates, Erica M.
   Isaacs, Mitchell W.
   Buxbaum, Laurel J.
   Wong, Aaron L.
TI Does spatial perspective in virtual reality affect imitation accuracy in
   stroke patients?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE imitation; virtual reality; spatial perspective; stroke; apraxia
ID MENTAL ROTATION; MIRROR NEURONS; GESTURES; REPRESENTATIONS;
   REHABILITATION; MOVEMENTS; CHILDREN; BRAIN; MODEL; BODY
AB Imitation is an important daily activity involved in social interactions, motor learning, and is commonly used for rehabilitation after stroke. Moreover, deficits in imitation of novel movements commonly occur after left hemisphere stroke (LCVA) in the syndrome of limb apraxia. In the current study, we used a novel virtual reality (VR) imitation paradigm to assess two factors that have remained underexplored in novel movement imitation: the imitation of complex, dynamic full-arm movements, and the effect of spatial perspective. VR holds promise as a tool for a number of clinical assessments and treatments, but has very rarely been studied in the context of imitation or diagnosis of apraxia. Thirty participants (18 with LCVA and 12 age- and education-matched controls) wore a VR headset and observed and imitated an instructor avatar demonstrating arm movements. Three spatial perspectives were examined within-subjects: first-person, third-person mirror, and third-person anatomical. Movements of the ipsilesional (left) arm were recorded and qualitatively coded for accuracy compared to the instructor avatar. Participants also completed embodiment questionnaires, a measure of limb apraxia (imitation of video-recorded meaningless movements), and three computerized background tasks that were hypothesized to evoke some of the same processing requirements of each of the three perspective conditions: a block-matching task, a block-mirroring task, and a mental rotation task. Imitation accuracy was highest in the first-person perspective, consistent with predictions, but did not differ between third-person mirror and anatomical. Surprisingly, patients and controls performed similarly on the imitation task for all spatial perspectives, with overall modest accuracy in both groups, and both patients and controls felt a moderate level of embodiment of their own avatar. Higher imitation accuracy related to quicker block-matching reaction times and higher mental rotation accuracy, regardless of perspective, but was unrelated to imitation of video-recorded meaningless movements. In sum, virtual reality provides advantages in terms of experimental manipulation and control but may present challenges in detecting clinical imitation deficits (limb apraxia).
C1 [Barhorst-Cates, Erica M.; Isaacs, Mitchell W.; Buxbaum, Laurel J.; Wong, Aaron L.] Moss Rehabil Res Inst, Philadelphia, PA 19141 USA.
RP Barhorst-Cates, EM (corresponding author), Moss Rehabil Res Inst, Philadelphia, PA 19141 USA.
EM Erica.Barhorst-Cates@jefferson.edu
OI Barhorst-Cates, Erica/0000-0001-9007-5652; Buxbaum,
   Laurel/0000-0003-2421-5455
FU Albert Einstein Society of the Einstein Healthcare Network [AES 19-02];
   NIH [R01 NS115862, R01 NS099061, 5T32HD071844]; Eunice Kennedy Shriver
   National Institute of Child Health and Human Development [T32HD071844]
   Funding Source: NIH RePORTER; National Institute of Neurological
   Disorders and Stroke [R01NS115862] Funding Source: NIH RePORTER
FX This research was supported by grant AES 19-02 from the Albert Einstein
   Society of the Einstein Healthcare Network, NIH grants R01 NS115862 to
   ALW and R01 NS099061 to LJB, and NIH postdoctoral training fellowship
   5T32HD071844.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bekkering H, 2000, Q J EXP PSYCHOL-A, V53, P153, DOI 10.1080/027249800390718
   Bevilacqua R, 2019, J CLIN MED, V8, DOI 10.3390/jcm8111882
   Brockmole JR, 2003, COGNITION, V87, pB59, DOI 10.1016/S0010-0277(02)00231-7
   Buxbaum LJ, 2007, CORTEX, V43, P411, DOI 10.1016/S0010-9452(08)70466-0
   Buxbaum Laurel J, 2018, Handb Clin Neurol, V151, P349, DOI 10.1016/B978-0-444-63622-5.00017-6
   Buxbaum LJ, 2014, BRAIN, V137, P1971, DOI 10.1093/brain/awu111
   Buxbaum LJ, 2012, NEUROPSYCHOLOGY, V26, P430, DOI 10.1037/a0028674
   Buxbaum LJ, 2005, COGNITIVE BRAIN RES, V25, P226, DOI 10.1016/j.cogbrainres.2005.05.014
   Alarcón-Aldana AC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20215989
   Chiavarino C, 2007, NEUROPSYCHOLOGIA, V45, P784, DOI 10.1016/j.neuropsychologia.2006.08.007
   Creem-Regehr SH, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00596
   DERENZI E, 1980, ARCH NEUROL-CHICAGO, V37, P6, DOI 10.1001/archneur.1980.00500500036003
   Donkervoort M, 2000, CLIN REHABIL, V14, P130, DOI 10.1191/026921500668935800
   Fitzpatrick M., 2018, MIRRORING SOCIAL LEA
   Franceschini M, 2010, EUR J PHYS REHAB MED, V46, P517
   Franz EA, 2007, BRAIN RES, V1145, P138, DOI 10.1016/j.brainres.2007.01.136
   Garcea Frank E, 2020, Cereb Cortex Commun, V1, ptgaa035, DOI 10.1093/texcom/tgaa035
   GOLDENBERG G, 1995, NEUROPSYCHOLOGIA, V33, P63, DOI 10.1016/0028-3932(94)00104-W
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Hatem SM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00442
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Isaacs MW, 2022, CORTEX, V147, P140, DOI 10.1016/j.cortex.2021.11.010
   Jackson PL, 2006, NEUROIMAGE, V31, P429, DOI 10.1016/j.neuroimage.2005.11.026
   Jax SA, 2006, J COGNITIVE NEUROSCI, V18, P2063, DOI 10.1162/jocn.2006.18.12.2063
   Kalénine S, 2013, NEUROPSYCHOLOGIA, V51, P1224, DOI 10.1016/j.neuropsychologia.2013.03.017
   Kessler K, 2010, COGNITION, V114, P72, DOI 10.1016/j.cognition.2009.08.015
   Krause D, 2013, HUM MOVEMENT SCI, V32, P314, DOI 10.1016/j.humov.2012.10.001
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Lenth R.V., 2022, Estimated marginal means, aka least-squares means
   Liao YL, 2020, COMPUT BIOL MED, V119, DOI 10.1016/j.compbiomed.2020.103687
   Mueller ST, 2014, J NEUROSCI METH, V222, P250, DOI 10.1016/j.jneumeth.2013.10.024
   Nishizawa H, 2015, J PHYS THER SCI, V27, P3417, DOI 10.1589/jpts.27.3417
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Peugh JL, 2010, J SCHOOL PSYCHOL, V48, P85, DOI 10.1016/j.jsp.2009.09.002
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   SCHOFIELD WN, 1976, Q J EXP PSYCHOL, V28, P571, DOI 10.1080/14640747608400584
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Small SL, 2012, DEV PSYCHOBIOL, V54, P293, DOI 10.1002/dev.20504
   Watanabe R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00701
   Watanabe R, 2013, EXP BRAIN RES, V228, P161, DOI 10.1007/s00221-013-3548-7
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [10.1007/978-3-319-24277-4, DOI 10.1007/978-3-319-24277-4]
   Wong AL, 2019, J NEUROSCI, V39, P3320, DOI 10.1523/JNEUROSCI.2597-18.2019
   Zacks JM, 2008, J COGNITIVE NEUROSCI, V20, P1, DOI 10.1162/jocn.2008.20013
NR 49
TC 0
Z9 0
U1 2
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 7
PY 2022
VL 3
AR 934642
DI 10.3389/frvir.2022.934642
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XT3
UT WOS:001023318000001
PM 37063476
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Glémarec, Y
   Lugrin, JL
   Bosser, AG
   Buche, C
   Latoschik, ME
AF Glemarec, Yann
   Lugrin, Jean-Luc
   Bosser, Anne-Gwenn
   Buche, Cedric
   Latoschik, Marc Erich
TI Controlling the Stage: A High-Level Control System for Virtual Audiences
   in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual agent; behavior perception; public speaking;
   education
ID PUBLIC-SPEAKING ANXIETY; EXPOSURE THERAPY; SOCIAL ANXIETY; PERFORMANCE;
   BEHAVIOR
AB This article presents a novel method for controlling a virtual audience system (VAS) in Virtual Reality (VR) application, called STAGE, which has been originally designed for supervised public speaking training in university seminars dedicated to the preparation and delivery of scientific talks. We are interested in creating pedagogical narratives: narratives encompass affective phenomenon and rather than organizing events changing the course of a training scenario, pedagogical plans using our system focus on organizing the affects it arouses for the trainees. Efficiently controlling a virtual audience towards a specific training objective while evaluating the speaker's performance presents a challenge for a seminar instructor: the high level of cognitive and physical demands required to be able to control the virtual audience, whilst evaluating speaker's performance, adjusting and allowing it to quickly react to the user's behaviors and interactions. It is indeed a critical limitation of a number of existing systems that they rely on a Wizard of Oz approach, where the tutor drives the audience in reaction to the user's performance. We address this problem by integrating with a VAS a high-level control component for tutors, which allows using predefined audience behavior rules, defining custom ones, as well as intervening during run-time for finer control of the unfolding of the pedagogical plan. At its core, this component offers a tool to program, select, modify and monitor interactive training narratives using a high-level representation. The STAGE offers the following features: i) a high-level API to program pedagogical narratives focusing on a specific public speaking situation and training objectives, ii) an interactive visualization interface iii) computation and visualization of user metrics, iv) a semi-autonomous virtual audience composed of virtual spectators with automatic reactions to the speaker and surrounding spectators while following the pedagogical plan V) and the possibility for the instructor to embody a virtual spectator to ask questions or guide the speaker from within the Virtual Environment. We present here the design, and implementation of the tutoring system and its integration in STAGE, and discuss its reception by end-users.
C1 [Glemarec, Yann; Bosser, Anne-Gwenn] ENIB, Lab STICC, CNRS UMR 6285, Brest, France.
   [Glemarec, Yann; Lugrin, Jean-Luc; Latoschik, Marc Erich] Julius Maximilians Univ Wurzburg, Chair Human Comp Interact Informat IX, Wurzburg, Germany.
   [Buche, Cedric] IRL Crossing, CNRS, ENIB, Adelaide, SA, Australia.
C3 Ecole Nationale d'Ingenieurs de Brest (ENIB); Universite de Bretagne
   Occidentale; University of Wurzburg
RP Glémarec, Y (corresponding author), ENIB, Lab STICC, CNRS UMR 6285, Brest, France.; Glémarec, Y (corresponding author), Julius Maximilians Univ Wurzburg, Chair Human Comp Interact Informat IX, Wurzburg, Germany.
EM yann.glemarec@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023; Lugrin, Jean-Luc/KMA-1030-2024
OI Latoschik, Marc Erich/0000-0002-9340-9600; Lugrin,
   Jean-Luc/0000-0002-2725-2123
FU ENIB, French Ministry of Higher Education, Research and Innovation; Open
   Access Publication Fund of the University of Wuerzburg
FX YG is partly by the ENIB, French Ministry of Higher Education, Research
   and Innovation. This publication was supported by the Open Access
   Publication Fund of the University of Wuerzburg.
CR Adobe Systems, 2022, AN 3D CHAR LIB
   Anderson PL, 2013, J CONSULT CLIN PSYCH, V81, P751, DOI 10.1037/a0033559
   Anderson PL, 2005, DEPRESS ANXIETY, V22, P156, DOI 10.1002/da.20090
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   ARTHUR KW, 1993, ACM T INFORM SYST, V11, P239, DOI 10.1145/159161.155359
   Bartholomay EM, 2016, PERS INDIV DIFFER, V94, P211, DOI 10.1016/j.paid.2016.01.026
   Batrinca Ligia, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P116, DOI 10.1007/978-3-642-40415-3_10
   Bevacqua E, 2010, LECT NOTES ARTIF INT, V6356, P194, DOI 10.1007/978-3-642-15892-6_21
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Blöte AW, 2009, J ANXIETY DISORD, V23, P305, DOI 10.1016/j.janxdis.2008.11.007
   Chollet M, 2017, IEEE COMPUT GRAPH, V37, P50, DOI 10.1109/MCG.2017.3271465
   Chollet M, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1657
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Delamarre A, 2021, INT J HUM-COMPUT ST, V152, DOI 10.1016/j.ijhcs.2021.102646
   Empatica I., 2022, EMPATICA E4 WRISTBAN
   Epic Games I., 2022, UNREAL ENGINE
   Fukuda M, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P11, DOI 10.1145/3125739.3125776
   Glemarec J.-L., 2022, VIRTUAL AUDIENCE PRO
   Glémarec Y, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.666232
   Hale KS, 2006, APPL ERGON, V37, P329, DOI 10.1016/j.apergo.2005.06.009
   Harris SR, 2002, CYBERPSYCHOL BEHAV, V5, P543, DOI 10.1089/109493102321018187
   Hayes Aleshia T., 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P142, DOI 10.1007/978-3-642-39420-1_16
   Heudin J.-C., 2007, INT C VIRT SYST MULT, P154
   Hosseinpanah A, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P184, DOI 10.1145/3284432.3284442
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Kang N, 2016, COMPUT HUM BEHAV, V55, P680, DOI 10.1016/j.chb.2015.10.008
   Kelly O, 2007, CYBERPSYCHOL BEHAV, V10, P655, DOI 10.1089/cpb.2007.9973
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Latoschik M., 2022, DECKER
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Lee C, 2010, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2010.5444820
   Lindner P, 2021, COGN BEHAV THERAPY, V50, P67, DOI 10.1080/16506073.2020.1795240
   Lugrin J.L., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, P49, DOI [10.1145/2503713.2503730, DOI 10.1145/2503713.2503730]
   Lugrin J-L., 2016, FRONTIERS ICT, V3, P26, DOI [10.3389/fict.2016.00026, DOI 10.3389/FICT.2016.00026]
   Marsella S., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P334
   Martens C, 2013, LECT NOTES COMPUT SC, V8148, P427, DOI 10.1007/978-3-642-40564-8_42
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Messinis I, 2010, 2010 INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING: IC4E 2010, PROCEEDINGS, P428, DOI 10.1109/IC4E.2010.137
   Mouw J.M., 2020, P INT C HIGH ED ADV, P325, DOI [10.4995/HEAd20.2020.11049, DOI 10.4995/HEAD20.2020.11049]
   Narayan M., 2005, P ACM S VIRT REAL SO, P78, DOI DOI 10.1145/1101616.1101632
   Owens ME, 2015, J PSYCHOPATHOL BEHAV, V37, P296, DOI 10.1007/s10862-014-9454-x
   Palmas F, 2019, INT SYM MIX AUGMENT, P363, DOI 10.1109/ISMAR.2019.00034
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Poeschl S., 2017, Frontiers in ICT, V4, P13, DOI DOI 10.3389/FICT.2017.00013
   ROSEMAN IJ, 1991, COGNITION EMOTION, V5, P161, DOI 10.1080/02699939108411034
   Rothbaum BO, 2000, J CONSULT CLIN PSYCH, V68, P1020, DOI 10.1037/0022-006X.68.6.1020
   Shernoff E. S., 2020, EVALUATING USABILITY, P1
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 2009, ANU PSICOL, V40, P193
   VirtualSpeech L., 2022, VIRT
   VRSpeaking L., 2022, OV
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Yngve VictorH., 1970, PAPERS 6 REGIONAL M, V6, P567
   Young R. M., 1999, Narrative Intelligence. Papers from the 1999 AAAI Fall Symposium, P164
NR 55
TC 4
Z9 4
U1 2
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 4
PY 2022
VL 3
AR 876433
DI 10.3389/frvir.2022.876433
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SU3
UT WOS:001021816600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Bergsnev, K
   Laws, AL
AF Bergsnev, Kamilla
   Laws, Ana Luisa Sanchez
TI Personalizing Virtual Reality for the Research and Treatment of
   Fear-Related Disorders: A Mini Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE fear-related disorders; fear learning; virtual reality; individual
   differences; contextual factors; exposure therapy; self-report measures
ID ANXIETY; CONTEXT; NEUROSCIENCE; EXTINCTION; HUMANS; RETURN
AB This mini review presents the current state of the art in studies on the personalization of virtual reality for basic research and treatment of fear-related disorders. Of particular interest to the review are the choice of self-report measures and manipulations of contextual factors that researchers are using in their virtual reality procedures. As this mini review will show, work is starting to emerge on the area of the interaction between context and individual differences, yet this topic remains a current gap in the literature on fear learning mechanisms and therapies for fear-related disorders. Studies in this review conclude that virtual reality environments offer many advantages, as they can be adjusted to model different contexts with great precision and control of the experimental context. Virtual reality is also seen by researchers as an opportunity to decrease the translational gap that exists between the research laboratories and the practical use for therapy treatments in clinics. However, the heterogeneity of methodological approaches that have created replicability as well as comparability issues in the field of fear learning is also a concern in studies using virtual reality. Thus, another, albeit secondary, aim of this mini review will be to point out some of the methodological challenges that should be addressed in future research aimed at the personalization of virtual reality for the research and treatment of fear-related disorders. Factors that will be addressed are 1) the use of self-report measures, and 2) interactivity aspects of contextual factor design in the virtual reality environment.
C1 [Bergsnev, Kamilla] UiT Arctic Univ Norway, Fac Hlth Sci, Dept Psychol, Res Grp Cognit Neurosci, Tromso, Norway.
   [Laws, Ana Luisa Sanchez] UiT Arctic Univ Norway, Fac Humanities Social Sci & Educ, Ctr Peace Studies, Ctr Womens & Gender Res,Ctr Sami & Indigenous Stud, Tromso, Norway.
C3 UiT The Arctic University of Tromso; UiT The Arctic University of Tromso
RP Bergsnev, K (corresponding author), UiT Arctic Univ Norway, Fac Hlth Sci, Dept Psychol, Res Grp Cognit Neurosci, Tromso, Norway.
EM kamilla.bergsnev@uit.no
RI Bergsnev, Kamilla/C-7886-2017
OI Bergsnev, Kamilla/0000-0002-6816-0137
CR Andreatta M, 2020, INT J PSYCHOPHYSIOL, V155, P140, DOI 10.1016/j.ijpsycho.2020.06.006
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Baas JM, 2004, BIOL PSYCHIAT, V55, P1056, DOI 10.1016/j.biopsych.2004.02.024
   Baas JMP, 2013, BIOL PSYCHOL, V92, P17, DOI 10.1016/j.biopsycho.2012.02.001
   Bandelow B, 2017, DIALOGUES CLIN NEURO, V19, P93
   Bouton ME, 2002, BIOL PSYCHIAT, V52, P976, DOI 10.1016/S0006-3223(02)01546-9
   Craske M.G., 2006, Fear and learning: Basic science to clinical application, DOI 10.1037/11474-000
   Craske MG., 2011, FOCUS, V9, P369, DOI [10.1176/foc.9.3.foc369, DOI 10.1176/FOC.9.3.FOC369]
   Davis Michael, 2011, Dialogues Clin Neurosci, V13, P463
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Gomez AF, 2018, EXPERT OPIN PHARMACO, V19, P883, DOI 10.1080/14656566.2018.1472767
   Grillon C, 2019, NEUROPSYCHOPHARMACOL, V44, P1999, DOI 10.1038/s41386-019-0445-1
   Hermans D., 2006, FEAR LEARNING BASIC
   IHME, 2019, GLOBAL BURDEN DIS ST
   Kogan CS, 2016, DEPRESS ANXIETY, V33, P1141, DOI 10.1002/da.22530
   Kritikos J, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.596980
   Kritikos J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051244
   Kroes MCW, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08184-7
   LeDoux JE, 2016, AM J PSYCHIAT, V173, P1083, DOI 10.1176/appi.ajp.2016.16030353
   Lonsdorf TB, 2017, NEUROSCI BIOBEHAV R, V80, P703, DOI 10.1016/j.neubiorev.2017.07.007
   McInerney J, 2021, BEHAV RES THER, V144, DOI 10.1016/j.brat.2021.103928
   Milad MR, 2014, BEHAV RES THER, V62, P17, DOI 10.1016/j.brat.2014.08.006
   Neueder D, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00152
   Otte Christian, 2011, Dialogues Clin Neurosci, V13, P413
   Schiller D, 2011, FRONT BEHAV NEUROSCI, V5, DOI 10.3389/fnbeh.2011.00024
   Schiller D, 2010, NATURE, V463, P49, DOI 10.1038/nature08637
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   World Health Organization, 2019, ICD 11 INT CLASS DIS
NR 28
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2022
VL 3
AR 834004
DI 10.3389/frvir.2022.834004
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PX9
UT WOS:001021741400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Oxley, JA
   Santa, K
   Meyer, G
   Westgarth, C
AF Oxley, James Andrew
   Santa, Kristof
   Meyer, Georg
   Westgarth, Carri
TI A Systematic Scoping Review of Human-Dog Interactions in Virtual and
   Augmented Reality: The Use of Virtual Dog Models and Immersive Equipment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE dogs; model; human-dog interactions; virtual reality; augmented reality;
   dogs (Canis familiaris)
ID POSTTRAUMATIC-STRESS-DISORDER; UNCANNY VALLEY; CHILDREN; PETS;
   EXPERIENCE; BENEFITS; ANIMALS; PHOBIA; COMPANIONSHIP; ANXIETY
AB Virtual reality is beneficial from a research and education perspective as it allows the assessment of participants in situations that would otherwise be ethically and practically difficult or impossible to study in the real world. This is especially the case where the assessment of human behaviour in the presence of stimuli (e.g. an aggressive dog) is being measured which could potentially constitute a risk in a real-world environment (e.g. a dog bite). Given that the dog is the most popular companion animal species, to date there is limited research that identifies and reviews the use of virtual and augmented reality directly relating to human-dog interactions. Furthermore, there also appears to be no review of the equipment and dog model specifications, such as dog breed and behaviours, which are currently used in these studies. As a result, this systematic scoping review searched ten databases to assess the current use and specifications of dog models which directly focused on human-dog interactions. Ten articles were identified. Six related to assessment or treatment of dog fear/phobia (cynophobia), three included multiple animal phobias, including dogs, and one article investigated the human and virtual dog interactions whilst walking. Six articles used a single breed (German Shepherd, Beagle, Doberman, and Rottweiler). Both the breed and behaviours displayed lacked justification and were often not evidence based. Specific measurements of model quality (e.g., polygons/vertices) were reported in only two articles which may affect repeatability and make comparisons between studies difficult. The virtual reality equipment (e.g. CAVE, head mounted display) and navigation methods (e.g. joystick, mouse, room scale walking) used varied between studies. In conclusion, there is a need for the accurate development and representation, including appearance and behaviours, of dog models in virtual and augmented reality. This is of high importance especially as most of the research covered in this review was conducted with the aim to treat the fear or phobia of dogs.
C1 [Oxley, James Andrew; Westgarth, Carri] Univ Liverpool, Fac Hlth & Life Sci, Dept Livestock & One Hlth, Leahurst Campus, Liverpool, England.
   [Santa, Kristof; Meyer, Georg] Univ Liverpool, Fac Hlth & Life Sci, Dept Psychol, Liverpool, England.
C3 University of Liverpool; University of Liverpool
RP Oxley, JA (corresponding author), Univ Liverpool, Fac Hlth & Life Sci, Dept Livestock & One Hlth, Leahurst Campus, Liverpool, England.
EM J.Oxley@liverpool.ac.uk
RI Westgarth, Carri/ABC-4581-2022
OI oxley, james/0000-0001-9483-9795; Westgarth, Carri/0000-0003-0471-2761
FU Dogs Trust Canine Welfare
FX JAO is a PhD student funded by a Dogs Trust Canine Welfare Grant.
CR Aguiar NR, 2015, COGNITIVE DEV, V34, P16, DOI 10.1016/j.cogdev.2014.12.004
   Ahn SJ, 2016, CYBERPSYCH BEH SOC N, V19, P86, DOI 10.1089/cyber.2015.0224
   Ahn SJ, 2015, J HEALTH COMMUN, V20, P807, DOI 10.1080/10810730.2015.1018597
   [Anonymous], 2018, 2018 3 DIG HER INT C, DOI DOI 10.1109/DIGITALHERITAGE.2018.8810075
   [Anonymous], 2017, What is virtual reality?
   [Anonymous], 2008, 7 INT C DISABILITY V
   Arluke A, 2018, J APPL ANIM WELF SCI, V21, P211, DOI 10.1080/10888705.2017.1387550
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   Berument SK, 1999, BRIT J PSYCHIAT, V175, P444, DOI 10.1192/bjp.175.5.444
   Botella C, 2010, BEHAV THER, V41, P401, DOI 10.1016/j.beth.2009.07.002
   Bylieva Daria, 2020, Digital Science 2019. Advances in Intelligent Systems and Computing (AISC 1114), P545, DOI 10.1007/978-3-030-37737-3_47
   Byrne S, 2012, J CHILD MEDIA, V6, P83, DOI 10.1080/17482798.2011.633410
   Carlin AS, 1997, BEHAV RES THER, V35, P153, DOI 10.1016/S0005-7967(96)00085-X
   Chen ZH, 2011, BRIT J EDUC TECHNOL, V42, P166, DOI 10.1111/j.1467-8535.2009.01003.x
   Chesney T, 2007, INTERACT STUD, V8, P337, DOI 10.1075/is.8.2.09che
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dixon CA, 2020, J PEDIATR-US, V225, P231, DOI 10.1016/j.jpeds.2020.06.071
   Farrell LJ, 2021, BEHAV THER, V52, P478, DOI 10.1016/j.beth.2020.06.003
   Friedmann E, 2018, REV SCI TECH OIE, V37, P71, DOI 10.20506/rst.37.1.2741
   Gee NR, 2019, ANTHROZOOS, V32, P183, DOI 10.1080/08927936.2019.1569903
   Hahn L, 2020, CYBERPSYCH BEH SOC N, V23, P471, DOI 10.1089/cyber.2019.0491
   Haug LI, 2008, VET CLIN N AM-SMALL, V38, P1023, DOI 10.1016/j.cvsm.2008.04.005
   Herbst KC, 2003, J PERS SOC PSYCHOL, V84, P1206, DOI 10.1037/0022-3514.84.6.1206
   Hnoohom N, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL ARTS, MEDIA AND TECHNOLOGY (ICDAMT): DIGITAL ECONOMY FOR SUSTAINABLE GROWTH, P417, DOI 10.1109/ICDAMT.2017.7905004
   Johnsen K, 2014, IEEE T VIS COMPUT GR, V20, P523, DOI 10.1109/TVCG.2014.33
   Johnston S., 2018, ENCY COMPUTER GRAPHI, P1, DOI [10.1007/978-3-319-08234-9_87-1, DOI 10.1007/978-3-319-08234-9_87-1]
   Kikuchi M., 2017, Dog Bites. A Multidisciplinary Perspective
   Kim K, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139151
   King GA, 2007, CHILD CARE HLTH DEV, V33, P28, DOI 10.1111/j.1365-2214.2006.00613.x
   Kogan L, 2017, COMPUT HUM BEHAV, V76, P431, DOI 10.1016/j.chb.2017.07.043
   Kogan LR, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16214081
   Labrodex Studios, 2019, OR CONT DEX
   Lalley J.P., 2010, International Journal of Environmental and Science Education, V5, P189
   Lee M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281533
   Li J, 2010, PEDIATRICS, V126, pE320, DOI 10.1542/peds.2009-3530
   Laureano-Cruces AL, 2012, J AMB INTEL HUM COMP, V3, P61, DOI 10.1007/s12652-011-0089-4
   Lin CL, 2017, INT CONF AFFECT, P362, DOI 10.1109/ACII.2017.8273625
   Love M, 2001, J AM VET MED ASSOC, V219, P446, DOI 10.2460/javma.2001.219.446
   Luh DB, 2015, INTERACT COMPUT, V27, P189, DOI 10.1093/iwc/iwt055
   Maglaya P. G. V., 2019, INT J RECENT TECH EN, V8, P139
   Maskey M, 2019, J AUTISM DEV DISORD, V49, P1912, DOI 10.1007/s10803-018-3861-x
   Meade P., 2006, Injury Extra, V37, P395, DOI [10.1016/j.injury.2006.05.007, DOI 10.1016/J.INJURY.2006.05.007, https://doi.org/10.1016/j.injury.2006.05.007]
   Miloff A, 2016, TRIALS, V17, DOI 10.1186/s13063-016-1171-1
   Minns S, 2018, J ANXIETY DISORD, V58, P1, DOI 10.1016/j.janxdis.2018.05.006
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   Mountford VA, 2016, CYBERPSYCH BEH SOC N, V19, P93, DOI 10.1089/cyber.2015.0169
   Nakamura R., 2021, ENCY COMPUTER GRAPHI, P1, DOI [10.1007/978-3-319-08234-9_83-1, DOI 10.1007/978-3-319-08234-9_83-1]
   NHS Providers, 2021, ACT TRACK
   Norouzi N, 2019, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2019.000-8
   OLLENDICK TH, 1983, BEHAV RES THER, V21, P685, DOI 10.1016/0005-7967(83)90087-6
   Owczarczak-Garstecka SC, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25671-7
   Peng XB, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI
   Peters V, 2004, J PEDIATR-US, V144, P121, DOI 10.1016/j.jpeds.2003.10.024
   PFMA, 2021, PET POP 2021
   PODBERSCEK AL, 1994, ANTHROZOOS, V7, P232, DOI 10.2752/089279394787001772
   Psious, 2018, PSIOUS CAN HELP YOU
   Quero S, 2014, BEHAV PSYCHOL, V22, P257
   Rativa AS, 2020, ADV INTELL SYST, V1023, P419, DOI 10.1007/978-3-030-26945-6_38
   Ratschen E, 2019, BMJ-BRIT MED J, V367, DOI 10.1136/bmj.l6260
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Ruckenstein M, 2010, CHILDHOOD, V17, P500, DOI 10.1177/0907568209352812
   Sachs-Ericsson N, 2002, REHABIL PSYCHOL, V47, P251, DOI 10.1037//0090-5550.47.3.251
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwebel DC, 2012, J PEDIATR PSYCHOL, V37, P272, DOI 10.1093/jpepsy/jsr102
   Schwind V, 2018, INT J HUM-COMPUT ST, V111, P49, DOI 10.1016/j.ijhcs.2017.11.003
   Shepherd K., 2009, BSAVA MANUAL CANINE, VChapter 2, P10, DOI [DOI 10.22233/9781905319879.2, 10.22233/9781905319879.2]
   Silverman W.K., 1996, The Anxiety Disorders Interview Schedule for Children for DSM-IV: Child and Parent Versions
   Sinski J, 2016, ANTHROZOOS, V29, P639, DOI 10.1080/08927936.2016.1228769
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slobounov SM, 2015, INT J PSYCHOPHYSIOL, V95, P254, DOI 10.1016/j.ijpsycho.2014.11.003
   Sorrento GU, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0364-0
   Sparrow S.S., 2005, SURVEY FORMS MANUAL, V2nd
   Spence SH, 1998, BEHAV RES THER, V36, P545, DOI 10.1016/S0005-7967(98)00034-5
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Suarez A. A., 2017, P LACCEI INT MULT EN
   Suied C, 2013, CYBERPSYCH BEH SOC N, V16, P145, DOI 10.1089/cyber.2012.1568
   Suso-Ribera C, 2019, CYBERPSYCH BEH SOC N, V22, P31, DOI 10.1089/cyber.2017.0672
   Swobodzinski M, 2021, BEHAV RES METHODS, V53, P977, DOI 10.3758/s13428-020-01458-5
   Taffou M, 2013, MULTISENS RES, V26, P347, DOI 10.1163/22134808-00002424
   Taffou M, 2012, STUD HEALTH TECHNOL, V181, P238, DOI 10.3233/978-1-61499-121-2-238
   Tardif N, 2019, CYBERPSYCH BEH SOC N, V22, P39, DOI 10.1089/cyber.2017.0711
   The Kings Fund, 2021, WAIT TIM EL NON TREA
   Tsai YF, 2014, J EDUC COMPUT RES, V51, P145, DOI 10.2190/EC.51.2.a
   Tulloch JSP, 2021, BMJ PAEDIATR OPEN, V5, DOI 10.1136/bmjpo-2021-001040
   Tulloch JSP, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81527-7
   Viaud-Delmon I, 2000, J ANXIETY DISORD, V14, P583, DOI 10.1016/S0887-6185(00)00052-9
   Wang Dangxiao, 2019, Virtual Reality Intell. Hardware, V1, P136, DOI [DOI 10.3724/SP.J.2096-5796.2019.0008, 10.3724/sp.j.2096-5796.2019.0008]
   Weiss A, 2009, INT J SOC ROBOT, V1, P243, DOI 10.1007/s12369-009-0024-4
   Wells DL, 2019, ANTHROZOOS, V32, P169, DOI 10.1080/08927936.2019.1569902
   Westgarth C, 2016, J VET BEHAV, V11, P99, DOI 10.1016/j.jveb.2015.02.004
   Wolpe J., 1973, PRACTICE BEHAV THERA
   Woodward L, 2012, SOC ANIM, V20, P236, DOI 10.1163/15685306-12341236
   Yamada Y, 2013, JPN PSYCHOL RES, V55, P20, DOI 10.1111/j.1468-5884.2012.00538.x
   Yin J, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202007428
NR 95
TC 3
Z9 3
U1 6
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 15
PY 2022
VL 3
AR 782023
DI 10.3389/frvir.2022.782023
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XR5
UT WOS:001023316100001
OA gold
DA 2024-07-18
ER

PT J
AU Evans, E
   Naugle, KE
   Ovispo, A
   Kaleth, AS
   Arnold, B
   Naugle, KM
AF Evans, Eric
   Naugle, Keith E.
   Ovispo, Alex
   Kaleth, Anthony S.
   Arnold, Brent
   Naugle, Kelly M.
TI Active Virtual Reality Games Reduce Pain Sensitivity in Young, Healthy
   Adults
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; active gaming; physical activity; pressure pain
   thresholds; pain sensitivity
ID RELIABILITY; EXERCISE; DISTRACTION; THRESHOLDS; MODULATION; ANALGESIA
AB Separately, both physical activity and virtual reality can attenuate pain sensitivity in healthy adults. What is unknown is whether virtual reality combined with physical activity (active virtual reality) could have a greater hypoalgesic effect compared to non-active virtual reality distraction (passive virtual reality engagement).Objective: The purpose of this study was to determine whether playing physically active virtual reality games exert a greater hypoalgesic effect than a non-active virtual reality game.Methods: Participants (n = 36) played three different active virtual reality games (Beat Saber, Holopoint, and Hot Squat) and one non-active virtual reality game (Relax Walk) for 15 min on four different visits. During gameplay, participants wore accelerometers on the thigh, wrist, and waist to measure movement intensity and quantity. Pressure pain thresholds were measured on the forearm and thigh immediately prior to gameplay (pretest) and immediately following each gaming bout (posttest).Results: Analysis of the accelerometer data indicated that Hot Squat elicited greater whole-body and lower body moderate to vigorous physical activity compared to the other games. The ANOVA revealed an overall hypoalgesic effect of the virtual reality games on the forearm, regardless of game type. Results also showed a significant hypoalgesic effect on the thigh following gameplay for Hot Squat, Holopoint, and Relax Walk VR. The magnitude of pain reduction was significantly greater during Hot Squat compared to the other games.Conclusion: Virtual reality gameplay exerted a hypoalgesic effect on experimental pressure pain. Additionally, the data provided evidence of a potential enhanced hypoalgesic effect of physically active virtual reality compared to non-active VR on pressure pain sensitivity.
C1 [Evans, Eric] Univ Alabama Birmingham, Sch Hlth Profess, Dept Hlth Serv Adm, Birmingham, AL 35294 USA.
   [Naugle, Keith E.; Kaleth, Anthony S.; Naugle, Kelly M.] Indiana Univ Purdue Univ Indianapolis, Sch Hlth & Human Sci, Dept Kinesiol, Indianapolis, IN USA.
   [Ovispo, Alex] Ball State Univ, Sch Kinesiol, Muncie, IN USA.
   [Arnold, Brent] Stockton Univ, Sch Hlth Sci, Galloway, NJ USA.
C3 University of Alabama System; University of Alabama Birmingham; Indiana
   University System; Indiana University Indianapolis; Ball State
   University; Stockton University
RP Evans, E (corresponding author), Univ Alabama Birmingham, Sch Hlth Profess, Dept Hlth Serv Adm, Birmingham, AL 35294 USA.
EM evansej@uab.edu
OI Evans, Eric/0000-0003-3751-0269
CR Aadland E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134606
   Aytar A, 2014, J MUSCULOSKELET PAIN, V22, P225, DOI 10.3109/10582452.2014.883033
   Bisset LM, 2015, J MANIP PHYSIOL THER, V38, P282, DOI 10.1016/j.jmpt.2015.03.001
   Boylan P, 2018, VIRTUAL REAL-LONDON, V22, P309, DOI 10.1007/s10055-017-0329-9
   Carey C, 2017, GAMES HEALTH J, V6, P255, DOI 10.1089/g4h.2017.0024
   Chesterton LS, 2007, CLIN J PAIN, V23, P760, DOI 10.1097/AJP.0b013e318154b6ae
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   Czub M, 2018, INT J HUM-COMPUT INT, V34, P1045, DOI 10.1080/10447318.2017.1412144
   Czub M, 2014, 2014 INTERNATIONAL CONFERENCE ON INTERACTIVE TECHNOLOGIES AND GAMES (ITAG 2014), P13, DOI 10.1109/iTAG.2014.8
   Demeter N, 2015, EUR J PAIN, V19, P1467, DOI 10.1002/ejp.678
   Duncan M. J., 2012, Medicina Sportiva, V16, P92, DOI 10.5604/17342260.1011386
   Evans E, 2021, GAMES HEALTH J, V10, P314, DOI 10.1089/g4h.2021.0036
   Freedson PS, 1998, MED SCI SPORT EXER, V30, P777, DOI 10.1097/00005768-199805000-00021
   Glennon C, 2018, ONCOL NURS FORUM, V45, P545, DOI 10.1188/18.ONF.545-552
   Gomolka S, 2019, PAIN MED, V20, P2272, DOI 10.1093/pm/pnz131
   Hayashi K, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/5021914
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2003, INT J HUM-COMPUT INT, V15, P469, DOI 10.1207/S15327590IJHC1503_10
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Jin WN, 2016, STUD HEALTH TECHNOL, V220, P154, DOI 10.3233/978-1-61499-625-5-154
   Jones D, 2018, INT J SPORTS PHYS TH, V13, P860, DOI 10.26603/ijspt20180860
   Jordan M, 2011, EUR J APPL PHYSIOL, V111, P1465, DOI 10.1007/s00421-010-1773-3
   Kelly Louise A, 2013, BMC Med Phys, V13, P5, DOI 10.1186/1756-6649-13-5
   KEMPPAINEN P, 1990, BRAIN RES, V519, P329, DOI 10.1016/0006-8993(90)90096-T
   Kim Y, 2015, MEAS PHYS EDUC EXERC, V19, P125, DOI 10.1080/1091367X.2015.1054390
   Koltyn KF, 2000, SPORTS MED, V29, P85, DOI 10.2165/00007256-200029020-00002
   Kosek E, 2003, EUR J PAIN, V7, P251, DOI 10.1016/S1090-3801(02)00124-6
   Law EF, 2011, J PEDIATR PSYCHOL, V36, P84, DOI 10.1093/jpepsy/jsq063
   Lotze M, 2006, J PHYSIOL-PARIS, V99, P386, DOI 10.1016/j.jphysparis.2006.03.012
   Magora F, 2006, ISR MED ASSOC J, V8, P261
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   Micalos PS, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1721-8
   Miller KJ, 2010, P NATL ACAD SCI USA, V107, P4430, DOI 10.1073/pnas.0913697107
   Naugle K.E., 2017, Athletic Training Sports Health Care, V9, P225, DOI [DOI 10.3928/19425864-20170619-03, 10.3928/19425864-20170619-03]
   Naugle KE, 2019, J STRENGTH COND RES, V33, P549, DOI 10.1519/JSC.0000000000002997
   Naugle KM, 2016, J PAIN, V17, P719, DOI 10.1016/j.jpain.2016.02.013
   Naugle KM, 2014, PAIN MED, V15, P692, DOI 10.1111/pme.12312
   Naugle KM, 2012, J PAIN, V13, P1139, DOI 10.1016/j.jpain.2012.09.006
   Naugle KM, 2014, MED SCI SPORT EXER, V46, P817, DOI 10.1249/MSS.0000000000000143
   Rice D, 2019, J PAIN, V20, P1249, DOI 10.1016/j.jpain.2019.03.005
   Scheer Krista S, 2014, Int J Exerc Sci, V7, P22
   Tegeder I, 2003, BRAIN, V126, P1092, DOI 10.1093/brain/awg115
   Vaegter HB, 2018, PAIN MED, V19, P2212, DOI 10.1093/pm/pny009
   Vaegter HB, 2014, PAIN, V155, P158, DOI 10.1016/j.pain.2013.09.023
   Waller R, 2015, SCAND J PAIN, V9, P38, DOI 10.1016/j.sjpain.2015.05.004
   Weaver JB, 2009, AM J PREV MED, V37, P299, DOI 10.1016/j.amepre.2009.06.014
NR 47
TC 2
Z9 2
U1 7
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 22
PY 2021
VL 2
AR 772293
DI 10.3389/frvir.2021.772293
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OQ5
UT WOS:001021708000001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Dai, ZY
   MacDorman, KF
AF Dai, Zhengyan
   MacDorman, Karl F.
TI Creepy, but Persuasive: In a Virtual Consultation, Physician Bedside
   Manner, Rather than the Uncanny Valley, Predicts Adherence
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE adherence; anthropomorphism; doctor-patient communication;
   heuristic-systematic model; interactive narratives; persuasive
   technologies; stereotype content model; uncanny valley effect
ID VISUAL ANALOG SCALES; RELATIONAL AGENTS; HEALTH BEHAVIORS; MEDICATION
   NONADHERENCE; PATIENT SATISFACTION; NONSUED PHYSICIANS; SOURCE
   CREDIBILITY; DIABETES-MELLITUS; SOCIAL-CONTROL; SAMPLE-SIZE
AB Care for chronic disease requires patient adherence to treatment advice. Nonadherence worsens health outcomes and increases healthcare costs. When healthcare professionals are in short supply, a virtual physician could serve as a persuasive technology to promote adherence. However, acceptance of advice may be hampered by the uncanny valley effect-a feeling of eeriness elicited by human simulations. In a hypothetical virtual doctor consultation, 441 participants assumed the patient's role. Variables from the stereotype content model and the heuristic-systematic model were used to predict adherence intention and behavior change. This 2 x 5 between-groups experiment manipulated the doctor's bedside manner-either good or poor-and virtual depiction at five levels of realism. These independent variables were designed to manipulate the doctor's level of warmth and eeriness. In hypothesis testing, depiction had a nonsignificant effect on adherence intention and diet and exercise change, even though the 3-D computer-animated versions of the doctor (i.e., animation, swapped, and bigeye) were perceived as eerier than the others (i.e., real and cartoon). The low-warmth, high-eeriness doctor prompted heuristic processing of information, while the high-warmth doctor prompted systematic processing. This pattern contradicts evidence reported in the persuasion literature. For the stereotype content model, a path analysis found that good bedside manner increased the doctor's perceived warmth significantly, which indirectly increased physical activity. For the heuristic-systematic model, the doctor's eeriness, measured in a pretest, had no significant effect on adherence intention and physical activity, while good bedside manner increased both significantly. Surprisingly, cognitive perspective-taking was a stronger predictor of change in physical activity than adherence intention. Although virtual characters can elicit the uncanny valley effect, their effect on adherence intention and physical activity was comparable to a video of a real person. This finding supports the development of virtual consultations.
C1 [Dai, Zhengyan; MacDorman, Karl F.] Indiana Univ, Sch Informat & Comp, Dept Human Ctr Comp, Indianapolis, IN 47405 USA.
C3 Indiana University System; Indiana University Indianapolis
RP MacDorman, KF (corresponding author), Indiana Univ, Sch Informat & Comp, Dept Human Ctr Comp, Indianapolis, IN 47405 USA.
EM kmacdorm@indiana.edu
CR Abelson Robert P, 1976, SCRIPT PROCESSING AT
   Abraham C, 1998, PSYCHOL HEALTH, V13, P569, DOI 10.1080/08870449808407420
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Anderson R, 2010, MATURITAS, V67, P151, DOI 10.1016/j.maturitas.2010.06.007
   André E, 2011, COGN TECHNOL, P585, DOI 10.1007/978-3-642-15184-2_30
   Austin JT, 1996, PSYCHOL BULL, V120, P338, DOI 10.1037/0033-2909.120.3.338
   Baylor A.L., 2005, International Journal of Artificial Intelligence in Education, V15, P95, DOI DOI 10.1007/BF02504991
   Bickmore T.W., 2009, Proceedings of the 27th international conference on Human factors in computing systems - CHI 09, P1265, DOI 10.1145/1518701.1518891
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore T, 2010, HARVARD REV PSYCHIAT, V18, P119, DOI 10.3109/10673221003707538
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Bickmore TW, 2009, PATIENT EDUC COUNS, V75, P315, DOI 10.1016/j.pec.2009.02.007
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Bravata DM, 2007, JAMA-J AM MED ASSOC, V298, P2296, DOI 10.1001/jama.298.19.2296
   Brown M, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.5710
   BROWNLOW S, 1992, J NONVERBAL BEHAV, V16, P101, DOI 10.1007/BF00990325
   Buller D. B., 1992, APPL NONVERBAL BEHAV, P119
   CACIOPPO JT, 1984, ADV CONSUM RES, V11, P673
   Carter E.J., 2013, Proceedings of the ACM Symposium on Applied Perception, P35, DOI DOI 10.1145/2492494.2502059
   CHAIKEN S, 1979, J PERS SOC PSYCHOL, V37, P1387, DOI 10.1037/0022-3514.37.8.1387
   CHAIKEN S, 1980, J PERS SOC PSYCHOL, V39, P752, DOI 10.1037/0022-3514.39.5.752
   CHAIKEN S, 1983, J PERS SOC PSYCHOL, V45, P241, DOI 10.1037/0022-3514.45.2.241
   CHAIKEN S, 1994, J PERS SOC PSYCHOL, V66, P460, DOI 10.1037/0022-3514.66.3.460
   Chaiken S., 1987, SOCIAL INFLUENCE ONT, V5
   CHARLES SC, 1985, AM J PSYCHIAT, V142, P437
   Chattopadhyay D, 2016, J VISION, V16, DOI 10.1167/16.11.7
   Chen S, 1999, DUAL-PROCESS THEORIES IN SOCIAL PSYCHOLOGY, P73
   Chisholm-Burns MA, 2012, J AM PHARM ASSOC, V52, P823, DOI 10.1331/JAPhA.2012.11088
   Chong Shanley, 2017, Diabetes Spectr, V30, P43, DOI 10.2337/ds15-0044
   COHEN J, 1973, EDUC PSYCHOL MEAS, V33, P107, DOI 10.1177/001316447303300111
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Conner M., 1996, ROLE SOCIAL COGNITIO
   Cousin G, 2013, SOC SCI MED, V98, P18, DOI 10.1016/j.socscimed.2013.08.034
   Cutler RL, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-016982
   Dai ZY, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.168
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   DEBONO KG, 1988, J PERS SOC PSYCHOL, V55, P541, DOI 10.1037/0022-3514.55.4.541
   DeSmet A, 2014, PREV MED, V69, P95, DOI 10.1016/j.ypmed.2014.08.026
   Diel A, 2022, ACM T HUM-ROBOT INTE, V11, DOI 10.1145/3470742
   Diel A, 2021, J VISION, V21, DOI 10.1167/jov.21.4.1
   Dillard JP, 2005, COMMUN MONOGR, V72, P144, DOI 10.1080/03637750500111815
   Eagly A. H., 1993, PSYCHOL ATTITUDES
   ERIKSSON KF, 1991, DIABETOLOGIA, V34, P891, DOI 10.1007/BF00400196
   Ettner SL, 1999, MED CARE, V37, P547, DOI 10.1097/00005650-199906000-00004
   Feng SY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206343
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   Fiske ST, 2007, TRENDS COGN SCI, V11, P77, DOI 10.1016/j.tics.2006.11.005
   Frith U, 2001, NEURON, V32, P969, DOI 10.1016/S0896-6273(01)00552-9
   Funke F, 2012, FIELD METHOD, V24, P310, DOI 10.1177/1525822X12444061
   Gollwitzer P.M., 1996, Social psychology: Handbook of basic principles, P361
   Green RD, 2008, COMPUT HUM BEHAV, V24, P2456, DOI 10.1016/j.chb.2008.02.019
   Greenwald A., 1968, Cognitive learning, cognitive response to persuasion and attitude change
   Griskevicius V, 2010, EMOTION, V10, P190, DOI 10.1037/a0018421
   Hale J.L., 2002, PERSUASION HDB DEV T, V14, P259, DOI [DOI 10.4135/9781412976046.N14, 10.4135/9781412976046]
   HICKSON GB, 1994, JAMA-J AM MED ASSOC, V272, P1583, DOI 10.1001/jama.272.20.1583
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   Ho Chin-Chang., 2008, Proceedings of the 3rd ACM/IEEE Conference on Human-Robot Interaction, 2008, P169, DOI [DOI 10.1145/1349822.1349845, 10.1145/1349822.1349845.]
   Ho PM, 2006, ARCH INTERN MED, V166, P1836, DOI 10.1001/archinte.166.17.1836
   Horcajo J, 2010, J PERS SOC PSYCHOL, V99, P498, DOI 10.1037/a0018626
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Iuga AO, 2014, RISK MANAG HEALTHC P, V7, P35, DOI 10.2147/RMHP.S19801
   Jackson DL, 2003, STRUCT EQU MODELING, V10, P128, DOI 10.1207/S15328007SEM1001_6
   Jelen Ben, 2020, PervasiveHealth '20: Proceedings of the 14th EAI International Conference on Pervasive Computing Technologies for Healthcare, P166, DOI 10.1145/3421937.3421976
   Johnson W.L., 2000, INT J ARTIFICIAL INT, V11, P47
   Kätsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   KELMAN HC, 1953, J ABNORM SOC PSYCH, V48, P327, DOI 10.1037/h0061861
   Kenny P, 2007, LECT NOTES ARTIF INT, V4722, P197
   Khazrai YM, 2014, DIABETES-METAB RES, V30, P24, DOI 10.1002/dmrr.2515
   Kim SS, 2004, EVAL HEALTH PROF, V27, P237, DOI 10.1177/0163278704267037
   Kirch DG, 2017, JAMA-J AM MED ASSOC, V317, P1947, DOI 10.1001/jama.2017.2714
   Kleinsinger Fred, 2018, Perm J, V22, P18, DOI 10.7812/TPP/18-033
   Kline R.B., 2016, Principles and Practice of Structural Equation Modeling, VFourth
   Koh YJ, 2010, HUM COMMUN RES, V36, P103, DOI 10.1111/j.1468-2958.2010.01370.x
   Kraft-Todd GT, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177758
   Krakow MM, 2018, HUM COMMUN RES, V44, P299, DOI 10.1093/hcr/hqy002
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   LESLIE AM, 1987, PSYCHOL REV, V94, P412, DOI 10.1037/0033-295X.94.4.412
   Levinson W, 1997, JAMA-J AM MED ASSOC, V277, P553, DOI 10.1001/jama.277.7.553
   Lewis MA, 1999, HEALTH PSYCHOL, V18, P63, DOI 10.1037/0278-6133.18.1.63
   Lin XL, 2018, COMMUN STUD, V69, P461, DOI 10.1080/10510974.2018.1489295
   Lin XL, 2016, COMPUT HUM BEHAV, V63, P264, DOI 10.1016/j.chb.2016.05.002
   Looije R, 2010, INT J HUM-COMPUT ST, V68, P386, DOI 10.1016/j.ijhcs.2009.08.007
   MacCallum RC, 1996, PSYCHOL METHODS, V1, P130, DOI 10.1037/1082-989X.1.2.130
   MacDorman KF, 2019, COMPUT HUM BEHAV, V94, P140, DOI 10.1016/j.chb.2019.01.011
   MacDorman KF, 2016, COGNITION, V146, P190, DOI 10.1016/j.cognition.2015.09.019
   MacDorman KF, 2009, COMPUT HUM BEHAV, V25, P695, DOI 10.1016/j.chb.2008.12.026
   Maddux J.E., 1999, EXPECTANCIES SHAPE E, P17
   Marc M, 2019, INT NURS REV, V66, P9, DOI 10.1111/inr.12473
   Martin Leslie R, 2005, Ther Clin Risk Manag, V1, P189
   Mast MS, 2007, PATIENT EDUC COUNS, V68, P16, DOI 10.1016/j.pec.2007.03.020
   McCroskey JC, 1999, COMMUN MONOGR, V66, P90, DOI 10.1080/03637759909376464
   McDonald HP, 2002, JAMA-J AM MED ASSOC, V288, P2868, DOI 10.1001/jama.288.22.2868
   McDonnell R., 2010, ACM SIGGRAPH ASIA 2010 Sketches, P1, DOI [DOI 10.1145/1899950.1899991, 10.1145/1899950, DOI 10.1145/1899950]
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   McGuire WilliamJ., 1978, Behavioral and Management Science in Marketing
   McKechnie T., 2016, QIHI J HEALTHC IMPRO, V2
   Messner M, 2008, SOC INFLUENCE, V3, P67, DOI 10.1080/15534510802045261
   MILLER N, 1976, J PERS SOC PSYCHOL, V34, P615, DOI 10.1037//0022-3514.34.4.615
   Miller Nancy Houston, 1997, American Journal of Medicine, V102, P43, DOI 10.1016/S0002-9343(97)00467-1
   Montano D.E., 2015, Health behavior: Theory, research and practice, DOI DOI 10.5771/9783845288277
   Morello Candis M, 2017, Am J Manag Care, V23, pS247
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nelson KM, 2002, DIABETES CARE, V25, P1722, DOI 10.2337/diacare.25.10.1722
   O'Hair D, 1986, Theor Med, V7, P147, DOI 10.1007/BF00489227
   Ogawa K., 2018, Geminoid Studies: Science and Technologies for Humanlike Teleoperated Androids, P235, DOI DOI 10.1007/978-981-10-8702-8_14
   Orji Rita, 2015, Persuasive Technology. 10th International Conference, PERSUASIVE 2015. Proceedings: LNCS 9072, P147, DOI 10.1007/978-3-319-20306-5_14
   PALLAK SR, 1983, SOC COGNITION, V2, P122, DOI 10.1521/soco.1983.2.2.122
   Patel H, 2015, PRESENCE-VIRTUAL AUG, V24, P1, DOI 10.1162/PRES_a_00212
   Patel H, 2014, COMPUT HUM BEHAV, V32, P32, DOI 10.1016/j.chb.2013.11.012
   Patel MS, 2015, JAMA-J AM MED ASSOC, V313, P459, DOI 10.1001/jama.2014.14781
   Petterson SM, 2012, ANN FAM MED, V10, P503, DOI 10.1370/afm.1431
   Petty R.E., 1981, Cognitive responses in persuasion
   Petty RE, 1998, PERS SOC PSYCHOL B, V24, P227, DOI 10.1177/0146167298243001
   Pornpitakpan C, 2004, J APPL SOC PSYCHOL, V34, P243, DOI 10.1111/j.1559-1816.2004.tb02547.x
   PROCHASKA JO, 1983, J CONSULT CLIN PSYCH, V51, P390, DOI 10.1037/0022-006X.51.3.390
   Prochaska JO., 1994, The transtheoretical model: Applications to exercise, P161, DOI DOI 10.1249/00005768-199411000-00016
   Prochaska JO., 2015, Health behavior: Theory, research, and practice, P97
   Reips UD, 2008, BEHAV RES METHODS, V40, P699, DOI 10.3758/BRM.40.3.699
   Rejeski WJ, 2012, NEW ENGL J MED, V366, P1209, DOI 10.1056/NEJMoa1110294
   Richards D., 2016, HDB RES HOLISTIC PER, V47-77
   Rogers T, 2014, JAMA-J AM MED ASSOC, V311, P2065, DOI 10.1001/jama.2014.3485
   Saeedi P, 2019, DIABETES RES CLIN PR, V157, DOI 10.1016/j.diabres.2019.107843
   Safran DG, 1998, J FAM PRACTICE, V47, P213
   Schein C, 2015, PERS SOC PSYCHOL B, V41, P1147, DOI 10.1177/0146167215591501
   Schindler S, 2017, SCI REP-UK, V7, DOI 10.1038/srep45003
   Schneider J, 2004, J GEN INTERN MED, V19, P1096, DOI 10.1111/j.1525-1497.2004.30418.x
   Seyama J, 2007, PRESENCE-TELEOP VIRT, V16, P337, DOI 10.1162/pres.16.4.337
   SHAPIRO RS, 1989, ARCH INTERN MED, V149, P2190, DOI 10.1001/archinte.149.10.2190
   Sillice MA, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7640
   Sokolov E., 1963, PERCEPTION CONDITION
   Stavropoulou C, 2011, PATIENT EDUC COUNS, V83, P7, DOI 10.1016/j.pec.2010.04.039
   Stein JP, 2018, INTERACT COMPUT, V30, P480, DOI 10.1093/iwc/iwy023
   Stonerock GL, 2017, PROG CARDIOVASC DIS, V59, P455, DOI 10.1016/j.pcad.2016.09.003
   STREET RL, 1990, Q J SPEECH, V76, P315
   Tamilmani K, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102269
   Todorov A., 2002, The persuasion handbook: Developments in theory and practice, P195
   Tuomilehto J, 2001, NEW ENGL J MED, V344, P1343, DOI 10.1056/NEJM200105033441801
   UMBERSON D, 1987, J HEALTH SOC BEHAV, V28, P306, DOI 10.2307/2136848
   Waeber B, 2000, J CARDIOVASC PHARM, V35, pS23, DOI 10.1097/00005344-200035063-00006
   Walsh CA, 2019, BRIT J CLIN PHARMACO, V85, P2464, DOI 10.1111/bcp.14075
   Wang YQ, 2013, INT CONF AFFECT, P479, DOI 10.1109/ACII.2013.85
   Webb TL, 2006, PSYCHOL BULL, V132, P249, DOI 10.1037/0033-2909.132.2.249
   WILLSON P, 1982, SOC SCI MED, V16, P1699, DOI 10.1016/0277-9536(82)90095-8
   Wojciszke B, 1998, PERS SOC PSYCHOL B, V24, P1251, DOI 10.1177/01461672982412001
   WOOD W, 1988, PERS SOC PSYCHOL B, V14, P172, DOI 10.1177/0146167288141017
   Yin LX, 2010, LECT NOTES ARTIF INT, V6356, P343, DOI 10.1007/978-3-642-15892-6_36
   Zell E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818126
   Zhuo XH, 2013, AM J PREV MED, V45, P253, DOI 10.1016/j.amepre.2013.04.017
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
   Ziegele M, 2020, COMMUN RES, V47, P891, DOI 10.1177/0093650216671854
NR 152
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 14
PY 2021
VL 2
AR 739038
DI 10.3389/frvir.2021.739038
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WT3
UT WOS:001019192800001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Sasikumar, P
   Chittajallu, S
   Raj, N
   Bai, HD
   Billinghurst, M
AF Sasikumar, Prasanth
   Chittajallu, Soumith
   Raj, Navindd
   Bai, Huidong
   Billinghurst, Mark
TI Spatial Perception Enhancement in Assembly Training Using Augmented
   Volumetric Playback
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE MR training; remote collaboration; presence enhancement; augmented
   reality; volumetric playback; hand gestures; eye gaze
ID REALITY; TRACKING
AB Conventional training and remote collaboration systems allow users to see each other's faces, heightening the sense of presence while sharing content like videos or slideshows. However, these methods lack depth information and a free 3D perspective of the training content. This paper investigates the impact of volumetric playback in a Mixed Reality (MR) spatial training system. We describe the MR system in a mechanical assembly scenario that incorporates various instruction delivery cues. Building upon previous research, four spatial instruction cues were explored; "Annotation", "Hand gestures", "Avatar", and "Volumetric playback". Through two user studies that simulated a real-world mechanical assembly task, we found that the volumetric visual cue enhanced spatial perception in the tested MR training tasks, exhibiting increased co-presence and system usability while reducing mental workload and frustration. We also found that the given tasks required less effort and mental load when eye gaze was incorporated. Eye gaze on its own was not perceived to be very useful, but it helped to compliment the hand gesture cues. Finally, we discuss limitations, future work and potential applications of our system.
C1 [Sasikumar, Prasanth; Chittajallu, Soumith; Raj, Navindd; Bai, Huidong; Billinghurst, Mark] Univ Auckland, Auckland, New Zealand.
C3 University of Auckland
RP Sasikumar, P (corresponding author), Univ Auckland, Auckland, New Zealand.
EM prasanth.sasikumar.psk@gmail.com
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759
CR Adcock M., 2013, SUI 2013 P ACM S SPA, P1, DOI [10.1145/2491367.2491378, DOI 10.1145/2491367.2491378]
   Alem L, 2011, ADV HUM-COMPUT INTER, V2011, DOI 10.1155/2011/987830
   Bauer M., 1999, Digest of Papers. Third International Symposium on Wearable Computers, P151, DOI 10.1109/ISWC.1999.806696
   Billinghurst M, 1999, MIXED REALITY, P261
   Billinghurst M., 2007, MIXED REALITY MERGIN
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Carrasco R., 2017, P 29 AUSTR C COMP HU, DOI [https://doi.org/10.1145/3152771.3152795, DOI 10.1145/3152771.3152795]
   Chang YS, 2017, IEEE SYMP 3D USER, P182, DOI 10.1109/3DUI.2017.7893337
   Cho S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P26, DOI [10.1109/VR46266.2020.1581170537418, 10.1109/VR46266.2020.00-84]
   De Pace F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00018
   Dou MS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130801
   Fussell SR, 2004, HUM-COMPUT INTERACT, V19, P273, DOI 10.1207/s15327051hci1903_3
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gurevich P., 2012, P SIGCHI C HUM FACT, P619
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Harms C., 2004, 7 ANN INT WORKSH PRE
   HART S G, 1988, P139
   Hasenfratz J.-M., 2004, EUROGRAPHICS WORKSHO, P147, DOI DOI 10.2312/EGVE/EGVE04/147-156
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Joachimczak M, 2017, P 19 ACM INT C MULT, P514, DOI [10.1145/3136755.3143031, DOI 10.1145/3136755.3143031]
   Kalra P, 1998, IEEE COMPUT GRAPH, V18, P42, DOI 10.1109/38.708560
   Ke CZ, 2005, LECT NOTES COMPUT SC, V3784, P836
   Kirk D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1039
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mohler B. J., 2008, FULL BODY AVATAR IMP, DOI [10.1145/1394281.1394323, DOI 10.1145/1394281.1394323]
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Olwal A, 2008, PROC SPIE, V6804, DOI 10.1117/12.760960
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Ou J., 2003, Proceedings of the 5th International Conference on Multimodal interfaces (ICMI), P242, DOI DOI 10.1145/958432.958477
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Regenbrecht H, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P90, DOI 10.1109/ISMAR.2017.26
   Rose E., 1995, COMPUT GRAPHICS-US, P357
   Sang-Hack Jung, 2006, Journal of Multimedia, V1
   Sasikumar P, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P393, DOI 10.1109/ISMAR-Adjunct.2019.000-3
   Schwald B, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P425
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Spakov O, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317959.3321489
   Wang TY, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4010003
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Wither J, 2009, COMPUT GRAPH-UK, V33, P679, DOI 10.1016/j.cag.2009.06.001
   Xu M., 2018, International Journal of Financial Research., V9, P90, DOI DOI 10.5430/IJFR.V9N2P90
   Yang J, 2020, J MULTIMODAL USER IN, V14, P337, DOI 10.1007/s12193-020-00331-1
   Yang YJ, 2002, COMPUT SCI ENG, V4, P86, DOI 10.1109/5992.976440
NR 47
TC 6
Z9 6
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 16
PY 2021
VL 2
AR 698523
DI 10.3389/frvir.2021.698523
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2RX5
UT WOS:001021793600001
OA gold
DA 2024-07-18
ER

PT J
AU Nordgård, R
   Låg, T
AF Nordgard, Rikke
   Lag, Torstein
TI The Effects of Virtual Reality on Procedural Pain and Anxiety in
   Pediatrics: A Systematic Review and Meta-Analysis
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; pain; anxiety; pediatrics; distraction analgesia;
   procedural preparation; meta-analysis; systematic review
ID PUBLICATION BIAS; DENTAL TREATMENT; AUDIOVISUAL DISTRACTION;
   PREOPERATIVE ANXIETY; PASSIVE DISTRACTION; VIDEO GLASSES; CHILDRENS
   BEHAVIOR; LOCAL-ANESTHESIA; MANAGEMENT; EFFICACY
AB Distraction and procedural preparation techniques are frequently used to manage pain and anxiety in children undergoing medical procedures. An increasing number of studies have indicated that Virtual Reality (VR) can be used to deliver these interventions, but treatment effects vary greatly. The present study is a systematic review and meta-analysis of studies that have used VR to reduce procedural pain and anxiety in children. It is the first meta-analytic assessment of the potential influence of technical specifications (immersion) and degree of user-system interactivity on treatment effects. 65 studies were identified, of which 42 reported pain outcomes and 35 reported anxiety outcomes. Results indicate large effect sizes in favor of VR for both outcomes. Larger effects were observed in dental studies and studies that used non-interactive VR. No relationship was found between the degree of immersion or participant age and treatment effects. Most studies were found to have a high risk of bias and there are strong indications of publication bias. The results and their implications are discussed in context of these limitations, and modified effect sizes are suggested. Finally, recommendations for future investigations are provided.
C1 [Nordgard, Rikke; Lag, Torstein] Univ Tromso Arctic Univ Norway, Fac Hlth Sci, Dept Psychol, Tromso, Norway.
   [Lag, Torstein] Univ Tromso Arctic Univ Norway, Univ Lib, Tromso, Norway.
C3 UiT The Arctic University of Tromso; UiT The Arctic University of Tromso
RP Låg, T (corresponding author), Univ Tromso Arctic Univ Norway, Fac Hlth Sci, Dept Psychol, Tromso, Norway.; Låg, T (corresponding author), Univ Tromso Arctic Univ Norway, Univ Lib, Tromso, Norway.
OI Lag, Torstein/0000-0002-1325-5235
FU UiT The Arctic University of Norway
FX No specific grant apart from institutional support from UiT The Arctic
   University of Norway.
CR Agrawal S, 2020, J AUDIO ENG SOC, V68, P404, DOI 10.17743/jaes.2020.0039
   Al-Halabi MN, 2018, ANAESTH PAIN INTENSI, V22, P55
   Al-Khotani A, 2016, ACTA ODONTOL SCAND, V74, P494, DOI 10.1080/00016357.2016.1206211
   Al-Nerabieah Z., 2020, Perioper Care Oper Room Manag, V21, P100129, DOI [10.1016/j.pcorm.2020.100129, DOI 10.1016/J.PCORM.2020.100129]
   [Anonymous], Cochrane Handbook for Systematic Reviews of Interventions, DOI [DOI 10.1002/9781119536604, 10.1002/9781119536604]
   Asl Aminabadi Naser, 2012, J Dent Res Dent Clin Dent Prospects, V6, P117, DOI 10.5681/joddd.2012.025
   Asvanund Y, 2015, QUINTESSENCE INT, V46, P513, DOI 10.3290/j.qi.a33932
   Attar RH, 2015, EUR ARCH PAEDIATR DE, V16, P1, DOI 10.1007/s40368-014-0136-x
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02508
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02265
   Augusteijn HEM, 2019, PSYCHOL METHODS, V24, P116, DOI 10.1037/met0000197
   Aydin AI, 2019, J PERIANESTH NURS, V34, P1215, DOI 10.1016/j.jopan.2019.05.134
   Bagattoni S, 2018, INT J PAEDIATR DENT, V28, P111, DOI 10.1111/ipd.12304
   Bailey B, 2012, PAIN, V153, P839, DOI 10.1016/j.pain.2012.01.006
   Bentley J., 2014, MANAGING PAIN CHILDR, V2nd ed.
   Birnie KA, 2014, PAIN RES MANAG, V19, P198, DOI 10.1155/2014/614784
   Boeldt D, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00773
   Borenstein M., 2009, INTRO METAANALYSIS
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Buldur B, 2021, PESQUI BRAS ODONTOPE, V21, DOI 10.1590/pboci.2021.002
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   Carter EC, 2019, ADV METH PRACT PSYCH, V2, P115, DOI 10.1177/2515245919847196
   Caruso TJ, 2020, PEDIATR ANESTH, V30, P116, DOI 10.1111/pan.13778
   Chan EA, 2007, J CLIN NURS, V16, P786, DOI 10.1111/j.1365-2702.2006.01719.x
   Chan E, 2019, J PEDIATR-US, V209, P160, DOI 10.1016/j.jpeds.2019.02.034
   Chan E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200987
   Chaudhary S., 2020, INT J SCI RES, V9, P32
   Chen YJ, 2020, J CLIN NURS, V29, P503, DOI 10.1111/jocn.15088
   Coburn Kathleen M, 2019, CRAN
   Cohen J., 1988, Statistical power analyses for behavioral sciences, V2nd, DOI [10.4324/9780203771587, DOI 10.4324/9780203771587]
   Cohen LL, 2008, ISSUES CLIN CHILD PS, P283
   Cohen LL, 2004, J CLIN PSYCHOL MED S, V11, P41, DOI 10.1023/B:JOCS.0000016268.40662.ed
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Curtis S., 2012, Evidence-Based Child Health, V7, P1363, DOI [DOI 10.1002/EBCH.1864, 10.1002/EBCH.1864]
   Dahlquist LM, 2007, HEALTH PSYCHOL, V26, P794, DOI 10.1037/0278-6133.26.6.794
   Das Debashish A, 2005, BMC Pediatr, V5, P1, DOI 10.1186/1471-2431-5-1
   DeMore M, 2005, J CLIN PSYCHOL MED S, V12, P281, DOI 10.1007/s10880-005-7813-1
   Dumoulin S, 2019, GAMES HEALTH J, V8, P285, DOI 10.1089/g4h.2018.0111
   Duval S, 2000, J AM STAT ASSOC, V95, P89, DOI 10.2307/2669529
   Edward K., 2015, ACORN J PERIOPERATIV, V28, P24
   Egger M, 1997, BMJ-BRIT MED J, V315, P629, DOI 10.1136/bmj.315.7109.629
   Eijlers R, 2019, EUR J ANAESTH, V36, P728, DOI 10.1097/EJA.0000000000001059
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   El-Sharkawi HFA, 2012, PEDIATR DENT, V34, P142
   Fakhruddin Kausar Sadia, 2015, Eur J Dent, V9, P470, DOI 10.4103/1305-7456.172637
   Ferguson CJ, 2012, PSYCHOL METHODS, V17, P120, DOI 10.1037/a0024445
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Friedrichsdorf SJ, 2020, PAIN REP, V5, DOI 10.1097/PR9.0000000000000804
   Fuchs P, 2019, VIRTUAL REALITY HEAD, P55
   Gandhi M, 2010, INT J PEDIAT, V2010, DOI 10.1155/2010/825657
   Garrocho-Rangel A, 2018, EUR J PAEDIATR DENT, V19, P74, DOI 10.23804/ejpd.2018.19.01.14
   Georgescu R, 2020, PSYCHOL MED, V50, P1795, DOI 10.1017/S0033291719001855
   Gerçeker GÖ, 2018, J PERIANESTH NURS, V33, P981, DOI 10.1016/j.jopan.2017.12.010
   Gerçeker GÖ, 2021, EUR J ONCOL NURS, V50, DOI 10.1016/j.ejon.2020.101886
   Gershon J, 2004, J AM ACAD CHILD PSY, V43, P1243, DOI 10.1097/01.chi.0000135621.23145.05
   Gigante MA, 1993, VIRTUAL REALITY SYST, P3, DOI [10.1016/B978-0-12-227748-1.50009-3, DOI 10.1016/B978-0-12-227748-1.50009-3]
   Gold JI, 2018, J PEDIATR PSYCHOL, V43, P266, DOI 10.1093/jpepsy/jsx129
   Gold JI, 2006, CYBERPSYCHOL BEHAV, V9, P207, DOI 10.1089/cpb.2006.9.207
   Goldman RD, 2021, EUR J PEDIATR, V180, P725, DOI 10.1007/s00431-020-03771-9
   Gupta A, 2018, PAIN MED, V19, P151, DOI 10.1093/pm/pnx109
   Gutierrez-Maldonado J, 2011, STUD HEALTH TECHNOL, V167, P69, DOI 10.3233/978-1-60750-766-6-69
   Gutiérrez-Martínez O, 2011, STUD HEALTH TECHNOL, V167, P111, DOI 10.3233/978-1-60750-766-6-111
   Han SH, 2019, JAMA PEDIATR, V173, P1026, DOI 10.1001/jamapediatrics.2019.3000
   Hardin AP, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2017-2151
   Hashimoto Y, 2020, J PERIANESTH NURS, V35, P321, DOI 10.1016/j.jopan.2019.10.001
   Hedges L. V., 1981, Journal of Educational Statistics, V6, P107, DOI [10.3102/10769986006002107, DOI 10.3102/10769986006002107, https://doi.org/10.3102/10769986006002107]
   Hedges LV, 2005, PUBLICATION BIAS IN META-ANALYSIS: PREVENTION, ASSESSMENT AND ADJUSTMENTS, P145
   Hempel S., 2011, Empirical evidence of associations between trial quality and effect sizes. Methods Research Report
   Hicks CL, 2001, PAIN, V93, P173, DOI 10.1016/S0304-3959(01)00314-1
   Higgins JPT, 2003, BMJ-BRIT MED J, V327, P557, DOI 10.1136/bmj.327.7414.557
   Higgins JPT., 2020, COCHRANE HDB SYSTEMA, DOI DOI 10.1002/9781119536604.CH10
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Hoge MA, 2012, PEDIATR DENT, V34, P378
   Howard R., 2012, Paediatric Anaesthesia, V22, P1, DOI DOI 10.1111/J.1460-9592.2012.03838.X
   Hua Y, 2015, PAIN MANAG NURS, V16, P685, DOI 10.1016/j.pmn.2015.03.001
   Hugues O., 2019, VIRTUAL REALITY HEAD, P79
   Iannicelli AM, 2019, ITAL J PEDIATR, V45, DOI 10.1186/s13052-019-0757-0
   Inangil D, 2020, J PERIANESTH NURS, V35, P407, DOI 10.1016/j.jopan.2020.01.008
   Indovina P, 2018, CLIN J PAIN, V34, P858, DOI 10.1097/AJP.0000000000000599
   Ioannidis JPA, 2008, EPIDEMIOLOGY, V19, P640, DOI 10.1097/EDE.0b013e31818131e7
   Isong IA, 2014, CLIN PEDIATR, V53, P230, DOI 10.1177/0009922813517169
   Jaaniste T, 2007, CLIN PSYCHOL-SCI PR, V14, P124, DOI 10.1111/j.1468-2850.2007.00072.x
   James KH, 2002, BEHAV RES METH INS C, V34, P383, DOI 10.3758/BF03195466
   Jeffs D, 2014, J BURN CARE RES, V35, P395, DOI 10.1097/BCR.0000000000000019
   Johnson Malcolm H, 2005, Curr Pain Headache Rep, V9, P90, DOI 10.1007/s11916-005-0044-1
   Johnson S, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.150567
   Jung MJ, 2021, ANESTH ANALG, V132, P798, DOI 10.1213/ANE.0000000000005004
   Kain ZN, 1997, ANESTH ANALG, V85, P783, DOI 10.1097/00000539-199710000-00012
   Kao G. S., 2019, CASE STUDIES PEDIAT, P260, DOI [10.1017/9781108668736.058, DOI 10.1017/9781108668736.058]
   Kennedy Robert M, 2008, Pediatrics, V122 Suppl 3, pS130, DOI 10.1542/peds.2008-1055e
   Kerimoglu B, 2013, ANESTH ANALG, V117, P1373, DOI 10.1213/ANE.0b013e3182a8c18f
   Khadra C, 2020, BURNS, V46, P1571, DOI 10.1016/j.burns.2020.04.006
   Khalafallah A, 2010, MEDITERR J HEMATOL I, V2, DOI [10.1136/bmj.l4898, 10.4084/MJHID.2010.005]
   Khan SDAA, 2019, INDO AM J PHARM SCI, V6, P4043, DOI 10.5281/zenodo.2566813
   Kipping B, 2012, BURNS, V38, P650, DOI 10.1016/j.burns.2011.11.010
   Koticha Paloni, 2019, Int J Clin Pediatr Dent, V12, P297, DOI 10.5005/jp-journals-10005-1640
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Lambert V, 2020, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010686.pub2
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lavoie K., 2013, ENCY BEHAV MED, P106, DOI [10.1007/978-1-4419-1005-9_1090, DOI 10.1007/978-1-4419-1005-9_1090]
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Light RJ., 1984, Summing up: The science of reviewing research, DOI DOI 10.4159/9780674040243
   Linton SJ, 2011, PHYS THER, V91, P700, DOI 10.2522/ptj.20100330
   LIPSEY MW, 1993, AM PSYCHOL, V48, P1181, DOI 10.1037/0003-066X.48.12.1181
   Liszio S, 2020, PROCEEDINGS OF IDC 2020, P470, DOI 10.1145/3392063.3394432
   Litwin SP, 2021, CLIN J PAIN, V37, P94, DOI 10.1097/AJP.0000000000000894
   Luo DH, 2018, STAT METHODS MED RES, V27, P1785, DOI 10.1177/0962280216669183
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Mathews L, 2011, INDIAN J PALLIAT CAR, V17, P70, DOI 10.4103/0973-1075.76247
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   McGuinness LA, 2021, RES SYNTH METHODS, V12, P55, DOI 10.1002/jrsm.1411
   McMurtry C Meghan, 2015, Clin J Pain, V31, pS3, DOI 10.1097/AJP.0000000000000272
   Melzack R, 1999, PAIN, pS121, DOI 10.1016/S0304-3959(99)00145-1
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   Mitrakul K, 2015, EUR J PAEDIATR DENT, V16, P239
   Moher D, 1998, LANCET, V352, P609, DOI 10.1016/S0140-6736(98)01085-X
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Neri SGR, 2017, CLIN REHABIL, V31, P1292, DOI 10.1177/0269215517694677
   Nichols S, 2002, APPL ERGON, V33, P251, DOI 10.1016/S0003-6870(02)00020-0
   Niharika Puppala, 2018, J Indian Soc Pedod Prev Dent, V36, P364, DOI 10.4103/JISPPD.JISPPD_1158_17
   Niki K, 2019, J PALLIAT MED, V22, P702, DOI 10.1089/jpm.2018.0527
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [10.17011/ht/urn.201611174652, DOI 10.17011/HT/URN.201611174652]
   Nunna Mahesh, 2019, J Dent Anesth Pain Med, V19, P277, DOI 10.17245/jdapm.2019.19.5.277
   Nuvvula S, 2015, EUR ARCH PAEDIATR DE, V16, P43, DOI 10.1007/s40368-014-0145-9
   O'Brien J. H., 2019, OXFORD TXB PALLIATIV, V5th ed., DOI [10.1093/med/9780190862374.003.0064, DOI 10.1093/MED/9780190862374.003.0064]
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Ohman A., 2008, HDB EMOTIONS, P709
   Osmanlliu E, 2021, CAN J EMERG MED, V23, P94, DOI 10.1007/s43678-020-00006-6
   Gerçeker GÖ, 2020, J CLIN NURS, V29, P1151, DOI 10.1111/jocn.15173
   Özkan TK, 2020, J PERIANESTH NURS, V35, P206, DOI 10.1016/j.jopan.2019.08.010
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pate JT, 1996, CHILD HEALTH CARE, V25, P281, DOI 10.1207/s15326888chc2504_4
   Peters JL, 2008, J CLIN EPIDEMIOL, V61, P991, DOI 10.1016/j.jclinepi.2007.11.010
   Piskorz J, 2018, J SPEC PEDIATR NURS, V23, DOI 10.1111/jspn.12201
   Piskorz JE, 2020, CYBERPSYCHOLOGY, V14, DOI 10.5817/CP2020-1-3
   Reid K., 2014, MANAGING PAIN CHILDR
   Ryu JH, 2017, BRIT J SURG, V104, P1628, DOI 10.1002/bjs.10684
   Ryu JH, 2019, PEDIATR ANESTH, V29, P98, DOI 10.1111/pan.13535
   Ryu JH, 2018, J CLIN MED, V7, DOI 10.3390/jcm7090284
   Sander Wint Suzanne, 2002, Oncol Nurs Forum, V29, pE8
   Schechter NL, 2007, PEDIATRICS, V119, pE1184, DOI 10.1542/peds.2006-1107
   Schlechter AK, 2021, AM J EMERG MED, V44, P296, DOI 10.1016/j.ajem.2020.04.009
   Schmitt YS, 2011, BURNS, V37, P61, DOI 10.1016/j.burns.2010.07.007
   Schunemann H., 2019, COCHRANE HDB SYSTEMA, DOI [10.1002/9781119536604.ch15, DOI 10.1002/9781119536604.CH15]
   Shah U, 2018, Int J Oral Care Res, V2, P01
   Shetty V, 2019, J CLIN PEDIATR DENT, V43, P97, DOI 10.17796/1053-4625-43.2.5
   Shi JD, 2020, RES SYNTH METHODS, V11, P641, DOI 10.1002/jrsm.1429
   Shi LY, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015987
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slifer KJ, 2014, CLINICIAN'S GUIDE TO HELPING CHILDREN COPE AND COOPERATE WITH MEDICAL CARE: AN APPLIED BEHAVIORAL APPROACH, P1
   Snider L, 2010, DEV NEUROREHABIL, V13, P120, DOI 10.3109/17518420903357753
   StataCorp, 2020, STATA STAT SOFTWARE
   Sterne JAC, 2005, PUBLICATION BIAS IN META-ANALYSIS: PREVENTION, ASSESSMENT AND ADJUSTMENTS, P75, DOI 10.1002/0470870168.ch5
   Sterne JAC, 2005, PUBLICATION BIAS IN META-ANALYSIS: PREVENTION, ASSESSMENT AND ADJUSTMENTS, P99
   Sterne JAC, 2016, BMJ-BRIT MED J, V355, DOI 10.1136/bmj.i4919
   Stevens BJ, 2011, CAN MED ASSOC J, V183, pE403, DOI 10.1503/cmaj.101341
   Sullivan C, 2000, J DENT CHILD, V67, P193
   Taddio A, 1997, LANCET, V349, P599, DOI 10.1016/S0140-6736(96)10316-0
   The International Association for the Study of Pain (IASP), 2019, IASP TERM
   Thompson SG, 2002, STAT MED, V21, P1559, DOI 10.1002/sim.1187
   del Castillo BT, 2019, AN PEDIATR, V91, P80, DOI 10.1016/j.anpedi.2018.10.019
   Tuena C, 2019, J CLIN MED, V8, DOI 10.3390/jcm8050620
   Twycross A, 2015, J PEDIATR ONCOL NURS, V32, P369, DOI 10.1177/1043454214563751
   van Aert RCM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215052
   Veroniki AA, 2016, RES SYNTH METHODS, V7, P55, DOI 10.1002/jrsm.1164
   Vevea JL, 2019, HANDBOOK OF RESEARCH SYNTHESIS AND META-ANALYSIS, 3RD EDITION, P383
   Vevea JL, 2005, PSYCHOL METHODS, V10, P428, DOI 10.1037/1082-989X.10.4.428
   von Baeyer CL, 2009, PAIN RES MANAG, V14, P39, DOI 10.1155/2009/259759
   Walther-Larsen Soren, 2019, Hosp Pediatr, V9, P501, DOI 10.1542/hpeds.2018-0249
   Wan X, 2014, BMC MED RES METHODOL, V14, DOI 10.1186/1471-2288-14-135
   Weisman SJ, 1998, ARCH PEDIAT ADOL MED, V152, P147
   Wender Regina, 2009, J Cyber Ther Rehabil, V2, P27
   Wilson D. B., 2021, PRACTICAL METAANALYS
   Wilson-Smith Elaine M, 2011, Rev Pain, V5, P4, DOI 10.1177/204946371100500303
   Wismeijer AAJ, 2005, ANN BEHAV MED, V30, P268, DOI 10.1207/s15324796abm3003_11
   Wolitzky K, 2005, PSYCHOL HEALTH, V20, P817, DOI 10.1080/14768320500143339
   Wong C. L., 2020, CANCER NURS, DOI [DOI 10.1097/NCC.0000000000000844, 10.1097/NCC.0000000000000844]
   Wong-Baker FACES Foundation, 2018, Wong!Baker FACES® pain rating scale
   Yang SN, 2012, OPTOMETRY VISION SCI, V89, P1068, DOI 10.1097/OPX.0b013e31825da430
   Young KD, 2005, ANN EMERG MED, V45, P160, DOI 10.1016/j.annemergmed.2004.09.019
NR 185
TC 13
Z9 13
U1 1
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 15
PY 2021
VL 2
AR 699383
DI 10.3389/frvir.2021.699383
PG 33
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PI7
UT WOS:001021726200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Turbyne, C
   Goedhart, A
   de Koning, P
   Schirmbeck, F
   Denys, D
AF Turbyne, Collin
   Goedhart, Abe
   de Koning, Pelle
   Schirmbeck, Frederike
   Denys, Damiaan
TI Systematic Review and Meta-Analysis of Virtual Reality in Mental
   Healthcare: Effects of Full Body Illusions on Body Image Disturbance
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; full body illusion; meta-analysis; mental healthcare;
   body image disturbance
ID ANOREXIA-NERVOSA; EATING-DISORDERS; BULIMIA-NERVOSA; EXPOSURE THERAPY;
   SIZE ESTIMATION; OBESE; BIAS; DISSATISFACTION; REPRESENTATION;
   PUBLICATION
AB Background: Body image (BI) disturbances have been identified in both clinical and non-clinical populations. Virtual reality (VR) has recently been used as a tool for modulating BI disturbances through the use of eliciting a full body illusion (FBI). This meta-analysis is the first to collate evidence on the effectiveness of an FBI to reduce BI disturbances in both clinical and non-clinical populations.Methods: We performed a literature search in MEDLINE (PubMed), EMBASE, PsychINFO, and Web of Science with the keywords and synonyms for "virtual reality" and "body image" to identify published studies until September 2020. We included studies that (1) created an FBI with a modified body shape or size and (2) reported BI disturbance outcomes both before and directly after the FBI. FBI was defined as a head-mounted display (HMD)-based simulation of embodying a virtual body from an egocentric perspective in an immersive 3D computer-generated environment.Results: Of the 398 identified unique studies, 13 were included after reading full-texts. Four of these studies were eligible for a meta-analysis on BI distortion inducing a small virtual body FBI in healthy females. Significant post-intervention results were found for estimations of shoulder width, hip width, and abdomen width, with the largest reductions in size being the estimation of shoulder circumference (SMD = -1.3; 95% CI: -2.2 to -0.4; p = 0.004) and hip circumference (SMD = -1.0; 95% CI: -1.6 to -0.4; p = 0.004). Mixed results were found in non-aggregated studies from large virtual body FBIs in terms of both estimated body size and BI dissatisfaction and in small virtual body FBI in terms of BI dissatisfaction.Conclusions: The findings presented in this paper suggest that the participants' BIs were able to conform to both an increased as well as a reduced virtual body size. However, because of the paucity of research in this field, the extent of the clinical utility of FBIs still remains unclear. In light of these limitations, we provide implications for future research about the clinical utility of FBIs for modulating BI-related outcomes.
C1 [Turbyne, Collin; Goedhart, Abe; de Koning, Pelle; Schirmbeck, Frederike; Denys, Damiaan] Univ Amsterdam, Acad Med Ctr, Dept Psychiat, Amsterdam, Netherlands.
C3 University of Amsterdam; Academic Medical Center Amsterdam
RP Turbyne, C (corresponding author), Univ Amsterdam, Acad Med Ctr, Dept Psychiat, Amsterdam, Netherlands.
EM c.a.turbyne@amsterdamumc.nl
OI Denys, Damiaan/0000-0002-3191-3844
CR [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI DOI 10.1371/JOURNAL.PMED.1000097
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Arcelus J, 2011, ARCH GEN PSYCHIAT, V68, P724, DOI 10.1001/archgenpsychiatry.2011.74
   Attia E, 2009, NEW ENGL J MED, V360, P500, DOI 10.1056/NEJMct0805569
   Bachner-Melman R, 2006, J NERV MENT DIS, V194, P697, DOI 10.1097/01.nmd.0000235795.51683.99
   Bassolino M, 2018, EUR J NEUROSCI, V47, P790, DOI 10.1111/ejn.13871
   BELL C, 1986, J CLIN PSYCHOL, V42, P431, DOI 10.1002/1097-4679(198605)42:3<431::AID-JCLP2270420305>3.0.CO;2-I
   BELLISLE F, 1995, INT J OBESITY, V19, P723
   Berends T, 2018, CURR OPIN PSYCHIATR, V31, P445, DOI 10.1097/YCO.0000000000000453
   Borenstein M., 2013, BIOSTAT
   Cash TF, 1997, INT J EAT DISORDER, V22, P107, DOI 10.1002/(SICI)1098-108X(199709)22:2<107::AID-EAT1>3.0.CO;2-J
   Cash Thomas F, 2002, Eat Disord, V10, P103, DOI 10.1080/10640260290081678
   Clus D, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7898
   Cohen J., 1988, STAT POWER ANAL BEHA
   COLLINS JK, 1987, INT J EAT DISORDER, V6, P633, DOI 10.1002/1098-108X(198709)6:5<633::AID-EAT2260060506>3.0.CO;2-U
   Corno G, 2018, CYBERPSYCH BEH SOC N, V21, P679, DOI 10.1089/cyber.2018.0340
   Cuijpers P, 2017, EPIDEMIOL PSYCH SCI, V26, P364, DOI 10.1017/S2045796016000809
   Dakanalis A, 2016, NAT REV DIS PRIMERS, V2, DOI 10.1038/nrdp.2016.26
   de Carvalho MR, 2017, BEHAV SCI-BASEL, V7, DOI 10.3390/bs7030043
   de Oliveira EC, 2016, SYMP VIRTUAL AUGMENT, P81, DOI 10.1109/SVR.2016.23
   de Vos JA, 2016, EAT DISORD, V24, P207, DOI 10.1080/10640266.2015.1090869
   Deeks J J, 2003, Health Technol Assess, V7, piii
   Dellazizzo L, 2020, J MED INTERNET RES, V22, DOI 10.2196/20889
   Docteur A, 2010, OBESITY, V18, P1464, DOI 10.1038/oby.2009.418
   Effective Public Health Practice Project, 1998, QUAL ASS TOOL QUANT
   Ferrer-García M, 2008, BEHAV RES METHODS, V40, P394, DOI 10.3758/BRM.40.2.394
   Ferrer-Garcia M, 2018, ANN REV CYBERTHERAPY, V16, P111
   Ferrer-García M, 2012, BODY IMAGE, V9, P1, DOI 10.1016/j.bodyim.2011.10.001
   Galmiche M, 2019, AM J CLIN NUTR, V109, P1402, DOI 10.1093/ajcn/nqy342
   Gardner RM, 2009, J CLIN PSYCHOL, V65, P113, DOI 10.1002/jclp.20526
   GARDNER RM, 1987, PSYCHOL MED, V17, P927, DOI 10.1017/S0033291700000738
   GARNER DM, 1976, PSYCHOSOM MED, V38, P327, DOI 10.1097/00006842-197609000-00005
   Gavin AR, 2010, J PSYCHOSOM RES, V69, P573, DOI 10.1016/j.jpsychores.2010.05.001
   Gilbody SM, 2000, ACTA PSYCHIAT SCAND, V102, P241, DOI 10.1034/j.1600-0447.2000.102004241.x
   Glashouwer KA, 2019, CLIN PSYCHOL REV, V74, DOI 10.1016/j.cpr.2019.101771
   Griffen TC, 2018, CLIN PSYCHOL REV, V65, P163, DOI 10.1016/j.cpr.2018.08.006
   Haynes A, 2019, APPETITE, V141, DOI 10.1016/j.appet.2019.104330
   Keizer A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163921
   Koskina A, 2013, NEUROSCI BIOBEHAV R, V37, P193, DOI 10.1016/j.neubiorev.2012.11.010
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Lander R, 2020, EAT WEIGHT DISORD-ST, V25, P1039, DOI 10.1007/s40519-019-00728-2
   Liu W, 2020, BRAIN STIMUL, V13, P643, DOI 10.1016/j.brs.2020.02.004
   Malighetti C, 2016, ANN REV CYBERTHERAPY, V14, P78
   Mathews RRS, 2011, MED J AUSTRALIA, V194, P232, DOI 10.5694/j.1326-5377.2011.tb02951.x
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mölbert SC, 2018, PSYCHOL MED, V48, P642, DOI 10.1017/S0033291717002008
   Mölbert SC, 2017, CLIN PSYCHOL REV, V57, P21, DOI 10.1016/j.cpr.2017.08.005
   Murray SB, 2019, PSYCHOL MED, V49, P535, DOI 10.1017/S0033291718002088
   Neyret S, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00031
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Ouzzani M, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0384-4
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Phillipou A, 2018, AUST NZ J PSYCHIAT, V52, P13, DOI 10.1177/0004867417722640
   Garcia BP, 2019, J CLIN MED, V8, DOI 10.3390/jcm8070925
   Porras-Garcia B, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00956
   Preston C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199426
   Preston C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085773
   Provenzano L, 2020, J CLIN MED, V9, DOI 10.3390/jcm9010098
   REED DL, 1991, J ANXIETY DISORD, V5, P323, DOI 10.1016/0887-6185(91)90032-O
   Riva G, 2003, PSYCHOTHERAPY, V40, P68, DOI 10.1037/0033-3204.40.1-2.68
   Riva G, 1997, PRESENCE-TELEOP VIRT, V6, P106, DOI 10.1162/pres.1997.6.1.106
   Riva G, 1998, Eat Weight Disord, V3, P141
   Riva G, 2014, EAT WEIGHT DISORD-ST, V19, P133, DOI 10.1007/s40519-013-0066-3
   Riva G, 2012, MED HYPOTHESES, V78, P254, DOI 10.1016/j.mehy.2011.10.039
   Riva Giuseppe, 2011, J Diabetes Sci Technol, V5, P283
   RORTY M, 1993, INT J EAT DISORDER, V14, P249, DOI 10.1002/1098-108X(199311)14:3<249::AID-EAT2260140303>3.0.CO;2-O
   Sarwer DB, 1998, J CONSULT CLIN PSYCH, V66, P651, DOI 10.1037/0022-006X.66.4.651
   Scarpina F, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091330
   Scarpina F, 2014, PSYCHIAT RES, V220, P960, DOI 10.1016/j.psychres.2014.08.020
   Schilder P., 1950, IMAGE APPEARANCE HUM
   Serino S, 2019, J CLIN PSYCHOL, V75, P313, DOI 10.1002/jclp.22724
   Serino S, 2018, CYBERPSYCH BEH SOC N, V21, P304, DOI 10.1089/cyber.2017.0674
   Serino S, 2017, ANN REV CYBERTHERAPY, V15, P111
   Serino S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00837
   Serino S, 2016, CYBERPSYCH BEH SOC N, V19, P127, DOI 10.1089/cyber.2015.0229
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Sterne JAC, 2000, J CLIN EPIDEMIOL, V53, P1119, DOI 10.1016/S0895-4356(00)00242-0
   Thaler A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192152
   Valentine JC, 2010, J EDUC BEHAV STAT, V35, P215, DOI 10.3102/1076998609346961
   Valtolina GG, 1998, PERCEPT MOTOR SKILL, V86, P1363, DOI 10.2466/pms.1998.86.3c.1363
   van Bennekom MJ, 2017, FRONT PSYCHIATRY, V8, DOI 10.3389/fpsyt.2017.00163
   Veale D, 2016, J BEHAV THER EXP PSY, V52, P38, DOI 10.1016/j.jbtep.2016.03.002
   Walker DC, 2012, BODY IMAGE, V9, P462, DOI 10.1016/j.bodyim.2012.06.001
   Wiederhold BK, 2016, CYBERPSYCH BEH SOC N, V19, P67, DOI 10.1089/cyber.2016.0012
   Windheim K, 2011, BEHAV RES THER, V49, P555, DOI 10.1016/j.brat.2011.05.003
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Ziser K, 2018, INT J EAT DISORDER, V51, P1121, DOI 10.1002/eat.22946
NR 88
TC 14
Z9 14
U1 3
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 21
PY 2021
VL 2
AR 657638
DI 10.3389/frvir.2021.657638
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XH0
UT WOS:001023305600001
OA gold
DA 2024-07-18
ER

PT J
AU Rosskamp, J
   Meissenhelter, H
   Weller, R
   Rüdel, MO
   Ganser, J
   Zachmann, G
AF Rosskamp, Janis
   Meissenhelter, Hermann
   Weller, Rene
   Ruedel, Marc O.
   Ganser, Johannes
   Zachmann, Gabriel
TI UnrealHaptics: Plugins for Advanced VR Interactions in Modern Game
   Engines
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; unreal engine; haptic feedback; grasping; plugin
   architecture; contact point; collision detection
AB We present UnrealHaptics, a plugin-architecture that enables advanced virtual reality (VR) interactions, such as haptics or grasping in modern game engines. The core is a combination of a state-of-the-art collision detection library with support for very fast and stable force and torque computations and a general device plugin for communication with different input/output hardware devices, such as haptic devices or Cybergloves. Our modular and lightweight architecture makes it easy for other researchers to adapt our plugins to their requirements. We prove the versatility of our plugin architecture by providing two use cases implemented in the Unreal Engine 4 (UE4). In the first use case, we have tested our plugin with a haptic device in different test scenes. For the second use case, we show a virtual hand grasping an object with precise collision detection and handling multiple contacts. We have evaluated the performance in our use cases. The results show that our plugin easily meets the requirements of stable force rendering at 1 kHz for haptic rendering even in highly non-convex scenes, and it can handle the complex contact scenarios of virtual grasping.
C1 [Rosskamp, Janis; Meissenhelter, Hermann; Weller, Rene; Ruedel, Marc O.; Ganser, Johannes; Zachmann, Gabriel] Univ Bremen, Fac Math Comp Sci 03, Comp Graph & Virtual Real, Bremen, Germany.
C3 University of Bremen
RP Rosskamp, J; Meissenhelter, H; Weller, R; Zachmann, G (corresponding author), Univ Bremen, Fac Math Comp Sci 03, Comp Graph & Virtual Real, Bremen, Germany.
EM j.rosskamp@cs.uni-bremen.de; hmeiss51@cs.uni-bremen.de;
   weller@cs.uni-bremen.de; zach@cs.uni-bremen.de
RI Zachmann, Gabriel/AAI-9685-2020
OI Zachmann, Gabriel/0000-0001-8155-1127
FU German Research Foundation DFG; Collaborative Research Center
   (Sonderforschungsbereich) 1320 EASE-Everyday Activity Science and
   Engineering, University of Bremen
FX The research reported in this paper has been (partially) supported by
   the German Research Foundation DFG, as part of Collaborative Research
   Center (Sonderforschungsbereich) 1320 EASE-Everyday Activity Science and
   Engineering, University of Bremen (http://www.ease-crc.org/).
CR 3D Systems, 2018, GEOM OPENHAPTICS TOO
   Andrews S., 2006, P FUTUREPLAY 2006 ON
   CHAI3D, 2016, US
   CHAI3D, 2016, CHAI3D DOC HAPT REND
   de Pedro J., 2016, P 4 INT C TECHNOLOGI, P1011, DOI [10.1145/3012430.3012640, DOI 10.1145/3012430.3012640]
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   Epic Games, 2020, INTR C PROGR UE4
   Epic Games, 2020, PLUGINS
   H3DAPI, 2019, US
   Haption S. A., 2020, VIRTUOSE 6D DESKTOP
   Kadleek P., 2011, P CESCG VIENN VIENN
   Kollasch F., 2017, SIRRAHERYDYA PHANTOM
   Lin J., 2016, SIGGRAPH ASIA 2016 V, P1
   Liu HX, 2019, IEEE INT CONF ROBOT, P5180, DOI [10.1109/icra.2019.8794230, 10.1109/ICRA.2019.8794230]
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Moehring M, 2011, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2011.5759451
   Mol ACA, 2008, IEEE COMPUT GRAPH, V28, P6
   Morris D., 2004, P EXPT GAM WORKSH SA
   Reinschluessel AnkeVerena., P 2017 CHI C EXTENDE, DOI [DOI 10.1145/3027063.3053173, https://doi.org/10.1145/3027063.3053173]
   Rüdel MO, 2018, LECT NOTES COMPUT SC, V11162, P128, DOI 10.1007/978-3-030-01790-3_8
   Ruffaldi E., 2006, P ACM S VIRTUAL REAL, P320, DOI [10.1145/1180495.1180559, DOI 10.1145/1180495.1180559]
   Sagardia M., 2014, EUROVR 2014 C EXH EU
   Tenorth M, 2015, KUNSTL INTELL, V29, P407, DOI 10.1007/s13218-015-0364-1
   The Glasgow School of Art, 2014, HAPT DEM UN US OPENH
   User ZeonmkII, 2016, ZEONMK OMN
   Verschoor M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P183, DOI 10.1109/VR.2018.8447555
   Weller R., 2009, P 2009 ACM SIGGRAPH, P151, DOI DOI 10.1145/1581073.1581097
   Weller Rene, 2010, P 17 ACM S VIRTUAL R, P63
   Zachmann G, 1998, P IEEE VIRT REAL ANN, P90, DOI 10.1109/VRAIS.1998.658428
   Zachmann G., 2001, P 1 INT GAM TECHN C
   Zachmann Gabriel., 2002, Proceedings of the ACM symposium on Virtual reality software and technology, VRST '02, P121
NR 31
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 16
PY 2021
VL 2
AR 640470
DI 10.3389/frvir.2021.640470
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YP8
UT WOS:001023340600001
OA gold
DA 2024-07-18
ER

PT J
AU Clemenson, GD
   Wang, LL
   Mao, ZQ
   Stark, SM
   Stark, CEL
AF Clemenson, Gregory D. D.
   Wang, Lulian
   Mao, Zeqian
   Stark, Shauna M. M.
   Stark, Craig E. L.
TI Exploring the Spatial Relationships Between Real and Virtual
   Experiences: What Transfers and What Doesn't
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE transfer; real-world navigation; virtual reality; spatial cognition;
   virtual environments (VE); real-environments
ID MORRIS WATER MAZE; CAUDATE-NUCLEUS; SEX-DIFFERENCES;
   INDIVIDUAL-DIFFERENCES; RETROSPLENIAL CORTEX; HUMAN NAVIGATION;
   HEAD-DIRECTION; LARGE-SCALE; HIPPOCAMPUS; PLACE
AB Virtual environments are commonly used to assess spatial cognition in humans. For the past few decades, researchers have used virtual environments to investigate how people navigate, learn, and remember their surrounding environment. In combination with tools such as electroencephalogram, neuroimaging, and electrophysiology, these virtual environments have proven invaluable in their ability to help elucidate the underlying neural mechanisms of spatial learning and memory in humans. However, a critical assumption that is made whenever using virtual experiences is that the spatial abilities used in the navigation of these virtual environments accurately represents the spatial abilities used in the real-world. The aim of the current study is to investigate the spatial relationships between real and virtual environments to better understand how well the virtual experiences parallel the same experiences in the real-world. Here, we performed three independent experiments to examine whether spatial information about object location, environment layout, and navigation strategy transfers between parallel real-world and virtual-world experiences. We show that while general spatial information does transfer between real and virtual environments, there are several limitations of the virtual experience. Compared to the real-world, the use of information in the virtual-world is less flexible, especially when testing spatial memory from a novel location, and the way in which we navigate these experiences are different as the perceptual and proprioceptive feedback gained from the real-world experience can influence navigation strategy.
C1 [Clemenson, Gregory D. D.; Wang, Lulian; Mao, Zeqian; Stark, Shauna M. M.; Stark, Craig E. L.] Univ Calif Irvine, Dept Neurobiol & Behav, Irvine, CA 92617 USA.
C3 University of California System; University of California Irvine
RP Stark, CEL (corresponding author), Univ Calif Irvine, Dept Neurobiol & Behav, Irvine, CA 92617 USA.
EM cestark@uci.edu
FU DANA Foundation; NIH [R21 AG056145]; McGaugh Chair in Neurobiology of
   Learning and Memory
FX This work was supported by the DANA Foundation, NIH R21 AG056145, and an
   endowment from the McGaugh Chair in Neurobiology of Learning and Memory
   awarded to CS.
CR Anon, 2019, JASP FRESH WAY DO ST
   Astur RS, 1998, BEHAV BRAIN RES, V93, P185, DOI 10.1016/S0166-4328(98)00019-9
   Bizon JL, 2003, EUR J NEUROSCI, V18, P215, DOI 10.1046/j.1460-9568.2003.02733.x
   Bohbot VD, 2007, J NEUROSCI, V27, P10078, DOI 10.1523/JNEUROSCI.1763-07.2007
   CaoGadgets LLC, 2010, MON FIND EV INT WIR
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Choi J, 2006, ENVIRON BEHAV, V38, P791, DOI 10.1177/0013916506287004
   Chrastil ER, 2015, J NEUROSCI, V35, P15442, DOI 10.1523/JNEUROSCI.1209-15.2015
   Clemenson G., 2018, OXFORD HDB DEV NEURA
   Clemenson GD, 2020, BEHAV BRAIN RES, V390, DOI 10.1016/j.bbr.2020.112667
   Clemenson GD, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00057
   Clemenson GD, 2015, J NEUROSCI, V35, P16116, DOI 10.1523/JNEUROSCI.2580-15.2015
   COOK D, 1988, BEHAV NEURAL BIOL, V49, P332, DOI 10.1016/S0163-1047(88)90338-X
   Coutrot A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213272
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   Diersch N, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.187252
   Drapeau E, 2003, P NATL ACAD SCI USA, V100, P14385, DOI 10.1073/pnas.2334169100
   Driscoll I, 2005, HORM BEHAV, V47, P326, DOI 10.1016/j.yhbeh.2004.11.013
   Ekstrom AD, 2003, NATURE, V425, P184, DOI 10.1038/nature01964
   Freund J, 2013, SCIENCE, V340, P756, DOI 10.1126/science.1235294
   Goodroe SC, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00250
   Google LLC, 2005, GOOGL MAPS
   Hartley T, 2003, NEURON, V37, P877, DOI 10.1016/S0896-6273(03)00095-3
   Harvey CD, 2009, NATURE, V461, P941, DOI 10.1038/nature08499
   Hegarty M, 2006, INTELLIGENCE, V34, P151, DOI 10.1016/j.intell.2005.09.005
   Hejtmanek L, 2020, MULTISENS RES, V33, P479, DOI 10.1163/22134808-20201445
   Hoffman M, 2011, P NATL ACAD SCI USA, V108, P14786, DOI 10.1073/pnas.1015182108
   HTC, 2016, VIVETM DISC VIRT REA
   Huffman DJ, 2019, NEURON, V104, P611, DOI 10.1016/j.neuron.2019.08.012
   Iaria G, 2003, J NEUROSCI, V23, P5945
   Jacobs J, 2013, NAT NEUROSCI, V16, P1188, DOI 10.1038/nn.3466
   KESNER RP, 1993, EXP BRAIN RES, V93, P462
   Kimura K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18289-8
   Kinateder M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00043
   Kolarik BS, 2016, NEUROPSYCHOLOGIA, V80, P90, DOI 10.1016/j.neuropsychologia.2015.11.013
   Konishi K, 2013, FRONT AGING NEUROSCI, V5, DOI 10.3389/fnagi.2013.00001
   Kraus BJ, 2015, NEURON, V88, P578, DOI 10.1016/j.neuron.2015.09.031
   Kropff E, 2015, NATURE, V523, P419, DOI 10.1038/nature14622
   Laczó J, 2010, NEURODEGENER DIS, V7, P148, DOI 10.1159/000289226
   Lester AW, 2017, NEURON, V95, P1019, DOI 10.1016/j.neuron.2017.06.037
   Livingstone-Lee SA, 2011, BEHAV BRAIN RES, V225, P117, DOI 10.1016/j.bbr.2011.07.005
   Maguire EA, 1998, SCIENCE, V280, P921, DOI 10.1126/science.280.5365.921
   Maguire EA, 2000, P NATL ACAD SCI USA, V97, P4398, DOI 10.1073/pnas.070039597
   Malinowski JC, 2001, J ENVIRON PSYCHOL, V21, P73, DOI 10.1006/jevp.2000.0183
   Marchette SA, 2011, J NEUROSCI, V31, P15264, DOI 10.1523/JNEUROSCI.3634-11.2011
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932
   MORRIS RGM, 1981, LEARN MOTIV, V12, P239, DOI 10.1016/0023-9690(81)90020-5
   Moser MB, 2015, CSH PERSPECT BIOL, V7, DOI 10.1101/cshperspect.a021808
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   Packard MG, 1996, NEUROBIOL LEARN MEM, V65, P65, DOI 10.1006/nlme.1996.0007
   Padilla LM, 2017, PSYCHON B REV, V24, P582, DOI 10.3758/s13423-016-1118-2
   Patai EZ, 2019, CEREB CORTEX, V29, P2748, DOI 10.1093/cercor/bhz044
   Pereira IT, 2015, NEUROBIOL AGING, V36, P3067, DOI 10.1016/j.neurobiolaging.2015.07.024
   Richardson AE, 1999, MEM COGNITION, V27, P741, DOI 10.3758/BF03211566
   Sargent JQ, 2019, MEM COGNITION, V47, P212, DOI 10.3758/s13421-018-0860-2
   Schmidt-Hieber C, 2013, NAT NEUROSCI, V16, P325, DOI 10.1038/nn.3340
   Shine JP, 2016, J NEUROSCI, V36, P6371, DOI 10.1523/JNEUROSCI.1268-15.2016
   Sneider JT, 2015, BEHAV PROCESS, V111, P42, DOI 10.1016/j.beproc.2014.11.015
   TAUBE JS, 1990, J NEUROSCI, V10, P420
   Technologies Unity, 2005, UN REAL TIM DEV PLAT
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Trimble, 2000, 3D DES SOFTW 3D MOD
   van Praag H, 2005, J NEUROSCI, V25, P8680, DOI 10.1523/JNEUROSCI.1731-05.2005
   Vashro L, 2015, EVOL HUM BEHAV, V36, P123, DOI 10.1016/j.evolhumbehav.2014.09.009
   VOYER D, 1995, PSYCHOL BULL, V117, P250, DOI 10.1037/0033-2909.117.2.250
   Waller D, 2007, PSYCHOL RES-PSYCH FO, V71, P322, DOI 10.1007/s00426-006-0087-x
   Wolbers T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00571
   Woollett K, 2011, CURR BIOL, V21, P2109, DOI 10.1016/j.cub.2011.11.018
   Woollett K, 2009, PHILOS T R SOC B, V364, P1407, DOI 10.1098/rstb.2008.0288
   Yuan L, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00128
   Zhao HT, 2020, J R SOC INTERFACE, V17, DOI 10.1098/rsif.2020.0116
NR 73
TC 6
Z9 6
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 8
PY 2020
VL 1
AR 572122
DI 10.3389/frvir.2020.572122
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4US2
UT WOS:001023238500001
PM 37885756
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Borghetti, D
   Zanobini, C
   Natola, I
   Ottino, S
   Parenti, A
   Brugada-Ramentol, V
   Jalali, H
   Bozorgzadeh, A
AF Borghetti, Davide
   Zanobini, Carlotta
   Natola, Ilenia
   Ottino, Saverio
   Parenti, Angela
   Brugada-Ramentol, Victoria
   Jalali, Hossein
   Bozorgzadeh, Amir
TI Evaluating cognitive performance using virtual reality gamified
   exercises
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive virtual reality; early detection; cognitive impairment;
   cognitive assessment; serious games
ID MEMORY
AB Virtual Reality (VR) environments have been proven useful in memory assessment and have shown to be more sensitive than pen-and-paper in prospective memory assessment. Moreover, these techniques provide the advantage of offering neuropsychological evaluations in a controlled, ecologically valid, and safe manner. In the present study, we used Enhance VR, a cognitive training and assessment tool in virtual reality. User performance was evaluated by means of the in-game scoring system. The primary goal of this study was to compare Enhance VR in-game scoring to already existing validated cognitive assessment tests. As a secondary goal, we tested the tolerance and usability of the system. 41 older adults took part in the study (mean age = 62.8 years). Each participant was evaluated with a predefined set of traditional pen-and-paper cognitive assessment tools and played four VR games. We failed to find a significant positive impact in explaining the variability of the Enhance VR game scores by the traditional pen-and-paper methodologies that addressed the same cognitive ability. This lack of effect may be related to the gamified environment of Enhance VR, where the players are awarded or subtracted points depending on their game performance, thus deviating from the scoring system used in traditional methodologies. Moreover, while the games were inspired by traditional assessment methodologies, presenting them in a VR environment might modify the processing of the information provided to the participant. The hardware and Enhance VR games were extremely well tolerated, intuitive, and within the reach of even those with no experience.
C1 [Borghetti, Davide; Zanobini, Carlotta; Natola, Ilenia; Ottino, Saverio] Ctr Dia Ri, Motor & Cognit Rehabil, Pisa, Italy.
   [Parenti, Angela] Univ Pisa, Dipartimento Econ & Management, Pisa, Tuscany, Italy.
   [Brugada-Ramentol, Victoria; Jalali, Hossein; Bozorgzadeh, Amir] Virtuleap, Lisbon, Portugal.
C3 University of Pisa
RP Borghetti, D (corresponding author), Ctr Dia Ri, Motor & Cognit Rehabil, Pisa, Italy.
EM info@davideborghetti.it
CR [Anonymous], 2006, Italian translation of MoCA test and of its instructions
   [Anonymous], 1983, The assessment of aphasia and related disorders
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Brugada-Ramentol V, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.916052
   Conti S, 2015, NEUROL SCI, V36, P209, DOI 10.1007/s10072-014-1921-3
   Corsi P.M., 1972, Human memory and the medial temporal region of the brain
   Díaz-Pérez E, 2018, REV NEUROLOGIA, V66, P344, DOI 10.33588/rn.6610.2017438
   Fraser S, 2013, WIRES COGN SCI, V4, P623, DOI 10.1002/wcs.1252
   GRANT DA, 1948, J EXP PSYCHOL, V38, P404, DOI 10.1037/h0059831
   Kourtesis P, 2021, J INT NEUROPSYCH SOC, V27, P181, DOI 10.1017/S1355617720000764
   MCDOWD JM, 1988, J EXP PSYCHOL HUMAN, V14, P267, DOI 10.1037/0096-1523.14.2.267
   Mrakic-Sposta S, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00282
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nolin P., 2013, AJIS, V2, P612, DOI [10.5901/AJIS.2013.V2N8P612, DOI 10.5901/AJIS.2013.V2N8P612]
   Novelli G., 1986, Neurol. Psichiatria", V47, P278
   Osterrieth P.A., 1944, ARCH PSYCHOLOGIE, V30, P206
   Ouellet É, 2018, J NEUROSCI METH, V303, P126, DOI 10.1016/j.jneumeth.2018.03.010
   Parsons TD, 2008, CYBERPSYCHOL BEHAV, V11, P17, DOI 10.1089/cpb.2007.9934
   Pinto TCC, 2019, INT PSYCHOGERIATR, V31, P491, DOI 10.1017/S1041610218001370
   Plotnik M, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00849-9
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   SAHAKIAN BJ, 1988, BRAIN, V111, P695, DOI 10.1093/brain/111.3.695
   Sala S.Della., 1997, VISUAL PATTERNS TEST
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Santangelo G, 2015, NEUROL SCI, V36, P585, DOI 10.1007/s10072-014-1995-y
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Spinnler H, 1987, Ital J Neurol Sci, V6, P47
   Spooner DM, 2006, ARCH CLIN NEUROPSYCH, V21, P327, DOI 10.1016/j.acn.2006.04.004
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   World Health Organization Regional Office for Europe, 2023, Dementia
NR 34
TC 1
Z9 1
U1 6
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 7
PY 2023
VL 4
AR 1153145
DI 10.3389/frvir.2023.1153145
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Y4HY2
UT WOS:001104901300001
OA gold
DA 2024-07-18
ER

PT J
AU Feick, M
   Degraen, D
   Hupperich, F
   Krueger, A
AF Feick, Martin
   Degraen, Donald
   Hupperich, Fabian
   Krueger, Antonio
TI MetaReality: enhancing tactile experiences using actuated 3D-printed
   metamaterials in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; haptic (tactile) illusion; fabrication; 3D-print;
   metamaterial; haptic (tactile) perception; active haptics; passive
   haptics
ID HAPTIC FEEDBACK; PERCEPTION
AB During interaction with objects in Virtual Reality haptic feedback plays a crucial role for creating convincing immersive experiences. Recent work building upon passive haptic feedback has looked towards fabrication processes for designing and creating proxy objects able to communicate objects' properties and characteristics. However, such approaches remain limited in terms of scalability as for each material a corresponding object needs to be fabricated. To create more flexible 3D-printed proxies, we explore the potential of metamaterials. To this aim, we designed metamaterial structures able to alter their tactile surface properties, e.g., their hardness and roughness, upon lateral compression. In this work, we designed five different metamaterial patterns based on features that are known to affect tactile properties. We evaluated whether our samples were able to successfully convey different levels of roughness and hardness sensations at varying levels of compression. While we found that roughness was significantly affected by compression state, hardness did not seem to follow the same pattern. In a second study, we focused on two metamaterial patterns showing promise for roughness perception and investigated their visuo-haptic perception in Virtual Reality. Here, eight different compression states of our two selected metamaterials were overlaid with six visual material textures. Our results suggest that, especially at low compression states, our metamaterials were the most promising ones to match the textures displayed to the participants. Additionally, when asked which material participants perceived, adjectives, such as "broken" and "damaged" were used. This indicates that metamaterial surface textures could be able to simulate different object states. Our results underline that metamaterial design is able to extend the gamut of tactile experiences of 3D-printed surfaces structures, as a single sample is able to reconfigure its haptic sensation through compression.
C1 [Feick, Martin; Degraen, Donald; Hupperich, Fabian; Krueger, Antonio] German Res Ctr Artificial Intelligence DFKI, Cognit Assistants COS, Saarbrucken, Germany.
   [Feick, Martin; Degraen, Donald; Hupperich, Fabian; Krueger, Antonio] Saarland Univ, Ubiquitous Media Technol Lab, Saarbrucken, Germany.
C3 German Research Center for Artificial Intelligence (DFKI); Saarland
   University
RP Feick, M; Degraen, D (corresponding author), German Res Ctr Artificial Intelligence DFKI, Cognit Assistants COS, Saarbrucken, Germany.; Feick, M; Degraen, D (corresponding author), Saarland Univ, Ubiquitous Media Technol Lab, Saarbrucken, Germany.
EM martin.feick@dfki.de; donald.degraen@dfki.de
OI Degraen, Donald/0000-0003-1029-931X
FU German Federal Ministry of Education and Research (BMBF) [01IS17043];
   Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [450247716, 425868555]; Priority Program SPP2199 Scalable Interaction
   Paradigms for Pervasive Computing Environments
FX This research was funded in part by the German Federal Ministry of
   Education and Research (BMBF) under grant number 01IS17043 (project
   VRGiO) and by the Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation), projects 450247716 and 425868555, the latter being part of
   Priority Program SPP2199 Scalable Interaction Paradigms for Pervasive
   Computing Environments.
CR Araujo B, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P218, DOI 10.1145/2839462.2839484
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Bergström J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1175, DOI 10.1145/3332165.3347939
   Bickel B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778800
   Charrad M, 2014, J STAT SOFTW, V61, P1
   CLARKE KR, 1993, AUST J ECOL, V18, P117, DOI 10.1111/j.1442-9993.1993.tb00438.x
   Cooke T., 2006, ACM Transactions on Applied Perception, V3, P239
   Culbertson H, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P295, DOI 10.1109/WHC.2013.6548424
   Degraen Donald, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P954, DOI 10.1145/3472749.3474798
   Degraen Donald, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P936, DOI 10.1145/3472749.3474797
   Degraen D, 2020, COMPANION PUBLICATION OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS' 20 COMPANION), P287, DOI [10.1145/10.1145/3393914.3395870, 10.1145/3393914.3395870]
   Degraen D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300479
   Dellon A L, 1978, J Hand Surg Am, V3, P474
   Ernst M. O., 2012, NEW HDB MULTISENSORY, DOI [10.7551/mitpress/8466.003.0048, DOI 10.7551/MITPRESS/8466.003.0048]
   Feick M., 2020, ADJUNCT P ANN ACM S, P68, DOI [DOI 10.1145/3379350.3416188, 10.1145/3379350.3416188]
   Feick M, 2020, INT SYM MIX AUGMENT, P195, DOI 10.1109/ISMAR50242.2020.00042
   Feick Martin., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1, DOI [10.1145/3411764.3445456, DOI 10.1145/3411764.3445456]
   Gangwar K., 2014, Adv. Electron. Electr. Eng., V4, P97
   Gedsun A, 2022, ADV MATER INTERFACES, V9, DOI 10.1002/admi.202101380
   Groeger D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P923, DOI 10.1145/3332165.3347937
   Iesaki A, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P265
   Insko B., 2001, THESIS U N CAROLINA
   Ion A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173910
   Ishizaki K., 2013, Porous materials: process technology and applications, V4
   Jun Gong, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1063, DOI 10.1145/3472749.3474806
   Kitahara I, 2010, ADVANCES IN HAPTICS, P565
   Klatzky RL, 2013, P IEEE, V101, P2081, DOI 10.1109/JPROC.2013.2248691
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee CJ, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445285
   Lu G, 1999, J POROUS MAT, V6, P359, DOI 10.1023/A:1009669730778
   Myers N.O., 1962, Wear, V5, P182, DOI [DOI 10.1016/0043-1648(62)90002-9, 10.1016/0043-1648(62)90002-9]
   Neville RM, 2016, SCI REP-UK, V6, DOI 10.1038/srep31067
   Nilsson NC, 2021, IEEE COMPUT GRAPH, V41, P104, DOI 10.1109/MCG.2021.3097671
   Okamoto S, 2013, IEEE T HAPTICS, V6, P81, DOI [10.1109/ToH.2012.32, 10.1109/TOH.2012.32]
   Piovarci M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925885
   Punpongsanon P, 2015, IEEE T VIS COMPUT GR, V21, P1279, DOI 10.1109/TVCG.2015.2459792
   Robles-De-La-Torre G, 2006, IEEE MULTIMEDIA, V13, P24, DOI 10.1109/MMUL.2006.69
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Sato Y, 2020, IEEE ACCESS, V8, P120473, DOI 10.1109/ACCESS.2020.3006440
   Schneider O, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503734
   Schneider O, 2017, INT J HUM-COMPUT ST, V107, P5, DOI 10.1016/j.ijhcs.2017.04.004
   Schumacher C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766926
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Speicher M, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312927
   Steed A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24974-0
   Strohmeier P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173639
   Takahashi H, 2022, ADJUNCT PROCEEDINGS OF THE 35TH ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2022, DOI 10.1145/3526114.3558655
   Torres C, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P583, DOI 10.1145/2807442.2807492
   Valipour A, 2022, P I MECH ENG L-J MAT, V236, P2171, DOI 10.1177/1464420721995858
   Vardar Y, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P395, DOI [10.1109/WHC.2019.8816095, 10.1109/whc.2019.8816095]
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Wittchen D, 2022, TEI'22: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, DOI 10.1145/3490149.3501307
   Xiao SY, 2020, J PHYS D APPL PHYS, V53, DOI 10.1088/1361-6463/abaced
   Yang WY, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545649
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
NR 55
TC 1
Z9 1
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 28
PY 2023
VL 4
AR 1172381
DI 10.3389/frvir.2023.1172381
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XH6
UT WOS:001023306200001
OA gold
DA 2024-07-18
ER

PT J
AU Ang, S
   Quarles, J
AF Ang, Samuel
   Quarles, John
TI Reduction of cybersickness in head mounted displays use: A systematic
   review and taxonomy of current strategies
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE cybersickness; visually induced motion sickness (VIMS); head mounted
   display (HMD); systematic review; simulator sickness; virtual reality
ID VIRTUAL-REALITY; SICKNESS; SEVERITY; IMPACT; HMD
AB This literature review examines the existing research into cybersickness reduction with regards to head mounted display use. Cybersickness refers to a collection of negative symptoms sometimes experienced as the result of being immersed in a virtual environment, such as nausea, dizziness, or eye strain. These symptoms can prevent individuals from utilizing virtual reality (VR) technologies, so discovering new methods of reducing them is critical. Our objective in this literature review is to provide a better picture of what cybersickness reduction techniques exist, the quantity of research demonstrating their effectiveness, and the virtual scenes testing has taken place in. This will help to direct researches towards promising avenues, and illuminate gaps in the literature. Following the preferred reporting items for systematic reviews and meta-analyses statement, we obtained a batch of 1,055 papers through the use of software aids. We selected 88 papers that examine potential cybersickness reduction approaches. Our acceptance criteria required that papers examined malleable conditions that could be conceivably modified for everyday use, examined techniques in conjunction with head mounted displays, and compared cybersickness levels between two or more user conditions. These papers were sorted into categories based on their general approach to combating cybersickness, and labeled based on the presence of statistically significant results, the use of virtual vehicles, the level of visual realism, and the virtual scene contents used in evaluation of their effectiveness. In doing this we have created a snapshot of the literature to date so that researchers may better understand what approaches are being researched, and the types of virtual experiences used in their evaluation. Keywords: Virtual reality cybersickness Simulator Sickness Visually induced motion sickness reduction Systematic review Head mounted display.
C1 [Ang, Samuel; Quarles, John] Univ Texas San Antonio, San Antonio, TX 78249 USA.
C3 University of Texas System; University of Texas at San Antonio (UTSA)
RP Ang, S (corresponding author), Univ Texas San Antonio, San Antonio, TX 78249 USA.
EM samuel.ang.prog@gmail.com
FU National Science Foundation [IIS-2007041, IIS-2211785]
FX Funding This research was supported in part by a grant from the National
   Science Foundation (IIS-2007041, IIS-2211785). The NSF did not have a
   direct role in this research project.
CR Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   Al Zayer M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300584
   Aldaba CN, 2020, MED BIOL ENG COMPUT, V58, P143, DOI 10.1007/s11517-019-02070-2
   Almeida A, 2018, ADV INTELL SYST, V588, P26, DOI 10.1007/978-3-319-60582-1_3
   Andersen Kurt, 2020, 17th International Conference on Information Technology-New Generations (ITNG 2020). Advances in Intelligent Systems and Computing (AISC 1134), P317, DOI 10.1007/978-3-030-43020-7_42
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Arnold JT, 2019, DISPLAYS, V60, P18, DOI 10.1016/j.displa.2019.08.007
   Aukstakalnis S., 1992, SILICON MIRAGE ART S
   Bala P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P244, DOI 10.1109/ISMAR-Adjunct.2018.00077
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Budhiraja P, 2017, Arxiv, DOI arXiv:1710.02599
   Buhler H, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P517, DOI 10.1109/VR.2018.8446346
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Carnegie Kieran., 2015, Mitigating visual discomfort on head mounted displays using estimated gaze dependent depth of field
   Carruth DW, 2019, LECT NOTES COMPUT SC, V11575, P34, DOI 10.1007/978-3-030-21565-1_3
   Caserman P, 2019, LECT NOTES COMPUT SC, V11863, P57, DOI 10.1007/978-3-030-34644-7_5
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Choros K, 2019, LECT NOTES ARTIF INT, V11431, P638, DOI 10.1007/978-3-030-14799-0_55
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cmentowski S, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P287, DOI 10.1145/3311350.3347183
   Cortes CAT, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365694
   Davis Simon., 2015, 11th Australasian Conference on Interactive Entertainment (IE 2015), P27, DOI DOI 10.17973/MMSJ.2015
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dorado Jose L., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P145, DOI 10.1109/3DUI.2015.7131742
   Dorado JL, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P47, DOI 10.1109/3DUI.2014.6798841
   Farmani Y, 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   FERDOUS SMS, 2018, P 24 ACM S VIRT REAL, P1, DOI DOI 10.1109/VR.2018.8446488
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Freiwald Jann Philipp., 2018, Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology, P1
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Gersak G, 2020, MULTIMED TOOLS APPL, V79, P14491, DOI 10.1007/s11042-018-6969-2
   Gonçalves G, 2020, IEEE ACCESS, V8, P29249, DOI 10.1109/ACCESS.2020.2970921
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   Han J., 2017, IS. T. Int. Symp. Electron. Imaging Sci. Technol, V29, P212, DOI [10.2352/ISSN.2470-1173.2017.14.HVEI-146, DOI 10.2352/ISSN.2470-1173.2017.14.HVEI-146]
   Harrington Jake., 2019, A somatic approach to combating cybersickness utilising airflow feedback
   Harzing A.W., 2007, Publish or Perish
   Ihemedu-Steinke QC, 2017, LECT NOTES COMPUT SC, V10280, P521, DOI 10.1007/978-3-319-57987-0_42
   Isaza M, 2019, INT CONF GAMES VIRTU, P142, DOI 10.1109/vs-games.2019.8864578
   Iskenderova A, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P561, DOI 10.1145/3116595.3116618
   Kala Nupur, 2017, SID Symposium Digest of Technical Papers, V48, P1645, DOI 10.1002/sdtp.11956
   Kaufeld M, 2019, LECT NOTES COMPUT SC, V11574, P461, DOI 10.1007/978-3-030-21607-8_36
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim D, 2019, COMPUT HUM BEHAV, V93, P346, DOI 10.1016/j.chb.2018.12.040
   Kim NG, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091919
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kwok KKK, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P91, DOI 10.1109/ISMAR-Adjunct.2018.00041
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343125
   Lin J, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2020.101040
   Litleskare S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02436
   Liu SH, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P817, DOI [10.1109/vr.2019.8798158, 10.1109/VR.2019.8798158]
   Llorach G, 2014, P ACM S VIRT REAL SO, P137
   Loup G, 2019, INT J HUM-COMPUT INT, V35, P1270, DOI 10.1080/10447318.2018.1519164
   Lugrin JL, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1062, DOI [10.1109/VR.2019.8798017, 10.1109/vr.2019.8798017]
   Luks R, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P280, DOI 10.1145/3316782.3321535
   Marengo J, 2019, IEEE CONF COMPU INTE
   Mayor J, 2021, IEEE T EMERG TOP COM, V9, P1542, DOI 10.1109/TETC.2019.2915287
   Mehrfard A, 2019, Arxiv, DOI arXiv:1912.02913
   Milosevic I., 2015, PHOBIAS PSYCHOL IRRA
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Monteiro D, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1830
   Moroz M, 2019, DISPLAYS, V58, P12, DOI 10.1016/j.displa.2018.09.001
   Mustafa Zaidi Syed Fawad., 2018, Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology, P1, DOI DOI 10.1145/3284398.3284431
   Nabioyuni M., 2015, The Eurographics Association, P167, DOI DOI 10.2312/EGVE.20151325
   Narciso D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3380903
   Ng AKT, 2020, DISPLAYS, V61, DOI 10.1016/j.displa.2019.08.004
   Ng AKT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1860, DOI [10.1109/vr.2019.8797781, 10.1109/VR.2019.8797781]
   Nguyen-Vo T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P415, DOI 10.1109/VR.2018.8446383
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   Norouzi N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225162
   Ochi Daisuke., 2016, ACM SIGGRAPH 2016 Emerging Technologies, P1
   Onuki Y, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1864, DOI 10.1109/VR.2019.8797722
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Paroz A, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P582, DOI 10.1145/3292147.3292229
   Peng YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376847
   Pouke M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P665, DOI 10.1109/VR.2018.8446078
   Qian YY, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P130, DOI 10.1145/3267782.3267798
   Qionghua W, 2019, Arxiv, DOI arXiv:1903.12617
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   REGAN EC, 1994, AVIAT SPACE ENVIR MD, V65, P527
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Ryge AN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P675, DOI 10.1109/VR.2018.8446206
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   SCHUIRMANN DJ, 1987, J PHARMACOKINET BIOP, V15, P657, DOI 10.1007/BF01068419
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Skopp NA, 2014, INT J HUM-COMPUT INT, V30, P24, DOI 10.1080/10447318.2013.796441
   Sra M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300905
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Ueda Y, 2018, LECT NOTES COMPUT SC, V11112, P228, DOI 10.1007/978-3-319-99426-0_22
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Wang Yuyang., 2018, A semiautomatic navigation interface to reduce visually induced motion sickness in virtual reality
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Wertheim AH., 2001, Predicting motion induced vomiting from subjective misery (MISC) ratings obtained in 12 experimental studies
   Widdowson C., 2019, ASSESSING POSTURAL
   Wienrich C., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications, P1, DOI [DOI 10.1109/VS-GAMES.2018.8493408, DOI 10.1109/VS-GAMES.2018, 10.1109/VS-Games.2018.8493408]
   Won Deok Park, 2017, Vibroengineering Procedia. 28th International Conference on Vibroengineering, P260, DOI 10.21595/vp.2017.19170
   Xia XY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1241, DOI [10.1109/VR.2019.8797791, 10.1109/vr.2019.8797791]
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yu XY, 2016, I C VIRTUAL REALITY, P426, DOI 10.1109/ICVRV.2016.78
   Ziegler P, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P743, DOI 10.1109/VR.2018.8446221
   Zielasko D., 2018, Proc. of IEEE VR Workshop on Everyday Virtual Reality
   Zielasko D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1884, DOI [10.1109/vr.2019.8797837, 10.1109/VR.2019.8797837]
NR 113
TC 4
Z9 4
U1 3
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 3
PY 2023
VL 4
AR 1027552
DI 10.3389/frvir.2023.1027552
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0HL3
UT WOS:001020149300001
OA gold
DA 2024-07-18
ER

PT J
AU Pinilla, A
   Voigt-Antons, JN
   Garcia, J
   Raffe, W
   Möller, S
AF Pinilla, Andres
   Voigt-Antons, Jan-Niklas
   Garcia, Jaime
   Raffe, William
   Moeller, Sebastian
TI Real-time affect detection in virtual reality: a technique based on a
   three-dimensional model of affect and EEG signals
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE affect detection; electroencephalography; virtual reality; emotion;
   affective computing; supervised learning; machine learning; feature
   selection
ID DYNAMICS; EMOTION
AB This manuscript explores the development of a technique for detecting the affective states of Virtual Reality (VR) users in real-time. The technique was tested with data from an experiment where 18 participants observed 16 videos with emotional content inside a VR home theater, while their electroencephalography (EEG) signals were recorded. Participants evaluated their affective response toward the videos in terms of a three-dimensional model of affect. Two variants of the technique were analyzed. The difference between both variants was the method used for feature selection. In the first variant, features extracted from the EEG signals were selected using Linear Mixed-Effects (LME) models. In the second variant, features were selected using Recursive Feature Elimination with Cross Validation (RFECV). Random forest was used in both variants to build the classification models. Accuracy, precision, recall and F1 scores were obtained by cross-validation. An ANOVA was conducted to compare the accuracy of the models built in each variant. The results indicate that the feature selection method does not have a significant effect on the accuracy of the classification models. Therefore, both variations (LME and RFECV) seem equally reliable for detecting affective states of VR users. The mean accuracy of the classification models was between 87% and 93%.
C1 [Pinilla, Andres; Moeller, Sebastian] Tech Univ Berlin, Inst Software Technol & Theoret Comp Sci, Fac Elect Engn & Comp Sci, Qual & Usabil Lab, Berlin, Germany.
   [Pinilla, Andres; Garcia, Jaime; Raffe, William] Univ Technol Sydney UTS, Fac Engn & IT, UTS Games Studio, Sydney, NSW, Australia.
   [Voigt-Antons, Jan-Niklas; Moeller, Sebastian] German Res Ctr Artificial Intelligence DFKI, Berlin, Germany.
   [Voigt-Antons, Jan-Niklas] Hamm Lippstadt Univ Appl Sci, Hamm, Germany.
C3 Technical University of Berlin; University of Technology Sydney; German
   Research Center for Artificial Intelligence (DFKI)
RP Pinilla, A (corresponding author), Tech Univ Berlin, Inst Software Technol & Theoret Comp Sci, Fac Elect Engn & Comp Sci, Qual & Usabil Lab, Berlin, Germany.; Pinilla, A (corresponding author), Univ Technol Sydney UTS, Fac Engn & IT, UTS Games Studio, Sydney, NSW, Australia.
EM andres.pinilla@qu.tu-berlin.de
RI Raffe, William Luke/AAI-2676-2020
OI Raffe, William Luke/0000-0001-5310-0943; Moller,
   Sebastian/0000-0003-3057-0760; Garcia, Jaime/0000-0001-5718-1605;
   Pinilla Palacios, Andres/0000-0002-0812-7896
FU Technische Universitat Berlin, Germany; University of Technology Sydney,
   Australia; School of Computer Science from the Faculty of Engineering
   and IT, University of Technology Sydney
FX This work was supported by the strategic partnership between the
   Technische Universitat Berlin, Germany, and the University of Technology
   Sydney, Australia. Additional support was provided by the School of
   Computer Science from the Faculty of Engineering and IT, University of
   Technology Sydney.
CR Akar SA, 2015, IEEE ENG MED BIO, P7410, DOI 10.1109/EMBC.2015.7320104
   Akbar S, 2021, LECT NOTES ARTIF INT, V12960, P509, DOI 10.1007/978-3-030-86993-9_45
   Antons J.-N., 2015, SER T LABS SERIES TE
   Antons JN, 2014, T-LAB SER TELECOMMUN, P109, DOI 10.1007/978-3-319-02681-7_8
   Baghaei Nilufar, 2021, EICS '21: Companion of the 2021 SIGCHI Symposium on Engineering Interactive Computing Systems, P6, DOI 10.1145/3459926.3464761
   Balan O, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010021
   Ball TM, 2020, BIOL PSYCHIAT-COGN N, V5, P261, DOI 10.1016/j.bpsc.2019.09.003
   Barlow D., 1991, CHRONIC ANXIETY GEN, P1
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Badia SBI, 2019, IEEE J BIOMED HEALTH, V23, P1877, DOI 10.1109/JBHI.2018.2878846
   Blandon D.Z., 2016, 2016 IEEE 11th Colombian Computing Conference (CCC), P1, DOI DOI 10.1109/COLUMBIANCC.2016.7750788
   Brook M, 2013, J ABNORM PSYCHOL, V122, P156, DOI 10.1037/a0030261
   Brouwer AM, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00136
   Cacioppo J T, 1997, Pers Soc Psychol Rev, V1, P3, DOI 10.1207/s15327957pspr0101_2
   Cao KY, 2020, IEEE ACCESS, V8, P85714, DOI 10.1109/ACCESS.2020.2991734
   DAVIDSON RJ, 1992, PSYCHOL SCI, V3, P39, DOI 10.1111/j.1467-9280.1992.tb00254.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dimberg U, 2000, PSYCHOL SCI, V11, P86, DOI 10.1111/1467-9280.00221
   Gramann K, 2011, REV NEUROSCIENCE, V22, P593, DOI 10.1515/RNS.2011.047
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Guy G., 2016, VIRTUAL DESKTOP
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Hofmann SM, 2021, ELIFE, V10, DOI [10.7554/eLife.64812, 10.7554/eLife.64812.sa0, 10.7554/eLife.64812.sa1, 10.7554/eLife.64812.sa2]
   Hofmann SM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P128, DOI 10.1109/AIVR.2018.00026
   Huster RJ, 2009, INT J PSYCHOPHYSIOL, V72, P212, DOI 10.1016/j.ijpsycho.2008.12.009
   Khosrowabadi R, 2014, IEEE T NEUR NET LEAR, V25, P609, DOI 10.1109/TNNLS.2013.2280271
   Klug M., 2018, BEMOBIL PIPELINE FAC
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kraljevic L, 2017, IEEE ROMAN, P653, DOI 10.1109/ROMAN.2017.8172372
   Kruger C, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123100
   Liu JX, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1722, DOI 10.1109/FSKD.2016.7603437
   Lombard M, 2000, HUM COMMUN RES, V26, P75, DOI 10.1111/j.1468-2958.2000.tb00750.x
   Mattek A., 2011, P 26 ANN C SOC EL MU
   Mehmood RM., 2015, ADV SCI TECHNOL LETT, V91, P24, DOI DOI 10.14257/ASTL.2015.91.05
   Mullen TR, 2015, IEEE T BIO-MED ENG, V62, P2553, DOI 10.1109/TBME.2015.2481482
   Ojeda A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00121
   Palmiero M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00763
   Patil A, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P429
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Perkis A., 2020, QUALINET WHITE PAPER, P05
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Pinilla A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.630731
   Pinilla A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00097
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   Quintero L, 2021, INT SYM MIX AUGMENT, P357, DOI 10.1109/ISMAR52148.2021.00052
   RAY WJ, 1985, SCIENCE, V228, P750, DOI 10.1126/science.3992243
   Riha C, 2020, BRAIN TOPOGR, V33, P413, DOI 10.1007/s10548-020-00772-7
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Semertzidis N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376599
   Shiban Y, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00400
   Singh AK, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P582, DOI 10.1109/SSCI47803.2020.9308292
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Tavares Vasconcelos Oliveira F., 2021, 6 INT C GAM SER GAM
   Thayer JF, 2009, ANN BEHAV MED, V37, P141, DOI 10.1007/s12160-009-9101-z
   Tripathi S., 2017, AAAI CONF ARTIF INTE
   Val-Calvo M, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00080
   Vallat R., 2022, ANTROPY
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Xu HY, 2012, IEEE INT WORKSH MULT, P299, DOI 10.1109/MMSP.2012.6343458
   Yin Z, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00019
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
   Zanetti R, 2022, IEEE T BIO-MED ENG, V69, P265, DOI 10.1109/TBME.2021.3092206
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 64
TC 2
Z9 2
U1 2
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 5
PY 2023
VL 3
AR 964754
DI 10.3389/frvir.2022.964754
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VJ3
UT WOS:001023255600001
OA gold
DA 2024-07-18
ER

PT J
AU Bakk, AK
AF Bakk, Agnes Karolina
TI Representing mental disorders with virtual reality applications:
   Designing for multimodality and complex participation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; complexity; narrative; participation; mental disorder
AB In this paper, I present various strategies adopted by creators of artistic interactive virtual reality (VR) experiences to represent mental health problems and their contexts. The strategies can foster dialogues about these problems, as they present their complexities by embedding them into various narrative and non-narrative elements. In discussing the representational complexity of these works, I emphasize design strategies that tackle stereotypes and their ethical representations and which create a specific type of suspense for the experiencer to bypass the representation of suffering that documentary VR works often use. These productions approach mental health issues as dynamic systems and represent them through linearity or non-linearity (see Stepney 2018). This approach offers limited agency to the interactor, in the sense that the user has a sense of embodiment (Kilteni et al., 2012) and is scripted as an interactor in specific cases (Murray 1997). In this paper, I argue that the VR medium's characteristic of expressing non-linearity via multimodality (see Ellestrom 2019) and sense of embodiment makes it suitable for such productions.
C1 [Bakk, Agnes Karolina] Nagy Univ Art & Design, Innovat Ctr Moholy, Budapest, Hungary.
RP Bakk, AK (corresponding author), Nagy Univ Art & Design, Innovat Ctr Moholy, Budapest, Hungary.
EM bakk@mome.hu
FU Innovation Center of Moholy-Nagy University of Art and Design, Budapest
   (Innovation Center); COST Action [18230]; Innovation Center of
   Moholy-Nagy University of Art and Design, Budapest (Innovation Center)
FX This research was supported by the Innovation Center of Moholy-Nagy
   University of Art and Design, Budapest (Innovation Center), and by COST
   Action no. 18230 Interactive Digital Narratives for Complexity
   Representations. The publication costs are entirely supported by the
   Innovation Center of Moholy-Nagy University of Art and Design, Budapest
   (Innovation Center).
CR Alston A, 2013, PERFORM RES, V18, P128, DOI 10.1080/13528165.2013.807177
   Bakk A. K., 2021, WELL PLAY J, V10, P116, DOI [10.1184/R1/14919645.v4, DOI 10.1184/R1/14919645.V4]
   Bakk AK, 2020, LECT NOTES COMPUT SC, V12497, P327, DOI 10.1007/978-3-030-62516-0_29
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   Bornkamm H., 2018, CINEMA, V63, P38
   Bown J., 2018, NARRATING COMPLEXITY, P253, DOI [10.1007/978-3-319-64714-2_18, DOI 10.1007/978-3-319-64714-2_18]
   Brewin CR, 2001, BEHAV RES THER, V39, P373, DOI 10.1016/S0005-7967(00)00087-5
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Ellestrom L, 2019, TRANSMEDIAL NARRATION: NARRATIVES AND STORIES IN DIFFERENT MEDIA, P1, DOI 10.1007/978-3-030-01294-6
   Fisher JA, 2018, LECT NOTES COMPUT SC, V11318, P577, DOI 10.1007/978-3-030-04028-4_68
   Fisher JA, 2017, LECT NOTES COMPUT SC, V10690, P233, DOI 10.1007/978-3-319-71027-3_19
   Foa E.B., 1994, POSTTRAUMATIC STRESS, P133
   Frank S., 2016, BEING REALLY VIRTUAL
   Fried EI, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01668-w
   Gaudenzi Sandra., 2013, LIVING DOCUMENTARY R
   Hameed A, 2018, LECT NOTES COMPUT SC, V11318, P323, DOI 10.1007/978-3-030-04028-4_35
   Heath E., 2019, MENT DIS POP FILM
   Jones S., 2017, Journal of Media Practice, V18, P171
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kirby Michael., 1972, Drama Review, V16, P3
   Klein Kitty., 2003, NARRATIVE THEORY COG, P56
   Kreitler M., DISINFORMATION CULTU
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Murray Janet H., 1997, Hamlet on the Holodeck: The Future of Narrative in Cyberspace
   Murray Smith., 1995, Engaging Characters: Fiction, Emotion, and the Cinema
   Nash K., 2021, INTERACTIVE DOCUMENT
   Peters C, 2011, JOURNALISM, V12, P297, DOI 10.1177/1464884910388224
   Robb J, 2016, J REHABIL, V82, P3
   Silberman Marc, 2014, Brecht on Theatre, V3rd
   Silverstone Roger., 2007, Media and Morality: On the Rise of the Mediapolis
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stepney S., 2018, NARRATING COMPLEXITY, P253, DOI [10.1007/978-3-319-64714-2_18, DOI 10.1007/978-3-319-64714-2_18]
   Suedfeld P, 1997, PSYCHOSOM MED, V59, P172, DOI 10.1097/00006842-199703000-00009
   Vitillio T., 2021, SKARREDGHOST BLOG
   Walsh K.R., 2002, Communications of the Associations of the Information Systems, V8 issue1, p, P20, DOI DOI 10.17705/1CAIS.00820
   Wiseman R, 2022, PEERJ, V10, DOI 10.7717/peerj.13755
NR 36
TC 2
Z9 2
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 4
PY 2023
VL 3
AR 881766
DI 10.3389/frvir.2022.881766
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XX2
UT WOS:001023321900001
OA gold
DA 2024-07-18
ER

PT J
AU Lin, JH
   Latoschik, ME
AF Lin, Jinghuai
   Latoschik, Marc Erich
TI Digital body, identity and privacy in social virtual reality: A
   systematic review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; avatar; social VR; identity theft; privacy; systemactic
   review
ID AVATAR; AUTHENTICATION; REPRESENTATION; CONSTRUCTION
AB Social Virtual Reality (social VR or SVR) provides digital spaces for diverse human activities, social interactions, and embodied face-to-face encounters. While our digital bodies in SVR can in general be of almost any conceivable appearance, individualized or even personalized avatars bearing users' likeness recently became an interesting research topic. Such digital bodies show a great potential to enhance the authenticity of social VR citizens and increase the trustworthiness of interpersonal interaction. However, using such digital bodies might expose users to privacy and identity issues such as identity theft: For instance, how do we know whether the avatars we encounter in the virtual world are who they claim to be? Safeguarding users' identities and privacy, and preventing harm from identity infringement, are crucial to the future of social VR. This article provides a systematic review on the protection of users' identity and privacy in social VR, with a specific focus on digital bodies. Based on 814 sources, we identified and analyzed 49 papers that either: 1) discuss or raise concerns about the addressed issues, 2) provide technologies and potential solutions for protecting digital bodies, or 3) examine the relationship between the digital bodies and users of social VR citizens. We notice a severe lack of research and attention on the addressed topic and identify several research gaps that need to be filled. While some legal and ethical concerns about the potential identity issues of the digital bodies have been raised, and despite some progress in specific areas such as user authentication has been made, little research has proposed practical solutions. Finally, we suggest potential future research directions for digital body protection and include relevant research that might provide insights. We hope this work could provide a good overview of the existing discussion, potential solutions, and future directions for researchers with similar concerns. We also wish to draw attention to identity and privacy issues in social VR and call for interdisciplinary collaboration.
C1 [Lin, Jinghuai; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
C3 University of Wurzburg
RP Lin, JH (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
EM jinghuai.lin@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023; Assistant, Research/JRW-7309-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600; Lin,
   Jinghuai/0000-0003-4205-3170
FU Privacy Matters (PriMa) project; European Union's Horizon 2020 research
   and innovation programme under the Marie Sklodowska-Curie [860315];
   Privacy Matters (PriMa) project; European Union's Horizon 2020 research
   and innovation programme under the Marie Sklodowska-Curie [860315]
FX This work is part of the Privacy Matters (PriMa) project. The PriMa
   project has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie grant
   agreement No 860315.
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Adams D, 2018, PROCEEDINGS OF THE FOURTEENTH SYMPOSIUM ON USABLE PRIVACY AND SECURITY, P427
   Ali N. A., 2019, EIJS, P2490, DOI [10.24996/ijs.2019.60.11.21, DOI 10.24996/IJS.2019.60.11.21]
   Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Alldieck T, 2018, INT CONF 3D VISION, P98, DOI 10.1109/3DV.2018.00022
   Allen C, 2016, PATH SELF SOVEREIGN
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Bader Samira, 2014, 2014 4th International Conference on Image Processing Theory, Tools and Applications (IPTA). Proceedings, P1, DOI 10.1109/IPTA.2014.7001949
   Bader S., 2014, INT IM PROC APPL SYS, P1, DOI [10.1109/IPAS.2014.7043319, DOI 10.1109/IPAS.2014.7043319]
   Bader S., 2016, INT J COMPUT SYST EN, V10, P1478
   Bader S, 2017, I C COMP SYST APPLIC, P1239, DOI 10.1109/AICCSA.2017.147
   Baig AF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175967
   Bailenson JN, 2004, PRESENCE-VIRTUAL AUG, V13, P428, DOI 10.1162/1054746041944803
   Bary E., 2020, Zoom, and Microsoft Teams usage are rocketing during coronavirus pandemic, new data show
   Basu T., 2021, MIT Technology Review
   Beacco A, 2020, IEEE IMAGE PROC, P2785, DOI 10.1109/ICIP40778.2020.9191091
   Bente Gary, 2014, HCI in Business. First International Conference, HCIB 2014. Held as Part of HCI International 2014. Proceedings: LNCS 8527, P461, DOI 10.1007/978-3-319-07293-7_45
   Beugnon S., 2022, MULTIMEDIA SECURITY, P219, DOI [10.1002/9781119901808.ch7, DOI 10.1002/9781119901808.CH7]
   Boukhris M., 2011, Proceedings of the 2011 16th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES 2011), P18, DOI 10.1109/CGAMES.2011.6000330
   Carruth AD, 2015, ETHICS INF TECHNOL, V17, P103, DOI 10.1007/s10676-015-9364-y
   Chae SW, 2016, INT J HUM-COMPUT INT, V32, P373, DOI 10.1080/10447318.2016.1150643
   Chan D, 2009, STATISTICAL AND METHODOLOGICAL MYTHS AND URBAN LEGENDS: DOCTRINE, VERITY AND FABLE IN THE ORGANIZATIONAL AND SOCIAL SCIENCES, P309
   Chen Y, 2014, J MANUF SYST, V33, P233, DOI 10.1016/j.jmsy.2013.11.005
   Cheng Yao Wang, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3476078
   Cole S.., 2020, This open-source program deepfakes you during zoom meetings, in real time
   Conrad M, 2017, COMPUT ENTERTAIN, V15, DOI 10.1145/3010078
   Deng XZ, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE & EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P337, DOI 10.1109/ITIME.2009.5236404
   Dilmegani C., 2022, AI MULT
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Falchuk B, 2018, IEEE TECHNOL SOC MAG, V37, P52, DOI 10.1109/MTS.2018.2826060
   Falk B, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2405, DOI 10.1145/3460120.3485345
   Feng A., 2014, P 7 INT C MOTION GAM, P49, DOI [10.1145/2668064.2668102, DOI 10.1145/2668064.2668102]
   Feng A, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1769
   Ferrari A., 2021, DIGITAL HUMANITY USE
   Ferrer X, 2021, IEEE TECHNOL SOC MAG, V40, P72, DOI 10.1109/MTS.2021.3056293
   Foerster K., 2021, INNOVATE LEARNING SU, P95
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Freeman G., 2020, 2020 CHI C HUM FACT, DOI 10.1145/3334480.3382923
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fysh MC, 2022, BEHAV RES METHODS, V54, P1461, DOI 10.3758/s13428-021-01676-5
   Gavrilova ML, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P179, DOI 10.1109/CW.2010.36
   Gorini A, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1029
   Graber MA, 2010, J MED INTERNET RES, V12, DOI 10.2196/jmir.1299
   Hale J, 2018, Q J EXP PSYCHOL, V71, P989, DOI 10.1080/17470218.2017.1307865
   Heath A., 2021, INSIDE FACEBOOK S ME
   Hu LW, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3130800.3130887, 10.1145/3130800.31310887]
   Huang Z, 2020, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR42600.2020.00316
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jensen J, 2011, LECT NOTES COMPUT SC, V6908, P1, DOI 10.1007/978-3-642-23300-5_1
   Jie Li, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382836
   John B, 2020, IEEE T VIS COMPUT GR, V26, P1880, DOI 10.1109/TVCG.2020.2973052
   Jones JM, 2021, IFIP ADV INF COMM TE, V613, P189, DOI 10.1007/978-3-030-81111-2_16
   Jonnalagadda A, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451259
   Kaleem K., 2022, META IS DEALING SEXU
   Kanamgotov A, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P93, DOI 10.1109/CW.2014.21
   Kelly K., 2016, The inevitable
   Kim Jinhwan, 2021, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V21, P1, DOI 10.7236/JIIBC.2021.21.4.1
   Lake J., 2020, EMORY LAW JOURNAL, V69, P48
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Lazova V, 2019, INT CONF 3D VISION, P643, DOI 10.1109/3DV.2019.00076
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Lee G, 2019, IEEE I CONF COMP VIS, P763, DOI 10.1109/ICCV.2019.00085
   Lemley MA, 2018, U PENN LAW REV, V166, P1051
   Liebers J., 2021, UNDERSTANDING USER I, P1, DOI DOI 10.1145/3411764.3445528
   Liu QX, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.668181
   Lohle MF, 2014, QUAL REP, V19
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lucas G., 2016, Proceedings of the 9th International Conference on Motion in Games, P167, DOI DOI 10.1145/2994258.2994263
   Malipatil M, 2020, 4 INT C I SMAC IOT S, P1, DOI DOI 10.1109/I-SMAC49090.2020.9243381
   Maloney D, 2021, Arxiv, DOI arXiv:2104.05030
   Marinussen M, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P285, DOI 10.1145/3325480.3325482
   McElroy R., 2021, DEEPFAKES CYBERATTAC
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Miller MR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74486-y
   Miller R, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P140, DOI 10.1109/VR50410.2021.00035
   Miller R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P311, DOI [10.1109/VRW50115.2020.00070, 10.1109/VRW50115.2020.0-206]
   Mohamed AA, 2012, 2012 17TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES (CGAMES), P143, DOI [10.1109/CGames.2012.6314566, 10.1109/GHTCE.2012.6490142]
   Mühle A, 2018, COMPUT SCI REV, V30, P80, DOI 10.1016/j.cosrev.2018.10.002
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   Neustaedter C., 2009, P GRAPH INT 2009, P183, DOI [10.5555/1555880.1555921, DOI 10.1900/RDS.2007.4.98]
   O'Brolcháin F, 2016, SCI ENG ETHICS, V22, P1, DOI 10.1007/s11948-014-9621-1
   Ometov A, 2018, CRYPTOGRAPHY-BASEL, V2, DOI 10.3390/cryptography2010001
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Pakanen M, 2022, ENTERTAIN COMPUT, V40, DOI 10.1016/j.entcom.2021.100457
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Pan Y, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00012
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Picchi A., 2018, A problem for Facebook users: Identity scams
   Preukschat A., 2021, Self-sovereign identity
   Ripka G., 2020, SITE INT C ASS ADV C, P549
   Roth Daniel, 2015, i-com: A Journal of Interactive and Cooperative Media, V14, P107, DOI 10.1515/icom-2015-0030
   Roth D., 2018, 2018 IEEE C VIRT REA, DOI [10.1109/VR.2018.8447550, DOI 10.1109/VR.2018.8447550]
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Roth D, 2017, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2017.7892275
   Ryu R, 2021, IEEE ACCESS, V9, P34541, DOI 10.1109/ACCESS.2021.3061589
   Sawers P., 2022, IDENTITY AUTHENTICAT
   Schell C., 2022, P IEEE INT C ART INT
   Schroepfer M., 2019, META
   Schuemie M. J., 2001, RES PRESENCE VIRTUAL
   Schultz A., 2020, Keeping our services stable and reliable during the COVID-19 outbreak
   Segovia KY, 2012, SOC INFLUENCE, V7, P285, DOI 10.1080/15534510.2012.670906
   Semple Mid, 2010, Journal of Educational Technology Systems, V39, P181, DOI 10.2190/ET.39.2.h
   Shao D, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12229345
   Siwicki B., 2021, HEALTHC IT NEWS
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Sreedhar N., 2020, MINTLOUNGE
   The European Data Protection Supervisor (EDPS), 2018, OP 4 2018 PROP 2 REG
   Triberti S, 2017, CYBERPSYCH BEH SOC N, V20, P501, DOI 10.1089/cyber.2016.0424
   Tummon HM, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520958033
   Tummon HM, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519863077
   Tweeddale A., 2021, CHEQD
   Vaidya Tavish., 2019, P 2019 CHI C HUMAN F, DOI DOI 10.1145/3290605.3300755
   Vanacker B, 2012, CONVERGENCE-US, V18, P71, DOI 10.1177/1354856511419916
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   W3C Community Group, 2020, PRIM DEC ID
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang MH, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012032
   Wenninger S., 2020, 26 ACM S VIRTUAL REA, P1, DOI [DOI 10.1145/3385956.3418940, 10.1145/3385956.3418940]
   Wong A, 2021, J INTENSIVE CARE SOC, V22, P255, DOI 10.1177/1751143720966280
   Yampolskiy RV, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P40, DOI 10.1109/ICMLA.2012.16
   Yoo I, 2021, DEEP 3D TO 2D WATERM
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
NR 126
TC 14
Z9 14
U1 8
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 17
PY 2022
VL 3
AR 974652
DI 10.3389/frvir.2022.974652
PG 25
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RY7
UT WOS:001023166700001
OA gold
DA 2024-07-18
ER

PT J
AU Ziat, M
   Jhunjhunwala, R
   Clepper, G
   Kivelson, PD
   Tan, HZ
AF Ziat, Mounia
   Jhunjhunwala, Rishi
   Clepper, Gina
   Kivelson, Pamela Davis
   Tan, Hong Z.
TI Walking on paintings: Assessment of passive haptic feedback to enhance
   the immersive experience
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE mid-air haptics; vibrations; passive haptic; virtual walking; paintings;
   visual art; virtual reality
ID CUTANEOUS AFFERENTS; VIRTUAL ENVIRONMENTS; HUMAN HAND; UNITS; GAIT
AB Virtual reality has been used in recent years for artistic expression and as a tool to engage visitors by creating immersive experiences. Most of these immersive installations incorporate visuals and sounds to enhance the user's interaction with the artistic pieces. Very few, however, involve physical or haptic interaction. This paper investigates virtual walking on paintings using passive haptics. More specifically we combined vibrations and ultrasound technology on the feet using four different configurations to evaluate users' immersion while they are virtually walking on paintings that transform into 3D landscapes. Results show that participants with higher immersive tendencies experienced the virtual walking by reporting illusory movement of their body regardless the haptic configuration used.
C1 [Ziat, Mounia; Jhunjhunwala, Rishi] Bentley Univ, Dept Informat Design & Corp Commun, Waltham, MA 02452 USA.
   [Clepper, Gina; Tan, Hong Z.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN USA.
   [Kivelson, Pamela Davis] Stanford Univ, Design Impact Program, Stanford, CA USA.
C3 Bentley University; Purdue University System; Purdue University;
   Stanford University
RP Ziat, M (corresponding author), Bentley Univ, Dept Informat Design & Corp Commun, Waltham, MA 02452 USA.
EM mziat@bentley.edu
RI Ziat, Mounia/JRX-8101-2023
OI Ziat, Mounia/0000-0003-4620-7886
FU National Science Foundation (NSF) [1925194]
FX This work is supported by the National Science Foundation under Grant
   NSF NRI #1925194.
CR Aimonetti JM, 2007, J PHYSIOL-LONDON, V580, P649, DOI 10.1113/jphysiol.2006.123075
   [Anonymous], 2009, P ACM INT C INT TABL, DOI [10.1145/1731903.1731922, DOI 10.1145/1731903.1731922]
   Applin Jo., 2012, Yayoi Kusama Infinity Mirror Room
   Asus xonar, 2022, XON U7 MKII 7 1 USB
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Carbon CC, 2013, P IEEE, V101, P2123, DOI 10.1109/JPROC.2012.2219831
   Vi CT, 2017, INT J HUM-COMPUT ST, V108, P1, DOI 10.1016/j.ijhcs.2017.06.004
   Chisholm B., 2018, INCREASING ART MUSEU
   Cho JD, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040470
   Davis Kivelson P., 2020, EMERGENCE
   de Grosbois J, 2020, IEEE HAPTICS SYM, P848, DOI 10.1109/HAPTICS45997.2020.ras.HAP20.9.699b3778
   De Luca A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5051, DOI 10.1109/IROS.2009.5354610
   Dim NK, 2017, INT J HUM-COMPUT ST, V97, P34, DOI 10.1016/j.ijhcs.2016.08.002
   Dima Mariza, 2014, Virtual, Augmented and Mixed Reality. Applications of Virtual and Augmented Reality. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8526, P3, DOI 10.1007/978-3-319-07464-1_1
   Fancher J., 2013, WORLDHAPTICS 2013 DE
   Frisoli A., 2005, WORLD HAPT C PIS MAR
   Galica AM, 2009, GAIT POSTURE, V30, P383, DOI 10.1016/j.gaitpost.2009.07.005
   Gao Y, 2018, 2018 FIRST ASIAN CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII ASIA)
   Giordano M., 2015, MULTISENSORY ART INS, P169
   Globalsources, 2022, JINL MACH EL CO LTD
   Hribar VE, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P221
   Insko B.E., 2001, Passive Haptics Significantly Enhances Virtual Environ- ments
   Jerome C. J., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2197
   JOHANSSON RS, 1979, J PHYSIOL-LONDON, V286, P283, DOI 10.1113/jphysiol.1979.sp012619
   JOHANSSON RS, 1982, BRAIN RES, V244, P17, DOI 10.1016/0006-8993(82)90899-X
   Jones Brennan, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P194, DOI 10.1145/3382507.3418820
   Kennedy PM, 2002, J PHYSIOL-LONDON, V538, P995, DOI 10.1113/jphysiol.2001.013087
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Lee L., 2022, WORLDS UNBOUND ART T
   Lim J, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P124, DOI 10.1145/3340555.3353728
   Lipsitz LA, 2015, ARCH PHYS MED REHAB, V96, P432, DOI 10.1016/j.apmr.2014.10.004
   Lovreglio R, 2018, ADV ENG INFORM, V38, P670, DOI 10.1016/j.aei.2018.08.018
   Matsuda Y, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.654088
   Matsumoto K., 2016, ACM SIGGRAPH 2016 EM, P1, DOI [10.1007/978-4-431-55933-7, DOI 10.1145/2929464.2929482]
   Meier Anita., 2015, P 2 INT WORKSHOP SEN, P11, DOI DOI 10.1145/2790044.2790051
   Mildren RL, 2016, J APPL PHYSIOL, V120, P855, DOI 10.1152/japplphysiol.00810.2015
   Nilsson Niels C., 2012, Haptic and Audio Interaction Design. Proceedings 7th International Conference, HAID 2012, P61, DOI 10.1007/978-3-642-32796-4_7
   Nordahl R, 2010, P IEEE VIRT REAL ANN, P147, DOI 10.1109/VR.2010.5444796
   Novacheck TF, 1998, GAIT POSTURE, V7, P77, DOI 10.1016/S0966-6362(97)00038-6
   Ortlieb SA, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520920309
   Pirker W, 2017, WIEN KLIN WOCHENSCHR, V129, P81, DOI 10.1007/s00508-016-1096-4
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Reed C. L., 2018, Reference Module in Neuroscience and Biobehavioral Psychology
   Reichinger A., 2011, ACM J COMPUT CULT HE, V4, P1, DOI [10.1145/2037820.2037822, DOI 10.1145/2037820.2037822]
   Richardson John., 2013, OXFORD HDB NEW AUDIO
   Riecke B. E., 2013, Human walking in virtual environments, P27, DOI 10.1007/978-1-4419-8432-6_2
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Son H, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P241, DOI [10.1109/whc.2019.8816165, 10.1109/WHC.2019.8816165]
   Son H, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186474
   Son H, 2018, IEEE ACCESS, V6, P76464, DOI 10.1109/ACCESS.2018.2883821
   Strzalkowski NDJ, 2017, J NEUROPHYSIOL, V118, P1931, DOI 10.1152/jn.00647.2016
   Strzalkowski NDJ, 2015, J NEUROPHYSIOL, V114, P2144, DOI 10.1152/jn.00524.2015
   Syntacts, 2022, SYNTACTS TACTOR SYNT
   Terziman L, 2013, IEEE T VIS COMPUT GR, V19, P652, DOI 10.1109/TVCG.2013.38
   Turchet L, 2013, APPL ACOUST, V75, P59, DOI 10.1016/j.apacoust.2013.06.016
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Ultraleap, 2022, ULTRALEAP
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Velázquez R, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/52653
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang TH, 2021, IEEE T HAPTICS, V14, P83, DOI 10.1109/TOH.2020.3017099
   Ziat M., 2022, HAPTICS HUMAN COMPUT
   Ziat M., 2014, ADJ P 27 ANN ACM S U, P65, DOI [DOI 10.1145/2658779.2659116, 10.1145/2658779.2659116]
   Ziat M, 2021, PERCEPTION, V50, P102
   Ziat M, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P351, DOI 10.1109/WHC.2015.7177737
   Ziat M, 2010, EXP BRAIN RES, V206, P299, DOI 10.1007/s00221-010-2407-z
   Zwolinski G, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030462
NR 70
TC 1
Z9 1
U1 7
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 7
PY 2022
VL 3
AR 997426
DI 10.3389/frvir.2022.997426
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VA1
UT WOS:001023246400001
OA gold
DA 2024-07-18
ER

PT J
AU McIntosh, V
AF McIntosh, Verity
TI Dialing up the danger: Virtual reality for the simulation of risk
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; risk; simulation; training; journalism; presence;
   ethics
AB There is a growing interest the use of virtual reality (VR) to simulate unsafe spaces, scenarios, and behaviours. Environments that might be difficult, costly, dangerous, or ethically contentious to achieve in real life can be created in virtual environments designed to give participants a convincing experience of "being there." There is little consensus in the academic community about the impact of simulating risky content in virtual reality, and a scarcity of evidence to support the various hypotheses which range from VR being a safe place to rehearse challenging scenarios to calls for such content creation to be halted for fear of irreversible harm to users. Perspectives split along disciplinary lines, with competing ideas emerging from cultural studies and games studies, from psychology and neuroscience, and with industry reports championing the efficacy of these tools for information retention, time efficiency and cost, with little equivalence in information available regarding impact on the wellbeing of participants. In this study we use thematic analysis and close reading language analysis to investigate the way in which participants in a VR training scenario respond to, encode and relay their own experiences. We find that participants overall demonstrate high levels of "perceptual proximity" to the experience, recounting it as something that happened to them directly and personally. We discuss the impact of particular affordances of VR, as well as a participant's prior experience on the impact of high-stress simulations. Finally, we consider the ethical mandate for training providers to mitigate the risk of traumatizing or re-traumatizing participants when creating high-risk virtual scenarios.
C1 [McIntosh, Verity] Univ West England, Bristol VR Lab, Bristol, England.
   [McIntosh, Verity] Univ West England, Digital Cultures Res Ctr, Bristol, England.
C3 University of West England; University of West England
RP McIntosh, V (corresponding author), Univ West England, Bristol VR Lab, Bristol, England.; McIntosh, V (corresponding author), Univ West England, Digital Cultures Res Ctr, Bristol, England.
EM verity.mcintosh@uwe.ac.uk
OI McIntosh, Verity/0000-0002-5529-2579
FU University of the West of England's faculty Research Funding Scheme
   2020-21; Bristol and Bath Creative R and D program is a part of The
   Creative Industries Clusters Programme [AH/S002936/1]; UUI
   [AH/S002936/1] Funding Source: UKRI
FX This project received support from the University of the West of
   England's faculty Research Funding Scheme 2020-21, and from the Bristol
   and Bath Creative R and D program which is a part of The Creative
   Industries Clusters Programme managed by the Arts and Humanities
   Research Council as part of the Industrial Strategy. Grant number for
   Bristol and Bath Creative R and D is AH/S002936/1.
CR Alhalabi WS, 2016, BEHAV INFORM TECHNOL, V35, P919, DOI 10.1080/0144929X.2016.1212931
   Allen C., 2017, VR PUBLISHERS MUST F
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bellos L., 2021, CO SHIFT VR EMPLOYEE
   Blackburn, 2015, DEV PSYCHOMETRIC PRO
   Bodyswaps, 2022, NAV MICR BOD
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bruner J., 1986, Actual minds, possible worlds
   Bye K., 2022, COMMUNICATION 0324
   Cadet L. B., 2020, INT J HUM-COMPUT ST, P144
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Chen J, 2007, COMMUN ACM, V50, P31, DOI 10.1145/1232743.1232769
   Chirico A, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02351
   Connect4Climate, 2017, CONNECT4CLIMATE 1102
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Cuervo E., 2018, Creating the perfect illusion: What will it take to create life-like virtual reality headsets?
   D-ID, 2022, D ID FAC PLATF GEN F
   Dalton J., 2021, Reality check: How immersive technologies can transform your business
   Diniz BernardoP., 2020, Journal of Technology in Behavioral Science, V6, P3, DOI [10.1007/s41347-020-00152-9, DOI 10.1007/S41347-020-00152-9]
   EASA, 2021, EASA approves the first Virtual Reality (VR) based Flight Simulation Training Device
   Epic Games, 2021, METAHUMAN CREAT UNR
   Farmer H., 2019, IMMERSE IMMERSE NEWS
   Gun Raiders Entertainment Inc, 2021, GUN RAID OC QUEST 2
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Kipping M., 2003, INT GUIDE MANAGEMENT, V2nd, P21
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Liao T., 2019, Virtual Reality; Children; Reality; Presence, V12, DOI DOI 10.4101/JVWR.V12I2.7361
   Madary M., 2016, REAL VIRTUALITY CODE
   Make Real, 2021, NHS AS TECHN VR MAK
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Massey B. L., 2018, FREELANCING JOURNALI
   Merleau-Ponty Maurice., 2005, PHENOMENOLOGY PERCEP
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Morgan G., 2019, OXFORD HDB GLOBAL PO
   Mursion, 2020, T MOB US VR SIM LEAD
   Nakamura L, 2020, J VIS CULT, V19, P47, DOI 10.1177/1470412920906259
   Nash K, 2018, STUD DOC FILM, V12, P119, DOI 10.1080/17503280.2017.1340796
   Nunez D., 2004, P 3 INT C COMPUTER G, V1, P83, DOI DOI 10.1145/1029949.1029964
   Ochs C., 2022, FRONT VIRTUAL REAL, P7
   Oculus, 2021, VR GOOD META QUEST
   PWC, 2020, Public Report 2020
   PwC, 2019, SEEING IS BELIEVING
   Ratan R., 2012, IGI GLOB, P321, DOI [10.4018/978-1-4666-2211-1.ch018, DOI 10.4018/978-1-4666-2211-1.CH018]
   Robinson A., 2016, AREA AUTODESK 1027
   Rose M, 2018, STUD DOC FILM, V12, P132, DOI 10.1080/17503280.2018.1496055
   Rossler KL, 2019, NURS EDUC, V44, P88, DOI 10.1097/NNE.0000000000000551
   Rubo M, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100111
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sinclair K., 2020, MAKING NEW REALITY T
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slaughter A., 2017, DART CTR JOURNALISM
   Thomas L. M., 2018, International Journal of Performance Arts and Digital Media, V14, P145, DOI [DOI 10.1080/14794713.2018.1499387, 10.1080/14794713.2018.1499387]
   Uricchio W., 2020, FINDING STORY USER E
   Warpfrog, 2021, BLADE SORCERY NOMAD
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Woodford S., 2021, PORNOGRAPHY PANDEMIC
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
NR 62
TC 1
Z9 1
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 11
PY 2022
VL 3
AR 909984
DI 10.3389/frvir.2022.909984
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WY7
UT WOS:001023297300001
OA gold
DA 2024-07-18
ER

PT J
AU Shell, AK
   Pena, AE
   Abbas, JJ
   Jung, RN
AF Shell, Aliyah K.
   Pena, Andres E.
   Abbas, James J.
   Jung, Ranu
TI Novel Neurostimulation-Based Haptic Feedback Platform for Grasp
   Interactions With Virtual Objects
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE non-invasive electrical stimulation; peripheral nerve stimulation;
   transcutaneous electrical stimulation; haptic feedback; neuromodulation;
   virtual interaction; neuro-haptics
ID MEDIAN NERVE; PROSTHESES
AB Haptic perception is a vital part of the human experience that enriches our engagement with the world, but the ability to provide haptic information in virtual reality (VR) environments is limited. Neurostimulation-based sensory feedback has the potential to enhance the immersive experience within VR environments by supplying relevant and intuitive haptic feedback related to interactions with virtual objects. Such feedback may contribute to an increase in the sense of presence and realism in VR and may contribute to the improvement of virtual reality simulations for future VR applications. This work developed and evaluated xTouch, a neuro-haptic platform that extends the sense of touch to virtual environments. xTouch is capable of tracking a user's grasp and manipulation interactions with virtual objects and delivering haptic feedback based on the resulting grasp forces. Seven study participants received haptic feedback delivered via multi-channel transcutaneous electrical stimulation of the median nerve at the wrist to receive the haptic feedback. xTouch delivered different percept intensity profiles designed to emulate grasp forces during manipulation of objects of different sizes and compliance. The results of a virtual object classification task showed that the participants were able to use the active haptic feedback to discriminate the size and compliance of six virtual objects with success rates significantly better than the chance of guessing it correctly (63.9 & PLUSMN; 11.5%, chance = 16.7%, p < 0.001). We demonstrate that the platform can reliably convey interpretable information about the physical characteristics of virtual objects without the use of hand-mounted devices that would restrict finger mobility. Thus, by offering an immersive virtual experience, xTouch may facilitate a greater sense of belonging in virtual worlds.
C1 [Pena, Andres E.] Univ Arkansas, Adapt Neural Syst Lab, Dept Biomed Engn, Fayetteville, AR 72701 USA.
   Univ Arkansas, Inst Integrat & Innovat Res, Fayetteville, AR USA.
C3 University of Arkansas System; University of Arkansas Fayetteville;
   University of Arkansas System; University of Arkansas Fayetteville
RP Pena, AE (corresponding author), Univ Arkansas, Adapt Neural Syst Lab, Dept Biomed Engn, Fayetteville, AR 72701 USA.
EM andresp@uark.edu
OI Pena, Andres/0000-0002-1473-0173
CR BANKS WP, 1981, PERCEPT PSYCHOPHYS, V29, P95, DOI 10.3758/BF03207272
   Boban L, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.860872
   Brooks DC, 2010, Physiother Can, V62, P1, DOI 10.3138/ptc.62.5
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   Colella N, 2019, IEEE ROBOT AUTOM LET, V4, P1572, DOI 10.1109/LRA.2019.2896484
   D'Anna E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11306-w
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Forst JC, 2015, J REHABIL RES DEV, V52, P397, DOI 10.1682/JRRD.2014.05.0128
   George JA, 2020, IEEE ENG MED BIO, P3893, DOI 10.1109/EMBC44109.2020.9176720
   Graczyk EL, 2016, SCI TRANSL MED, V8, DOI 10.1126/scitranslmed.aaf5187
   Hinchet R, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P901, DOI 10.1145/3242587.3242657
   Hoffman H. G., 1998, Virtual Reality, V3, P226, DOI 10.1007/BF01408703
   Hummel J, 2016, P IEEE VIRT REAL ANN, P39, DOI 10.1109/VR.2016.7504686
   Hvass J, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)
   Martínez-Payá JJ, 2015, J APPL BIOMECH, V31, P439, DOI 10.1123/jab.2015-0026
   Jones I, 2009, BJA EDUC, V9, P130, DOI 10.1093/bjaceaccp/mkp021
   Jung R., 2021, SYSTEMS METHODS HAPT, P199903
   Kourtesis P, 2022, Arxiv, DOI arXiv:2105.05343
   Lapicque L., 1909, SOC BIOL
   Li KR, 2017, IEEE SENS J, V17, P2625, DOI 10.1109/JSEN.2017.2674965
   Maereg AT, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00042
   Mogyoros I, 1996, BRAIN, V119, P439, DOI 10.1093/brain/119.2.439
   Mystakidis S., 2022, ENCYCLOPEDIA, V2, P486, DOI [10.3390/encyclopedia2010031, DOI 10.3390/ENCYCLOPEDIA2010031]
   NAKAMICHI K, 1992, J HAND SURG-BRIT EUR, V17B, P213, DOI 10.1016/0266-7681(92)90092-G
   Newman M, 2022, J ENVIRON PSYCHOL, V79, DOI 10.1016/j.jenvp.2021.101733
   OCHOA JL, 1980, BRAIN, V103, P835, DOI 10.1093/brain/103.4.835
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Pena AE, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abf28c
   Pena A. E., 2020, THESIS FLORIDA INT U
   Pezent E., 2019, IEEE World Haptics Conference WHC, P1, DOI DOI 10.1109/WHC.2019.8816098
   Preatoni G, 2021, I IEEE EMBS C NEUR E, P1105, DOI 10.1109/NER49283.2021.9441283
   Preusche C, 2007, VISUAL COMPUT, V23, P273, DOI 10.1007/s00371-007-0101-3
   Price S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.642782
   Saal HP, 2015, NEUROPSYCHOLOGIA, V79, P344, DOI 10.1016/j.neuropsychologia.2015.06.010
   Salomon R, 2016, SCI REP-UK, V6, DOI 10.1038/srep25847
   Shin H, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aabd5d
   Stephens-Fripp B, 2018, IEEE ACCESS, V6, P6878, DOI 10.1109/ACCESS.2018.2791583
   STEVENS SS, 1956, AM J PSYCHOL, V69, P1, DOI 10.2307/1418112
   Tan DW, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3008669
   Vargas L, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab4d99
   Vizcay Sebastian, 2021, ARXIV, DOI [10.2312/egve.20211331, DOI 10.2312/EGVE.20211331]
   Wang Dangxiao, 2019, Virtual Reality Intell. Hardware, V1, P136, DOI [DOI 10.3724/SP.J.2096-5796.2019.0008, 10.3724/sp.j.2096-5796.2019.0008]
   Weber AI, 2013, P NATL ACAD SCI USA, V110, P17107, DOI 10.1073/pnas.1305509110
   Weiss G., 1901, Archs ital Biol, V35, P413, DOI DOI 10.5935/1678-9741.20140015
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Witteveen HJB, 2014, IEEE T NEUR SYS REH, V22, P53, DOI 10.1109/TNSRE.2013.2267394
   Yang S.-R., 2012, ISCAS 2012, DOI [10.1109/ISCAS.2012.6271686, DOI 10.1109/ISCAS.2012.6271686]
   Yem V, 2017, P IEEE VIRT REAL ANN, P99, DOI 10.1109/VR.2017.7892236
NR 49
TC 3
Z9 3
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 3
PY 2022
VL 3
AR 910379
DI 10.3389/frvir.2022.910379
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VN6
UT WOS:001019160900001
OA gold
DA 2024-07-18
ER

PT J
AU Koger, CR
   Hassan, SS
   Yuan, J
   Ding, YC
AF Koger, Casey R.
   Hassan, Sohail S.
   Yuan, Jie
   Ding, Yichen
TI Virtual Reality for Interactive Medical Analysis
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; visualization; manipulation; interactive; exploration;
   analysis
AB Molecular imaging along with 3-dimensional (3-D) or 4-D (3-D spatial + 1-D temporal) visualization is widely used in clinical diagnosis and surgical planning. However, the pre-defined perspective and confined manipulation limit the in-depth exploration and analysis in 3-D/4-D. To overcome this obstacle, we utilized virtual reality (VR) to interact with CT images of the cardiopulmonary system in a 3-D immersive environment. We implemented manipulative functionalities into the VR environment that altered the cardiopulmonary models to interactively generate new data analysis perspectives. We successfully sliced a CT cardiac model showing in-depth surface visualizations of the ventricles and atria. Our customized framework enables enhanced data interpretation interactivity of CT images and establishes a user-directed manipulative VR platform derived from imaging results for remote medical practices including training, education, and investigation.
C1 [Koger, Casey R.; Hassan, Sohail S.; Yuan, Jie; Ding, Yichen] Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Dept Bioengn, Richardson, TX 75080 USA.
   [Ding, Yichen] UT Southwestern Med Ctr, Hamon Ctr Regenerat Sci & Med, Dallas, TX 75390 USA.
C3 University of Texas System; University of Texas Dallas; University of
   Texas System; University of Texas Southwestern Medical Center Dallas
RP Ding, YC (corresponding author), Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Dept Bioengn, Richardson, TX 75080 USA.; Ding, YC (corresponding author), UT Southwestern Med Ctr, Hamon Ctr Regenerat Sci & Med, Dallas, TX 75390 USA.
EM Yichen.Ding@utdallas.edu
FU NIH [R00 HL148493]; University of Texas at Dallas; National Heart Lung
   and Blood Institute [R00HL148493] Funding Source: NIH RePORTER
FX This work was supported by NIH R00 HL148493 (YD) and the University of
   Texas at Dallas.
CR Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Arivis, 2021, VISIONVR
   Bryson S, 1996, COMMUN ACM, V39, P62, DOI 10.1145/229459.229467
   Cutrale F, 2019, ANNU REV BIOMED DA S, V2, P223, DOI 10.1146/annurev-biodatasci-072018-021305
   Ding YC, 2021, IEEE T BIO-MED ENG, V68, P225, DOI 10.1109/TBME.2020.2991754
   Ding YC, 2017, JCI INSIGHT, V2, DOI 10.1172/jci.insight.97180
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Hale KellyS., 2015, Handbook of virtual environments
   Hussein M., 2015, The benefits of virtual reality in education-A Comparison Study
   immSci, 2021, EXMICROVR IMM SCI
   Kalarat K, 2019, INT J TECHNOL, V10, P1307, DOI 10.14716/ijtech.v10i7.3259
   Krapichler C, 1998, COMPUT METH PROG BIO, V56, P65, DOI 10.1016/S0169-2607(98)00007-8
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Maher MM, 2004, KOREAN J RADIOL, V5, P55, DOI 10.3348/kjr.2004.5.1.55
   Nocerino E, 2016, INT ARCH PHOTOGRAMM, V41, P887, DOI 10.5194/isprsarchives-XLI-B5-887-2016
   Pidhorskyi S., 2018, PREPRINT, DOI DOI 10.48550/ARXIV.1804.08197
   Pixmeo, 2021, OSIRIX DICOM IM LIB
   Rizzi Silvio H., 2007, Proceedings of the 3rd Annual IEEE Conference on Automation Science and Engineering, P152
   Silva JNA, 2018, JACC-BASIC TRANSL SC, V3, P420, DOI 10.1016/j.jacbts.2017.11.009
   Slicer Community, 2020, SEGM ED 3 D SLIC
   Spark A, 2020, NAT METHODS, V17, P1097, DOI 10.1038/s41592-020-0962-1
   Sutherland J, 2019, J DIGIT IMAGING, V32, P38, DOI 10.1007/s10278-018-0122-7
   The Vision and Image Analysis Group, 2003, ELCAP PUBL LUNG IM D
   Uccheddu F, 2018, INT J INTERACT DES M, V12, P597, DOI 10.1007/s12008-017-0415-y
   Weissleder R, 2001, NAT BIOTECHNOL, V19, P316, DOI 10.1038/86684
   Weissleder R, 2008, NATURE, V452, P580, DOI 10.1038/nature06917
   Wu M, 2018, CONTRAST MEDIA MOL I, DOI 10.1155/2018/1382183
NR 28
TC 5
Z9 5
U1 4
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 14
PY 2022
VL 3
AR 782854
DI 10.3389/frvir.2022.782854
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2UD4
UT WOS:001021851700001
PM 36711187
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Margrett, JA
   Ouverson, KM
   Gilbert, SB
   Phillips, LA
   Charness, N
AF Margrett, Jennifer A. A.
   Ouverson, Kaitlyn M. M.
   Gilbert, Stephen B. B.
   Phillips, L. Alison
   Charness, Neil
TI Older Adults' Use of Extended Reality: A Systematic Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE extended reality; older adults; technology use; quality of life;
   systematic review
ID VIRTUAL-REALITY; GAMING SYSTEM; TECHNOLOGY; DESIGN; FEASIBILITY;
   DEMENTIA; STRENGTH; BALANCE; HEALTH
AB Research has pointed to the potential of extended reality (XR), including virtual, mixed, and augmented reality, for broadly impactful benefits, including learning, physical activity and health, and psychosocial aspects such as increased empathy and reduced loneliness. More research is needed to evaluate the outcomes of XR in new populations of users, including older adults. The purpose of this systematic review is to summarize the extant literature that centers on older adult use of XR in order to identify key themes, as well as identified benefits and barriers to XR use. In total, 17 studies from 2015 to 2019 met the inclusion criteria, namely that the study collected data from a sample of adults at least 60 years of age interacting with a 3D virtual environment. Through qualitative analysis of the corpus, six thematic areas were identified: Socialization, Physical Rehabilitation, Driving Simulation, Cognitive Training, Reminiscence, and Assessment. Furthermore, the unique contexts and outcomes of XR use, preferences for XR use, and reported occurrences of cybersickness in older adults are highlighted. Research after 2019 is also noted. This review is intended to guide future research supporting deployment of XR with older adults, emphasizing the psychosocial impacts of the technology.Systematic Review Registration: (website), identifier (registration number)
C1 [Margrett, Jennifer A. A.] Iowa State Univ, Dept Human Dev & Family Studies, Gerontol Program, Ames, IA 50011 USA.
   [Ouverson, Kaitlyn M. M.] Iowa State Univ, Virtual Real Applicat Ctr, Human Comp Interact, Ames, IA USA.
   [Gilbert, Stephen B. B.] Iowa State Univ, Virtual Real Applicat Ctr, Dept Ind & Mfg Syst Engn, Gerontol Program,Human Comp Interact, Ames, IA USA.
   [Phillips, L. Alison] Iowa State Univ, Dept Psychol, Gerontol Program, Ames, IA USA.
   [Charness, Neil] Florida State Univ, Inst Successful Longev, Dept Psychol, Tallahassee, FL USA.
C3 Iowa State University; Iowa State University; Iowa State University;
   Iowa State University; State University System of Florida; Florida State
   University
RP Margrett, JA (corresponding author), Iowa State Univ, Dept Human Dev & Family Studies, Gerontol Program, Ames, IA 50011 USA.
EM margrett@iastate.edu
RI Gilbert, Stephen/F-3138-2018
OI Gilbert, Stephen/0000-0002-5332-029X
FU Iowa State University Nanovaccine Institute [2901738]; National
   Institute of Food and Agriculture [IOW04116]
FX Funding Funding for this project was provided by Iowa State University
   Nanovaccine Institute (award # 2901738) and support for JM was provided
   by the National Institute of Food and Agriculture (project # IOW04116).
CR Almajid R., 2019, DISSERT ABSTR
   Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Baker Steven, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359251
   Barbot B, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106431
   Benoit M, 2015, NEUROPSYCH DIS TREAT, V11, P557, DOI 10.2147/NDT.S73179
   Bertrand P, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00026
   Bier B, 2018, NEUROPSYCHOLOGY, V32, P597, DOI 10.1037/neu0000417
   Blackwell Lindsay, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359202
   Brown JA, 2019, GERONTOL GERIATR MED, V5, DOI 10.1177/2333721419885287
   Bruun-Pedersen JR, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P216, DOI 10.1109/ICHI.2016.31
   Campo-Prieto P, 2021, VIRTUAL REAL-LONDON, V25, P801, DOI 10.1007/s10055-020-00495-x
   Chang CJ, 2016, BIOMED ENG-APP BAS C, V28, DOI 10.4015/S1016237216500204
   Craig M, 2016, NEUROBIOL AGING, V48, P143, DOI 10.1016/j.neurobiolaging.2016.08.007
   Czaja Sara J., 2019, Designing for older adults: Principles and creative human factors approaches, VThird, DOI DOI 10.1201/B22189
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dermody G, 2020, J MED INTERNET RES, V22, DOI 10.2196/17331
   DIENER E, 1985, J PERS ASSESS, V49, P71, DOI 10.1207/s15327752jpa4901_13
   Diener E, 2009, SOC INDIC RES SER, V39, P247, DOI 10.1007/978-90-481-2354-4_12
   Geraets CNW, 2020, SCHIZOPHR RES, V222, P227, DOI 10.1016/j.schres.2020.05.047
   Gugenheimer J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299028
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Gunkel S, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P233, DOI 10.1145/3210825.3213566
   Hayhurst J, 2018, PROGR IS, P295, DOI 10.1007/978-3-319-64027-3_20
   Higgins J, 2021, Cochrane Handbook for Systematic Reviews of Interventions version 6.3
   Hoffmann F, 2021, J CLIN EPIDEMIOL, V138, P1, DOI 10.1016/j.jclinepi.2021.05.022
   Howes SC, 2019, J ENABLING TECHNOL, V13, P101, DOI 10.1108/JET-12-2018-0057
   Hutchison Andrew., 2007, Proceedings of the 2nd International Conference on Digital Interactive Media in Entertainment and Arts (DIMEA'07), P98, DOI [DOI 10.1145/1306813, 10.1145/1306813.1306838, DOI 10.1145/1306813.1306838]
   Corregidor-Sánchez AI, 2021, AGE AGEING, V50, P370, DOI 10.1093/ageing/afaa197
   Johnson-Glenberg MC, 2014, J EDUC PSYCHOL, V106, P86, DOI 10.1037/a0034008
   Kang M., 2019, J EXT, V47(5), p1, DOI [10.3389/fnagi.2021.586999, DOI 10.3389/FNAGI.2021.586999]
   Kim A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0225-2
   Kong Saoane Thach, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P303, DOI 10.1145/3441000.3441003
   Kraus M., 2015, Proceedings of the 2015 Virtual Reality International Conference on ZZZ - VRIC'15, 08-10-Apri, P1, DOI [DOI 10.1145/2806173.2806198, 10.1145/2806173, DOI 10.1145/2806173]
   Kujawski C., 2018, CONTROLLER DEVICE PA
   Lawton G, 2006, COMPUTER, V39, P12, DOI 10.1109/MC.2006.204
   Lee M, 2016, EUR J INTEGR MED, V8, P738, DOI 10.1016/j.eujim.2016.08.166
   Lee M, 2015, ARCH GERONTOL GERIAT, V61, P154, DOI 10.1016/j.archger.2015.06.010
   Lee Y, 2017, J AGING PHYS ACTIV, V25, P621, DOI 10.1123/japa.2015-0271
   Lin CX, 2018, LECT NOTES COMPUT SC, V10927, P89, DOI 10.1007/978-3-319-92037-5_8
   Manera V, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151487
   Martin P., 2018, AGING EXPLORING COMP, P525
   McGill M., 2016, SUPPORTING COLLOCATE
   Micarelli A, 2019, ARCH GERONTOL GERIAT, V83, P246, DOI 10.1016/j.archger.2019.05.008
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Moher D, 2009, PHYS THER, V89, P873, DOI 10.1093/ptj/89.9.873
   Molina KI, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-156
   Molka-Danielsen J, 2018, PR IEEE INT CONF TEA, P408, DOI 10.1109/TALE.2018.8615147
   Montague DPF, 2002, CHILD DEV, V73, P1339, DOI 10.1111/1467-8624.00475
   Montana JI, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020500
   Mostajeran F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376565
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Niki K, 2019, J PALLIAT MED, V22, P702, DOI 10.1089/jpm.2018.0527
   Nishchyk A, 2021, JMIR AGING, V4, DOI 10.2196/27972
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Ramkhalawansingh R, 2018, PSYCHOL AGING, V33, P798, DOI 10.1037/pag0000271
   Roberts AR, 2019, CLIN GERONTOLOGIST, V42, P27, DOI 10.1080/07317115.2018.1442380
   Robine JM, 2019, J GERONTOL A-BIOL, V74, pS13, DOI 10.1093/gerona/glz198
   Rogers EM, 2003, DIFFUSION INNOVATION
   Skurla MD, 2022, INT PSYCHOGERIATR, V34, P143, DOI 10.1017/S104161022100017X
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stone W. B., 2017, PSYCHOMETRIC EVALUAT
   Syed-Abdul S, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1218-8
   WalkinVR, 2020, WALKINVR DRIV 2MW EL
   Waycott J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P411, DOI 10.1145/3197391.3197401
   World Health Organization, 2018, Ageing and health
   Yang KT, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P499, DOI 10.1145/3242587.3242630
   Yirou Li, 2020, HCI in Games. Second International Conference, HCI-Games 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12211), P128, DOI 10.1007/978-3-030-50164-8_9
   Zhu SZ, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.586999
NR 70
TC 8
Z9 8
U1 8
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 26
PY 2022
VL 2
AR 760064
DI 10.3389/frvir.2021.760064
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AP4
UT WOS:001019294200001
OA gold
DA 2024-07-18
ER

PT J
AU Maruhn, P
AF Maruhn, Philipp
TI VR Pedestrian Simulator Studies at Home: Comparing Google Cardboards to
   Simulators in the Lab and Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; google cardboard; pedestrian simulator; road crossing;
   behavioral validity; pedestrians; bayesian statistics
ID VIRTUAL-REALITY; DRIVING SIMULATOR; VALIDATION; ROAD
AB Virtual Reality is commonly applied as a tool for analyzing pedestrian behavior in a safe and controllable environment. Most such studies use high-end hardware such as Cave Automatic Virtual Environments (CAVEs), although, more recently, consumer-grade head-mounted displays have also been used to present these virtual environments. The aim of this study is first of all to evaluate the suitability of a Google Cardboard as low-cost alternative, and then to test subjects in their home environment. Testing in a remote setting would ultimately allow more diverse subject samples to be recruited, while also facilitating experiments in different regions, for example, investigations of cultural differences. A total of 60 subjects (30 female and 30 male) were provided with a Google Cardboard. Half of the sample performed the experiment in a laboratory at the university, the other half at home without an experimenter present. The participants were instructed to install a mobile application to their smartphones, which guided them through the experiment, contained all the necessary questionnaires, and presented the virtual environment in conjunction with the Cardboard. In the virtual environment, the participants stood at the edge of a straight road, on which two vehicles approached with gaps of 1-5 s and at speeds of either 30 or 50 km/h. Participants were asked to press a button to indicate whether they considered the gap large enough to be able to cross safely. Gap acceptance and the time between the first vehicle passing and the button being pressed were recorded and compared with data taken from other simulators and from a real-world setting on a test track. A Bayesian approach was used to analyze the data. Overall, the results were similar to those obtained with the other simulators. The differences between the two Cardboard test conditions were marginal, but equivalence could not be demonstrated with the evaluation method used. It is worth mentioning, however, that in the home setting with no experimenter present, significantly more data points had to be treated or excluded from the analysis.
C1 [Maruhn, Philipp] Tech Univ Munich, Chair Ergon, Sch Engn & Design, Dept Mech Engn, Munich, Germany.
C3 Technical University of Munich
RP Maruhn, P (corresponding author), Tech Univ Munich, Chair Ergon, Sch Engn & Design, Dept Mech Engn, Munich, Germany.
EM philipp.maruhn@tum.de
OI Maruhn, Philipp/0000-0003-0525-6665
CR [Anonymous], 2016, 2016 IEEE Aerospace Conference, DOI 10.1109/AER0.2016.7500674
   Br├a┬╝hlmann F., 2020, METHODS PSYCHOL, V2, P100022, DOI DOI 10.1016/J.METIP.2020.100022
   Capretto T., 2020, BAMBI SIMPLE INTERFA
   Cavallo V, 2019, TRANSPORT RES F-TRAF, V61, P217, DOI 10.1016/j.trf.2017.04.012
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cumming G, 2001, EDUC PSYCHOL MEAS, V61, P532, DOI 10.1177/0013164401614002
   Deb S, 2017, APPL ERGON, V65, P449, DOI 10.1016/j.apergo.2017.03.007
   Feldstein IT, 2020, PERCEPTION, V49, P558, DOI 10.1177/0301006620914789
   Feldstein IT, 2020, ACCIDENT ANAL PREV, V137, DOI 10.1016/j.aap.2019.105356
   Feldstein IT, 2019, PERCEPTION, V48, P769, DOI 10.1177/0301006619861892
   Hibbard PB, 2020, INT CONF 3D IMAG, DOI 10.1109/IC3D51119.2020.9376369
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Josman N, 2008, INT J DISABIL HUM DE, V7, P49
   Kaleefathullah AA, 2022, HUM FACTORS, V64, P1070, DOI 10.1177/0018720820970751
   Kaptein N., 1995, TRANSPORT RES REC, V1550, P30, DOI [DOI 10.1177/0361198196155000105, 10.1177/0361198196155000105]
   Knapper A, 2015, EUR J TRANSP INFRAST, V15, P205
   Korber M., 2016, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V60, P2009
   Kruschke J. K., 2015, DOING BAYESIAN DATA, VSecond EditionSecond edition edn, P297, DOI [10.1016/B978-0-12-405888-0.00011-8, DOI 10.1016/B978-0-12-405888-0.00011-8]
   Kruschke J. K., 2015, Doing Bayesian data analysis, V2nd, P721, DOI [10.1016/B978-0-12-405888-0.00025-8, DOI 10.1016/B978-0-12-405888-0.00025-8]
   Kruschke JK, 2018, ADV METH PRACT PSYCH, V1, P270, DOI 10.1177/2515245918771304
   Kruschke JK, 2012, ORGAN RES METHODS, V15, P722, DOI 10.1177/1094428112457829
   Kumar R., 2019, J. Open Source Software, V4, P1143, DOI DOI 10.21105/JOSS.01143
   Lelkes Y, 2012, J EXP SOC PSYCHOL, V48, P1291, DOI 10.1016/j.jesp.2012.07.002
   Linowes J., 2016, CARDBOARD VR PROJECT
   Makowski D., 2019, J OPEN SOURCE SOFTW, V4, P1541, DOI DOI 10.21105/JOSS.01541
   Mallaro S, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139171
   Maruhn P., 2022, P 21 C INT ERG ASS I, DOI [10.1007/978-3-030-74614-8_26, DOI 10.1007/978-3-030-74614-8_26]
   Maruhn P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P313, DOI [10.1109/VR46266.2020.1581242905378, 10.1109/VR46266.2020.00-53]
   McComas J, 2002, CYBERPSYCHOL BEHAV, V5, P185, DOI 10.1089/109493102760147150
   McElreath R, 2016, TEXT STAT SCI, pXI
   Meade AW, 2012, PSYCHOL METHODS, V17, P437, DOI 10.1037/a0028085
   Oswald D., 2014, REV SOCIAL STUDIES, V1, P53, DOI DOI 10.21586/ROSS0000004
   Peli E., 1999, Visual Instrumentation: Optical Design and Engineering Principles, P205, DOI DOI 10.1117/1.1839231
   Prattico FG, 2021, IEEE T VEH TECHNOL, V70, P1157, DOI 10.1109/TVT.2021.3054312
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Salvatier J, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.55
   Schneider S, 2022, HUM FACTORS, V64, P1210, DOI 10.1177/0018720820987446
   Schneider S, 2020, TRANSPORT RES F-TRAF, V68, P231, DOI 10.1016/j.trf.2019.11.005
   Schwebel DC, 2008, ACCIDENT ANAL PREV, V40, P1394, DOI 10.1016/j.aap.2008.03.005
   Schwebel DC, 2017, INJURY PREV, V23, P357, DOI 10.1136/injuryprev-2016-042168
   Schwebel DC, 2017, VIRTUAL REAL-LONDON, V21, P145, DOI 10.1007/s10055-016-0304-x
   Simpson G, 2003, ACCIDENT ANAL PREV, V35, P787, DOI 10.1016/S0001-4575(02)00081-7
   Sobhani A., 2017, 2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC), P1
   Vehtari A., 2021, BAYESIAN ANAL, V16, P667, DOI DOI 10.1214/20-BA1221
   Vehtari A, 2017, STAT COMPUT, V27, P1413, DOI 10.1007/s11222-016-9696-4
   Woldegiorgis BH, 2019, ERGONOMICS, V62, P76, DOI 10.1080/00140139.2018.1526328
   Wynne RA, 2019, SAFETY SCI, V117, P138, DOI 10.1016/j.ssci.2019.04.004
NR 47
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 20
PY 2021
VL 2
AR 746971
DI 10.3389/frvir.2021.746971
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YK4
UT WOS:001019236700001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Griffin, R
   Langlotz, T
   Zollmann, S
AF Griffin, Ruairi
   Langlotz, Tobias
   Zollmann, Stefanie
TI 6DIVE: 6 Degrees-of-Freedom Immersive Video Editor
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE VR; VR video; video editing; 6DOF; VR headset
AB Editing 6DoF videos using standard video editing tools is challenging, especially for non-expert users. There is a large gap between the 2D interface used for traditional video editing and the immersive VR environment used for replay. In this paper, we present 6DIVE, a 6 degrees-of-freedom (DoF) immersive video editor. 6DIVE allows users to edit these 6DoF videos directly in an immersive VR environment. In this work, we explored options for a timeline representation as well as UI placement suitable for immersive video editing. We used our prototypical implementation of an immersive video editor to conduct a user study to analyze the feasibility and usability of immersive 6DoF editing. We compared 6DIVE to a desktop-based implementation of a VR video editor. Our initial results suggest that 6DIVE allows even non-expert users to perform basic editing operations on videos in VR. While we did not find any statistically significant differences for the workload between the VR and the desktop interface, we found a statistically significant difference in user preference, with a preference for the VR interface. We also found higher ratings for the user experience metrics in VR captured by the user experience questionnaire.
C1 [Griffin, Ruairi; Zollmann, Stefanie] Univ Otago, Dept Comp Sci, Dunedin, New Zealand.
   [Langlotz, Tobias] Univ Otago, Dept Informat Sci, Dunedin, New Zealand.
C3 University of Otago; University of Otago
RP Zollmann, S (corresponding author), Univ Otago, Dept Comp Sci, Dunedin, New Zealand.
EM stefanie.zollmann@otago.ac.nz
OI Zollmann, Stefanie/0000-0002-4690-5409
FU New Zealand Marsden Council [UOO1724]
FX Funding We gratefully acknowledge the support of the New Zealand Marsden
   Council through Grant UOO1724.
CR Anderson R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980257
   Attal Benjamin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P441, DOI 10.1007/978-3-030-58452-8_26
   Baker L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P782, DOI [10.1109/VR46266.2020.1581313146787, 10.1109/VR46266.2020.000-2]
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Broxton M., 2020, ACM SIGGRAPH 2020 Immersive Pavilion, P1
   Nguyen C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5428, DOI 10.1145/3025453.3025675
   Elmezeny Ahmed, 2018, J. Virt. Worlds Res., V11, P1, DOI DOI 10.4101/JVWR.V11I1.7298
   Fleisher O., 2020, 3 SIXDOF
   Gladstone J., 2019, PSEUDOSCIENCE STEREO
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Langlotz T., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P318, DOI DOI 10.1145/2414536.2414588
   Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379
   Nebeling M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P333, DOI 10.1109/ISMAR-Adjunct.2018.00098
   Nguyen C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173638
   Pavel A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P289, DOI 10.1145/3126594.3126636
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Regenbrecht Holger, 2019, Frontiers in ICT, V6, P7, DOI DOI 10.3389/FICT.2019.00007
   Rematas K, 2018, PROC CVPR IEEE, P4738, DOI 10.1109/CVPR.2018.00498
   Reyna J, 2018, INTED PROC, P1448
   Richardt C, 2013, PROC CVPR IEEE, P1256, DOI 10.1109/CVPR.2013.166
   Richardt Christian, 2020, OMNIDIRECTIONAL STER, P1, DOI [10.1007/978-3-030-03243-2_808-1, DOI 10.1007/978-3-030-03243-2_808-1]
   Richardt Christian, 2019, ACM SIGGRAPH 2019 CO, P1, DOI [10.1145/3305366.3328028, DOI 10.1145/3305366.3328028]
   Schrepp M., 2014, Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience, P383, DOI [DOI 10.1007/978-3-319-07668-3_37, 10.9781/ijimai.2017.445, DOI 10.9781/IJIMAI.2017.445, DOI 10.1007/978-3-319-07668-337]
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Schroers C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3225150
   Schwarz S, 2018, PICT COD SYMP, P61, DOI 10.1109/PCS.2018.8456265
   Serrano A, 2019, IEEE T VIS COMPUT GR, V25, P1817, DOI 10.1109/TVCG.2019.2898757
   Sheikh A., 2016, Directing attention in 360-degree video [Paper presentation]. IBC 2016 Conference, DOI [10.1049/ibc.2016.0029, DOI 10.1049/IBC.2016.0029]
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tan J, 2018, IEEE MULTIMEDIA, V25, P87, DOI 10.1109/MMUL.2018.011921238
   Vert Silviu, 2019, ITM Web of Conferences, V29, DOI 10.1051/itmconf/20192903008
   Zollmann Stefanie, 2020, VRST '20: 26th ACM Symposium on Virtual Reality Software and Technology, DOI 10.1145/3385956.3422119
NR 35
TC 7
Z9 7
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 14
PY 2021
VL 2
AR 676895
DI 10.3389/frvir.2021.676895
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AP9
UT WOS:001019294700001
OA gold
DA 2024-07-18
ER

PT J
AU Franzluebbers, A
   Platt, S
   Johnsen, K
AF Franzluebbers, Anton
   Platt, Simon
   Johnsen, Kyle
TI Comparison of Command-Based vs. Reality-Based Interaction in a
   Veterinary Medicine Training Application
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; simulation; training; reality-based interface;
   neurological examination
ID SIMULATION; EDUCATION; FIDELITY
AB This paper presents a study evaluating alternative interaction styles for a novel virtual reality simulator proposed for veterinary neurology training. We compared a reality-based interaction metaphor, which is commonly used in virtual reality applications, to a command-based metaphor that reduced interactivity toward improving overall application usability. A cohort of 55 veterinary medicine students took part in the study, which took place at the veterinary school building. The study used a crossover design that allowed each participant to try both systems. Results suggested some correctable usability issues with the reality-based system, particularly the inclusion of haptic feedback for certain parts of the examination. A strong overall preference for the reality-based system was also observed. The study highlighted the potential of using both systems in tandem, with the command-based system being used prior to the reality-based system.
C1 [Franzluebbers, Anton; Johnsen, Kyle] Univ Georgia, Coll Engn, Dept Elect & Comp Engn, Virtual Experiences Lab, Athens, GA 30602 USA.
   [Platt, Simon] Univ Georgia, Coll Vet Med, Dept Small Anim Med & Surg, Athens, GA USA.
C3 University System of Georgia; University of Georgia; University System
   of Georgia; University of Georgia
RP Franzluebbers, A (corresponding author), Univ Georgia, Coll Engn, Dept Elect & Comp Engn, Virtual Experiences Lab, Athens, GA 30602 USA.
EM anton@uga.edu
FU University of Georgia; DVM Scholarship of Teaching and Learning Grant
   Award, University of Georgia
FX This work was supported by development of a virtual reality canine model
   to teach the neurological examination, Learning Technologies Grant
   Award, Funded July 2017, University of Georgia and assessment of virtual
   reality neurological examination model for veterinary student training,
   DVM Scholarship of Teaching and Learning Grant Award, University of
   Georgia.
CR Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Bogert K, 2016, J VET MED EDUC, V43, P26, DOI 10.3138/jvme.0215-027R1
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Dede C, 1996, P IEEE VIRT REAL ANN, P246, DOI 10.1109/VRAIS.1996.490534
   Ermak DM, 2013, J AM OSTEOPATH ASSOC, V113, P628, DOI 10.7556/jaoa.2013.024
   Issenberg SB, 2008, PERSPECT BIOL MED, V51, P31, DOI 10.1353/pbm.2008.0004
   Jacob R.J., 2007, CHI'07 extended abstracts on Human factors in computing systems, P2465
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Kaufmann H., 2000, Education and Information Technologies, V5, P263, DOI 10.1023/A:1012049406877
   McBride S., 2017, J ED TRAIN, V4, P97, DOI [10.5296/jet.v4i2.11753, DOI 10.5296/JET.V4I2.11753]
   Motola I, 2013, MED TEACH, V35, pE1511, DOI 10.3109/0142159X.2013.818632
   Norman G, 2012, MED EDUC, V46, P636, DOI 10.1111/j.1365-2923.2012.04243.x
   Ray A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P187
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Scerbo Mark W, 2007, Simul Healthc, V2, P224, DOI 10.1097/SIH.0b013e31815c25f1
   Schoenherr JR, 2017, SIMUL HEALTHC, V12, P117, DOI 10.1097/SIH.0000000000000226
   Stuerzlinger Wolfgang, 2006, UIST 06 ACM S US INT, P309, DOI [10.1145/1166253.1166301, DOI 10.1145/1166253.1166301]
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Vembar D., 2005, P HCI INT, P22
   Vinayagamoorthy V., 2005, P SOC MECH ANDR SCI, P119
   Vora J, 2002, APPL ERGON, V33, P559, DOI 10.1016/S0003-6870(02)00039-X
   Whitelock D., 1996, P EUR C ART INT ED
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
NR 23
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 11
PY 2020
VL 1
AR 608853
DI 10.3389/frvir.2020.608853
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L9FP0
UT WOS:001026252000001
OA gold
DA 2024-07-18
ER

PT J
AU Lewis, MM
   Waltz, C
   Scelina, K
   Scelina, L
   Owen, K
   Hastilow, K
   Koop, MM
   Rosenfeldt, AB
   Alberts, JL
AF Lewis, Morgan McGrath
   Waltz, Colin
   Scelina, Kathryn
   Scelina, Logan
   Owen, Kelsey
   Hastilow, Karissa
   Miller Koop, Mandy
   Rosenfeldt, Anson B.
   Alberts, Jay L.
TI Older adults exhibit declines in instrumental activities of daily living
   during a virtual grocery shopping task
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; digital health; technology; aging; instrumental
   activities of daily living (IADL); omnidirectional treadmill
ID EXECUTIVE FUNCTION; ALZHEIMERS-DISEASE; PROCESSING-SPEED; TRAJECTORIES;
   VALIDATION; USABILITY; DEFICITS; MEMORY; LIFE; TOOL
AB Introduction: The successful performance of instrumental activities of daily living (IADLs) is critical in maintaining independence for older adults. Traditional IADL questionnaires and performance-based assessments are time consuming, potentially unreliable, and fail to adequately consider the interplay between cognitive and motor performance in completing IADLs. The Cleveland Clinic Virtual Reality Shopping (CC-VRS) platform was developed to objectively quantify IADL performance through the characterization of cognitive, motor, and cognitive-motor function. The CC-VRS combines an immersive virtual grocery store with an omnidirectional treadmill to create a scenario in which the user physically navigates through a virtual environment. The primary aim of this project was to determine the known-group validity of the CC-VRS platform to characterize IADL performance in healthy older adults and young adults.Methods: Twenty healthy young (n = 10) and older (n = 10) adults completed the Basic and Complex CC-VRS scenarios. Position data from VR trackers on the hands, waist, and feet were used to quantify motor performance. Cognitive and dual-task performance were automatically calculated by the application during specific shopping sub-tasks.Results: Older adults exhibited significantly worse performance on multiple cognitive, motor, and dual-task outcomes of the CC-VRS (e. g., average walking speed, number of list activations, and stopping frequency).Discussion: The CC-VRS successfully discriminated IADL performance between young and healthy older adults. The complex realistic environment of the CC-VRS, combined with simultaneous evaluation of motor and cognitive performance, has the potential to more accurately characterize IADL performance by identifying subtle functional deficits that may precede neurological disease.
C1 [Lewis, Morgan McGrath; Waltz, Colin; Scelina, Kathryn; Scelina, Logan; Owen, Kelsey; Hastilow, Karissa; Miller Koop, Mandy; Rosenfeldt, Anson B.; Alberts, Jay L.] Cleveland Clin, Biomed Engn, Lerner Res Inst, Cleveland, OH 44195 USA.
   [Lewis, Morgan McGrath] Case Western Reserve Univ, Sch Med, Cleveland, OH USA.
   [Alberts, Jay L.] Cleveland Clin, Neurol Inst, Ctr Neurol Restorat, Cleveland, OH 44195 USA.
C3 Cleveland Clinic Foundation; University System of Ohio; Case Western
   Reserve University; Cleveland Clinic Foundation
RP Alberts, JL (corresponding author), Cleveland Clin, Biomed Engn, Lerner Res Inst, Cleveland, OH 44195 USA.; Alberts, JL (corresponding author), Cleveland Clin, Neurol Inst, Ctr Neurol Restorat, Cleveland, OH 44195 USA.
EM albertj@ccf.org
FU Michael J. Fox Foundation for Parkinson's Research [MJFF-020020]; Edward
   and Barbara Bell Family Chair
FX We would like to thank Elm Park Labs (Detroit, MI) for their assistance
   in building the VR environment and Evelyn Thoman for her assistance with
   project execution.r The author(s) declare financial support was received
   for the research, authorship, and/or publication of this article. This
   work was supported by the Michael J. Fox Foundation for Parkinson's
   Research (MJFF-020020) and the Edward and Barbara Bell Family Chair.
CR Alberts JL, 2023, FRONT NEUROL, V14, DOI 10.3389/fneur.2023.1212113
   Alberts JL, 2022, JOVE-J VIS EXP, DOI 10.3791/63978
   Alexander GE, 2012, FRONT AGING NEUROSCI, V4, DOI 10.3389/fnagi.2012.00021
   Amieva H, 2008, ANN NEUROL, V64, P492, DOI 10.1002/ana.21509
   Bailey PE, 2010, Q J EXP PSYCHOL, V63, P646, DOI 10.1080/17470210903521797
   Bell-McGinty S, 2002, INT J GERIATR PSYCH, V17, P828, DOI 10.1002/gps.646
   Bohannon RW, 1996, J ORTHOP SPORT PHYS, V24, P86, DOI 10.2519/jospt.1996.24.2.86
   Borgnis F, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.833136
   Burgess PW, 2006, J INT NEUROPSYCH SOC, V12, P194, DOI 10.1017/S1355617706060310
   Cahn-Weiner Deborah A, 2002, Appl Neuropsychol, V9, P187, DOI 10.1207/S15324826AN0903_8
   Chan RCK, 2008, ARCH CLIN NEUROPSYCH, V23, P201, DOI 10.1016/j.acn.2007.08.010
   Lecavalier NC, 2020, NEUROPSYCHOL REHABIL, V30, P462, DOI 10.1080/09602011.2018.1477684
   Darweesh SKL, 2017, BRAIN, V140, P429, DOI 10.1093/brain/aww291
   Davis JC, 2010, BMC GERIATR, V10, DOI 10.1186/1471-2318-10-16
   Finkel D, 2004, AGING NEUROPSYCHOL C, V11, P325, DOI 10.1080/13825580490511152
   Foubert-Samier A, 2020, PARKINSONISM RELAT D, V79, P40, DOI 10.1016/j.parkreldis.2020.08.022
   Gold DA, 2012, J CLIN EXP NEUROPSYC, V34, P11, DOI 10.1080/13803395.2011.614598
   Hughes TF, 2012, AM J GERIAT PSYCHIAT, V20, P836, DOI 10.1097/JGP.0b013e3182423961
   Huxhold O, 2006, BRAIN RES BULL, V69, P294, DOI 10.1016/j.brainresbull.2006.01.002
   Janouch C, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00602
   Jefferson AL, 2006, ARCH CLIN NEUROPSYCH, V21, P311, DOI 10.1016/j.acn.2006.03.007
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kortumand P, 2015, INT J HUM-COMPUT INT, V31, P518, DOI 10.1080/10447318.2015.1064658
   LAWTON MP, 1969, GERONTOLOGIST, V9, P179, DOI 10.1093/geront/9.3_Part_1.179
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Luo L, 2008, CAN J PSYCHIAT, V53, P346, DOI 10.1177/070674370805300603
   Mancini M, 2015, NEUROREHABILITATION, V37, P3, DOI 10.3233/NRE-151236
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nenna F, 2021, EUR J NEUROSCI, V54, P8158, DOI 10.1111/ejn.14956
   Nóbrega-Sousa P, 2020, NEUROREHAB NEURAL RE, V34, P915, DOI 10.1177/1545968320953824
   Park DC, 2009, ANNU REV PSYCHOL, V60, P173, DOI 10.1146/annurev.psych.59.103006.093656
   Parsons TD, 2017, J NEUROSCI METH, V291, P13, DOI 10.1016/j.jneumeth.2017.07.027
   Peres K, 2008, J AM GERIATR SOC, V56, P37, DOI 10.1111/j.1532-5415.2007.01499.x
   Plechatá A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01330
   Rand D, 2009, NEUROPSYCHOL REHABIL, V19, P583, DOI 10.1080/09602010802469074
   Royall DR, 2007, J NEUROPSYCH CLIN N, V19, P249, DOI 10.1176/appi.neuropsych.19.3.249
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   SHALLICE T, 1991, BRAIN, V114, P727, DOI 10.1093/brain/114.2.727
   Snowdon DA, 1996, JAMA-J AM MED ASSOC, V275, P528, DOI 10.1001/jama.275.7.528
   SPECTOR WD, 1987, J CHRON DIS, V40, P481, DOI 10.1016/0021-9681(87)90004-X
   Vaughan L, 2010, PSYCHOL AGING, V25, P343, DOI 10.1037/a0017729
   Vickers KL, 2018, NEUROREHABILITATION, V42, P213, DOI 10.3233/NRE-172301
NR 42
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 29
PY 2023
VL 4
AR 1261096
DI 10.3389/frvir.2023.1261096
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CP4W8
UT WOS:001126446700001
OA gold
DA 2024-07-18
ER

PT J
AU Maneuvrier, A
   Nguyen, NDT
   Renaud, P
AF Maneuvrier, Arthur
   Nguyen, Ngoc-Doan-Trang
   Renaud, Patrice
TI Predicting VR cybersickness and its impact on visuomotor performance
   using head rotations and field (in)dependence
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE motion sickness; virtual reality; field-dependence; sense of presence;
   eyes-hand coordination; kinetosis; virtual environments; immersion
ID VISUALLY INDUCED MOTION; VIRTUAL-REALITY; SICKNESS QUESTIONNAIRE;
   IMMERSIVE TECHNOLOGY; EXPERIENCE; GENDER; ROLL; ENVIRONMENTS;
   DEPENDENCE; COGNITION
AB Introduction: This exploratory study aims to participate in the development of the VR framework by focusing on the issue of cybersickness. The main objective is to explore the possibilities of predicting cybersickness using i) field dependence-independence measures and ii) head rotations data through automatic analyses. The second objective is to assess the impact of cybersickness on visuomotor performance.Methods: 40 participants completed a 13.5-min VR immersion in a first-person shooter game. Head rotations were analyzed in both their spatial (coefficients of variations) and temporal dimensions (detrended fluctuations analyses). Exploratory correlations, linear regressions and clusters comparison (unsupervised machine learning) analyses were performed to explain cybersickness and visuomotor performance. Traditional VR human factors (sense of presence, state of flow, video game experience, age) were also integrated.Results: Results suggest that field dependence-independence measured before exposure to VR explain 1/4 of the variance of cybersickness, while the Disorientation scale of the Simulator Sickness Questionnaire predicts 16.3% of the visuomotor performance. In addition, automatic analyses of head rotations during immersion revealed two different clusters of participants, one of them reporting more cybersickness than the other.Discussion: These results are discussed in terms of sensory integration and a diminution of head rotations as an avoidance behavior of negative symptoms. This study suggests that measuring field dependence-independence using the (Virtual) Rod and Frame Test before immersion and tracking head rotations using internal sensors during immersion might serve as powerful tools for VR actors.
C1 [Maneuvrier, Arthur; Nguyen, Ngoc-Doan-Trang] Univ Brest, Lab STICC, CNRS, UMR 6285, Brest, France.
   [Maneuvrier, Arthur; Renaud, Patrice] Univ Quebec Outaouais, Dept Psychoeduc & Psychol, Lab Cyberpsychol, Gatineau, PQ, Canada.
C3 Universite de Bretagne Occidentale; Centre National de la Recherche
   Scientifique (CNRS); University of Quebec; University Quebec Outaouais
RP Maneuvrier, A (corresponding author), Univ Brest, Lab STICC, CNRS, UMR 6285, Brest, France.; Maneuvrier, A (corresponding author), Univ Quebec Outaouais, Dept Psychoeduc & Psychol, Lab Cyberpsychol, Gatineau, PQ, Canada.
EM arthur.maneuvrier@protonmail.com
OI Maneuvrier, Arthur/0000-0002-1897-8643
CR Adhanom I, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.848001
   Amrhein V, 2019, NATURE, V567, P305, DOI 10.1038/d41586-019-00857-9
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   [Anonymous], 1975, Motion sickness
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Asbee J, 2023, VIRTUAL REAL-LONDON, V27, P1391, DOI 10.1007/s10055-022-00744-1
   Aykent B, 2014, P I MECH ENG D-J AUT, V228, P818, DOI 10.1177/0954407013516101
   Bailey GS, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.1001080
   Baniqued PL, 2013, ACTA PSYCHOL, V142, P74, DOI 10.1016/j.actpsy.2012.11.009
   Barnett MD, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12081019
   Beck J, 2019, TOUR REV, V74, P586, DOI 10.1108/TR-03-2017-0049
   Bian YL, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384529
   Bian YL, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018)
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bosser A.G., 2006, Entertainment Computing-ICEC 2006, P374, DOI DOI 10.1007/11872320_53
   Bouchard S., 2007, Acte de colloque du Annu. Rev. CyberTherapy Telemedicine, V5
   Bouchard S, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.739742
   Bradley E, 2015, CHAOS, V25, DOI 10.1063/1.4917289
   Brenner A., 2017, CMC Senior
   Brown P, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.945800
   Bryson S, 2013, Arxiv, DOI [arXiv:1312.4322, 10.48550/arXiv.1312.4322, DOI 10.48550/ARXIV.1312.4322]
   Budhiraja P, 2017, Arxiv, DOI arXiv:1710.02599
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Carrieri M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00053
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Choi W, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31758-y
   Chung WL, 2023, VIRTUAL REAL-LONDON, V27, P2029, DOI 10.1007/s10055-023-00786-z
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Csikszentmihalyi M., 1991, Flow: The Psychology of Optimal Experience, DOI DOI 10.5465/AMR.1991.4279513
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   David EJ, 2022, J VISION, V22, DOI 10.1167/jov.22.4.12
   Dawson DR, 2017, NEUROPSYCHOL REHABIL, V27, P599, DOI 10.1080/09602011.2017.1313379
   DEICH RF, 1973, PERCEPT MOTOR SKILL, V36, P1115, DOI 10.2466/pms.1973.36.3c.1115
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dove ES, 2018, J LAW MED ETHICS, V46, P1013, DOI 10.1177/1073110518822003
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Draper JV, 1996, IEEE INT CONF ROBOT, P1030, DOI 10.1109/ROBOT.1996.506844
   Eng K, 2007, MED BIOL ENG COMPUT, V45, P901, DOI 10.1007/s11517-007-0239-1
   Evans C, 2013, BRIT J EDUC PSYCHOL, V83, P210, DOI 10.1111/bjep.12015
   Faiola A., 2013, Correlating the effects of flow and telepresence in virtual worlds: enhancing our understanding of user behavior in game-based learning
   Flach JM, 1998, PRESENCE-TELEOP VIRT, V7, P90, DOI 10.1162/105474698565550
   Fleury P., 2012, Progress in cultural heritage preservation, P159, DOI [10.1007/978-3-642-34234-9_16, DOI 10.1007/978-3-642-34234-9_16]
   Fragkos Konstantinos C, 2014, Int Sch Res Notices, V2014, P825383, DOI 10.1155/2014/825383
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Garcia-Agundez A, 2019, GAMES HEALTH J, V8, P439, DOI 10.1089/g4h.2019.0045
   Garcia-Agundez A, 2017, LECT NOTES COMPUT SC, V10622, P203, DOI 10.1007/978-3-319-70111-0_19
   GIBSON JAMES J., 1966
   Goodman SN, 2018, NATURE, V564, P7, DOI 10.1038/d41586-018-07589-2
   Gresty MA, 2008, AVIAT SPACE ENVIR MD, V79, P105, DOI 10.3357/ASEM.2143.2008
   Gresty MA, 2009, ANN NY ACAD SCI, V1164, P263, DOI 10.1111/j.1749-6632.2008.03744.x
   Grosprêtre S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13278
   Hadadi A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.973236
   Hardstone R, 2012, FRONT PHYSIOL, V3, DOI 10.3389/fphys.2012.00450
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hirota M, 2019, ERGONOMICS, V62, P759, DOI 10.1080/00140139.2019.1582805
   Hitching R, 2023, J CLIN MED, V12, DOI 10.3390/jcm12030843
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Jasper A, 2023, COMPUT HUM BEHAV, V146, DOI 10.1016/j.chb.2023.107800
   Jia S, 2014, NEUROSCIENCE, V278, P136, DOI 10.1016/j.neuroscience.2014.07.075
   Kapalo K.A., 2015, P HUMAN FACTORS ERGO, DOI DOI 10.1177/1541931215591261
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   Kemeny A., 2017, The Engineering Reality of Virtual Reality, P48
   KENNEDY RS, 1975, AVIAT SPACE ENVIR MD, V46, P1349
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Köster H, 2021, J NEUROL, V268, P2843, DOI 10.1007/s00415-021-10445-5
   Kourtesis P, 2023, IEEE T VIS COMPUT GR, V29, P2326, DOI 10.1109/TVCG.2023.3247062
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lachlan K, 2011, COMMUN RES REP, V28, P27, DOI 10.1080/08824096.2010.518924
   Lahude AB, 2023, DISABIL REHABIL-ASSI, V18, P1237, DOI 10.1080/17483107.2021.2001060
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Laver KE, 2017, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub4
   Li Y, 2019, BIOMED SIGNAL PROCES, V49, P202, DOI 10.1016/j.bspc.2018.12.007
   Lovie P., 2005, ENCY STAT BEHAV SCI, P317, DOI [10.1002/0470013192.bsa107, DOI 10.1002/0470013192.BSA107]
   Maneuvrier A, 2023, VIRTUAL REAL-LONDON, V27, P849, DOI 10.1007/s10055-022-00698-4
   Maneuvrier A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.706712
   Maneuvrier A, 2020, PRESENCE-VIRTUAL AUG, V29, P141, DOI 10.1162/pres_a_00359
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Miloff A, 2019, BEHAV RES THER, V118, P130, DOI 10.1016/j.brat.2019.04.004
   MIRABILE C S JR, 1976, Neuropsychobiology, V2, P45
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Palmisano S, 2023, VIRTUAL REAL-LONDON, V27, P1293, DOI 10.1007/s10055-022-00732-5
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   PARNETTI L, 2006, COGN PROCESS S5, V7, P77
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pithers R., 2002, Journal of Vocational Education and Training, P117, DOI [DOI 10.1080/13636820200200191, 10.1080/13636820200200191]
   Pointer JS, 1999, OPHTHAL PHYSL OPT, V19, P317, DOI 10.1046/j.1475-1313.1999.00441.x
   Porcino T, 2022, ENTERTAIN COMPUT, V41, DOI 10.1016/j.entcom.2021.100473
   Possin KL, 2010, NEUROCASE, V16, P466, DOI 10.1080/13554791003730600
   Pratviel Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79885-9
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Renaud P, 2002, IEEE T INF TECHNOL B, V6, P235, DOI [10.1109/TITB.2002.802381, 10.1109/TITB.2002.802381.]
   Renaud P., 2000, Trofimova, V320, P333
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riva G., 2022, Comprehensive clinical psychology, V91, DOI [10.1016/B978-0-12-818697-8.00006-6, DOI 10.1016/B978-0-12-818697-8.00006-6, https://doi.org/10.1016/B978-0-12-818697-8.00006-6]
   Robillard G., 2002, 25E CONGRES ANNUEL S
   Rothstein H.R., 2008, Journal of Experimental Criminology, V4, P61, DOI 10.1007/s11292-007-9046-9
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Scozzari S, 2011, STUD COMPUT INTELL, V337, P63
   Seitz R. J., 2014, Int. J. Neurorehabilitation, V01, DOI [10.4172/2376-0281.1000113, DOI 10.4172/2376-0281.1000113]
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Sirkkunen E., 2016, Proceedings of the 20th international academic mindtrek conference, P297, DOI DOI 10.1145/2994310.2994353
   Slater M., 2003, PRESENCE 2003 6 ANN, VVolume 157
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Sumayli Y, 2023, VIBRATION-BASEL, V6, P45, DOI 10.3390/vibration6010004
   Tan CW, 2021, DATA MIN KNOWL DISC, V35, P1032, DOI 10.1007/s10618-021-00745-9
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Varmaghani S, 2022, VIRTUAL REAL-LONDON, V26, P659, DOI 10.1007/s10055-021-00535-0
   Wasserstein RL, 2019, AM STAT, V73, P1, DOI 10.1080/00031305.2019.1583913
   Weech S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00010
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weiqin Chen, 2020, Computers Helping People with Special Needs. 17th International Conference, ICCHP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12376), P138, DOI 10.1007/978-3-030-58796-3_18
   Wibirama S, 2020, VIRTUAL REAL-LONDON, V24, P39, DOI 10.1007/s10055-019-00386-w
   Witkin H.-A., 1962, Psychological differentiation: studies of development, P418
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang AHX, 2022, BRAIN INFORM, V9, DOI 10.1186/s40708-022-00172-6
   Yang S, 2022, CYBERPSYCH BEH SOC N, V25, P101, DOI 10.1089/cyber.2021.0037
NR 136
TC 1
Z9 1
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 27
PY 2023
VL 4
AR 1307925
DI 10.3389/frvir.2023.1307925
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA AM1Q1
UT WOS:001118794500001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Arnfred, B
   Svendsen, JK
   Adjourlu, A
   Horthoj, C
AF Arnfred, Benjamin
   Svendsen, Johanna Kvist
   Adjourlu, Ali
   Horthoj, Carsten
TI Scoping review of the hardware and software features of virtual reality
   exposure therapy for social anxiety disorder, agoraphobia, and specific
   phobia
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality exposure therapy; social anxiety disorder; agoraphobia;
   specific phobia; virtual reality technology; scoping review
ID IN-VIVO EXPOSURE; ONE-SESSION TREATMENT; BEHAVIORAL-THERAPY; PANIC
   DISORDER; DENTAL PHOBIA; FEAR; EFFICACY; METAANALYSIS; ACROPHOBIA;
   12-MONTH
AB Introduction: The use of virtual reality technology to deliver exposure therapy in the treatment of phobic anxiety (i.e., social anxiety disorder, agoraphobia, and specific phobia) has been proposed to be advantageous compared with in-vivo exposure therapy. These supposed advantages depend on the features of the virtual reality technology and how it is used therapeutically. Therefore, the aim of this study was to provide a comprehensive overview of the features of the hardware and software used in studies examining virtual reality exposure therapy studies for phobic anxiety disorders.
   Methods: 70 studies using virtual reality exposure therapy to treat social anxiety disorder, agoraphobia and/or specific phobia, were systematically reviewed for 46 data points relating to these features.
   Results: We found that studies generally did not utilize contemporary virtual reality technology and that hardware and software features were inconsistently delineated.
   Discussion: The implications of these findings are that the use of modern virtual reality technology represents a relevant frontier in anxiety treatment and that a framework for reporting technical features of virtual reality exposure interventions would benefit the field.
C1 [Arnfred, Benjamin; Svendsen, Johanna Kvist; Horthoj, Carsten] Copenhagen Univ Hosp, Copenhagen Res Ctr Mental Hlth, Mental Hlth Ctr Copenhagen, CORE, Hellerup, Denmark.
   [Adjourlu, Ali] Aalborg Univ, Multisensory Experience Lab, Copenhagen, Denmark.
   [Horthoj, Carsten] Univ Copenhagen, Dept Publ Hlth, Copenhagen, Denmark.
C3 University of Copenhagen; Aalborg University; University of Copenhagen
RP Arnfred, B (corresponding author), Copenhagen Univ Hosp, Copenhagen Res Ctr Mental Hlth, Mental Hlth Ctr Copenhagen, CORE, Hellerup, Denmark.
EM benjamin.alexander.thorup.arnfred@regionh.dk
OI Adjorlu, Ali/0000-0001-5414-8631
FU Novo Nordisk Foundation [NNF17OC0027780]; TrygFonden [146169]
FX & nbsp;This study was conducted as part of a PhD programme, embedded
   into the SoREAL trial (Can be found online at
   https://clinicaltrials.gov/ct2/show/NCT03845101). The SoREAL trial was
   funded by the Novo Nordisk Foundation [NNF17OC0027780] and by TrygFonden
   [ID: 146169]. The study is entirely independent of the Novo Nordisk
   Foundation and TrygFonden and therefore, the funding bodies plays no
   role in the design of the study, the review process, the analysis, and
   interpretation of data, in writing the manuscript, or the decision to
   submit it for publication.
CR Abramowitz J. S., 2019, EXPOSURE THERAPY ANX, DOI DOI 10.1007/S10879-011-9187-Z
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Anderson PL, 2013, J CONSULT CLIN PSYCH, V81, P751, DOI 10.1037/a0033559
   Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [10.1080/1364557032000119616, DOI 10.1080/1364557032000119616]
   Arnfred B, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2021-051147
   Botella C, 2007, CLIN PSYCHOL PSYCHOT, V14, P164, DOI 10.1002/cpp.524
   Botella C., 2014, REV PSICOPATOLOG A P, V19, P157, DOI DOI 10.5944/RPPC.VOL.19.NUM.3.2014.13898
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bouchard Stephane, 2006, Technol Health Care, V14, P19
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Bouchard S, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P81, DOI 10.5772/46417
   Boutron I., 2009, J CHIN INTEGR MED, V7, P690
   Brade J, 2017, INT J HUM-COMPUT ST, V101, P76, DOI 10.1016/j.ijhcs.2017.01.004
   Breuer T. A., 2017, THESIS
   BUTLER G, 1985, BEHAV RES THER, V23, P651, DOI 10.1016/0005-7967(85)90060-9
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chesham RK, 2018, BEHAV CHANGE, V35, P152, DOI 10.1017/bec.2018.15
   Choi YH, 2005, CYBERPSYCHOL BEHAV, V8, P387, DOI 10.1089/cpb.2005.8.387
   Cieslik B, 2020, COMPLEMENT THER MED, V52, DOI 10.1016/j.ctim.2020.102480
   Clemmensen L, 2020, BMC PSYCHIATRY, V20, DOI 10.1186/s12888-020-2453-4
   Coelho CM, 2006, CYBERPSYCHOL BEHAV, V9, P336, DOI 10.1089/cpb.2006.9.336
   Côté S, 2005, APPL PSYCHOPHYS BIOF, V30, P217, DOI 10.1007/s10484-005-6379-x
   Craske M.G., 2008, Clinical handbook of psychological disorders: A step-by-step treatment manual, V4th, P1
   Craske MG, 2022, BEHAV RES THER, V152, DOI 10.1016/j.brat.2022.104069
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   de Quervain DJF, 2011, P NATL ACAD SCI USA, V108, P6621, DOI 10.1073/pnas.1018214108
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Diemer J, 2014, WORLD J BIOL PSYCHIA, V15, P427, DOI 10.3109/15622975.2014.892632
   Dilgul M, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.609545
   Emmelkamp PMG, 2020, CURR PSYCHIAT REP, V22, DOI 10.1007/s11920-020-01156-1
   Farrell LJ, 2021, BEHAV THER, V52, P478, DOI 10.1016/j.beth.2020.06.003
   Felton WM, 2022, INT J HUM-COMPUT INT, V38, P1, DOI 10.1080/10447318.2021.1921368
   Foa EB, 2016, ANNU REV CLIN PSYCHO, V12, P1, DOI 10.1146/annurev-clinpsy-021815-093533
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Geraets CNW, 2019, BEHAV COGN PSYCHOTH, V47, P745, DOI 10.1017/S1352465819000225
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Grillon H., 2006, Int. J. Disability Hum. Develop., V5, P243
   Guidi J, 2018, PSYCHOTHER PSYCHOSOM, V87, P276, DOI 10.1159/000490574
   Gujjar KR, 2019, J ANXIETY DISORD, V62, P100, DOI 10.1016/j.janxdis.2018.12.001
   Gujjar KR, 2018, BEHAV COGN PSYCHOTH, V46, P367, DOI 10.1017/S1352465817000534
   Gujjar Kumar Raghav, 2017, Dent Update, V44, P423
   Hartanto D, 2016, COMM COM INF SC, V604, P85, DOI 10.1007/978-3-319-32270-4_9
   Jeong HS, 2021, J CLIN MED, V10, DOI 10.3390/jcm10050915
   Jiang MYW, 2020, J AFFECT DISORDERS, V276, P636, DOI 10.1016/j.jad.2020.07.076
   Jones MB, 2004, PRESENCE-VIRTUAL AUG, V13, P589, DOI 10.1162/1054746042545247
   Kampmann IL, 2016, BEHAV RES THER, V77, P147, DOI 10.1016/j.brat.2015.12.016
   Kessler RC, 2005, ARCH GEN PSYCHIAT, V62, P617, DOI 10.1001/archpsyc.62.6.617
   Kessler RC, 2012, INT J METH PSYCH RES, V21, P169, DOI 10.1002/mpr.1359
   Kim HJ, 2020, J MED INTERNET RES, V22, DOI 10.2196/23024
   Krijn M, 2007, CYBERPSYCHOL BEHAV, V10, P362, DOI 10.1089/cpb.2006.9943
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Lindner P, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00116
   Lindner P, 2019, J ANXIETY DISORD, V61, P45, DOI 10.1016/j.janxdis.2018.07.003
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lombard M., 2015, Immersed in media, P13, DOI [DOI 10.1007/978-3-319-10190-3, https://doi.org/10.1007/978-3-319-10190-32, DOI 10.1007/978-3-319-10190-32, 10.1007/978-3-319-10190-3_2, DOI 10.1007/978-3-319-10190-3_2]
   Lundin J, 2022, BEHAV COGN PSYCHOTH, V50, P158, DOI 10.1017/S1352465821000473
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Malbos E, 2020, CLIN CASE STUD, V19, P339, DOI 10.1177/1534650120940014
   Malbos E, 2013, AUST NZ J PSYCHIAT, V47, P160, DOI 10.1177/0004867412453626
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Meindl JN, 2019, J APPL RES INTELLECT, V32, P1446, DOI 10.1111/jar.12637
   Meyerbroeker K, 2013, PSYCHOTHER PSYCHOSOM, V82, P170, DOI 10.1159/000342715
   Meyerbroeker K, 2012, PSYCHOTHER PSYCHOSOM, V81, P29, DOI 10.1159/000329454
   Meyerbröker K, 2018, J ANXIETY DISORD, V57, P48, DOI 10.1016/j.janxdis.2018.05.001
   Meyerbröker K, 2011, STUD HEALTH TECHNOL, V167, P51, DOI 10.3233/978-1-60750-766-6-51
   Michaliszyn D, 2010, CYBERPSYCH BEH SOC N, V13, P689, DOI 10.1089/cyber.2009.0277
   Miloff A, 2019, BEHAV RES THER, V118, P130, DOI 10.1016/j.brat.2019.04.004
   Moldovan R, 2014, J EVID-BASED PSYCHOT, V14, P67
   Morina N, 2023, PSYCHOL MED, V53, P2176, DOI 10.1017/S0033291721001690
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   National Institute for Health and Care Excellence, 2013, NICE GUID SOC ANX DI, DOI [10.1002/9781118775349.ch47, DOI 10.1002/9781118775349.CH47]
   National Institute for Health and Care Excellence, 2011, Clinical Guideline
   National Institute for Health and Clinical Excellence, 2011, clinical guideline 123
   Nazligul MD, 2017, COMM COM INF SC, V748, P191, DOI 10.1007/978-3-319-64218-5_15
   Neudeck P., 2012, Exposure Therapy: Rethinking the Model - Refining the Method, P23, DOI DOI 10.1007/978-1-4614-3342-2_3
   Olatunji BO, 2009, COGN BEHAV PRACT, V16, P172, DOI 10.1016/j.cbpra.2008.07.003
   Öst LG, 2012, AUT CHILD PSYCHO, P59, DOI 10.1007/978-1-4614-3253-1_4
   Pelissolo A., 2012, VIRTUAL REAL MED I B, V5, P35
   Peperkorn HM, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00268
   Peperkorn HM, 2015, COMPUT HUM BEHAV, V48, P542, DOI 10.1016/j.chb.2015.02.028
   Pérez-Ara MA, 2010, STUD HEALTH TECHNOL, V154, P77, DOI 10.3233/978-1-60750-561-7-77
   Pham MT, 2014, RES SYNTH METHODS, V5, P371, DOI 10.1002/jrsm.1123
   Pittig A, 2019, BEHAV THER, V50, P353, DOI 10.1016/j.beth.2018.07.003
   Pot-Kolder RMCA, 2018, LANCET PSYCHIAT, V5, P217, DOI 10.1016/S2215-0366(18)30053-1
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Price M, 2011, J ANXIETY DISORD, V25, P763, DOI 10.1016/j.janxdis.2011.03.004
   Reitmaier J, 2022, PSYCHOL PSYCHOTHER-T, V95, P57, DOI 10.1111/papt.12363
   Rothbaum BO, 2006, BEHAV THER, V37, P80, DOI 10.1016/j.beth.2005.04.004
   Rus-Calafell M, 2013, BEHAV MODIF, V37, P568, DOI 10.1177/0145445513482969
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Servera M, 2020, REV PSICOL CLIN NINO, V7, P16, DOI 10.21134/rpcna.2020.07.2.2
   Shin B, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/30590
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Stein DJ, 2017, BMC MED, V15, DOI 10.1186/s12916-017-0889-2
   Sundhedsstyrelsen, 2016, NAT KLIN RETN BEH AN
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Tortella-Feliu M, 2011, BEHAV MODIF, V35, P3, DOI 10.1177/0145445510390801
   Trahan MH, 2021, CLIN SOC WORK J, V49, P220, DOI 10.1007/s10615-020-00784-7
   Turk C.L., 2008, Clinical handbook of psychological disorders: A step-by-step treatment manual, V4th, P123
   Veritas Health Innovation, 2022, Covidence systematic review software
   Wallach HS, 2011, ISR J PSYCHIATR REL, V48, P91
   Wang PS, 2005, ARCH GEN PSYCHIAT, V62, P629, DOI 10.1001/archpsyc.62.6.629
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Whitney SL, 2005, PHYS THER, V85, P443, DOI 10.1093/ptj/85.5.443
   Youngblut C., 2003, Experience of presence in virtual environments
   Zainal NH, 2021, BEHAV RES THER, V147, DOI 10.1016/j.brat.2021.103984
NR 112
TC 0
Z9 0
U1 13
U2 28
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 6
PY 2023
VL 4
AR 952741
DI 10.3389/frvir.2023.952741
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XL6
UT WOS:001023310200001
OA gold
DA 2024-07-18
ER

PT J
AU Landeck, M
   Igarzábal, FA
   Unruh, F
   Habenicht, H
   Khoshnoud, S
   Wittmann, M
   Lugrin, JL
   Latoschik, ME
AF Landeck, Maximilian
   Igarzabal, Federico Alvarez
   Unruh, Fabian
   Habenicht, Hannah
   Khoshnoud, Shiva
   Wittmann, Marc
   Lugrin, Jean-Luc
   Latoschik, Marc Erich
TI Journey through a virtual tunnel: Simulated motion and its effects on
   the experience of time
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE passage of time; illusion of self-motion; vection; virtual tunnel;
   therapeutic application; virtual reality; extended reality (XR)
ID SELF-MOTION; PERCEPTION; REALITY; OVERESTIMATION; REPRESENTATION;
   EMBODIMENT; OWNERSHIP; IMMERSION; AVATAR; COLOR
AB This paper examines the relationship between time and motion perception in virtual environments. Previous work has shown that the perception of motion can affect the perception of time. We developed a virtual environment that simulates motion in a tunnel and measured its effects on the estimation of the duration of time, the speed at which perceived time passes, and the illusion of self-motion, also known as vection. When large areas of the visual field move in the same direction, vection can occur; observers often perceive this as self-motion rather than motion of the environment. To generate different levels of vection and investigate its effects on time perception, we developed an abstract procedural tunnel generator. The generator can simulate different speeds and densities of tunnel sections (visibly distinguishable sections that form the virtual tunnel), as well as the degree of embodiment of the user avatar (with or without virtual hands). We exposed participants to various tunnel simulations with different durations, speeds, and densities in a remote desktop and a virtual reality (VR) laboratory study. Time passed subjectively faster under high-speed and high-density conditions in both studies. The experience of self-motion was also stronger under high-speed and high-density conditions. Both studies revealed a significant correlation between the perceived passage of time and perceived self-motion. Subjects in the virtual reality study reported a stronger self-motion experience, a faster perceived passage of time, and shorter time estimates than subjects in the desktop study. Our results suggest that a virtual tunnel simulation can manipulate time perception in virtual reality. We will explore these results for the development of virtual reality applications for therapeutic approaches in our future work. This could be particularly useful in treating disorders like depression, autism, and schizophrenia, which are known to be associated with distortions in time perception. For example, the tunnel could be therapeutically applied by resetting patients' time perceptions by exposing them to the tunnel under different conditions, such as increasing or decreasing perceived time.
C1 [Landeck, Maximilian; Unruh, Fabian; Lugrin, Jean-Luc; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
   [Igarzabal, Federico Alvarez; Habenicht, Hannah; Khoshnoud, Shiva; Wittmann, Marc] Inst Frontier Areas Psychol & Mental Hlth, Freiburg, Germany.
C3 University of Wurzburg
RP Landeck, M (corresponding author), Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
EM maximilian.landeck@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023; Lugrin, Jean-Luc/KMA-1030-2024
OI Latoschik, Marc Erich/0000-0002-9340-9600; Lugrin,
   Jean-Luc/0000-0002-2725-2123; Alvarez Igarzabal,
   Federico/0000-0002-1335-5340
FU European Union; University of Wuerzburg;  [824128]
FX & nbsp;This work is funded by the VIRTUALTIMES project (ID-824128)
   funded by the European Union under the Horizon 2020 program. This
   publication was supported by the Open Access Publication Fund of the
   University of Wuerzburg.
CR Abe S., 1935, TOHOKU PSYCHOL FOLIA, V3, P53
   Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Allman M. J., 2015, Time distortions in mind, P37, DOI [DOI 10.1163/9789004230699_003, DOI 10.1163/J.CTT1W8H2WK.7]
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bansal A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40870-6
   Benussi V., 1913, PSYCHOL ZEITAUFFASSU, P6
   Bilgili B, 2020, TOTAL QUAL MANAG BUS, V31, P1098, DOI 10.1080/14783363.2018.1465814
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   BROWN SW, 1995, PERCEPT PSYCHOPHYS, V57, P105, DOI 10.3758/BF03211853
   Bruder G, 2014, 2014 IEEE VIRTUAL REALITY (VR), P67, DOI 10.1109/VR.2014.6802054
   Bryson S, 2013, Arxiv, DOI [arXiv:1312.4322, 10.48550/arXiv.1312.4322, DOI 10.48550/ARXIV.1312.4322]
   CAELLI T, 1982, PERCEPT PSYCHOPHYS, V31, P437, DOI 10.3758/BF03204853
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   COHEN J, 1953, NATURE, V172, P901, DOI 10.1038/172901a0
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Dichgans J., 1978, HDB SENSORY PHYSL, VVIII., P755
   Epic Games, 2022, Unreal engine
   Fischer MH, 1924, PFLUG ARCH GES PHYS, V202, P553, DOI 10.1007/BF01723520
   Friedman D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00943
   Gall D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P73, DOI 10.1109/VR.2018.8446153
   GOLDSTON.S, 1974, PERCEPT MOTOR SKILL, V39, P63, DOI 10.2466/pms.1974.39.1.63
   Haahr M., 1998, TRUE RANDOM NUMBER S
   Haggard P, 2017, NAT REV NEUROSCI, V18, P197, DOI 10.1038/nrn.2017.14
   Helson H, 1931, J EXP PSYCHOL, V14, P202, DOI 10.1037/h0071164
   Igarzabal FA., 2021, TMB, DOI [10.1037/tmb0000038, DOI 10.1037/TMB0000038]
   JASP Team, 2022, ABOUT US
   Jokic T., 2018, TIMING TIME PERCEPT, V6, P71, DOI DOI 10.1163/22134468-00002101
   Kanai R, 2006, J VISION, V6, P1421, DOI 10.1167/16.12.8
   Kaneko S, 2009, J VISION, V9, DOI 10.1167/9.7.14
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Khoshnoud S, 2020, PEERJ, V8, DOI 10.7717/peerj.10520
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kitajima M., 2020, 26 ACM S VIRTUAL REA, P1, DOI [10.1145/3385956.3422104, DOI 10.1145/3385956.3422104]
   Kühn S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00129
   Landau DH, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01229
   Landum M., 2020, IBER CONF INF SYST, P1, DOI [10.1145/3385956.3422111, DOI 10.23919/CISTI49556.2020.9141166, DOI 10.23919/cisti49556.2020.9141166]
   Latoschik M. E., 2022, PROVISIONALLY ACCEPT, V2022, P1, DOI [10.3389/frvir.2022.694433, DOI 10.3389/FRVIR.2022.694433]
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lelyveld P., 2015, SMPTE Motion Imaging Journal, V124, P78, DOI [10.5594/j18599, DOI 10.5594/J18599]
   Lugrin Jean-Luc, 2019, 25 ACM S VIRT REAL S, P1
   Malpica S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0265591
   Manning WG, 1998, J HEALTH ECON, V17, P283, DOI 10.1016/S0167-6296(98)00025-3
   Martin B, 2019, PSYCH J, V8, P82, DOI 10.1002/pchj.268
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Peña J, 2009, COMMUN RES, V36, P838, DOI 10.1177/0093650209346802
   Pfeifer E, 2016, MUSIC MED, V8, P180, DOI [10.47513/mmd.v8i4.473, DOI 10.47513/MMD.V8I4.473]
   Pizarro R., 2015, ICAT EGVE, P117, DOI DOI 10.5555/2852313.2852329
   Ratajczyk D, 2019, BIO-ALGORITHMS MED-S, V15, DOI 10.1515/bams-2019-0008
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Riecke BernhardE., 2012, P ACM S APPL PERCEPT, P17, DOI DOI 10.1145/2338676.2338680
   Roelofs CO, 1951, ACTA PSYCHOL, V8, P89, DOI 10.1016/0001-6918(51)90007-8
   Rutrecht H, 2021, TIMING TIME PERCEPT, V9, P353, DOI 10.1163/22134468-bja10033
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schatzschneider C, 2016, IEEE T VIS COMPUT GR, V22, P1387, DOI 10.1109/TVCG.2016.2518137
   Schmitz Carsten, 2006, LimeSurvey
   Schneider SM, 2007, ONCOL NURS FORUM, V34, P39, DOI 10.1188/07.ONF.39-46
   Schneider SM, 2011, SUPPORT CARE CANCER, V19, P555, DOI 10.1007/s00520-010-0852-7
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seno T, 2017, I-PERCEPTION, V8, DOI [10.1177/2041669518774069, 10.1177/2041669517742176]
   Seno T, 2011, PERCEPTION, V40, P497, DOI 10.1068/p6885
   Shibasaki M, 2014, SCI REP-UK, V4, DOI 10.1038/srep05899
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Teghil A, 2020, BEHAV BRAIN RES, V377, DOI 10.1016/j.bbr.2019.112242
   Thones S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19892-z
   Tobin S, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009271
   Unruh F, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.658509
   Vierordt K., 1868, ZEITSINN NACH VERSUC
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Weber S, 2020, TIMING TIME PERCEPT, V8, P119, DOI 10.1163/22134468-20191152
   Wittmann M, 2015, CONSCIOUS COGN, V38, P172, DOI 10.1016/j.concog.2015.06.008
   Wittmann M, 2013, NAT REV NEUROSCI, V14, P217, DOI 10.1038/nrn3452
   Zakay D, 1997, CURR DIR PSYCHOL SCI, V6, P12, DOI 10.1111/1467-8721.ep11512604
   Zakay D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00917
NR 81
TC 2
Z9 2
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 9
PY 2023
VL 3
AR 1059971
DI 10.3389/frvir.2022.1059971
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YU3
UT WOS:001023345100001
OA gold
DA 2024-07-18
ER

PT J
AU Porffy, LA
   Mehta, MA
   Mouchlianitis, E
   Shergill, SS
AF Porffy, Lilla A.
   Mehta, Mitul A.
   Mouchlianitis, Elias
   Shergill, Sukhi S.
TI VStore: Feasibility and acceptability of a novel virtual reality
   functional cognition task
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual reality assessment; neuropsychological testing;
   cognition; functional cognition; cognitive assessment; ageing; psychosis
ID CLINICAL-TRIALS; SPATIAL MAP; DRUGS; DECLINE; HIPPOCAMPUS; VALIDATION;
   DISORDERS; VALIDITY; DEFICITS; SCALE
AB Virtual reality (VR) is becoming an increasingly popular tool in neuroscience and mental health research. In recent years, efforts have been made to virtualise neuropsychological testing with the intent to increase the ecological validity of cognitive assessments. However, there are some limitations in the current literature-feasibility and acceptability data are often not reported or available and sample sizes have generally been small. In this study, we describe the development and establish the feasibility and acceptability of use of a novel functional cognition VR shopping task, VStore, in three separate samples with data from a total of 210 participants. Two samples include healthy volunteers between the ages of 20 and 79 and there is one clinical cohort of patients with psychosis. Main VStore outcomes were: 1) verbal recall of 12 grocery items, 2) time to collect items, 3) time to select items on a self-checkout machine, 4) time to make the payment, 5) time to order hot drink, and 6) total time. Feasibility and acceptability were assessed by the completion rate across the three studies. VR induced adverse effects were assessed pre- and post-VStore administration to establish tolerability. Finally, as an exploratory objective, VStore's ability to differentiate between younger and older age groups, and between patients and matched healthy controls was examined as preliminary indication of its potential utility. The overall completion rate across the studies was exceptionally high (99.95%), and VStore did not induce any adverse effects. Additionally, there was a clear difference in VStore performance metrics between both the patients and controls and between younger and older age groups, suggesting potential clinical utility of this VR assessment. These findings demonstrate that VStore is a promising neuropsychological tool that is well-tolerated and feasible to administer to both healthy and clinical populations. We discuss the implications for future research involving neuropsychological testing based on our experience and the contemporary literature.
C1 [Porffy, Lilla A.; Mehta, Mitul A.; Mouchlianitis, Elias; Shergill, Sukhi S.] Kings Coll London, Inst Psychiat Psychol & Neurosci, London, England.
   [Mouchlianitis, Elias] Univ East London, Sch Psychol, London, England.
   [Shergill, Sukhi S.] Kent & Medway Med Sch, Canterbury, England.
   [Shergill, Sukhi S.] Kent & Medway Natl Hlth Serv & Social Care Partner, Gillingham, England.
C3 University of London; King's College London; University of East London
RP Porffy, LA (corresponding author), Kings Coll London, Inst Psychiat Psychol & Neurosci, London, England.
EM lilla.a.porffy@kcl.ac.uk
OI Porffy, Lilla Alexandra/0000-0001-7420-3618
FU National Institute for Health Research (NIHR) Maudsley Biomedical
   Research Centre at South London; Maudsley NHS Foundation Trust; King's
   College London; National Institute for Health Research Maudsley
   Biomedical Research Centre
FX This paper represents independent research part funded by the National
   Institute for Health Research (NIHR) Maudsley Biomedical Research Centre
   at South London and Maudsley NHS Foundation Trust and King's College
   London. SS is supported by the National Institute for Health Research
   Maudsley Biomedical Research Centre.
CR ALBERT MS, 1981, J CONSULT CLIN PSYCH, V49, P835
   Ames SL, 2005, OPTOMETRY VISION SCI, V82, P168, DOI 10.1097/01.OPX.0000156307.95086.6
   Anthes C, 2016, IEEE AEROSPACE C IEE
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Atkins AS, 2018, JPAD-J PREV ALZHEIM, V5, P216, DOI 10.14283/jpad.2018.28
   Axelrod BN, 2002, ASSESSMENT, V9, P17, DOI 10.1177/1073191102009001003
   Bermudez-Contreras E, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00063
   Birckhead B, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11973
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Buchanan RW, 2005, SCHIZOPHRENIA BULL, V31, P5, DOI 10.1093/schbul/sbi020
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Chersi F, 2015, NEURON, V88, P64, DOI 10.1016/j.neuron.2015.09.021
   Clus D, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7898
   Coughlan G, 2018, NAT REV NEUROL, V14, P496, DOI 10.1038/s41582-018-0031-x
   Davison SMC, 2018, ACTA NEUROPSYCHIATR, V30, P79, DOI 10.1017/neu.2017.14
   Eichenberg C, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P35, DOI 10.5772/50094
   Fervaha G, 2014, JAMA PSYCHIAT, V71, P1058, DOI 10.1001/jamapsychiatry.2014.1105
   Fornells-Ambrojo M, 2008, SCHIZOPHR RES, V104, P228, DOI 10.1016/j.schres.2008.05.013
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Guna J, 2020, MOBILE NETW APPL, V25, P1436, DOI 10.1007/s11036-019-01373-w
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Halvorsrud K, 2019, SOC PSYCH PSYCH EPID, V54, P1311, DOI 10.1007/s00127-019-01758-y
   Harvey Philip D, 2017, Innov Clin Neurosci, V14, P18
   Heckers S, 2001, HIPPOCAMPUS, V11, P520, DOI 10.1002/hipo.1068
   Herweg NA, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00297
   KAY SR, 1987, SCHIZOPHRENIA BULL, V13, P261, DOI 10.1093/schbul/13.2.261
   Keefe RSE, 2013, SCHIZOPHRENIA BULL, V39, P417, DOI 10.1093/schbul/sbr153
   Knopman DS, 2021, ALZHEIMERS DEMENT, V17, P696, DOI 10.1002/alz.12213
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Leucht S, 2016, SCHIZOPHRENIA BULL, V42, pS90, DOI 10.1093/schbul/sbv167
   Migoya-Borja M, 2020, CYBERPSYCH BEH SOC N, V23, P246, DOI 10.1089/cyber.2019.0497
   Millan MJ, 2012, NAT REV DRUG DISCOV, V11, P141, DOI 10.1038/nrd3628
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Office for National Statistics, 2015, 2011 census analysis: Ethnicity and religion of the non-UK born population in England and Wales
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   Oliveira CR, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01085
   Olson KE, 2011, AGEING INT, V36, P123, DOI 10.1007/s12126-010-9077-9
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Parsons TD, 2014, J NEUROSCI METH, V222, P15, DOI 10.1016/j.jneumeth.2013.10.006
   Parsons TD, 2013, J CLIN EXP NEUROPSYC, V35, P812, DOI 10.1080/13803395.2013.824556
   Patchitt J., 2022, RELATIONSHIP VIRTUAL, DOI [10.3389/fnagi.2022.876832/full, DOI 10.3389/FNAGI.2022.876832/FULL]
   Plascencia-Villa G, 2020, INT REV NEUROBIOL, V154, P3, DOI 10.1016/bs.irn.2020.03.022
   Porffy LA, 2022, J MED INTERNET RES, V24, DOI 10.2196/27641
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Rönnlund M, 2005, PSYCHOL AGING, V20, P3, DOI 10.1037/0882-7974.20.1.3
   Rus-Calafell M, 2018, PSYCHOL MED, V48, P362, DOI 10.1017/S0033291717001945
   Ruse Stacy A, 2014, Schizophr Res Cogn, V1, pe21
   Sabbagh MN, 2019, ALZH DEMENT-TRCI, V5, P13, DOI 10.1016/j.trci.2018.11.004
   Salthouse TA, 2009, NEUROBIOL AGING, V30, P507, DOI 10.1016/j.neurobiolaging.2008.09.023
   Segawa T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01409
   Sevigny J, 2016, NATURE, V537, P50, DOI 10.1038/nature19323
   Sheehan DV, 1998, J CLIN PSYCHIAT, V59, P22, DOI 10.4088/JCP.09m05305whi
   Slater M, 2004, CYBERPSYCHOL BEHAV, V7, P121, DOI 10.1089/109493104322820200
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Spreij LA, 2022, NEUROPSYCHOL REHABIL, V32, P499, DOI 10.1080/09602011.2020.1831935
   US Food and Drug Administration, 2020, DDT COA 000107 VIR R
   Valmaggia LR, 2007, BRIT J PSYCHIAT, V191, pS63, DOI 10.1192/bjp.191.51.s63
   van der Linden WJ, 2006, J EDUC BEHAV STAT, V31, P181, DOI 10.3102/10769986031002181
   Wechsler D., 1999, WECHSLER ABBREVIATED
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wilson RS, 2002, PSYCHOL AGING, V17, P179, DOI 10.1037/0882-7974.17.2.179
   Wolf T. J., 2019, Functional cognition and occupational therapy: A practical approach to treating individuals with cognitive loss, DOI [DOI 10.7139/2017.978-1-56900-477-7, 10.7139/2017.978-1-56900-477-7]
NR 64
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 2
PY 2022
VL 3
AR 875197
DI 10.3389/frvir.2022.875197
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4TG3
UT WOS:001023200500001
OA Green Submitted, Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Brown, P
   Spronck, P
   Powell, W
AF Brown, Phillip
   Spronck, Pieter
   Powell, Wendy
TI The simulator sickness questionnaire, and the erroneous zero baseline
   assumption
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cybersickness; simulator sickness; SSQ; motion sickness; virtual
   reality; self report; baseline
ID VIRTUAL-REALITY; MOTION SICKNESS; CYBERSICKNESS; PAIN
AB Cybersickness assessment is predominantly conducted via the Simulator Sickness Questionnaire (SSQ). Literature has highlighted that assumptions which are made concerning baseline assessment may be incorrect, especially the assumption that healthy participants enter with no or minimal associated symptoms. An online survey study was conducted to explore further this assumption amongst a general population sample (N = 93). Results for this study suggest that the current baseline assumption may be inherently incorrect.
C1 [Brown, Phillip; Spronck, Pieter; Powell, Wendy] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
C3 Tilburg University
RP Brown, P (corresponding author), Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
EM p.c.brown@tilburguniversity.edu
OI Brown, Phillip/0000-0002-3775-8101; Powell, Wendy/0000-0002-7234-5628
FU Department of Cognitive Science and Artificial Intelligence at Tilburg
   University, Netherlands
FX & nbsp;This work was funded by the Department of Cognitive Science and
   Artificial Intelligence at Tilburg University, Netherlands.
CR Bahat HS, 2015, MANUAL THER, V20, P68, DOI 10.1016/j.math.2014.06.008
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   Bolte B., 2011, P VIRT REAL INT C VR
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Bouchard S, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.739742
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Brown P., 2021, CYBERPSYCHOLOGY, V25, P66
   Brown P, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.672245
   Bruck S, 2009, I C COMP GRAPH IM VI, P486, DOI 10.1109/CGIV.2009.83
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Cebeci B, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1893
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   CRONBACH LJ, 1970, PSYCHOL BULL, V74, P68, DOI 10.1037/h0029382
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davis S., 2015, 11 AUSTR C INT ENT I
   Edwards RR, 2001, J GERONTOL A-BIOL, V56, pM180, DOI 10.1093/gerona/56.3.M180
   Freeman D, 2008, BRIT J PSYCHIAT, V192, P258, DOI 10.1192/bjp.bp.107.044677
   Freitag S., 2018, 25 IEEE C VIRT REAL, DOI [10.1109/VR.2018.8447553, DOI 10.1109/VR.2018.8447553]
   Garcia L., 2021, JMIR, V10, P59, DOI [10.2196/25291, DOI 10.2196/25291]
   Garcia-Agundez A., 2019, IJVR, V19, P1, DOI DOI 10.20870/IJVR.2019.19.1.2907
   Garrett B, 2017, JMIR MED INF, V5, P17, DOI 10.2196/medinform.7271
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Golding JF, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.576871
   Helland A, 2016, ACCIDENT ANAL PREV, V94, P180, DOI 10.1016/j.aap.2016.05.008
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91573-w
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Knight M. M., 2006, ACM SIGGRAPH 2006 Res Posters, DOI [10.1145/1179622.1179846, DOI 10.1145/1179622.1179846]
   Kruk R. V., 1992, FLIGHT SIMULATION TE, DOI [10.2514/6.1992-4135, DOI 10.2514/6.1992-4135]
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lucas G, 2020, TRANSPORT RES F-TRAF, V68, P15, DOI 10.1016/j.trf.2019.11.011
   Magaki T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1072, DOI [10.1109/VR.2019.8797748, 10.1109/vr.2019.8797748]
   Mahrer NE, 2009, CURR PAIN HEADACHE R, V13, P100, DOI 10.1007/s11916-009-0019-8
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Mavridou I, 2018, PROCEEDINGS OF THE WORKSHOP ON HUMAN-HABITAT FOR HEALTH (H3'18): HUMAN-HABITAT MULTIMODAL INTERACTION FOR PROMOTING HEALTH AND WELL-BEING IN THE INTERNET OF THINGS ERA, DOI 10.1145/3279963.3279969
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Mostajeran F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83277-y
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Oberdörfer S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.679277
   Oberdörfer S, 2019, INT J COMPUT GAMES T, V2019, DOI 10.1155/2019/7626349
   Park JR, 2008, INT J NEUROSCI, V118, P857, DOI 10.1080/00207450701239459
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Qualtrics, 2005, QUALTRICS
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Recenti M, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.635661
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Spiegel B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219115
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stone W. B., 2017, PSYCHOMETRIC EVALUAT
   Tan C.T., 2015, P CHI PLAY 15, P253
   Tashjian VC, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7387
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wiederhold BK, 2014, CYBERPSYCH BEH SOC N, V17, P346, DOI 10.1089/cyber.2014.0207
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Young SD, 2006, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2006.44
   Zanbaka C, 2004, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2004.1310068
NR 70
TC 12
Z9 12
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 6
PY 2022
VL 3
AR 945800
DI 10.3389/frvir.2022.945800
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XA8
UT WOS:001023299400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Bremner, P
   Mitchell, TJ
   McIntosh, V
AF Bremner, Paul
   Mitchell, Thomas J.
   McIntosh, Verity
TI The impact of data sonification in virtual reality robot teleoperation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; teleoperation; sonification; presence; robotics;
   auditory display; digital twin; human robot interaction
AB Virtual Reality (VR) is being increasingly used to provide a more intuitive and embodied approach to robotic teleoperation, giving operators a sense of presence in the remote environment. Prior research has shown that presence can be enhanced when additional sensory cues such as sound are introduced. Data sonification is the use of non-speech audio to convey information and, in the context of VR robot teleoperation, it has the potential to 1) improve task performance by enhancing an operator's sense of presence and 2) reduce task load by spreading data between sensory modalities. Here we present a novel study methodology to investigate how the design of data sonification impacts on these important metrics and other key measures of user experience, such as stress. We examine a nuclear decommissioning application of robotic teleoperation where the benefits of VR in terms of spatial reasoning and task performance are desirable. However, as the operational environment is hazardous, a sense of presence may not be desirable as it can lead to heightened operator stress. We conduct a study in which we compare the effects of diegetic sounds (literal and established sonifications) with abstract sounds (non-established sonifications). Our findings show that the diegetic sounds decrease workload, whereas abstract sounds increase workload, and are more stressful. Additionally, and contrary to expectations, sonification does not impact presence. These findings have implications for the design of sonic environments in virtual reality.
C1 [Bremner, Paul] Univ West England, Bristol Robot Lab, Bristol, England.
   [Mitchell, Thomas J.] Univ West England, Creat Technol Lab, Bristol, England.
   [Mitchell, Thomas J.; McIntosh, Verity] Univ West England, Digital Cultures Res Ctr, Bristol, England.
   [McIntosh, Verity] Univ West England, Bristol VR Lab, Bristol, England.
C3 University of Bristol; University of West England; University of West
   England; University of West England; University of West England
RP McIntosh, V (corresponding author), Univ West England, Digital Cultures Res Ctr, Bristol, England.; McIntosh, V (corresponding author), Univ West England, Bristol VR Lab, Bristol, England.
EM verity.mcintosh@uwe.ac.uk
OI McIntosh, Verity/0000-0002-5529-2579
FU Robotics for Nuclear Environments (EPSRC) [EP/P01366X/1]; Isomorph (Apex
   Award) [APX/R1/180118]; University of the West of England VCIRCF;
   virtually there (TAS, UKRI); EPSRC [EP/P01366X/1] Funding Source: UKRI;
   UUI [AH/S002936/1] Funding Source: UKRI
FX This work was funded by the Robotics for Nuclear Environments (EPSRC
   grant number EP/P01366X/1), Isomorph (Apex Award Grant No.
   APX/R1/180118), the University of the West of England VCIRCF and
   virtually there (TAS, UKRI).
CR [Anonymous], 2007, P INT C AUD DISPL MO
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bramas Berenger, 2008, 2008 International Conference on Control, Automation and Systems (ICCAS), P2732, DOI 10.1109/ICCAS.2008.4694222
   Brewster S, 2002, PERS UBIQUIT COMPUT, V6, P188, DOI 10.1007/s007790200019
   Carlile S., 2011, The Sonification Handbook, P41
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Di GQ, 2016, APPL ACOUST, V105, P164, DOI 10.1016/j.apacoust.2015.12.006
   Droumeva M., 2006, P INT C AUD DISPL LO
   Dubus G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082491
   Ferguson J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174185
   Ferguson J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312988
   Frauenberger C, 2006, BCS CONF SERIES, P473, DOI 10.1007/1-84628-249-7_30
   Frid E, 2019, J MULTIMODAL USER IN, V13, P279, DOI 10.1007/s12193-018-0264-4
   Fuller A, 2020, IEEE ACCESS, V8, P108952, DOI 10.1109/ACCESS.2020.2998358
   García JC, 2017, IEEE COMPUT GRAPH, V37, P34, DOI 10.1109/MCG.2015.118
   Goudarzi V., 2015, P 21 INT C AUD DISPL
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Grond F, 2014, ORGAN SOUND, V19, P41, DOI 10.1017/S1355771813000393
   HART S G, 1988, P139
   Hermann T., 2011, The sonification handbook
   Hermann Thomas, 2003, P INT C AUDITORY DIS, P247
   Kelly Jonathan W., 2022, Frontiers in Virtual Reality, V3, P27
   Kramer Gregory, 2010, Sonification report: Status of the field and research agenda
   KRAMM G, 1994, AIR POLLUTION II, VOL 1: COMPUTER SIMULATION, P285
   Latupeirissa A. B., 2020, P SOUND MUS COMP C T, V2020, P434
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lokki T, 2005, IEEE MULTIMEDIA, V12, P80, DOI 10.1109/MMUL.2005.33
   MacDonald D., 2018, INT C AUDITORY DISPL, P145, DOI [10.21785/ICAD2018.009, DOI 10.21785/ICAD2018.009]
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   MEIJER PBL, 1992, IEEE T BIO-MED ENG, V39, P112, DOI 10.1109/10.121642
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Murray Janet H., 1997, Hamlet on the Holodeck: The Future of Narrative in Cyberspace
   Nunez D., 2004, P 3 INT C COMPUTER G, V1, P83, DOI DOI 10.1145/1029949.1029964
   Pirhonen A., 2006, P INT C AUD DISPL LO
   Plazak J, 2017, HEALTHC TECHNOL LETT, V4, P199, DOI 10.1049/htl.2017.0074
   Proulx MJ, 2014, NEUROSCI BIOBEHAV R, V41, P1, DOI 10.1016/j.neubiorev.2014.03.004
   Ratan R., 2012, IGI GLOB, P321, DOI [10.4018/978-1-4666-2211-1.ch018, DOI 10.4018/978-1-4666-2211-1.CH018]
   Robinson FA, 2021, 2021 16TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI, P53, DOI 10.1145/3434073.3444658
   Rubo M, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100111
   Rutherford E, 1908, P R SOC LOND A-CONTA, V81, P141, DOI 10.1098/rspa.1908.0065
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sauro Jef, 2011, A Practical Guide to the System Usability Scale: Background, Benchmarks, and Best Practices
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwarz M, 2017, J FIELD ROBOT, V34, P400, DOI 10.1002/rob.21677
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Sinclair P, 2012, AI SOC, V27, P173, DOI 10.1007/s00146-011-0346-2
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spiegel JS, 2018, SCI ENG ETHICS, V24, P1537, DOI 10.1007/s11948-017-9979-y
   Temperton J., 2016, INSIDE SELLAFIELD UK
   Triantafyllidis E, 2020, IEEE ACCESS, V8, P78213, DOI 10.1109/ACCESS.2020.2990080
   Vickers P., 2011, The Sonification Handbook, P455
   Walker BN, 2019, EBIOMEDICINE, V40, P176, DOI 10.1016/j.ebiom.2019.01.028
   Walker B. N., 2005, ACM Transactions on Applied Perception, V2, P407, DOI [10.1145/1101530.1101534, DOI 10.1145/1101530.1101534]
   Walker BN, 2002, J EXP PSYCHOL-APPL, V8, P211, DOI 10.1037/1076-898X/8.4.211
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zahray L, 2020, IEEE ROMAN, P978, DOI [10.1109/ro-man47096.2020.9223452, 10.1109/RO-MAN47096.2020.9223452]
   Zhang R., 2017, P 22 INT C AUD DISPL, P83, DOI [10.21785/icad2016.007, DOI 10.21785/ICAD2016.007]
NR 63
TC 4
Z9 4
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 23
PY 2022
VL 3
AR 904720
DI 10.3389/frvir.2022.904720
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XU8
UT WOS:001023319500001
OA gold
DA 2024-07-18
ER

PT J
AU Stuart, J
   Aul, K
   Stephen, A
   Bumbach, MD
   Lok, B
AF Stuart, Jacob
   Aul, Karen
   Stephen, Anita
   Bumbach, Michael D.
   Lok, Benjamin
TI The Effect of Virtual Human Rendering Style on User Perceptions of
   Visual Cues
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual human; rendering style; visual cue; augmented reality;
   photorealistic; conversational agent
ID COMMUNICATION
AB Introduction: Virtual humans have expanded the training opportunities available to healthcare learners. Particularly, virtual humans have allowed simulation to display visual cues that were not previously possible in other forms of healthcare training. However, the effect of virtual human fidelity on the perception of visual cues is unclear. Therefore, we explore the effect of virtual human rendering style on the perceptions of visual cues in a healthcare context.Methods: To explore the effect of rendering style on visual cues, we created a virtual human interface that allows users to interact with virtual humans that feature different rendering styles. We performed a mixed design user study that had undergraduate healthcare students (n = 107) interact with a virtual patient. The interaction featured a patient experiencing an allergic reaction and required trainees to identify visual cues (patient symptoms). The rendering styles explored include a 3D modeled virtual human and an AI generated photorealistic virtual human. Visual cues were applied using a Snapchat Lens.Results: When users are given a frame of reference (users could directly compare symptoms on both rendering styles), they rated the realism and severity of the photorealistic virtual human's symptoms significantly higher than the realism of the 3D virtual human's symptoms. However, we were unable to find significant differences in symptom realism and severity ratings when users were not given a frame of reference (users only interacted with one style of virtual humans). Additionally, we were unable to find significant differences in user interpersonal communication behaviors between the 3D and photorealistic rendering styles.Conclusion: Our findings suggest 1) higher fidelity rendering styles may be preferred if the learning objectives of a simulation require observing subtle visual cues on virtual humans and 2) the realism of virtual human rendering style does not necessarily affect participants' interpersonal communication behaviors (time spent, questions asked).
C1 [Stuart, Jacob; Lok, Benjamin] Univ Florida, Dept Comp & Informat Sci & Engn, Virtual Experiences Res Grp, Gainesville, FL 32611 USA.
   [Aul, Karen; Stephen, Anita; Bumbach, Michael D.] Univ Florida, Coll Nursing, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of Florida
RP Stuart, J (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Virtual Experiences Res Grp, Gainesville, FL 32611 USA.
EM jacobstuart@ufl.edu
OI Stuart, Jacob/0000-0003-2103-5782; Lok, Benjamin/0000-0002-1190-3729
CR Adobe, 2020, FUSE
   [Anonymous], 1992, Presence, DOI DOI 10.1162/PRES.1992.1.3.344
   [Anonymous], 2012, INT IND TRAIN SIM ED
   Blender Online Community, 2021, Blender-a 3D modelling and rendering package
   Brown SGA, 2004, J ALLERGY CLIN IMMUN, V114, P371, DOI 10.1016/j.jaci.2004.04.029
   Cendan J, 2012, ADV PHYSIOL EDUC, V36, P48, DOI 10.1152/advan.00054.2011
   Cordar A, 2017, P IEEE VIRT REAL ANN, P148, DOI 10.1109/VR.2017.7892242
   Daher S, 2020, SIMUL HEALTHC, V15, P115, DOI 10.1097/SIH.0000000000000409
   Daher S, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P99, DOI 10.1145/3267851.3267876
   Deladisma AM, 2009, AM J SURG, V197, P102, DOI 10.1016/j.amjsurg.2008.08.012
   Dieckmann Peter, 2007, Simul Healthc, V2, P183, DOI 10.1097/SIH.0b013e3180f637f5
   Eiris R, 2021, AUTOMAT CONSTR, V128, DOI 10.1016/j.autcon.2021.103754
   Flynn D, 2004, EUR J PSYCHOL ASSESS, V20, P49, DOI 10.1027/1015-5759.20.1.49
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Google, 2021, DialogflowIntegrations
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI [10.3389/frvir.2020.00002, DOI 10.3389/FRVIR.2020.00002]
   Houts PS, 2006, PATIENT EDUC COUNS, V61, P173, DOI 10.1016/j.pec.2005.05.004
   Huber BJ, 2022, NURSE EDUC PRACT, V59, DOI 10.1016/j.nepr.2021.103131
   KeenTools, 2021, FACEBUILDER
   Kognito, 2022, AT RISK MENT HLTH SI
   Kotranza A., 2010, J. Bioalgorithms Med-systems, V6, P25
   Kotranza A, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P99
   Kotranza A, 2009, IEEE T VIS COMPUT GR, V15, P369, DOI 10.1109/TVCG.2008.195
   Krasnoryadtseva A, 2020, PATIENT EDUC COUNS, V103, P556, DOI 10.1016/j.pec.2019.09.026
   Lok B, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.68
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Nanji KC, 2013, SIMUL HEALTHC, V8, P143, DOI 10.1097/SIH.0b013e31827d27f9
   Qualtrics, 2020, ABOUT US
   Rademacher P. M., 2003, MEASURING PERCEIVED
   Ring L, 2014, LECT NOTES ARTIF INT, V8637, P374, DOI 10.1007/978-3-319-09767-1_49
   Robinson MK, 1999, CONTACT DERMATITIS, V41, P65
   Shadow Health, 2022, HLTH ASS DIG CLIN EX
   Snap Inc, 2021, LENS STUD
   Sundar S.S., 2008, Digital media, youth, and credibility, P73, DOI 10.1162/dmal.9780262562324.073
   Synthesia.io, 2021, ABOUT US
   Vilaro MJ, 2020, PSYCHO-ONCOLOGY, V29, P2048, DOI 10.1002/pon.5538
   Volonte M, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P141, DOI 10.1145/3308532.3329461
   Volonte M, 2021, J MULTIMODAL USER IN, V15, P109, DOI 10.1007/s12193-020-00341-z
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Wang I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300511
   Watts PI, 2021, CLIN SIMUL NURS, V58, P14, DOI 10.1016/j.ecns.2021.08.009
   White C, 2015, J CONTIN EDUC HEALTH, V35, P158, DOI 10.1002/chp.21302
   Xu K, 2020, J COMPUT-MEDIAT COMM, V25, P32, DOI 10.1093/jcmc/zmz023
   Zalake M, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P73, DOI 10.1145/3308532.3329471
   Zell E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818126
   Zibrek K., 2014, P ACM S APPL PERCEPT, P111, DOI DOI 10.1145/2628257.2628270
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
NR 47
TC 6
Z9 6
U1 4
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 16
PY 2022
VL 3
AR 864676
DI 10.3389/frvir.2022.864676
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZO1
UT WOS:001019266700001
OA gold
DA 2024-07-18
ER

PT J
AU Yarossi, M
   Mangalam, M
   Naufel, S
   Tunik, E
AF Yarossi, Mathew
   Mangalam, Madhur
   Naufel, Stephanie
   Tunik, Eugene
TI Virtual Reality as a Context for Adaptation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; context learning; vestibulo-ocular reflex; optic flow;
   motor learning; sensorimotor transformation
ID HUMAN VESTIBULOOCULAR REFLEX; VISUOMOTOR TRANSFORMATIONS; MOTOR
   ADAPTATION; PRISM ADAPTATION; YOUNG-CHILDREN; OCULAR REFLEX;
   ENVIRONMENTS; MEMORY; FEAR; CEREBELLAR
AB The COVID-19 pandemic has accelerated interest in virtual reality (VR) for education, entertainment, telerehabilitation, and skills training. As the frequency and duration of VR engagement increases-the number of people in the United States using VR at least once per month is forecasted to exceed 95 million-it is critical to understand how VR engagement influences brain and behavior. Here, we evaluate neurophysiological effects of sensory conflicts induced by VR engagement and posit an intriguing hypothesis: the brain processes VR as a unique "context" leading to the formation and maintenance of independent sensorimotor representations. We discuss known VR-induced sensorimotor adaptations to illustrate how VR might manifest as a context for learning and how technological and human factors might mediate the context-dependency of sensorimotor representations learned in VR.
C1 [Yarossi, Mathew; Mangalam, Madhur; Tunik, Eugene] Northeastern Univ, Dept Phys Therapy Movement & Rehabil Sci, Boston, MA 02115 USA.
   [Yarossi, Mathew; Tunik, Eugene] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
   [Naufel, Stephanie] Facebook Real Labs Res, Menlo Pk, CA USA.
   [Tunik, Eugene] Northeastern Univ, Dept Bioengn, Boston, MA USA.
C3 Northeastern University; Northeastern University; Northeastern
   University
RP Yarossi, M (corresponding author), Northeastern Univ, Dept Phys Therapy Movement & Rehabil Sci, Boston, MA 02115 USA.; Yarossi, M (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
EM m.yarossi@northeastern.edu
FU Facebook;  [NIH-2R01NS085122];  [NIH-2R01HD058301];  [NSF-CBET-1804550];
    [NSF-CMMI-M3X-1935337]
FX The project was primarily funded by a research contract under Facebook's
   Sponsored Academic Research Agreement. The project was additionally
   supported in part by NIH-2R01NS085122 (ET), NIH-2R01HD058301 (ET),
   NSF-CBET-1804550 (ET), and NSF-CMMI-M3X-1935337 (ET and MY)
CR Affouneh S., 2020, INTERDISCIPLINARY J, V11, P135, DOI DOI 10.30476/IJVLMS.2020.86120.1033
   Aghajan ZM, 2015, NAT NEUROSCI, V18, P121, DOI 10.1038/nn.3884
   AIBA A, 1994, CELL, V79, P365, DOI 10.1016/0092-8674(94)90204-6
   Anglin JM, 2017, SCI REP-UK, V7, DOI 10.1038/srep45469
   Antoniadis EA, 2000, BEHAV BRAIN RES, V108, P1, DOI 10.1016/S0166-4328(99)00121-7
   Avraham G, 2021, PLOS BIOL, V19, DOI 10.1371/journal.pbio.3001147
   Bailey JO, 2017, COGNITIVE DEVELOPMENT IN DIGITAL CONTEXTS, P181, DOI 10.1016/B978-0-12-809481-5.00009-2
   BALOH RW, 1993, EXP BRAIN RES, V95, P509
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Bouton M.E., 2010, MIND CONTEXT, P233
   BOUTON ME, 1994, CURR DIR PSYCHOL SCI, V3, P49, DOI 10.1111/1467-8721.ep10769943
   Burguière E, 2005, NAT NEUROSCI, V8, P1292, DOI 10.1038/nn1532
   COLLEWIJN H, 1983, J PHYSIOL-LONDON, V340, P259, DOI 10.1113/jphysiol.1983.sp014762
   Monteiro CBD, 2014, RES DEV DISABIL, V35, P2430, DOI 10.1016/j.ridd.2014.06.006
   De Ponti R, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-02245-8
   DEMER JL, 1987, AVIAT SPACE ENVIR MD, V58, pA175
   Di Girolamo S, 2001, ACTA OTO-LARYNGOL, V121, P211
   DiZio P., 1992, PRESENCE, V1, P319, DOI [10.1162/pres.1992.1.3.319, DOI 10.1162/PRES.1992.1.3.319]
   Draper M., 1996, Can Your Eyes Make You Sick? Investigating the Relationship Between the Vestibulo-Ocular Reflex and Virtual Reality
   Draper M. H., 1998, THESIS AIR FORCE I T
   Ehrlich H, 2020, WORLD J SURG, V44, P2053, DOI 10.1007/s00268-020-05574-3
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133
   FLAVELL JH, 1990, J BROADCAST ELECTRON, V34, P399, DOI 10.1080/08838159009386752
   Fu QS, 2012, J NEUROSCI, V32, P15086, DOI 10.1523/JNEUROSCI.2468-12.2012
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   GAUTHIER GM, 1975, BRAIN RES, V92, P331, DOI 10.1016/0006-8993(75)90279-6
   Gimmon Y, 2018, J NEUROPHYSIOL, V120, P1496, DOI 10.1152/jn.00134.2018
   Glover S, 2001, EXP BRAIN RES, V137, P254, DOI 10.1007/s002210000651
   GONSHOR A, 1976, J PHYSIOL-LONDON, V256, P361, DOI 10.1113/jphysiol.1976.sp011329
   GONSHOR A, 1976, J PHYSIOL-LONDON, V256, P381, DOI 10.1113/jphysiol.1976.sp011330
   Gori M, 2008, CURR BIOL, V18, P694, DOI 10.1016/j.cub.2008.04.036
   Hegele M, 2010, CONSCIOUS COGN, V19, P906, DOI 10.1016/j.concog.2010.05.005
   Herdman SJ, 1998, OTOLARYNG HEAD NECK, V119, P49, DOI 10.1016/S0194-5998(98)70195-0
   Holloway R. L., 1995, THESIS U N CAROLINA
   Huang VS, 2011, NEURON, V70, P787, DOI 10.1016/j.neuron.2011.04.012
   Huberdeau DM, 2015, J NEUROPHYSIOL, V114, P969, DOI 10.1152/jn.00369.2015
   Ingram JN, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002196
   Ito M, 1998, TRENDS COGN SCI, V2, P313, DOI 10.1016/S1364-6613(98)01222-4
   Jones M.N., 2015, The Oxford Handbook of Computational and Mathematical Psychology, P232, DOI [10.1093/oxfordhb/9780199957996.013.11, DOI 10.1093/OXFORDHB/9780199957996.013.11]
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   Krakauer JW, 2005, J NEUROSCI, V25, P473, DOI 10.1523/JNEUROSCI.4218-04.2005
   Krakauer JW, 1999, NAT NEUROSCI, V2, P1026, DOI 10.1038/14826
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   Lee YY, 2019, J MOTOR BEHAV, V51, P121, DOI 10.1080/00222895.2018.1437020
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Lewis RF, 2003, EXP BRAIN RES, V152, P335, DOI 10.1007/s00221-003-1563-9
   Lonsdorf TB, 2017, NEUROSCI BIOBEHAV R, V77, P247, DOI 10.1016/j.neubiorev.2017.02.026
   Luaute J, 2009, J NEUROSCI, V29, P169, DOI 10.1523/JNEUROSCI.3054-08.2009
   Mantovani E, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00926
   Marchal-Crespo L, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00061
   Marchal-Crespo L, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00526
   Maren S, 2013, NAT REV NEUROSCI, V14, P417, DOI 10.1038/nrn3492
   Marschner A, 2008, J NEUROSCI, V28, P9030, DOI 10.1523/JNEUROSCI.1651-08.2008
   McDougle SD, 2015, J NEUROSCI, V35, P9568, DOI 10.1523/JNEUROSCI.5061-14.2015
   Micarelli A, 2019, ARCH GERONTOL GERIAT, V83, P246, DOI 10.1016/j.archger.2019.05.008
   Micarelli A, 2017, INT J REHABIL RES, V40, P325, DOI 10.1097/MRR.0000000000000244
   Miehlbradt J. C., 2020, BIORXIV
   Mistry S, 2004, MOTOR CONTROL, V8, P534, DOI 10.1123/mcj.8.4.534
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nardini M, 2014, CURR BIOL, V24, pR532, DOI 10.1016/j.cub.2014.04.034
   Neszmélyi B, 2019, HUM MOVEMENT SCI, V67, DOI 10.1016/j.humov.2019.102503
   ORNITZ EM, 1985, ACTA OTO-LARYNGOL, V100, P180, DOI 10.3109/00016488509104780
   PAIGE GD, 1991, EXP BRAIN RES, V84, P25
   Park JL, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00361
   Pears M, 2020, SCOT MED J, V65, P112, DOI 10.1177/0036933020956317
   Pregowska A, 2021, EDUC SCI, V11, DOI 10.3390/educsci11030118
   Ramos AA, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217074
   Redding GM, 2005, NEUROSCI BIOBEHAV R, V29, P431, DOI 10.1016/j.neubiorev.2004.12.004
   Redding GM, 2013, ATTEN PERCEPT PSYCHO, V75, P1168, DOI 10.3758/s13414-013-0467-4
   Richardson AE, 1999, MEM COGNITION, V27, P741, DOI 10.3758/BF03211566
   Richert RA, 2011, CHILD DEV, V82, P82, DOI 10.1111/j.1467-8624.2010.01542.x
   Richter S, 2004, PSYCHOL RES-PSYCH FO, V68, P245, DOI 10.1007/s00426-003-0140-y
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Rosas JM, 2013, WIRES COGN SCI, V4, P237, DOI 10.1002/wcs.1225
   Ruitenberg MFL, 2012, PSYCHOL RES-PSYCH FO, V76, P812, DOI 10.1007/s00426-011-0388-6
   Schubert MC, 2008, ARCH PHYS MED REHAB, V89, P500, DOI 10.1016/j.apmr.2007.11.010
   Schween R, 2018, J NEUROPHYSIOL, V120, P2775, DOI 10.1152/jn.00451.2018
   Sharar SR, 2007, ARCH PHYS MED REHAB, V88, pS43, DOI 10.1016/j.apmr.2007.09.004
   Sharoni Z, 2001, ANN OTO RHINOL LARYN, V110, P127, DOI 10.1177/000348940111000207
   Shelhamer M, 1992, J Vestib Res, V2, P89
   Sigala M, 2020, J BUS RES, V117, P312, DOI 10.1016/j.jbusres.2020.06.015
   Simons DJ, 1998, PSYCHOL SCI, V9, P315, DOI 10.1111/1467-9280.00062
   Singh RP, 2020, DIABETES METAB SYND, V14, P661, DOI 10.1016/j.dsx.2020.05.011
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   TAN HS, 1992, ANN NY ACAD SCI, V656, P158, DOI 10.1111/j.1749-6632.1992.tb25206.x
   Taylor JA, 2014, PROG BRAIN RES, V210, P217, DOI 10.1016/B978-0-444-63356-9.00009-1
   Taylor JA, 2014, J NEUROSCI, V34, P3023, DOI 10.1523/JNEUROSCI.3619-13.2014
   Taylor JA, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1001096
   Urcelay GP, 2014, BEHAV PROCESS, V104, P2, DOI 10.1016/j.beproc.2014.02.008
   Viirre E, 1996, IEEE ENG MED BIOL, V15, P41, DOI 10.1109/51.486717
   Viziano A, 2019, CLIN REHABIL, V33, P24, DOI 10.1177/0269215518788598
   Wang RXF, 1999, COGNITION, V70, P191
   Wang SSY, 2020, J PALLIAT MED, V23, P756, DOI 10.1089/jpm.2020.0212
   Wasserman EA, 1997, ANNU REV PSYCHOL, V48, P573, DOI 10.1146/annurev.psych.48.1.573
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Welch TDJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096440
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
   Wolpe N, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13034
   Yakushin SB, 2003, EXP BRAIN RES, V152, P137, DOI 10.1007/s00221-003-1543-0
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
   Zarahn E, 2008, J NEUROPHYSIOL, V100, P2537, DOI 10.1152/jn.90529.2008
NR 110
TC 2
Z9 2
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 18
PY 2021
VL 2
AR 733076
DI 10.3389/frvir.2021.733076
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OF8
UT WOS:001021697100001
OA gold
DA 2024-07-18
ER

PT J
AU Miller, MR
   Bailenson, JN
AF Miller, Mark Roman
   Bailenson, Jeremy N.
TI Social Presence Outside the Augmented Reality Field of View
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; field-of-view; unaugmented periphery; social
   presence; social facilitation; social inhibition
ID FACILITATION; METAANALYSIS
AB Augmented reality headsets in use today have a large area in which the real world can be seen, but virtual content cannot be displayed. Users perceptions of content in this area is not well understood. This work studies participants perception of a virtual character in this area by grounding this question in relevant theories of perception and performing a study using both behavioral and self-report measures. We find that virtual characters within the augmented periphery receive lower social presence scores, but we do notfind a difference in task performance. These findings inform application design and encourage future work in theories of AR perception and perception of virtual humans.
C1 [Miller, Mark Roman] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   [Bailenson, Jeremy N.] Stanford Univ, Dept Commun, Stanford, CA USA.
C3 Stanford University; Stanford University
RP Miller, MR (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM mrmillr@stanford.edu
FU National Science Foundation [1800922, 1839974]
FX Funding National Science Foundation, grants 1800922 and 1839974. The
   funders had no role in the study design, collection, analysis, or
   interpretation of the results.
CR Aiello JR, 2001, GROUP DYN-THEOR RES, V5, P163, DOI 10.1037//1089-2699.5.3.163
   [Anonymous], 2015, ROAD VR MICROSOFT HO
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Blascovich J, 2002, COMP SUPP COMP W SER, P127
   BOND CF, 1983, PSYCHOL BULL, V94, P265, DOI 10.1037/0033-2909.94.2.265
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dashiell JF, 1930, J ABNORM SOC PSYCH, V25, P190, DOI 10.1037/h0075144
   Gibson Js. J., 2019, PERCEPTION PSYCHOPHY, V5, P194, DOI [10.4324/9780367823771-19, DOI 10.4324/9780367823771-19]
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Hoyt CL, 2003, PRESENCE-TELEOP VIRT, V12, P183, DOI 10.1162/105474603321640932
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Kim Kangsoo, 2018, INT C ART REAL TEL E
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lee M, 2018, IEEE T VIS COMPUT GR, V24, P1525, DOI 10.1109/TVCG.2018.2794074
   Lee M, 2016, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2016.7504683
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   Michotte A., 1964, Les complements amodaux des structures perceptives
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Molenaar PCM, 2009, CURR DIR PSYCHOL SCI, V18, P112, DOI 10.1111/j.1467-8721.2009.01619.x
   Nosek BA, 2018, P NATL ACAD SCI USA, V115, P2600, DOI 10.1073/pnas.1708274114
   Park S, 2007, HUM FACTORS, V49, P1054, DOI 10.1518/001872007X249910
   Piaget J., 1954, La construction du reel chez l'enfant
   Ram N., 2013, OXFORD HDB QUANTITAT, V2, P441
   Scholl BJ, 1999, COGNITIVE PSYCHOL, V38, P259, DOI 10.1006/cogp.1998.0698
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Triplett N., 1898, American Journal of Psychology, V9, P507, DOI DOI 10.2307/1412188
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
   ZAJONC RB, 1965, SCIENCE, V149, P269, DOI 10.1126/science.149.3681.269
   Zanbaka C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1561
NR 29
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 7
PY 2021
VL 2
AR 656473
DI 10.3389/frvir.2021.656473
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AB0
UT WOS:001019279700001
OA gold
DA 2024-07-18
ER

PT J
AU Reiners, D
   Davahli, MR
   Karwowski, W
   Cruz-Neira, C
AF Reiners, Dirk
   Davahli, Mohammad Reza
   Karwowski, Waldemar
   Cruz-Neira, Carolina
TI The Combination of Artificial Intelligence and Extended Reality: A
   Systematic Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE artificial intelligence; extended reality; learning environment;
   autonomous cars; robotics
ID VIRTUAL-REALITY; SIMULATION; DIAGNOSIS; METRICS; GAME
AB Artificial intelligence (AI) and extended reality (XR) differ in their origin and primary objectives. However, their combination is emerging as a powerful tool for addressing prominent AI and XR challenges and opportunities for cross-development. To investigate the AI-XR combination, we mapped and analyzed published articles through a multi-stage screening strategy. We identified the main applications of the AI-XR combination, including autonomous cars, robotics, military, medical training, cancer diagnosis, entertainment, and gaming applications, advanced visualization methods, smart homes, affective computing, and driver education and training. In addition, we found that the primary motivation for developing the AI-XR applications include 1) training AI, 2) conferring intelligence on XR, and 3) interpreting XR- generated data. Finally, our results highlight the advancements and future perspectives of the AI-XR combination.
C1 [Reiners, Dirk; Cruz-Neira, Carolina] Univ Cent Florida, Dept Comp Sci, Orlando, FL USA.
   [Davahli, Mohammad Reza; Karwowski, Waldemar] Univ Cent Florida, Dept Ind Engn & Management Syst, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida; State
   University System of Florida; University of Central Florida
RP Davahli, MR (corresponding author), Univ Cent Florida, Dept Ind Engn & Management Syst, Orlando, FL 32816 USA.
EM mohammadreza.davahli@ucf.edu
RI Karwowski, Waldemar/B-2449-2012
OI Karwowski, Waldemar/0000-0002-9134-3441
CR Amini A, 2020, IEEE ROBOT AUTOM LET, V5, P1143, DOI 10.1109/LRA.2020.2966414
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bicakci S, 2020, SIMUL MODEL PRACT TH, V102, DOI 10.1016/j.simpat.2019.101993
   Bissonnette V, 2019, J BONE JOINT SURG AM, V101, DOI 10.2106/JBJS.18.01197
   Bousmalis K, 2018, IEEE INT CONF ROBOT, P4243
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   VanHorn KC, 2019, Arxiv, DOI arXiv:1906.05925
   Caudell Thomas P., 2003, Anatomical Record, V270B, P23, DOI 10.1002/ar.b.10007
   Cavazza M, 2000, APPL ARTIF INTELL, V14, P125, DOI 10.1080/088395100117188
   Chen PHC, 2019, NAT MED, V25, P1453, DOI 10.1038/s41591-019-0539-7
   Davahli MR, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010102
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Ershad M, 2018, INT J COMPUT ASS RAD, V13, P1037, DOI 10.1007/s11548-018-1738-2
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Forbes Technology Council, 2020, COUNC POST 15 EFF US
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gaidon A, 2016, PROC CVPR IEEE, P4340, DOI 10.1109/CVPR.2016.470
   Great Learning, 2020, WHAT IS ARTIFICIAL I
   Guerra W., 2019, ARXIV, DOI [10.1109/IROS40897.2019.8968116, DOI 10.1109/IROS40897.2019.8968116]
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Gutiérrez-Maldonado J, 2008, STUD COMPUT INTELL, V142, P497
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   Hilleli B., 2018, P AAAI C ART INT NEW
   Israelsen B, 2018, J AEROSP INFORM SYST, V15, P38, DOI 10.2514/1.I010553
   Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2
   Jog Amod, 2011, IEEE International Conference on Robotics and Automation, P5273
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Kerwin T, 2012, INT J COMPUT ASS RAD, V7, P1, DOI 10.1007/s11548-011-0566-4
   Koenig N., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2149
   Kopp S., 2003, KI, V17, P11
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurach K, 2020, AAAI CONF ARTIF INTE, V34, P4501
   Lamotte Oliver, 2010, Proceedings of the 2010 Second International Conference on Advances in System Simulation (SIMUL 2010), P28, DOI 10.1109/SIMUL.2010.19
   Latoschik ME, 2005, LECT NOTES COMPUT SC, V3638, P25
   Liang H, 2011, APPL MECH MATER, V40-41, P812, DOI 10.4028/www.scientific.net/AMM.40-41.812
   Liberati A, 2009, PLOS MED, V6, DOI [10.1371/journal.pmed.1000100, 10.7326/0003-4819-151-4-200908180-00136]
   Loukas C, 2011, IEEE T BIO-MED ENG, V58, P3289, DOI 10.1109/TBME.2011.2167324
   Marcus Gary, 2018, arXiv
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Megali G, 2006, IEEE T BIO-MED ENG, V53, P1911, DOI 10.1109/TBME.2006.881784
   Meissler N, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P152, DOI 10.1109/AIVR46125.2019.00031
   National Heart LungBlood Institute (NHLBI), 2019, Quality assessment tool for observational cohort and cross-sectional studies
   NEWELL A, 1958, PSYCHOL REV, V65, P151, DOI 10.1037/h0048495
   Richstone L, 2010, ANN SURG, V252, P177, DOI 10.1097/SLA.0b013e3181e464fb
   Ropelato S., 2018, International Series on Information Systems and Management in Creative EMedia (CreMedia), V2017, P12, DOI DOI 10.3929/ETHZ-B-000195951
   Sadeghi AH, 2021, JTCVS TECHNIQUES, V7, P309, DOI 10.1016/j.xjtc.2021.03.016
   Sadeghi F, 2018, PROC CVPR IEEE, P4691, DOI 10.1109/CVPR.2018.00493
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Santara A, 2020, Arxiv, DOI arXiv:2010.00993
   Sewell C, 2008, COMPUT AIDED SURG, V13, P63, DOI 10.3109/10929080801957712
   Shah S., 2017, Field and service robotics, DOI 10.1007/978-3-319-67361-5_40
   Shen BK, 2021, Arxiv, DOI arXiv:2012.02924
   Strodthoff N, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/aaf34d
   SZOLOVITS P, 1988, ANN INTERN MED, V108, P80, DOI 10.7326/0003-4819-108-1-80
   Talbot TB, 2012, INT J GAMING COMPUT-, V4, P1, DOI 10.4018/jgcms.2012070101
   Turan E, 2019, COMPUT STAND INTER, V66, DOI 10.1016/j.csi.2019.103361
   Wang Fei, 2019, Yearb Med Inform, V28, P16, DOI 10.1055/s-0039-1677908
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   WARNER HR, 1961, JAMA-J AM MED ASSOC, V177, P177, DOI 10.1001/jama.1961.03040290005002
   Weidenbach M, 2004, COMPUT BIOL MED, V34, P407, DOI 10.1016/S0010-4825(03)00084-2
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Yu KH, 2017, CELL SYST, V5, P620, DOI 10.1016/j.cels.2017.10.014
NR 62
TC 18
Z9 18
U1 9
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 7
PY 2021
VL 2
AR 721933
DI 10.3389/frvir.2021.721933
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TQ4
UT WOS:001021838700001
OA gold
DA 2024-07-18
ER

PT J
AU Wienrich, C
   Latoschik, ME
AF Wienrich, Carolin
   Latoschik, Marc Erich
TI eXtended Artificial Intelligence: New Prospects of Human-AI Interaction
   Research
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE human-artificial intelligence interface; human-artificial intelligence
   interaction; XR-artificial intelligence continuum; XR-artificial
   intelligence combination; research methods; human-centered; human-robot;
   recommender system
ID VIRTUAL-REALITY
AB Artificial Intelligence (AI) covers a broad spectrum of computational problems and use cases. Many of those implicate profound and sometimes intricate questions of how humans interact or should interact with AIs. Moreover, many users or future users do have abstract ideas of what AI is, significantly depending on the specific embodiment of AI applications. Human-centered-design approaches would suggest evaluating the impact of different embodiments on human perception of and interaction with AI. An approach that is difficult to realize due to the sheer complexity of application fields and embodiments in reality. However, here XR opens new possibilities to research human-AI interactions. The article's contribution is twofold: First, it provides a theoretical treatment and model of human-AI interaction based on an XR-AI continuum as a framework for and a perspective of different approaches of XR-AI combinations. It motivates XR-AI combinations as a method to learn about the effects of prospective human-AI interfaces and shows why the combination of XR and AI fruitfully contributes to a valid and systematic investigation of human-AI interactions and interfaces. Second, the article provides two exemplary experiments investigating the aforementioned approach for two distinct AI-systems. The first experiment reveals an interesting gender effect in human-robot interaction, while the second experiment reveals an Eliza effect of a recommender system. Here the article introduces two paradigmatic implementations of the proposed XR testbed for human-AI interactions and interfaces and shows how a valid and systematic investigation can be conducted. In sum, the article opens new perspectives on how XR benefits human-centered AI design and development.
C1 [Wienrich, Carolin] Univ Wurzburg, Human Technol Syst Grp, Wurzburg, Germany.
   [Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Wienrich, C (corresponding author), Univ Wurzburg, Human Technol Syst Grp, Wurzburg, Germany.
EM carolin-wienrich@uni.wuerzburg.de
FU Open-Access Publication Fund of the University of Wuerzburg
FX This publications was supported by the Open-Access Publication Fund of
   the University of Wuerzburg.
CR [Anonymous], 2008, P ACM VRST 2008
   [Anonymous], 1982, BLADE RUNNER LADD CO
   Antakli A, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P319, DOI 10.1145/3267851.3267867
   Aragon SR., 2003, New Directions for Adult and Continuing Education, V100, P57, DOI [DOI 10.1002/ACE.119, 10.1002/ace.119, 10.1002/ACE.119]
   Azmandian M, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P16, DOI 10.1145/3308532.3329436
   Bailenson Jeremy N., 2004, Proceedings of the 7th Annual International Workshop on PRESENCE, P1864
   Bar N., 2011, REFLEXIONEN VISIONEN, P627
   Bawden D., 2008, Digital literacies: Concepts, policies and practices, P17
   Bickmore Timothy, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P68, DOI 10.1007/978-3-642-40415-3_6
   Biocca F, 1999, HUM FAC INF, V13, P113, DOI 10.1016/S0923-8433(99)80011-2
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Blascovich J, 2002, COMP SUPP COMP W SER, P127
   Bombari D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00869
   Cameron J., 1984, TERMINATOR HENDALE F
   Carolus A., 2019, CLOSE DO YOU FEED YO, DOI [10.18420/muc2019-ws-652, DOI 10.18420/MUC2019-WS-652]
   Carolus A, 2019, NEW MEDIA SOC, V21, P914, DOI 10.1177/1461444818817074
   Carpenter J., 1974, DARK STAR JH HARRIS, DOI [10.5962/bhl.title.84512, DOI 10.5962/BHL.TITLE.84512]
   Cavazza M., 2007, P 15 ACM INT C MULT, P651, DOI DOI 10.1145/1291233.1291387
   Clarke Arthur C., 1962, Profiles of the Future: An Inquiry into the Limits of the Possible
   Congdon S. P., 2002, 43 ANN M PSYCH SOC
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   DiSessa Andrea A, 2001, Changing minds: Computers, learning, and literacy
   Fan L, 2017, LECT NOTES ARTIF INT, V10498, P129, DOI 10.1007/978-3-319-67401-8_15
   Field A., 2009, Discovering statistics with SPSS, V3rd
   Fischbach M, 2017, IEEE T VIS COMPUT GR, V23, P1407, DOI 10.1109/TVCG.2017.2657098
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   Fitrianie S, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423873
   Fraser J, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P179, DOI 10.1145/3267851.3267896
   Gall D., 2018, P 25 IEEE VIRT REAL, DOI [10.1109/vr.2018.8446153, DOI 10.1109/VR.2018.8446153]
   HART S G, 1988, P139
   Hassenzahl M, 2015, INT J HUM-COMPUT INT, V31, P530, DOI 10.1080/10447318.2015.1064664
   Hassenzahl M, 2010, HUM-COMPUT INTERACT, V25, P235, DOI 10.1080/07370024.2010.500139
   Hatfield E, 1992, Review of Personality and Social Psychology, V14, P151
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   Huta V, 2016, INT HANDB QUALITY, P215, DOI 10.1007/978-3-319-42445-3_15
   Jonas Klaus, 2014, SOZIALPSYCHOLOGIE, V6
   Kelley PG, 2021, Arxiv, DOI arXiv:2001.00081
   Kistler F, 2012, J MULTIMODAL USER IN, V6, P39, DOI 10.1007/s12193-011-0087-z
   Kubrick Stanley, 2001, A space odyssey
   Kuhlen AK, 2013, PSYCHON B REV, V20, P54, DOI 10.3758/s13423-012-0341-8
   Kulms P, 2016, LECT NOTES ARTIF INT, V10011, P75, DOI 10.1007/978-3-319-47665-0_7
   Latoschik M. E., 1998, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop Proceedings, P185
   Latoschik M.E., 2005, Proceedings of the 7th international conference on Multimodal interfaces (ICMI), P76
   Latoschik M. E., 2014, INFORM SPEKTRUM, V37, P36, DOI [10.1007/s00287-013-0759-z, DOI 10.1007/S00287-013-0759-Z]
   Latoschik M. E., 2017, 23 ACM S VIRT REAL S, p39:1
   Latoschik ME, 2022, Arxiv, DOI arXiv:2104.04846
   Lieberman H, 1996, COMMUN ACM, V39, P38, DOI 10.1145/232014.232026
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   Luck M, 2000, APPL ARTIF INTELL, V14, P3, DOI 10.1080/088395100117142
   Mattar N, 2015, LECT NOTES ARTIF INT, V9238, P356, DOI 10.1007/978-3-319-21996-7_39
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nass C, 2000, COMMUN ACM, V43, P36, DOI 10.1145/348941.348976
   Nomura T, 2006, INTERACT STUD, V7, P437, DOI 10.1075/is.7.3.14nom
   Obaid Mohammad, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P412, DOI 10.1007/978-3-642-33197-8_42
   Ospina-Bohórquez A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13084326
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Pham DT, 1998, INT J MACH TOOL MANU, V38, P1257, DOI 10.1016/S0890-6955(97)00137-5
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Razzouk R, 2012, REV EDUC RES, V82, P330, DOI 10.3102/0034654312457429
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Rieser V, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P5, DOI 10.1145/3308532.3337712
   Russell S., 2020, ARTIF INTELL
   Schreier J., 2012, ROBOT FRANK STAGE 6
   Scott R., 1979, ALIEN BRANDYWINE PRO, DOI [10.6028/nbs.sp.480-12, DOI 10.6028/NBS.SP.480-12]
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sterna R, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P123, DOI 10.1109/VRW52623.2021.00030
   Strathmann C, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423906
   Terry L. R., 2007, J DISTANCE ED, V14, P1
   Topál J, 2008, SCIENCE, V321, P1831, DOI 10.1126/science.1161437
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wardrip-Fruin N., 2001, DIGIT HUMANIT, V1
   Wienrich Carolin, 2020, i-com: Journal of Interactive Media, V19, P103, DOI 10.1515/icom-2020-0008
   Wienrich C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P207, DOI 10.1109/VR.2018.8446575
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Wienrich C, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.685250
   Wienrich C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P191, DOI 10.1109/VR.2018.8446352
   Yan X, 1996, COMPUT AIDED DESIGN, V28, P307, DOI 10.1016/0010-4485(95)00035-6
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zhang B., 2019, SSRN Electronic Journal, DOI [10.2139/ssrn.3312874, DOI 10.2139/SSRN.3312874]
   Zhang H, 2010, LECT NOTES ARTIF INT, V6356, P49, DOI 10.1007/978-3-642-15892-6_6
   Zimmerer Chris, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2040081
   Zimmerer C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P745, DOI 10.1109/VR.2018.8446151
NR 85
TC 7
Z9 7
U1 12
U2 27
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 6
PY 2021
VL 2
AR 686783
DI 10.3389/frvir.2021.686783
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PO5
UT WOS:001021732000001
OA gold, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Wienrich, C
   Döllinger, N
   Hein, R
AF Wienrich, Carolin
   Doellinger, Nina
   Hein, Rebecca
TI Behavioral Framework of Immersive Technologies (BehaveFIT): How and Why
   Virtual Reality can Support Behavioral Change Processes
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive technologies; behavior change; intervention design;
   intervention evaluation; framework; virtual reality;
   intention-behavior-gap; human-computer interaction
ID EXPOSURE THERAPY; SELF-EFFICACY; HEALTH; EMBODIMENT; ENVIRONMENTS; BODY
AB The design and evaluation of assisting technologies to support behavior change processes have become an essential topic within the field of human-computer interaction research in general and the field of immersive intervention technologies in particular. The mechanisms and success of behavior change techniques and interventions are broadly investigated in the field of psychology. However, it is not always easy to adapt these psychological findings to the context of immersive technologies. The lack of theoretical foundation also leads to a lack of explanation as to why and how immersive interventions support behavior change processes. The Behavioral Framework for immersive Technologies (BehaveFIT) addresses this lack by 1) presenting an intelligible categorization and condensation of psychological barriers and immersive features, by 2) suggesting a mapping that shows why and how immersive technologies can help to overcome barriers and finally by 3) proposing a generic prediction path that enables a structured, theory-based approach to the development and evaluation of immersive interventions. These three steps explain how BehaveFIT can be used, and include guiding questions for each step. Further, two use cases illustrate the usage of BehaveFIT. Thus, the present paper contributes to guidance for immersive intervention design and evaluation, showing that immersive interventions support behavior change processes and explain and predict 'why' and 'how' immersive interventions can bridge the intention-behavior-gap.
C1 [Wienrich, Carolin; Doellinger, Nina; Hein, Rebecca] Julius Maximilian Univ Wurzburg, Human Tech Syst, Wurzburg, Germany.
C3 University of Wurzburg
RP Wienrich, C (corresponding author), Julius Maximilian Univ Wurzburg, Human Tech Syst, Wurzburg, Germany.
EM carolin.wienrich@uni-wuerzburg.de
OI Dollinger, Nina/0000-0002-0609-8841
FU Open Access Publication Fund of the University of Wuerzburg; German
   Federal Ministry of Education and Research in the project ViTraS
   [16SV8219]
FX This publication was supported by the Open Access Publication Fund of
   the University of Wuerzburg. This research has been funded by the German
   Federal Ministry of Education and Research in the project ViTraS
   (project number 16SV8219).
CR Ahn SJ, 2019, MEDIA PSYCHOL, V22, P626, DOI 10.1080/15213269.2018.1492939
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Ahn SJ, 2015, COMMUN RES, V42, P839, DOI 10.1177/0093650214534973
   Ahn SJ, 2014, COMPUT HUM BEHAV, V39, P235, DOI 10.1016/j.chb.2014.07.025
   Ajzen I, 2011, PSYCHOL HEALTH, V26, P1113, DOI 10.1080/08870446.2011.613995
   [Anonymous], 2016, Interactions, DOI DOI 10.1145/2907069
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   [Anonymous], 2003, Observing the user experience: A practitioner's guide to user research
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   BECKER MH, 1975, MED CARE, V13, P10, DOI 10.1097/00005650-197501000-00002
   Biocca F., 2002, Proc. Presence, V2002, P1, DOI DOI 10.1.1.84.8350
   Biocca F., 2003, GUIDE NETWORKED MIND, P1
   Blake J., 1999, Local Environment, V4, P257, DOI [DOI 10.1080/13549839908725599, https://doi.org/10.1080/13549839908725599]
   Bolger N, 2019, APPL PSYCHOL-HLTH WE, V11, P198, DOI 10.1111/aphw.12159
   Bridle C, 2005, PSYCHOL HEALTH, V20, P283, DOI 10.1080/08870440512331333997
   Byrne M, 2020, HEALTH PSYCHOL REV, V14, P165, DOI 10.1080/17437199.2019.1707106
   Cane J, 2012, IMPLEMENT SCI, V7, DOI 10.1186/1748-5908-7-37
   Carrington MJ, 2010, J BUS ETHICS, V97, P139, DOI 10.1007/s10551-010-0501-6
   Davis R, 2015, HEALTH PSYCHOL REV, V9, P323, DOI 10.1080/17437199.2014.941722
   De Kort Y. A., 2007, P PRESENCE, P1
   Ferrari R., 2015, REV GEN PSYCHOL, V24, P230, DOI [DOI 10.1037/1089-2680.1.3.311, 10.1179/2047480615Z.000000000329, DOI 10.1179/2047480615Z.000000000329, https://doi.org/10.1179/2047480615Z.000000000329]
   Fishbein M., 1980, UNDERSTANDING ATTITU
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Gifford R., 2018, Psychology and Climate Change: Human Perceptions, Impacts, and Responses, P161, DOI DOI 10.1016/B978-0-12-813130-5.00006-0
   Gollwitzer P. M., 1996, The psychology of action: Linking cognition and motivation to behavior
   Hassenzahl M, 2010, INTERACT COMPUT, V22, P353, DOI 10.1016/j.intcom.2010.04.002
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Holtzblatt K, 2017, CONTEXTUAL DESIGN: DESIGN FOR LIFE, 2ND EDITION, P43, DOI 10.1016/B978-0-12-800894-2.00003-X
   Hsu WC, 2018, EDUC TECHNOL SOC, V21, P187
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim SY, 2014, COMPUT HUM BEHAV, V36, P376, DOI 10.1016/j.chb.2014.03.067
   Klasnja P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3063
   Kollmuss Anja., 2002, Environmental Education Research, V8, P239, DOI [10.1080/13504620220145401, DOI 10.1080/13504620220145401, https://doi.org/10.1080/13504620220145401]
   Kuo P.-Y., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA'15, P207
   MARCUS BH, 1992, RES Q EXERCISE SPORT, V63, P60, DOI 10.1080/02701367.1992.10607557
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Michie S, 2014, The behaviour change wheel. A guide to designing interventions, P1003
   Michie S, 2013, ANN BEHAV MED, V46, P81, DOI 10.1007/s12160-013-9486-6
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Prochaska JO, 1997, AM J HEALTH PROMOT, V12, P38, DOI 10.4278/0890-1171-12.1.38
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Rothman AJ, 2019, APPL PSYCHOL-HLTH WE, V11, P191, DOI 10.1111/aphw.12158
   Scholz U, 2019, APPL PSYCHOL-HLTH WE, V11, P173, DOI 10.1111/aphw.12156
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwarzer R., 2014, Self-efficacy: Thought control of action
   Sheeran P., 2002, EUR REV SOC PSYCHOL, V12, P1, DOI [10.1080/14792772143000003, DOI 10.1080/14792772143000003, https://doi.org/10.1080/14792772143000003]
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Soliman M, 2017, J MEDIA PSYCHOL-GER, V29, P8, DOI 10.1027/1864-1105/a000213
   Stawarz K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2653, DOI 10.1145/2702123.2702230
   Verplanken B, 2003, J APPL SOC PSYCHOL, V33, P1313, DOI 10.1111/j.1559-1816.2003.tb01951.x
   Whitmarsh L, 2009, J ENVIRON PSYCHOL, V29, P13, DOI 10.1016/j.jenvp.2008.05.003
   Wienrich Carolin, 2020, i-com: Journal of Interactive Media, V19, P103, DOI 10.1515/icom-2020-0008
   Wienrich C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P207, DOI 10.1109/VR.2018.8446575
   Wilson TE, 2020, HEALTH PSYCHOL REV, V14, P66, DOI 10.1080/17437199.2019.1706615
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 62
TC 26
Z9 26
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 24
PY 2021
VL 2
AR 627194
DI 10.3389/frvir.2021.627194
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TF1
UT WOS:001021827400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Hoffman, HG
   Patterson, DR
   Rodriguez, RA
   Pena, R
   Beck, W
   Meyer, WJ
AF Hoffman, Hunter G.
   Patterson, David R.
   Rodriguez, Robert A.
   Pena, Raquel
   Beck, Wanda
   Meyer, Walter J.
TI Virtual Reality Analgesia for Children With Large Severe Burn Wounds
   During Burn Wound Debridement
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; pain; pediatric burn injuries; analgesia; burn; opioid
ID ADJUNCTIVE PAIN-CONTROL; PHYSICAL-THERAPY; DISTRACTION; MECHANISMS;
   MANAGEMENT; MAGNITUDE; PATIENT; HELMET; TRIALS; MOTION
AB The objective of this study was to compare the effect of adjunctive virtual reality vs. standard analgesic pain medications during burn wound cleaning/debridement. Participants were predominantly Hispanic children aged 6-17 years of age, with large severe burn injuries (TBSA = 44%) reporting moderate or higher baseline pain during burn wound care. Using a randomized between-groups design, participants were randomly assigned to one of two groups, (a) the Control Group = pain medications only or (b) the VR Group = pain medications + virtual reality. A total of 50 children (88% Hispanic) with large severe burns (mean TBSA > 10%) received severe burn wound cleaning sessions. For the primary outcome measure of worst pain (intensity) on Study Day 1, using a between groups ANOVA, burn injured children in the group that received virtual reality during wound care showed significantly less pain intensity than the No VR control group, [mean worst pain ratings for the No VR group = 7.46 (SD = 2.93) vs. 5.54 (SD = 3.56), F-(1,F-48) = 4.29, < 0.05, MSE = 46.00]. Similarly, one of the secondary pain measures, "lowest pain during wound care" was significantly lower in the VR group, No VR = 4.29 (SD = 3.75) vs. 1.68 (2.04) for the VR group, F-(1,F-47) = 9.29, <0.005, MSE = 83.52 for Study Day 1. The other secondary pain measures showed the predicted pattern on Study Day 1, but were non-significant. Regarding whether VR reduced pain beyond Study Day 1, absolute change in pain intensity (analgesia = baseline pain minus the mean of the worst pain scores on Study days 1-10) was significantly greater for the VR group, F-(1,F-48) = 4.88, p < 0.05, MSE = 34.26, partial eta squared = 0.09, but contrary to predictions, absolute change scores were non-significant for all secondary measures.
C1 [Hoffman, Hunter G.] Univ Washington, Coll Engn, Dept Mech Engn, Seattle, WA 98195 USA.
   [Hoffman, Hunter G.] Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
   [Hoffman, Hunter G.; Meyer, Walter J.] Univ Washington, Dept Radiol, Seattle, WA 98195 USA.
   [Patterson, David R.] Univ Washington, Dept Rehabil Med, Seattle, WA USA.
   [Rodriguez, Robert A.; Pena, Raquel; Meyer, Walter J.] Univ Texas Med Branch Galveston, Galveston, TX USA.
   [Rodriguez, Robert A.; Pena, Raquel; Beck, Wanda; Meyer, Walter J.] Shriners Hosp Children Galveston, Galveston, TX USA.
C3 University of Washington; University of Washington Seattle; University
   of Washington; University of Washington Seattle; University of
   Washington; University of Washington Seattle; University of Washington;
   University of Washington Seattle; University of Texas System; University
   of Texas Medical Branch Galveston
RP Hoffman, HG (corresponding author), Univ Washington, Coll Engn, Dept Mech Engn, Seattle, WA 98195 USA.; Hoffman, HG (corresponding author), Univ Washington, Dept Psychol, Seattle, WA 98195 USA.; Hoffman, HG (corresponding author), Univ Washington, Dept Radiol, Seattle, WA 98195 USA.
EM hoontair@gmail.com
RI Peña, Raquel/JFA-1159-2023
FU NIH [R01GM042725]; MayDay Fund
FX This research was funded by an NIH grant R01GM042725 to DP with help
   from a charitable donation from the MayDay Fund (PI WM and HH).
CR Al-Ghamdi NA, 2020, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00467
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02508
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02265
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Ballantyne JC, 2018, PAIN, V159, pS24, DOI 10.1097/j.pain.0000000000001270
   Berterame S, 2016, LANCET, V387, P1644, DOI 10.1016/S0140-6736(16)00161-6
   Birnie KA, 2017, PAIN, V158, P1012, DOI 10.1097/j.pain.0000000000000913
   Bittner EA, 2015, ANESTHESIOLOGY, V122, P448, DOI 10.1097/ALN.0000000000000559
   Bloemink B., 2006, Design life now: national design triennial 2006
   Carrougher GJ, 2009, J BURN CARE RES, V30, P785, DOI 10.1097/BCR.0b013e3181b485d3
   Chen QS, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2018.7621
   Cherny N, 2001, J CLIN ONCOL, V19, P2542, DOI 10.1200/JCO.2001.19.9.2542
   Clark A, 2017, BURNS TRAUMA, V5, DOI 10.1186/s41038-017-0076-x
   Dahlquist LM, 2007, HEALTH PSYCHOL, V26, P794, DOI 10.1037/0278-6133.26.6.794
   Davis MP, 2018, AM J HOSP PALLIAT ME, V35, P1118, DOI 10.1177/1049909118771374
   Dunwoody DR, 2018, NURS FORUM, V53, P399, DOI 10.1111/nuf.12266
   Eccleston C, 1999, PSYCHOL BULL, V125, P356, DOI 10.1037/0033-2909.125.3.356
   Ehde DM, 1999, BURNS, V25, P587, DOI 10.1016/S0305-4179(99)00050-9
   Faber AW, 2013, J BURN CARE RES, V34, P563, DOI 10.1097/BCR.0b013e3182777904
   Fields HL, 2018, PAIN, V159, pS3, DOI 10.1097/j.pain.0000000000001272
   Firoozabadi R, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.553492
   Garrett B, 2014, CLIN J PAIN, V30, P1089, DOI 10.1097/AJP.0000000000000064
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gold JI, 2018, J PEDIATR PSYCHOL, V43, P266, DOI 10.1093/jpepsy/jsx129
   Gold JI, 2006, CYBERPSYCHOL BEHAV, V9, P207, DOI 10.1089/cpb.2006.9.207
   Harris K, 2007, CLIN ONCOL-UK, V19, P523, DOI 10.1016/j.clon.2007.04.007
   Hemington KS, 2017, J PAIN, V18, P1117, DOI 10.1016/j.jpain.2017.04.009
   Herndon D., 2002, TOTAL BURN CARE, V2nd
   Hoffman H. G., 1998, Virtual Reality, V3, P226, DOI 10.1007/BF01408703
   Hoffman H. G., 2019, Virtual reality for psychological and neurocognitive interventions. Virtual reality Technologies for Health and clinical applications, P195, DOI DOI 10.1007/978-1-4939-9482-3_8
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Hoffman HG, 2004, J CLIN PSYCHOL, V60, P189, DOI 10.1002/jclp.10244
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Hoffman HG, 2020, J HAND THER, V33, P254, DOI 10.1016/j.jht.2020.04.001
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Hoffman HG, 2014, CYBERPSYCH BEH SOC N, V17, P397, DOI 10.1089/cyber.2014.0058
   Hoffman HG, 2011, ANN BEHAV MED, V41, P183, DOI 10.1007/s12160-010-9248-7
   Hoffman HG, 2009, CYBERPSYCHOL BEHAV, V12, P47, DOI 10.1089/cpb.2008.0056
   Houle Sherilyn, 2015, Can J Hosp Pharm, V68, P28
   IBM SPSS, 2019, STAT 26 0
   Jeffs D, 2014, J BURN CARE RES, V35, P395, DOI 10.1097/BCR.0000000000000019
   Jensen M.P., 2001, HDB PAIN ASSESSMENT, V2nd, P15
   Jensen MP, 2003, J PAIN, V4, P2, DOI 10.1054/jpai.2003.1
   Kahneman D., 1973, Attention and effort
   Keefe FJ, 2018, PHYS THER, V98, P398, DOI 10.1093/ptj/pzy024
   Keefe FJ, 2012, PAIN, V153, P2163, DOI 10.1016/j.pain.2012.05.030
   Khadra C, 2020, BURNS, V46, P1571, DOI 10.1016/j.burns.2020.04.006
   Kipping B, 2012, BURNS, V38, P650, DOI 10.1016/j.burns.2011.11.010
   Krane EJ, 2019, CLIN J PAIN, V35, P468, DOI 10.1097/AJP.0000000000000700
   Lang EV, 2002, RADIOLOGY, V222, P375, DOI 10.1148/radiol.2222010528
   Maani CV, 2011, J TRAUMA, V71, pS125, DOI 10.1097/TA.0b013e31822192e2
   Malchow RJ, 2008, CRIT CARE MED, V36, pS346, DOI 10.1097/CCM.0b013e31817e2fc9
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   McGhee LL, 2011, J BURN CARE RES, V32, P46, DOI 10.1097/BCR.0b013e318204b359
   McIntyre MK, 2016, BURNS, V42, P1161, DOI 10.1016/j.burns.2016.01.023
   McSherry T, 2018, J BURN CARE RES, V39, P278, DOI 10.1097/BCR.0000000000000589
   MELZACK R, 1990, SCI AM, V262, P27, DOI 10.1038/scientificamerican0290-27
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   Montgomery GH, 2000, INT J CLIN EXP HYP, V48, P138, DOI 10.1080/00207140008410045
   Nelson S, 2019, EUR J PAIN, V23, P421, DOI 10.1002/ejp.1319
   Noel M, 2015, PAIN, V156, P800, DOI 10.1097/j.pain.0000000000000102
   Peña R, 2020, ARCH PHYS MED REHAB, V101, pS26, DOI 10.1016/j.apmr.2017.10.023
   Prothero J., 1995, TR955 U WASH HUM INT
   Rainville P, 1997, SCIENCE, V277, P968, DOI 10.1126/science.277.5328.968
   Rainville P, 2002, CURR OPIN NEUROBIOL, V12, P195, DOI 10.1016/S0959-4388(02)00313-6
   Ratcliff SL, 2006, BURNS, V32, P554, DOI 10.1016/j.burns.2005.12.006
   Rosenberg L, 2015, J CLIN PSYCHIAT, V76, P1564, DOI 10.4088/JCP.14m09365
   Schulz KF, 2002, LANCET, V359, P696, DOI 10.1016/S0140-6736(02)07816-9
   Schwaller F, 2014, EUR J NEUROSCI, V39, P344, DOI 10.1111/ejn.12414
   SCOTT J, 1976, PAIN, V2, P175, DOI 10.1016/0304-3959(76)90113-5
   Sharar SR, 2007, ARCH PHYS MED REHAB, V88, pS43, DOI 10.1016/j.apmr.2007.09.004
   Sharar SR, 2016, GAMES HEALTH J, V5, P197, DOI 10.1089/g4h.2015.0046
   Sil S, 2014, J BEHAV MED, V37, P156, DOI 10.1007/s10865-012-9479-0
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Soltani M, 2018, REHABIL PSYCHOL, V63, P487, DOI 10.1037/rep0000239
   TESLER MD, 1991, RES NURS HEALTH, V14, P361, DOI 10.1002/nur.4770140507
   Trost Z, 2021, PAIN, V162, P325, DOI 10.1097/j.pain.0000000000002060
   Wender Regina, 2009, J Cyber Ther Rehabil, V2, P27
   Williamson A, 2005, J CLIN NURS, V14, P798, DOI 10.1111/j.1365-2702.2005.01121.x
   Wilson N, 2020, MMWR-MORBID MORTAL W, V69, P290, DOI 10.15585/mmwr.mm6911a4
NR 84
TC 22
Z9 23
U1 0
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 10
PY 2020
VL 1
AR 602299
DI 10.3389/frvir.2020.602299
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XJ6
UT WOS:001023308200001
PM 33585833
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Gonzalez-Franco, M
   Ofek, E
   Pan, Y
   Antley, A
   Steed, A
   Spanlang, B
   Maselli, A
   Banakou, D
   Pelechano, N
   Orts-Escolano, S
   Orvalho, V
   Trutoiu, L
   Wojcik, M
   Sanchez-Vives, MV
   Bailenson, J
   Slater, M
   Lanier, J
AF Gonzalez-Franco, Mar
   Ofek, Eyal
   Pan, Ye
   Antley, Angus
   Steed, Anthony
   Spanlang, Bernhard
   Maselli, Antonella
   Banakou, Domna
   Pelechano, Nuria
   Orts-Escolano, Sergio
   Orvalho, Veronica
   Trutoiu, Laura
   Wojcik, Markus
   Sanchez-Vives, Maria V. V.
   Bailenson, Jeremy
   Slater, Mel
   Lanier, Jaron
TI The Rocketbox Library and the Utility of Freely Available Rigged Avatars
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE avatars; virtual reality; augmented reality; rigging; animation; motion
   capture; blendshapes; Microsoft Rocketbox
ID VIRTUAL BODY OWNERSHIP; SELF-REPRESENTATION; ILLUSORY OWNERSHIP; RACIAL
   BIAS; EMBODIMENT; REALITY; HAND; PAIN; PERCEPTION; TIME
AB As part of the open sourcing of the Microsoft Rocketbox avatar library for research and academic purposes, here we discuss the importance of rigged avatars for the Virtual and Augmented Reality (VR, AR) research community. Avatars, virtual representations of humans, are widely used in VR applications. Furthermore many research areas ranging from crowd simulation to neuroscience, psychology, or sociology have used avatars to investigate new theories or to demonstrate how they influence human performance and interactions. We divide this paper in two main parts: the first one gives an overview of the different methods available to create and animate avatars. We cover the current main alternatives for face and body animation as well introduce upcoming capture methods. The second part presents the scientific evidence of the utility of using rigged avatars for embodiment but also for applications such as crowd simulation and entertainment. All in all this paper attempts to convey why rigged avatars will be key to the future of VR and its wide adoption.
C1 [Gonzalez-Franco, Mar; Ofek, Eyal; Antley, Angus; Steed, Anthony; Lanier, Jaron] Microsoft Res, Redmond, WA 98052 USA.
   [Pan, Ye] Disney Res, Los Angeles, CA USA.
   [Steed, Anthony] UCL, Comp Sci Dept, London, England.
   [Spanlang, Bernhard] Virtual Bodyworks SL, Barcelona, Spain.
   [Maselli, Antonella] CNR, Inst Cognit Sci & Technol, Rome, Italy.
   [Banakou, Domna; Slater, Mel] Univ Barcelona, Dept Psychol, Inst Neurosci, Barcelona, Spain.
   [Banakou, Domna; Slater, Mel] Univ Barcelona, EventLab, Barcelona, Spain.
   [Pelechano, Nuria] Univ Politecn Cataluna, Comp Sci Dept, Barcelona, Spain.
   [Orts-Escolano, Sergio] Google, Mountain View, CA USA.
   [Orvalho, Veronica] Univ Porto, Fac Ciencias, Porto, Portugal.
   [Orvalho, Veronica] Inst Telecomunicacoes, Porto, Portugal.
   [Orvalho, Veronica] Didimo Inc, Porto, Portugal.
   [Sanchez-Vives, Maria V. V.] Inst Invest Biomed August Pi i Sunyer, Barcelona, Spain.
   [Sanchez-Vives, Maria V. V.] Inst Catalana Recerca & Estudis Avancats, Barcelona, Spain.
   [Bailenson, Jeremy] Stanford Univ, Dept Commun, Stanford, CA USA.
C3 Microsoft; University of London; University College London; Consiglio
   Nazionale delle Ricerche (CNR); Istituto di Scienze e Tecnologie della
   Cognizione (ISTC-CNR); University of Barcelona; University of Barcelona;
   Universitat Politecnica de Catalunya; Google Incorporated; Universidade
   do Porto; Instituto de Telecomunicacoes; University of Barcelona;
   Hospital Clinic de Barcelona; IDIBAPS; ICREA; Stanford University
RP Gonzalez-Franco, M (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
EM margon@microsoft.com
RI Gonzalez-Franco, Mar/L-4994-2014; Sanchez-Vives, Maria/J-8526-2014
OI Ofek, Eyal/0000-0003-4750-1569; Steed, Anthony/0000-0001-9034-3020;
   Banakou, Domna/0000-0002-0974-6971; Sanchez-Vives,
   Maria/0000-0002-8437-9083
FU NEUROVIRTUAL-AGAUR [SGR 1296]; European Union [881712]; European
   Research Council Advanced Grant [742989]; Spanish Ministry of Economy,
   Industry and Competitiveness [TIN2017-88515-C2-1-R]
FX MS-V and MS are funded by NEUROVIRTUAL-AGAUR (2017 SGR 1296). MS-V and
   Virtual Bodyworks are also supported by the European Union's Rights,
   Equality and Citizenship Programme (2014-2020) under Grant Agreement:
   881712 (VRperGenere). DB and MS are supported by the European Research
   Council Advanced Grant MoTIVE #742989. NP was partly funded by the
   Spanish Ministry of Economy, Industry and Competitiveness under Grant
   No. TIN2017-88515-C2-1-R.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Ahuja K, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P453, DOI 10.1145/3332165.3347889
   Aitpayev K., 2012, ASIAN T FUNDAM ELECT, V1, P12
   Aneja D, 2018, IEEE WINT CONF APPL, P160, DOI 10.1109/WACV.2018.00024
   [Anonymous], 2020, Blender
   [Anonymous], 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, DOI DOI 10.1145/2503713.2503747
   [Anonymous], 2020, CATS
   [Anonymous], 2020, AD FUS
   [Anonymous], 2020, MAYA
   [Anonymous], 2020, MICR
   [Anonymous], 2020, BIN HYPRS
   [Anonymous], 2020, 3D STUD MAX
   [Anonymous], 2020, bbc
   [Anonymous], 2006, EUROGRAPHICS
   [Anonymous], 2017, AVATAR ASSEMBLED SOC
   [Anonymous], 2016, P 29 INT C COMPUTER, DOI DOI 10.1145/2915926.2915936
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   Aymerich-Franch L., 2012, Proceedings of the International Society for Presence Research Annual Conference, USA, P24
   Badler N.I., 1993, PRESENCE-VIRTUAL AUG, V2, P82, DOI 10.1162/pres.1993.2.1.82
   Bailenson Jeremy N, 2004, Berkshire Encyclopedia of Human-Computer Interaction, P64, DOI DOI 10.1108/095041206106853731
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14620-5
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Baumberg A., 2002, BRIT MACHINE VISION, P404
   Beacco A, 2016, COMPUT GRAPH FORUM, V35, P32, DOI 10.1111/cgf.12774
   Bedder RL, 2019, COGNITION, V184, P1, DOI 10.1016/j.cognition.2018.11.010
   Bem D. J., 1972, ADV EXPT SOCIAL PSYC, V6, P1, DOI [DOI 10.1016/S0065-2601(08)60024-6, 10.1016/S0065-2601(08)60024-6]
   Berger CC, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225172
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Blanchard C., 1990, Computer Graphics, V24, P35, DOI 10.1145/91394.91409
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Cannavò A, 2019, IEEE ACCESS, V7, P125463, DOI 10.1109/ACCESS.2019.2939427
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P95, DOI 10.1111/cgf.12403
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   de Borst Aline W, 2020, eNeuro, V7, DOI 10.1523/ENEURO.0263-19.2019
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Dou MS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130801
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Ehrsson H.H., 2012, HDB MULTISENSORY PRO, P775, DOI DOI 10.1126/SCIENCE.1097011
   Ehrsson HH, 2007, P NATL ACAD SCI USA, V104, P9828, DOI 10.1073/pnas.0610011104
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Falconer CJ, 2016, BJPSYCH OPEN, V2, P74, DOI 10.1192/bjpo.bp.115.002147
   Falconer CJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111933
   Feng Andrew, 2015, P 8 ACM SIGGRAPH C M, P57
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Folegatti A, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006920
   Friedman D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00943
   Frueh C, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085083
   Gal R, 2010, COMPUT GRAPH FORUM, V29, P479, DOI 10.1111/j.1467-8659.2009.01617.x
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gonzalez-Franco M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P941, DOI [10.1109/VR.2019.8798348, 10.1109/vr.2019.8798348]
   Gonzalez-Franco M, 2019, IEEE T HAPTICS, V12, P319, DOI 10.1109/TOH.2019.2925038
   Gonzalez-Franco M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209704
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Gonzalez-Franco M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00392
   González-Franco M, 2014, EXP BRAIN RES, V232, P875, DOI 10.1007/s00221-013-3800-1
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Graziano M. S., 2002, BRAIN REPRESENTS BOD
   Groom V, 2009, SOC INFLUENCE, V4, P231, DOI 10.1080/15534510802643750
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Ha Sehoon, 2011, 2011 ACM SIGGRAPH EU, P129, DOI DOI 10.1145/2019406.2019424
   Hamilton-Giachritsis C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21036-2
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Hu LW, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3130800.3130887, 10.1145/3130800.31310887]
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Joshi P., 2006, ACM Siggraph 2006 Courses, P17, DOI 10.1145/1185657.1185857
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kobbelt L, 2004, COMPUT GRAPH-UK, V28, P801, DOI 10.1016/j.cag.2004.08.009
   Körding KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Lanier J, 2001, SCI AM, V284, P66, DOI 10.1038/scientificamerican0401-66
   Lanier J., 1990, ARS ELECT, V2, P186
   Lasko-Harvill A., 1988, Digest of Papers: COMPCON Spring 88. Thirty-Third IEEE Computer Society International Conference (Cat. No.88CH2539-5), P536, DOI 10.1109/CMPCON.1988.4925
   Lee Yongjoon, 2010, Proc. ACMSIGGRAPH Papers, P1
   Lempitsky V., 2007, COMPUTER VISION PATT
   Lenggenhager B., 2010, ANALGESIC EFFECTS IL
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lewis JP, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Liu LB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201315
   Llobera J, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0300
   Llobera J, 2013, EXP BRAIN RES, V225, P105, DOI 10.1007/s00221-012-3352-9
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Loop C, 2016, INT CONF 3D VISION, P380, DOI 10.1109/3DV.2016.47
   López A, 2019, COMPUT GRAPH FORUM, V38, P181, DOI 10.1111/cgf.13629
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Luo LB, 2008, COMPUT ANIMAT VIRT W, V19, P271, DOI 10.1002/cav.238
   Ma YL, 2006, BEHAV RES METHODS, V38, P134, DOI 10.3758/BF03192758
   MacQuarrie A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P645, DOI [10.1109/VR.2019.8797852, 10.1109/vr.2019.8797852]
   Maister L, 2013, COGNITION, V128, P170, DOI 10.1016/j.cognition.2013.04.002
   Makin TR, 2008, BEHAV BRAIN RES, V191, P1, DOI 10.1016/j.bbr.2008.02.041
   Mancini F, 2011, PSYCHOL SCI, V22, P325, DOI 10.1177/0956797611398496
   Martini M, 2014, EUR J PAIN, V18, P1040, DOI 10.1002/j.1532-2149.2014.00451.x
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Martini M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00438
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Matamala-Gomez M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020291
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mölbert SC, 2018, PSYCHOL MED, V48, P642, DOI 10.1017/S0033291717002008
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Narang S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P91, DOI 10.1145/2993369.2993378
   Neyret S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62932-w
   Nierula B, 2021, J PHYSIOL-LONDON, V599, P2419, DOI 10.1113/JP278167
   Nierula B, 2017, J PAIN, V18, P645, DOI 10.1016/j.jpain.2017.01.003
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Orvalho Veronica., 2012, Eurographics (State of the Art Reports), P183
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Overbeck RS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275031
   Padrao G, 2016, NEUROIMAGE, V124, P147, DOI 10.1016/j.neuroimage.2015.08.022
   Pan X., 2011, P HCI 2011 25 BCS C, P46, DOI DOI 10.14236/EWIC/HCI2011.26
   Pan X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146837
   Pan XN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032931
   Pan Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P759, DOI [10.1109/VRW50115.2020.00-45, 10.1109/VRW50115.2020.00230]
   Pan Y, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1397, DOI 10.1145/2556288.2557276
   Pandey R, 2019, PROC CVPR IEEE, P9701, DOI 10.1109/CVPR.2019.00994
   Parger M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281529
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pelechano Nuria, 2011, International Journal of Virtual Reality, V10, P13
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechano N., 2016, SIMULATING HETEROGEN
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Phillips L, 2010, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2010.5444802
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   PoseVR, 2019, WALT DISN AN STUD
   Pujades S, 2019, IEEE T VIS COMPUT GR, V25, P1887, DOI 10.1109/TVCG.2019.2898748
   Ríos A, 2020, VIRTUAL REAL-LONDON, V24, P683, DOI 10.1007/s10055-020-00428-8
   Ríos A, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274513
   Roth D., 2019, VR Developer Gems, V1, P321, DOI [10.1201/b21598-17, DOI 10.1201/B21598-17]
   Roth D, 2016, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2016.7504760
   Rovira A, 2009, FRONT BEHAV NEUROSCI, V3, DOI 10.3389/neuro.08.059.2009
   Saito S., 2016, SIGGRAPH ASIA EMERGI, DOI [10.1145/2988240.3014572, DOI 10.1145/2988240.3014572]
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Salmanowitz N, 2018, J LAW BIOSCI, V5, P174, DOI 10.1093/jlb/lsy005
   Samad M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117178
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schroeder Ralph, 2012, The social life of avatars: Presence and interaction in shared virtual environments
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Seitz S.M., 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI 10.1109/CVPR.2006.19
   Serino A, 2006, ADV CONSC RES, V66, P323
   Shams L, 2010, TRENDS COGN SCI, V14, P425, DOI 10.1016/j.tics.2010.07.001
   Shiratori T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964926
   Shysheya A, 2019, PROC CVPR IEEE, P2382, DOI 10.1109/CVPR.2019.00249
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00091
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052766
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Thalmann D., 2007, CROWD SIMULATION, DOI [10.1002/9780470050118.ecse676, DOI 10.1002/9780470050118.ECSE676]
   Thorn J., 2016, P 24 ACM INT C MULTI, P147, DOI DOI 10.1145/2964284.2967200
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang L., 2001, Computer Vision and Pattern Recognition, pI
   Wang TC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073614
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Wei Y., 2019, ACM T GRAPHIC
   Wei Y., 2005, SIGGRAPH, DOI [10.1145/1187112.1187292, DOI 10.1145/1187112.1187292]
   Weng CY, 2019, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR.2019.00606
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, MEDIA PSYCHOL, V12, P195, DOI 10.1080/15213260902849943
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zhao MM, 2018, PROC CVPR IEEE, P7356, DOI 10.1109/CVPR.2018.00768
   Zhao MM, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P267, DOI 10.1145/3230543.3230579
   Zheng EH, 2018, FRONT NEUROROBOTICS, V12, DOI 10.3389/fnbot.2018.00047
   Zopf R, 2011, COGN NEUROSCI-UK, V2, P147, DOI 10.1080/17588928.2011.578208
NR 209
TC 64
Z9 68
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 3
PY 2020
VL 1
AR 561558
DI 10.3389/frvir.2020.561558
PG 23
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YG9
UT WOS:001023331700001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Fettrow, T
   DiBianca, S
   dos Santos, FV
   Reimann, H
   Jeka, J
AF Fettrow, Tyler
   DiBianca, Stephen
   Vanderlinde dos Santos, Fernando
   Reimann, Hendrik
   Jeka, John
TI Flexible Recruitment of Balance Mechanisms to Environmental Constraints
   During Walking
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; locomotion; dynamic balance; walking; obstacles
ID FOOT PLACEMENT; VISUAL CONTROL; LOCOMOTION; STRATEGY; ANXIETY; TESTS
AB Background: Humans need to actively control their upright posture during walking to avoid loss of balance. We do not have a comprehensive theory for how humans regulate balance during walking, especially in complex environments. The nervous system must process many aspects of the environment to produce an appropriate motor output in order to maintain balance on two legs. We have previously identified three balance mechanisms that young healthy adults use to maintain balance while walking: (1) The ankle roll mechanism, a modulation of ankle inversion/eversion; (2) The foot placement mechanism, a shift of the swing foot placement; and (3) The push-off mechanism, a modulation of the ankle plantarflexion angle during double stance. We know that these mechanisms are interdependent and can be influenced by internal factors such as the phase of the gait cycle and walking cadence. Here we seek to determine whether there are changes in neural control of balance when walking in the presence of environmental constraints.Methods: Subjects walked on a self-paced treadmill while immersed in a virtual environment that provides three different colored pathways. Subjects were instructed not to step in the No-Step Zone, which appeared either on the right or left side of the subject. While walking, subjects received balance perturbations in the form of galvanic vestibular stimulation, providing the sensation of falling sideways, either toward the No-Step zone or toward the Neutral zone on the other side.Results: The results indicate that the use of the balance mechanisms are altered depending on whether the perceived fall is toward the No-Step or the Neutral zone. Participants increased the use of the lateral ankle and foot placement mechanisms for No-Step stimuli resulting in a larger shift of the center of mass (CoM) compared to the Neutral stimuli.Conclusion: This experiment provides further evidence that the balance control system during walking is extremely flexible, recruiting multiple mechanisms at different times in the gait cycle to adapt to environmental constraints.
C1 [Fettrow, Tyler; DiBianca, Stephen; Vanderlinde dos Santos, Fernando; Reimann, Hendrik; Jeka, John] Univ Delaware, Dept Kinesiol & Appl Physiol, Newark, DE 19716 USA.
   [Fettrow, Tyler] Univ Florida, Dept Appl Kinesiol & Physiol, Gainesville, FL 32611 USA.
   [Vanderlinde dos Santos, Fernando] Bertec Corp, Columbus, OH USA.
C3 University of Delaware; State University System of Florida; University
   of Florida
RP Fettrow, T (corresponding author), Univ Delaware, Dept Kinesiol & Appl Physiol, Newark, DE 19716 USA.; Fettrow, T (corresponding author), Univ Florida, Dept Appl Kinesiol & Physiol, Gainesville, FL 32611 USA.
EM tfettrow@ufl.edu
OI Fettrow, Tyler/0000-0003-3325-6726
FU German Research Foundation [RE 3780/1-1]; National Science Foundation
   (NSF) [CRCNS 1822568]
FX HR was funded from a Research Fellowship from the German Research
   Foundation (RE 3780/1-1). HR, TF, and JJ were funded by the National
   Science Foundation (NSF CRCNS 1822568).
CR Acasio J, 2017, GAIT POSTURE, V52, P171, DOI 10.1016/j.gaitpost.2016.11.034
   Adcock M, 2020, EUR REV AGING PHYS A, V17, DOI 10.1186/s11556-019-0233-2
   Banala SK, 2010, IEEE-ASME T MECH, V15, P216, DOI 10.1109/TMECH.2010.2041245
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Bruijn SM, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0816
   DAVIS RB, 1991, HUM MOVEMENT SCI, V10, P575, DOI 10.1016/0167-9457(91)90046-Z
   Delp SL, 2007, IEEE T BIO-MED ENG, V54, P1940, DOI 10.1109/TBME.2007.901024
   DELP SL, 1990, IEEE T BIO-MED ENG, V37, P757, DOI 10.1109/10.102791
   dos Santos LF, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0289-4
   Eggenberger P, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00066
   Fai AHT, 1996, J STAT COMPUT SIM, V54, P363, DOI 10.1080/00949659608811740
   Felsberg DT, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00979
   Fettrow T., 2019, THESIS U DELAWARE NE
   Fettrow T, 2019, FRONT SPORTS ACT LIV, V1, DOI 10.3389/fspor.2019.00040
   Fettrow T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225902
   Hof AL, 2013, EXP BRAIN RES, V230, P301, DOI 10.1007/s00221-013-3655-5
   HORAK FB, 1989, J NEUROPHYSIOL, V62, P841, DOI 10.1152/jn.1989.62.4.841
   Jansen SEM, 2011, EXP BRAIN RES, V212, P449, DOI 10.1007/s00221-011-2757-1
   Kiemel T, 2008, J NEUROPHYSIOL, V100, P3394, DOI 10.1152/jn.01272.2007
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Leavy B, 2015, BMC GERIATR, V15, DOI 10.1186/s12877-015-0036-x
   Lu TW, 1999, J BIOMECH, V32, P129, DOI 10.1016/S0021-9290(98)00158-4
   Matthis JS, 2014, J EXP PSYCHOL HUMAN, V40, P106, DOI 10.1037/a0033101
   Otten E, 1999, PHILOS T R SOC B, V354, P869, DOI 10.1098/rstb.1999.0439
   Patla AE, 2006, NEUROSCI LETT, V397, P110, DOI 10.1016/j.neulet.2005.12.016
   PATLA AE, 1991, J EXP PSYCHOL HUMAN, V17, P603, DOI 10.1037/0096-1523.17.3.603
   Peterka RJ, 2002, J NEUROPHYSIOL, V88, P1097, DOI 10.1152/jn.2002.88.3.1097
   Peterson SM, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0207-18.2018
   Raffegeau TE, 2020, GAIT POSTURE, V77, P6, DOI 10.1016/j.gaitpost.2020.01.006
   Rankin BL, 2014, J NEUROPHYSIOL, V112, P374, DOI 10.1152/jn.00138.2014
   Reimann H, 2019, FRONT SPORTS ACT LIV, V1, DOI 10.3389/fspor.2019.00025
   Reimann H, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.01271
   Reimann H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172215
   Rietdyk S, 2011, OPHTHAL PHYSL OPT, V31, P302, DOI 10.1111/j.1475-1313.2011.00837.x
   Schättin A, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnag.2016.00278
   Seth A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006223
   Sibley KM, 2007, HUM MOVEMENT SCI, V26, P103, DOI 10.1016/j.humov.2006.09.004
   TOWNSEND MA, 1985, J BIOMECH, V18, P21, DOI 10.1016/0021-9290(85)90042-9
   Wang Y, 2014, BIOL LETTERS, V10, DOI 10.1098/rsbl.2014.0405
   Winter DA, 1998, J NEUROPHYSIOL, V80, P1211, DOI 10.1152/jn.1998.80.3.1211
NR 41
TC 3
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 7
PY 2020
VL 1
AR 5
DI 10.3389/frvir.2020.00005
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WL5
UT WOS:001023284100001
OA gold
DA 2024-07-18
ER

PT J
AU Josupeit, J
AF Josupeit, Judith
TI Cybersickness as the virtual reality sickness questionnaire (VRSQ)
   measures it!? -an environment-specific revision of the VRSQ
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE simulator sickness questionnaire; virtual reality sickness
   questionnaire; cybersickness; confirmatory factor analysis; structural
   equation modelling; moderator effect
ID MOTION SICKNESS; R PACKAGE; SIMULATOR; SYMPTOMS
AB Background: Virtual Reality (VR) does not only include the use of stereoscopic images, but also possibilities for an interaction with and participation in a computer-generated environment. However, laboratory studies primarily focus on the first part of the definition only. In this context, comparing results from different VR applications with diverging goals becomes difficult. This is especially true in the field of cybersickness research (visually induced motion sickness in VR), as self-report symptom questionnaires are used. The prominent Simulator Sickness Questionnaire (SSQ) is criticized for the lack of specificity, the double factorial loadings, the outdatedness, and the unrepresentative sample. VR-specific revisions like the Virtual Reality Sickness Questionnaire (VRSQ) address these criticisms but lack generalizability.Methods: The current paper uses a Confirmatory Factor Analysis of the VRSQ with data from three different VR environments and a sample size of N = 244. The environments had different setups, visual complexities, and interaction possibilities. These characteristics influenced the factorial structure of the VRSQ as a moderator. Furthermore, to control for VR-unrelated effects Baseline ratings were taken into account.Results: The Confirmatory Factor Analysis indicated a moderate fit for the global model, but a misspecification for two of the three environments. Only the environment similar to the original VRSQ paper converged with the model.Conclusions: In conclusion, a detailed description of the VR environment is required in scientific method reports. Focusing on VR accessibility for physically impaired in addition to healthy subjects, an added Baseline measurement can address the discriminant validity. Until generalizable VR-specific revisions of the SSQ are validated, the paper suggests using the Delta-SSQ in aggregated raw format.
C1 [Josupeit, Judith] Tech Univ Dresden, Inst Work Org & Social Psychol, Engn Psychol & Appl Cognit Res, Dresden, Germany.
C3 Technische Universitat Dresden
RP Josupeit, J (corresponding author), Tech Univ Dresden, Inst Work Org & Social Psychol, Engn Psychol & Appl Cognit Res, Dresden, Germany.
EM judith.josupeit@tu-dresden.de
OI Josupeit, Judith/0000-0003-2144-3161
FU Joint publication funds of the TU Dresden; Carl Gustav Carus Faculty of
   Medicine; SLUB Dresden; Open Access Publication Funding of the DFG
FX The author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. The Article Processing
   Charges (APC) were funded by the joint publication funds of the TU
   Dresden, including Carl Gustav Carus Faculty of Medicine, and the SLUB
   Dresden as well as the Open Access Publication Funding of the DFG.
CR Almeida A, 2018, ADV INTELL SYST, V588, P26, DOI 10.1007/978-3-319-60582-1_3
   [Anonymous], 1975, Motion sickness
   Arns L. L., 2005, IEEE P VR 2005 VIRTU
   Balk S., 2017, P 7 INT DRIV S HUM F
   Boring E. G., 1961, Studies in individual differences: the search for intelligence
   Bos JE, 2005, AVIAT SPACE ENVIR MD, V76, P1111
   Bos JE, 2022, VIBRATION-BASEL, V5, P755, DOI 10.3390/vibration5040044
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Cooperman AW, 2022, PSYCHOL METHODS, V27, P156, DOI 10.1037/met0000384
   Davis Simon., 2014, P 2014 C INTERACTIVE, p8:1
   Fiori F, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00734
   Flora DB, 2017, CAN J BEHAV SCI, V49, P78, DOI 10.1037/cbs0000069
   Friedrich S, 2019, R J, V11, P380
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Giannopulu I., 2018, Neuroscience, robotics, and virtual reality: Internalised vs externalised mind/brain
   HERZOG AR, 1981, PUBLIC OPIN QUART, V45, P549, DOI 10.1086/268687
   HOLM S, 1979, SCAND J STAT, V6, P65
   Josupeit J., 2023, P 7 INT C ARTIFICIAL
   Josupeit J., 2023, AHFE INT C
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2023, HUM FACTORS, V65, P107, DOI 10.1177/00187208211008687
   Kim D.H., 2004, A New Procedure for Measuring Simulator Sickness-the RSSQ
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   Kuiper OX, 2020, HUM FACTORS, V62, P1339, DOI 10.1177/0018720819876139
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Liao CY, 2020, IEEE ACCESS, V8, P126784, DOI 10.1109/ACCESS.2020.3008165
   MARDIA KV, 1970, BIOMETRIKA, V57, P519, DOI 10.1093/biomet/57.3.519
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Ning HS, 2017, IEEE INTERNET THINGS, V4, P783, DOI 10.1109/JIOT.2017.2666798
   Palmisano S, 2022, VIRTUAL REAL-LONDON, V26, P1373, DOI 10.1007/s10055-022-00634-6
   Paris R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343131
   Petri K., 2020, Am. J. Biomed. Sci, P107, DOI DOI 10.5099/AJ200200107
   R Core Team, 2023, R LANG ENV STAT COMP
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rosseel Y, 2012, J STAT SOFTW, V48, P1, DOI 10.18637/jss.v048.i02
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schmitt N, 2008, HUM RESOUR MANAGE R, V18, P210, DOI 10.1016/j.hrmr.2008.03.003
   Science Direct, 2023, Data in brief [online]
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Springer Nature Limited, 2023, Scientific data [online]
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stone W. B., 2017, PSYCHOMETRIC EVALUAT
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Turoff M, 1997, COMMUN ACM, V40, P38, DOI 10.1145/260750.260761
   Ubiquity Press, 2023, Codata data science journal
   von Oertzen T, 2015, STRUCT EQU MODELING, V22, P148, DOI 10.1080/10705511.2014.935842
   Weinbaum S. G., 2012, Pygmalion's spectacles
   Young SD, 2007, IEEE T VIS COMPUT GR, V13, P422, DOI [10.1109/TVCG.2007.1029, 10.1109/TVCG.2007.1041]
NR 51
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 6
PY 2023
VL 4
AR 1291078
DI 10.3389/frvir.2023.1291078
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CZ1C2
UT WOS:001128951400001
OA gold
DA 2024-07-18
ER

PT J
AU Paradise, A
   Surve, S
   Menezes, JC
   Gupta, M
   Bisht, V
   Jang, KR
   Liu, C
   Qiu, SM
   Dong, JY
   Shin, J
   Ferrari, S
AF Paradise, Andre
   Surve, Sushrut
   Menezes, Jovan C.
   Gupta, Madhav
   Bisht, Vaibhav
   Jang, Kyung Rak
   Liu, Cong
   Qiu, Suming
   Dong, Junyi
   Shin, Jane
   Ferrari, Silvia
TI RealTHASC-a cyber-physical XR testbed for AI-supported real-time human
   autonomous systems collaborations
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE robotics; virtual reality; human-autonomy teams; simulation systems;
   human-robot interaction; multi-robot communication;
   simulation-to-reality gap; artificial intelligence
ID SEARCH; SWARM
AB Today's research on human-robot teaming requires the ability to test artificial intelligence (AI) algorithms for perception and decision-making in complex real-world environments. Field experiments, also referred to as experiments "in the wild," do not provide the level of detailed ground truth necessary for thorough performance comparisons and validation. Experiments on pre-recorded real-world data sets are also significantly limited in their usefulness because they do not allow researchers to test the effectiveness of active robot perception and control or decision strategies in the loop. Additionally, research on large human-robot teams requires tests and experiments that are too costly even for the industry and may result in considerable time losses when experiments go awry. The novel Real-Time Human Autonomous Systems Collaborations (RealTHASC) facility at Cornell University interfaces real and virtual robots and humans with photorealistic simulated environments by implementing new concepts for the seamless integration of wearable sensors, motion capture, physics-based simulations, robot hardware and virtual reality (VR). The result is an extended reality (XR) testbed by which real robots and humans in the laboratory are able to experience virtual worlds, inclusive of virtual agents, through real-time visual feedback and interaction. VR body tracking by DeepMotion is employed in conjunction with the OptiTrack motion capture system to transfer every human subject and robot in the real physical laboratory space into a synthetic virtual environment, thereby constructing corresponding human/robot avatars that not only mimic the behaviors of the real agents but also experience the virtual world through virtual sensors and transmit the sensor data back to the real human/robot agent, all in real time. New cross-domain synthetic environments are created in RealTHASC using Unreal Engine (TM), bridging the simulation-to-reality gap and allowing for the inclusion of underwater/ground/aerial autonomous vehicles, each equipped with a multi-modal sensor suite. The experimental capabilities offered by RealTHASC are demonstrated through three case studies showcasing mixed real/virtual human/robot interactions in diverse domains, leveraging and complementing the benefits of experimentation in simulation and in the real world.
C1 [Paradise, Andre; Surve, Sushrut; Menezes, Jovan C.; Gupta, Madhav; Bisht, Vaibhav; Jang, Kyung Rak; Liu, Cong; Qiu, Suming; Dong, Junyi; Ferrari, Silvia] Cornell Univ, Sibley Sch Mech & Aerosp Engn, Lab Intelligent Syst & Controls LISC, Ithaca, NY 14850 USA.
   [Shin, Jane] Univ Florida, Dept Mech & Aerosp Engn, Act Percept & Robot Intelligence Lab APRILab, Gainesville, FL USA.
C3 Cornell University; State University System of Florida; University of
   Florida
RP Ferrari, S (corresponding author), Cornell Univ, Sibley Sch Mech & Aerosp Engn, Lab Intelligent Syst & Controls LISC, Ithaca, NY 14850 USA.
EM ferrari@cornell.edu
RI Ferrari, Silvia/G-5964-2011
OI Paradise, Andre/0000-0002-8503-3500; Shin, Jaejeong/0000-0002-5755-8385
FU Office of Naval Research Defense University Research Instrumentation
   Program (DURIP) [N00014-20-S-F004]; Cornell Engineering Colman
   Fellowship; Alfred P. Sloan Foundation [G-2019-11435]; National Science
   Foundation (NSF) [EFMA-2223811]; Office of Naval Research (ONR)
   [N00014-22-1-2513]
FX This research was funded by the Office of Naval Research Defense
   University Research Instrumentation Program (DURIP) grant
   N00014-20-S-F004. AP was supported by the Cornell Engineering Colman
   Fellowship, by the Alfred P. Sloan Foundation grant G-2019-11435, and by
   the National Science Foundation (NSF) grant EFMA-2223811. SS was
   supported by the Office of Naval Research (ONR) grant N00014-22-1-2513.
   SF was supported by the National Science Foundation (NSF) grant
   EFMA-2223811.
CR Bassyouni Z, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.724798
   Bradski G, 2000, DR DOBBS J, V25, P120
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chang S, 2018, PROC SPIE, V10628, DOI 10.1117/12.2319988
   Chen JN, 2015, IEEE T ROBOT, V31, P307, DOI 10.1109/TRO.2015.2400731
   Choi H, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.1907856118
   DeepMotion, 2023, DeepMotion SDK-virtual reality tracking
   Deitke M, 2020, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR42600.2020.00323
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Epic Games, 2019, Unreal engine
   Erez T, 2015, IEEE INT CONF ROBOT, P4397, DOI 10.1109/ICRA.2015.7139807
   Ferrari S., 2021, INFORM DRIVEN PLANNI
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Garg G, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131810336
   Gemerek J, 2019, IFAC PAPERSONLINE, V51, P176, DOI 10.1016/j.ifacol.2019.01.062
   Google LLC, 2022, Google cloud speech API
   Guerra W, 2019, IEEE INT C INT ROBOT, P6941, DOI [10.1109/iros40897.2019.8968116, 10.1109/IROS40897.2019.8968116]
   Hu JY, 2018, ROBOT AUTON SYST, V103, P162, DOI 10.1016/j.robot.2018.02.019
   Inamura T, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.549360
   KAO WW, 1991, VNIS 91 : VEHICLE NAVIGATION & INFORMATION SYSTEMS CONFERENCE PROCEEDINGS, PTS 1 AND 2, P635
   Koenig N., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2149
   Krajník T, 2014, J INTELL ROBOT SYST, V76, P539, DOI 10.1007/s10846-014-0041-x
   Liu R, 2022, ACM T HUM-ROBOT INTE, V11, DOI 10.1145/3477391
   Michel O., 2004, International Journal of Advanced Robotic Systems, V1, P39
   Mizuchi Y, 2017, IEEE/SICE I S SYS IN, P948, DOI 10.1109/SII.2017.8279345
   Murnane M, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P470, DOI 10.1109/VRW52623.2021.00117
   Naghsh AM, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P255, DOI 10.1109/ROMAN.2008.4600675
   Nourbakhsh IR, 2005, IEEE PERVAS COMPUT, V4, P72, DOI 10.1109/MPRV.2005.13
   Ognibene D, 2022, FRONT NEUROROBOTICS, V16, DOI 10.3389/fnbot.2022.848065
   Oh J, 2017, SPR PROC ADV ROBOT, V1, P309, DOI 10.1007/978-3-319-50115-4_28
   Pendleton SD, 2017, MACHINES, V5, DOI 10.3390/machines5010006
   Pingping Zhu, 2017, 2017 IEEE 56th Annual Conference on Decision and Control (CDC), P2724, DOI 10.1109/CDC.2017.8264055
   Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886
   Qiu WC, 2016, LECT NOTES COMPUT SC, V9915, P909, DOI 10.1007/978-3-319-49409-8_75
   Reiners D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.721933
   Sammelmann GS, 1997, P SOC PHOTO-OPT INS, V3079, P160, DOI 10.1117/12.280850
   Shah S., 2017, Field and service robotics, DOI 10.1007/978-3-319-67361-5_40
   Shen BK, 2021, IEEE INT C INT ROBOT, P7520, DOI 10.1109/IROS51168.2021.9636667
   Shin J, 2022, IEEE J OCEANIC ENG, V47, P780, DOI 10.1109/JOE.2021.3119150
   Shin J, 2022, OCEANS-IEEE, DOI 10.1109/OCEANS47191.2022.9977275
   Skulj G., 2021, Procedia CIRP, V104, P336, DOI [10.1016/j.procir.2021.11.057, DOI 10.1016/J.PROCIR.2021.11.057]
   Spurny V, 2019, J FIELD ROBOT, V36, P125, DOI 10.1002/rob.21816
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
NR 43
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 4
PY 2023
VL 4
AR 1210211
DI 10.3389/frvir.2023.1210211
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DA3S4
UT WOS:001129279700001
OA gold
DA 2024-07-18
ER

PT J
AU Buche, H
   Michel, A
   Blanc, N
AF Buche, Helene
   Michel, Aude
   Blanc, Nathalie
TI When virtual reality supports patients' emotional management in
   chemotherapy
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; breast cancer; emotional management; anxiety;
   chemotherapy
ID CANCER; EFFICACY; ANXIETY; SYSTEM
AB Objectives: Our study is a follow-up of a previous research study that was carried out in physiotherapy. The present study aims to evaluate the effectiveness of virtual reality (VR) as a tool to support emotional management during the acute phase of breast cancer treatment (chemotherapy session).Materials and methods: A quasi-experimental protocol was implemented in an oncology department with 120 patients randomly assigned to one of four conditions that were being compared. During the first 10 minutes of a chemotherapy session, patients could either be exposed to a participatory immersion in a natural environment; or be placed in a contemplative immersion condition in the same environment; or listen to classical music; or receive no distraction. The involvement of the patients in the virtual environment and the relevance of the immersive modalities were measured through the evaluation of sense of presence. Particular interest was given to the evaluation of anxiety level and the emotional state of the patients.Results: VR during chemotherapy reduces anxiety and calms emotional tension. The multi-sensory nature of this emotional regulation support tool was more effective than music in inducing positive emotion, and this benefit was the most salient when immersion was offered in an interactive format.Conclusion: The relevance of providing support through VR in oncology is confirmed in this study. This tool can compensate for the fluctuating availability of caregivers by offering patients the possibility of shaping their own relaxing worlds and could help preserve the patient-caregiver relationship.
C1 [Buche, Helene; Michel, Aude; Blanc, Nathalie] Univ Paul Valery Montpellier 3, Dept Psychol, EPSYLON Lab 4556, Montpellier, France.
   [Michel, Aude] Clin Clementville, Montpellier Inst Sein, Montpellier, France.
C3 Universite de Montpellier; Universite Paul-Valery
RP Buche, H; Michel, A (corresponding author), Univ Paul Valery Montpellier 3, Dept Psychol, EPSYLON Lab 4556, Montpellier, France.; Michel, A (corresponding author), Clin Clementville, Montpellier Inst Sein, Montpellier, France.
EM helene.buche@univ-montp3.fr; aude.michel@univ-montp3.fr
RI Blanc, Nathalie/H-3912-2012
OI Buche, Helene/0009-0005-2176-4418
FU AstraZeneca
FX The authors thank AstraZeneca for their financial support.r The
   author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. The author(s) received
   specific funding for this study. AstraZeneca funded the virtual reality
   headsets required for this research. Thus, the funder was not involved
   in the study design, data collection, analysis, interpretation, writing
   of this article or the decision to submit it for publication.
CR Ahmadpour N, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/14565
   Ando MM, 2022, ANN ONCOL, V33, pS478, DOI 10.1016/j.annonc.2022.05.052
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Birkhoff SD, 2021, ONCOL NURS FORUM, V48, P431, DOI 10.1188/21.ONF.431-439
   Birnie KA, 2018, J PEDIATR ONCOL NURS, V35, P406, DOI 10.1177/1043454218782138
   Bouvier P., 2009, La presence en realite virtuelle, une approche centree utilisateur These de doctorat en informatique
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Buche H, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.894162
   Buche H, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.631186
   Carline J., 2017, Greener games
   Chirico A, 2020, J CELL PHYSIOL, V235, P5353, DOI 10.1002/jcp.29422
   Chirico A, 2016, J CELL PHYSIOL, V231, P275, DOI 10.1002/jcp.25117
   Coppee E., 2021, L'humanisme au cœur de la pratique quotidienne des soignants:  Quelles sont les strategies mises en place par le personnel infirmier afin de maintenir des soins humanisants au patient malgre un systeme de soins contraint ? . Faculte de sante publique
   Cyberpsychology Laboratory of UQO, 2002, Cyberpsychologie
   El-Hage W, 2020, ENCEPHALE, V46, pS73, DOI [10.1016/j.encep.2020.04.008, 10.1016/j.encep.2020.014.008]
   Fredrickson BL, 2001, AM PSYCHOL, V56, P218, DOI 10.1037/0003-066X.56.3.218
   Gamble KR, 2014, EXP AGING RES, V40, P513, DOI 10.1080/0361073X.2014.956618
   Garrett BM, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03916
   Hjeij Danny, 2022, Can Oncol Nurs J, V32, P387, DOI 10.5737/23688076323387
   Independent Television Commission, 2000, Sens of presence inventory administration and scoring instructions
   Indovina P, 2018, CLIN J PAIN, V34, P858, DOI 10.1097/AJP.0000000000000599
   Janssen A, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/29579
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Lai JB, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3976
   Lerebours F, 2015, B CANCER, V102, P316, DOI 10.1016/j.bulcan.2015.01.011
   Macey A. L., 2024, INT GAMIFIN C APR 2, P64
   Maneuvrier A., 2020, Le sentiment de presence en realite virtuelle: role moderateur des facteurs humains sur la performance (Doctoral dissertation, Normandie Universite; Universite de Montreal)
   Michel A, 2019, PSYCHO-ONCOLOGIE, V13, P69, DOI 10.3166/pson-2019-0087
   Morgand C., 2022, Sante Publique Prepublication, p1t, DOI [10.3917/spub.pr1.0020, DOI 10.3917/SPUB.PR1.0020]
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   O'Gara G, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2020-047626
   Oyama H, 2000, J Med Syst, V24, P173, DOI 10.1023/A:1005591626518
   Plaisant O, 2010, ANN MED-PSYCHOL, V168, P97, DOI 10.1016/j.amp.2009.09.003
   Prip A, 2018, CANCER NURS, V41, pE11, DOI 10.1097/NCC.0000000000000533
   Reynolds LM, 2022, BMC CANCER, V22, DOI 10.1186/s12885-021-09081-z
   Riecke B. E., 2003, 11th annual workshop on object perception, attention, and memory, P8
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rutkowski S, 2021, COMPLEMENT THER MED, V61, DOI 10.1016/j.ctim.2021.102767
   Sakhri S., 2021, Archives Med. Case Rep. Case Study, V5, DOI [10.31579/2692-9392/101, DOI 10.31579/2692-9392/101]
   Schneider S M, 1999, Cyberpsychol Behav, V2, P125, DOI 10.1089/cpb.1999.2.125
   Schneider SM, 2011, SUPPORT CARE CANCER, V19, P555, DOI 10.1007/s00520-010-0852-7
   Servotte JC, 2020, CLIN SIMUL NURS, V38, P35, DOI 10.1016/j.ecns.2019.09.006
   Sharifpour S, 2021, COUNS PSYCHOTHER RES, V21, P218, DOI 10.1002/capr.12311
   Spielberger G., 1983, Manual for the State-Trait Anxiety Inventory, DOI DOI 10.1037/T06496-000
   Street RL, 2009, PATIENT EDUC COUNS, V74, P295, DOI 10.1016/j.pec.2008.11.015
   Tennant M, 2020, EUR J ONCOL NURS, V48, DOI 10.1016/j.ejon.2020.101804
   Tsaras Konstantinos, 2018, Asian Pac J Cancer Prev, V19, P1661
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   Valtchanov D, 2015, J ENVIRON PSYCHOL, V43, P184, DOI 10.1016/j.jenvp.2015.07.001
   Vincent C, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259364
   Whitehead-Pleaux AM, 2007, J MUSIC THER, V44, P217, DOI 10.1093/jmt/44.3.217
   Wilson K, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.695449
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wong CL, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258514
   Zielinska-Wieczkowska H, 2010, WSPOLCZESNA ONKOL, V14, P276
NR 56
TC 0
Z9 0
U1 5
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 14
PY 2023
VL 4
AR 1294482
DI 10.3389/frvir.2023.1294482
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Z7QH5
UT WOS:001113982300001
OA gold
DA 2024-07-18
ER

PT J
AU Rundel, S
   De Amicis, R
AF Rundel, Samuel
   De Amicis, Raffaele
TI Leveraging digital twin and game-engine for traffic simulations and
   visualizations
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE digital twin; unity; traffic simulation; game engine; city information
   model; geographic information system; data combination; SUMO
AB Combined with simulation software packages, City Information Models allow analysts and decision-makers to explore 'what-if?' questions and scenarios for various engineering and strategic applications. In this context, crowd and traffic simulations are most commonly utilized. Urban intelligent traffic management and pedestrian flow analysis greatly benefits from the latest generation of 3D City Information Models created from accurate urban-scale geospatial information. Analysis and simulation tools based on geometric, semantic, morphological, and structural information at the urban scale level offer the scientific foundation for all the activities required for identifying, detecting, planning, training, and analyzing vulnerability that may threaten human lives in urban environments. Nevertheless, the literature research showed that samples of operational Digital Twins incorporating simulation capabilities are impracticable for small municipalities and rural, low-income communities due to their complex infrastructure, hardware, and data requirements. It is desirable to reduce the requirements for these Digital Twins and still be capable of running comprehensive and accurate simulations based on urban-scale geospatial information. This article proposes an innovative framework and workflow capable of generating an operational Digital Twin and its visualization in the form of a 3D model using a procedural approach. The Digital Twin is connected with the traffic simulation SUMO and the Game Engine Unity for visualization using the TraCI middleware. The middleware is extended with additional functionalities and acts as an authoring tool. Unity allows visualizations in VR. The entire framework can be run on a single, standalone computer and is ready in a matter of minutes. The proposed framework for integrating modeling, simulation, and visualization of operational Digital Twins can help guide better decision-making for both rural areas as well as cities.
C1 [Rundel, Samuel; De Amicis, Raffaele] Oregon State Univ, Coll Engn, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
C3 Oregon State University
RP De Amicis, R (corresponding author), Oregon State Univ, Coll Engn, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
EM raffaele.deamicis@oregonstate.edu
OI Rundel, Samuel/0000-0001-9071-4979
CR Angelidou M, 2017, J URBAN TECHNOL, V24, P3, DOI 10.1080/10630732.2017.1348880
   Cannon A., 2016, AIMING STUDENTS
   Corvallis GIS Services, 2022, TRANSP FIL GEOD
   Corvallis GIS Services, 2022, STRUCT FIL GEOD
   Dembski F, 2019, ECAADE SIGRADI 2019: ARCHITECTURE IN THE AGE OF THE 4TH INDUSTRIAL REVOLUTION, VOL 1, P795
   Dembski F, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062307
   Eberhard K, 2023, MANAG REV Q, V73, P167, DOI 10.1007/s11301-021-00235-8
   Google, 2022, OR STAT U CAMP AR
   Lopez PA, 2018, IEEE INT C INTELL TR, P2575, DOI 10.1109/ITSC.2018.8569938
   Microsoft, 2022, OR STAT U CAMP AR
   National Research Foundation Singapore, 2016, US VIRT SING
   National Research Foundation Singapore, 2021, VIRT SING
   OSM-Contributors, 2022, OPENSTREETMAP WIK
   OSM-Contributors, 2022, OR STAT U CAMP AR
   Safe Software, 2022, WHAT IS FME INTR FME
   Schrotter G, 2020, PFG-J PHOTOGRAMM REM, V88, P99, DOI 10.1007/s41064-020-00092-2
   Singapore Land Authority, 2012, VIRT SING 3D CIT MOD
   Son H., 2015, ISARC Proc. Int. Symp. Autom. Robot. Constr, V32, P1, DOI 10.22260/ISARC2015/0050
   Wang Z., 2021, P 2021 IEEE INT C MU, P1, DOI 10.1109/DTPI52967.2021.9540074
   Xu Z, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199333
NR 20
TC 3
Z9 3
U1 10
U2 16
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 21
PY 2023
VL 4
AR 1048753
DI 10.3389/frvir.2023.1048753
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XV8
UT WOS:001023320500001
OA gold
DA 2024-07-18
ER

PT J
AU Kirollos, R
   Merchant, W
AF Kirollos, Ramy
   Merchant, Wasim
TI Comparing cybersickness in virtual reality and mixed reality
   head-mounted displays
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; mixed reality; head-mounted display (HMD);
   cybersickness; simulator sickness questionnaire (SSQ)
ID VISUALLY INDUCED MOTION; INTERPUPILLARY DISTANCE; SICKNESS; EXPOSURE;
   INDEX
AB Introduction: Defence Research and Development Canada is developing guidance on the use of Mixed Reality head-mounted displays for naval operations in the Royal Canadian Navy. Virtual reality head-mounted displays display graphics to the user in 3D and completely occlude the user's view of the real world. Mixed Reality head-mounted displays overlay and integrate graphics onto the real world allowing the user to perceive the real world and rich 3D graphic elements simultaneously. Nausea and other debilitating symptoms caused by the use of head-mounted displays, known as 'cybersickness', is well documented during Virtual reality head-mounted display exposure and can be quite severe. However, it is not yet clear from the literature on Mixed Reality head-mounted displays whether CS differs in Virtual reality vs. Mixed Reality head-mounted displays. The objective of this study was to determine the impact of MR HMDs on CS.Method: This was done by modulating the quantity of graphics in two Mixed Reality conditions and one Virtual reality condition. Only foreground objects were graphically rendered in the first Mixed Reality condition (called 'Mixed Reality' condition), while the entire scene was graphically rendered in the second Mixed Reality condition (called 'Mixed Reality +' condition). The Virtual reality condition simulated the Mixed Reality + condition but was displayed in a Virtual reality head-mounted display. Participants observed the virtually rendered scene in one of the three conditions and reported their CS with the simulator sickness questionnaire six times throughout the 30-min experiment. We hypothesized that CS severity would increase as quantity of graphics in the display increased.Results and Discussion: Findings indicated that CS was significantly greater in the 'Mixed Reality +' condition compared to the 'Mixed Reality' and 'Virtual reality' conditions, providing partial evidence for our main hypothesis. Moreover, CS increased significantly and meaningfully after 25 min in the 'Mixed Reality +' condition. These findings indicate safe use of Mixed Reality head-mounted displays by the RCN for shore-based applications provided quantity of graphics is limited.
C1 [Kirollos, Ramy; Merchant, Wasim] Def Res & Dev Canada, Toronto Res Ctr, Toronto, ON, Canada.
C3 Defence Research & Development Canada
RP Kirollos, R (corresponding author), Def Res & Dev Canada, Toronto Res Ctr, Toronto, ON, Canada.
EM Ramy.Kirollos@drdc-rddc.gc.ca
FU DRDC Toronto
FX & nbsp;Funding was provided internally by DRDC Toronto.
CR Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   [Anonymous], 2014, BULL ENVIRON PHARMAC
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Aslankurt M, 2013, J OPHTHALMOL, V2013, DOI 10.1155/2013/485059
   Beadle SC, 2021, DISPLAYS, V66, DOI 10.1016/j.displa.2020.101985
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Bos J. E., 2021, INTRO GUIDELINES MIT
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Casali J. G., 1986, TRANSP RES REC, V1059, P57
   Deepa BMS, 2019, J FAM MED PRIM CARE, V8, P3850, DOI 10.4103/jfmpc.jfmpc_755_19
   Eom Y, 2013, JPN J OPHTHALMOL, V57, P486, DOI 10.1007/s10384-013-0253-9
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Golding JF, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.576871
   He ZH, 2019, APPL OPTICS, V58, pA74, DOI 10.1364/AO.58.000A74
   Hemmerich W, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582095
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Jasper A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582108
   Jennings S, 2004, J AIRCRAFT, V41, P1327, DOI 10.2514/1.449
   Kemeny A., 2020, Virtual reality, augmented reality, and simulators
   Kemeny A., 2017, The Engineering Reality of Virtual Reality, P48
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kirollos R., 2021, INT C HUM COMP INT 0
   Kirollos R., 2021, SAFETY CONSIDERATION
   Kuiper OX, 2019, DISPLAYS, V58, P82, DOI 10.1016/j.displa.2018.10.001
   Langbehn E, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P241, DOI 10.1145/2993369.2993379
   Lawson B., 2014, HDB VIRTUAL ENV DESI, V2 ed.
   Lawson B D, 2005, P 11 INT C HUM COMP, P1
   Lawson B. D., 2021, FACTORS IMPACTING CY
   Lin J.-W., 2002, P IEEE VIRT REAL 200
   Luu W, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89751-x
   Mai M. N., 2010, INVESTIGATIVE OPHTHA, V51, P4359
   Merchant W., 2022, OVERVIEW CYBERSICKNE
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Parker D., 2003, UNIFIED APPROACH PRE
   Porcino T., 2021, Journal on Interactive Systems, V12, P269, DOI DOI 10.5753/JIS.2021.2058
   Rea L.M., 2014, Designing and conducting survey research: A comprehensive guide
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Tomczak M., 2014, NEED REPORT EFFECT S, DOI DOI 10.1186/S13054-016-1208-6
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Van Benthem K., 2021, HUMAN FACTORS ERGONO
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Whittinghill D. M., 2015, NASUM VIRTUALIS SIMP
   XR Collaboration, 2021, XR GLOSS
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Zhao JB, 2017, P IEEE VIRT REAL ANN, P313, DOI 10.1109/VR.2017.7892302
NR 64
TC 6
Z9 6
U1 10
U2 18
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 13
PY 2023
VL 4
AR 1130864
DI 10.3389/frvir.2023.1130864
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YN5
UT WOS:001023338300001
OA gold
DA 2024-07-18
ER

PT J
AU Brunye, TT
   Giles, GE
AF Brunye, Tad T. T.
   Giles, Grace E. E.
TI Methods for eliciting and measuring behavioral and physiological
   consequences of stress and uncertainty in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; acute stress; decision making; eye tracking;
   marksmanship; memory; spatial orientation; methods
ID SALIVARY ALPHA-AMYLASE; PERCEPTUAL DECISION-MAKING; CORE EXECUTIVE
   FUNCTIONS; HEART-RATE-VARIABILITY; HPA AXIS RESPONSES; WORKING-MEMORY;
   CORTISOL RESPONSES; PREFRONTAL CORTEX; COGNITIVE PERFORMANCE;
   SYMPATHETIC ACTIVITY
AB Military operations are characterized by high levels of stress and uncertainty, and these states can influence cognitive and physical performance outcomes. These states, however, can be difficult to reliably induce in laboratory contexts, making it challenging to quantify and model their influences on perceptual and cognitive processes underlying performance on applied tasks. Herein we describe the development and validation of a novel scenario-based virtual reality methodology, the decision making under uncertainty and stress (DeMUS) scenario, that accomplishes four primary goals. First, it induces physiological and biochemical stress responses through a threat of shock manipulation. Second, it induces transient states of uncertainty by manipulating stimulus clarity in a perceptual decision-making task. Third, it generates several performance metrics regarding recognition memory, spatial orienting, threat classification, and marksmanship decision making. Finally, the task combines behavioral, physiological, and biochemical measures to provide a more comprehensive understanding of how stress and uncertainty influence applied task performance. To provide an initial validation of the scenario and its associated tasks and measures, we conducted a pilot study (n = 18) involving stress induction and cognitive performance assessment. Analyses revealed that: 1) the DeMUS scenario elicited tonic and phasic biochemical (salivary alpha amylase and cortisol) and physiological (heart rate, pupil diameter) stress responses, 2) the scenario elicited variable sympathetic autonomic nervous system and hypothalamic-pituitary adrenal (HPA) axis responses, and 3) stress influenced some measures of memory and decision-making in both negative and positive directions. Continuing research will assess individual- and group-level predictors of performance on these virtual reality tasks, and emerging performance enhancement techniques that can help military personnel sustain performance during stressful operations.
C1 [Brunye, Tad T. T.; Giles, Grace E. E.] US Army DEVCOM Soldier Ctr, Natick, MA 01760 USA.
   [Brunye, Tad T. T.; Giles, Grace E. E.] Tufts Univ, Ctr Appl Brain & Cognit Sci, Medford, MA 02155 USA.
C3 Tufts University
RP Brunye, TT (corresponding author), US Army DEVCOM Soldier Ctr, Natick, MA 01760 USA.; Brunye, TT (corresponding author), Tufts Univ, Ctr Appl Brain & Cognit Sci, Medford, MA 02155 USA.
EM tbruny01@tufts.edu
FU U.S. Army DEVCOM Soldier Center [W911QY-19-2-0003]; Tufts University
FX This work was supported by the U.S. Army DEVCOM Soldier Center under a
   cooperative agreement (W911QY-19-2-0003) with Tufts University.
CR Adam GE, 2008, PHYSIOL BEHAV, V93, P748, DOI 10.1016/j.physbeh.2007.11.028
   Ali N, 2020, INT J BEHAV MED, V27, P337, DOI 10.1007/s12529-019-09843-x
   Allahyar M., 2003, INT J TEST, V3, P263, DOI [10.1207/S15327574IJT0303_5, DOI 10.1207/S15327574IJT03035]
   Angelova M, 2021, FRONT PHYSIOL, V12, DOI 10.3389/fphys.2021.612245
   [Anonymous], 1993, Time Pressure and Stress in Human Judgment and Decision Making, DOI [DOI 10.1007/978-1-4757-6846-6_2, 10.1007/978-1-4757-6846-6_2]
   Arnsten AFT, 1998, TRENDS COGN SCI, V2, P436, DOI 10.1016/S1364-6613(98)01240-6
   Arnsten AFT, 2009, NAT REV NEUROSCI, V10, P410, DOI 10.1038/nrn2648
   Astrom U., 2011, CAMOUFLAGE GENERATOR
   AXELROD J, 1984, SCIENCE, V224, P452, DOI 10.1126/science.6143403
   Bali A, 2015, REV NEUROSCIENCE, V26, P555, DOI 10.1515/revneuro-2015-0004
   Balodis IM, 2010, PSYCHONEUROENDOCRINO, V35, P1363, DOI 10.1016/j.psyneuen.2010.03.011
   Bartone PT, 2006, MIL PSYCHOL, V18, pS131, DOI 10.1207/s15327876mp1803s_10
   Beckner ME, 2021, PHYSIOL BEHAV, V236, DOI 10.1016/j.physbeh.2021.113413
   Berghorst LH, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00133
   Blanchard E B, 1982, Psychiatr Q, V54, P220, DOI 10.1007/BF01064817
   Bogacz R, 2010, Q J EXP PSYCHOL, V63, P863, DOI 10.1080/17470210903091643
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Bradley MM, 2017, PSYCHOPHYSIOLOGY, V54, P1419, DOI 10.1111/psyp.12890
   Britt T.W., 2013, Building psychological resilience in military personnel: Theory and practice, P3, DOI [DOI 10.1037/14190-001, 10.1037/14190-001]
   Broadbent D. E., 1971, DECIS STRESS, pxiv522
   Bruns CR, 2019, LANDSCAPE URBAN PLAN, V189, P296, DOI 10.1016/j.landurbplan.2019.05.006
   Brunyé TT, 2021, FRONT PHYSIOL, V12, DOI 10.3389/fphys.2021.738973
   Brunyé TT, 2020, J COGN ENHANCE, V4, P453, DOI 10.1007/s41465-020-00167-3
   Brunyé TT, 2019, SPAT COGN COMPUT, V19, P283, DOI 10.1080/13875868.2019.1633540
   Brunyé TT, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00140
   Brunyé TT, 2017, INT J PSYCHOPHYSIOL, V120, P60, DOI 10.1016/j.ijpsycho.2017.07.008
   Brunyé TT, 2017, Q J EXP PSYCHOL, V70, P1439, DOI 10.1080/17470218.2016.1187637
   Brunyé TT, 2017, J BIOMED INFORM, V66, P171, DOI 10.1016/j.jbi.2017.01.004
   Buchheim JI, 2019, FRONT PHYSIOL, V10, DOI 10.3389/fphys.2019.00085
   CALLISTER R, 1992, J PHYSIOL-LONDON, V454, P373, DOI 10.1113/jphysiol.1992.sp019269
   Cerqueira JJ, 2007, J NEUROSCI, V27, P2781, DOI 10.1523/JNEUROSCI.4372-06.2007
   Chan HL, 2007, PHYSIOL MEAS, V28, P277, DOI 10.1088/0967-3334/28/3/004
   Charmandari E, 2005, ANNU REV PHYSIOL, V67, P259, DOI 10.1146/annurev.physiol.67.040403.120816
   Chatterton RT, 1996, CLIN PHYSIOL, V16, P433, DOI 10.1111/j.1475-097X.1996.tb00731.x
   de Berker AO, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10996
   Dibbets P, 2020, J BEHAV THER EXP PSY, V67, DOI 10.1016/j.jbtep.2019.01.001
   Dickerson SS, 2004, PSYCHOL BULL, V130, P355, DOI 10.1037/0033-2909.130.3.355
   DiDomenico A, 2011, INT J IND ERGONOM, V41, P255, DOI 10.1016/j.ergon.2011.01.008
   DIMSDALE JE, 1980, PSYCHOSOM MED, V42, P493, DOI 10.1097/00006842-198009000-00003
   Diniz BernardoP., 2020, Journal of Technology in Behavioral Science, V6, P3, DOI [10.1007/s41347-020-00152-9, DOI 10.1007/S41347-020-00152-9]
   Ditzen B, 2014, BIOL PSYCHOL, V103, P15, DOI 10.1016/j.biopsycho.2014.08.001
   Duncko R, 2007, LEARN MEMORY, V14, P329, DOI 10.1101/lm.483807
   EAGLE M, 1964, J EXP PSYCHOL, V68, P58, DOI 10.1037/h0044655
   EDWARDS W, 1956, J EXP PSYCHOL, V52, P177, DOI 10.1037/h0047727
   Farina EK, 2019, PHYSIOL BEHAV, V210, DOI 10.1016/j.physbeh.2019.112647
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Feltman KA, 2020, MIL MED, V185, pE53, DOI 10.1093/milmed/usz189
   Fiedler S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00335
   Filimon F, 2013, J NEUROSCI, V33, P2121, DOI 10.1523/JNEUROSCI.2334-12.2013
   Flin R.H., 1997, DECISION MAKING STRE
   Foley P, 2010, NEUROSCI BIOBEHAV R, V35, P91, DOI 10.1016/j.neubiorev.2010.01.010
   Franke C, 2017, SPAT COGN COMPUT, V17, P20, DOI 10.1080/13875868.2016.1219912
   Gagnon SA, 2016, ANN NY ACAD SCI, V1369, P55, DOI 10.1111/nyas.12996
   Gamble KR, 2018, INT J PSYCHOPHYSIOL, V131, P73, DOI 10.1016/j.ijpsycho.2018.03.017
   Gigerenzer G., 2008, RATIONALITY MORTALS, P256
   Giles GE, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113618
   Green N, 2009, PROG BRAIN RES, V174, P207, DOI 10.1016/S0079-6123(09)01317-X
   Grillon C, 2004, BEHAV NEUROSCI, V118, P916, DOI 10.1037/0735-7044.118.5.916
   Hansen AL, 2009, ANXIETY STRESS COPIN, V22, P77, DOI 10.1080/10615800802272251
   Heekeren HR, 2008, NAT REV NEUROSCI, V9, P467, DOI 10.1038/nrn2374
   Heekeren HR, 2004, NATURE, V431, P859, DOI 10.1038/nature02966
   Hooge LTC, 1996, PERCEPT PSYCHOPHYS, V58, P969, DOI 10.3758/BF03206825
   Hupbach A, 2012, BEHAV NEUROSCI, V126, P819, DOI 10.1037/a0030489
   Jensen AE, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02964
   Jha AP, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116889
   Joëls M, 2006, TRENDS COGN SCI, V10, P152, DOI 10.1016/j.tics.2006.02.002
   Julius K., 1986, Handbook of Motivation and Cognition: Foundations of Social Behavior, P404
   Kavanagh J., 2005, STRESS PERFORMANCE R
   Keller AM, 2020, COGN RES, V5, DOI 10.1186/s41235-020-00245-2
   Kemeny ME, 2003, CURR DIR PSYCHOL SCI, V12, P124, DOI 10.1111/1467-8721.01246
   Kerous B, 2020, J AMB INTEL HUM COMP, V11, P6033, DOI 10.1007/s12652-020-01858-7
   Kim EJ, 2015, LEARN MEMORY, V22, P411, DOI 10.1101/lm.037291.114
   KIRSCHBAUM C, 1994, PSYCHONEUROENDOCRINO, V19, P313, DOI 10.1016/0306-4530(94)90013-2
   Kisker J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.716318
   Kothe C., 2021, LAB STREAMING LAYER
   KOZLOWSKI LT, 1977, J EXP PSYCHOL HUMAN, V3, P590, DOI 10.1037/0096-1523.3.4.590
   Krajbich I, 2010, NAT NEUROSCI, V13, P1292, DOI 10.1038/nn.2635
   Kudielka BM, 2004, PSYCHONEUROENDOCRINO, V29, P983, DOI 10.1016/j.psyneuen.2003.08.009
   Kudielka BM, 2005, BIOL PSYCHOL, V69, P113, DOI 10.1016/j.biopsycho.2004.11.009
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Lang PJ, 2008, A8 U FLOR
   Ledford AK, 2020, BEHAV MED, V46, P290, DOI 10.1080/08964289.2020.1712648
   Levine A, 2007, PHYSIOL BEHAV, V90, P43, DOI 10.1016/j.physbeh.2006.08.025
   Liberzon I, 1999, BIOL PSYCHIAT, V45, P817, DOI 10.1016/S0006-3223(98)00246-7
   Lipshitz R, 1997, ORGAN BEHAV HUM DEC, V69, P149, DOI 10.1006/obhd.1997.2679
   LUINE V, 1994, BRAIN RES, V639, P167, DOI 10.1016/0006-8993(94)91778-7
   Martin K, 2019, HUM FACTORS, V61, P1205, DOI 10.1177/0018720819839817
   Mather M, 2011, PERSPECT PSYCHOL SCI, V6, P114, DOI 10.1177/1745691611400234
   McCarley JS, 2004, PSYCHOL SCI, V15, P302, DOI 10.1111/j.0956-7976.2004.00673.x
   McCullough AM, 2015, NEUROBIOL LEARN MEM, V123, P1, DOI 10.1016/j.nlm.2015.04.007
   McEwen BS, 2007, PHYSIOL REV, V87, P873, DOI 10.1152/physrev.00041.2006
   Meyers J.L., 2014, HDB LEARNING COGNITI
   Miletic S, 2016, J NEUROSCI, V36, P5909, DOI 10.1523/JNEUROSCI.0894-16.2016
   Miller R, 2013, PSYCHONEUROENDOCRINO, V38, P941, DOI 10.1016/j.psyneuen.2012.09.013
   Morales JM, 2021, PROC SPIE, V11749, DOI 10.1117/12.2587098
   Nagy T, 2015, BIOL PSYCHOL, V109, P111, DOI 10.1016/j.biopsycho.2015.04.012
   Nater UM, 2009, PSYCHONEUROENDOCRINO, V34, P486, DOI 10.1016/j.psyneuen.2009.01.014
   Nater UM, 2006, PSYCHONEUROENDOCRINO, V31, P49, DOI 10.1016/j.psyneuen.2005.05.010
   Nater UM, 2005, INT J PSYCHOPHYSIOL, V55, P333, DOI 10.1016/j.ijpsycho.2004.09.009
   Oei NYL, 2006, STRESS, V9, P133, DOI 10.1080/10253890600965773
   Olver JS, 2015, STRESS HEALTH, V31, P115, DOI 10.1002/smi.2533
   Pabst S, 2013, BEHAV BRAIN RES, V250, P39, DOI 10.1016/j.bbr.2013.04.046
   Padgett DA, 2003, TRENDS IMMUNOL, V24, P444, DOI 10.1016/S1471-4906(03)00173-X
   Pakhomov SVS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229942
   Parsons IT, 2019, FRONT PHYSIOL, V10, DOI 10.3389/fphys.2019.01485
   Patton D., 2013, P 22 ANN C BEH REPR
   Patton D, 2016, LECT NOTES ARTIF INT, V9743, P372, DOI 10.1007/978-3-319-39955-3_35
   Payne BK, 2001, J PERS SOC PSYCHOL, V81, P181, DOI 10.1037/0022-3514.81.2.181
   Philiastides MG, 2011, CURR BIOL, V21, P980, DOI 10.1016/j.cub.2011.04.034
   Philiastides MG, 2006, CEREB CORTEX, V16, P509, DOI 10.1093/cercor/bhi130
   Porcelli AJ, 2008, PHYSIOL BEHAV, V95, P282, DOI 10.1016/j.physbeh.2008.04.027
   Richardson AE, 2011, PHYSIOL BEHAV, V103, P459, DOI 10.1016/j.physbeh.2011.03.019
   Robinson OJ, 2011, COGN AFFECT BEHAV NE, V11, P217, DOI 10.3758/s13415-011-0030-5
   Roozendaal B, 2009, NAT REV NEUROSCI, V10, P423, DOI 10.1038/nrn2651
   Sapolsky RM, 2000, ENDOCR REV, V21, P55, DOI 10.1210/er.21.1.55
   Schwabe L, 2007, LEARN MEMORY, V14, P109, DOI 10.1101/lm.435807
   Schwabe L, 2012, NEUROSCI BIOBEHAV R, V36, P1740, DOI 10.1016/j.neubiorev.2011.07.002
   Seddon JA, 2020, PSYCHONEUROENDOCRINO, V116, DOI 10.1016/j.psyneuen.2020.104582
   Seidel EM, 2015, HUM BRAIN MAPP, V36, P744, DOI 10.1002/hbm.22661
   Shadlen MN, 2013, NEURON, V80, P791, DOI 10.1016/j.neuron.2013.10.047
   Shelton AL, 2001, COGNITIVE PSYCHOL, V43, P274, DOI 10.1006/cogp.2001.0758
   SHEPARD RN, 1967, J VERB LEARN VERB BE, V6, P156, DOI 10.1016/S0022-5371(67)80067-7
   Shields GS, 2019, PSYCHONEUROENDOCRINO, V108, P78, DOI 10.1016/j.psyneuen.2019.06.001
   Shields GS, 2017, PSYCHOL BULL, V143, P636, DOI 10.1037/bul0000100
   Shields GS, 2016, NEUROSCI BIOBEHAV R, V68, P651, DOI 10.1016/j.neubiorev.2016.06.038
   Shields GS, 2015, PSYCHONEUROENDOCRINO, V58, P91, DOI 10.1016/j.psyneuen.2015.04.017
   Sloan RP, 1996, PSYCHOSOM MED, V58, P25, DOI 10.1097/00006842-199601000-00005
   Smith C. D., 1984, J ENVIRON PSYCHOL, V4, P229, DOI [10.1016/S0272-4944(84)80044-4, DOI 10.1016/S0272-4944(84)80044-4]
   Smith Sean M, 2006, Dialogues Clin Neurosci, V8, P383
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Standage D, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00236
   Starcke K, 2012, NEUROSCI BIOBEHAV R, V36, P1228, DOI 10.1016/j.neubiorev.2012.02.003
   SUESS WM, 1980, PSYCHOPHYSIOLOGY, V17, P535, DOI 10.1111/j.1469-8986.1980.tb02293.x
   Sullivan-Kwantes W, 2021, J SCI MED SPORT, V24, P954, DOI 10.1016/j.jsams.2020.11.010
   Susindar Sahinya, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P252, DOI 10.1177/1071181319631509
   Taylor MK, 2008, MIL MED, V173, P738, DOI 10.7205/MILMED.173.8.738
   Terkelsen AJ, 2005, AUTON NEUROSCI-BASIC, V121, P101, DOI 10.1016/j.autneu.2005.07.001
   Terse-Thakoor T, 2020, NPJ FLEX ELECTRON, V4, DOI 10.1038/s41528-020-00081-w
   Troxel Wendy M, 2015, Rand Health Q, V5, P19
   UMEDA T, 1981, CLIN CHIM ACTA, V110, P245
   van Stegeren AH, 2008, INT J PSYCHOPHYSIOL, V69, P33, DOI 10.1016/j.ijpsycho.2008.02.008
   VANDOORNEN LJP, 1992, PSYCHOPHYSIOLOGY, V29, P173
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1020, DOI 10.1037/0022-3514.54.6.1020
   Werkhoven P, 2014, DISPLAYS, V35, P110, DOI 10.1016/j.displa.2014.04.001
   ZELINSKY G, 1995, STUD VIS INFORM PROC, V6, P325
   Zimmer P, 2019, PSYCHONEUROENDOCRINO, V101, P186, DOI 10.1016/j.psyneuen.2018.11.010
NR 146
TC 1
Z9 1
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 17
PY 2023
VL 4
AR 951435
DI 10.3389/frvir.2023.951435
PG 22
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YF0
UT WOS:001023329700001
OA gold
DA 2024-07-18
ER

PT J
AU Piumsomboon, T
   Ong, G
   Urban, C
   Ens, B
   Topliss, J
   Bai, XL
   Hoermann, S
AF Piumsomboon, Thammathip
   Ong, Gavin
   Urban, Cameron
   Ens, Barrett
   Topliss, Jack
   Bai, Xiaoliang
   Hoermann, Simon
TI Ex-Cit XR: Expert-elicitation and validation of Extended Reality
   visualisation and interaction techniques for disengaging and
   transitioning users from immersive virtual environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE elicitation; disengagement; immersive virtual environment; Extended
   Reality; Mixed Reality; Augmented Reality; Virtual Reality; behavioral
   manipulation
AB This research explores visualisation and interaction techniques to disengage users from immersive virtual environments (IVEs) and transition them back to the Augmented Reality mode in the real world. To gain a better understanding and novel ideas, we invited eleven Extended Reality (XR) experts to participate in an elicitation study to design such techniques for disengagement. From the elicitation study, we elicited a total of 132 techniques for four different scenarios of IVEs: Narrative-driven, Social-platform, Adventure Sandbox, and Fast-paced Battle experiences. Through extracted keywords and thematic analysis, we classified the elicited techniques into six categories of Activities, Breaks, Cues, Degradations, Notifications, and Virtual Agents. We shared our analyses on users' intrinsic motivation to engage in different experiences, subjective ratings of four design attributes in designing the disengagement techniques, Positive and Negative Affect Schedules, and user preference. In addition, we gave the design patterns found and illustrated the exemplary user cases of Ex-Cit XR. Finally, we conducted an online survey to preliminarily validate our design recommendations. We proposed the SPINED behavioural manipulation spectrum for XR disengagement to guide how the systems can strategically escalate to disengage users from an IVE.
C1 [Piumsomboon, Thammathip; Ong, Gavin; Urban, Cameron; Topliss, Jack; Hoermann, Simon] Univ Canterbury, Fac Engn, Sch Prod Design, Christchurch, New Zealand.
   [Ens, Barrett] Monash Univ, Dept Human Ctr Comp, Melbourne, Vic, Australia.
   [Bai, Xiaoliang] Northwestern Polytech Univ, Cyber Phys Interact Lab, Xian, Peoples R China.
C3 University of Canterbury; Monash University; Northwestern Polytechnical
   University
RP Piumsomboon, T (corresponding author), Univ Canterbury, Fac Engn, Sch Prod Design, Christchurch, New Zealand.
EM tham.piumsomboon@canterbury.ac.nz
FU College of Engineering Strategic Research Fund of the University of
   Canterbury, New Zealand; National Natural Science Foundation of China
   (NSFC) [61850410532]
FX & nbsp;This research was supported by the College of Engineering
   Strategic Research Fund of the University of Canterbury, New Zealand,
   and the National Natural Science Foundation of China (NSFC), Grant No:
   61850410532.
CR Ali AX, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P177, DOI 10.1145/3242587.3242621
   Baker H., OCULUS QUEST 2SPACE
   Bar-Zeev A., 2015, BARZEEV A
   Barreda-Angeles M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107047
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Billinghurst M., 2008, ACM SIGGRAPH ASIA, V7, P1, DOI [10.1145/1508044.1508051, DOI 10.1145/1508044.1508051]
   Boellstorff Tom, 2015, Coming of age in Second Life
   Dao E., 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764.3445435, 10.1145/3411764.3445435]
   Webber FD, 2016, Arxiv, DOI arXiv:1511.08855
   Deci E.L., 1985, INTRINSIC MOTIVATION, DOI [10.1007/978-1-4899-2271-7, DOI 10.1007/978-1-4899-2271-7]
   Desolda G, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3057859
   Dey A, 2022, INT J HUM-COMPUT ST, V160, DOI 10.1016/j.ijhcs.2021.102762
   Dey A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4045, DOI 10.1145/3025453.3026028
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fender AR, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501836
   Fullerton Tracy., 2019, GAME DESIGN WORKSHOP, V4th
   Galea, BRIDG MIX REAL NEUR
   Gao L., 2017, REAL TIME VISUAL REP
   George C, 2020, INT SYM MIX AUGMENT, P412, DOI 10.1109/ISMAR50242.2020.00067
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Gottsacker M, 2021, INT SYM MIX AUGMENT, P310, DOI 10.1109/ISMAR52148.2021.00047
   Gumilar I, 2021, COMPUT GRAPH-UK, V94, P62, DOI 10.1016/j.cag.2020.10.003
   Halbig A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.837616
   Hart JD, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION EXTENDED ABSTRACTS (CHI PLAY 2018), P453, DOI 10.1145/3270316.3271543
   Hart JD, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P212, DOI 10.1109/ISMAR-Adjunct.2018.00069
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Hassib M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5114, DOI 10.1145/3025453.3025669
   Hayden S., VARJOS ENTHUSIAST GR
   Hayden S., VALVE OPENBCI TOBII
   Heaney D., VALVE INDEX GETS 3D
   Heaney D., META QUEST PROHANDS
   Hodent C., 2017, The Gamer's Brain: How Neuroscience and UX Can Impact Video Game Design
   Irlitti A, 2019, IEEE T VIS COMPUT GR, V25, P3178, DOI 10.1109/TVCG.2019.2932173
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Jung S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P267, DOI 10.1109/VR.2018.8447562
   Kim MJ, 2019, INT J INFORM MANAGE, V46, P236, DOI 10.1016/j.ijinfomgt.2018.11.016
   Kitson A, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P655, DOI 10.1145/3357236.3395560
   Knibbe J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174057
   Kudo Yoshiki, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3486950
   Lang B., VIVE FOCUS 2 0 UPDAT
   Lang B., MICROSOFT IS ADDING
   Lee G.A., 2017, ICAT EGVE 2017 INT C, P197, DOI DOI 10.2312/EGVE.20171359
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Lisle L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI 10.1109/VR50410.2021.00077
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Maloney D, 2021, IDC '21: PROCEEDINGS OF INTERACTION DESIGN AND CHILDREN 2021, P69, DOI 10.1145/3459990.3460703
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Miltenberger R.G., 2015, Behavior modification: Principles and procedures, V4th
   Morris Meredith Ringel, 2014, Interactions, V21, P40, DOI [DOI 10.1145/2591689, 10.1145/2591689]
   Niki K, 2021, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.598161
   Noggle R., 2018, ETHICS MANIPULATION
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P19, DOI 10.1145/3393712.3395339
   Piumsomboon Thammathip, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P38, DOI 10.1109/ISUVR.2017.20
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186495
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139200
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P365
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Putze S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376144
   Saravanan M., 2018, P IEEE INT C BIG DAT, P1, DOI [10.1145/3227696.3227720, DOI 10.1145/3227696.3227720]
   Schell J., 2008, The Art of Game Design: A Book of Lenses
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Skarbez R., 2021, FRONT VIRTUAL REAL, V2, P647997, DOI [DOI 10.3389/FRVIR.2021.647997, 10.3389/frvir.2021.647997]
   Skinner B. F., 1938, The behavior of organisms: An experimental analysis
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sra M., 2021, arXiv
   Sra M, 2018, IEEE T VIS COMPUT GR, V24, P3174, DOI 10.1109/TVCG.2017.2762691
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Steptoe W., 2013, AR RIFT STEREO CAMER
   Thanyadit Santawat, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512983
   Thorndike E. L., 1898, Psychol Review Monograph Supplement, pUnpaginated
   Tran JQD, 2020, PLATELETS, V31, P365, DOI 10.1080/09537104.2019.1636019
   Valkov D, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P12, DOI 10.1145/3131277.3132183
   Varjo (n.d.), VARJ XR 3 MIX REAL H
   von Willich J, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P487, DOI 10.1145/3322276.3322334
   Wassom, 2014, AUGMENTED REALITY LA
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wikipedia (n.d.), LIST MOST PLAYED VID
   Yoon HJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94680-w
   Zagal J., 2013, Foundations of Digital Games 2013
   Zenner A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188505
   Zhang JJ, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.672537
   Zhou ZY, 2011, INT J INFORM MANAGE, V31, P261, DOI 10.1016/j.ijinfomgt.2010.07.007
NR 88
TC 2
Z9 2
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 14
PY 2022
VL 3
AR 943696
DI 10.3389/frvir.2022.943696
PG 27
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WN0
UT WOS:001023285600001
OA gold
DA 2024-07-18
ER

PT J
AU He, CXY
   Chrastil, ER
   Hegarty, M
AF He, Chuanxiuyue
   Chrastil, Elizabeth R.
   Hegarty, Mary
TI A new psychometric task measuring spatial perspective taking in
   ambulatory virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE perspective taking; immersive virtual reality; spatial cognition;
   embodied cognition; navigation
ID PATH-INTEGRATION; INDIVIDUAL-DIFFERENCES; SEX-DIFFERENCES;
   SOCIAL-SKILLS; ORIENTATION; REPRESENTATIONS; DISSOCIATION; RELIABILITY;
   DIRECTIONS; NAVIGATION
AB Spatial perspective taking is an essential cognitive ability that enables people to imagine how an object or scene would appear from a perspective different from their current physical viewpoint. This process is fundamental for successful navigation, especially when people utilize navigational aids (e.g., maps) and the information provided is shown from a different perspective. Research on spatial perspective taking is primarily conducted using paper-pencil tasks or computerized figural tasks. However, in daily life, navigation takes place in a three-dimensional (3D) space and involves movement of human bodies through space, and people need to map the perspective indicated by a 2D, top down, external representation to their current 3D surroundings to guide their movements to goal locations. In this study, we developed an immersive viewpoint transformation task (iVTT) using ambulatory virtual reality (VR) technology. In the iVTT, people physically walked to a goal location in a virtual environment, using a first-person perspective, after viewing a map of the same environment from a top-down perspective. Comparing this task with a computerized version of a popular paper-and-pencil perspective taking task (SOT: Spatial Orientation Task), the results indicated that the SOT is highly correlated with angle production error but not distance error in the iVTT. Overall angular error in the iVTT was higher than in the SOT. People utilized intrinsic body axes (front/back axis or left/right axis) similarly in the SOT and the iVTT, although there were some minor differences. These results suggest that the SOT and the iVTT capture common variance and cognitive processes, but are also subject to unique sources of error caused by different cognitive processes. The iVTT provides a new immersive VR paradigm to study perspective taking ability in a space encompassing human bodies, and advances our understanding of perspective taking in the real world.
C1 [He, Chuanxiuyue; Hegarty, Mary] Univ Calif Santa Barbara, Dept Psychol & Brain Sci, Santa Barbara, CA 93106 USA.
   [Chrastil, Elizabeth R.] Univ Calif Irvine, Dept Neurobiol & Behav, Irvine, CA USA.
   [Chrastil, Elizabeth R.] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA USA.
C3 University of California System; University of California Santa Barbara;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine
RP He, CXY (corresponding author), Univ Calif Santa Barbara, Dept Psychol & Brain Sci, Santa Barbara, CA 93106 USA.
EM c_he@ucsb.edu
RI He, Chuanxiuyue/JUV-2805-2023
OI He, Chuanxiuyue/0000-0002-5819-7171
FU National Science Foundation [2024633]
FX This work was supported by the National Science Foundation (NSF-FO award
   ID 2024633).
CR Ackerman PL, 2020, INTELLIGENCE, V80, DOI 10.1016/j.intell.2020.101440
   Allen GL, 1996, INTELLIGENCE, V23, P157, DOI 10.1016/S0160-2896(96)90010-0
   Baron-Cohen S, 2005, SCIENCE, V310, P819, DOI 10.1126/science.1115455
   Barry C, 2006, REV NEUROSCIENCE, V17, P71
   Brucato M, 2023, TOP COGN SCI, V15, P46, DOI 10.1111/tops.12597
   Bryant DJ, 1999, J EXP PSYCHOL LEARN, V25, P137, DOI 10.1037/0278-7393.25.1.137
   Campos JL, 2014, EXP BRAIN RES, V232, P3277, DOI 10.1007/s00221-014-4011-0
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chrastil ER, 2021, J EXP PSYCHOL HUMAN, V47, P13, DOI 10.1037/xhp0000875
   Chrastil ER, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.06.010
   Chrastil ER, 2017, EXP BRAIN RES, V235, P1885, DOI 10.1007/s00221-017-4910-y
   Chrastil ER, 2013, J EXP PSYCHOL LEARN, V39, P1520, DOI 10.1037/a0032382
   de Vega M, 2001, EUR J COGN PSYCHOL, V13, P369
   Ferrara K, 2016, NEUROPSYCHOLOGIA, V89, P180, DOI 10.1016/j.neuropsychologia.2016.05.012
   FRANKLIN N, 1990, J EXP PSYCHOL GEN, V119, P63, DOI 10.1037/0096-3445.119.1.63
   Friedman A, 2020, BEHAV RES METHODS, V52, P799, DOI 10.3758/s13428-019-01277-3
   Galati A, 2018, LANG COGN NEUROSCI, V33, P467, DOI 10.1080/23273798.2017.1384029
   Grant SC, 1998, HUM FACTORS, V40, P489, DOI 10.1518/001872098779591296
   Gunalp P, 2021, PSYCHON B REV, V28, P1289, DOI 10.3758/s13423-021-01896-y
   Gunalp P, 2019, MEM COGNITION, V47, P1031, DOI 10.3758/s13421-019-00910-y
   Hedge C, 2018, BEHAV RES METHODS, V50, P1166, DOI 10.3758/s13428-017-0935-1
   Hegarty M, 2006, INTELLIGENCE, V34, P151, DOI 10.1016/j.intell.2005.09.005
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   HINTZMAN DL, 1981, COGNITIVE PSYCHOL, V13, P149, DOI 10.1016/0010-0285(81)90007-4
   Holmes CA, 2017, J EXP PSYCHOL LEARN, V43, P851, DOI 10.1037/xlm0000346
   Huffman DJ, 2019, SPAT COGN COMPUT, V19, P93, DOI 10.1080/13875868.2018.1531869
   JOHNSON DW, 1975, J PERS SOC PSYCHOL, V31, P241, DOI 10.1037/h0076285
   Kearns MJ, 2002, PERCEPTION, V31, P349, DOI 10.1068/p3311
   Kessler K, 2012, SPAT COGN COMPUT, V12, P133, DOI 10.1080/13875868.2011.634533
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Kozhevnikov M, 2001, MEM COGNITION, V29, P745, DOI 10.3758/BF03200477
   Lever C, 2009, J NEUROSCI, V29, P9771, DOI 10.1523/JNEUROSCI.1319-09.2009
   LEVINE M, 1982, J EXP PSYCHOL GEN, V111, P157, DOI 10.1037/0096-3445.111.2.157
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   LOOMIS JM, 1993, J EXP PSYCHOL GEN, V122, P73, DOI 10.1037/0096-3445.122.1.73
   May M, 2004, COGNITIVE PSYCHOL, V48, P163, DOI 10.1016/S0010-0285(03)00127-0
   Montello DR, 2004, HUMAN SPATIAL MEMORY: REMEMBERING WHERE, P251
   Montello DR, 1999, PERCEPTION, V28, P981, DOI 10.1068/p2940
   Parsons S, 2019, ADV METH PRACT PSYCH, V2, P378, DOI 10.1177/2515245919879695
   Petzschner FH, 2011, J NEUROSCI, V31, P17220, DOI 10.1523/JNEUROSCI.2028-11.2011
   PRESSON CC, 1984, J EXP PSYCHOL LEARN, V10, P716, DOI 10.1037/0278-7393.10.4.716
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Schneider W., 2012, E-Prime 2.0 reference guide manual
   Schwartz M, 1999, J EXP PSYCHOL HUMAN, V25, P852, DOI 10.1037/0096-1523.25.3.852
   Shelton AL, 2012, J EXP PSYCHOL GEN, V141, P199, DOI 10.1037/a0024617
   Solstad T, 2008, SCIENCE, V322, P1865, DOI 10.1126/science.1166466
   Tarampi MR, 2016, PSYCHOL SCI, V27, P1507, DOI 10.1177/0956797616667459
   Weisberg SM, 2014, J EXP PSYCHOL LEARN, V40, P669, DOI 10.1037/a0035261
   Wraga M, 2003, J EXP PSYCHOL LEARN, V29, P993, DOI 10.1037/0278-7393.29.5.993
NR 49
TC 1
Z9 1
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 6
PY 2022
VL 3
AR 971502
DI 10.3389/frvir.2022.971502
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YK2
UT WOS:001023335000001
OA gold
DA 2024-07-18
ER

PT J
AU Georgieva, I
   Georgiev, GV
AF Georgieva, Iva
   Georgiev, Georgi V.
TI Narrative self-recreation in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; narrative; self-recreation; trauma; healthcare;
   storytelling; therapeutic approach; self-construction
ID IDENTITY
AB The narrative essence of human nature is that humans are storytellers, and this ability helps to constitute our identities. Challenges that disrupt this innate ability are adverse events that affect the human perception of the world and undermine the meaning one finds in reality. Such events might range from short-term stressors to long-term testing conditions such as pandemics. Tools for overcoming these negative effects and for achieving self-preservation might be sought in individual storytelling abilities in relation to self-constitution and identification. An example of an interactive digital narrative medium that provides a platform for such expression of complex issues is virtual reality (VR), which has been used as a visual narrative storytelling tool for decades. This study sets the notion of trauma in a new light, as a break in the individual story used to explain one's life and as a story to be intertwined with and re-adapted to one's overall lifetime. In the healthcare context, this experience can be most effectively presented in VR because it offers added meaning, potential choices, closure, and resolution as methods of utilization. Therefore, VR can be seen not only as a medium whereby traumatic events can be processed but also as an alternative viewpoint of the goal of self-(re)creation. This research discusses a theoretical proposal for ways of playing with self-construction mechanisms in the context of an immersive VR environment to create more opportunities to change one's narrative and, hence, one's real-life story.
C1 [Georgieva, Iva] Bulgarian Acad Sci, Inst Philosophy & Sociol, Sofia, Bulgaria.
   [Georgieva, Iva] Inst Adv Study, Varna, Bulgaria.
   [Georgiev, Georgi V.] Univ Oulu, Ctr Ubiquitous Comp, Oulu, Finland.
C3 Bulgarian Academy of Sciences; University of Oulu
RP Georgieva, I (corresponding author), Bulgarian Acad Sci, Inst Philosophy & Sociol, Sofia, Bulgaria.; Georgieva, I (corresponding author), Inst Adv Study, Varna, Bulgaria.
EM ivavgeorgieva@gmail.com
RI Georgiev, Georgi V./I-3197-2017
OI Georgiev, Georgi V./0000-0002-3127-9820; Georgieva,
   Iva/0000-0001-9458-8690
FU Academy of Finland 6G Flagship [346208]; European Union's Horizon 2020
   research and innovation programme [H2020-856998]
FX This work was supported by the Academy of Finland 6G Flagship (grant
   346208) and European Union's Horizon 2020 research and innovation
   programme (grant number H2020-856998).
CR Angus R., 2013, BU Journal of Graduate Studies in Education, V5, P17
   Baceviciute Sarune, 2012, Interactive Storytelling. Proceedings of the 5th International Conference, ICIDS 2012, P48, DOI 10.1007/978-3-642-34851-8_5
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Baker Steven, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3434176
   Botella C, 2008, DEATH STUD, V32, P674, DOI 10.1080/07481180802231319
   Brailas A., 2021, Global Journal of Community Psychology Practice, V12, P1
   Brown SA, 2021, LECT NOTES COMPUT SC, V13138, P312, DOI 10.1007/978-3-030-92300-6_30
   Bruce T. A., 2020, P 33 INT BCS HUM COM, DOI [10.14236/ewic/HCI20DC.19, DOI 10.14236/EWIC/HCI20DC.19]
   Bryant L, 2020, DISABIL REHABIL-ASSI, V15, P365, DOI 10.1080/17483107.2018.1549276
   Bucher J, 2018, STORYTELLING FOR VIRTUAL REALITY: METHODS AND PRINCIPLES FOR CRAFTING IMMERSIVE NARRATIVES, P1
   Caruth Cathy., 1995, Trauma: Explorations in Memory
   Coyle D., 2012, CHI 12 EXTENDED ABST, P2775
   De La Lama L B., 2011, Counseling a terminally ill agnostic seeking to reclaim spirituality: A narrative approach to dying well
   Dilgul M., 2021, DEV FEASIBILITY VIRT
   Fenison C, 2020, THESIS U N CAROLINA
   Franco GE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01657
   Frewen P, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00858
   Gallon R., 2021, LIGHTS CAMERA INTERA
   Georgiev DD, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11020221
   Georgieva I, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010026
   Georgieva I, 2019, BEHAV SCI-BASEL, V9, DOI 10.3390/bs9110111
   Georgieva I, 2011, STUD HEALTH TECHNOL, V167, P20, DOI 10.3233/978-1-60750-766-6-20
   Gong ZY, 2022, PROCEEDINGS OF THE 14TH CREATIVITY AND COGNITION, C&C 2022, P510, DOI 10.1145/3527927.3535205
   Gong ZY, 2022, DIGIT CREAT, V33, P96, DOI 10.1080/14626268.2022.2064879
   Hacmun I, 2021, ART PSYCHOTHER, V72, DOI 10.1016/j.aip.2020.101745
   Hammond N., 2017, THESIS ATHABASCA U A
   Higgins M., 2021, THESIS U PORTSMOUTH
   Hoydis J, 2021, OPEN LIBR HUMANIT, V7, DOI 10.16995/olh.4695
   Hu X., 2021, Proceedings of the Design Society, V1, P2601, DOI [10.1017/pds.2021.521, DOI 10.1017/PDS.2021.521]
   Huberman A., 2021, ERASING FEAR TRAUMAS
   Jeffs T.L., 2009, Themes in Science and Technology Education, V2, P253
   Kamkuimo SA, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156683
   Knaevelsrud C, 2014, J NERV MENT DIS, V202, P651, DOI 10.1097/NMD.0000000000000178
   Koenitz H., 2022, GAMES NARRATIVE THEO, P207
   Koenitz H, 2021, LECT NOTES COMPUT SC, V13138, P488, DOI 10.1007/978-3-030-92300-6_49
   Koenitz H, 2018, LECT NOTES COMPUT SC, V11318, P107, DOI 10.1007/978-3-030-04028-4_8
   Kybartas B, 2017, IEEE T COMP INTEL AI, V9, P239, DOI 10.1109/TCIAIG.2016.2546063
   Lanyi C.S., 2006, The International Journal of Virtual Reality, V5, P55
   Lee E, 2022, CLIN SOC WORK J, V50, P147, DOI 10.1007/s10615-021-00816-w
   Lee MR, 2021, WORLDV EVID-BASED NU, V18, P50, DOI 10.1111/wvn.12478
   Markham A., 1998, Life Online: Researching Real Experiences in Virtual Space
   McAdams DanP., 1993, The Stories We Live By: personal myths and the making of the self
   McLean KC, 2005, DEV PSYCHOL, V41, P683, DOI 10.1037/0012-1649.41.4.683
   McMahon E., 2022, DIGITAL DELIVERY MEN, P256
   McSweeney Terence., 2019, Through the Black Mirror, P271
   Mehl-Madrona L., 2010, Healing the mind through the power of story
   Mochocka A., 2022, GAMES NARRATIVE THEO, P315
   Montesano A, 2021, TRIALS, V22, DOI 10.1186/s13063-021-05809-1
   Moran S, 2013, J REHABIL, V79, P34
   Murray J.H., 2016, Hamlet on the Holodeck
   Nagy P, 2014, CONVERGENCE-US, V20, P276, DOI 10.1177/1354856514531532
   Neimeyer R., 2014, Handbook of posttraumatic growth, P82, DOI DOI 10.4324/9781315805597
   Nikpour Khoshgrudi Y., 2021, THESIS U W ONTARIO L
   Nisi V., 2006, CROSSINGS, V2, P27
   Perram M, 2022, DIGIT CREAT, V33, P128, DOI 10.1080/14626268.2022.2074047
   Redmond D. B., 2018, 29 NAT YOUTH ADV RES, P72
   Rettberg S., 2020, ELECT BOOK REV, DOI [10.7273/1ma1-pk87, DOI 10.7273/1MA1-PK87]
   Riva G, 2011, ANN REV CYBERTHERAPY, V9, P2
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Roemmele Melissa., 2017, Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology-From Linguistic Signal to Clinical Reality, P48
   Rosenthal G, 2003, QUAL INQ, V9, P915, DOI 10.1177/1077800403254888
   Roth B., 2015, NARRATIVE PHILOS LIF, P81
   Roth C, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P247, DOI 10.1145/3317697.3325124
   Ryu S, 2022, ARTS HEALTH, V14, P326, DOI 10.1080/17533015.2021.1942939
   Sartre J. P., 2021, NAUSEA
   Schachter EP, 2005, IDENTITY, V5, P137, DOI 10.1207/s1532706xid0502_4
   Schanzel D., 2022, Games and narrative: Theory and practice, P61
   Schechtman M, 2014, Staying alive: personal identity, practical concerns, and the unity of a life, DOI [10.1093/acprof:oso/9780199684878.001.0001, DOI 10.1093/ACPROF:OSO/9780199684878.001.0001]
   Schechtman Marya., 2012, Philos. Technol, V25, P329, DOI [10.1007/s13347-012-0062-y, DOI 10.1007/S13347-012-0062-Y]
   Setlak W., 2022, GAMES NARRATIVE THEO, P327
   Shibolet Y., 2019, THESIS UTRECHT U UTR
   Smethurst T, 2015, GAMES CULT, V10, P269, DOI 10.1177/1555412014559306
   Soares L., 2012, 26 BCS C HUM COMP IN, V26, P1, DOI [10.14236/ewic/HCI2012.80, DOI 10.14236/EWIC/HCI2012.80]
   Spencer S., 2018, THESIS ROCHESTER I T
   Strickland D, 1997, ST HEAL T, V44, P81
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
   Torres Pernas G., 2020, THESIS U CORUNA CORU
   Turkle S., 1994, MIND CULT ACT, V1, P158, DOI [DOI 10.1080/10749039409524667, https://doi.org/10.1080/10749039409524667]
   Twist D. M., 2015, THESIS GEORGE FOX U
NR 79
TC 1
Z9 1
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 29
PY 2022
VL 3
AR 854333
DI 10.3389/frvir.2022.854333
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WS6
UT WOS:001023291200001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Stefanucci, JK
   Brickler, D
   Finney, HC
   Wilson, E
   Drew, T
   Creem-Regehr, SH
AF Stefanucci, Jeanine K.
   Brickler, David
   Finney, Hunter C.
   Wilson, Emi
   Drew, Trafton
   Creem-Regehr, Sarah H.
TI Effects of simulated augmented reality cueing in a virtual navigation
   task
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; augmented reality; navigation; spatial memory;
   situational awareness; cognitive load
ID SPATIAL KNOWLEDGE ACQUISITION; COMPUTER-AIDED DETECTION; EYE-TRACKING;
   MAPS; STRATEGIES; SEARCH; REPRESENTATIONS; ENVIRONMENTS; IMPAIRMENT;
   SUPPORT
AB Navigational tools are relied on to traverse unfamiliar grounds, but their use may come at a cost to situational awareness and spatial memory due to increased cognitive load. In order to test for a cost-benefit trade off in navigational cues, we implemented a variety of navigation cues known to facilitate target search and spatial knowledge acquisition of an urban virtual environment viewed through an HTC VIVE Pro as a simulation of cues that would be possible using Augmented Reality (AR). We used a Detection Response Task (DRT) during the navigation task to measure cognitive load and situational awareness. Participants searched for targets in the city with access to a map that did or did not have a "you are here" indicator showing the viewer's location as they moved. In addition, navigational beacons were also present or absent in the environment as well as a compass and street name indicator. Participants searched for three separate target objects and then returned back to their starting location in the virtual world. After returning home, as a measure of spatial knowledge acquisition, they pointed toward each target from the home location and pointed to home and to the other targets from each target location. Results showed that the navigational cues aided spatial knowledge without increasing cognitive load as assessed with the DRT. Pointing error was lowest when all navigational cues were present during navigation and when pointing was done from home to the target objects. Participants who received the "you are here" indicator on their map consulted the map more often, but without detrimental effects for the acquisition of spatial knowledge compared to a map with no indicator. Taken together, the results suggest that navigational cues can help with spatial learning during navigation without additional costs to situational awareness.
C1 [Stefanucci, Jeanine K.; Brickler, David; Finney, Hunter C.; Wilson, Emi; Drew, Trafton; Creem-Regehr, Sarah H.] Univ Utah, Dept Psychol, Salt Lake City, UT 84112 USA.
C3 Utah System of Higher Education; University of Utah
RP Creem-Regehr, SH (corresponding author), Univ Utah, Dept Psychol, Salt Lake City, UT 84112 USA.
EM sarah.creem@psych.utah.edu
FU U.S. Army Combat Capabilities Development Command Soldier Center
   Measuring and Advancing Soldier Tactical Readiness and Effectiveness
   (MASTR-E) [W911NF2020268]; Office of Naval Research [N00014-21-1-2583]
FX This work was funded by the U.S. Army Combat Capabilities Development
   Command Soldier Center Measuring and Advancing Soldier Tactical
   Readiness and Effectiveness (MASTR-E) program under contract
   #W911NF2020268 and by the Office of Naval Research under contract
   #N00014-21-1-2583.
CR Allen GL, 2003, LECT NOTES COMPUT SC, V2825, P390
   [Anonymous], 2016, 17488 ISO DIS
   Bolton A., 2015, P 7 INT C AUT US INT, P56, DOI [DOI 10.1145/2799250.2799253, 10.1145/2799250, DOI 10.1145/2799250, 10.1145/2799250.2799253]
   Brügger A, 2019, COGN RES, V4, DOI 10.1186/s41235-019-0156-5
   Brunyé TT, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0098-3
   Brunyé TT, 2016, INT J HUM-COMPUT ST, V96, P1, DOI 10.1016/j.ijhcs.2016.07.008
   Brunyé TT, 2012, COMPUT HUM BEHAV, V28, P257, DOI 10.1016/j.chb.2011.09.008
   Bruyas M.-P., 2013, Proceedings of the Seventh International Driving Symposium on Human Factors in Driver Assessment, Training, and Vehicle Design, P64, DOI DOI 10.17077/DRIVINGASSESSMENT.1468
   Chen JL, 1999, PRESENCE-TELEOP VIRT, V8, P671, DOI 10.1162/105474699566558
   Chrastil ER, 2012, PSYCHON B REV, V19, P1, DOI 10.3758/s13423-011-0182-x
   Chu Cao, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287033
   Credé S, 2020, J ENVIRON PSYCHOL, V67, DOI 10.1016/j.jenvp.2019.101369
   Dahmani L, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62877-0
   Darken RP, 1999, P IEEE VIRT REAL ANN, P133, DOI 10.1109/VR.1999.756944
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Drew T, 2020, J EXP PSYCHOL-APPL, V26, P659, DOI 10.1037/xap0000277
   Drew T, 2012, ACAD RADIOL, V19, P1260, DOI 10.1016/j.acra.2012.05.013
   Engstr?m J., 2013, Proceedings of the Seventh International Driving Symposium on Human Factors in Driver Assessment, Training, and Vehicle Design, P369
   Epstein RA, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0533
   Gagnon KT, 2018, COGNITION, V180, P108, DOI 10.1016/j.cognition.2018.06.020
   Gardony AL, 2015, SPAT COGN COMPUT, V15, P246, DOI 10.1080/13875868.2015.1059432
   Gardony AL, 2013, SPAT COGN COMPUT, V13, P319, DOI 10.1080/13875868.2013.792821
   Gerber MA, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376751
   Hartmeyer S, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00235
   Hejtmánek L, 2018, INT J HUM-COMPUT ST, V116, P15, DOI 10.1016/j.ijhcs.2018.04.006
   Hilton C, 2020, PSYCHOL RES-PSYCH FO, V84, P1473, DOI 10.1007/s00426-019-01159-5
   Hollands JG, 2019, HUM FACTORS, V61, P763, DOI 10.1177/0018720819825803
   Holscher C., 2007, P 29 ANN COGN SCI SO
   Hupse R, 2013, RADIOLOGY, V266, P123, DOI 10.1148/radiol.12120218
   Ishikawa T, 2006, COGNITIVE PSYCHOL, V52, P93, DOI 10.1016/j.cogpsych.2005.08.003
   Ishikawa T, 2008, J ENVIRON PSYCHOL, V28, P74, DOI 10.1016/j.jenvp.2007.09.002
   Johanson C, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P341, DOI 10.1145/3116595.3116602
   Jose R, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010918
   Knierim JJ, 2011, PHYSIOL REV, V91, P1245, DOI 10.1152/physrev.00021.2010
   König SU, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.625548
   Lawton CA, 2002, SEX ROLES, V47, P389, DOI 10.1023/A:1021668724970
   Liu J, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10855-z
   Löwen H, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8030149
   Lu J.-Y, 2021, 2021 Fifteenth International Congress on Artificial Materials for Novel Wave Phenomena (Metamaterials), P1, DOI 10.1109/Metamaterials52332.2021.9577144
   Montello D.R., 1998, SPATIAL TEMPORAL REA, P143, DOI DOI 10.1088/1748-6041/6/2/025001
   Münzer S, 2020, J EXP PSYCHOL-APPL, V26, P73, DOI 10.1037/xap0000237
   Münzer S, 2012, J EXP PSYCHOL-APPL, V18, P18, DOI 10.1037/a0026553
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   Richardson AE, 1999, MEM COGNITION, V27, P741, DOI 10.3758/BF03211566
   Roskos-Ewoldsen B, 1998, J EXP PSYCHOL LEARN, V24, P215, DOI 10.1037/0278-7393.24.1.215
   Ruddle RA, 1999, J EXP PSYCHOL-APPL, V5, P54, DOI 10.1037/1076-898X.5.1.54
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruginski IT, 2019, J ENVIRON PSYCHOL, V64, P12, DOI 10.1016/j.jenvp.2019.05.001
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Steck SD, 2000, PRESENCE-TELEOP VIRT, V9, P69, DOI 10.1162/105474600566628
   Stojmenova K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020594
   Strayer DL, 2022, J EXP PSYCHOL-APPL, V28, P262, DOI 10.1037/xap0000388
   Strayer DL, 2015, HUM FACTORS, V57, P1300, DOI 10.1177/0018720815575149
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   Weisberg SM, 2018, J EXP PSYCHOL LEARN, V44, P667, DOI 10.1037/xlm0000472
   Young Mark S., 2008, Cognition, Technology & Work, V10, P231, DOI 10.1007/s10111-007-0095-7
NR 58
TC 2
Z9 2
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 29
PY 2022
VL 3
AR 971310
DI 10.3389/frvir.2022.971310
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VW0
UT WOS:001023268400001
OA gold
DA 2024-07-18
ER

PT J
AU Rother, A
   Spiliopoulou, M
AF Rother, Anne
   Spiliopoulou, Myra
TI Virtual Reality for Medical Annotation Tasks: A Systematic Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE immersive virtual reality (VR); medical annotation; eye movement
   monitoring; wearable sensors; eye-tracking; head-mounted display (HMD);
   crowdsourcing; gender-specific differences
ID PERFORMANCE; SKILLS; TOOL
AB Virtual reality technologies are broadly used in medicine, including medical educational tasks like surgery training. Annotations are an inseparable part of many medical research and educational tasks. In this systematic review, we investigate the potential of VR for medical tasks with focus on annotation. The questions we pursue are as follows. (Q1) For which healthcare-associated tasks do we find VR-associated investigations and which involve a crowd worker-based annotation? (Q2) To what extent are there gender-specific differences in the usage of VR? To address these questions, we formulated a keyword list and inclusion/exclusion criteria for the collection of recent scientific articles according to the PRISMA Statement 2020. We queried the Medline database and included 59 free full articles available in English and published from 2017 upward. We inspected the abstracts of the retained articles and organized them into 6 categories that referred to VR in the medical context. We identified categories of medicine-related tasks, for which VR is used, and one category associated to cybersickness. We traced technologies used with a higher priority for some tasks, and we found that gender-related investigations are more widespread for some categories than for others. The main findings of our investigation on the role of VR for medical annotation tasks are as follows: VR was used widely for tasks associated with medicine, including medical research and healthcare, but the use of VR for annotation purposes in that context was very limited. Many of the relevant studies concerned VR in education, where annotations may refer to labeling or other enhancements of materials or may refer to exercises. The investigation of gender-related aspects was typically found in studies that encompassed the usage of VR on patients and controls, or on healthy participants in order to assess the potential and limitations of VR for specific tasks/medical assessments or treatments. To fully exploit the VR potential for tasks of medical annotation, especially for the creation of ground truth datasets and similar resources, more research is needed, especially on the interplay of annotator demographics and accessibility to VR technologies.
C1 [Rother, Anne; Spiliopoulou, Myra] Otto von Guericke Univ, Fac Comp Sci, Magdeburg, Germany.
C3 Otto von Guericke University
RP Rother, A (corresponding author), Otto von Guericke Univ, Fac Comp Sci, Magdeburg, Germany.
EM anne.rother@ovgu.de
OI Rother, Anne/0000-0002-6768-5871
FU Equal Opportunities Fund of the Faculty of Computer Science, Otto von
   Guericke University Magdeburg
FX The student assistant position of author AR has been financed through
   the Equal Opportunities Fund of the Faculty of Computer Science, Otto
   von Guericke University Magdeburg.
CR Alagha MA, 2017, EUR SPINE J, V26, P1298, DOI 10.1007/s00586-017-4949-2
   Aljohaney AA, 2019, ADV MED EDUC PRACT, V10, P63, DOI 10.2147/AMEP.S186275
   Ausburn L. J., 2009, Journal of STEM Teacher Education, V46, P6
   Azkue JJ, 2013, EUR J ANAT, V17, P146
   Bolt E, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94869-z
   Chheang V, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P1, DOI 10.1109/AIVR46125.2019.00011
   Chiang THC, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.608407
   Chiu HY, 2020, J FORMOS MED ASSOC, V119, P462, DOI 10.1016/j.jfma.2019.06.013
   Cikajlo I, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.625225
   Concannon BJ, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/18313
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Czerwinski M., 2002, ACM C HUMAN FACTORS, P195, DOI DOI 10.1145/503376.503412
   de Castell S, 2019, ACTA PSYCHOL, V199, DOI 10.1016/j.actpsy.2019.102895
   Dirin A., 2019, Gender differences in perceptions of conventional video, virtual reality and augmented reality
   Feinerer I, 2008, J STAT SOFTW, V25, P1
   Fernandez-Baizan C, 2019, BEHAV BRAIN RES, V359, P694, DOI 10.1016/j.bbr.2018.09.017
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Haddaway Neal R, 2020, Zenodo, DOI 10.5281/ZENODO.4287835
   Hodgetts CJ, 2020, CORTEX, V124, P97, DOI 10.1016/j.cortex.2019.10.017
   Huaulmé A, 2019, INT J COMPUT ASS RAD, V14, P1663, DOI 10.1007/s11548-019-02008-x
   Johnson B. P., 2021, CROWDSOURCING COGNIT
   Joshi AA, 2018, NEUROIMAGE, V172, P740, DOI 10.1016/j.neuroimage.2018.01.058
   Juliano JM, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00678-2
   Kim Byeol, 2020, JMIR Cardio, V4, pe20633, DOI 10.2196/20633
   Kim N, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.665658
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Kpokiri EE, 2021, BMC INFECT DIS, V21, DOI 10.1186/s12879-021-06628-0
   Legetth O, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103251
   Lier EJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208405
   Madden J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229788
   Marshall IJ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P7, DOI 10.18653/v1/P17-4002
   Matsuda Y, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.654088
   Moro C, 2021, ANAT SCI EDUC, V14, P368, DOI 10.1002/ase.2049
   Mottelson A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.681482
   Nag A, 2020, J MED INTERNET RES, V22, DOI 10.2196/13810
   Nimavat N, 2021, ADV MED EDUC PRACT, V12, P237, DOI 10.2147/AMEP.S295728
   Oussi N, 2021, SURG OPEN SCI, V4, P19, DOI 10.1016/j.sopen.2020.06.002
   Oussi N, 2018, SURG ENDOSC, V32, P87, DOI 10.1007/s00464-017-5641-7
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Peitek N, 2018, EYE MOVEMENTS IN PROGRAMMING (EMIP 2018), DOI 10.1145/3216723.3216725
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Reichenberger J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01617
   Rethlefsen ML, 2021, SYST REV-LONDON, V10, DOI 10.1186/s13643-020-01542-z
   Ross J., 2010, CHI 10 EXTENDED ABST, P2863, DOI [10.1145/1753846.1753873, DOI 10.1145/1753846.1753873]
   Sargezeh BA, 2019, PHYSIOL BEHAV, V206, P43, DOI 10.1016/j.physbeh.2019.03.023
   Solnick RE, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2019.20511
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Tucker JD, 2019, PEERJ, V7, DOI 10.7717/peerj.6762
   van Deursen M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92109-y
   Vanhove AJ, 2021, J PERS PSYCHOL, V20, P176, DOI 10.1027/1866-5888/a000281
   Walbron P, 2020, ORTHOP TRAUMATOL-SUR, V106, P717, DOI 10.1016/j.otsr.2020.03.009
   Wang C, 2020, INFECT DIS POVERTY, V9, DOI 10.1186/s40249-020-0622-9
   Wazny K, 2018, J GLOB HEALTH, V8, DOI 10.7189/jogh.08.010502
   Yin J, 2019, INDOOR AIR, V29, P1028, DOI 10.1111/ina.12593
   Yuling Sun, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3492854
NR 56
TC 2
Z9 2
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 29
PY 2022
VL 3
AR 717383
DI 10.3389/frvir.2022.717383
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VP4
UT WOS:001023261700001
OA gold
DA 2024-07-18
ER

PT J
AU Graham, TCN
   King, N
   Coo, H
   Zabojnikova, P
   Gurd, BJ
   Samdup, D
AF Graham, T. C. Nicholas
   King, Nia
   Coo, Helen
   Zabojnikova, Pavla
   Gurd, Brendon J.
   Samdup, Dawa
TI Design and Evaluation of an Exergaming System for Children With Autism
   Spectrum Disorder: The Children's and Families' Perspective
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE game design; autism spectrum disorder (ASD); exergame; kinaesthetic
   interaction; active game
ID PHYSICAL-ACTIVITY LEVELS; SERIOUS GAME; ENERGY-EXPENDITURE; EXECUTIVE
   FUNCTION; CYCLING EXERGAME; ADOLESCENTS; SKILLS; INTERVENTIONS;
   PREVALENCE; BEHAVIORS
AB Children with autism spectrum disorder (ASD) have lower levels of physical activity than their typically developing peers. Barriers to participation include deficits in motor function and in social interaction, both of which reduce opportunities to engage in leisure activities that incorporate physical exertion. Because children with ASD also have higher than average levels of media use, exergames-video games that require bodily interaction to play-are a promising form of exercise. While studies have examined exergaming interventions for children with ASD, to date there has been little research on exergames that have been specifically designed for children with neurodevelopmental disorders, or qualitative analysis of players' and families' experience with exergaming programs. In this paper we present Liberi, an exergaming system involving kinaesthetic interaction within a virtual world, and designed explicitly for children with neurodevelopmental disorders. We report the results of a 6-week study where Liberi was played from the home by five children with ASD. The paper describes those aspects of the design that were successful and unsuccessful; how children and parents viewed the exergames; how the games were incorporated into the children's lives; and how parents envisaged exergames could be best deployed for children with ASD.
C1 [Graham, T. C. Nicholas] Queens Univ, Sch Comp, Kingston, ON, Canada.
   [King, Nia] Queens Univ, Sch Med, Kingston, ON, Canada.
   [Coo, Helen; Zabojnikova, Pavla; Samdup, Dawa] Queens Univ, Dept Pediat, Kingston, ON, Canada.
   [Gurd, Brendon J.] Queens Univ, Sch Kinesiol & Hlth Studies, Kingston, ON, Canada.
C3 Queens University - Canada; Queens University - Canada; Queens
   University - Canada; Queens University - Canada
RP Graham, TCN (corresponding author), Queens Univ, Sch Comp, Kingston, ON, Canada.; Samdup, D (corresponding author), Queens Univ, Dept Pediat, Kingston, ON, Canada.
EM nicholas.graham@queensu.ca; Dawa.Samdup@kingstonhsc.ca
FU Innovation Fund; joint initiative of the Ontario Ministry of Health and
   the Ontario Medical Association
FX This work was supported by a grant from the Innovation Fund (ifpoc.org),
   a joint initiative of the Ontario Ministry of Health and the Ontario
   Medical Association. The funder had no role in the design or conduct of
   this study, or in the interpretation of the findings.
CR Alarcon-Licona S, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P58, DOI 10.1145/329214.3292208
   Alves S, 2013, PSYCHNOLOGY J, V11, P191
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Anderson-Hanley C, 2011, PSYCHOL RES BEHAV MA, V4, P129, DOI 10.2147/PRBM.S24016
   [Anonymous], 1998, Dance Dance Revolution [Arcade,Dreamcast,Playstation,Wii,Xbox, XBox 360, PC]
   [Anonymous], 2007, Wii Fit
   [Anonymous], 2006, WII SPORTS
   Baker M.J., 2000, Journal of Positive Behavior Interventions, V2, P66, DOI [DOI 10.1177/109830070000200201, 10.1177/109830070000200201]
   Battocchi A., 2009, Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces (ITS '09), P197, DOI [DOI 10.1145/1731903.1731940, 10.1145/1731903.1731940]
   Benzing V, 2018, J CLIN MED, V7, DOI 10.3390/jcm7110422
   Bernardes M, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P127, DOI 10.1109/ICVR.2015.7358609
   Bhatt SK, 2014, INT J SMART SENS INT, V7, P519, DOI 10.21307/ijssis-2017-668
   Bhattacharya A., 2015, P 14 INT C INTERACTI, P69, DOI DOI 10.1145/2771839.2771847
   Blum-Dimaya A., 2010, Education and Treatment of Children, V33, P351, DOI DOI 10.1353/ETC.0.0103
   Bono V, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00070
   Bossavit B, 2016, PARTICIPATORY DESIGN IN AN ERA OF PARTICIPATION (PDC 2016), VOL 1, P11, DOI 10.1145/2940299.2940313
   Boyd LE, 2015, ACM T ACCESS COMPUT, V7, DOI 10.1145/2751564
   Braun V, 2012, APA HDB RES METHODS, V2, P57, DOI [DOI 10.1037/13620-004, DOI 10.1037/13620]
   Braun V, 2019, QUAL RES SPORT EXERC, V11, P589, DOI 10.1080/2159676X.2019.1628806
   Broder-Fingert S, 2014, ACAD PEDIATR, V14, P408, DOI 10.1016/j.acap.2014.04.004
   Cardenas A, 2021, DEV NEUROREHABIL, V24, P230, DOI 10.1080/17518423.2020.1858359
   Caro K, 2017, INT J HUM-COMPUT ST, V105, P12, DOI 10.1016/j.ijhcs.2017.03.005
   Caro K, 2017, COMPUT HUM BEHAV, V71, P479, DOI 10.1016/j.chb.2015.05.055
   Carson V, 2016, J SCI MED SPORT, V19, P573, DOI 10.1016/j.jsams.2015.07.011
   Carter C.M., 2001, J POSITIVE BEHAV INT, V3, P131, DOI DOI 10.1177/109830070100300302
   Christinaki E., 2013, 8 INT C FDN DIG GAM, P2
   Constantino JN, 2003, J AUTISM DEV DISORD, V33, P427, DOI 10.1023/A:1025014929212
   Demetriou EA, 2018, MOL PSYCHIATR, V23, P1198, DOI 10.1038/mp.2017.75
   Durkin K, 2013, Z PSYCHOL, V221, P79, DOI 10.1027/2151-2604/a000138
   Edwards J, 2017, J SPORT HEALTH SCI, V6, P17, DOI 10.1016/j.jshs.2016.09.004
   Ellis B., 2021, GAME ACCESSIBILITY G
   Fang Q, 2019, GAMES HEALTH J, V8, P74, DOI 10.1089/g4h.2018.0032
   Ferguson B, 2012, GAMES HEALTH J, V1, P248, DOI 10.1089/g4h.2012.0717
   Finkelstein S., 2010, CHI 10 EXTENDED ABST, P4189, DOI DOI 10.1145/1753846.1754124
   Finkelstein S, 2013, 2013 1ST WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P11, DOI 10.1109/VAAT.2013.6786186
   Fournier KA, 2010, J AUTISM DEV DISORD, V40, P1227, DOI 10.1007/s10803-010-0981-3
   Fridenson-Hayo S, 2017, EUR CHILD ADOLES PSY, V26, P979, DOI 10.1007/s00787-017-0968-0
   Getchell N, 2012, GAMES HEALTH J, V1, P58, DOI 10.1089/g4h.2011.0019
   Gioia G.A., 2015, BRIEF: Behavior rating inventory of executive function
   Golden D, 2017, GAMES HEALTH J, V6, P97, DOI 10.1089/g4h.2016.0083
   Goodyear VA, 2023, PHYS EDUC SPORT PEDA, V28, P94, DOI 10.1080/17408989.2021.1953459
   Gotsis M., 2010, P 9 INT C INT DES CH, DOI [10.1145/1810543.1810569, DOI 10.1145/1810543.1810569]
   Grapel Jordan N., 2015, Yale Journal of Biology and Medicine, V88, P69
   Guagliano JM, 2013, MED SCI SPORT EXER, V45, P116, DOI 10.1249/MSS.0b013e31826a0a73
   HARROLD N, 2012, P WORKSH SIGGRAPH AS, P33, DOI DOI 10.1145/2425296.2425302
   Heiberger RM, 2014, J STAT SOFTW, V57
   Hernandez H.A., 2012, P 2012 ACM ANN C HUM, P2619, DOI 10.1145
   Hernandez Hamilton A., 2013, P SIGCHI C HUM FACT, P1261, DOI [10.1145/2470654.2466164, DOI 10.1145/2470654.2466164]
   Hernandez HamiltonA., 2014, P 16 INT ACM SIGACCE, P161, DOI [10.1145/2661334.2661370, DOI 10.1145/2661334]
   Hill AP, 2015, PEDIATRICS, V136, P1051, DOI 10.1542/peds.2015-1437
   Hill EL, 2004, TRENDS COGN SCI, V8, P26, DOI 10.1016/j.tics.2003.11.003
   Hilton CL, 2014, AM J OCCUP THER, V68, P57, DOI 10.5014/ajot.2014.008664
   Hiniker A., 2013, P ACM INT C PROCEEDI, P463, DOI [DOI 10.1145/2485760.2485808, 10.1145/2485760.2485808]
   Hinkley T, 2014, PREV MED, V62, P182, DOI 10.1016/j.ypmed.2014.02.007
   Hwang S, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P699, DOI 10.1145/3064663.3064664
   Ikuta N, 2016, HONG KONG J OCCUP TH, V28, P24, DOI 10.1016/j.hkjot.2016.09.001
   Johnson TG, 2010, J PHYS ACT HEALTH, V7, P355, DOI 10.1123/jpah.7.3.355
   Jones RA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172482
   Kajastila R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P758, DOI 10.1145/2858036.2858450
   Kaos MD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300660
   Kaos MD, 2018, ANN BEHAV MED, V52, P878, DOI 10.1093/abm/kax061
   Keiver K, 2019, ALCOHOL CLIN EXP RES, V43, p226A
   KERN L, 1982, J AUTISM DEV DISORD, V12, P399, DOI 10.1007/BF01538327
   Ketcheson Mallory., 2015, P 2015 ANN S COMPUTE, P79, DOI [10.1145/ 2793107.2793122, DOI 10.1145/2793107.2793122, https://doi.org/10.1145/2793107.2793122]
   Khowaja K, 2019, INT J HUM-COMPUT INT, V35, P1, DOI 10.1080/10447318.2017.1420006
   King G, 2014, INT J DISABIL DEV ED, V61, P44, DOI 10.1080/1034912X.2014.878542
   Kingdon D, 2016, J CHILD PSYCHOL PSYC, V57, P116, DOI 10.1111/jcpp.12451
   Knights S, 2016, DEV NEUROREHABIL, V19, P135, DOI 10.3109/17518423.2014.923056
   Kowalski K.C., 2004, The Physical Activity Questionnaire for Older Children (PAQ0C) and for Adolescents (PAQ-A) Manual
   Kwan C, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10110786
   Léger LA, 1988, J SPORT SCI, V6, P93, DOI 10.1080/02640418808729800
   MacIntosh A, 2017, GAMES HEALTH J, V6, P379, DOI 10.1089/g4h.2017.0053
   Maenner M., 2020, Prevalence of Autism Spectrum Disorder Among Children Aged 8 Years - Autism and Developmental Disabilities Monitoring Network, 11 Sites, United States, 2016, DOI DOI 10.15585/MMWR.SS6904A1
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Marshall J, 2021, IEEE T GAMES, V13, P160, DOI 10.1109/TG.2020.2995370
   Marshall J, 2016, INT J HUM-COMPUT ST, V90, P1, DOI 10.1016/j.ijhcs.2016.02.003
   Mazurek MO, 2013, J AUTISM DEV DISORD, V43, P1258, DOI 10.1007/s10803-012-1659-9
   Mazurek MO, 2012, J AUTISM DEV DISORD, V42, P1757, DOI 10.1007/s10803-011-1413-8
   McConachie H, 2018, J AUTISM DEV DISORD, V48, P1041, DOI 10.1007/s10803-017-3282-2
   Microsoft Game Studios, 2010, KIN ADV
   Silva GFM, 2014, PROCEDIA COMPUT SCI, V27, P84, DOI 10.1016/j.procs.2014.02.011
   Mueller F, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P207, DOI 10.1145/3374920.3374931
   Must A, 2015, J PHYS ACT HEALTH, V12, P529, DOI 10.1123/jpah.2013-0271
   Ofner M., 2018, AUTISM SPECTRUM DISO
   Pan CY, 2016, PHYS THER, V96, P511, DOI 10.2522/ptj.20140353
   Peng W, 2011, CYBERPSYCH BEH SOC N, V14, P681, DOI 10.1089/cyber.2010.0578
   Pfeiffer B, 2019, PHYS OCCUP THER PEDI, V39, P60, DOI 10.1080/01942638.2018.1496963
   Piper Anne Marie, 2006, 20 ANN C COMP SUPP C, P1, DOI DOI 10.1145/1180875.1180877
   Rhodes RE, 2019, PSYCHOL SPORT EXERC, V41, P181, DOI 10.1016/j.psychsport.2018.03.009
   Richards Chad., 2014, Proceedings of the first ACM SIGCHI annual symposium on Computer-human interaction in play, P217, DOI [DOI 10.1145/2658537.2658683, 10.1145/2658537.2658683]
   Robinson S, 2009, BRAIN COGNITION, V71, P362, DOI 10.1016/j.bandc.2009.06.007
   Sacheck JM, 2011, PEDIATR EXERC SCI, V23, P281, DOI 10.1123/pes.23.2.281
   Schneider ALJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376480
   Srinivasan SM, 2014, PHYS THER, V94, P875, DOI 10.2522/ptj.20130157
   Stanley KevinG., 2010, P INT ACAD C FUTURE, P243, DOI DOI 10.1145/1920778.1920817
   Sturm D, 2016, IEEE INT CONF SERIOU
   Tanaka JW, 2010, J CHILD PSYCHOL PSYC, V51, P944, DOI 10.1111/j.1469-7610.2010.02258.x
   Tyler Kiley, 2014, Autism Res Treat, V2014, P312163, DOI 10.1155/2014/312163
   Ubisoft, 2009, JUST DANC
   van Sluijs EMF, 2007, BMJ-BRIT MED J, V335, P703, DOI 10.1136/bmj.39320.843947.BE
   Verschuren O, 2011, DEV MED CHILD NEUROL, V53, P861, DOI 10.1111/j.1469-8749.2011.03989.x
   Warburton D E. R., 2015, The Health Fitness Journal of Canada, V8, P53, DOI [DOI 10.14288/HFJC.V8I1.194, 10.14288/hfjc.v8i1.194]
   White SW, 2007, J AUTISM DEV DISORD, V37, P1858, DOI 10.1007/s10803-006-0320-x
   Whyte EM, 2015, J AUTISM DEV DISORD, V45, P3820, DOI 10.1007/s10803-014-2333-1
   Wijnhoven LAMW, 2015, BMC PSYCHIATRY, V15, DOI 10.1186/s12888-015-0522-x
   Winoto P, 2016, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016), P601, DOI 10.1145/2930674.2936012
   Yan F, 2011, LECT NOTES COMPUT SC, V6944, P129, DOI 10.1007/978-3-642-23834-5_12
   Yim Jeffrey., 2007, Proceedings of the 2007 conference on Future Play - Future Play '07, ACM Press, P166, DOI https://doi.org/10.1145/1328202.1328232
   Zwift inc, 2014, ABOUT US
NR 109
TC 1
Z9 1
U1 6
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 13
PY 2022
VL 3
AR 817303
DI 10.3389/frvir.2022.817303
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TI1
UT WOS:001021830400001
OA gold
DA 2024-07-18
ER

PT J
AU Unruh, F
   Landeck, M
   Oberdoerfer, S
   Lugrin, JL
   Latoschik, ME
AF Unruh, Fabian
   Landeck, Maximilian
   Oberdoerfer, Sebastian
   Lugrin, Jean-Luc
   Latoschik, Marc Erich
TI The Influence of Avatar Embodiment on Time Perception-Towards VR for
   Time-Based Therapy
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; time perception; avatar embodiment; immersion; human
   computer interaction (HCI)
ID VIRTUAL-REALITY; DURATION; CONSEQUENCES; JUDGMENTS; MODEL; TAU;
   CONSCIOUSNESS; EXPERIENCE; OWNERSHIP; IMMERSION
AB Psycho-pathological conditions, such as depression or schizophrenia, are often accompanied by a distorted perception of time. People suffering from this conditions often report that the passage of time slows down considerably and that they are "stuck in time." Virtual Reality (VR) could potentially help to diagnose and maybe treat such mental conditions. However, the conditions in which a VR simulation could correctly diagnose a time perception deviation are still unknown. In this paper, we present an experiment investigating the difference in time experience with and without a virtual body in VR, also known as avatar. The process of substituting a person's body with a virtual body is called avatar embodiment. Numerous studies demonstrated interesting perceptual, emotional, behavioral, and psychological effects caused by avatar embodiment. However, the relations between time perception and avatar embodiment are still unclear. Whether or not the presence or absence of an avatar is already influencing time perception is still open to question. Therefore, we conducted a between-subjects design with and without avatar embodiment as well as a real condition (avatar vs. no-avatar vs. real). A group of 105 healthy subjects had to wait for seven and a half minutes in a room without any distractors (e.g., no window, magazine, people, decoration) or time indicators (e.g., clocks, sunlight). The virtual environment replicates the real physical environment. Participants were unaware that they will be asked to estimate their waiting time duration as well as describing their experience of the passage of time at a later stage. Our main finding shows that the presence of an avatar is leading to a significantly faster perceived passage of time. It seems to be promising to integrate avatar embodiment in future VR time-based therapy applications as they potentially could modulate a user's perception of the passage of time. We also found no significant difference in time perception between the real and the VR conditions (avatar, no-avatar), but further research is needed to better understand this outcome.
C1 [Unruh, Fabian; Landeck, Maximilian; Oberdoerfer, Sebastian; Lugrin, Jean-Luc; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
C3 University of Wurzburg
RP Unruh, F (corresponding author), Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
EM fabian.unruh@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023; Lugrin, Jean-Luc/KMA-1030-2024
OI Latoschik, Marc Erich/0000-0002-9340-9600; Lugrin,
   Jean-Luc/0000-0002-2725-2123
FU VIRTUALTIMES project by European Union [ID-824128]; University of
   Wuerzburg
FX This work is funded by the VIRTUALTIMES project (ID-824128) funded by
   the European Union under the Horizon 2020 program. This publication was
   supported by the Open Access Publication Fund of the University of
   Wuerzburg.
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Anders D., 2021, FRONT VIRTUAL REAL, V2, P47, DOI [10.3389/frvir.2021.656788, DOI 10.3389/FRVIR.2020.609545]
   Angrilli A, 1997, PERCEPT PSYCHOPHYS, V59, P972, DOI 10.3758/BF03205512
   [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   [Anonymous], 2015, P 21 ACM S VIRTUAL R, DOI DOI 10.1145/2821592.2821607
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bansal A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40870-6
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   BLOCK RA, 1978, J EXP PSYCHOL-HUM L, V4, P656, DOI 10.1037/0278-7393.4.6.656
   Block RA, 1996, TIME AND MIND, P171
   BLOCK RA, 1982, J EXP PSYCHOL LEARN, V8, P530, DOI 10.1037/0278-7393.8.6.530
   BLOCK RA, 1992, NATO ADV SCI INST SE, V66, P141
   Boone HN., 2012, J EXT, V50, P48, DOI [https://doi.org/10.34068/joe.50.02.48, DOI 10.1007/S11172-017-1908-3]
   BROWN SW, 1995, PERCEPT PSYCHOPHYS, V57, P105, DOI 10.3758/BF03211853
   Bruder G, 2014, 2014 IEEE VIRTUAL REALITY (VR), P67, DOI 10.1109/VR.2014.6802054
   Bryson S, 2013, Arxiv, DOI [arXiv:1312.4322, 10.48550/arXiv.1312.4322, DOI 10.48550/ARXIV.1312.4322]
   Buhusi CV, 2005, NAT REV NEUROSCI, V6, P755, DOI 10.1038/nrn1764
   Carmack John, 2013, Latency mitigation strategies
   Craig AD, 2009, PHILOS T R SOC B, V364, P1933, DOI 10.1098/rstb.2009.0008
   Döllinger N, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.644683
   Droit-Volet S, 2004, COGNITION EMOTION, V18, P849, DOI 10.1080/02699930341000194
   Droit-Volet S., 2013, TIMING TIME PERCEPT, V1, P99, DOI [DOI 10.1163/22134468-00002004, 10.1163/22134468-00002004]
   Fleisig D, 2009, NEUROQUANTOLOGY, V7, P58
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Friedman D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00943
   Fuchs T, 2013, PHENOMENOL COGN SCI, V12, P75, DOI 10.1007/s11097-010-9189-4
   Gall D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P73, DOI 10.1109/VR.2018.8446153
   Giersch A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01659
   GLASS GV, 1972, REV EDUC RES, V42, P237, DOI 10.3102/00346543042003237
   Gomez J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01611
   Gonçalves R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048469
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Hamzeheinejad N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1421, DOI [10.1109/VR.2019.8797763, 10.1109/vr.2019.8797763]
   Helson H, 1931, J EXP PSYCHOL, V14, P202, DOI 10.1037/h0071164
   HICKS RE, 1976, AM J PSYCHOL, V89, P719, DOI 10.2307/1421469
   Hirzle T, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445361
   James W., 1890, PRINCIPLES PSYCHOL, V1
   Javitt DC, 2015, AM J PSYCHIAT, V172, P17, DOI 10.1176/appi.ajp.2014.13121691
   Jokic T., 2018, TIMING TIME PERCEPT, V6, P71, DOI DOI 10.1163/22134468-00002101
   JONES B, 1982, PSYCHOL BULL, V91, P128, DOI 10.1037/0033-2909.91.1.128
   Kabat-Zinn J, 2003, CLIN PSYCHOL-SCI PR, V10, P144, DOI 10.1093/clipsy/bpg016
   Kanai R, 2006, J VISION, V6, P1421, DOI 10.1167/16.12.8
   Kant I., 1990, CRITIQUE PURE REASON
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kern F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P500, DOI [10.1109/VR.2019.8797828, 10.1109/vr.2019.8797828]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kitajima M., 2020, 26 ACM S VIRTUAL REA, P1, DOI [10.1145/3385956.3422104, DOI 10.1145/3385956.3422104]
   Landau DH, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01229
   Landum M., 2020, IBER CONF INF SYST, P1, DOI [10.1145/3385956.3422111, DOI 10.23919/CISTI49556.2020.9141166, DOI 10.23919/cisti49556.2020.9141166]
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P73, DOI 10.1145/2993369.2993399
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lelyveld P., 2015, SMPTE Motion Imaging Journal, V124, P78, DOI [10.5594/j18599, DOI 10.5594/J18599]
   Lindner P, 2021, INT J COGN THER, V14, P23, DOI 10.1007/s41811-020-00090-7
   Lix LM, 1996, REV EDUC RES, V66, P579, DOI 10.3102/00346543066004579
   Lugrin Jean-Luc, 2019, 25 ACM S VIRT REAL S, P1
   Martin B, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07987-y
   Meissner K, 2011, BIOL PSYCHOL, V86, P289, DOI 10.1016/j.biopsycho.2011.01.001
   MINSKY M., 1974, FRAMEWORK REPRESENTI
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   NIEMI P, 1981, PSYCHOL BULL, V89, P133, DOI 10.1037/0033-2909.89.1.133
   Ornstein R., 1969, On the experience of time
   OSUNA EE, 1985, J MATH PSYCHOL, V29, P82, DOI 10.1016/0022-2496(85)90020-3
   Peña J, 2009, COMMUN RES, V36, P838, DOI 10.1177/0093650209346802
   Pfeifer E, 2016, MUSIC MED, V8, P180, DOI [10.47513/mmd.v8i4.473, DOI 10.47513/MMD.V8I4.473]
   Phillips L, 2010, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2010.5444802
   Pizarro R., 2015, ICAT EGVE, P117, DOI DOI 10.5555/2852313.2852329
   Pollatos O, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086934
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Roth D., 2019, CONSTRUCTION VALIDAT
   Roth D., 2017, P 2017 CHI C HUM FAC, P2875
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Sackett AM, 2010, PSYCHOL SCI, V21, P111, DOI 10.1177/0956797609354832
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sarrazin JC, 2004, J EXP PSYCHOL HUMAN, V30, P411, DOI 10.1037/0096-1523.30.3.411
   Schatzschneider C, 2016, IEEE T VIS COMPUT GR, V22, P1387, DOI 10.1109/TVCG.2016.2518137
   Schneider SM, 2007, ONCOL NURS FORUM, V34, P39, DOI 10.1188/07.ONF.39-46
   Schneider SM, 2011, SUPPORT CARE CANCER, V19, P555, DOI 10.1007/s00520-010-0852-7
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Schwind V, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P507, DOI 10.1145/3116595.3116596
   Shahnewaz S, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P265, DOI 10.1109/3DUI.2016.7460072
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Stauffert JP, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P707, DOI [10.1109/VRW50115.2020.00-71, 10.1109/VRW50115.2020.00204]
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   TAYLOR S, 1994, J MARKETING, V58, P56, DOI 10.2307/1252269
   The free dictionary, 2020, TIM DEF
   Thones S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19892-z
   Thones S., 2016, Psychology of Consciouness: Theory, Research and Practice, V3, P316, DOI DOI 10.1037/CNS0000088
   Tobin S, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009271
   van der Ham IJM, 2019, COMPUT HUM BEHAV, V94, P77, DOI 10.1016/j.chb.2019.01.005
   Vogeley K, 2007, SCHIZOPHRENIA BULL, V33, P157, DOI 10.1093/schbul/sbl056
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wearden JH, 2015, CONSCIOUS COGN, V38, P165, DOI 10.1016/j.concog.2015.06.005
   Wearden JH, 2008, LANG LEARN, V58, P149, DOI 10.1111/j.1467-9922.2008.00468.x
   Wearden JH, 1998, Q J EXP PSYCHOL-B, V51, P97
   Weiner L, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00786
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wittmann M, 2013, NAT REV NEUROSCI, V14, P217, DOI 10.1038/nrn3452
   Wittmann MarcErik Butler., 2016, FELT TIME PSYCHOL WE
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   ZAKAY D, 1993, PERCEPT PSYCHOPHYS, V54, P656, DOI 10.3758/BF03211789
   Zakay D, 1997, CURR DIR PSYCHOL SCI, V6, P12, DOI 10.1111/1467-8721.ep11512604
   Zakay D., 1995, TIME DYNAMIC CONTROL, P167
   Zakay D, 2015, CONSCIOUS COGN, V38, P182, DOI 10.1016/j.concog.2015.10.006
   Zakay D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00917
NR 115
TC 7
Z9 8
U1 1
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 19
PY 2021
VL 2
AR 658509
DI 10.3389/frvir.2021.658509
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2UC9
UT WOS:001021851200001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Döllinger, N
   Wienrich, C
   Latoschik, ME
AF Doellinger, Nina
   Wienrich, Carolin
   Latoschik, Marc Erich
TI Challenges and Opportunities of Immersive Technologies for Mindfulness
   Meditation: A Systematic Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; augmented reality; mindfulness; XR; meditation
ID VIRTUAL-REALITY; SCALE; SELF; EMBODIMENT; QUESTIONNAIRE; ENVIRONMENTS;
   BENEFITS; ILLUSION; THERAPY
AB Mindfulness is considered an important factor of an individual's subjective well-being. Consequently, Human-Computer Interaction (HCI) has investigated approaches that strengthen mindfulness, i.e., by inventing multimedia technologies to support mindfulness meditation. These approaches often use smartphones, tablets, or consumer-grade desktop systems to allow everyday usage in users' private lives or in the scope of organized therapies. Virtual, Augmented, and Mixed Reality (VR, AR, MR; in short: XR) significantly extend the design space for such approaches. XR covers a wide range of potential sensory stimulation, perceptive and cognitive manipulations, content presentation, interaction, and agency. These facilities are linked to typical XR-specific perceptions that are conceptually closely related to mindfulness research, such as (virtual) presence and (virtual) embodiment. However, a successful exploitation of XR that strengthens mindfulness requires a systematic analysis of the potential interrelation and influencing mechanisms between XR technology, its properties, factors, and phenomena and existing models and theories of the construct of mindfulness. This article reports such a systematic analysis of XR-related research from HCI and life sciences to determine the extent to which existing research frameworks on HCI and mindfulness can be applied to XR technologies, the potential of XR technologies to support mindfulness, and open research gaps. Fifty papers of ACM Digital Library and National Institutes of Health's National Library of Medicine (PubMed) with and without empirical efficacy evaluation were included in our analysis. The results reveal that at the current time, empirical research on XR-based mindfulness support mainly focuses on therapy and therapeutic outcomes. Furthermore, most of the currently investigated XR-supported mindfulness interactions are limited to vocally guided meditations within nature-inspired virtual environments. While an analysis of empirical research on those systems did not reveal differences in mindfulness compared to non-mediated mindfulness practices, various design proposals illustrate that XR has the potential to provide interactive and body-based innovations for mindfulness practice. We propose a structured approach for future work to specify and further explore the potential of XR as mindfulness-support. The resulting framework provides design guidelines for XR-based mindfulness support based on the elements and psychological mechanisms of XR interactions.
C1 [Doellinger, Nina; Wienrich, Carolin] Univ Wurzburg, Human Technol Syst, Wurzburg, Germany.
   [Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Döllinger, N (corresponding author), Univ Wurzburg, Human Technol Syst, Wurzburg, Germany.
EM nina.doellinger@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600; Dollinger,
   Nina/0000-0002-0609-8841
FU German Federal Ministry of Education and Research in the project ViTraS
   [16SV8219]; Open Access Publication Fund of the University of
   Wuuml;rzburg
FX This research has been funded by the German Federal Ministry of
   Education and Research in the project ViTraS (project number 16SV8219).
   This publication was supported by the Open Access Publication Fund of
   the University of Wuerzburg. We thank Roland Zechner for table and
   figure formatting.
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Andersen T, 2017, P IEEE VIRT REAL ANN, P343, DOI 10.1109/VR.2017.7892317
   Auccahuasi W., 2019, P 5 INT C COMM INF P, P119, DOI [10.1145/3369985.3370015, DOI 10.1145/3369985.3370015]
   Baer RA, 2008, ASSESSMENT, V15, P329, DOI 10.1177/1073191107313003
   Barton AC, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02050
   Bednarz, 2018, ACM SIGGRAPH 2018 AP, P1
   BENSON H, 1975, INT J PSYCHIAT MED, V6, P87, DOI 10.2190/376W-E4MT-QM6Q-H0UM
   Bergomi C, 2013, MINDFULNESS, V4, P191, DOI 10.1007/s12671-012-0110-9
   Bostanov V, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00249
   Botella C, 2013, CYBERPSYCH BEH SOC N, V16, P215, DOI 10.1089/cyber.2012.1572
   Brown KW, 2003, J PERS SOC PSYCHOL, V84, P822, DOI 10.1037/0022-3514.84.4.822
   Burton M, 2013, J CLIN PSYCHOL, V69, P222, DOI 10.1002/jclp.21929
   Cebolla A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01521
   Chavez LJ, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/18244
   Chen XJ, 2018, CONTEMP CLIN TRIALS, V70, P99, DOI 10.1016/j.cct.2018.04.006
   Cheng VYW, 2020, J MED INTERNET RES, V22, DOI 10.2196/17096
   Choo A, 2014, 2014 IEEE GAMES, MEDIA, ENTERTAINMENT (GEM)
   Chung K, 2018, J MED INTERNET RES, V20, DOI 10.2196/11152
   Cikajlo I, 2017, JMIR RES PROTOC, V6, DOI 10.2196/resprot.6849
   Costa Mark R., 2020, HCI International 2020 - Late Breaking Papers. Cognition, Learning and Games. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12425), P176, DOI 10.1007/978-3-030-60128-7_14
   Costa MR, 2019, LECT NOTES ARTIF INT, V11580, P517, DOI 10.1007/978-3-030-22419-6_37
   Cox, 2018, 2018 CHI C HUM FACT, P1
   Czub M, 2019, CYBERPSYCH BEH SOC N, V22, P494, DOI 10.1089/cyber.2018.0700
   Damen KHB, 2018, LECT NOTES COMPUT SC, V11112, P241, DOI 10.1007/978-3-319-99426-0_24
   De Kort Y. A., 2007, P PRESENCE, P1
   Derthick Katie., 2014, CHI '14 Extended Abstracts on Human Factors in Computing Systems, CHI EA'14, page, P2275, DOI DOI 10.1145/2559206.2581368
   Du Plessis I., 2017, ACM SIGGRAPH 2017 VR, P1, DOI [10.1145/3089269.3089273, DOI 10.1145/3089269.3089273]
   Feldman G, 2007, J PSYCHOPATHOL BEHAV, V29, P177, DOI 10.1007/s10862-006-9035-8
   Filippetti ML, 2017, COGNITION, V159, P1, DOI 10.1016/j.cognition.2016.11.002
   Flores A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00531
   Frewen P., 2011, MINDFULNESS, V2, P254, DOI DOI 10.1007/S12671-011-0069-Y
   Goldenhersch E, 2020, J MED INTERNET RES, V22, DOI 10.2196/17571
   Gomez J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01611
   Gromala D., 2011, CHI 2011 Extended Abstracts on Human Factors in Computing Systems, P1171, DOI DOI 10.1145/1979742.1979704
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Grosse-Hering Barbara., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P3431, DOI 10.1145/2470654.2466472
   Haisley KR, 2020, COMPLEMENT THER MED, V49, DOI 10.1016/j.ctim.2020.102356
   Hanh T.N., 2013, Moments of mindfulness: Daily inspiration
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Heeter C, 2016, PRESENCE-TELEOP VIRT, V25, P175, DOI 10.1162/PRES_a_00256
   Hertweck S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P970, DOI [10.1109/VR.2019.8798369, 10.1109/vr.2019.8798369]
   Kabat-Zinn J, 2003, CLIN PSYCHOL-SCI PR, V10, P144, DOI 10.1093/clipsy/bpg016
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kazzi C, 2018, IEEE ENG MED BIO, P2768, DOI 10.1109/EMBC.2018.8512816
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khoury B, 2017, MINDFULNESS, V8, P1160, DOI 10.1007/s12671-017-0700-7
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kosunen I., 2017, P 2017 ACM WORKSH AP, P29, DOI [DOI 10.1145/3038439.3038443, 10.1145/3038439.3038443,doi, DOI 10.1145/3038439.3038443,DOI, 10.1145/3038439]
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Kühle L, 2017, PHILOS PSYCHOL, V30, P571, DOI 10.1080/09515089.2017.1311999
   Kwon JH, 2020, CYBERPSYCH BEH SOC N, V23, P715, DOI 10.1089/cyber.2019.0651
   Lau MA, 2006, J CLIN PSYCHOL, V62, P1445, DOI 10.1002/jclp.20326
   Lee SY, 2020, INTENS CRIT CARE NUR, V59, DOI 10.1016/j.iccn.2020.102849
   Llobera J, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0300
   Methley AM, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/s12913-014-0579-0
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mistry D, 2020, PSYCHOL TRAUMA-US, V12, P847, DOI 10.1037/tra0000959
   Moher D, 2011, EPIDEMIOLOGY, V22, P128, DOI 10.1097/EDE.0b013e3181fe7825
   Monti A, 2020, J NEUROPHYSIOL, V123, P420, DOI 10.1152/jn.00617.2019
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Moseley R, 2017, 2017 COMPUTING CONFERENCE, P523, DOI 10.1109/SAI.2017.8252146
   Moseley R, 2016, STUD COMPUT INTELL, V647, P315, DOI 10.1007/978-3-319-33353-3_17
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Niksirat KS, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3359593
   Niksirat KS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2672, DOI 10.1145/3025453.3025914
   Ortega, 2020, OPTO-ELECT COMMUN C, P1, DOI DOI 10.1109/oecc48412.2020.9273526
   Paredes Pablo E., 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287062
   Patibanda R, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P19, DOI 10.1145/3116595.3116621
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pendse A, 2016, ACM SIGGRAPH 2016 VR VILLAGE (SIGGRAPH '16), DOI 10.1145/2929490.2932421
   Piron H., 2003, Journal for Meditation and Meditation Research, V3, P45
   Potts D, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P583, DOI 10.1145/3325480.3326584
   Prpa M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P71, DOI 10.1145/3196709.3196765
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Reavley N, 2009, PERS INDIV DIFFER, V47, P547, DOI 10.1016/j.paid.2009.05.007
   Rice VJ, 2018, MIL MED, V183, P413, DOI 10.1093/milmed/usx227
   Roo JS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1459, DOI 10.1145/3025453.3025743
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Salminen M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P73, DOI 10.1145/3172944.3172991
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seabrook E, 2020, J MED INTERNET RES, V22, DOI 10.2196/16106
   Seol E, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141199
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Song M, 2019, ICIGP 2019: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING / 2019 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, P150, DOI 10.1145/3313950.3313978
   Stahl Anna., 2016, P 2016 CHI C EXTENDE, DOI DOI 10.1145/2851581.2889464
   Sze JA, 2010, EMOTION, V10, P803, DOI 10.1037/a0020146
   Tajadura-Jiménez A, 2012, CONSCIOUS COGN, V21, P1725, DOI 10.1016/j.concog.2012.10.004
   Tanay G, 2013, PSYCHOL ASSESSMENT, V25, P1286, DOI 10.1037/a0034044
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Terzimehic N, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300687
   Tinga AM, 2019, APPL PSYCHOPHYS BIOF, V44, P51, DOI 10.1007/s10484-018-9421-5
   Van Gordon W, 2018, MINDFULNESS, V9, P1655, DOI 10.1007/s12671-018-0883-6
   Venuturupalli R Swamy, 2019, ACR Open Rheumatol, V1, P667, DOI 10.1002/acr2.11092
   Walsh R, 2006, AM PSYCHOL, V61, P227, DOI 10.1037/0003-066X.61.3.227
   Wienrich C., 2017, VIRTUELLE ERWEITERTE, P162
   Wienrich C., 2020, ARXIV201210912
   Wienrich C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P690, DOI [10.1109/VR.2019.8798070, 10.1109/vr.2019.8798070]
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Zaharuddin Farhah Amaliya, 2019, Advances in Visual Informatics. 6th International Visual Informatics Conference, IVIC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11870), P25, DOI 10.1007/978-3-030-34032-2_3
   Zeidan F, 2010, CONSCIOUS COGN, V19, P597, DOI 10.1016/j.concog.2010.03.014
   Zhu B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2685, DOI 10.1145/3025453.3025590
NR 106
TC 21
Z9 22
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 27
PY 2021
VL 2
AR 644683
DI 10.3389/frvir.2021.644683
PG 22
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XL8
UT WOS:001023310400001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Wang, YX
   Du, B
   Wei, Y
   So, RHY
AF Wang, Yixuan
   Du, Bo
   Wei, Yue
   So, Richard H. Y.
TI Visually Induced Roll Circular Vection: Do Effects of Stimulation
   Velocity Differ for Supine and Upright Participants?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE circular vection; stimulation velocity; upright position; supine
   position; otolith cues
ID CANADIAN VESTIBULAR EXPERIMENTS; INDUCED MOTION SICKNESS; SPACELAB-1
   MISSION; HEAD ORIENTATION; MOVEMENT; TILT; BODY; DIRECTION; AXIS
AB Visually induced circular vection (CV) has been the subject of a wide range of functional brain and behavioral research. Participants in MRI or PET studies on CV were mostly in a supine viewing position, while participants in behavioral studies on CV were mostly in an upright viewing position. This study examines the effects of viewing positions (upright and supine) on roll CV reported by 16 participants while watching random dots (92 x 60 degrees field-of-view) rotating at different angular velocities (2, 4, 8, 16, 32, 64 deg/s) for 30 s. Viewing positions affected roll CV durations differently depending on the stimulation velocities. At slower velocities (2, 4, and 8 deg/s), participants exhibited significantly longer roll CV sensations when they were sitting in an upright position as opposed to lying in a supine position. The onset of roll CV was also significantly earlier with participants in an upright position despite similar roll CV intensities in both viewing positions. Significant two-way interactions between effects of viewing positions and dot rotating velocities for some conditions were noted. Consistency between current findings and the hypothesis predicting a weaker roll CV in upright positions based upon perceived gravity by the otolith organs is discussed.
C1 [Wang, Yixuan; Du, Bo; Wei, Yue; So, Richard H. Y.] Hong Kong Univ Sci & Technol, Dept Ind Engn & Decis Analyt, Hong Kong, Peoples R China.
   [Wang, Yixuan; Du, Bo; Wei, Yue; So, Richard H. Y.] Hong Kong Univ Sci & Technol, Sch Engn, Bioengn Grad Program, Hong Kong, Peoples R China.
   [Wei, Yue] Incus Co Ltd, Hong Kong Sci Pk, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology; Hong Kong University of
   Science & Technology
RP Wang, YX (corresponding author), Hong Kong Univ Sci & Technol, Dept Ind Engn & Decis Analyt, Hong Kong, Peoples R China.; Wang, YX (corresponding author), Hong Kong Univ Sci & Technol, Sch Engn, Bioengn Grad Program, Hong Kong, Peoples R China.
EM ywanggx@connect.ust.hk
RI Wang, Yixuan/GZK-6559-2022
FU Hong Kong Research Grants Council [618812, 16200915]; Innovation
   Technology Commission [SST/182/20GP]
FX The authors would like to thank the Hong Kong Research Grants Council
   for partially funded this research under project no. 618812 and 16200915
   and the Innovation Technology Commission for partial support through
   project SST/182/20GP.
CR Allison RS, 1999, PERCEPTION, V28, P299, DOI 10.1068/p2891
   Antal A, 2008, VISUAL NEUROSCI, V25, P17, DOI 10.1017/S0952523808080024
   BENSON AJ, 1986, AVIAT SPACE ENVIR MD, V57, P1088
   Berti S, 2021, MULTISENS RES, V34, P153, DOI 10.1163/22134808-bja10035
   Brandt T, 1998, BRAIN, V121, P1749, DOI 10.1093/brain/121.9.1749
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   Campos J, 2018, HEARING RES, V369, P42, DOI 10.1016/j.heares.2018.03.025
   Cardin V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047685
   Chen DJ, 2016, ERGONOMICS, V59, P582, DOI 10.1080/00140139.2015.1078501
   CHEUNG BSK, 1990, EXP BRAIN RES, V81, P391
   Deutschländer A, 2004, HUM BRAIN MAPP, V21, P143, DOI 10.1002/hbm.10155
   Dichgans J., 1978, HDB SENSORY PHYSL, VVIII., P755
   Fujimoto K, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.581920
   Giannopulu I, 1998, PERCEPTION, V27, P363, DOI 10.1068/p270363
   Guterman PS, 2012, J VESTIBUL RES-EQUIL, V22, P105, DOI 10.3233/VES-2012-0448
   HELD R, 1975, VISION RES, V15, P357, DOI 10.1016/0042-6989(75)90083-8
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hettinger LJ, 2015, HUM FACTORS ERGON, P435
   Ji JTT, 2009, HUM FACTORS, V51, P739, DOI 10.1177/0018720809349708
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Kim J, 2014, J VISION, V14, DOI 10.1167/14.5.5
   Kleinschmidt A, 2002, NEUROIMAGE, V16, P873, DOI 10.1006/nimg.2002.1181
   Oyamada K, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520939585
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Reinhart S, 2016, NEUROPSYCHOLOGIA, V92, P174, DOI 10.1016/j.neuropsychologia.2016.04.027
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   Tanahashi S, 2012, I-PERCEPTION, V3, P804, DOI 10.1068/i0479
   Trutoiu LC, 2009, COMPUT GRAPH-UK, V33, P47, DOI 10.1016/j.cag.2008.11.008
   Uesaki M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00775
   Ujike H, 2004, P ANN INT IEEE EMBS, V26, P2399
   Warren R., 1990, PERCEPTION CONTROL S
   Webb NA, 2003, AVIAT SPACE ENVIR MD, V74, P622
   Weech S, 2020, DISPLAYS, V64, DOI 10.1016/j.displa.2020.101961
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   YOUNG LR, 1986, EXP BRAIN RES, V64, P291
   YOUNG LR, 1975, AVIAT SPACE ENVIR MD, V46, P264
   YOUNG LR, 1986, EXP BRAIN RES, V64, P299
   YOUNG LR, 1990, AVIAT SPACE ENVIR MD, V61, P525
   Zhao Y, 2017, IDENTIFYING VESTIBUL, DOI [10.14711/thesis-b1781036, DOI 10.14711/THESIS-B1781036]
NR 41
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 26
PY 2021
VL 2
AR 611214
DI 10.3389/frvir.2021.611214
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0HP6
UT WOS:001020153600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Pathak, A
   Chang, JSK
   Resch, G
   Doucette, A
   Yeboah, G
   Welsh, TN
   Nitsche, M
   Mazalek, A
AF Pathak, Aarohi
   Chang, Jack S. K.
   Resch, Gabby
   Doucette, Alison
   Yeboah, Georgina
   Welsh, Timothy Nevin
   Nitsche, Michael
   Mazalek, Ali
TI Thinking Through the Box: Evaluating a 3D Game to Engage Penetrative
   Thinking
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; tangible interaction; spatial ability; penetrative
   thinking; embodied interaction
ID SPATIAL THINKING; PERCEPTION; ROTATION; ANATOMY; ABILITY
AB Spatial skills allow us to mentally imagine and manipulate objects and their spatial relations. These skills are crucial in both every day and expert tasks. The present paper reports on an evaluation of a 3D game developed to train a specific spatial skill known as penetrative thinking-the ability to imagine cross-sections of 3D objects from their surface features. In the game, users change the location and orientation of a virtual plane to make cuts through 3D objects in a series of spatial puzzles. Users operate an interface to position the virtual plane until a "slice" at the location of the plane matches a target cross-section of a virtual object. Multiple spatial puzzles with different properties are completed throughout the game. In one version of the game, users completed the puzzles in an immersive virtual environment and operated a tangible interface to move the virtual plane. A secondary version of the game required users to view the puzzles in a virtual environment displayed on a computer screen, and to position the slicing plane with a keyboard and mouse. Participants (n = 45) completed a measure of penetrative thinking (Santa Barbara Solids Test) before and after completing one of three interventions: the game with the tangible interface (n = 15), the game with the keyboard interface (n = 15), or a series of (control) questions (n = 15). Although there were no significant pre-/post-intervention changes in penetrative thinking in any of the groups, participants' performance in the game correlated with scores on a standardized test of penetrative thinking. These results provide evidence that the game and the standardized test accessed similar spatial skills and, as a consequence, indicate that the 3D game has the potential to be a valid approach for training penetrative thinking skills.
C1 [Pathak, Aarohi; Welsh, Timothy Nevin] Univ Toronto, Act & Attent Lab, Toronto, ON, Canada.
   [Chang, Jack S. K.; Resch, Gabby; Doucette, Alison; Yeboah, Georgina; Mazalek, Ali] Ryerson Univ, Synaesthet Media Lab, Toronto, ON, Canada.
   [Nitsche, Michael] Georgia Tech, Sch Literature Media & Commun, Atlanta, GA USA.
C3 University of Toronto; Toronto Metropolitan University; University
   System of Georgia; Georgia Institute of Technology
RP Resch, G (corresponding author), Ryerson Univ, Synaesthet Media Lab, Toronto, ON, Canada.
EM gabby.resch@ryerson.ca
OI Welsh, Timothy/0000-0002-5892-8595
FU Social Sciences and Humanities Research Council of Canada; Canada
   Foundation for Innovation; Ontario Ministry for Research and Innovation
FX This research was supported by an Insight Grant from the Social Sciences
   and Humanities Research Council of Canada, an Innovation Fund grant from
   the Canada Foundation for Innovation, and & nbsp;funding & nbsp;from the
   Ontario Ministry for Research and Innovation.
CR [Anonymous], 2016, JASP VERS 0 7 5 5 CO
   Antle AlissaN., 2013, Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction, TEI '13, P65, DOI DOI 10.1145/2460625.2460635
   Atit K., 2015, J GEOSCIENCE ED, V63, n, P66, DOI DOI 10.5408/14-008.1
   Baykal G. E., 2018, International Journal of Child-Computer Interaction, V16, P104, DOI 10.1016/j.ijcci.2018.01.003
   Berg E M., 2011, ACM SIGCHI Conference on Tangible Embedded, Embodied Interaction; Funchal, Portugal, P129, DOI DOI 10.1145/1935701.1935727
   Bozgeyikli L, 2019, DIS '19 COMPANION: COMPANION PUBLICATION OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P135, DOI 10.1145/3301019.3323904
   Chagué S, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927945
   Chang J., 2018, EXT ABSTR 2018 CHI C, VD307, P1, DOI [10.1145/3170427.3186530, DOI 10.1145/3170427.3186530]
   Chang JSK, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P215, DOI 10.1145/3322276.3322280
   Chang JSK, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1239, DOI 10.1145/3064663.3064675
   Chang JSK, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P68, DOI 10.1145/3131277.3132171
   Chiu PT, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P67
   Cohen C. A., 2007, P 29 ANN C COGNITIVE
   COHEN Cheryl, 2018, The Engineering Design Graphics Journal, V82, P1
   Cohen CA, 2012, LEARN INDIVID DIFFER, V22, P868, DOI 10.1016/j.lindif.2012.05.007
   Dadi G.B., 2014, VISUALIZATION ENG, V2, P1, DOI [10.1186/s40327-014-0009-8, DOI 10.1186/S40327-014-0009-8]
   Dourish Paul., 2001, Where the Action Is: The Foundations of Embodied Interaction, DOI DOI 10.7551/MITPRESS/7221.001.0001
   Dunser A., 2006, P 7 ACM SIGCHI NZ CH, P125, DOI 10.1145/1152760.1152776
   Eliot J., 1983, INT DIRECTORY SPATIA
   Frick A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00386
   Fröhlich T, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P153, DOI 10.1145/3242671.3242697
   Gold AU, 2018, INT J SCI EDUC, V40, P2205, DOI 10.1080/09500693.2018.1525621
   Goldin-Meadow S, 2010, PERSPECT PSYCHOL SCI, V5, P664, DOI 10.1177/1745691610388764
   Hannula K.A., 2019, J GEOSCIENCE ED, V67, P143, DOI DOI 10.1080/10899995.2018.1548004
   Harris J, 2013, COGN PROCESS, V14, P105, DOI 10.1007/s10339-013-0544-6
   Hegarty M., 2008, PERSPECTIVE TAKING S
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103
   Jeannerod M, 2001, NEUROIMAGE, V14, pS103, DOI 10.1006/nimg.2001.0832
   Jeffreys H., 1962, THEORY PROBABILITY
   Kali Y, 1996, J RES SCI TEACH, V33, P369, DOI 10.1002/(SICI)1098-2736(199604)33:4<369::AID-TEA2>3.0.CO;2-Q
   Kozhevnikov M, 2001, MEM COGNITION, V29, P745, DOI 10.3758/BF03200477
   Levinson AJ, 2007, MED EDUC, V41, P495, DOI 10.1111/j.1365-2929.2006.02694.x
   Lubinski D, 2006, PERSPECT PSYCHOL SCI, V1, P316, DOI 10.1111/j.1745-6916.2006.00019.x
   Macaranas A., 2012, P 6 INT C TANG EMB E, P161, DOI [10.1145/2148131.2148166, DOI 10.1145/2148131.2148166]
   Malinverni L, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P332, DOI 10.1145/2839462.2839477
   Nakanishi Yasuto., 2012, Proc. Des. Interact. Syst. Conf. - DIS, V12, P458, DOI DOI 10.1145/2317956.2318024
   Oberdörfer S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300405
   Ormand C.J., 2014, J GEOSCIENCE ED, V62, P146, DOI DOI 10.5408/13-027.1
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551
   Reinhardt D, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P638, DOI 10.1145/3173225.3173258
   Sanandaji A, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119888
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Small M.Y., 1983, J COLL SCI TEACH, V13, P41
   Sousa M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4057, DOI 10.1145/3025453.3025566
   Tran C, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0053-8
   Uttal DH, 2012, PSYCHOL LEARN MOTIV, V57, P147, DOI 10.1016/B978-0-12-394293-7.00004-2
   Vandenberg S., 1978, PERCEPT MOTOR SKILL, V27, P599, DOI [10.2466/pms.1978.47.2.599, DOI 10.2466/PMS.1978.47.2.599]
   Wai J, 2009, J EDUC PSYCHOL, V101, P817, DOI 10.1037/a0016127
   Wainman B, 2018, MED EDUC, V52, P1138, DOI 10.1111/medu.13683
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Wauck H, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P125, DOI 10.1145/3025171.3025225
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Wohlschläger A, 2001, PERCEPT PSYCHOPHYS, V63, P709, DOI 10.3758/BF03194431
NR 55
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 10
PY 2020
VL 1
AR 569674
DI 10.3389/frvir.2020.569674
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L7GE4
UT WOS:001024898400001
OA gold
DA 2024-07-18
ER

PT J
AU Banakou, D
   Slater, M
AF Banakou, Domna
   Slater, Mel
TI A comparison of two methods for moving through a virtual environment:
   walking in place and interactive redirected walking
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; locomotion; wayfinding; redirected walking;
   walking-in-place; navigation; room-scale virtual reality
AB Moving through a virtual environment that is larger than the physical space in which the participant operates has been a challenge since the early days of virtual reality. Many different methods have been proposed, such as joystick-based navigation, walking in place where the participant makes walking movements but is stationary in the physical space, and redirected walking where the environment is surreptitiously changed giving the illusion of walking in a long straight line in the virtual space but maybe a circle in the physical space. Each type of method has its limitations, ranging from simulator sickness to still requiring more physical space than is available. Stimulated by the COVID-19 lockdown, we developed a new method of locomotion which we refer to as interactive redirected walking. Here, the participant really walks but, when reaching a boundary, rotates the virtual world so that continuation of walking is always within the physical boundary. We carried out an exploratory study to compare this method with walking in place with respect to presence using questionnaires as well as qualitative responses based on comments written by the participants that were subjected to sentiment analysis. Surprisingly, we found that smaller physical boundaries favor interactive redirected walking, but for boundary lengths more than approximately 7 adult paces, the walking-in-place method is preferable.
C1 [Banakou, Domna] New York Univ Abu Dhabi, Interact Media Arts & Humanities Div, Abu Dhabi, U Arab Emirates.
   [Slater, Mel] Univ Barcelona, Inst Neurosci, Dept Clin Psychol & Psychobiol, Event Lab, Barcelona, Spain.
C3 New York University Abu Dhabi; University of Barcelona
RP Slater, M (corresponding author), Univ Barcelona, Inst Neurosci, Dept Clin Psychol & Psychobiol, Event Lab, Barcelona, Spain.
EM melslater@ub.edu
FU European Research Council (ERC) [742989]
FX The author(s) declare that financial support was received for the
   research, authorship, and/or publication of this article. This work was
   financially supported by the European Research Council (ERC) Advanced
   Grant MoTIVE (Moments in Time in Immersive Virtual Environments)
   (#742989).
CR [Anonymous], 1999, P 26 ANN C COMP GRAP
   Azmandian M., 2015, ICAT-EGVE), P93
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P452
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brotons-Mas JR, 2006, PRESENCE-TELEOP VIRT, V15, P485, DOI 10.1162/pres.15.5.485
   Cherni H., 2020, International Journal of Virtual Reality, V20, P1, DOI [DOI 10.20870/IJVR.2020.20.1.3183, 10.20870/ijvr.2020.20.1, DOI 10.20870/IJVR.2020.20.1]
   Darken R.P., 1996, P SIGCHI C HUMAN FAC, P142, DOI DOI 10.1145/238386.238459
   Darken RP, 1999, PRESENCE-TELEOP VIRT, V8, pIII, DOI 10.1162/pres.1999.8.6.iii
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   FAIRCHILD KM, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P47, DOI 10.1109/VRAIS.1993.380799
   Fan LW, 2023, IEEE T VIS COMPUT GR, V29, P4104, DOI 10.1109/TVCG.2022.3179269
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Feuerriegel S., 2018, Package 'SentimentAnalysis'
   FEUERRIEGEL S, 2019, SENTIMENTANALYSIS DI
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Gorisse G, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03373-x
   Hanson S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P367, DOI [10.1109/vr.2019.8797751, 10.1109/VR.2019.8797751]
   Held R. M., 1992, Presence: Teleoperators and Virtual Environments, V1, P109, DOI [https://doi.org/10.1162/pres.1992.1.1.109, 10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Hwang J.-Y., 2022, arXiv
   Jockers M., 2017, Package "syuzhet
   Kassambara A, 2017, Practical Guide to Principal Component Methods in R: PCA, M (CA), FAMD, MFA, HCPC, Factoextra
   Kassambara A., 2017, Factoextra: extract and visualize the results of multivariate data analyses, V1, P337
   Kim D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P379, DOI 10.1109/VR51125.2022.00057
   Kim YM, 2021, APPL ERGON, V96, DOI 10.1016/j.apergo.2021.103482
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lee CG, 2023, VIRTUAL REAL-LONDON, V27, P717, DOI 10.1007/s10055-022-00682-y
   Leeb R, 2006, PRESENCE-TELEOP VIRT, V15, P500, DOI 10.1162/pres.15.5.500
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Loetscher T, 2023, MULTIMODAL TECHNOLOG, V7, DOI 10.3390/mti7030032
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Mottelson A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.681482
   Naldi M, 2019, Arxiv, DOI [arXiv:1901.08319, DOI 10.48550/ARXIV.1901.08319]
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Peck TC, 2012, IEEE T VIS COMPUT GR, V18, P1053, DOI 10.1109/TVCG.2011.289
   Pfurtscheller G, 2006, BRAIN RES, V1071, P145, DOI 10.1016/j.brainres.2005.11.083
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   Radiah R, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3472617
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Razzaque S., 2001, Proc. Eurogr, P289, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Rinker T., 2021, sentimentr: Calculate text polarity sentiment version 2.9.0
   Ruddle RA, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2465780.2465785
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Sheridan TB, 1996, PRESENCE-TELEOP VIRT, V5, P241, DOI 10.1162/pres.1996.5.2.241
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2023, VIRTUAL REAL-LONDON, V27, P651, DOI 10.1007/s10055-022-00685-9
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Sousa M, 2019, Arxiv, DOI arXiv:1911.13032
   Stan Development Team, 2011, Stan modeling language users guide and reference manual, V2, P25
   Stanney K. M., 2009, Human factors in simulation and training, P117
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Yoon S, 2017, STUD HEALTH TECHNOL, V245, P1292, DOI 10.3233/978-1-61499-830-3-1292
NR 61
TC 0
Z9 0
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 20
PY 2023
VL 4
AR 1294539
DI 10.3389/frvir.2023.1294539
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Z5RF1
UT WOS:001112637300001
OA gold
DA 2024-07-18
ER

PT J
AU Thomas, LJ
AF Thomas, Laura J.
TI The future potential of virtual reality countermeasures for maintaining
   behavioural health during long duration space exploration
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; space; Mars; behavioural health; monitoring;
   countermeasures; CBT (cognitive behavioural therapy); psychological
   safety
ID MENTAL-HEALTH; PSYCHOLOGICAL SAFETY; THERAPY; STRESS; SPACEFLIGHT;
   VALIDATION; ASTRONAUTS; ALLIANCE; SYMPTOMS; TOOL
AB Long duration space exploration is no longer a fantasy, with Elon Musk claiming to launch astronauts to Mars as early as 2029. The substantial increase in spaceflight duration required for a Mars mission has resulted in a stronger focus on behavioural health outcomes at NASA, with increased interest in using virtual reality countermeasures to both monitor and promote psychological wellbeing. From the perspective of a practitioner psychologist, this paper first considers the utility of virtual reality assessment of emerging behavioural health concerns for remote monitoring purposes. Key opportunities include using virtual reality for functional cognitive testing and leveraging the predictive abilities of multimodal data for personalised insights into symptomology. Suggestions are given as to how astronauts can self-monitor usage of virtual leisure activities that facilitate positive emotional experiences. Secondly, the potential to develop virtual reality countermeasures to deliver semi-structured therapeutic interventions such as collaborative cognitive-behavioural formulation in the absence of real-time communication is discussed. Finally, considerations for the responsible implementation of psychological monitoring tools are reviewed within a context of fostering psychological safety and reducing stigma.
EM laura.thomas.psychology@gmail.com
CR Alfano CA, 2021, ACTA ASTRONAUT, V181, P405, DOI 10.1016/j.actaastro.2021.01.051
   Alfano CA, 2018, ACTA ASTRONAUT, V142, P289, DOI 10.1016/j.actaastro.2017.11.009
   Anderson A, 2022, HUM FACTORS, DOI 10.1177/00187208221100693
   Baghaei N, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/29681
   Baier AL, 2020, CLIN PSYCHOL REV, V82, DOI 10.1016/j.cpr.2020.101921
   Basner M, 2015, AEROSP MED HUM PERF, V86, P942, DOI 10.3357/AMHP.4343.2015
   Bell IH, 2020, DIALOGUES CLIN NEURO, V22, P169, DOI 10.31887/DCNS.2020.22.2/lvalmaggia
   Carulli M., 2015, P ASME 2019 INT DESI, DOI [10.1115/DETC2019-97836, DOI 10.1115/DETC2019-97836]
   Chitale V, 2022, GAMES HEALTH J, V11, P341, DOI 10.1089/g4h.2021.0227
   Choukér A, 2020, NPJ MICROGRAVITY, V6, DOI 10.1038/s41526-020-00122-8
   Copyright C., 2022, PSYCHOL SAFETY MOD M
   David D, 2018, J EVID-BASED PSYCHOT, V18, P1
   Edmondson A, 1999, ADMIN SCI QUART, V44, P350, DOI 10.2307/2666999
   ESA-K Oldenburg, 2010, ESA HUM SPAC STAT
   Fara S., 2022, PREPRINT, DOI [10.48550/arXiv.2204.00088, DOI 10.48550/ARXIV.2204.00088]
   Flückiger C, 2020, J CONSULT CLIN PSYCH, V88, P829, DOI 10.1037/ccp0000594
   Fordham B, 2021, PSYCHOL MED, V51, P21, DOI 10.1017/S0033291720005292
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Gatti M, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e09414
   Geraets CNW, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.828410
   Goemaere S, 2019, ACTA ASTRONAUT, V159, P273, DOI 10.1016/j.actaastro.2019.03.059
   Gonzalez A., 2022, ASYNCHRONOUS TECHNIQ
   Hataya Ryuichiro, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2211, 10.48550/arXiv.2211, 10.48550/arXiv.2211.]
   Jimenez MP, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18094790
   Jo H, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16234739
   Johannes B, 2020, STRESS CHALLENGES AND IMMUNITY IN SPACE: FROM MECHANISMS TO MONITORING AND PREVENTIVE STRATEGIES, 2ND EDITION, P421, DOI 10.1007/978-3-030-16996-1_22
   Johannes B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134814
   Johnson PJ, 2010, ACTA ASTRONAUT, V67, P561, DOI 10.1016/j.actaastro.2010.05.001
   Josh R., 2020, PROJECT ATLAS
   Kanas N., 2016, PSYCHIAT ISSUES SPAC
   Kanas N, 2008, SPACE TECHNOL LIB, V22, P15, DOI 10.1007/978-1-4020-6770-9_2
   Kane R.L., 2019, Handbook of Psychological Assessment, P573, DOI [10.1016/b978-0-12-802203-0.00020-1, DOI 10.1016/B978-0-12-802203-0.00020-1]
   Kane RL, 2005, AVIAT SPACE ENVIR MD, V76, pB183
   Kearney A. R., 2016, TM201619275 NASA JOH
   Keller N, 2022, FRONT PHYSIOL, V13, DOI 10.3389/fphys.2022.932425
   Kroenke K, 2009, J AFFECT DISORDERS, V114, P163, DOI 10.1016/j.jad.2008.06.026
   Kuyken W., 2011, Collaborative case conceptualization: Working effectively with clients in cognitive-behavioral therapy
   Landon L. B., 2022, RISK PERFORMANCE BEH
   Leach J, 2016, EXTREME PHYSIOL MED, V5, DOI 10.1186/s13728-016-0048-y
   Lee ARG, 2020, NPJ MICROGRAVITY, V6, DOI 10.1038/s41526-020-0097-9
   Leigh-Hunt N, 2017, PUBLIC HEALTH, V152, P157, DOI 10.1016/j.puhe.2017.07.035
   Lindner P, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00792
   Lorenzo-Luaces L, 2017, BEHAV THER, V48, P581, DOI 10.1016/j.beth.2016.11.011
   Lyons KD, 2020, AEROSP MED HUM PERF, V91, P876, DOI 10.3357/AMHP.5705.2020
   Mollicone D., 2011, INDIVIDUALIZED BEHAV
   Mollicone D., 2012, INDIVIDUALIZED STRES
   Musk E., 2022, WHATS YOUR GUESS
   NASA, 2015, Reference Guide to the International Space Station
   Nasa S. T. E. M., 2020, NASA STEM STARS VIRT
   NASA Video, 2022, NASA SEEKS INPUT MOO
   Newman A, 2017, HUM RESOUR MANAGE R, V27, P521, DOI 10.1016/j.hrmr.2017.01.001
   Padesky CA, 2012, CLIN PSYCHOL PSYCHOT, V19, P283, DOI 10.1002/cpp.1795
   PALINKAS LA, 1995, J APPL SOC PSYCHOL, V25, P557, DOI 10.1111/j.1559-1816.1995.tb01599.x
   Palinkas LA, 2008, LANCET, V371, P153, DOI 10.1016/S0140-6736(07)61056-3
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   Ping Wu, 2015, 2015 IEEE International Vacuum Electronics Conference (IVEC), P1, DOI 10.1109/IVEC.2015.7223837
   Prudenzi A, 2019, VIRTUAL REAL-LONDON, V23, P179, DOI 10.1007/s10055-018-0372-1
   Roy-O'Reilly M, 2021, NPJ MICROGRAVITY, V7, DOI 10.1038/s41526-021-00133-z
   Rozovsky J., 2015, 5 KEYS SUCCESSFUL GO
   Salamon N, 2018, ACTA ASTRONAUT, V146, P117, DOI 10.1016/j.actaastro.2018.02.034
   Sheikh M, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.662811
   Siani A, 2021, HEALTH TECHNOL-GER, V11, P425, DOI 10.1007/s12553-021-00528-8
   Slack K., 2016, RISK ADVERSE COGNITI
   Smith N., 2023, ADV HLTH MONITORING
   Smith N, 2023, JMIR FORM RES, V7, DOI 10.2196/37784
   Stahn AC, 2019, NEW ENGL J MED, V381, P2273, DOI 10.1056/NEJMc1904905
   Stepanova K., 2021, VIRTUAL REALITY CAN
   Strangman GE, 2014, AVIAT SPACE ENVIR MD, V85, P1033, DOI 10.3357/ASEM.3961.2014
   Stroud KJ, 2005, AVIAT SPACE ENVIR MD, V76, P352
   Stuster J., 2010, J COSMOL, V12, P3566
   Takács E, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-88938-6
   Temp A.G. M., 2020, Safety in Extreme Environments, V2, P141, DOI DOI 10.1007/S42797-019-00013-6
   Varshney LR, 2021, J INTELL-BASEL, V9, DOI 10.3390/jintelligence9040054
   Vartanian O, 2021, J COGN ENHANCE, V5, P280, DOI 10.1007/s41465-020-00201-4
   Vessel E. A., 2015, TM2015218576 NASA
   Voinescu A, 2023, VIRTUAL REAL-LONDON, V27, P119, DOI 10.1007/s10055-021-00520-7
   Whatley AE, 2023, READ PSYCHOL, V44, P710, DOI 10.1080/02702711.2023.2187906
   Wheeler SG, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.671664
   Wiebe A, 2022, CLIN PSYCHOL REV, V98, DOI 10.1016/j.cpr.2022.102213
   Wu P, 2016, PROCEDIA ENGINEER, V159, P108, DOI 10.1016/j.proeng.2016.08.132
NR 80
TC 0
Z9 0
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 21
PY 2023
VL 4
AR 1180165
DI 10.3389/frvir.2023.1180165
PG 6
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WT1
UT WOS:001023291700001
OA gold
DA 2024-07-18
ER

PT J
AU Wang, Y
   Lin, YS
AF Wang, Yuchen
   Lin, Yin-Shan
TI Public participation in urban design with augmented reality technology
   based on indicator evaluation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE urban design; mobile augmented reality; public participation and
   evaluation; urban design indicator; interactive operation
ID TOOL
AB Decision-making processes in traditional urban design approaches are mainly top-down. Such processes have defects including not only taking a long time to examine design results but also leading to irreversible impacts after design implementation. Policymakers and researchers stress the importance of collaborating with different stakeholders in the process of urban design policy and guideline making in order to minimize these negative impacts. However, introducing public participation into urban design from the bottom up is challenging, especially when the process involves abstract urban design concepts such as indicators. This paper explores a new workflow aimed at enhancing public participation to cooperate in urban design work with the help of a newly designed platform tool powered by mobile augmented-reality technologies. The platform is intuitive to use and displays scenes of potential urban design results by superimposing the virtual models onto real-world environments on mobile devices. The public stakeholders are provided with this platform on-site to evaluate the initial values of urban design indicators by interacting with the prototype design along with an immersive experience. They can also grow familiar with the concepts of the given indicators during this process, which helps them better understand the implications of guidelines in future published urban design drafts and estimate the potential results. Their feedback is collected, which can help urban designers further optimize the indicators in urban design guideline making in order to improve their rationality. This process of urban design involving public participation is repeatable, which makes it possible to continuously adjust the design results. A user study was conducted to examine the platform's usability and its ability to enhance public familiarity with the concepts of given indicators and their willingness to participate in urban design evaluation. The study also attests to the possibility of a workflow that integrates public feedback with the urban design process.
C1 [Wang, Yuchen; Lin, Yin-Shan] Univ Hawaii Manoa, Sch Architecture, Honolulu, HI 96822 USA.
C3 University of Hawaii System; University of Hawaii Manoa
RP Lin, YS (corresponding author), Univ Hawaii Manoa, Sch Architecture, Honolulu, HI 96822 USA.
EM lilianlin003@163.com
CR Alibegovic D. J., 2006, CHALLENGE BUILDING P
   Allbach B., 2011, MOBILE AUGMENTED CIT
   Allen M., 2011, Proceedings of OZCHI'11, P11, DOI [DOI 10.1145/2071536.2071538, 10.1145/2071536.2071538, DOI 10.1145/2071536]
   Amado M.P., 2010, International Journal of Human and Social Sciences, V5, P102
   [Anonymous], 1961, DEATH LIFE GT AM CIT
   Atkinson William., 1912, ORIENTATION BUILDING
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Batty M., 2009, CITIES COMPLEX SYSTE, DOI DOI 10.1007/978-0-387-30440-3_69
   Batty M., 2012, Complexity Theories of Cities Have Come of Age, P21, DOI 10.1007/978-3-642-24544-2_3
   Bekele MK, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00091
   Brody SD, 2003, J AM PLANN ASSOC, V69, P245, DOI 10.1080/01944360308978018
   Broschart D., 2013, P REAL CORP, P119
   Broschart D., 2015, GIS SCI DIE F R GEOI, V1, DOI [10.5282/ubm/epub.35802, DOI 10.5282/UBM/EPUB.35802]
   Burby RJ, 2003, J AM PLANN ASSOC, V69, P33, DOI 10.1080/01944360308976292
   Calabrese Chiara., 2017, Urban design and representation: a multidisciplinary and multisensory approach, P181, DOI DOI 10.1007/978-3-319-51804-6_14
   Calhoun Craig., 1992, HABERMAS PUBLIC SPHE
   Campoli J., 2012, Made for walking
   Carmona M., 2021, Public places urban spaces: The dimensions of urban design, P690
   Carozza L, 2014, COMPUT-AIDED CIV INF, V29, P2, DOI 10.1111/j.1467-8667.2012.00798.x
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chen R., 2008, Tsinghua Science Technology, V13, P13, DOI DOI 10.1016/S1007-0214(08)70120-2
   Creighton J.L., 2005, PUBLIC PARTICIPATION
   Dasimah O., 2009, Asian Social Science, V5, P30, DOI DOI 10.5539/ASS.V5N3P30
   Dias N, 2018, INT J STRATEG PROP M, V22, P265, DOI 10.3846/ijspm.2018.3683
   Ewing R, 2013, METR PLANN DES, P1, DOI 10.5822/978-1-61091-209-9
   Ewing R., 1996, PEDESTRIAN TRANSIT F
   Ewing R, 2010, J AM PLANN ASSOC, V76, P265, DOI 10.1080/01944361003766766
   Ewing R, 2009, J URBAN DES, V14, P65, DOI 10.1080/13574800802451155
   Farshid M, 2018, BUS HORIZONS, V61, P657, DOI 10.1016/j.bushor.2018.05.009
   Ford R. T., 2001, LEGAL GEOGRAPHIES RE, P118
   Fukuda T, 2014, FRONT ARCHIT RES, V3, P386, DOI 10.1016/j.foar.2014.08.003
   Fukuda Tomohiro., 2017, Computer-Aided Architectural Design. Future Trajectories: 17th International Conference, CAAD Futures 2017, Istanbul, Turkey, July 12-14, 2017, P60, DOI DOI 10.1007/978-981-10-5197-5_4
   Gehl Jan., 2006, URBAN DES INT, V11, P32, DOI [DOI 10.1057/PALGRAVE.UDI.9000162, 10.1057/palgrave.udi.9000162]
   Grassi S, 2016, J PHYS CONF SER, V749, DOI 10.1088/1742-6596/749/1/012020
   Guan C., 2018, URBAN PLAN INT, V33, P22, DOI [10.22217/upi.2017.540, DOI 10.22217/UPI.2017.540]
   Haahr M, 2017, LECT NOTES COMPUT SC, V10622, P313, DOI 10.1007/978-3-319-70111-0_29
   Handy S., 1993, Regional versus local accessibility: Implications for non-work travel
   Hanzl M, 2007, DESIGN STUD, V28, P289, DOI 10.1016/j.destud.2007.02.003
   Healey P, 2006, RTPI LIB SER, P1
   Healey P.:., 1992, Town planning review, V63, P143, DOI [DOI 10.3828/TPR.63.2.422X602303814821, 10.3828/tpr.63.2.422x602303814821]
   ICLEI, 2016, GLOB DEV URB AD RES
   Imottesjo H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020797
   Innes JE, 2015, PLAN THEOR, V14, P195, DOI 10.1177/1473095213519356
   Ismail WAW, 2015, PROCD SOC BEHV, V168, P357, DOI 10.1016/j.sbspro.2014.10.241
   Kikuchi N, 2022, J COMPUT DES ENG, V9, P837, DOI 10.1093/jcde/qwac032
   Korhonen O., 2017, P 30 BLED ECONFERENC, DOI [10.18690/978-961-286-043-1.24, DOI 10.18690/978-961-286-043-1.24]
   Krek A., 2005, P 10 S INF COMM TECH, VVolume 5, P420
   Li SJ, 2022, ENVIRON PLAN B-URBAN, V49, P1197, DOI 10.1177/23998083211056341
   Lock O, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365734
   Loures L., 2008, WSEAS Transactions on Environment and Development, V4, P794
   Lynch K., 1960, The Image of the City, P1
   Miraftab F, 2003, J PLAN EDUC RES, V22, P226, DOI 10.1177/0739456X02250305
   Miyake M., 2016, 16 INT C COMP CIV BU, P1644
   Moeslund T. B., 2004, WORKSHOP MULTIUSER U, P25
   Mystakidis S., 2022, ENCYCLOPEDIA, V2, P486, DOI [10.3390/encyclopedia2010031, DOI 10.3390/ENCYCLOPEDIA2010031]
   Nasser N, 2003, J PLAN LIT, V17, P467, DOI 10.1177/0885412203017004001
   NOBLE MA, 1993, LAND USE POLICY, V10, P127, DOI 10.1016/0264-8377(93)90004-T
   Oduor M, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.706162
   Park CS, 2013, AUTOMAT CONSTR, V33, P95, DOI 10.1016/j.autcon.2012.09.012
   Penn A, 2004, RECENT ADVANCES IN DESIGN AND DECISION SUPPORT SYSTEMS IN ARCHITECTURE AND URBAN PLANNING, P213
   Phan V. T., 2010, INT J COMPUT APPL, V4, P26, DOI [10.5120/809-1149, DOI 10.5120/809-1149]
   Piekarski W, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P31, DOI 10.1109/ISWC.2001.962093
   Quintero J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01835
   Domínguez ER, 2017, RIED-REV IBEROAM EDU, V20, P141, DOI 10.5944/ried.20.2.17675
   Roy U., 2009, 57 NAT TOWN COUNTR P
   Salimannshausen SM, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P250, DOI 10.1145/3461778.3462130
   Sanoff H., 2000, Community Participation Methods in Design and Planning
   Sareika M., 2007, P ISMAR, P27, DOI [10.1109/ISMAR.2007.4538821, DOI 10.1109/ISMAR.2007.4538821]
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Schmidt S, 2010, J URBAN DES, V15, P453, DOI 10.1080/13574809.2010.502331
   Schubert G, 2015, COMM COM INF SC, V527, P55, DOI 10.1007/978-3-662-47386-3_4
   Seichter H, 2007, COMPUTER-AIDED ARCHITECTURAL DESIGN FUTURES (CAAD FUTURES) 2007, P3, DOI 10.1007/978-1-4020-6528-6_1
   Semeraro T, 2020, LAND-BASEL, V9, DOI 10.3390/land9040098
   Shin D, 2019, INFORM COMMUN SOC, V22, P1212, DOI 10.1080/1369118X.2017.1411519
   Skrimizea E, 2019, PLAN THEOR, V18, P122, DOI 10.1177/1473095218780515
   St-Aubin B., 2010, P CAN GEOM C, P13
   Thomas B., 1999, INT J DESIGN COMPUTI, V1
   TONG Z, 2010, 2010 18 INT C GEOINF, P1
   Vanegas CA, 2010, COMPUT GRAPH FORUM, V29, P25, DOI 10.1111/j.1467-8659.2009.01535.x
   Vanegas CA, 2009, IEEE T VIS COMPUT GR, V15, P424, DOI 10.1109/TVCG.2008.193
   Ventura J, 2012, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2012.6402531
   Wang X., 2001, PUBLIC PERFORM MANAG, V24, P322, DOI [DOI 10.2307/3381222, 10.2307/3381222]
   Wang XY, 2007, CAADRIA 2007: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA, P561
   Wang XY, 2009, INT J ARCHIT COMPUT, V7, P310, DOI 10.1260/147807709788921985
   Webster A, 1996, COMPUTING IN CIVIL ENGINEERING, P913
   Yabuki N, 2011, AUTOMAT CONSTR, V20, P228, DOI 10.1016/j.autcon.2010.08.003
   Ye Y, 2019, ENVIRON PLAN B-URBAN, V46, P1439, DOI 10.1177/2399808319828734
   Young I.M., 1990, Justice and the Politics of Difference
   Zheng NX, 2019, IOP C SER EARTH ENV, V267, DOI 10.1088/1755-1315/267/5/052007
NR 89
TC 4
Z9 4
U1 3
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 6
PY 2023
VL 4
AR 1071355
DI 10.3389/frvir.2023.1071355
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RT8
UT WOS:001023161800001
OA gold
DA 2024-07-18
ER

PT J
AU Thoma, SP
   Hartmann, M
   Christen, J
   Mayer, B
   Mast, FW
   Weibel, D
AF Thoma, Stefan P.
   Hartmann, Matthias
   Christen, Jonas
   Mayer, Boris
   Mast, Fred W.
   Weibel, David
TI Increasing awareness of climate change with immersive virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; environmental attitude; changing attitude; climate
   change; realism; IAT; immersion; presence
ID IMPLICIT ASSOCIATION TEST; ENVIRONMENTS; EXPERIENCE; TECHNOLOGY;
   ATTITUDES; PEOPLE; IMPACT; MODEL; IAT
AB Previous research has shown that immersive virtual reality (VR) is a suitable tool for visualizing the consequences of climate change. The aim of the present study was to investigate whether visualization in VR has a stronger influence on climate change awareness and environmental attitudes compared to traditional media. Furthermore, it was examined how realistic a VR experience has to be in order to have an effect. The VR experience consisted of a model of the Aletsch glacier (Switzerland) melting over the course of 220 years. Explicit measurements (new environmental paradigm NEP, climate change scepticism, and nature relatedness) and an implicit measurement (implicit association test) were collected before and after the VR intervention and compared to three different non-VR control conditions (video, images with text, and plain text). In addition, the VR environment was varied in terms of degrees of realism and sophistication (3 conditions: abstract visualization, less sophisticated realistic visualization, more sophisticated realistic visualization). The six experimental conditions (3 VR conditions, three control conditions) were modeled as mixed effects, with VR versus control used as a fixed effect in a mixed effects modeling framework. Across all six conditions, environmental awareness (NEP) was higher after the participants (N = 142) had been confronted with the glacier melting, while no differences were found for nature relatedness and climate change scepticism before and after the interventions. There was no significant difference between VR and control conditions for any of the four measurements. Nevertheless, contrast analyses revealed that environmental awareness increased significantly only for the VR but not for the control conditions, suggesting that VR is more likely to lead to attitude change. Our results show that exposure to VR environments successfully increased environmental awareness independently of the design choices, suggesting that even abstract and less sophisticated VR environment designs may be sufficient to increase pro-environmental attitudes.
C1 [Thoma, Stefan P.; Mayer, Boris; Mast, Fred W.; Weibel, David] Univ Bern, Dept Psychol, Bern, Switzerland.
   [Thoma, Stefan P.; Hartmann, Matthias; Mayer, Boris; Weibel, David] Fac Psychol, UniDistance Suisse, Brig, Switzerland.
   [Christen, Jonas] Zurich Univ Arts, Dept Design, Zurich, Switzerland.
C3 University of Bern
RP Weibel, D (corresponding author), Univ Bern, Dept Psychol, Bern, Switzerland.; Weibel, D (corresponding author), Fac Psychol, UniDistance Suisse, Brig, Switzerland.
EM david.weibel@unibe.ch
OI Hartmann, Matthias/0000-0003-1132-1339
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Ahn SJ, 2015, COMMUN RES, V42, P839, DOI 10.1177/0093650214534973
   Ahn SJ, 2014, COMPUT HUM BEHAV, V39, P235, DOI 10.1016/j.chb.2014.07.025
   Akerlof K, 2013, GLOBAL ENVIRON CHANG, V23, P81, DOI 10.1016/j.gloenvcha.2012.07.006
   Arnold RD, 2015, PROCEDIA COMPUT SCI, V44, P669, DOI 10.1016/j.procs.2015.03.050
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beattie G, 2012, SEMIOTICA, V192, P315, DOI 10.1515/sem-2012-0066
   Beattie Geoffrey, 2011, INT J ENV CULTURAL E, V7, P211, DOI [DOI 10.18848/1832-2077/CGP/v07i04/54948, 10.18848/1832-2077/cgp/v07i04/54948, DOI 10.18848/1832-2077/CGP/V07I04/54948]
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bujic M, 2020, INTERNET RES, V30, P1407, DOI 10.1108/INTR-07-2019-0306
   Carey Mark., 2010, In the Shadow of Melting Glaciers: Climate Change and Andean Society
   Carmichael JT, 2017, ENVIRON POLIT, V26, P232, DOI 10.1080/09644016.2016.1263433
   Chirico A, 2021, VIRTUAL REAL-LONDON, V25, P107, DOI 10.1007/s10055-020-00442-w
   Craig SD, 2002, J EDUC PSYCHOL, V94, P428, DOI 10.1037//0022-0663.94.2.428
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Deringer SA, 2021, ECOPSYCHOLOGY, V13, P219, DOI 10.1089/eco.2020.0044
   Dunlap RE, 2000, J SOC ISSUES, V56, P425, DOI 10.1111/0022-4537.00176
   Erolin C, 2019, J VIS COMMUN MED, V42, P93, DOI 10.1080/17453054.2019.1597626
   Evans JSBT, 2008, ANNU REV PSYCHOL, V59, P255, DOI 10.1146/annurev.psych.59.103006.093629
   Fauville G., 2020, Technology and Health, P91, DOI DOI 10.1016/B978-0-12-816958-2.00005-8
   Fiedler K., 2006, EUROPEAN REV SOCIAL, V17, P74, DOI [10.1080/10463280600681248, DOI 10.1080/10463280600681248]
   Field CB, 2014, CLIMATE CHANGE 2014: IMPACTS, ADAPTATION, AND VULNERABILITY, PT A: GLOBAL AND SECTORAL ASPECTS, P1
   Friese M, 2006, PSYCHOL MARKET, V23, P727, DOI 10.1002/mar.20126
   Gonçalves G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3533377
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Greenwald AG, 2003, J PERS SOC PSYCHOL, V85, P197, DOI 10.1037/0022-3514.85.2.197
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Hamstra SJ, 2014, ACAD MED, V89, P387, DOI 10.1097/ACM.0000000000000130
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Hsu WC, 2018, EDUC TECHNOL SOC, V21, P187
   Huang J., 2021, THESIS PENNSYLVANIA
   Hvass J, 2017, 2017 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video (3DTV-CON), P1, DOI [DOI 10.1109/3DTV.2017.8280421, DOI 10.1109/3DTV.2017]
   Hvass J., 2018, PRELIMINA
   Igroup, 2016, ISS ONLIN
   Ijsselsteijn W, 2001, PRESENCE-TELEOP VIRT, V10, P298, DOI 10.1162/105474601300343621
   Jackson M, 2015, WIRES CLIM CHANGE, V6, P479, DOI 10.1002/wcc.351
   Jacobson J, 2017, SMART COMPUT INTELL, P35, DOI 10.1007/978-981-10-5490-7_3
   Jost JT, 2019, CURR DIR PSYCHOL SCI, V28, P10, DOI 10.1177/0963721418797309
   Jouvet G, 2011, J GLACIOL, V57, P1033, DOI 10.3189/002214311798843359
   Karpinski A, 2001, J PERS SOC PSYCHOL, V81, P774, DOI 10.1037/0022-3514.81.5.774
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Lezak SB, 2016, J ENVIRON PSYCHOL, V46, P143, DOI 10.1016/j.jenvp.2016.04.005
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Linsbauer A, 2012, J GEOPHYS RES-EARTH, V117, DOI 10.1029/2011JF002313
   Littledyke M, 2008, ENVIRON EDUC RES, V14, P1, DOI 10.1080/13504620701843301
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   Markowitz DM, 2021, CURR OPIN PSYCHOL, V42, P60, DOI 10.1016/j.copsyc.2021.03.009
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   Markowitz E., 2014, CONNECTING CLIMATE G
   Mayer R. E., 2014, The Cambridge handbook of multimedia learning, P43, DOI [10.1017/CBO9781139547369.017, DOI 10.1017/CBO9781139547369.017]
   McCright AM, 2016, ENVIRON POLIT, V25, P338, DOI 10.1080/09644016.2015.1090371
   Mierke J, 2003, J PERS SOC PSYCHOL, V85, P1180, DOI 10.1037/0022-3514.85.6.1180
   Nardi B, 2018, COMMUN ACM, V61, P86, DOI 10.1145/3183582
   Nisbet EK, 2009, ENVIRON BEHAV, V41, P715, DOI 10.1177/0013916508318748
   Nosek BA, 2005, PERS SOC PSYCHOL B, V31, P166, DOI 10.1177/0146167204271418
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Petersen GB, 2020, BRIT J EDUC TECHNOL, V51, P2098, DOI 10.1111/bjet.12991
   Pollard KA, 2020, VIRTUAL REAL-LONDON, V24, P783, DOI 10.1007/s10055-019-00411-y
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Price M., 2009, CLIMATIC CHANGE, V94, P517, DOI [10.1007/s10584-008-9513-y, DOI 10.1007/S10584-008-9513-Y]
   Rihs M, 2022, RELIG BRAIN BEHAV, V12, P271, DOI 10.1080/2153599X.2022.2035800
   Rothermund K, 2004, J EXP PSYCHOL GEN, V133, P139, DOI 10.1037/0096-3445.133.2.139
   Ryu D, 2020, CYTOTECHNOLOGY, V72, P579, DOI 10.1007/s10616-020-00408-5
   Sajjadi P, 2022, FRONT ENV SCI-SWITZ, V10, DOI 10.3389/fenvs.2022.957204
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schultz PW, 2004, J ENVIRON PSYCHOL, V24, P31, DOI 10.1016/S0272-4944(03)00022-7
   Slabbinck H, 2011, EUR J PERSONALITY, V25, P76, DOI 10.1002/per.778
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Soliman M, 2017, J MEDIA PSYCHOL-GER, V29, P8, DOI 10.1027/1864-1105/a000213
   Spangenberger P, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05184-0
   Trémolière B, 2021, J ENVIRON PSYCHOL, V74, DOI 10.1016/j.jenvp.2021.101561
   Trope Y, 2010, PSYCHOL REV, V117, P440, DOI 10.1037/a0018963
   Tussyadiah IP, 2018, TOURISM MANAGE, V66, P140, DOI 10.1016/j.tourman.2017.12.003
   UCLA: Statistical Consulting Group, 2022, R LIB CONTR COD SYST
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Vorderer P., 2004, Mec spatial presence questionnaire
   Wang J, 2019, ENVIRON BEHAV, V51, P3, DOI 10.1177/0013916517738036
   Weber S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.628298
   Weibel D, 2011, INT J COMPUT GAMES T, V2011, DOI 10.1155/2011/282345
   Weibel D, 2011, COGNITION EMOTION, V25, P1291, DOI 10.1080/02699931.2010.543016
   Whitmarsh L, 2008, J RISK RES, V11, P351, DOI 10.1080/13669870701552235
   Whitmarsh L, 2011, GLOBAL ENVIRON CHANG, V21, P690, DOI 10.1016/j.gloenvcha.2011.01.016
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Wilson T. L., 2017, IAFOR J PSYCHOL BEHA, V3, P11, DOI [10.22492/ijpbs.3.1.02, DOI 10.22492/IJPBS.3.1.02]
   Wilson TD, 2000, PSYCHOL REV, V107, P101, DOI 10.1037/0033-295X.107.1.101
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xiao CY, 2019, SOC NATUR RESOUR, V32, P53, DOI 10.1080/08941920.2018.1501529
NR 94
TC 4
Z9 4
U1 5
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 13
PY 2023
VL 4
AR 897034
DI 10.3389/frvir.2023.897034
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RW6
UT WOS:001023164600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Steed, A
   Izzouzi, L
   Brandstätter, K
   Friston, S
   Congdon, B
   Olkkonen, O
   Giunchi, D
   Numan, N
   Swapp, D
AF Steed, Anthony
   Izzouzi, Lisa
   Brandstatter, Klara
   Friston, Sebastian
   Congdon, Ben
   Olkkonen, Otto
   Giunchi, Daniele
   Numan, Nels
   Swapp, David
TI Ubiq-exp: A toolkit to build and run remote and distributed mixed
   reality experiments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; 3D user interfaces; experiment design; distributed
   experiments; remote experiments
ID VIRTUAL-REALITY
AB Developing mixed-reality (MR) experiments is a challenge as there is a wide variety of functionality to support. This challenge is exacerbated if the MR experiment is multi-user or if the experiment needs to be run out of the lab. We present Ubiq-Exp - a set of tools that provide a variety of functionality to facilitate distributed and remote MR experiments. We motivate our design and tools from recent practice in the field and a desire to build experiments that are easier to reproduce. Key features are the ability to support supervised and unsupervised experiments, and a variety of tools for the experimenter to facilitate operation and documentation of the experimental sessions. We illustrate the potential of the tools through three small-scale pilot experiments. Our tools and pilot experiments are released under a permissive open-source license to enable developers to appropriate and develop them further for their own needs.
C1 [Steed, Anthony; Izzouzi, Lisa; Brandstatter, Klara; Friston, Sebastian; Congdon, Ben; Olkkonen, Otto; Giunchi, Daniele; Numan, Nels; Swapp, David] UCL, Dept Comp Sci, London, England.
C3 University of London; University College London
RP Steed, A (corresponding author), UCL, Dept Comp Sci, London, England.
EM A.Steed@ucl.ac.uk
OI Swapp, David/0000-0002-9335-8663; Brandstatter,
   Klara/0000-0002-8586-7804; Steed, Anthony/0000-0001-9034-3020; Numan,
   Nels/0000-0003-2931-7653; Giunchi, Daniele/0000-0003-1674-8876
FU United Kingdom EPSRC project Graphics Pipelines for Next Generation
   Mixed Reality Systems [EP/T01346X/1]; EU H2020 project CLIPE [860768];
   EU H2020 project RISE [739578]
FX This work was partly funded by United Kingdom EPSRC project Graphics
   Pipelines for Next Generation Mixed Reality Systems (grant reference
   EP/T01346X/1), EU H2020 project RISE (grant number 739578) and EU H2020
   project CLIPE (grant number 860768).
CR Alexandrovsky D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376260
   [Anonymous], 1995, ACM Transactions on Computer-Human Interaction (TOCHI), DOI DOI 10.1145/210079.210088
   Bebko AO, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520938400
   Bierbaum A, 2001, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2001.913774
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Blanchard C., 1990, Computer Graphics, V24, P35, DOI 10.1145/91394.91409
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Bschel W., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445651
   CARLSSON C, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P394, DOI 10.1109/VRAIS.1993.380753
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Damer B., 1997, Avatars! Exploring and Building Virtual Worlds on the Internet
   Dubosc C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P438, DOI 10.1109/VRW52623.2021.00101
   Ehthesham Muhammad Umair, 2018, PUZZLE MAKER
   Ellis S. R., 1991, Computing Systems in Engineering, V2, P321, DOI 10.1016/0956-0521(91)90001-L
   Fabri M, 1999, LECT NOTES ARTIF INT, V1739, P269
   Feick M., 2020, ADJ PUBL 33 ANN ACM, P68
   Freeman G., 2020, 2020 CHI C HUM FACT, DOI 10.1145/3334480.3382923
   Friedman D, 2006, PRESENCE-TELEOP VIRT, V15, P599, DOI 10.1162/pres.15.5.599
   Friston S, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489871
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Greenhalgh C, 2002, P IEEE VIRT REAL ANN, P101, DOI 10.1109/VR.2002.996512
   Jonas M, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P437, DOI 10.1145/3341215.3356271
   Juvrud J, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00305
   Kolesnichenko A, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P241, DOI 10.1145/3322276.3322352
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Latoschik ME, 2011, P IEEE VIRT REAL ANN, P171, DOI 10.1109/VR.2011.5759457
   Liu QX, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.668181
   Morozov M, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P199, DOI 10.1109/CW.2012.35
   Mottelson A, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139141
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Murgia A, 2008, IEEE ACM DIS SIM, P252, DOI 10.1109/DS-RT.2008.25
   Office Environment, 2017, 3D MOD OFF INT PACK
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Ponto K, 2012, IEEE T VIS COMPUT GR, V18, P607, DOI 10.1109/TVCG.2012.41
   Putze S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376144
   Puzzle Maker, 2013, JIGS PUZZL MAK 1 0 0
   Radiah R, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3472617
   Raij AB, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P91
   Ratcliffe J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445170
   Saffo David., 2021, P 2021 CHI C HUMAN F, DOI [10.1145/3411764.3445426, DOI 10.1145/3411764.3445426]
   Schroeder Ralph, 2010, Being There Together: Social interaction in shared virtual environments
   Schulz R., 2021, COMPREHENSIVE LIST S
   Singhal S., 1999, Networked Virtual Environments
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Steed A, 2010, NETWORKED GRAPHICS: BUILDING NETWORKED GAMES AND VIRTUAL ENVIRONMENTS, P1
   Steed A, 1999, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.1999.756941
   Steed A., 2020, Interactions, V27, P62, DOI DOI 10.1145/3406098
   Steed A, 2021, Arxiv, DOI arXiv:2104.05359
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Steptoe W, 2012, PRESENCE-TELEOP VIRT, V21, P388, DOI 10.1162/PRES_a_00123
   Tanenbaum T. J., 2020, CHI 20 P 2020 CHI C, P1
   Wang CY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376642
   Williams JK, 2022, PROTEINS, V90, P1044, DOI 10.1002/prot.26208
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
   Zhao JY, 2021, INT SYM MIX AUGMENT, P450, DOI 10.1109/ISMAR52148.2021.00062
NR 58
TC 8
Z9 8
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 14
PY 2022
VL 3
AR 912078
DI 10.3389/frvir.2022.912078
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VP8
UT WOS:001023262100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Reese, G
   Mehner, M
   Nelke, I
   Stahlberg, J
   Menzel, C
AF Reese, Gerhard
   Mehner, Marie
   Nelke, Insa
   Stahlberg, Jasmin
   Menzel, Claudia
TI Into the wild ... or not: Virtual nature experiences benefit well-being
   regardless of human-made structures in nature
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; well-being; restoration; vitality; urban nature; nature
ID STRESS RECOVERY; EXPOSURE; GREEN; RESTORATIVENESS; ENVIRONMENTS;
   SICKNESS; OUTDOORS; MOTION
AB Immersive nature experiences increase human well-being. There is now an increasing number of studies suggesting that virtual nature experiences-e.g., within a virtual reality (VR) environment-can evoke comparable benefits. In the current study using VR, we tested whether human-made structures within nature settings hinder such effects of virtual nature experience on well-being. To do so, 67 participants were led through a VR nature surrounding that was either wild and untouched by humans, or was characterized by few inconspicuous human structures (i.e., paths, buildings, walls, bridges). Before and after the intervention, we measured subjective vitality and after the intervention, we assessed perceived restorative outcome as two indicators of well-being. Results revealed that both virtual nature experiences improved participants' subjective vitality. Across both groups, participants reported relatively high-and similar-levels of restoration. These findings suggest that (virtual) nature experiences can be beneficial for well-being even when human-made structures interfere. Thus, irrespective of how pristine the environment is, the beneficial effects of immersive VR nature experiences provide opportunities for well-being when physical nature is inaccessible.
C1 [Reese, Gerhard; Mehner, Marie; Nelke, Insa; Stahlberg, Jasmin; Menzel, Claudia] Univ Koblenz Landau, Inst Psychol, Dept Social Environm & Econ Psychol, Mainz, Germany.
C3 University of Koblenz & Landau
RP Reese, G (corresponding author), Univ Koblenz Landau, Inst Psychol, Dept Social Environm & Econ Psychol, Mainz, Germany.
EM reese@uni-landau.de
OI Stahlberg, Jasmin/0000-0003-3975-7687; Menzel,
   Claudia/0000-0003-1156-5392
CR Allard-Poesi F, 2022, HEALTH PLACE, V74, DOI 10.1016/j.healthplace.2022.102759
   Alvarsson JJ, 2010, INT J ENV RES PUB HE, V7, P1036, DOI 10.3390/ijerph7031036
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Barrett J, 2004, NEUROPSYCHOPHARMACOL, V29, P1172, DOI 10.1038/sj.npp.1300411
   Becker DA, 2019, URBAN FOR URBAN GREE, V41, P39, DOI 10.1016/j.ufug.2019.02.012
   Berman MG, 2008, PSYCHOL SCI, V19, P1207, DOI 10.1111/j.1467-9280.2008.02225.x
   Bertrams A., 2020, Open Psychology, V2, P57, DOI DOI 10.1515/PSYCH-2020-0005
   Blythe J, 2021, PEOPLE NAT, V3, P1284, DOI 10.1002/pan3.10253
   Bratman GN, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aax0903
   Braun J, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00808
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Brown DK, 2013, ENVIRON SCI TECHNOL, V47, P5562, DOI 10.1021/es305019p
   Browning MHEM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02200
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Dunn ME, 2021, PEOPLE NAT, V3, P1205, DOI 10.1002/pan3.10273
   Dziuda L, 2014, APPL ERGON, V45, P406, DOI 10.1016/j.apergo.2013.05.003
   Egner LE, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17186792
   Ekkel ED, 2017, LANDSCAPE URBAN PLAN, V157, P214, DOI 10.1016/j.landurbplan.2016.06.008
   Franco LS, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14080864
   Frost S, 2022, J ENVIRON PSYCHOL, V80, DOI 10.1016/j.jenvp.2022.101765
   Gladwell VF, 2012, EUR J APPL PHYSIOL, V112, P3379, DOI 10.1007/s00421-012-2318-8
   Grad FP, 2002, B WORLD HEALTH ORGAN, V80, P981
   Han KT, 2018, J LEISURE RES, V49, P151, DOI 10.1080/00222216.2018.1505159
   Hartig T, 1997, SCAND HOUS PLAN RES, V14, P175, DOI 10.1080/02815739708730435
   Hartig T, 2014, ANNU REV PUBL HEALTH, V35, P207, DOI 10.1146/annurev-publhealth-032013-182443
   Hauru K, 2012, LANDSCAPE URBAN PLAN, V107, P361, DOI 10.1016/j.landurbplan.2012.07.002
   Hedblom M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46099-7
   Johnson JA, 2021, J ENVIRON PSYCHOL, V78, DOI 10.1016/j.jenvp.2021.101709
   Joye Y, 2011, URBAN FOR URBAN GREE, V10, P261, DOI 10.1016/j.ufug.2011.07.004
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kondo MC, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15030445
   Kondo MC, 2018, HEALTH PLACE, V51, P136, DOI 10.1016/j.healthplace.2018.03.001
   Korpela KM, 2008, HEALTH PLACE, V14, P636, DOI 10.1016/j.healthplace.2007.10.008
   Kuo FE, 2001, ENVIRON BEHAV, V33, P543, DOI 10.1177/00139160121973124
   Kuo M, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpg.2015.01093, 10.3389/fpsyg.2015.01093]
   Marselle MR, 2021, CURR ENV HLTH REP, V8, P146, DOI 10.1007/s40572-021-00313-9
   Mattila O, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106295
   McMahan EA, 2015, J POSIT PSYCHOL, V10, P507, DOI 10.1080/17439760.2014.994224
   Menardo E, 2021, PSYCHOL REP, V124, P417, DOI 10.1177/0033294119884063
   Menzel C, 2022, J ENVIRON PSYCHOL, V81, DOI 10.1016/j.jenvp.2022.101804
   Menzel C, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.591403
   Mygind L, 2021, ENVIRON BEHAV, V53, P184, DOI 10.1177/0013916519873376
   Mygind L, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00943
   Newman M, 2022, J ENVIRON PSYCHOL, V79, DOI 10.1016/j.jenvp.2021.101733
   Ohly H, 2016, J TOXICOL ENV HEAL B, V19, P305, DOI 10.1080/10937404.2016.1196155
   Plumptre AJ, 2021, FRONT FOR GLOB CHANG, V4, DOI 10.3389/ffgc.2021.626635
   Reese G, 2022, VIRTUAL REAL-LONDON, V26, P1245, DOI 10.1007/s10055-022-00631-9
   Reese G, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041995
   Ryan RM, 2010, J ENVIRON PSYCHOL, V30, P159, DOI 10.1016/j.jenvp.2009.10.009
   Ryan RM, 1997, J PERS, V65, P529, DOI 10.1111/j.1467-6494.1997.tb00326.x
   Scates D, 2020, ENVIRON BEHAV, V52, P895, DOI 10.1177/0013916520916259
   Shrestha T, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18042003
   Silk M, 2021, PEOPLE NAT, V3, P1130, DOI 10.1002/pan3.10284
   Staats H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146213
   Stevenson MP, 2018, J TOXICOL ENV HEAL B, V21, P227, DOI 10.1080/10937404.2018.1505571
   Tanja-Dijkstra K, 2018, ENVIRON BEHAV, V50, P599, DOI 10.1177/0013916517710077
   Twedt E, 2019, J ENVIRON PSYCHOL, V65, DOI 10.1016/j.jenvp.2019.101322
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   Valtchanov D., 2010, J Cyber Ther Rehabil, V3, P359
   Van den Berg AE, 2006, LANDSCAPE URBAN PLAN, V78, P362, DOI 10.1016/j.landurbplan.2005.11.006
   Weber AM, 2018, ENVIRON HEALTH INSIG, V12, DOI 10.1177/1178630218812805
   Wilkins A., 2018, J SUSTAINABLE DESIGN
   Yu CP, 2018, URBAN FOR URBAN GREE, V35, P106, DOI 10.1016/j.ufug.2018.08.013
NR 65
TC 3
Z9 3
U1 6
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 14
PY 2022
VL 3
AR 952073
DI 10.3389/frvir.2022.952073
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XE1
UT WOS:001023302700001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Steinhaeusser, SC
   Oberdörfer, S
   von Mammen, S
   Latoschik, ME
   Lugrin, B
AF Steinhaeusser, Sophia C.
   Oberdoerfer, Sebastian
   von Mammen, Sebastian
   Latoschik, Marc Erich
   Lugrin, Birgit
TI Joyful Adventures and Frightening Places-Designing Emotion-Inducing
   Virtual Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual environments; immersion; emotions; design
ID HORROR; DARKNESS; MOOD; RESPONSES; BEHAVIOR; STIMULI; REALITY; AROUSAL;
   REFLEX; COLOR
AB Virtual environments (VEs) can evoke and support emotions, as experienced when playing emotionally arousing games. We theoretically approach the design of fear and joy evoking VEs based on a literature review of empirical studies on virtual and real environments as well as video games' reviews and content analyses. We define the design space and identify central design elements that evoke specific positive and negative emotions. Based on that, we derive and present guidelines for emotion-inducing VE design with respect to design themes, colors and textures, and lighting configurations. To validate our guidelines in two user studies, we 1) expose participants to 360 & DEG; videos of VEs designed following the individual guidelines and 2) immerse them in a neutral, positive and negative emotion-inducing VEs combining all respective guidelines in Virtual Reality. The results support our theoretically derived guidelines by revealing significant differences in terms of fear and joy induction.
C1 [Steinhaeusser, Sophia C.; Oberdoerfer, Sebastian; von Mammen, Sebastian; Latoschik, Marc Erich; Lugrin, Birgit] Univ Wurzburg, Chair Human Comp Interact, Wurzburg, Germany.
C3 University of Wurzburg
RP Steinhaeusser, SC (corresponding author), Univ Wurzburg, Chair Human Comp Interact, Wurzburg, Germany.
EM sophia.steinhaeusser@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600
CR Adamgryu, 2019, SHORT HIK
   Adams E., 2014, Fundamentals of Game Design
   [Anonymous], 1993, Myst
   [Anonymous], 2009, RES EV 5
   [Anonymous], 2004, ADVENTURE GAMES LEAR
   [Anonymous], 1992, AL DARK
   [Anonymous], 1999, Silent hill
   [Anonymous], 2004, COSIGN 2004 P
   [Anonymous], 2001, SWEET HOM
   Atari, 1982, HAUNT HOUS
   Baecker R, 2015, HUM-COMPUT INT-SPRIN, P31, DOI 10.1007/978-1-4471-6744-0_5
   Baird R, 2000, FILM QUART, V53, P12, DOI 10.1525/fq.2000.53.3.04a00030
   Balaguero J., 2007, REC MOVIE
   BARON RA, 1992, MOTIV EMOTION, V16, P1, DOI 10.1007/BF00996485
   Bellizzi JosephA., 1992, PSYCHOL MARKET, V9, P347, DOI [10.1002/mar.4220090502, DOI 10.1002/MAR.4220090502]
   Berman P. S., 1945, PICTURE DORIAN GRAY
   Birbaumer N., 2010, BIOLOGISCHE PSYCHOLO
   Botkin D.B., 1997, Urban Ecosystems, V1, P3, DOI 10.1023/A:1014354923367
   Bradley MM, 2005, PSYCHOL SCI, V16, P468
   Calahan Sharon., 1999, Advanced RenderMan: Creating CGI for Motion Pictures, P337
   Capcom, 2005, RES EV 4
   Chan K. H., 2020, RISE IMPOSSIBLY CUTE
   Cho H, 2018, J ASSOC INF SCI TECH, V69, P633, DOI 10.1002/asi.23988
   Clark L.A., 1994, PANAS X MANUAL POSIT
   CLARK MS, 1984, J PERS SOC PSYCHOL, V46, P551, DOI 10.1037/0022-3514.46.3.551
   Dickey MD, 2006, ETR&D-EDUC TECH RES, V54, P245, DOI 10.1007/s11423-006-8806-y
   Dijkstra K, 2006, J ADV NURS, V56, P166, DOI 10.1111/j.1365-2648.2006.03990.x
   Dinis Susana, 2013, Design, User Experience, and Usability. User Experience in Novel Technological Environments. Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8014, P475, DOI 10.1007/978-3-642-39238-2_52
   Dreampainters, 2012, ANNA
   Edge, 2017, LEG ZELD BREATH WILD, P102
   Edge, 2020, AR SIMPL STOR EDG, P112
   Edge, 2018, MOSS POL DEB ADV LEN, P46
   Edge, 2016, ABZ EDG, P52
   Edge, 2017, LOST EMB EDG, P38
   EKMAN P, 1985, J PERS SOC PSYCHOL, V49, P1416, DOI 10.1037/0022-3514.49.5.1416
   El-Nasr M. S., 2006, P 2006 ACM SIGCHI IN, P63, DOI [10.1145/1178823.1178898, DOI 10.1145/1178823.1178898]
   Ellsworth P.C., 1988, Cognition and Emotion, V2, P301, DOI [DOI 10.1080/02699938808412702, 10.1080/02699938808412702]
   Endress SI, 2016, CHI PLAY 2016: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION, P149, DOI 10.1145/2968120.2987716
   Ewan Kirkland, 2011, IRISH J GOTHIC HORRO, V10
   FANSELOW MS, 1994, PSYCHON B REV, V1, P429, DOI 10.3758/BF03210947
   FrictionalGames, 2010, AMNESIA DARK DESCENT
   Gall D, 2020, COMPUT HUM BEHAV, V109, DOI 10.1016/j.chb.2020.106346
   Garner T., 2011, P 6 AUDIO MOSTLY C C, P31, DOI [10.1145/2095667.2095672, DOI 10.1145/2095667.2095672]
   Gerber W., 1986, SERENITY LIVING EQUA
   Gerling KM, 2013, PROCEEDINGS OF THE 17TH INTERNATIONAL ACADEMIC MINDTREK CONFERENCE, P229
   Giant Squid, 2016, ABZU
   Graf Linda, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P155, DOI 10.1145/3404983.3405507
   Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857
   Grillon C, 1997, BIOL PSYCHIAT, V42, P453, DOI 10.1016/S0006-3223(96)00466-0
   Grillon C, 1999, INT J PSYCHOPHYSIOL, V32, P63, DOI 10.1016/S0167-8760(99)00002-1
   Guillaume Roux-Girard, 2011, GAME SOUND TECHNOLOG, P192, DOI DOI 10.4018/978-1-61692-828-5.CH010
   Hamzeheinejad N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1421, DOI [10.1109/VR.2019.8797763, 10.1109/vr.2019.8797763]
   HTC Corporation, 2011, HTC VIVE
   idSoftware, 2004, DOOM 3
   JASP Team, 2021, JASP
   Jellicoe Z., 2010, IRJ GOTHIC HORROR ST, V11, P129
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jicol C., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1, DOI DOI 10.1145/3411764.3445588
   Jones CM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00260
   Karhulahti V.-M., 2011, INT J ARTS SOC ANN R, V6, P31, DOI [10.18848/1833-1866/cgp/v06i02/35926, DOI 10.18848/1833-1866/CGP/V06I02/35926]
   Kaya N., 2004, COLL STUD J, V38, P396
   Keating S, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P2046
   Kennedy A. J., 2014, THESIS PURDUE U
   Kern F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P500, DOI [10.1109/VR.2019.8797828, 10.1109/vr.2019.8797828]
   Kirkland E., 2010, IRJ GOTHIC HORROR ST, V8, P79
   Kirkland E., 2005, J MEDIA PRACTICE, V6, P167, DOI DOI 10.1386/JMPR.6.3.167/1
   Kirkland E, 2015, BRUMAL-RES J FANTAST, V3, P161, DOI 10.5565/rev/brumal.182
   Kirkland E, 2010, GAMES CULT, V5, P314, DOI 10.1177/1555412010364976
   Kirkland E, 2009, GAMES CULT, V4, P115, DOI 10.1177/1555412008325483
   Kirkland Ewan., 2007, Convergence: The International Journal of Research into New Media Technologies, V13, P403, DOI DOI 10.1177/1354856507081964
   KNEZ I, 1995, J ENVIRON PSYCHOL, V15, P39, DOI 10.1016/0272-4944(95)90013-6
   Knez I, 2008, CYBERPSYCHOL BEHAV, V11, P129, DOI 10.1089/cpb.2007.0006
   Kohlmaier S., 2014, SPIEL FILM
   Kohne J., 2008, HORROR STHETIK, P50
   Konami, 2004, SIL HILL 4 ROOM
   Kreitzer MJ, 2009, J HOLIST NURS, V27, P7, DOI 10.1177/0898010108327212
   Küller R, 2006, ERGONOMICS, V49, P1496, DOI 10.1080/00140130600858142
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Leitner F., 2017, MEDIENHORROR MEDIALE
   LimeSurvey GmbH, 2021, LIM
   Lin JHT, 2018, NEW MEDIA SOC, V20, P3223, DOI 10.1177/1461444817744850
   Lindsay S., 2009, IRJ GOTHIC HORROR ST, P82
   Liszio S., 2020, P INT DES CHILDR C J, DOI [10.1145/3392063.3394432, DOI 10.1145/3392063.3394432]
   LucasArts, 1990, MONK ISL
   Lucassen MP, 2011, COLOR RES APPL, V36, P426, DOI 10.1002/col.20647
   Lynch T, 2015, J BROADCAST ELECTRON, V59, P298, DOI 10.1080/08838151.2015.1029128
   MacKerron G, 2013, GLOBAL ENVIRON CHANG, V23, P992, DOI 10.1016/j.gloenvcha.2013.03.010
   McEachern M, 2010, COMPUT GRAPH WORLD, V33, P10
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Mitchell BriarLee., 2012, Game design essentials
   Mooneye Studios, 2019, LOST EMB
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mühlberger A, 2008, BIOL PSYCHOL, V77, P47, DOI 10.1016/j.biopsycho.2007.09.004
   Murphy E., 2008, IRJ GOTHIC HORROR ST, V5, P107
   Niedenthal S., 2009, HORROR VIDEO GAMES E, P168
   Niedenthal S., 2007, WORLDS PLAY
   Nintendo, 2017, The Legend of Zelda: Breath of the Wild
   Nittono Hiroshi., 2016, East Asian Journal of Popular Culture, V2, P79, DOI [10.1386/eapc.2.1.79_1, DOI 10.1386/EAPC.2.1.79_1]
   Oberdoerfer S, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.828553
   Oberdörfer S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.679277
   Pallavicini F, 2018, ADV INTELL SYST, V608, P225, DOI 10.1007/978-3-319-60639-2_23
   Peli Oren., 2007, Paranormal Activity
   Peng XL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376221
   Perron B., 2005, AESTHET PLAY
   Perron Bernard., 2012, SILENT HILL TERROR E
   Perry B.D., 2005, Centre for Children and families in the justice system, P1
   Perry David., 2009, David Perry on Game Design: A Brainstorming Toolbox
   Piccolo Studio S. L., 2019, ARISE SIMPLE STORY
   Pisanthanakun Banjong., 2004, SHUTTER
   Plass JL, 2014, LEARN INSTR, V29, P128, DOI 10.1016/j.learninstruc.2013.02.006
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Polyarc, 2018, MOSS
   Prohaszkova Viktoria., 2012, AM INT J CONT RES, V2, P132
   Pruett C., 2010, LOADING, P1
   Rautzenberg M., 2010, SEE IM REAL, P126
   RedCandleGames, 2019, DEV
   RemedyEntertainment, 2010, AL WAK
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rocke C., 2003, German translation of the PANAS-X
   Roohi S, 2019, ENTERTAIN COMPUT, V30, DOI 10.1016/j.entcom.2019.100298
   Rossi S, 2014, ACM-IEEE J CONF DIG, P475, DOI 10.1109/JCDL.2014.6970232
   Rupprecht CDD, 2015, LANDSCAPE URBAN PLAN, V143, P205, DOI 10.1016/j.landurbplan.2015.07.003
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schilling C., 2020, EDGE FUTURE INTERACT, P78
   Sierra Entertainment, 1983, KINGS QUEST QUEST CR
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Staats H, 1997, J ENVIRON PSYCHOL, V17, P283, DOI 10.1006/jevp.1997.0069
   Steinmetz KF, 2018, CRIME MEDIA CULT, V14, P265, DOI 10.1177/1741659017699045
   STRONGMAN KT, 1991, B PSYCHONOMIC SOC, V29, P195
   Tajeran M., 2012, FIGHT FLIGHT NEUROSC
   Toet A, 2009, CYBERPSYCHOL BEHAV, V12, P363, DOI 10.1089/cpb.2008.0293
   Ulrich R.S., 2001, DESIGN HLTH P 2 INT, P49
   Um E, 2012, J EDUC PSYCHOL, V104, P485, DOI 10.1037/a0026609
   Unity, 2021, UN 2020 1 10F1
   Vachiratamporn V, 2013, INT CONF AFFECT, P576, DOI 10.1109/ACII.2013.101
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Valve Coorperation, 2015, STEAMVR PLUG
   VivendiGames, 2005, FEAR 1 ENC ASS REC
   Watkins PC, 2018, J POSIT PSYCHOL, V13, P522, DOI 10.1080/17439760.2017.1414298
   Whalen Z., 2004, GAME STUD, V4
   Wilms L, 2018, PSYCHOL RES-PSYCH FO, V82, P896, DOI 10.1007/s00426-017-0880-8
   Windleharth TW, 2016, CAT CLASSIF Q, V54, P418, DOI 10.1080/01639374.2016.1190951
   Wolf M. J. P., 2011, MYST RIVEN WORLD DNI, DOI [10.2307/j.ctv65sx38, DOI 10.2307/J.CTV65SX38]
   Yin J, 2020, ENVIRON INT, V136, DOI 10.1016/j.envint.2019.105427
NR 148
TC 2
Z9 2
U1 4
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 26
PY 2022
VL 3
AR 919163
DI 10.3389/frvir.2022.919163
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8XA3
UT WOS:001019199900001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Kameoka, T
   Kajimoto, H
AF Kameoka, Takayuki
   Kajimoto, Hiroyuki
TI Design of Suction-Type Tactile Presentation Mechanism to Be Embedded in
   HMD
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE air pressure; FEM; HMD; suction haptics; virtual reality
ID PERCEPTION; PRESSURE; FEEDBACK; SKIN; HAND
AB To enrich the virtual reality experience and improve realism, many studies have proposed embedding tactile devices into head-mounted displays (HMDs). However, although thermal and vibrotactile cues have become commonplace, presentation of the constant pressure necessary for softness expression remains relatively rare. In this study, we propose a suction-type tactile presentation method that addresses this issue. Through subjective evaluation and simulation using the finite element method, we verified that the proposed suction-type tactile presentation method is suitable for use with HMDs and that by increasing the number and density of the suction holes, a stronger tactile sensation can be created.
C1 [Kameoka, Takayuki; Kajimoto, Hiroyuki] Univ Electrocommun, Dept Informat, Chofu, Japan.
   [Kameoka, Takayuki] Japan Soc Promot Sci, Tokyo, Japan.
C3 University of Electro-Communications - Japan; Japan Society for the
   Promotion of Science
RP Kameoka, T (corresponding author), Univ Electrocommun, Dept Informat, Chofu, Japan.; Kameoka, T (corresponding author), Japan Soc Promot Sci, Tokyo, Japan.
EM kameoka@kaji-lab.jp
OI Kameoka, Takayuki/0000-0001-9897-4433
FU JSPS KAKENHI [JP20K20627, JP20J23626]
FX Funding This research was supported by JSPS KAKENHI, Grant Numbers
   JP20K20627 and JP20J23626.
CR Antfolk C, 2012, J REHABIL MED, V44, P702, DOI 10.2340/16501977-1001
   Arai F, 2001, IEEE INT CONF ROBOT, P2486, DOI 10.1109/ROBOT.2001.932996
   Ben Porquis L, 2014, IEEE HAPTICS SYM, P289, DOI 10.1109/HAPTICS.2014.6775469
   Ben Porquis L, 2013, IEEE INT C INT ROBOT, P2023, DOI 10.1109/IROS.2013.6696626
   Ben Porquis L, 2011, IEEE INT C INT ROBOT, P3488, DOI 10.1109/IROS.2011.6048370
   Chang HY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P927, DOI 10.1145/3242587.3242588
   Chopra K, 2015, AESTHET SURG J, V35, P1007, DOI 10.1093/asj/sjv079
   Hachisu T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P411, DOI 10.1145/2556288.2557252
   Hwang I, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P213, DOI 10.1109/WHC.2017.7989903
   Ichinose A, 2017, NEUROREHAB NEURAL RE, V31, P717, DOI 10.1177/1545968317718268
   Jun JH, 2015, SCI REP-UK, V5, DOI 10.1038/srep11016
   Kameoka T, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P949, DOI 10.1109/WHC49131.2021.9517176
   Kameoka T, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P11, DOI 10.1145/3267782.3267789
   Kim SY, 2022, J AMB INTEL HUM COMP, V13, P1665, DOI 10.1007/s12652-019-01408-w
   Kim SB, 2014, J ACUPUNCT MERIDIAN, V7, P306, DOI 10.1016/j.jams.2013.09.004
   Kon Y., 2017, In proceedings of the ACM SIGGRAPH 2017 emerging Technologies, P1, DOI [10.1145/3084822.3084842, DOI 10.1145/3084822.3084842]
   Kyung KU, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P96
   Maemori D, 2014, LECT NOTES COMPUT SC, V8619, P285, DOI 10.1007/978-3-662-44196-1_35
   Maeno T, 1998, JSME INT J C-MECH SY, V41, P94, DOI 10.1299/jsmec.41.94
   Maisto M, 2017, IEEE T HAPTICS, V10, P511, DOI 10.1109/TOH.2017.2691328
   Makino Y, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P2931
   Makino Y, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P90, DOI 10.1109/HAPTIC.2004.1287182
   Makino Y., 2005, PROC SICE ANN C, P1285
   Moriyama T., 2019, SIGGRAPH ASIA 2019 E, P42, DOI [10.1145/3355049.3360532, DOI 10.1145/3355049.3360532]
   Moriyama T, 2018, SA'18: SIGGRAPH ASIA 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3275476.3275488
   Nagano H, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P389, DOI [10.1109/whc.2019.8816156, 10.1109/WHC.2019.8816156]
   Okano T, 2018, LECT NOTES ELECTR EN, V432, P175, DOI 10.1007/978-981-10-4157-0_30
   Peiris RL, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5452, DOI 10.1145/3025453.3025824
   Penfield W., 1950, The cerebral cortex of man
   Porquis L. B. C., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P393, DOI 10.1109/HAPTIC.2012.6183820
   Ramachandran VS, 1998, BRAIN, V121, P1603, DOI 10.1093/brain/121.9.1603
   Saal HP, 2017, P NATL ACAD SCI USA, V114, pE5693, DOI 10.1073/pnas.1704856114
   Saito K, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P265, DOI [10.1109/whc.2019.8816161, 10.1109/WHC.2019.8816161]
   Schoepp KR, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2866105
   Shen VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501960
   Shi G, 2020, IEEE T HAPTICS, V13, P204, DOI 10.1109/TOH.2020.2970056
   Wang C, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P439, DOI 10.1145/3332165.3347898
   Wolf D, 2019, IEEE T VIS COMPUT GR, V25, P3169, DOI 10.1109/TVCG.2019.2932215
   Yamaoka M, 2008, LECT NOTES COMPUT SC, V5024, P427, DOI 10.1007/978-3-540-69057-3_56
NR 39
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 17
PY 2022
VL 3
AR 894873
DI 10.3389/frvir.2022.894873
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZO2
UT WOS:001019266800001
OA gold
DA 2024-07-18
ER

PT J
AU Hartmann, T
   Hofer, M
AF Hartmann, Tilo
   Hofer, Matthias
TI I Know It Is Not Real (And That Matters) Media Awareness vs. Presence in
   a Parallel Processing Account of the VR Experience
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE media awareness; presence; perceptual sensation; representation;
   pictorial competence; parallel processing; virtual reality
ID DUAL-PROCESS THEORIES; VIRTUAL ENVIRONMENTS; PERCEIVED REALISM; SPATIAL
   PRESENCE; EYE CONTACT; MODEL; RECEPTION; ENTERTAINMENT; PSYCHOLOGY;
   FRAMEWORK
AB Inspired by the widely recognized idea that in VR/XR, not only presence but also encountered plausibility is relevant (Slater, Phil. Trans. R. Soc. B, 2009, 364 (1535), 3549-3557), we propose a general psychological parallel processing account to explain users' VR and XR experience. The model adopts a broad psychological view by building on interdisciplinary literature on the dualistic nature of perceiving and experiencing (mediated) representations. It proposes that perceptual sensations like presence are paralleled by users' belief that "this is not really happening," which we refer to as media awareness. We review the developmental underpinnings of basic media awareness, and argue that it is triggered in users' conscious exposure to VR/XR. During exposure, the salience of media awareness can vary dynamically due to factors like encountered sensory and semantic (in)consistencies. Our account sketches media awareness and presence as two parallel processes that together define a situation as a media exposure situation. We also review potential joint effects on subsequent psychological and behavioral responses that characterize the user experience in VR/XR. We conclude the article with a programmatic outlook on testable assumptions and open questions for future research.
C1 [Hartmann, Tilo] Vrije Univ Amsterdam VU, Dept Commun Sci, Amsterdam, Netherlands.
   [Hofer, Matthias] Univ Zurich, Fac Arts & Social Sci, Dept Commun & Media Res, Zurich, Switzerland.
C3 Vrije Universiteit Amsterdam; University of Zurich
RP Hartmann, T (corresponding author), Vrije Univ Amsterdam VU, Dept Commun Sci, Amsterdam, Netherlands.
EM t.hartmann@vu.nl
RI Hartmann, Tilo/B-7084-2011
OI Hartmann, Tilo/0000-0002-1862-7595
CR Abraham A, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004741
   Ahn S.J., 2012, Leadership in science and technology: A reference handbook, V2, P695
   Andrade EB, 2007, J CONSUM RES, V34, P283, DOI 10.1086/519498
   [Anonymous], 2001, WHAT IS PRES
   Berthiaume M, 2018, PRESENCE-VIRTUAL AUG, V27, P378, DOI [10.1162/PRES_a_00336, 10.1162/pres_a_00336]
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Biocca F., 2006, Journal of Computer-Mediated Communication., V3, DOI DOI 10.1111/J.1083-6101.1997.TB00070.X
   Blankendaal R, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P553
   Busselle R, 2008, COMMUN THEOR, V18, P255, DOI 10.1111/j.1468-2885.2008.00322.x
   Camos V, 2018, ANN NY ACAD SCI, V1424, P19, DOI 10.1111/nyas.13616
   CANTOR J, 1988, CURR PSYCHOL RES REV, V7, P58, DOI 10.1007/BF02686664
   Cowan N, 2017, PSYCHON B REV, V24, P1158, DOI 10.3758/s13423-016-1191-6
   Cupchik GC, 2001, MEDIA PSYCHOL, V3, P69, DOI 10.1207/S1532785XMEP0301_04
   de Gelder B, 2018, BRIT J PSYCHOL, V109, P421, DOI 10.1111/bjop.12308
   DeLoache JS, 2003, CURR DIR PSYCHOL SCI, V12, P114, DOI 10.1111/1467-8721.01244
   DeLoache JS, 2010, PSYCHOL SCI, V21, P1570, DOI 10.1177/0956797610384145
   Dokic J, 2017, TOPOI-INT REV PHILOS, V36, P299, DOI 10.1007/s11245-015-9327-2
   Evans JSBT, 2007, THINK REASONING, V13, P321, DOI 10.1080/13546780601008825
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   FLAVELL JH, 1983, COGNITIVE PSYCHOL, V15, P95, DOI 10.1016/0010-0285(83)90005-1
   Flavell JH, 2000, INT J BEHAV DEV, V24, P15, DOI 10.1080/016502500383421
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Frey F, 2018, COMMUN THEOR, V28, P487, DOI 10.1093/ct/qty010
   Gallup AC, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36570-2
   Gawronski B., 2014, Dual process theories of the social mind, P188
   Gawronski B, 2011, ADV EXP SOC PSYCHOL, V44, P59, DOI 10.1016/B978-0-12-385522-0.00002-0
   Gendler T., 2019, CONT EPISTEMOLOGY, P91, DOI DOI 10.1002/9781119420828.CH7
   Gendler TS, 2008, J PHILOS, V105, P634, DOI 10.5840/jphil20081051025
   GILBERT DT, 1993, J PERS SOC PSYCHOL, V65, P221, DOI 10.1037/0022-3514.65.2.221
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Grodal T., 2006, Film Studies, V8, P1, DOI DOI 10.7227/FS.8.3
   Grodal T., 2002, Realism and 'reality'in film and media, P67
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Hall A, 2003, J COMMUN, V53, P624, DOI 10.1093/joc/53.4.624
   Hartman Tilo., 2015, IMMERSED MEDIA TELEP, P115, DOI [DOI 10.1007/978-3-319-10190-3_7, 10.1007/978-3-319-10190-3_7]
   Hartmann T., 2017, GAME STUD, V17
   Hartmann T., 2011, Vice city virtue: Moral issues in digital game play, P135
   Herschbach M, 2015, CONSCIOUS COGN, V36, P483, DOI 10.1016/j.concog.2015.04.001
   Hofer M., 2016, INVOLVEMENT PRESENCE
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI [10.3389/frvir.2020.00002, DOI 10.3389/FRVIR.2020.00002]
   Hofer M, 2015, J MEDIA PSYCHOL-GER, V27, P47, DOI 10.1027/1864-1105/a000134
   Jacobs C, 2015, NEUROSCI BIOBEHAV R, V55, P510, DOI 10.1016/j.neubiorev.2015.06.003
   Kahneman D., 2002, HEURISTICS BIASES PS, P49, DOI DOI 10.1017/CBO9780511808098
   Kahneman D, 2015, FORTUNE, V172, P20
   Koblizek Tomas., 2017, AESTHETIC ILLUSION L
   Krcmar M, 2019, J MEDIA PSYCHOL-GER, V31, P2, DOI 10.1027/1864-1105/a000215
   Latoschik ME, 2022, Arxiv, DOI arXiv:2104.04846
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Merfeld DM, 2016, J NEUROPHYSIOL, V115, P39, DOI 10.1152/jn.00225.2015
   Michelle C, 2007, COMMUN REV, V10, P181, DOI 10.1080/10714420701528057
   Nanay B, 2005, BRIT J AESTHET, V45, P248, DOI 10.1093/aesthj/ayi034
   Nieding G, 2017, MEDIA PSYCHOL, V20, P401, DOI 10.1080/15213269.2016.1202773
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pönkänen LM, 2011, SOC COGN AFFECT NEUR, V6, P486, DOI 10.1093/scan/nsq068
   Popova L., 2010, Perceived reality of media messages: Concept explication and testing
   Quaglia JT, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR.2018.8446546
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Risko EF, 2016, CURR DIR PSYCHOL SCI, V25, P70, DOI 10.1177/0963721415617806
   Ross M, 2015, 3D CINEMA: OPTICAL ILLUSIONS AND TACTILE EXPERIENCES, P1, DOI 10.1057/9781137378576
   Rozin P, 2013, JUDGM DECIS MAK, V8, P439
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   Schlottmann A, 2001, CHILD DEV, V72, P103, DOI 10.1111/1467-8624.00268
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Senju A, 2009, TRENDS COGN SCI, V13, P127, DOI 10.1016/j.tics.2008.11.009
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Shapiro MA, 2012, MEDIA PSYCHOL, V15, P93, DOI 10.1080/15213269.2011.649666
   Skarbez R, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281530
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Skarbez Richard T, 2016, PhD thesis
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sloman SA, 1996, PSYCHOL BULL, V119, P3, DOI 10.1037/0033-2909.119.1.3
   Smith ER, 2000, PERS SOC PSYCHOL REV, V4, P108, DOI 10.1207/S15327957PSPR0402_01
   Suckfüll M, 2009, COMMUNICATIONS-GER, V34, P361, DOI 10.1515/COMM.2009.023
   Timmins LR, 2005, PRESENCE-TELEOP VIRT, V14, P492, DOI 10.1162/105474605774785307
   Turner P, 2016, AI SOC, V31, P147, DOI 10.1007/s00146-014-0579-y
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124
   Vorderer P, 2001, POETICS, V29, P247, DOI 10.1016/S0304-422X(01)00037-7
   Vorderer P., 2021, The Oxford handbook of entertainment theory, DOI [10.1093/oxfordhb/9780190072216.013.37, DOI 10.1093/OXFORDHB/9780190072216.013.37]
   Waal NEV, 2021, FOOD QUAL PREFER, V90, DOI 10.1016/j.foodqual.2020.104167
   Waterworth J., 2021, PSYARXIV, P1, DOI [10.31234/osf.io/qbcfe, DOI 10.31234/OSF.IO/QBCFE]
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Wolf W., 2014, LIVING HDB NARRATOLO, DOI [10.1515/9783110316469.270, DOI 10.1515/9783110316469.270]
   Wolf W., 2017, AESTHETIC ILLUSION L
   Wollheim R, 1998, J AESTHET ART CRITIC, V56, P217, DOI 10.2307/432361
   Zeimbekis J., 2015, COGNITIVE PENETRABIL, P298, DOI DOI 10.1093/ACPROF:OSO/9780198738916.003.0013
NR 90
TC 8
Z9 8
U1 3
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 28
PY 2022
VL 3
AR 694048
DI 10.3389/frvir.2022.694048
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YU9
UT WOS:001019247400001
OA gold, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Carnell, S
   De Siqueira, AG
   Miles, A
   Lok, B
AF Carnell, Stephanie
   De Siqueira, Alexandre Gomes
   Miles, Anna
   Lok, Benjamin
TI Informing and Evaluating Educational Applications With the Kirkpatrick
   Model in Virtual Environments: Using a Virtual Human Scenario to Measure
   Communication Skills Behavior Change
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; educational technology; communication skills;
   kirkpatrick model; virtual humans; virtual patients
ID MEDICAL-STUDENTS; REALITY; HEALTH; SIMULATION; CLASSIFICATION;
   ELDERSPEAK; LITERACY; EMPATHY
AB Increasingly, virtual environments are being used in educational and training applications. As with other types of applications that use virtual environments, these scenarios must be evaluated in terms of user experience. However, they also should be evaluated on the efficacy of the training or learning provided, so as to ensure learning transfer. Frameworks, such as the Kirkpatrick Model, exist to evaluate training scenarios, but application of these frameworks has not been fully utilized in development of virtual environment-based education and training. To address this gap and to also share our process with other virtual environment developers, we discuss our experience applying the Kirkpatrick Model to an existing virtual human (VH) application for medical communication skills training. The Kirkpatrick Model provides different levels of evaluation for training programs that include learners' reactions to the training, the knowledge acquired from the training, behaviors indicating the training was applied, and the degree high-level results were impacted as a result of the training. While we discuss all of the Model's levels, our focus for this work is Level 3 Behavior. The Kirkpatrick Model currently recommends that behavioral change may only be measured while a trainee is working in a real-world context. However, given existing evidence that VH applications have been shown to elicit real-world behaviors from participants, we suggest that VH training scenarios may be a method of measuring Behavior level metrics before trainees are evaluated in situ. Initial support for this suggestion is provided by our study examining whether VHs can elicit changes in communication skills learners' message production behavior over time. This study indicates that learners displayed changes in several metrics over the course of the semester. Based on this finding, we suggest a direction for future research: observing learner behavior in a virtual environment as a pre-cursor to behavioral measures while in a real-world scenario.
C1 [Carnell, Stephanie] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
   [De Siqueira, Alexandre Gomes; Lok, Benjamin] Univ Florida, Dept Comp & Informat Sci & Engn, Orlando, FL USA.
   [Miles, Anna] Univ Auckland, Speech Sci, Auckland, New Zealand.
C3 State University System of Florida; University of Central Florida; State
   University System of Florida; University of Florida; University of
   Auckland
RP Carnell, S (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
EM stephaniecarnell@gmail.com
OI Miles, Anna/0000-0003-3260-5824; Lok, Benjamin/0000-0002-1190-3729;
   Gomes de Siqueira, Alexandre/0000-0002-9213-9602
CR Agarwal N, 2013, JAMA INTERN MED, V173, P1257, DOI 10.1001/jamainternmed.2013.6060
   Alaraj Ali, 2011, Surg Neurol Int, V2, P52, DOI 10.4103/2152-7806.80117
   Alliger GM, 1997, PERS PSYCHOL, V50, P341, DOI 10.1111/j.1744-6570.1997.tb00911.x
   Asha A. S.-L.-H. A., 2020, PROFILE ASHA MEMBERS
   Bassi LJ., 1996, Trends: Position yourself for the future
   Beal MD, 2017, SIMUL HEALTHC, V12, P104, DOI 10.1097/SIH.0000000000000189
   Berger CR, 2003, LEA COMMUN SER, P257
   Bird S., 2009, NATURAL LANGUAGE PRO
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   BRADSHAW PW, 1975, BRIT J SOC CLIN PSYC, V14, P55, DOI 10.1111/j.2044-8260.1975.tb00149.x
   Brogden HE, 1950, EDUC PSYCHOL MEAS, V10, P159, DOI 10.1177/001316445001000201
   Cassell J., 2009, P 2009 INT C MULTIMO, P135, DOI DOI 10.1145/1647314.1647338
   Cincinnati Childrens, 2021, SPEECH LANG PATH GLO
   Cohen D, 2013, RESUSCITATION, V84, P78, DOI 10.1016/j.resuscitation.2012.05.014
   Delisle M, 2019, SIMUL HEALTHC, V14, P318, DOI 10.1097/SIH.0000000000000377
   DiMatteo M Robin, 2004, JAAPA, V17, P18
   Dukes LC, 2013, P 2013 INT C INT US, P395, DOI DOI 10.1145/2449396.2449447
   Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532
   Flesch Rudolf, 1949, The art of readable writing, V8
   Foster A, 2016, SIMUL HEALTHC, V11, P181, DOI 10.1097/SIH.0000000000000142
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Gordon D, 1996, CAN MED ASSOC J, V155, P1152
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Graham Suzanne, 2008, Perm J, V12, P67
   Green JA, 2014, PATIENT EDUC COUNS, V95, P76, DOI 10.1016/j.pec.2014.01.004
   Greene J., 1993, COMMUN THEOR, V3, P26
   Halan S., 2018, P 17 INT C AUT AG MU
   Halan S, 2015, LECT NOTES ARTIF INT, V9238, P239, DOI 10.1007/978-3-319-21996-7_24
   Kemper S, 1994, AGING NEUROPSYCHOL C, V1, P17, DOI DOI 10.1080/09289919408251447
   Kidd LI, 2012, J PSYCHOSOC NURS MEN, V50, P28, DOI 10.3928/02793695-20120605-04
   Kirkpatrick D. L., 1954, Evaluating human relations programs for industrial foremen and supervisors
   Kirkpatrick DL, 1970, Evaluation of Training
   Kirkpatrick J. D., 2016, Kirkpatricks Four Levels of Training Evaluation
   Kleinsmith A, 2015, COMPUT HUM BEHAV, V52, P151, DOI 10.1016/j.chb.2015.05.033
   Kundhal PS, 2009, SURG ENDOSC, V23, P645, DOI 10.1007/s00464-008-0043-5
   Lei L, 2016, J ENGL ACAD PURP, V22, P42, DOI 10.1016/j.jeap.2016.01.008
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Loukas C, 2011, SIMUL HEALTHC, V6, P213, DOI 10.1097/SIH.0b013e31821d08a9
   Martin Leslie R, 2005, Ther Clin Risk Manag, V1, P189
   Morphis M, 2002, INTERNETWEEK, P31
   Oates DJ, 2009, CIRCULATION, V119, P1049, DOI 10.1161/CIRCULATIONAHA.108.818468
   Raij A, 2006, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VR.2006.91
   Rossen B. H., 2011, THESIS U FLORIDA GAI
   Schmidt B, 2009, NURS EDUC, V34, P152, DOI 10.1097/NNE.0b013e3181aabbe8
   Shaw A, 2009, PATIENT EDUC COUNS, V75, P114, DOI 10.1016/j.pec.2008.09.026
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Speer M., 2015, COMMUNICATING PEDIAT, P221
   Suárez G, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.658561
   Unger Layla., 2010, SOCIAL ROLE LINGUIST
   Üstün TB, 2003, DISABIL REHABIL, V25, P565, DOI 10.1080/0963828031000137063
   Van Wyk E., 2009, P 6 INT C COMP GRAPH, P53, DOI DOI 10.1145/1503454.1503465
   Waisman Y, 2003, ISRAEL MED ASSOC J, V5, P567
   Williams KN, 2009, AM J ALZHEIMERS DIS, V24, P11, DOI 10.1177/1533317508318472
   Williamson JML, 2010, INT J CLIN PRACT, V64, P1824, DOI 10.1111/j.1742-1241.2010.02408.x
   Wouda JC, 2013, PAEDIATR RESPIR REV, V14, P213, DOI 10.1016/j.prrv.2013.04.005
   Wouda JC, 2012, PATIENT EDUC COUNS, V86, P57, DOI 10.1016/j.pec.2011.03.011
   Wouda JC, 2011, PATIENT EDUC COUNS, V85, P92, DOI 10.1016/j.pec.2010.09.007
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Zaveri P. P., 2016, CUREUS J MED SCIENCE
NR 59
TC 2
Z9 2
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 14
PY 2022
VL 3
AR 810797
DI 10.3389/frvir.2022.810797
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AV0
UT WOS:001019299800001
OA gold
DA 2024-07-18
ER

PT J
AU Teixeira, J
   Miellet, S
   Palmisano, S
AF Teixeira, Joel
   Miellet, Sebastien
   Palmisano, Stephen
TI Unexpected Vection Exacerbates Cybersickness During HMD-Based Virtual
   Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cybersickness; motion sickness; virtual reality; head-mounted display
   (HMD); vection
ID INDUCED MOTION SICKNESS; OPTOKINETIC NYSTAGMUS; SIMULATORS; SYMPTOMS;
   DRIVER; CUES
AB Visually induced illusions of self-motion (vection) are thought to cause cybersickness during head-mounted display based virtual reality (HMD VR). However, the empirical support for this widespread belief is rather mixed. Our exploratory study examined the possibility that only unexpected experiences of vection provoke cybersickness. Fifteen males and 15 females played an HMD VR game (Mission: ISS) for up to 14 min with: 1) their experiences of vection and cybersickness assessed every 2 minutes; and 2) the game being terminated whenever they reported feeling sick. Of the 30 participants tested, 17 reported feeling sick and 13 remained well. Sick and well participants did not differ in terms of the strength of their vection experiences. However, the sick participants were significantly more likely to report unexpected/uncontrolled vection. When these data were subjected to machine learning analysis, unexpected vection was found to be the most important predictor of cybersickness. These preliminary findings suggest that vection can be used to safely enhance experiences in HMD VR-as long as developers ensure that any simulated self-motions are expected and perceived to be under the user's control.
C1 [Teixeira, Joel; Miellet, Sebastien; Palmisano, Stephen] Univ Wollongong, Sch Psychol, Wollongong, NSW, Australia.
C3 University of Wollongong
RP Palmisano, S (corresponding author), Univ Wollongong, Sch Psychol, Wollongong, NSW, Australia.
EM stephenp@uow.edu.au
RI Miellet, Sebastien/AFL-6215-2022; Palmisano, Stephen/O-1553-2018
OI Miellet, Sebastien/0000-0002-3519-033X; Teixeira,
   Joel/0009-0003-9154-044X; Palmisano, Stephen/0000-0002-9140-5681
FU Australian Research Council (ARC) Discovery Project [DP210101475]
FX Funding This research was supported by an Australian Research Council
   (ARC) Discovery Project (DP210101475) to SP.
CR ANDERSEN GJ, 1985, J EXP PSYCHOL HUMAN, V11, P122, DOI 10.1037/0096-1523.11.2.122
   [Anonymous], 1975, Motion sickness
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bonato F, 2005, AVIAT SPACE ENVIR MD, V76, P823
   Bonato F, 2004, AVIAT SPACE ENVIR MD, V75, P306
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Brysbaert Marc, 2018, J Cogn, V1, P9, DOI 10.5334/joc.10
   Burns JA, 2017, OTOLARYNG CLIN N AM, V50, P903, DOI 10.1016/j.otc.2017.05.003
   Chang CH, 2021, HUM MOVEMENT SCI, V78, DOI 10.1016/j.humov.2021.102832
   Chang CH, 2021, EXP BRAIN RES, V239, P491, DOI 10.1007/s00221-020-05940-6
   Chang CH, 2012, EXP BRAIN RES, V217, P299, DOI 10.1007/s00221-011-2993-4
   Chen DJZ, 2011, I-PERCEPTION, V2, P415
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Feenstra PJ, 2011, DISPLAYS, V32, P194, DOI 10.1016/j.displa.2010.11.002
   Flanagan MB, 2002, AVIAT SPACE ENVIR MD, V73, P1067
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Griffin MJ, 2004, AVIAT SPACE ENVIR MD, V75, P739
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Ji JTT, 2009, HUM FACTORS, V51, P739, DOI 10.1177/0018720809349708
   Judd CM, 2017, ANNU REV PSYCHOL, V68, P601, DOI 10.1146/annurev-psych-122414-033702
   Kennedy R. S., 1994, AGARD CP VIRTUAL INT, V5412, P1
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2014, EXP BRAIN RES, V232, P827, DOI 10.1007/s00221-013-3793-9
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kuiper OX, 2020, HUM FACTORS, V62, P1339, DOI 10.1177/0018720819876139
   Kuiper OX, 2019, DISPLAYS, V58, P82, DOI 10.1016/j.displa.2018.10.001
   Lawson B D, 2005, P 11 INT C HUM COMP, P1
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lee AY, 2017, OTOLARYNG CLIN N AM, V50, P893, DOI 10.1016/j.otc.2017.05.002
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Miller ML, 2020, BMC MED RES METHODOL, V20, DOI 10.1186/s12874-020-00936-w
   Nooij SAE, 2018, EXP BRAIN RES, V236, P3031, DOI 10.1007/s00221-018-5340-1
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Palmisano S, 2004, PERCEPTION, V33, P987, DOI 10.1068/p5242
   Palmisano S, 2007, AVIAT SPACE ENVIR MD, V78, P951, DOI 10.3357/ASEM.2079.2007
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Perrin P, 2013, AVIAT SPACE ENVIR MD, V84, P473, DOI 10.3357/ASEM.3523.2013
   Pfandler M, 2017, SPINE J, V17, P1352, DOI 10.1016/j.spinee.2017.05.016
   Pöhlmann KMT, 2021, MULTISENS RES, V34, P623, DOI 10.1163/22134808-bja10049
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   ROLNICK A, 1991, ERGONOMICS, V34, P867, DOI 10.1080/00140139108964831
   Seay A.F., 2002, CHI 02 EXTENDED ABST, P784, DOI DOI 10.1145/506443.506596
   Seno T, 2017, I-PERCEPTION, V8, DOI [10.1177/2041669518774069, 10.1177/2041669517742176]
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P447, DOI 10.1162/105474698565848
   STOFFREGEN T A, 1991, Ecological Psychology, V3, P159, DOI 10.1207/s15326969eco0303_1
   Stoffregen TA, 2001, BEHAV BRAIN SCI, V24, P195, DOI 10.1017/S0140525X01003946
   Stoffregen TA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187120
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Turner M, 1999, ERGONOMICS, V42, P1646, DOI 10.1080/001401399184730
   Wada T, 2018, INT J IND ERGONOM, V63, P89, DOI 10.1016/j.ergon.2016.11.003
   Webb NA, 2003, AVIAT SPACE ENVIR MD, V74, P622
   Webb NA, 2002, AVIAT SPACE ENVIR MD, V73, P351
   Xiang Liu, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P416, DOI 10.1007/978-3-319-39907-2_40
NR 72
TC 4
Z9 4
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 13
PY 2022
VL 3
AR 860919
DI 10.3389/frvir.2022.860919
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OQ4
UT WOS:001021707900001
OA gold
DA 2024-07-18
ER

PT J
AU Peterson, BN
   Hitching, R
   Howard, L
   Zhu, KTY
   Fontenot, MR
   Alhalabi, W
   Seibel, A
   Harris, OA
   Madrigal, E
   Adamson, MM
   Hoffman, HG
AF Peterson, Barry N.
   Hitching, Rita
   Howard, Lisa
   Zhu, Kaitlly
   Fontenot, Miles R.
   Alhalabi, Wadee
   Seibel, Asher
   Harris, Odette A.
   Madrigal, Esmeralda
   Adamson, Maheen Mausoof
   Hoffman, Hunter G.
TI Immersive Virtual Reality: A Safe, Scalable, Non-opioid Analgesic for
   Military and Veteran Patients
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; opioids; analgesia; chronic pain; military; veterans
ID POSTTRAUMATIC-STRESS-DISORDER; REGIONAL PAIN SYNDROME; GRADED MOTOR
   IMAGERY; BURN WOUND CARE; EXPOSURE THERAPY; CORTICAL REORGANIZATION;
   MIRROR THERAPY; MINDFULNESS MEDITATION; PROCEDURAL PAIN; D-CYCLOSERINE
AB In Iraq and Afghanistan over 75% of the combat casualties suffered by U.S. troops have involved explosive devices. Improvements in body armor and advances in military medicine have significantly reduced the number of combat-related fatalities, but have greatly increased the number of U.S. active component personnel suffering painful trauma injuries. Unfortunately, so far, advances in pharmacologic analgesia pain medications have not kept pace with advances in survivability. For many active component personnel and Veterans, pain is a top health complaint from patients. The opioid epidemic has increased the urgency of developing powerful non-pharmacologic approaches for the management of pain. Immersive VR is proving to be a powerful non-opioid pain management technique for acute pain. However, the cost and usability limitations of pre-2016 VR clinical products resulted in limited treatment adoption rates for clinical use. In recent years, VR technology has become increasingly immersive, portable, and miniaturized, requiring minimal technical expertise to operate, and low-cost, factors that are likely contributing to the recent increase in the clinical use of VR analgesia. VR is greatly benefitting from a growing string of major technological breakthroughs and VR treatment improvements that will likely continue to increase the effectiveness and suitability of VR analgesia for military and VA patients. Regarding acute pain, we propose that the next revision to the current Tactical Combat Casualty Care guidelines consider including VR as an effective and hemodynamically safe approach to the current management of acute trauma pain in military personnel during medical procedures. With recent miniaturization and ruggedization, VR can potentially be used closer to the battlefield in the future. Beyond distraction, innovative VR therapy techniques designed to help reduce chronic pain are discussed. Recent breakthroughs in the mass production of inexpensive, highly immersive lightweight stand alone VR systems and augmented reality systems increase the potential for widespread dissemination of VR analgesia for acute and potentially for chronic pain. For example, the U.S. military recently purchased 22 billion dollar's worth of Microsoft Hololens mixed reality systems (e.g., for training). Expanded research and development of VR analgesia customized for the unique needs of military and VA patients is recommended.
C1 [Peterson, Barry N.] Dept Vet Affairs, Reno, NV USA.
   [Hitching, Rita; Zhu, Kaitlly] Palo Alto Inst Res, Palo Alto, CA USA.
   [Howard, Lisa] VA Palo Alto Hlth Care Syst, Palo Alto, CA USA.
   [Fontenot, Miles R.] Univ Washington, Anesthesia & Pain Med, Sch Med, Seattle, WA USA.
   [Alhalabi, Wadee; Hoffman, Hunter G.] King Abdulaziz Univ, Dept Comp Sci, Jeddah, Saudi Arabia.
   [Seibel, Asher; Hoffman, Hunter G.] Univ Washington, Dept Mech Engn HPL, Seattle, WA 98195 USA.
   [Harris, Odette A.; Madrigal, Esmeralda; Adamson, Maheen Mausoof] VA Palo Alto Hlth Care Syst, Rehabil Serv, Palo Alto, CA 94304 USA.
   [Harris, Odette A.; Adamson, Maheen Mausoof] Stanford Univ, Neurosurg, Sch Med, Palo Alto, CA 94305 USA.
   [Hoffman, Hunter G.] Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
C3 US Department of Veterans Affairs; Veterans Health Administration (VHA);
   VA Palo Alto Health Care System; University of Washington; University of
   Washington Seattle; King Abdulaziz University; University of Washington;
   University of Washington Seattle; US Department of Veterans Affairs;
   Veterans Health Administration (VHA); VA Palo Alto Health Care System;
   Stanford University; University of Washington; University of Washington
   Seattle
RP Hoffman, HG (corresponding author), King Abdulaziz Univ, Dept Comp Sci, Jeddah, Saudi Arabia.; Hoffman, HG (corresponding author), Univ Washington, Dept Mech Engn HPL, Seattle, WA 98195 USA.; Adamson, MM (corresponding author), VA Palo Alto Hlth Care Syst, Rehabil Serv, Palo Alto, CA 94304 USA.; Adamson, MM (corresponding author), Stanford Univ, Neurosurg, Sch Med, Palo Alto, CA 94305 USA.; Hoffman, HG (corresponding author), Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
EM madamson@stanford.edu; hunthoff9@gmail.com
RI Alhalabi, Wadee/C-2449-2015
OI Alhalabi, Wadee/0000-0002-4505-7268; Vieira Mota De Campos Hitching,
   Rita/0000-0002-1636-0807
FU Mayday Fund; Deanship of Scientific Research (DSR), King Abdulaziz
   University, Jeddah, Saudi Arabia [DF-582-611-1441]
FX This project was funded in part by the Mayday Fund to HH. The project
   was funded by the Deanship of Scientific Research (DSR), King Abdulaziz
   University, Jeddah, Saudi Arabia under grant NO. (DF-582-611-1441) to
   WA.
CR Al-Ghamdi NA, 2020, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00467
   Alexander JC, 2019, BEST PRAC RES-CL ANA, V33, P341, DOI 10.1016/j.bpa.2019.07.009
   [Anonymous], 1998, Cyberpsychol Behav Soc Netw, DOI [10.1089/cpb.1998.1.195, DOI 10.1089/CPB.1998.1.195]
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02508
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02265
   Austin PD, 2021, J SPINAL CORD MED, V44, P8, DOI 10.1080/10790268.2019.1575554
   Bader CE, 2018, WORLDV EVID-BASED NU, V15, P264, DOI 10.1111/wvn.12301
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Belmont Philip J, 2010, J Surg Orthop Adv, V19, P2
   Bermo M, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.705242
   Bermo Mohammed S, 2020, Top Magn Reson Imaging, V29, P203, DOI 10.1097/RMR.0000000000000248
   Birnie KA, 2017, PAIN, V158, P1012, DOI 10.1097/j.pain.0000000000000913
   Bruehl S, 2010, ANESTHESIOLOGY, V113, P713, DOI 10.1097/ALN.0b013e3181e3db38
   Burrowes SAB, 2022, PAIN, V163, P436, DOI 10.1097/j.pain.0000000000002372
   Butler FK., 2018, J SPEC OPER MED, V18, P37, DOI DOI 10.55460/YJB8-ZC0Y
   Butler FK, 2017, MIL MED, V182, pE1563, DOI 10.7205/MILMED-D-16-00214
   Carrougher GJ, 2009, J BURN CARE RES, V30, P785, DOI 10.1097/BCR.0b013e3181b485d3
   Casserly E., 2017, PERIOPERATIVE USES I
   Chan BL, 2007, NEW ENGL J MED, V357, P2206, DOI 10.1056/NEJMc071927
   Chan E, 2019, J PEDIATR-US, V209, P160, DOI 10.1016/j.jpeds.2019.02.034
   Chan E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200987
   Cleeland CS, 2003, CLIN J PAIN, V19, P298, DOI 10.1097/00002508-200309000-00003
   Correll DJ, 2014, J PAIN RES, V7, P199, DOI 10.2147/JPR.S60842
   Crofford Leslie J, 2015, Trans Am Clin Climatol Assoc, V126, P167
   Difede J, 2002, CYBERPSYCHOL BEHAV, V5, P529, DOI 10.1089/109493102321018169
   Difede J, 2014, NEUROPSYCHOPHARMACOL, V39, P1052, DOI 10.1038/npp.2013.317
   Egan TD, 2019, BRIT J ANAESTH, V122, pE127, DOI 10.1016/j.bja.2019.02.018
   Firoozabadi R, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.553492
   Flett JAM, 2019, MINDFULNESS, V10, P863, DOI 10.1007/s12671-018-1050-9
   Flor H, 2001, LANCET, V357, P1763, DOI 10.1016/S0140-6736(00)04890-X
   FLOR H, 1995, NATURE, V375, P482, DOI 10.1038/375482a0
   Flores A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00531
   Fregoso G, 2019, PAIN PHYSICIAN, V22, P479
   Garcia-Palacios A, 2015, CLIN J PAIN, V31, P564, DOI 10.1097/AJP.0000000000000196
   Gardner SE, 2017, WOUND REPAIR REGEN, V25, P558, DOI 10.1111/wrr.12553
   Garimella V, 2013, CLIN COLON RECT SURG, V26, P191, DOI 10.1055/s-0033-1351138
   Garrett B, 2014, CLIN J PAIN, V30, P1089, DOI 10.1097/AJP.0000000000000064
   Glare P, 2019, LANCET, V393, P1537, DOI 10.1016/S0140-6736(19)30352-6
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gold JI, 2018, J PEDIATR PSYCHOL, V43, P266, DOI 10.1093/jpepsy/jsx129
   Gomez J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01611
   Gordon Emma M., 2004, BMC Pharmacology, V4, P21, DOI 10.1186/1471-2210-4-21
   Gramlich MA, 2021, DEPRESS ANXIETY, V38, P626, DOI 10.1002/da.23141
   Gupta S, 2020, PERIOPER MED-LONDON, V9, DOI 10.1186/s13741-020-00147-3
   Harden RN, 2013, PAIN MED, V14, P180, DOI 10.1111/pme.12033
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2006, CNS SPECTRUMS, V11, P45, DOI 10.1017/S1092852900024202
   Hoffman HG, 2004, NEUROREPORT, V15, P1245, DOI 10.1097/01.wnr.0000127826.73576.91
   Hoffman HG, 2004, J CLIN PSYCHOL, V60, P189, DOI 10.1002/jclp.10244
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Hoffman HG, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89526-4
   Hoffman HG, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.602299
   Hoffman HG, 2020, J HAND THER, V33, P254, DOI 10.1016/j.jht.2020.04.001
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Hoffman HG, 2011, ANN BEHAV MED, V41, P183, DOI 10.1007/s12160-010-9248-7
   Indovina P, 2018, CLIN J PAIN, V34, P858, DOI 10.1097/AJP.0000000000000599
   Juottonen K, 2002, PAIN, V98, P315, DOI 10.1016/S0304-3959(02)00119-7
   Kabat-Zinn J., 1990, DELACORTE
   KABATZINN J, 1982, GEN HOSP PSYCHIAT, V4, P33, DOI 10.1016/0163-8343(82)90026-3
   KABATZINN J, 1985, J BEHAV MED, V8, P163, DOI 10.1007/BF00845519
   Katz N, 2002, J PAIN SYMPTOM MANAG, V24, pS38, DOI 10.1016/S0885-3924(02)00411-6
   Keefe FJ, 2012, PAIN, V153, P2163, DOI 10.1016/j.pain.2012.05.030
   Kharasch ED, 2016, ANESTHESIOLOGY, V124, P960, DOI 10.1097/ALN.0000000000001012
   Kingery WS, 1997, PAIN, V73, P123, DOI 10.1016/S0304-3959(97)00049-3
   Kipping B, 2012, BURNS, V38, P650, DOI 10.1016/j.burns.2011.11.010
   Kopp B, 1999, NEUROREPORT, V10, P807, DOI 10.1097/00001756-199903170-00026
   Kramer TL, 2010, PSYCHIAT SERV, V61, P1153, DOI 10.1176/ps.2010.61.11.1153
   Kuys S. S., 2012, ISRN REHABIL, V2012, P1, DOI [10.5402/2012/926784, DOI 10.5402/2012/926784]
   Ladha KS, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.10734
   Le May S, 2021, J ADV NURS, V77, P439, DOI 10.1111/jan.14607
   Lew D, 2020, AM J GASTROENTEROL, V115, pS39
   Liepert J, 2000, STROKE, V31, P1210, DOI 10.1161/01.STR.31.6.1210
   Linehan M. M., 1993, Cognitive-behavioral treatment of borderline personality disorder
   Louw A, 2020, SOUTH AFR J PHYSIOTH, V76, DOI 10.4102/sajp.v76i1.1417
   Love AS, 2021, J PRIM CARE COMMUNIT, V12, DOI 10.1177/21501327211007393
   Maani C., 2008, J CYBERTHERAPY REHAB, V1, P193
   Maani CV, 2011, J TRAUMA, V71, pS125, DOI 10.1097/TA.0b013e31822192e2
   Maani CV, 2011, PAIN MED, V12, P673, DOI 10.1111/j.1526-4637.2011.01091.x
   Malchow RJ, 2008, CRIT CARE MED, V36, pS346, DOI 10.1097/CCM.0b013e31817e2fc9
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Matamala-Gomez M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020291
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   McGreevy Kai, 2011, Eur J Pain Suppl, V5, P365
   McLay R, 2014, CYBERPSYCH BEH SOC N, V17, P439, DOI 10.1089/cyber.2013.0383
   McSherry T, 2018, J BURN CARE RES, V39, P278, DOI 10.1097/BCR.0000000000000589
   Méndez-Rebolledo G, 2017, J BACK MUSCULOSKELET, V30, P441, DOI 10.3233/BMR-150500
   Miner A, 2016, PSYCHOL TRAUMA-US, V8, P384, DOI 10.1037/tra0000092
   Molloy JM, 2020, MIL MED, V185, pE1461, DOI 10.1093/milmed/usaa027
   Montgomery H. R., 2021, J SPEC OPER MED, V21, P120
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Morris LD, 2009, CLIN J PAIN, V25, P815, DOI 10.1097/AJP.0b013e3181aaa909
   Moseley GL, 2008, PAIN, V138, P7, DOI 10.1016/j.pain.2008.06.026
   Moseley GL, 2004, PAIN, V108, P192, DOI 10.1016/j.pain.2004.01.006
   Mowery DC, 2002, RES POLICY, V31, P1369, DOI 10.1016/S0048-7333(02)00069-0
   Nahin RL, 2017, J PAIN, V18, P247, DOI 10.1016/j.jpain.2016.10.021
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   Neria Y, 2021, AM J PSYCHIAT, V178, P128, DOI 10.1176/appi.ajp.2020.20121727
   Nguyen KT, 2020, MIL MED, V185, pE2097, DOI 10.1093/milmed/usaa200
   Norr AM, 2018, DEPRESS ANXIETY, V35, P523, DOI 10.1002/da.22751
   O'Malley Kelly A, 2020, Public Policy Aging Rep, V30, P19, DOI 10.1093/ppar/prz027
   Perez RSGM, 2001, J PAIN SYMPTOM MANAG, V21, P511, DOI 10.1016/S0885-3924(01)00282-2
   Pierce BS, 2021, AM PSYCHOL, V76, P14, DOI 10.1037/amp0000722
   Ramachandran VS, 1996, P ROY SOC B-BIOL SCI, V263, P377, DOI 10.1098/rspb.1996.0058
   Rawlins CR, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.719681
   Reif S, 2018, MIL MED, V183, pE330, DOI 10.1093/milmed/usx200
   Rizzo A, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1414560
   Rogers E., 2013, Clinical Geriatrics, V21
   Rosenberg JM, 2018, PAIN MED, V19, P928, DOI 10.1093/pm/pnx203
   Rothbaum BO, 2014, AM J PSYCHIAT, V171, P640, DOI 10.1176/appi.ajp.2014.13121625
   Sampaio M, 2021, TELEMED E-HEALTH, V27, P919, DOI 10.1089/tmj.2021.0124
   Sampaio M, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.576421
   Sandbrink F, 2020, J GEN INTERN MED, V35, P927, DOI 10.1007/s11606-020-06258-3
   Satava RM, 2020, ANN SURG, V272, P384, DOI 10.1097/SLA.0000000000003220
   Schwoebel J, 2001, BRAIN, V124, P2098, DOI 10.1093/brain/124.10.2098
   Shoar Saeed, 2012, Anesth Pain Med, V1, P184, DOI 10.5812/kowsar.22287523.3443
   Siedlecka M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109909
   Skadberg RM, 2020, PAIN MANAG, V10, P13, DOI 10.2217/pmt-2019-0037
   Smart KM, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010853.pub2
   Solcà M, 2018, NEUROLOGY, V91, pE479, DOI 10.1212/WNL.0000000000005905
   Sun EC, 2016, JAMA INTERN MED, V176, P1286, DOI 10.1001/jamainternmed.2016.3298
   Tanielian T, 2019, HEALTH AFFAIR, V38, P1259, DOI 10.1377/hlthaff.2019.00239
   Taylor SS, 2021, PAIN THER, V10, P875, DOI 10.1007/s40122-021-00279-4
   Tran JE, 2021, JMIR RES PROTOC, V10, DOI 10.2196/26133
   Trost Z, 2022, PAIN, V163, P350, DOI 10.1097/j.pain.0000000000002348
   Trost Z, 2021, PAIN, V162, P325, DOI 10.1097/j.pain.0000000000002060
   Upton D, 2012, J WOUND CARE, V21, P53, DOI 10.12968/jowc.2012.21.2.53
   van Steenbergen H, 2019, COGN AFFECT BEHAV NE, V19, P435, DOI 10.3758/s13415-019-00710-6
   Wang XQ, 2021, LIFE SCI, V280, DOI 10.1016/j.lfs.2021.119609
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wender Regina, 2009, J Cyber Ther Rehabil, V2, P27
   Wendrich R. E., 2016, P ASME 2016 INT DES, P21
   Wiederhold BK, 2014, CYBERPSYCH BEH SOC N, V17, P346, DOI 10.1089/cyber.2014.0207
   Wiederhold MD, 2007, PAIN MED, V8, pS182, DOI 10.1111/j.1526-4637.2007.00381.x
   Wilson N, 2020, MMWR-MORBID MORTAL W, V69, P290, DOI 10.15585/mmwr.mm6911a4
   Woolf CJ, 2011, PAIN, V152, pS2, DOI 10.1016/j.pain.2010.09.030
   Zhang Y, 2020, NEUROTOXICOLOGY, V78, P71, DOI 10.1016/j.neuro.2020.02.006
   Zogas A., 2021, PATIENT EDUC COUNS, VS0738-3991, P00400, DOI [10.1016/j.pec.2021.06.002i, DOI 10.1016/J.PEC.2021.06.002I]
NR 141
TC 5
Z9 5
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 30
PY 2021
VL 2
AR 742290
DI 10.3389/frvir.2021.742290
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SV4
UT WOS:001021817700001
OA gold
DA 2024-07-18
ER

PT J
AU Wheeler, SG
   Engelbrecht, H
   Hoermann, S
AF Wheeler, Steven G.
   Engelbrecht, Hendrik
   Hoermann, Simon
TI Human Factors Research in Immersive Virtual Reality Firefighter
   Training: A Systematic Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE training; firefighter; human factor; human computer interaction (HCI);
   virtual reality
ID EXPERIENCE
AB Immersive virtual reality (VR) shows a lot of potential for the training of professionals in the emergency response domain. Firefighters occupy a unique position among emergency personnel as the threats they encounter are mainly environmental. Immersive VR therefore represents a great opportunity to be utilized for firefighter training. This systematic review summarizes the existing literature of VR firefighting training that has a specific focus on human factors and learning outcomes, as opposed to literature that solely covers the system, or simulation, with little consideration given to its user. An extensive literature search followed by rigorous filtering of publications with narrowly defined criteria was performed to aggregate results from methodologically sound user studies. The included studies provide evidence that suggests the suitability of VR firefighter training, especially in search and rescue and commander training scenarios. Although the overall number of publications is small, the viability of VR as an ecologically valid analog to real-life training is promising. In the future, more work is needed to establish clear evidence and guidelines to optimize the effectiveness of VR training and to increase reliable data through appropriate research endeavors.
C1 [Wheeler, Steven G.; Engelbrecht, Hendrik; Hoermann, Simon] Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
   [Hoermann, Simon] Univ Canterbury, Sch Prod Design, Christchurch, New Zealand.
C3 University of Canterbury; University of Canterbury
RP Hoermann, S (corresponding author), Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.; Hoermann, S (corresponding author), Univ Canterbury, Sch Prod Design, Christchurch, New Zealand.
EM simon.hoermann@canterbury.ac.nz
OI Wheeler, Steven Graham/0000-0002-6588-2935
CR Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Alcañiz M, 2009, PRESENCE-TELEOP VIRT, V18, P97, DOI 10.1162/pres.18.2.97
   Amokrane Kahina, 2008, International Journal of Virtual Reality, V7, P23
   [Anonymous], 2003, Proceedings of the 2003 conference on Diversity in computing: ACM
   [Anonymous], 2018, FIREFIGHTER FATALITI
   [Anonymous], 2016, 2016 IEEE Aerospace Conference, DOI 10.1109/AER0.2016.7500674
   Ave W., 1994, ENVR4 TECH REP
   Backlund P, 2007, IEEE INT CONF INF VI, P899
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   Choe M, 2019, INT J HUM-COMPUT INT, V35, P620, DOI 10.1080/10447318.2018.1484054
   Chow Yang-Wai., 2005, TENCON 2005. 2005 IEEE Region 10, P1, DOI [10.1109/tencon.2005.301329, DOI 10.1109/TENCON.2005.301329]
   Clifford R. M. S., 2018, 2018 10 INT C VIRT W, DOI DOI 10.1109/VS-GAMES.2018.8493423
   Clifford RMS, 2018, 2018 IEEE WORKSHOP ON AUGMENTED AND VIRTUAL REALITIES FOR GOOD (VAR4GOOD)
   Cohen-Hatton SR, 2015, J EXP PSYCHOL-APPL, V21, P395, DOI 10.1037/xap0000061
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Danowitz A, 2012, COMMUN ACM, V55, P55, DOI [10.1145/2133806.2133822, 10.1145/2133806.2133622]
   Dunn V., 2015, Safety and survival on the fireground, V2nd
   Engelbrecht H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00101
   Evarts B., 2018, U.S. Firefighter Injuries 2017
   Ha G, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P301, DOI 10.1145/2993369.2996306
   Heick R, 2009, J OCCUP ENVIRON MED, V51, P963, DOI 10.1097/JOM.0b013e3181af6b76
   Herveille R., 2001, VGA LCD CORE SPECIFI
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Hulett D., 2008, NATL REPORT CARD WOM
   Hulett D.M., 2007, Enhancing women's inclusion in firefighting
   Insko B., 2001, THESIS U N CAROLINA
   Jarmon L, 2009, COMPUT EDUC, V53, P169, DOI 10.1016/j.compedu.2009.01.010
   Jeon SG, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364268
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Lindner P, 2021, INT J COGN THER, V14, P23, DOI 10.1007/s41811-020-00090-7
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P227, DOI 10.1109/VR.2015.7223378
   Lukosch Heide, 2019, HCI in Games. First International Conference, HCI-Games 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11595), P165, DOI 10.1007/978-3-030-22602-2_14
   Lyons K, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14020142
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Oliva D., 2019, CEUR WORKSHOP P, P241
   Ooi S, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON EDUCATIONAL AND INFORMATION TECHNOLOGY (ICEIT 2019), P301, DOI 10.1145/3318396.3318431
   Paljic A, 2017, LECT NOTES COMPUT SC, V10590, P301, DOI 10.1007/978-3-319-70742-6_28
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Rizzo A, 2011, J CLIN PSYCHOL MED S, V18, P176, DOI 10.1007/s10880-011-9247-2
   ROBERTSON GG, 1993, COMPUTER, V26, P81, DOI 10.1109/2.192002
   Seo S, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P447, DOI 10.23919/elinfocom.2019.8706466
   Sharma S, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR HUMAN-LIKE INTELLIGENCE (CIHLI), P1
   Shaw E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300856
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Stetz MC, 2007, ANN REV CYBERTHERAPY, V5, P192
   Tate DL, 1997, IEEE COMPUT GRAPH, V17, P23, DOI 10.1109/38.626965
   Toet A, 2007, PERCEPT MOTOR SKILL, V105, P1245, DOI 10.2466/PMS.105.4.1245-1256
   Tortell R., 2007, Virtual Reality, V11, P61, DOI 10.1007/s10055-006-0056-0
   van Berlo M., 2005, P 2 INT ISCRAM C, P195
   Vincent DS, 2008, ACAD EMERG MED, V15, P1160, DOI 10.1111/j.1553-2712.2008.00191.x
   Wiederhold B. K., 2003, CYBERPSYCHOLOGY MIND
   Wiederhold MD, 2004, CYBERPSYCHOL BEHAV, V7, P319
   Yu FJ, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P219, DOI 10.1145/3013971.3013977
   Yuan DP, 2007, COMM COM INF SC, V5, P365
   Zybura M., 1999, OLFACTION VIRTUAL RE
NR 64
TC 6
Z9 7
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 12
PY 2021
VL 2
AR 671664
DI 10.3389/frvir.2021.671664
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8XC8
UT WOS:001019202400001
OA gold
DA 2024-07-18
ER

PT J
AU Turbyne, C
   de Koning, P
   Smit, D
   Denys, D
AF Turbyne, Collin
   de Koning, Pelle
   Smit, Dirk
   Denys, Damiaan
TI Affective and Physiological Responses During Acute Pain in Virtual
   Reality: The Effect of First-Person Versus Third-Person Perspective
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; first person perspective; third person perspective;
   affective psychophysiology; acute pain analgesia
ID BODY; DISTRACTION; SIZE; SELF
AB Background: Virtual reality (VR) has been previously shown as a means to mitigate acute pain. The critical parameters involved in the clinical efficacy of mitigating acute pain from different perspectives remains unknown. This study attempted to further deconstruct the critical parameters involved in mitigating acute pain by investigating whether affective and physiological responses to painful stimuli differed between a first and a third person perspective in virtual reality.Methods: Two conditions were compared in a repeated-measures within subject study design for 17 healthy participants: First person perspective (i.e., where participants experienced their bodies from an anatomical and egocentric perspective) and third person perspective (i.e., where participants experienced their bodies from an anatomical perspective from across the room). The participants received noxious electrical stimulation at pseudorandom intervals and anatomical locations during both conditions. Physiological stress responses were measured by means of electrocardiography (ECG) and impedance cardiography (ICG). Subjective scores measuring tension, pain, anger, and fear were reported after every block sequence.Results: There were no significant differences in physiological stress responses between conditions. However, the participants reported significantly higher tension during the third person condition.Conclusion: Relative to a third person perspective, there are no distinct physiological benefits to inducing a first person perspective to mitigate physiological stress responses to acute pain in healthy individuals. However, there may be additional clinical benefits for doing so in specific clinical populations that have shown to benefit from relaxation techniques. Further research is needed in order to refine the clinical utility of different perspectives during virtual reality immersions that serve to act as a non-pharmacological analgesic during acute pain.
C1 [Turbyne, Collin; de Koning, Pelle; Smit, Dirk; Denys, Damiaan] Univ Amsterdam, Acad Med Ctr, Dept Psychiat, Amsterdam, Netherlands.
C3 University of Amsterdam; Academic Medical Center Amsterdam
RP Turbyne, C (corresponding author), Univ Amsterdam, Acad Med Ctr, Dept Psychiat, Amsterdam, Netherlands.
EM c.a.turbyne@amsterdamumc.nl
OI Denys, Damiaan/0000-0002-3191-3844
CR AKSELROD S, 1981, SCIENCE, V213, P220, DOI 10.1126/science.6166045
   Alford DP, 2006, ANN INTERN MED, V144, P127, DOI 10.7326/0003-4819-144-2-200601170-00010
   Berntson GG, 2004, PSYCHOPHYSIOLOGY, V41, P333, DOI 10.1111/j.1469-8986.2004.00156.x
   Blom KJ, 2014, PERCEPTION, V43, P275, DOI 10.1068/p7618
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Gershon J, 2004, J AM ACAD CHILD PSY, V43, P1243, DOI 10.1097/01.chi.0000135621.23145.05
   Hänsel A, 2011, EUR J PAIN, V15, P874, DOI 10.1016/j.ejpain.2011.03.013
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2001, CYBERPSYCHOL BEHAV, V4, P527, DOI 10.1089/109493101750527088
   Hoffman HG, 2011, ANN BEHAV MED, V41, P183, DOI 10.1007/s12160-010-9248-7
   IASP, 2017, IASP TERM
   Jiang MZ, 2019, J CLIN MONIT COMPUT, V33, P493, DOI 10.1007/s10877-018-0174-8
   KATONA PG, 1975, J APPL PHYSIOL, V39, P801, DOI 10.1152/jappl.1975.39.5.801
   Kwekkeboom KL, 2006, J NURS SCHOLARSHIP, V38, P269, DOI 10.1111/j.1547-5069.2006.00113.x
   Kyle BN, 2014, PAIN RES MANAG, V19, P159, DOI 10.1155/2014/536859
   Lang PJ, 2008, A8 U FLOR
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   LIANG KY, 1993, ANNU REV PUBL HEALTH, V14, P43, DOI 10.1146/annurev.pu.14.050193.000355
   Lier EJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66035-4
   Longo MR, 2009, J NEUROSCI, V29, P12125, DOI 10.1523/JNEUROSCI.3072-09.2009
   Luebbert K, 2001, PSYCHO-ONCOLOGY, V10, P490, DOI 10.1002/pon.537
   Mancini F, 2011, PSYCHOL SCI, V22, P325, DOI 10.1177/0956797611398496
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Martini M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00438
   Matamala-Gomez M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020291
   NEWLIN DB, 1979, PSYCHOPHYSIOLOGY, V16, P546, DOI 10.1111/j.1469-8986.1979.tb01519.x
   Pfeiffer C, 2014, EXP BRAIN RES, V232, P4021, DOI 10.1007/s00221-014-4080-0
   Rizzo A.S., 2019, Virtual reality for psychological and neurocognitive interventions, DOI [10.1007/978-1-4939-9482-3, DOI 10.1007/978-1-4939-9482-3]
   Roelofs J, 2004, J PAIN, V5, P250, DOI 10.1016/j.jpain.2004.04.001
   Romano D, 2014, NEUROPSYCHOLOGIA, V57, P93, DOI 10.1016/j.neuropsychologia.2014.03.002
   Schmidt K, 2018, J PAIN, V19, P135, DOI 10.1016/j.jpain.2017.09.005
   Schneider SM, 2004, ONCOL NURS FORUM, V31, P81, DOI 10.1188/04.ONF.81-88
   Turbyne C, 2021, BMJ CASE REP, V14, DOI 10.1136/bcr-2020-238554
   Vrije Universiteit, 2019, DATA ANAL MANAGEMENT
   ZEGER SL, 1988, BIOMETRICS, V44, P1049, DOI 10.2307/2531734
NR 35
TC 1
Z9 1
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 21
PY 2021
VL 2
AR 694511
DI 10.3389/frvir.2021.694511
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OL8
UT WOS:001021703300001
OA gold
DA 2024-07-18
ER

PT J
AU Jung, SC
   Lindeman, RW
AF Jung, Sungchul
   Lindeman, Robert. W.
TI Perspective: Does Realism Improve Presence in VR? Suggesting a Model and
   Metric for VR Experience Evaluation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE realism; presence; immersion; evaluation model; metric; illusion;
   theory; Coherence
ID OWNERSHIP; IMMERSION; SENSE
AB The concepts of "immersion" and "presence" have been considered as staple metrics for evaluating the quality of virtual reality experiences for more than five decades, even as the concepts themselves have evolved in terms of both technical and psychological aspects. To enhance the user's experience, studies have investigated the impact of different visual, auditory, and haptic stimuli in various contexts to mainly explore the concepts of "plausibility illusion" and "place illusion". Previous research has sometimes shown a positive correlation between increased realism and an increase in presence, but not always, and thus, very little of the work around the topic of presence reports an unequivocal correlation. Indeed, one might classify the overall findings within the field around presence as "messy". Better (or more) visual, auditory, or haptic cues, or increased agency, may lead to increased realism, but not necessarily increased presence, and may well depend on the application context. Rich visual and audio cues in concert contribute significantly to both realism and presence, but the addition of tactile cues, gesture input support, or a combination of these might improve realism, but not necessarily presence. In this paper, we review previous research and suggest a possible theory to better define the relationship between increases in sensory-based realism and presence, and thus help VR researchers create more effective experiences.
C1 [Jung, Sungchul] Univ Canterbury, Coll Engn, Human Interface Technol Lab, HIT Lab NZ, Christchurch, New Zealand.
   [Jung, Sungchul; Lindeman, Robert. W.] Kennesaw State Univ, Coll Comp & Software Engn, Dept Software Engn & Game Design & Dev, Marietta, GA, Belgium.
C3 University of Canterbury
RP Jung, SC (corresponding author), Univ Canterbury, Coll Engn, Human Interface Technol Lab, HIT Lab NZ, Christchurch, New Zealand.; Jung, SC (corresponding author), Kennesaw State Univ, Coll Comp & Software Engn, Dept Software Engn & Game Design & Dev, Marietta, GA, Belgium.
EM sungchul.jung@canterbury.ac.nz
OI Jung, Sungchul/0000-0003-3633-7767
CR Alexander A.L., 2005, From gaming to training: A review of studies on fidelity, immersion, presence, and buy-in and their effects on transfer in PC-based simulations and games
   [Anonymous], 2000, PRES 2000 3 INT WORK
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Beckhaus S, 2011, VIRTUAL REALITIES: DAGSTUHL SEMINAR 2008, P39, DOI 10.1007/978-3-211-99178-7_3
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Doukakis E, 2019, IEEE T VIS COMPUT GR, V25, P1865, DOI 10.1109/TVCG.2019.2898823
   Erving G., 1963, Behavior in public places: notes on the social organization of gatherings
   Feng M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P95, DOI 10.1109/3DUI.2016.7460037
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Insko B. E., 2001, THESIS U N CAROLINA
   Jung S., 2021, 2021 IEEE C VIRT REA
   Jung S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P463, DOI [10.1109/VR46266.2020.1580947852943, 10.1109/VR46266.2020.00-37]
   Jung S, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P3, DOI 10.1145/3131277.3132186
   Jung S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P267, DOI 10.1109/VR.2018.8447562
   Jung Sungchul., 2016, P 26 INT C ART REAL, P107, DOI DOI 10.2312/EGVE.20161442
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lindeman RW, 1999, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.1999.756952
   MacIntyre B., 2004, Proceedings of the 7th Annual International Workshop on Presence
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Mi Feng, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P149, DOI 10.1109/3DUI.2015.7131744
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Naef M., 2002, VIRTUAL REALITY SOFT, P65
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Riccio G. E., 1995, Local applications of the ecological approach to human-machine systems, P60
   Samad M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117178
   Schroeder R., 2005, PRESENCE 2002 5 INT, P274
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez Richard T, 2016, PhD thesis
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stoffregen TA, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P111, DOI 10.1201/9781410608888.ch6
   Sungchul Jung, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449146
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 40
TC 17
Z9 17
U1 3
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 15
PY 2021
VL 2
AR 693327
DI 10.3389/frvir.2021.693327
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OR3
UT WOS:001021708800001
OA gold
DA 2024-07-18
ER

PT J
AU Komaritzan, M
   Wenninger, S
   Botsch, M
AF Komaritzan, Martin
   Wenninger, Stephan
   Botsch, Mario
TI Inside Humans: Creating a Simple Layered Anatomical Model from Human
   Surface Scans
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual human; anatomy; non rigid registration; virtual reality; human
   shape analysis
ID BODY-COMPOSITION; CHILDREN; ADULTS
AB 3D morphable models are widely used to describe the variation of human body shapes. However, these models typically focus on the surface of the human body, since the acquisition of the volumetric interior would require prohibitive medical imaging. In this paper we present a novel approach for creating a volumetric body template and for fitting this template to the surface scan of a person in a just a few seconds. The body model is composed of three surface layers for bones, muscles, and skin, which enclose the volumetric muscle and fat tissue in between them. Our approach includes a data-driven method for estimating the amount of muscle mass and fat mass from a surface scan, which provides more accurate fits to the variety of human body shapes compared to previous approaches. We also show how to efficiently embed fine-scale anatomical details, such as high resolution skeleton and muscle models, into the layered fit of a person. Our model can be used for physical simulation, statistical analysis, and anatomical visualization in computer animation and medical applications, which we demonstrate on several examples.
C1 [Komaritzan, Martin; Wenninger, Stephan; Botsch, Mario] TU Dortmund Univ, Comp Graph Grp, Dortmund, Germany.
C3 Dortmund University of Technology
RP Komaritzan, M (corresponding author), TU Dortmund Univ, Comp Graph Grp, Dortmund, Germany.
EM martin.komaritzan@tu-dortmund.de
OI Wenninger, Stephan/0009-0008-2404-7117
FU German Federal Ministry of Education and Research (BMBF) [16SV8225]
FX The authors are grateful to Jascha Achenbach for valuable discussion and
   implementation hints and to Hendrik Meyer for his help with the
   renderings of our models. This research was supported by the German
   Federal Ministry of Education and Research (BMBF) through the project
   ViTraS (ID 16SV8225). The scale and ruler emojis in Figure 2 are
   designed by OpenMoji (https://openmoji.org) and provided through CC
   BY-SA 4.0 License.
CR Achenbach J, 2018, P EUR WORKSH VIS COM, P67
   Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Ackerman MJ, 1998, P IEEE, V86, P504, DOI 10.1109/5.662875
   Ali-Hamadi D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508415
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Autodesk, 2014, CHAR GEN
   Aydin Kabakci AD, 2017, INT J MORPHOL, V35, P219, DOI 10.4067/S0717-95022017000100036
   Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591
   Botsch M, 2005, COMPUT GRAPH FORUM, V24, P611, DOI 10.1111/j.1467-8659.2005.00886.x
   Botsch M., 2010, Polygon Mesh Processing
   Bouaziz S, 2014, EUROGRAPHICS TUTORIA, P1, DOI [10.2312/egt.20141021, DOI 10.1118/1.4830428]
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Bouaziz S, 2012, COMPUT GRAPH FORUM, V31, P1657, DOI 10.1111/j.1467-8659.2012.03171.x
   Brochu T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185592
   BROZEK J, 1963, ANN NY ACAD SCI, V110, P113, DOI 10.1111/j.1749-6632.1963.tb17079.x
   Christ A, 2010, PHYS MED BIOL, V55, pN23, DOI 10.1088/0031-9155/55/2/N01
   Dayal MR, 2008, S AFR J SCI, V104, P124
   Deul C., 2013, VIRTUAL REALITY INTE
   Deuss M., 2015, SHAPEOP A ROBUST EXT, P505
   Fields DA, 2002, AM J CLIN NUTR, V75, P453, DOI 10.1093/ajcn/75.3.453
   Fit3D, 2020, FIT3D SCANN SYST
   Gietzen T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210257
   Guennebaud G., 2020, EIGEN V3
   Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x
   Heymsfield SB, 2011, AM J CLIN NUTR, V93, P736, DOI 10.3945/ajcn.110.007161
   Ichim AE, 2016, S COMP AN, P107
   Ichim AE, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073664
   JACKSON AS, 1985, PHYSICIAN SPORTSMED, V13, P76, DOI 10.1080/00913847.1985.11708790
   Kadlecek P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982438
   Kim M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073685
   Komaritzan M., 2019, PROC ACM MOTION, V22, P10, DOI [DOI 10.1145/3359566.3360073, 10.1145/3359566.3360073]
   Komaritzan M, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203203
   Kyle UG, 2001, NUTRITION, V17, P534, DOI 10.1016/S0899-9007(01)00555-X
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Maalin N, 2021, BEHAV RES METHODS, V53, P1308, DOI 10.3758/s13428-020-01494-1
   Ng BK, 2016, EUR J CLIN NUTR, V70, P1265, DOI 10.1038/ejcn.2016.109
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Piryankova IV, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641568
   Riviere J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392464
   Robinette K. M., 2002, 1 SYTR INC
   Romero C, 2020, COMPUT GRAPH FORUM, V39, P77, DOI 10.1111/cgf.13913
   Saito S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766957
   SHOEMAKE K, 1992, GRAPH INTER, P258
   Sieger D., 2013, Proceedings of 21th International Meshing Roundtable, P1, DOI DOI 10.1007/978-3-642-33573-0_1
   Siri W. E., 1956, UCRL3349 LAWR BERK N
   Tomlinson DJ, 2016, BIOGERONTOLOGY, V17, P467, DOI 10.1007/s10522-015-9626-4
   Weng CY, 2019, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR.2019.00606
   Wenninger S., 2020, PROC ACM S VIRTUAL R, P1
   Zhu LF, 2015, COMPUT GRAPH FORUM, V34, P459, DOI 10.1111/cgf.12575
   Ziylan T, 2002, TURKISH J MED SCI, V32, P231, DOI DOI 10.1127/ANTHRANZ/64/2006/389
   Zygote, 2019, DEF
NR 51
TC 4
Z9 4
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 5
PY 2021
VL 2
AR 694244
DI 10.3389/frvir.2021.694244
PG 21
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AQ2
UT WOS:001019295000001
OA gold
DA 2024-07-18
ER

PT J
AU Pouke, M
   Mimnaugh, KJ
   Chambers, AP
   Ojala, T
   LaValle, SM
AF Pouke, Matti
   Mimnaugh, Katherine J. J.
   Chambers, Alexis P. P.
   Ojala, Timo
   LaValle, Steven M. M.
TI The Plausibility Paradox for Resized Users in Virtual Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; perception; scaling; plausibility; human factors
ID ILLUSORY OWNERSHIP; HAPTIC FEEDBACK; COLLABORATION; PERCEPTION; SYSTEMS
AB This paper identifies and confirms a perceptual phenomenon: when users interact with simulated objects in a virtual environment where the users' scale deviates greatly from normal, there is a mismatch between the object physics they consider realistic and the object physics that would be correct at that scale. We report the findings of two studies investigating the relationship between perceived realism and a physically accurate approximation of reality in a virtual reality experience in which the user has been scaled by a factor of ten. Study 1 investigated perception of physics when scaled-down by a factor of ten, whereas Study 2 focused on enlargement by a similar amount. Studies were carried out as within-subjects experiments in which a total of 84 subjects performed simple interaction tasks with objects under two different physics simulation conditions. In the true physics condition, the objects, when dropped and thrown, behaved accurately according to the physics that would be correct at that either reduced or enlarged scale in the real world. In the movie physics condition, the objects behaved in a similar manner as they would if no scaling of the user had occurred. We found that a significant majority of the users considered the movie physics condition to be the more realistic one. However, at enlarged scale, many users considered true physics to match their expectations even if they ultimately believed movie physics to be the realistic condition. We argue that our findings have implications for many virtual reality and telepresence applications involving operation with simulated or physical objects in abnormal and especially small scales.
C1 [Pouke, Matti; Mimnaugh, Katherine J. J.; Chambers, Alexis P. P.; Ojala, Timo; LaValle, Steven M. M.] Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Ubiquitous Comp, Oulu, Finland.
C3 University of Oulu
RP Pouke, M (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Ubiquitous Comp, Oulu, Finland.
EM matti.pouke@oulu.fi
FU  [3D User Interfaces (IEEE VR 2020)]
FX Funding This work was supported by the PIXIE (331822) and PERCEPT
   (322637) projects funded by the Academy of Finland, the COMBAT project
   (293389) funded by the Strategic Research Council at the Academy of
   Finland, as well as the HUMOR (3656/31/2019) project funded by Business
   Finland.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Alatalo T., 2016, P 21 INT C WEB3D TEC, P95, DOI [DOI 10.1145/2945292.2945305, 10.1145/2945292.2945305]
   Alex J., 1998, P DETC98 1998 ASME E
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Billinghurst M, 2001, COMPUT GRAPH-UK, V25, P745, DOI 10.1016/S0097-8493(01)00117-0
   Bolopion A, 2013, IEEE T AUTOM SCI ENG, V10, P496, DOI 10.1109/TASE.2013.2245122
   Cross R, 2004, AM J PHYS, V72, P305, DOI 10.1119/1.1634964
   Deng Z, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/3264342
   Dodgson NA, 2004, PROC SPIE, V5291, P36, DOI 10.1117/12.529999
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Hatamura Y., 1990, Proceedings. IEEE Micro Electro Mechanical Systems. An Investigation of Micro Structures, Sensors, Actuators, Machines and Robots (Cat. No.90CH2832-4), P203, DOI 10.1109/MEMSYS.1990.110277
   Hongo K, 2002, NEUROSURGERY, V51, P985, DOI 10.1227/01.NEU.0000029082.48894.18
   Interrante V, 2008, PRESENCE-TELEOP VIRT, V17, P176, DOI 10.1162/pres.17.2.176
   Izumihara A., 2019, ACM SIGGRAPH 2019 EM, P1
   Jingjing Zhang, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382876
   Kim J., 2017, P 27 INT C ARTIFICIA, P153, DOI DOI 10.5555/3298830.32988592
   Kopper R, 2006, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2006.47
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   Langbehn E, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P211, DOI 10.1109/3DUI.2016.7460054
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Leyrer M., 2011, P ACM SIGGRAPH S APP, DOI 10.1145/2077451.2077464
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   McCoy J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217513
   McIntyre J, 2001, NAT NEUROSCI, V4, P693, DOI 10.1038/89477
   Millet G, 2008, LECT NOTES COMPUT SC, V5024, P847, DOI 10.1007/978-3-540-69057-3_107
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Nilsson N. C., 2017, 2017 IEEE 3 WORKSH E, P1, DOI [https://doi.org/10.1109/WEVR.2017.7957710, DOI 10.1109/WEVR.2017.7957710]
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Ogawa N., 2017, P 8 AUGMENTED HUMAN, P1
   Patton MQ, 2005, QUALITATIVE RES, DOI DOI 10.1002/0470013192.BSA514
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Plisson H., 2015, Digital Applications in Archaeology and Cultural Heritage, V2, P102, DOI [10.1016/j.daach.2015.06.002, DOI 10.1016/J.DAACH.2015.06.002]
   Pouke M, 2021, Arxiv, DOI arXiv:2102.03179
   Pouke M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P913, DOI [10.1109/VR46266.2020.00116, 10.1109/VR46266.2020.1580974317169]
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rietzler M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173702
   Rovira A, 2009, FRONT BEHAV NEUROSCI, V3, DOI 10.3389/neuro.08.059.2009
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Senot P, 2005, J NEUROPHYSIOL, V94, P4471, DOI 10.1152/jn.00527.2005
   Shenai MB, 2014, J NEUROSURG, V121, P277, DOI 10.3171/2014.4.JNS131805
   Sitti M, 2007, IEEE ROBOT AUTOM MAG, V14, P53, DOI 10.1109/MRA.2007.339606
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Ullman TD, 2017, TRENDS COGN SCI, V21, P649, DOI 10.1016/j.tics.2017.05.012
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Yao Hsin-yun, 2006, P EUR, P325
   Zhang J., 2020, S SPAT US INT CAN OC, P1
   Zhang XL, 2005, PRESENCE-TELEOP VIRT, V14, P31, DOI 10.1162/1054746053890288
   Zhaoyi Li, 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4591, P153, DOI 10.1117/12.441646
   Zheng SQ, 2017, NAT METHODS, V14, P331, DOI 10.1038/nmeth.4193
NR 59
TC 6
Z9 6
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 30
PY 2021
VL 2
AR 655744
DI 10.3389/frvir.2021.655744
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZS6
UT WOS:001019271300001
OA gold, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Baillet, H
   Burin-Chu, S
   Lejeune, L
   Le Chénéchal, M
   Thouvarecq, R
   Benguigui, N
   Leconte, P
AF Baillet, Heloise
   Burin-Chu, Simone
   Lejeune, Laure
   Le Chenechal, Morgan
   Thouvarecq, Regis
   Benguigui, Nicolas
   Leconte, Pascale
TI Impact of task constraints on a 3D visuomotor tracking task in virtual
   reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE 3D virtual environment; target tracking task; constraints; motor
   control; depth dimension
ID CEREBELLAR MOTOR DISORDERS; DEPTH-PERCEPTION; MOVEMENTS; DISTANCE; CUES;
   COORDINATION; INFORMATION; ADAPTATION; KINEMATICS; EXPERTISE
AB Objective: The aim of the present study was to evaluate the impact of different task constraints on the participants' adaptation when performing a 3D visuomotor tracking task in a virtual environment.Methods: Twenty-three voluntary participants were tested with the HTC Vive Pro Eye VR headset in a task that consisted of tracking a virtual target moving in a cube with an effector controlled with the preferred hand. Participants had to perform 120 trials according to three task constraints (i.e., gain, size, and speed), each performed according to four randomized conditions. The target-effector distance and elbow range of movement were measured.Results: The results showed an increase in the distance to the target when the task constraints were the strongest. In addition, a change in movement kinematics was observed, involving an increase in elbow amplitude as task constraints increased. It also appeared that the depth dimension played a major role in task difficulty and elbow amplitude and coupling in the tracking task.Conclusion: This research is an essential step towards characterizing interactions with a 3D virtual environment and showing how virtual constraints can facilitate arm's involvement in the depth dimension.
C1 [Baillet, Heloise; Burin-Chu, Simone; Lejeune, Laure; Benguigui, Nicolas] Normandie Univ, UNICAEN, ENSICAEN, CNRS,UMR,GREYC, Caen, France.
   [Baillet, Heloise; Thouvarecq, Regis] Univ Rouen Normandie, CETAPS, UR 3832, Rouen, France.
   [Le Chenechal, Morgan] Open Mind Neurotechnol, Paris, France.
   [Leconte, Pascale] Normandie Univ, UNICAEN, INSERM, COMETE, Caen, France.
C3 Universite de Caen Normandie; Centre National de la Recherche
   Scientifique (CNRS); Universite de Rouen Normandie; Universite de Caen
   Normandie; Institut National de la Sante et de la Recherche Medicale
   (Inserm)
RP Baillet, H (corresponding author), Normandie Univ, UNICAEN, ENSICAEN, CNRS,UMR,GREYC, Caen, France.; Baillet, H (corresponding author), Univ Rouen Normandie, CETAPS, UR 3832, Rouen, France.
EM bailletheloise@gmail.com
RI BURIN-CHU, Simone/KBC-8726-2024
OI Burin-Chu, Simone/0000-0002-4439-1731
FU "RV reeduc" European project; Normandy County Council; European Union
FX This work was supported by the "RV reeduc" European project, co-funded
   by the Normandy County Council and the European Union in the framework
   of the ERDF-ESF operational programme 2014-2020.
CR ADAMS JA, 1961, PSYCHOL BULL, V58, P55, DOI 10.1037/h0041559
   Nguyen A, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139167
   Ao D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128328
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   BEPPU H, 1984, BRAIN, V107, P787, DOI 10.1093/brain/107.3.787
   BEPPU H, 1987, BRAIN, V110, P1, DOI 10.1093/brain/110.1.1
   BERNSTEIN N., 1967
   Bideau B, 2004, NEUROSCI LETT, V372, P119, DOI 10.1016/j.neulet.2004.09.023
   Bideau B, 2010, IEEE COMPUT GRAPH, V30, P14, DOI 10.1109/MCG.2009.134
   Bingham GP, 2005, ECOL PSYCHOL, V17, P55, DOI 10.1207/s15326969eco1702_1
   Brassel S, 2021, J MED INTERNET RES, V23, DOI 10.2196/26344
   Buekers MJ, 2000, NEUROSCI LETT, V290, P181, DOI 10.1016/S0304-3940(00)01350-1
   Choi W, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251371
   Choi W, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31758-y
   Cutting J. E., 2021, Movies on our minds: The evolution of cinematic engagement
   Cutting JE, 1997, BEHAV RES METH INS C, V29, P27, DOI 10.3758/BF03200563
   Fan MY, 2019, IEEE ACCESS, V7, P8890, DOI 10.1109/ACCESS.2019.2891132
   Faure C, 2020, J SPORT SCI, V38, P192, DOI 10.1080/02640414.2019.1689807
   Fine JM, 2014, ACTA PSYCHOL, V149, P24, DOI 10.1016/j.actpsy.2014.02.012
   Gajda K, 2016, EXP BRAIN RES, V234, P2859, DOI 10.1007/s00221-016-4688-3
   Gerig N, 2018, ADV INTELL SYST, V663, P113, DOI 10.1007/978-3-319-67846-7_12
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Gielen CCAM, 2009, CORTEX, V45, P340, DOI 10.1016/j.cortex.2008.02.009
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hoskinson Reynald., 2004, APGV 04, P164, DOI [10.1145/1012551.1012586, DOI 10.1145/1012551.1012586]
   Jo HJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216368
   Le Chenechal M., 2018, ICAT EGVE 2018
   Le Runigo C, 2005, HUM MOVEMENT SCI, V24, P429, DOI 10.1016/j.humov.2005.06.008
   Limanowski J, 2017, NEUROIMAGE, V146, P81, DOI 10.1016/j.neuroimage.2016.11.009
   Mallek M, 2017, EUR J SPORT SCI, V17, P1270, DOI 10.1080/17461391.2017.1375014
   Naceri A, 2011, PRESENCE-TELEOP VIRT, V20, P254, DOI 10.1162/PRES_a_00048
   Newell K.M., 1996, RES ECOL PS, P393
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Pacheco MM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01874
   Park W, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123477
   POULTON EC, 1957, J EXP PSYCHOL, V53, P189, DOI 10.1037/h0043798
   Raab M, 2013, EXP BRAIN RES, V228, P155, DOI 10.1007/s00221-013-3546-9
   Ranganathan R, 2007, J MOTOR BEHAV, V39, P369, DOI 10.3200/JMBR.39.5.369-380
   van der Kooij K, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193002
   VANEMMERIK REA, 1990, ACTA PSYCHOL, V73, P171, DOI 10.1016/0001-6918(90)90078-T
   Vienne C, 2020, IEEE ACCESS, V8, P29099, DOI 10.1109/ACCESS.2020.2972122
   Vignais Nicolas, 2009, International Journal of Virtual Reality, V8, P43
   Warren WH, 2006, PSYCHOL REV, V113, P358, DOI 10.1037/0033-295X.113.2.358
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Xie X., 2010, Proc. 7th Symposium on Applied Perception in Graphics and Visualization (APGV), P65, DOI DOI 10.1145/1836248.1836260
   Yang SY, 2020, IEEE T HUM-MACH SYST, V50, P79, DOI 10.1109/THMS.2019.2947580
   Zhang R., 2014, Proc. Proceedings of the 2nd ACM Symposium on Spatial User Interaction, P62
   Zhu H., 2020, Depth perception in virtual peripersonal space: an investigation of motion parallax on perception- VS action-estimations
NR 48
TC 1
Z9 1
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 17
PY 2023
VL 4
AR 1119238
DI 10.3389/frvir.2023.1119238
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA W3JO7
UT WOS:001090626900001
OA gold
DA 2024-07-18
ER

PT J
AU Junior, BJD
   Perreault, L
   Lopes, MKS
   Roberge, MC
   Oliveira, AA
   Falk, TH
AF De Jesus Junior, Belmir Jose
   Perreault, Lea
   Lopes, Marilia K. S.
   Roberge, Marie-Claude
   Oliveira, Alcyr A.
   Falk, Tiago H.
TI Using multisensory virtual reality nature immersion as a therapeutic
   modality for improving HRV and cognitive functions in post-traumatic
   stress disorder: a pilot-study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; relaxation training; olfactory; multisensory; mental
   health
ID EXPOSURE THERAPY; RELIABILITY; VALIDITY; PHQ-9
AB Introduction: Immersive virtual reality (VR) applications are burgeoning within healthcare as they promote high levels of engagement. Notwithstanding, existing solutions only stimulate two of our five senses (audio and visual), thus may not be optimal in the sense of promoting immersion and of "being present". In this paper, we explore the benefits of an immersive multisensory experience as a therapeutic modality for participants suffering from post-traumatic stress disorder (PTSD).Methods: In addition to 360-degree videos and corresponding natural sounds, nature smells are also presented by means of a portable ION 2 scent diffusion device attached to an Oculus Quest 2 VR head-mounted display. A 3-week 12-sessions protocol was applied to a sample of 20 participants diagnosed with PTSD.Results and discussion: We report the outcomes seen from a battery of qualitative metrics, including cognitive functioning tests, psychological symptoms, severity of PTSD, and several self-reported questionnaires and heart rate variability (HRV) metrics. Results are compared not only between pre-and post intervention, but also after a 3-month follow-up period. Results suggest a decrease in the severity of PTSD, as well as improvements in processing speed and sustained attention post-intervention, but also sustained decrease in the severity of PTSD and in dissociative tendencies at the 3-month follow-up. Overall, participants rated the experience as highly immersive and produced very mild to no symptoms of cybersickness, thus corroborating the feasibility and usefulness of the proposed multisensory immersive VR tool for reducing PTSD symptoms.
C1 [De Jesus Junior, Belmir Jose; Perreault, Lea; Lopes, Marilia K. S.; Falk, Tiago H.] Univ Quebec, Inst Natl Rech Sci, Montreal, PQ, Canada.
   [Perreault, Lea; Roberge, Marie-Claude] Traumas Cote Nord, Sept iles, PQ, Canada.
   [Oliveira, Alcyr A.] Fed Univ Hlth Sci Porto Alegre, Porto Alegre, RS, Brazil.
C3 University of Quebec; University of Quebec Montreal; Institut national
   de la recherche scientifique (INRS)
RP Junior, BJD; Falk, TH (corresponding author), Univ Quebec, Inst Natl Rech Sci, Montreal, PQ, Canada.
EM belmir.jesus@inrs.ca; tiago.falk@inrs.ca
FU The author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. This work was funded
   partly by an NSERC Discovery grant to TF (RGPIN-2021-03246).
   [RGPIN-2021-03246]; NSERC Discovery grant
FX The author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. This work was funded
   partly by an NSERC Discovery grant to TF (RGPIN-2021-03246).
CR Aiken MP, 2015, VIRTUAL REAL-LONDON, V19, P95, DOI 10.1007/s10055-015-0260-x
   Ashbaugh AR, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161645
   Beard C, 2016, J AFFECT DISORDERS, V193, P267, DOI 10.1016/j.jad.2015.12.075
   Bomyea J, 2012, NEUROPHARMACOLOGY, V62, P607, DOI 10.1016/j.neuropharm.2011.05.028
   Bouchard S., 2011, Journal of Computer and Information Technology, V1, P20
   Carlson E.B., 1993, DISSOCIATION, V6, P16, DOI DOI 10.1177/1073191116645904
   Cassani R., 2018, 2018 10 INT C QUAL M, P1
   Cassani R, 2020, IEEE SYST MAN CYBERN, V6, P20, DOI 10.1109/MSMC.2019.2953627
   Cleophas T.J., 2016, CLIN DATA ANAL POCKE, DOI 10.1007/978-3-319-27104-0_34
   De Jesus B., 2022, P 2 WORKSH MULT EXP
   Emmelkamp PMG, 2021, ANNU REV CLIN PSYCHO, V17, P495, DOI 10.1146/annurev-clinpsy-081219-115923
   Forkus SR, 2023, CLIN PSYCHOL-SCI PR, V30, P110, DOI 10.1037/cps0000111
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Gualtieri CT, 2006, ARCH CLIN NEUROPSYCH, V21, P623, DOI 10.1016/j.acn.2006.05.007
   Halbig A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.837616
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Knaust T, 2022, VIRTUAL REAL-LONDON, V26, P925, DOI 10.1007/s10055-021-00595-2
   Kothgassner OD, 2019, EUR J PSYCHOTRAUMATO, V10, DOI 10.1080/20008198.2019.1654782
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Lee DJ, 2022, PSYCHOL ASSESSMENT, V34, P604, DOI 10.1037/pas0001130
   Littleton AC, 2015, SPORTS HEALTH, V7, P443, DOI 10.1177/1941738115586997
   Lo JC, 2017, J COGN ENG DECIS MAK, V11, P323, DOI 10.1177/1555343417716040
   Lopes MKS, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON METROLOGY FOR EXTENDED REALITY, ARTIFICIAL INTELLIGENCE AND NEURAL ENGINEERING (METROXRAINE), P459, DOI 10.1109/MetroXRAINE54828.2022.9967576
   Marmar C.R., 2004, The peritraumatic dissociative experiences questionnaire
   Mistry D, 2020, PSYCHOL TRAUMA-US, V12, P847, DOI 10.1037/tra0000959
   Noronha H, 2022, INTERACT COMPUT, V33, P353, DOI 10.1093/iwc/iwac004
   Pole N, 2007, PSYCHOL BULL, V133, P725, DOI 10.1037/0033-2909.133.5.725
   Qureshi SU, 2011, J NEUROPSYCH CLIN N, V23, P16, DOI 10.1176/appi.neuropsych.23.1.16
   Ragsdale K.A., 2020, Curr. Treat. Options Psychiatry, V7, P291, DOI [DOI 10.1007/S40501-020-00219-7, 10.1007/s40501-020-00219-7]
   Rauch SAM, 2012, J REHABIL RES DEV, V49, P679, DOI 10.1682/JRRD.2011.08.0152
   Riches S, 2023, SOC PSYCH PSYCH EPID, V58, P989, DOI 10.1007/s00127-022-02417-5
   Rivest-Beauregard M, 2022, PSYCHOL ASSESSMENT, V34, pE26, DOI 10.1037/pas0001099
   Rizzo A, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1414560
   Robillard G., 2002, P 25IEME CONGRES SOC
   Schneider M, 2020, PSYCHOL MED, V50, P1937, DOI 10.1017/S003329172000207X
   Shalev A, 2017, NEW ENGL J MED, V376, P2459, DOI 10.1056/NEJMra1612499
   Taylor S, 2003, J CONSULT CLIN PSYCH, V71, P330, DOI 10.1037/0022-006X.71.2.330
   Weathers F., 1993, INT SOC TRAUM STRESS
   Weathers FW, 2018, PSYCHOL ASSESSMENT, V30, P383, DOI 10.1037/pas0000486
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 40
TC 1
Z9 1
U1 5
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 2
PY 2023
VL 4
AR 1261093
DI 10.3389/frvir.2023.1261093
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA U6ZZ0
UT WOS:001086280300001
OA gold
DA 2024-07-18
ER

PT J
AU Shah, NSK
   Taunk, NK
   Maxwell, R
   Wang, XM
   Hubley, E
   Anamalayil, S
   Trotter, JW
   Li, TR
AF Shah, Nishant K.
   Taunk, Neil K.
   Maxwell, Russell
   Wang, Xingmei
   Hubley, Emily
   Anamalayil, Shibu
   Trotter, Jacob W.
   Li, Taoran
TI Comparison of virtual reality platforms to enhance medical education for
   procedures
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; medical education; procedures; simulation; residency;
   training
ID CERVICAL-CANCER; BRACHYTHERAPY; PROFICIENCY; RESIDENTS
AB Background: Historically, medical education relied on apprentice-based experiences requiring direct observation in patient cases. Simulation-based education has been shown to improve resident confidence but can be time intensive and difficult to coordinate. The COVID-19 pandemic demonstrated the need to develop distributed educational tools. Virtual reality (VR) platform has been shown to improve resident confidence and proficiencies. This pilot study compared educational and cost effectiveness of low-cost cardboard viewer VR (CVVR) and commercially available integrated headset VR (IHVR).Methods and Materials: We created a 2D, 360-degree VR video of an intracavitary brachytherapy case for treatment of cervical cancer. Radiation oncology residents from a single ACGME-accredited training program were recruited and randomized to IHVR or CVVR. Both groups were given unlimited access to their randomized technology. Each resident performed a timed intracavitary procedure on a simulator while five implant quality metrics were recorded. A pre- and post-simulation questionnaire assessed self-confidence, procedural knowledge, and perceived usefulness of VR technology.Results: There were 13 residents, including four post-graduate year (PGY)-2, three PGY-3, two PGY-4, and four PGY-5, in the study. Both VR technologies improved self-perceived overall confidence. Average time required for implant (mean: CVVR - 200 s vs IHVR - 235 s, p = 0.38) and median objective proficiencies of implant quality (5/5 in both group, p = 0.56) were similar. There was no difference between CVVR and IHVR as useful, enjoyable and engaging educational tool. Both groups would recommend the technology to another trainee. IHVR-based program would cost & SIM;33x more than CVVR-based program based on an assessment of US-based programs.Conclusion: CVVR is a cost-effective alternative to a IHVR as a virtual video-based education tool.
C1 [Shah, Nishant K.; Taunk, Neil K.; Maxwell, Russell; Hubley, Emily; Anamalayil, Shibu; Trotter, Jacob W.; Li, Taoran] Univ Penn, Perelman Sch Med, Dept Radiat Oncol, Philadelphia, PA 19104 USA.
   [Wang, Xingmei] Univ Penn, Perelman Sch Med, Dept Biostat, Philadelphia, PA USA.
C3 University of Pennsylvania; University of Pennsylvania
RP Li, TR (corresponding author), Univ Penn, Perelman Sch Med, Dept Radiat Oncol, Philadelphia, PA 19104 USA.
EM Taoran.Li@pennmedicine.upenn.edu
FU Evan McCabe Fund Grant; ACRO Luther Brady Educational Grant
FX This work was supported in part by the Evan McCabe Fund Grant (TL) and
   ACRO Luther Brady Educational Grant (NS).
CR Ahlberg G, 2007, AM J SURG, V193, P797, DOI 10.1016/j.amjsurg.2006.06.050
   Bambakidis NC, 2020, J NEUROSURG, V133, P10, DOI 10.3171/2020.3.JNS20965
   Baniasadi Tayebeh, 2020, Oman Med J, V35, pe125, DOI 10.5001/omj.2020.43
   Boruff JT, 2014, J MED LIBR ASSOC, V102, P22, DOI 10.3163/1536-5050.102.1.006
   Dimopoulos JCA, 2009, RADIOTHER ONCOL, V93, P311, DOI 10.1016/j.radonc.2009.07.001
   Dimopoulos JCA, 2009, INT J RADIAT ONCOL, V75, P56, DOI 10.1016/j.ijrobp.2008.10.033
   Donnelly ED, 2020, BRACHYTHERAPY, V19, P732, DOI 10.1016/j.brachy.2020.09.016
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Gupta DK, 2017, JAMA NEUROL, V74, P1223, DOI 10.1001/jamaneurol.2017.2073
   Han K, 2013, INT J RADIAT ONCOL, V87, P111, DOI 10.1016/j.ijrobp.2013.05.033
   Irvin W, 2003, GYNECOL ONCOL, V90, P113, DOI 10.1016/S0090-8258(03)00230-0
   Katz-Sidlow RJ, 2012, J HOSP MED, V7, P595, DOI 10.1002/jhm.1950
   Khan R, 2019, ENDOSCOPY, V51, P653, DOI 10.1055/a-0894-4400
   Lee MC, 2010, COMPUT EDUC, V54, P506, DOI 10.1016/j.compedu.2009.09.002
   Lorello GR, 2014, BRIT J ANAESTH, V112, P231, DOI 10.1093/bja/aet414
   Lynch B, 2005, RESUSCITATION, V67, P31, DOI 10.1016/j.resuscitation.2005.04.017
   Marcrom SR, 2019, INT J RADIAT ONCOL, V103, P557, DOI 10.1016/j.ijrobp.2018.10.023
   Mesko S, 2020, BRACHYTHERAPY, V19, P738, DOI 10.1016/j.brachy.2020.08.009
   Monaghan AM, 2020, J MED EDUC CURRIC DE, V7, DOI 10.1177/2382120520965255
   National Cancer Institute (NCI), 2016, RAD THER YOU SUPP PE
   Portelli M, 2020, ANN ROY COLL SURG, V102, P672, DOI 10.1308/rcsann.2020.0178
   Pulijala Y, 2018, J ORAL MAXIL SURG, V76, P1065, DOI 10.1016/j.joms.2017.10.002
   Ros M, 2021, ETR&D-EDUC TECH RES, V69, P1529, DOI 10.1007/s11423-021-10003-w
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Stepan K, 2017, INT FORUM ALLERGY RH, V7, P1006, DOI 10.1002/alr.21986
   Taunk NK, 2021, BRACHYTHERAPY, V20, P695, DOI 10.1016/j.brachy.2021.03.003
   Tcha-Tokey K., 2016, Int. J. Virtual Real, V16, P33, DOI DOI 10.20870/IJVR.2016.16.1.2880
   Terry Danielle L, 2018, PRiMER, V2, P18, DOI 10.22454/PRiMER.2018.766371
   Viswanathan AN, 2012, INT J GYNECOL CANCER, V22, P123, DOI 10.1097/IGC.0b013e31823ae3c9
   Zhao S, 2018, BRACHYTHERAPY, V17, P653, DOI 10.1016/j.brachy.2018.03.001
NR 30
TC 2
Z9 2
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 15
PY 2022
VL 3
AR 1000035
DI 10.3389/frvir.2022.1000035
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4ST9
UT WOS:001023188000001
OA gold
DA 2024-07-18
ER

PT J
AU Chassin, T
   Ingensand, J
AF Chassin, Thibaud
   Ingensand, Jens
TI E-guerrilla 3D participation: Approach, implementation, and usability
   study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE participatory sciences; urban planning; urban participatory e-planning;
   3D; virtual geographic environment; e-guerrilla 3D participation
ID PUBLIC-PARTICIPATION; COMMUNITY OPPOSITION; TACTICAL URBANISM;
   VISUALIZATION; GIS; TOOLS; ENGAGEMENT; FRAMEWORK; REALITY; DESIGN
AB Typical urban participatory approaches engage citizens through lengthy sessions far from the area under transformation by an urban project. Several issues result from these settings of involvement including the mobilization of similar individuals, overwhelming participatory codes, or a gap between the affected urban landscape and the location of the session. This study introduces a modern approach that leverages the use of 3D web applications to address some of the critical challenges of popular participatory sessions. The developed approach, named e-guerrilla 3D participation, is based on five dimensions: immediate participation, ease of use, flexibility, place-based engagement, and immersivity. A prototype complying with these five dimensions was implemented in this study. The prototype promotes an in situ engagement where all the users (without distinction) of a public area can explore a future urban project and get involved within minutes. A usability study conducted with 26 expert and non-expert participants investigated the prototype through a fictive scenario. The findings demonstrate a positive outcome in terms of participatory results that are identifiable with the prototype (highlighting the controversial elements of the projects) and encourage feedback collected during a survey and interview. The usability study suggests key aspects that should be considered to improve the design of participatory sessions and their interactive mediums (or tools), such as realism, affordance, incentive, and purpose. The promising participatory approach (and prototype), which was unpacked step-by-step in this study, does not replace typical practices but could help to complement them by reaching a non-selected and broader public; hence leading to the design of more inclusive participatory approaches.
C1 [Chassin, Thibaud] Ecole Polytech Fed Lausanne, Lab Geog Informat Syst LaSIG, Lausanne, Switzerland.
   [Chassin, Thibaud; Ingensand, Jens] Univ Appl Sci & Arts Western Switzerland HEIG VD, Inst Terr Engn Insit, Yverdon, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Chassin, T (corresponding author), Ecole Polytech Fed Lausanne, Lab Geog Informat Syst LaSIG, Lausanne, Switzerland.; Chassin, T (corresponding author), Univ Appl Sci & Arts Western Switzerland HEIG VD, Inst Terr Engn Insit, Yverdon, Switzerland.
EM thibaud.chassin@epfl.ch
OI Chassin, Thibaud/0000-0003-1295-4373; Ingensand,
   Jens/0000-0003-3330-4986
CR Al-Kodmany K, 1999, LANDSCAPE URBAN PLAN, V45, P37, DOI 10.1016/S0169-2046(99)00024-9
   Al-Kodmany K, 2001, J URBAN TECHNOL, V8, P1, DOI 10.1080/106307301316904772
   [Anonymous], 2013, SITUATING ENGAGEMENT
   [Anonymous], 2014, LEARN DISABIL PRACT, DOI DOI 10.7748/LDP2014.03.17.3.36.E1530
   [Anonymous], 2018, NORDIC J SURV REAL E, DOI [DOI 10.30672/NJSR.67846, 10.30672/njsr.67846]
   Appleton K, 2003, LANDSCAPE URBAN PLAN, V65, P117, DOI 10.1016/S0169-2046(02)00245-1
   Babelon I, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10110783
   Basile M., 2010, FLUX, V78, P58, DOI [10.3917/flux.078.0058, DOI 10.3917/FLUX.078.0058]
   Batty M, 1997, FUTURES, V29, P337, DOI 10.1016/S0016-3287(97)00018-9
   Besancon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4727, DOI 10.1145/3025453.3025863
   Bohoj Morten., 2011, Proceedings of the 5th International Conference on Communities and Technologies, P88, DOI DOI 10.1145/2103354.2103367
   Brown G., 2012, URISA Journal, V24, P7
   Brown G, 2020, LOCAL ENVIRON, V25, P85, DOI 10.1080/13549839.2019.1703660
   Brown G, 2014, APPL GEOGR, V48, P42, DOI 10.1016/j.apgeog.2014.01.008
   Bugs G., 2019, CIVIC ENGAGEMENT POL, P177, DOI [10.4018/978-1-5225-7669-3.ch009, DOI 10.4018/978-1-5225-7669-3.CH009]
   Bugs G, 2010, CITIES, V27, P172, DOI 10.1016/j.cities.2009.11.008
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Cariello A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132011482
   Carpini MXD, 2004, ANNU REV POLIT SCI, V7, P315, DOI 10.1146/annurev.polisci.7.121003.091630
   Chassin T., 2021, INT ARCH PHOTOGRAMM, V2021, P353, DOI [10.5194/isprs-archives-XLIII-B4-2021-353-2021, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B4-2021-353-2021]
   Chassin T, 2022, LANDSCAPE URBAN PLAN, V224, DOI 10.1016/j.landurbplan.2022.104432
   Chassin T, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10080563
   Chetelat J., 2005, L MENTS M THODOLOGIQ, DOI [10.5075/EPFL-THESIS-2961, DOI 10.5075/EPFL-THESIS-2961]
   Christophe S, 2020, IVAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 3: IVAPP, P325, DOI 10.5220/0009355703250332
   Coltekin A, 2016, INT ARCH PHOTOGRAMM, V41, P387, DOI 10.5194/isprsarchives-XLI-B2-387-2016
   Courage C., 2013, ENGAGE 32 CITIZENSHI
   Czepkiewicz M, 2018, QUAEST GEOGR, V37, P177, DOI 10.2478/quageo-2018-0033
   de Oliveira AR, 2020, ENVIRON IMPACT ASSES, V83, DOI 10.1016/j.eiar.2020.106413
   Dell N., 2012, CHI 12, DOI [10.1145/2207676.2208589, DOI 10.1145/2207676.2208589]
   Diederichs Frederik, 2020, Virtual, Augmented and Mixed Reality. Design and Interaction. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12190), P3, DOI 10.1007/978-3-030-49695-1_1
   Ertiö TP, 2015, PLAN PRACT RES, V30, P303, DOI 10.1080/02697459.2015.1052942
   Everatt D, 2010, POLITIKON-UK, V37, P223, DOI 10.1080/02589346.2010.522333
   Falco E, 2019, HABITAT INT, V94, DOI 10.1016/j.habitatint.2019.102038
   Foltête JC, 2020, LANDSCAPE URBAN PLAN, V197, DOI 10.1016/j.landurbplan.2020.103756
   Gill L, 2015, COMPUT ENVIRON URBAN, V54, P356, DOI 10.1016/j.compenvurbsys.2015.09.012
   Gore A., 1998, DIGITAL EARTH UNDERS
   Haklay M, 2018, QUAEST GEOGR, V37, P127, DOI 10.2478/quageo-2018-0030
   Hayek UW, 2011, ENVIRON PLANN B, V38, P921, DOI 10.1068/b36113
   Healey P., 1998, TOWN PLAN REV, V69, P1
   Hunter M., 2021, QUT EPRINTS
   Ingensand J., 2018, AGILE 2018
   Innes J. E., 2004, PLANNING THEORY PRAC, V5, P419, DOI [DOI 10.1080/1464935042000293170, https://doi.org/10.1080/1464935042000293170]
   Kahila-Tani M, 2019, LANDSCAPE URBAN PLAN, V186, P45, DOI 10.1016/j.landurbplan.2019.02.019
   Kessels RPC, 2010, AGING NEUROPSYCHOL C, V17, P556, DOI 10.1080/13825585.2010.481354
   Keysers J., 2015, DIGITAL GLOBE REV 20
   Kingston R., 2000, Computers, Environment and Urban Systems, V24, P109, DOI 10.1016/S0198-9715(99)00049-6
   Krämer M, 2015, WEB3D 2015, P188, DOI 10.1145/2775292.2775303
   Lafrance F, 2019, ISPRS INT GEO-INF, V8, DOI 10.3390/ijgi8060253
   Lak A, 2020, GEOFORUM, V115, P54, DOI 10.1016/j.geoforum.2020.07.003
   Lallemand C., 2018, METHODES DESIGN UX 3
   Lin H., 2022, NEW THINKING GISCIEN, DOI [10.1007/978-981-19-3816-0_3, DOI 10.1007/978-981-19-3816-0_3]
   Lin Hui., 2001, Geographic Information Sciences, V7, P1, DOI DOI 10.1080/10824000109480550
   Lokka IE, 2020, CARTOGR GEOGR INF SC, V47, P14, DOI 10.1080/15230406.2019.1595151
   Lokka IE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29029-x
   Lydon MikeAnthony Garcia., 2015, TACTICAL URBANISM SH
   McFee Brian, 2022, Zenodo
   McLain RJ, 2017, J ENVIRON MANAGE, V204, P61, DOI 10.1016/j.jenvman.2017.08.037
   Metze T, 2020, J ENVIRON POL PLAN, V22, P745, DOI 10.1080/1523908X.2020.1798751
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Morgan-Daniel J., 2021, Hypothesis, V33, DOI [10.18060/25262, DOI 10.18060/25262]
   Mossberger K, 2021, INT J E-PLAN RES, V10, P19, DOI 10.4018/IJEPR.20210701.oa2
   Münster S, 2017, PROCEDIA COMPUT SCI, V112, P2391, DOI 10.1016/j.procs.2017.08.102
   Nielsen J., 1994, Guerrilla HCI: Using Discount Usability Engineering to Penetrate the Intimidation Barrier
   Onitsuka K, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093059
   Pánek J, 2018, QUAEST GEOGR, V37, P151, DOI 10.2478/quageo-2018-0031
   Peng ZR, 2001, ENVIRON PLANN B, V28, P889, DOI 10.1068/b2750t
   Pouke M., 2019, 2019 IEEE 5 WORKSH, DOI 10.1109/wevr.2019.8809590
   Ring K., 2020, INTRO CESIUM OSM BUI
   Rinner C, 2001, ENVIRON PLANN B, V28, P847, DOI 10.1068/b2748t
   Rowe G, 2000, SCI TECHNOL HUM VAL, V25, P3, DOI 10.1177/016224390002500101
   Ruming K, 2018, GEOGR RES-AUST, V56, P181, DOI 10.1111/1745-5871.12269
   Ruming K, 2012, GEOGR RES-AUST, V50, P421, DOI 10.1111/j.1745-5871.2012.00751.x
   Schroth O, 2011, FUTURE INTERNET, V3, P204, DOI 10.3390/fi3040204
   Sieber R, 2006, ANN ASSOC AM GEOGR, V96, P491, DOI 10.1111/j.1467-8306.2006.00702.x
   Sieber RE, 2016, ANN AM ASSOC GEOGR, V106, P1030
   Silva P, 2016, ENVIRON PLANN B, V43, P1040, DOI 10.1177/0265813516657340
   Sinclair AJ, 2017, IMPACT ASSESS PROJ A, V35, P148, DOI 10.1080/14615517.2016.1251697
   StatCounter, 2022, DESKT VS MOB VS TABL
   Steiniger S, 2016, URBAN PLAN, V1, P49, DOI 10.17645/up.v1i2.607
   Stevens Q, 2021, URBAN POLICY RES, V39, P262, DOI 10.1080/08111146.2021.1963225
   Talen E, 1999, ENVIRON PLANN B, V26, P533, DOI 10.1068/b260533
   Ugwitz P, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091873
   Voinov A, 2018, INT J DIGIT EARTH, V11, P408, DOI 10.1080/17538947.2017.1365961
   Wobbrock JO, 2008, INT J HUM-COMPUT ST, V66, P857, DOI 10.1016/j.ijhcs.2008.03.004
   WurstleP SanthanavanichT., 2021, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, P123, DOI [10.5194/isprs-archives-XLVI-4-W1-2021-123-2021, DOI 10.5194/ISPRS-ARCHIVES-XLVI-4-W1-2021-123-2021]
   Zaman SR, 2021, P INT COMP SOFTW APP, P338, DOI 10.1109/COMPSAC51774.2021.00055
   Zhang  A., 2017, SPEECH RECOGNITION
NR 87
TC 2
Z9 2
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 25
PY 2022
VL 3
AR 1054252
DI 10.3389/frvir.2022.1054252
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WR4
UT WOS:001023290000001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Pedram, S
   Palmisano, S
   Miellet, S
   Farrelly, M
   Perez, P
AF Pedram, Shiva
   Palmisano, Stephen
   Miellet, Sebastien
   Farrelly, Matthew
   Perez, Pascal
TI Influence of age and industry experience on learning experiences and
   outcomes in virtual reality mines rescue training
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; training; sociodemographic; vocational training; adult
   learning; high risk industry
ID COMPUTER ANXIETY; TECHNOLOGY; OLDER; ATTITUDES; ADULTS
AB This study examined the effects of age and industry expertise on trainees' state of mind before, learning experiences during, and outcomes following virtual reality (VR) mines rescue training. The trainees were 284 mine rescue brigadesmen attending group VR training sessions run by Coal Services NSW. They were aged between 24 and 64 years and had up to 40 years of mines rescue experience. Questionnaire data and learning outcome measures showed that these miners were able to effectively engage with, and learn from, this VR training regardless of their age or mining experience. While the older trainees initially reported higher levels of stress and had less gaming experience, their experiences during VR training were very similar (although reports that the VR technology sometimes did not meet the task requirements did increase with age). Crucially, the perceived learning outcomes of this VR training were unaffected by age or field experience.
C1 [Pedram, Shiva; Perez, Pascal] Univ Wollongong, SMART Infrastructure Facil, Wollongong, NSW, Australia.
   [Palmisano, Stephen; Miellet, Sebastien] Univ Wollongong, Fac Arts, Sch Psychol, Wollongong, NSW, Australia.
   [Farrelly, Matthew] Coal Serv Pty Ltd, Woonona, NSW, Australia.
C3 University of Wollongong; University of Wollongong
RP Pedram, S (corresponding author), Univ Wollongong, SMART Infrastructure Facil, Wollongong, NSW, Australia.
EM spedram@uow.edu.au
RI Miellet, Sebastien/AFL-6215-2022; Palmisano, Stephen/O-1553-2018
OI Miellet, Sebastien/0000-0002-3519-033X; Palmisano,
   Stephen/0000-0002-9140-5681; Pedram, Shiva/0000-0002-5835-4093
CR Arbaugh JB, 2002, MANAGE LEARN, V33, P331, DOI 10.1177/1350507602333003
   Barteit S, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29080
   Berkowsky RW, 2017, INNOV AGING, V1, DOI 10.1093/geroni/igy002
   Bielsa VF, 2021, J PLAST RECONSTR AES, V74, P2372, DOI 10.1016/j.bjps.2021.03.066
   Broady T, 2010, BRIT J EDUC TECHNOL, V41, P473, DOI 10.1111/j.1467-8535.2008.00914.x
   Czaja SJ, 2006, PSYCHOL AGING, V21, P333, DOI 10.1037/0882-7974.21.2.333
   Demirbilek M, 2010, J INF TECHNOL EDUC-R, V9, P235
   Fozard J. L., 2012, AGE COHORT EFFECTS G
   Hauk N, 2018, COMPUT HUM BEHAV, V84, P304, DOI 10.1016/j.chb.2018.01.020
   Hawthorn D, 2007, BEHAV INFORM TECHNOL, V26, P333, DOI 10.1080/01449290601176930
   Heinz M, 2013, J GERONTOL NURS, V39, P42, DOI 10.3928/00989134-20121204-04
   Holden RJ, 2010, J BIOMED INFORM, V43, P159, DOI 10.1016/j.jbi.2009.07.002
   Honey M. L. L., 2009, TEACHING VIRTUAL SPA, P1222
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   IGBARIA M, 1990, BEHAV INFORM TECHNOL, V9, P229, DOI 10.1080/01449299008924239
   Knerr B.W., 2007, Immersive simulation training for the dismounted soldier
   Laguna K, 1997, COMPUT HUM BEHAV, V13, P317, DOI 10.1016/S0747-5632(97)00012-5
   Makransky G, 2019, COMPUT EDUC, V134, P15, DOI 10.1016/j.compedu.2019.02.002
   Mayer RE, 2014, ACKNOWLEDGMENTS DEDI, V59
   Mehrotra Divya, 2021, J Oral Biol Craniofac Res, V11, P486, DOI 10.1016/j.jobcr.2021.06.002
   Morris MG, 2005, IEEE T ENG MANAGE, V52, P69, DOI 10.1109/TEM.2004.839967
   Park SI, 2009, COMPUT EDUC, V52, P649, DOI 10.1016/j.compedu.2008.11.014
   Parnell J.A., 2003, J MANAG EDUC, V27, P431
   Patterson JM, 2010, ACCIDENT ANAL PREV, V42, P1379, DOI 10.1016/j.aap.2010.02.018
   Pedram S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627333
   Pedram S, 2021, VIRTUAL REAL-LONDON, V25, P1071, DOI 10.1007/s10055-021-00514-5
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Peters R.H., 2010, Extracting the Science: A Century of Mining Research, P501
   Renaud K, 2007, BEHAV INFORM TECHNOL, V26, P309, DOI 10.1080/01449290601173770
   Schmitt PJ, 2012, WORLD NEUROSURG, V78, P214, DOI 10.1016/j.wneu.2012.06.014
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Sweller J., 1994, Learning and instruction, P295, DOI DOI 10.1016/0959-4752(94)90003-5
   Syed-Abdul S, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1218-8
   Tichon J., 2011, J HLTH SAFETY RES PR, V3, P33
   Williams A M., 1999, Int J Sport Psychol
NR 35
TC 4
Z9 4
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 14
PY 2022
VL 3
AR 941225
DI 10.3389/frvir.2022.941225
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WS3
UT WOS:001023290900001
OA gold
DA 2024-07-18
ER

PT J
AU Bailey, GS
   Arruda, DG
   Stoffregen, TA
AF Bailey, George S.
   Arruda, Danilo G.
   Stoffregen, Thomas A.
TI Using quantitative data on postural activity to develop methods to
   predict and prevent cybersickness
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cybersickness; virtual reality; postural stability; movement; motion
   sickness; posture
ID INDUCED MOTION SICKNESS; VIRTUAL-REALITY; SEX-DIFFERENCES; BODY SWAY;
   STABILIZATION; FLOW; PERFORMANCE; INSTABILITY; STABILITY; SYMPTOMS
AB In this article, we discuss general approaches to the design of interventions that are intended to overcome the problem of cybersickness among users of head-mounted display (HMD) systems. We note that existing approaches have had limited success, and we suggest that this may be due, in part, to the traditional focus on the design of HMD hardware and content. As an alternative, we argue that cybersickness may have its origins in the user's ability (or inability) to stabilize their own bodies during HMD use. We argue that HMD systems often promote unstable postural control, and that existing approaches to cybersickness intervention are not likely to promote improved stability. We argue that successful cybersickness interventions will be designed to promote stability in the control of the body during HMD use. Our approach motivates new types of interventions; we describe several possible directions for the development of such interventions. We conclude with a discussion of new research that will be required to permit our approach to lead to interventions that can be implemented by HMD designers.
C1 [Bailey, George S.; Arruda, Danilo G.; Stoffregen, Thomas A.] Univ Minnesota, Sch Kinesiol, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Stoffregen, TA (corresponding author), Univ Minnesota, Sch Kinesiol, Minneapolis, MN 55455 USA.
EM tas@umn.edu
FU NSF [1901423]; CHS: Medium: Prediction, Early Detection, and Mitigation
   of Virtual Reality Simulator Sickness
FX Preparation of this article was supported by NSF-1901423, CHS: Medium:
   Prediction, Early Detection, and Mitigation of Virtual Reality Simulator
   Sickness.
CR Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   Akizuki H, 2005, NEUROSCI LETT, V379, P23, DOI 10.1016/j.neulet.2004.12.041
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Bala P., 2018, IEEE INT S MIX AUGM, DOI [10.1109/ISMARAdjunct.2018.00077, DOI 10.1109/ISMARADJUNCT.2018.00077]
   Balasubramaniam R, 2000, GAIT POSTURE, V11, P12, DOI 10.1016/S0966-6362(99)00051-X
   Bonato F, 2015, MIL MED, V180, P1268, DOI 10.7205/MILMED-D-14-00424
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   boyd D., 2014, Is the Oculus Rift sexist?
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P1068, DOI 10.1109/TVCG.2011.274
   Budhiraja Pulkit., 2017, Rotation Blurring: Use of Artificial Blurring to Reduce Cybersickness in Virtual Reality First Person Shooters
   Burns C. M., 2004, ECOLOGICAL INTERFACE
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Chang CH, 2021, HUM MOVEMENT SCI, V78, DOI 10.1016/j.humov.2021.102832
   Chang CH, 2017, AEROSP MED HUM PERF, V88, P985, DOI 10.3357/AMHP.4893.2017
   Chang CH, 2012, EXP BRAIN RES, V217, P299, DOI 10.1007/s00221-011-2993-4
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chardonnet J.-R., 2015, INT C ART REAL TEL K, P9
   Chattha UA, 2020, IEEE ACCESS, V8, P130486, DOI 10.1109/ACCESS.2020.3007076
   Chen YC, 2012, ECOL PSYCHOL, V24, P279, DOI 10.1080/10407413.2012.726181
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cook HE, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01901
   Curry C, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.581132
   Curry C, 2020, ERGONOMICS, V63, P1502, DOI 10.1080/00140139.2020.1808713
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   D'Amour S, 2017, EXP BRAIN RES, V235, P2811, DOI 10.1007/s00221-017-5009-1
   Dennison M, 2019, PROC SPIE, V11006, DOI 10.1117/12.2519085
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   DiZio P., 1997, P RTO HFM WORKSH
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Dorado J. L., 2014, IEEE S 3D US INT
   Duh H. B.-L., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P85, DOI 10.1145/365024.365051
   Farmani Y, 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Flach J. M., 2018, GLOBAL PERSPECTIVES
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   GIBSON JAMES J., 1966
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Groth C., 2021, 2021 IEEE C VIRT REA
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   Hancock P. A., 2018, LOCAL APPL ECOLOGICA
   Jasper A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582108
   Jin WN, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P382, DOI 10.1109/GEM.2018.8516469
   Kemeny A., 2020, Virtual reality, augmented reality, and simulators
   Keshavarz B, 2017, J EXP PSYCHOL-APPL, V23, P85, DOI 10.1037/xap0000107
   Keshavarz B, 2012, PRESENCE-TELEOP VIRT, V21, P213, DOI 10.1162/PRES_a_00102
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim S, 2018, J SOC INF DISPLAY, V26, P376, DOI 10.1002/jsid.669
   Kim YY, 2008, PRESENCE-TELEOP VIRT, V17, P1, DOI 10.1162/pres.17.1.1
   Koslucher F, 2016, EXP BRAIN RES, V234, P2709, DOI 10.1007/s00221-016-4675-8
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Koslucher F, 2015, AEROSP MED HUM PERF, V86, P787, DOI 10.3357/AMHP.4243.2015
   Lamb S, 2013, J WIND ENG IND AEROD, V119, P1, DOI 10.1016/j.jweia.2013.05.004
   LAWTHER A, 1986, ERGONOMICS, V29, P535, DOI 10.1080/00140138608968289
   Lee D. N., 1975, Journal of Human Movement Studies, V1, P87, DOI DOI 10.3758/BF03199297
   LEE DN, 1974, PERCEPT PSYCHOPHYS, V15, P529, DOI 10.3758/BF03199297
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Li RX, 2018, EXP BRAIN RES, V236, P1631, DOI 10.1007/s00221-018-5246-y
   Liao CY, 2020, IEEE ACCESS, V8, P126784, DOI 10.1109/ACCESS.2020.3008165
   Lin YX, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419984
   Maltoni D., 2009, HDB FINGERPRINT IDEN
   Matthis JS, 2017, P NATL ACAD SCI USA, V114, pE6720, DOI 10.1073/pnas.1611699114
   Mayo AM, 2011, PSYCHOL SCI, V22, P118, DOI 10.1177/0956797610392927
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Mouzat A, 2004, NEUROSCI LETT, V365, P79, DOI 10.1016/j.neulet.2004.04.062
   Munafo J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166900
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Munafo J, 2016, EXP BRAIN RES, V234, P2721, DOI 10.1007/s00221-016-4676-7
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Nishiike S, 2013, J MED INVESTIG, V60, P236
   Norouzi N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225162
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   Plouzeau J., 2015, P INT C ARTIFICIAL R, P1
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   Prothero JD, 1999, AVIAT SPACE ENVIR MD, V70, P277
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riley MA, 1999, HUM MOVEMENT SCI, V18, P795, DOI 10.1016/S0167-9457(99)00041-X
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Serres JR, 2017, ARTHROPOD STRUCT DEV, V46, P703, DOI 10.1016/j.asd.2017.06.003
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Slowinski P, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2015.1093
   Smart L.J., 2020, PERCEPTION INFORM DE, P174
   Smart LJ, 2023, HUM FACTORS, V65, P1830, DOI 10.1177/00187208211059623
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stevens SC, 2002, MAR TECHNOL SNAME N, V39, P29
   STOFFREGEN T A, 1991, Ecological Psychology, V3, P159, DOI 10.1207/s15326969eco0303_1
   Stoffregen T.A., 2006, VIRTUAL REAL-LONDON, V10, P4, DOI [DOI 10.1007/S10055-006-0025-7, 10.1007/s10055-006-0025-7]
   STOFFREGEN TA, 1987, PERCEPTION, V16, P113, DOI 10.1068/p160113
   STOFFREGEN TA, 1985, J EXP PSYCHOL HUMAN, V11, P554, DOI 10.1037/0096-1523.11.5.554
   Stoffregen TA, 2001, BEHAV BRAIN SCI, V24, P195, DOI 10.1017/S0140525X01003946
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 2000, HUM MOVEMENT SCI, V19, P203, DOI 10.1016/S0167-9457(00)00009-9
   Stoffregen TA, 1999, J EXP PSYCHOL HUMAN, V25, P1641
   STOFFREGEN TA, 1988, PSYCHOL REV, V95, P3, DOI 10.1037/0033-295X.95.1.3
   Stoffregen TA., 2011, Sci Motricite, V74, P19, DOI [10.1051/sm/2011111, DOI 10.1051/SM/2011111]
   Stoffregen TA, 2008, HUM FACTORS, V50, P322, DOI 10.1518/001872008X250755
   Stoffregen TA, 2007, J MOTOR BEHAV, V39, P126, DOI 10.3200/JMBR.39.2.126-138
   Stoffregen TA, 2006, ECOL PSYCHOL, V18, P191, DOI 10.1207/s15326969eco1803_3
   Stoffregen TA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187120
   Stoffregen TA, 2017, ECOL PSYCHOL, V29, P165, DOI 10.1080/10407413.2017.1331116
   Stoffregen TA, 2014, EXP BRAIN RES, V232, P1389, DOI 10.1007/s00221-014-3859-3
   Stoffregen TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066949
   Stoffregen TA, 2010, ECOL PSYCHOL, V22, P169, DOI 10.1080/10407413.2010.496645
   Streit M, 2007, PSYCHON B REV, V14, P1001, DOI 10.3758/BF03194135
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Thorp S, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6050031
   Turner M, 1999, ERGONOMICS, V42, P444, DOI 10.1080/001401399185586
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Walter HJ, 2019, HUM MOVEMENT SCI, V64, P389, DOI 10.1016/j.humov.2019.03.006
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Widyanti A, 2022, VIRTUAL REAL-LONDON, V26, P631, DOI 10.1007/s10055-021-00525-2
   Wienrich C., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications, P1, DOI [DOI 10.1109/VS-GAMES.2018.8493408, DOI 10.1109/VS-GAMES.2018, 10.1109/VS-Games.2018.8493408]
   Win KN, 2020, FUTURE GENER COMP SY, V110, P758, DOI 10.1016/j.future.2019.10.019
   Wu F, 2021, STUD APPL MATH, V146, P730, DOI 10.1111/sapm.12365
   Zielasko D., 2018, P IEEE 4 WORKSH EV V
   Zielasko D., 2017, P IEEE VIS WORKSH IM
NR 133
TC 3
Z9 4
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 10
PY 2022
VL 3
AR 1001080
DI 10.3389/frvir.2022.1001080
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XB1
UT WOS:001023299700001
OA gold
DA 2024-07-18
ER

PT J
AU Brelet, L
   Gaffary, Y
AF Brelet, Lisa
   Gaffary, Yoren
TI Stress reduction interventions: A scoping review to explore progress
   toward use of haptic feedback in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE stress reduction; relaxation techniques; meditation techniques; virtual
   reality; tactile stimulation; multisensorial approach
ID RELAXATION INTERVENTIONS; ENHANCED RELAXATION; ANXIETY DISORDERS;
   DEPRESSION; MINDFULNESS; QUESTIONNAIRE; METAANALYSIS; STIMULATION;
   OUTCOMES; THERAPY
AB With the objective of providing scientific guidance for the development of a multisensory virtual reality (VR) relaxation device using haptic stimulation, the present review focuses on analysis of existing traditional and VR-based stress reduction interventions as well as their relevant measures. Two primary methods of stress reduction are explored: relaxation techniques and meditation techniques. Relaxation techniques enable the practitioner to achieve a tension-free state through control of and reduction in physiological activity. Meditation techniques also induce a relaxation response, but can additionally increase sustained attention to the present moment, to one's own bodily sensations, emotions, tensions, thoughts, etc., or to an object, without judgement or adherence to a particular perspective. The limitations of traditional techniques are also noted, including the time required for training or mastery and the need for visualization efforts, and the benefits of VR-based relaxation techniques for the user are explored: these include the reduction of negative emotions, stress, anxiety, depression, and pain, as well as improved relaxation and positive affect. Particular attention is paid to the multisensorial approach made possible by VR. However, while it has been known for decades that tactile stimulation is very efficient to relax users, reduce stress, and induce positive emotions, tactile stimuli are currently under-exploited in VR-based stress reduction interventions. This review focuses specifically on touch and its beneficial effects on stress and affect. Finally, we discuss and provide forward-looking perspectives on the present and future use of tactile stimulation as a component of VR tools designed to reduce stress.
C1 [Brelet, Lisa] Jeolis Solut, R&D Dept Hlth, Clermont Ferrand, France.
   [Gaffary, Yoren] Jeolis Solut, R&D Dept Virtual & Augmented Real, Lille, France.
RP Brelet, L (corresponding author), Jeolis Solut, R&D Dept Hlth, Clermont Ferrand, France.; Gaffary, Y (corresponding author), Jeolis Solut, R&D Dept Virtual & Augmented Real, Lille, France.
EM lisa.brelet@lojelis.com; yoren.gaffary@lojelis.com
FU Jeolis Solutions
FX This research received funding by Jeolis Solutions. The funder was not
   involved in the study design, collection, analysis, interpretation of
   data, the writing of this article or the decision to submit it for
   publication. All authors declare no other competing interests.
CR Andersen T, 2017, P IEEE VIRT REAL ANN, P343, DOI 10.1109/VR.2017.7892317
   [Anonymous], 2019, STRESS AM STRESS CUR
   [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI DOI 10.1371/JOURNAL.PMED.1000097
   Aschbacher K, 2013, PSYCHONEUROENDOCRINO, V38, P1698, DOI 10.1016/j.psyneuen.2013.02.004
   Baer RA, 2006, ASSESSMENT, V13, P27, DOI 10.1177/1073191105283504
   Baer RA, 2008, ASSESSMENT, V15, P329, DOI 10.1177/1073191107313003
   Ban YK, 2022, FRONT COMP SCI-SWITZ, V4, DOI 10.3389/fcomp.2022.770701
   Bandelow B, 2015, DIALOGUES CLIN NEURO, V17, P327
   BECK AT, 1988, CLIN PSYCHOL REV, V8, P77, DOI 10.1016/0272-7358(88)90050-5
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Brown KW, 2003, J PERS SOC PSYCHOL, V84, P822, DOI 10.1037/0022-3514.84.4.822
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Chiesa A, 2009, J ALTERN COMPLEM MED, V15, P593, DOI 10.1089/acm.2008.0495
   Choi KY, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451602
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   CROWNE DP, 1960, J CONSULT PSYCHOL, V24, P349, DOI 10.1037/h0047358
   da Costa RT, 2018, REV BRAS PSIQUIATR, V40, P192
   de Witte M, 2020, HEALTH PSYCHOL REV, V14, P294, DOI 10.1080/17437199.2019.1627897
   Derogatis L., 1993, Brief Symptoms Inventory (BSI) 19 administration, scoring, and procedures manuel
   Derogatis L R, 1987, Adv Psychosom Med, V17, P30
   Dierolf AM, 2018, NEUROPSYCHOLOGIA, V119, P434, DOI 10.1016/j.neuropsychologia.2018.08.020
   Dijk Esko O., 2013, International Journal of Autonomous and Adaptive Communications Systems, V6, P324
   Ekman P, 2002, FACIAL ACTION CODING
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Garfin DR, 2018, J PSYCHOSOM RES, V112, P107, DOI 10.1016/j.jpsychores.2018.05.017
   Giannakakis G, 2017, BIOMED SIGNAL PROCES, V31, P89, DOI 10.1016/j.bspc.2016.06.020
   Gong MM, 2020, J AFFECT DISORDERS, V274, P1028, DOI 10.1016/j.jad.2020.05.118
   Gorini A, 2010, STUD HEALTH TECHNOL, V154, P39, DOI 10.3233/978-1-60750-561-7-39
   Gorska G., 2020, USE VIRTUAL REALITY, P87
   Greene S, 2016, IEEE CONSUM ELECTR M, V5, P44, DOI 10.1109/MCE.2016.2590178
   Gu GX, 2017, LECT NOTES ARTIF INT, V10512, P176, DOI 10.1007/978-3-319-67615-9_16
   HAMILTON M, 1959, BRIT J MED PSYCHOL, V32, P50, DOI 10.1111/j.2044-8341.1959.tb00467.x
   Henricson Maria, 2008, Complement Ther Clin Pract, V14, P244, DOI 10.1016/j.ctcp.2008.03.003
   Huhtela OS, 2020, J ORAL REHABIL, V47, P123, DOI 10.1111/joor.12884
   Jafari H, 2017, PAIN, V158, P995, DOI 10.1097/j.pain.0000000000000865
   Janssen M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191332
   Kaminska D, 2020, IEEE ACCESS, V8, P200351, DOI 10.1109/ACCESS.2020.3035540
   Kanji N, 2000, COMPLEMENT THER MED, V8, P106, DOI 10.1054/ctim.2000.0354
   Kelling C., 2016, Proceedings of the 20th International Academic Mindtrek Conference, P130, DOI DOI 10.1145/2994310.2994368
   Kim HS, 2018, ARCH PSYCHIAT NURS, V32, P278, DOI 10.1016/j.apnu.2017.11.015
   Kim YI, 2019, PSYCHIAT INVEST, V16, P167, DOI 10.30773/pi.2018.12.25.1
   Klainin-Yobas P, 2015, AGING MENT HEALTH, V19, P1043, DOI 10.1080/13607863.2014.997191
   Kwekkeboom KL, 2006, J NURS SCHOLARSHIP, V38, P269, DOI 10.1111/j.1547-5069.2006.00113.x
   Leitch S, 2019, INT J QUAL STUD HEAL, V14, DOI 10.1080/17482631.2019.1690091
   Liljencrantz J, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00037
   Lindner P, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00132
   Lovibond SH., 1995, Manual for the depression anxiety and stress scales (DASS21), V2nd ed, P1
   Mahalil I, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGY AND TECHNOPRENEURSHIP (ICE2T), P295, DOI 10.1109/ICE2T.2014.7006265
   Manseur A., 2019, ADV ANIM VET SCI, V7, P1113, DOI [10.17582/journal.aavs/2019/7.12.1113.1119, DOI 10.17582/JOURNAL.AAVS/2019/7.12.1113.1119]
   McGowan J, 2006, NEW ZEAL J PSYCHOL, V35, P92
   McLoughlin E, 2021, PSYCHOL SPORT EXERC, V52, DOI 10.1016/j.psychsport.2020.101823
   Mehta M., 2018, International Journal of Research Foundation of Hospital and Healthcare Administration, V6, P6, DOI [DOI 10.5005/JP-JOURNALS-10035-1084, DOI 10.5005/JP-JOURNALS-10071-23949, 10.5005/jp-journals-10035-1084]
   Mental Health Foundation, 2021, MENT HLTH STAT STRES
   Montero-Marin J, 2019, PSYCHOL MED, V49, P2118, DOI 10.1017/S0033291719001600
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Orme-Johnson DW, 2014, J ALTERN COMPLEM MED, V20, P330, DOI 10.1089/acm.2013.0204
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   Pascoe MC, 2020, INT J ADOLESC YOUTH, V25, P104, DOI 10.1080/02673843.2019.1596823
   Pascoe MC, 2015, J PSYCHIATR RES, V68, P270, DOI 10.1016/j.jpsychires.2015.07.013
   Patel M. N., 2019, INT JOUR PSYCH NURS, V5, P17, DOI [10.5958/2395-180x.2019.00022.7, DOI 10.5958/2395-180X.2019.00022.7]
   Pedersen K, 2018, BMJ SUPPORT PALLIAT, V8, P30, DOI 10.1136/bmjspcare-2017-001421
   Perhakaran G, 2016, SMART INNOV SYST TEC, V45, P365, DOI 10.1007/978-3-319-23024-5_33
   Quagliato LA, 2019, J PSYCHOPHARMACOL, V33, P1340, DOI 10.1177/0269881119859372
   Reddy K.J., 2018, BIOMED PHARMACOL J, V11, DOI [DOI 10.13005/bpj/1404, 10.13005/bpj/1404]
   Ritchie H., 2018, PLASTIC POLLUTION
   Salari N, 2020, GLOBALIZATION HEALTH, V16, DOI 10.1186/s12992-020-00589-w
   Sandi C, 2013, WIRES COGN SCI, V4, P245, DOI 10.1002/wcs.1222
   Satistics Canada, 2020, CAN MENT HLTH COVID, P1
   Scates D, 2020, ENVIRON BEHAV, V52, P895, DOI 10.1177/0013916520916259
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   SEAY B, 1964, J ABNORM SOC PSYCH, V69, P345, DOI 10.1037/h0040539
   Seo E, 2018, COMPLEMENT THER MED, V39, P62, DOI 10.1016/j.ctim.2018.05.005
   Serrano B, 2016, COMPUT HUM BEHAV, V55, P1, DOI 10.1016/j.chb.2015.08.007
   Sethi K., 2019, TELKOMNIKA, V17, P1539, DOI [10.12928/TELKOMNIKA.V17I3.9719, 10.12928/TELKOMNIKA.v17i3.9719, DOI 10.12928/TELKOMNIKA.V17I3.9719]
   Setiawan A, 2019, INT J EMERG TECHNOL, V14, P34, DOI 10.3991/ijet.v14i01.8944
   Shahsavarani A.M., 2015, INT J MEDICAL REV, V2, P230
   Sharma N, 2012, COMPUT METH PROG BIO, V108, P1287, DOI 10.1016/j.cmpb.2012.07.003
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slavich GM, 2016, TEACH PSYCHOL, V43, P346, DOI 10.1177/0098628316662768
   Slevin E, 1999, J CLIN NURS, V8, P48, DOI 10.1046/j.1365-2702.1999.00211.x
   Smith JC, 2000, PSYCHOL REP, V86, P1201, DOI 10.2466/PR0.86.3.1201-1208
   Smith M., 2020, ANXIETY MEDICATION
   Soares MC, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1547
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Stanko-Kaczmarek M, 2016, CREATIVITY RES J, V28, P283, DOI 10.1080/10400419.2016.1189769
   Steptoe A, 2013, ANNU REV PUBL HEALTH, V34, P337, DOI 10.1146/annurev-publhealth-031912-114452
   Stetz MC, 2011, MIL MED, V176, P1065, DOI 10.7205/MILMED-D-10-00393
   Tcha-Tokey K, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927955
   Turna J, 2021, J PSYCHIATR RES, V137, P96, DOI 10.1016/j.jpsychires.2021.02.059
   Turner AI, 2020, PSYCHONEUROENDOCRINO, V114, DOI 10.1016/j.psyneuen.2020.104599
   Ueoka R, 2018, LECT NOTES COMPUT SC, V10904, P436, DOI 10.1007/978-3-319-92043-6_37
   Vailland G., 2020, ACM IEEE INT C HUM R
   van Oers HJJ, 1998, J NEUROSCI, V18, P10171
   Villani D., 2014, Interacting with Presence: HCI and the Sense of Presence in Computer-mediated Environments, P139, DOI [DOI 10.2478/9783110409697, 10.2478/9783110409697]
   Yaribeygi H, 2017, EXCLI J, V16, P1057, DOI 10.17179/excli2017-480
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 96
TC 0
Z9 0
U1 2
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 3
PY 2022
VL 3
AR 900970
DI 10.3389/frvir.2022.900970
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RZ7
UT WOS:001023167700001
OA gold
DA 2024-07-18
ER

PT J
AU Kim, G
   Okamoto, S
   Akiyama, Y
   Yamada, Y
AF Kim, Giryeon
   Okamoto, Shogo
   Akiyama, Yasuhiro
   Yamada, Youji
TI Weight illusion by presenting vibration to the fingertip
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE fingertips; haptics; threshold; vibration; weight illusion
ID MUSCLE; SIZE; SKIN; PERCEPTION; SENSATIONS; RESPONSES; HAND
AB It is difficult for humans to perceive weight accurately, because the perception of weight is produced by the process of multisensory integration. This implies that, by manipulating certain factors, the weight of an object could be perceived differently from the actual weight. Here, the effects of vibration on weight perception were investigated using behavioral tests and questionnaires. As a behavioral test, from a number of identically appearing non-vibrating boxes of different weights, participants had to select a box that they perceived to be of the same weight as a vibrating box. They were also asked whether vibration affected the perceived weight of the box. Even though they reported that vibration created an illusion of weight, the results of the behavioral test did not show a statistically significant effect of vibration on perceived weight. Furthermore, we investigated how the frequency of vibration affected the illusion and found that the weight illusion requires smaller acceleration of vibration at lower frequencies, such as 30 Hz. The illusion was more intense at lower frequencies than at higher frequencies, such as 200 and 300 Hz. Thus, this study demonstrated that vibrotactile stimuli presented to the fingertips produce a weight illusion: vibrating objects are perceived to feel heavier. Even though the principles of this illusion are still unknown, the effect is concrete, and our approach allows easy implementation in virtual reality applications.
C1 [Kim, Giryeon; Okamoto, Shogo; Akiyama, Yasuhiro; Yamada, Youji] Nagoya Univ, Dept Mech Syst Engn, Nagoya, Japan.
   [Okamoto, Shogo] Tokyo Metropolitan Univ, Dept Comp Sci, Hachioji, Japan.
C3 Nagoya University; Tokyo Metropolitan University
RP Kim, G (corresponding author), Nagoya Univ, Dept Mech Syst Engn, Nagoya, Japan.
EM kim.giryeon.y2@s.mail.nagoya-u.ac.jp
FU MEXT Kakenhi [21H05819]; Grants-in-Aid for Scientific Research
   [22KJ1587, 21H05819] Funding Source: KAKEN
FX Funding This study was in part supported by MEXT Kakenhi #21H05819.
CR Amemiya T, 2008, IEEE T HAPTICS, V1, P9, DOI [10.1109/TOH.2008.5, 10.1109/ToH.2008.5]
   [Anonymous], 1891, Archiv Physiol Norm Pathol
   BOLANOWSKI SJ, 1988, J ACOUST SOC AM, V84, P1680, DOI 10.1121/1.397184
   Brisben AJ, 1999, J NEUROPHYSIOL, V81, P1548, DOI 10.1152/jn.1999.81.4.1548
   BRODIE EE, 1984, PERCEPT PSYCHOPHYS, V36, P477, DOI 10.3758/BF03207502
   BURKE D, 1976, J PHYSIOL-LONDON, V261, P673, DOI 10.1113/jphysiol.1976.sp011580
   Cardinale M, 2003, J STRENGTH COND RES, V17, P621
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   Culbertson H, 2016, IEEE HAPTICS SYM, P27, DOI 10.1109/HAPTICS.2016.7463151
   Ellis RR, 1999, PERCEPT PSYCHOPHYS, V61, P1564, DOI 10.3758/BF03213118
   ENOKA RM, 1992, J APPL PHYSIOL, V72, P1631, DOI 10.1152/jappl.1992.72.5.1631
   Flanagan JR, 2000, NAT NEUROSCI, V3, P737, DOI 10.1038/76701
   GANDEVIA SC, 1981, CLIN SCI, V60, P463, DOI 10.1042/cs0600463
   GOODWIN GM, 1972, SCIENCE, V175, P1382, DOI 10.1126/science.175.4028.1382
   Grandy MS, 2006, J NEUROPHYSIOL, V95, P3887, DOI 10.1152/jn.00851.2005
   Guinan A. L., 2012, 2012 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2012), P101, DOI 10.1109/HAVE.2012.6374430
   Guinan AL, 2014, IEEE HAPTICS SYM, P277, DOI 10.1109/HAPTICS.2014.6775467
   Hiramatsu Y, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138506
   Ho HN, 2014, SCI REP-UK, V4, DOI 10.1038/srep05527
   Johansson RS, 2004, NAT NEUROSCI, V7, P170, DOI 10.1038/nn1177
   JOHANSSON RS, 1984, EXP BRAIN RES, V56, P550
   Jones LA, 2018, IEEE HAPTICS SYM, P307, DOI 10.1109/HAPTICS.2018.8357193
   Kamikawa Yasuhisa, 2018, IEEE Robotics and Automation Letters, V3, P2174, DOI 10.1109/LRA.2018.2810940
   Martin BJ, 1997, EUR J APPL PHYSIOL, V75, P504, DOI 10.1007/s004210050196
   Matsui K, 2014, IEEE T HAPTICS, V7, P78, DOI 10.1109/TOH.2013.71
   MCCLOSKE.DI, 1974, EXP NEUROL, V42, P220, DOI 10.1016/0014-4886(74)90019-3
   Minamizawa Kouta, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P257, DOI 10.1109/HAPTIC.2010.5444646
   Minamizawa K, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P367
   Nagano H., 2015, HAPTIC INTERACT, V277, P17, DOI [10.1007/978-4-431-55690-9_4, DOI 10.1007/978-4-431-55690-9_4]
   Okamoto S, 2011, IEEE T HAPTICS, V4, P307, DOI [10.1109/TOH.2011.16, 10.1109/ToH.2011.16]
   Park J, 2018, IEEE T HAPTICS, V11, P518, DOI 10.1109/TOH.2018.2854721
   RAJ DV, 1985, BRAIN, V108, P95, DOI 10.1093/brain/108.1.95
   ROSS HE, 1987, Q J EXP PSYCHOL-A, V39, P77, DOI 10.1080/02724988743000042
   ROSS HE, 1981, PERCEPTION, V10, P319, DOI 10.1068/p100319
   ROSS HE, 1969, Q J EXP PSYCHOL, V21, P346, DOI 10.1080/14640746908400230
   Shadmehr R, 2010, ANNU REV NEUROSCI, V33, P89, DOI 10.1146/annurev-neuro-060909-153135
   Tanabe T, 2016, IEEE HAPTICS SYM, P21, DOI 10.1109/HAPTICS.2016.7463150
   van Beek FE, 2021, IEEE T HAPTICS, V14, P20, DOI 10.1109/TOH.2020.3009599
   Walker P, 2010, EXP PSYCHOL, V57, P462, DOI 10.1027/1618-3169/a000057
   Warden CJ, 1926, AM J PSYCHOL, V37, P398, DOI 10.2307/1413626
   Zaidell LN, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0085247
NR 41
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 15
PY 2022
VL 3
AR 797993
DI 10.3389/frvir.2022.797993
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0IG1
UT WOS:001020170100001
OA gold
DA 2024-07-18
ER

PT J
AU Tarrant, J
   Jackson, R
   Viczko, J
AF Tarrant, Jeff
   Jackson, Ray
   Viczko, Jeremy
TI A Feasibility Test of a Brief Mobile Virtual Reality Meditation for
   Frontline Healthcare Workers in a Hospital Setting
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; meditation; neurofeedback; mental health; apps and
   smartphones; Mindfulness; Body Scan
ID MENTAL-HEALTH; COGNITIVE THERAPY; EXPOSURE THERAPY; STRESS; ANXIETY;
   NEUROFEEDBACK; METAANALYSIS; TECHNOLOGY; PREVENTION; PSYCHOSIS
AB The purpose of this study was to examine whether a virtual reality plus neurofeedback (VR+NF) meditation experience (experimental condition) was more effective than a standard guided audio-only meditation (control condition) in improving mood in one hundred healthcare workers. Data collection occurred in a hospital setting between October, 2020 and March, 2021 at the height of the COVID-19 pandemic. Participants were alternately assigned to one of the two conditions. Before and after the meditation experience, participants completed the Brunel Mood Scale. Results indicated that both groups showed a similar and significant decrease in Anger, Tension, and Depression. On scales measuring Vigor, Fatigue, and Confusion, the VR+NF group showed decreases, while the audio-only group showed no significant change. The VR+NF group showed significant increases on the Calmness and Happiness scales, which did not change significantly in the audio-only group. These results suggest that the addition of VR and neurofeedback may increase the positive outcomes associated with standard audio-guided meditation. These increased benefits may be due to the sense of presence intrinsic to VR, the inclusion of nature-based scenes in the VR experience, as well as the increased self-awareness created by the addition of neurofeedback. As the pre and post measures take place within one 50-min session, further studies assessing the longer-term changes are needed.
C1 [Tarrant, Jeff; Jackson, Ray] NeuroMeditat Inst, Eugene, OR 97401 USA.
   [Viczko, Jeremy] Univ Victoria, Dept Psychol, Victoria, BC, Canada.
C3 University of Victoria
RP Jackson, R (corresponding author), NeuroMeditat Inst, Eugene, OR 97401 USA.
EM info@neuromeditationinstitute.com
FU GSK Consumer Healthcare
FX GSK Consumer Healthcare.
CR Alharbi J, 2020, J CLIN NURS, V29, P2762, DOI 10.1111/jocn.15314
   American Psychiatric Association, 2017, MENT HLTH DISP DIV P
   Asmundson GJG, 2020, J ANXIETY DISORD, V71, DOI 10.1016/j.janxdis.2020.102211
   Athanas AJ, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/12617
   Baniasadi Tayebeh, 2020, Oman Med J, V35, pe125, DOI 10.5001/omj.2020.43
   Bao YP, 2020, LANCET, V395, pE37, DOI 10.1016/S0140-6736(20)30309-3
   Berger AM, 2018, NEUROSCIENCE, V378, P189, DOI 10.1016/j.neuroscience.2017.06.007
   Botella C, 2009, PSYCHNOLOGY J, V7, P77
   Brandmeyer T, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00246
   Brandmeyer T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00688
   Çakiroglu AA, 2020, INT J APPL EXERC PHY, V9, P126
   Carissoli C, 2015, CYBERPSYCH BEH SOC N, V18, P46, DOI 10.1089/cyber.2014.0062
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chirico F, 2021, BJPSYCH INT, V18, DOI 10.1192/bji.2020.39
   Coulon SM, 2016, AM J PREV MED, V51, P95, DOI 10.1016/j.amepre.2016.01.026
   Cullen W, 2020, QJM-INT J MED, V113, P311, DOI 10.1093/qjmed/hcaa110
   De Hert S, 2020, LOCAL REG ANESTH, V13, P171, DOI 10.2147/LRA.S240564
   Döllinger N, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.644683
   Eichenberg C, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P1, DOI 10.5772/2607
   Evans S, 2018, MINDFULNESS, V9, P1280, DOI 10.1007/s12671-017-0872-1
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fergusson DM, 2014, JAMA PSYCHIAT, V71, P1025, DOI 10.1001/jamapsychiatry.2014.652
   Flavián C, 2021, J BUS RES, V123, P289, DOI 10.1016/j.jbusres.2020.09.036
   Flett JAM, 2019, MINDFULNESS, V10, P863, DOI 10.1007/s12671-018-1050-9
   Fox KCR, 2016, NEUROSCI BIOBEHAV R, V65, P208, DOI 10.1016/j.neubiorev.2016.03.021
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Garrison KA, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00440
   Gillani NB, 2001, J CLIN PSYCHOL, V57, P839, DOI 10.1002/jclp.1053
   Gorini A, 2010, STUD HEALTH TECHNOL, V154, P39, DOI 10.3233/978-1-60750-561-7-39
   Goyal M, 2014, JAMA INTERN MED, V174, P357, DOI 10.1001/jamainternmed.2013.13018
   Graffigna G, 2013, ARCH PHYS MED REHAB, V94, P2034, DOI 10.1016/j.apmr.2013.04.024
   Greenberg, 2020, Treating Complex Trauma, P191, DOI DOI 10.1007/978-3-030-45285-8_10
   Hammond DC, 2005, CHILD ADOL PSYCH CL, V14, P105, DOI 10.1016/j.chc.2004.07.008
   HOLM S, 1979, SCAND J STAT, V6, P65
   Kabat-Zinn J, 2003, CLIN PSYCHOL-SCI PR, V10, P144, DOI 10.1093/clipsy/bpg016
   Kadosh KC, 2019, NEUROIMAGE, V185, P545, DOI 10.1016/j.neuroimage.2018.10.021
   Krystal JH, 2020, NAT MED, V26, P639, DOI 10.1038/s41591-020-0878-4
   Lane A.M., 2007, Mood and Human Performance: Conceptual, Measurement, and Applied Issues, P119
   Liu S, 2020, LANCET PSYCHIAT, V7, pE17, DOI 10.1016/S2215-0366(20)30077-8
   Malbos E, 2013, PRESSE MED, V42, P1442, DOI 10.1016/j.lpm.2013.01.065
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Miu AS, 2021, ACAD PSYCHIATR, V45, P539, DOI 10.1007/s40596-021-01427-w
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Motraghi TE, 2014, J CLIN PSYCHOL, V70, P197, DOI 10.1002/jclp.22051
   Nica E, 2017, EDUC PHILOS THEORY, V49, P571, DOI 10.1080/00131857.2017.1288787
   Nichols S, 2002, APPL ERGON, V33, P251, DOI 10.1016/S0003-6870(02)00020-0
   Olbrich S, 2011, J PSYCHOPHYSIOL, V25, P190, DOI 10.1027/0269-8803/a000061
   Orakpo N, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.660105
   Orrù G, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18010337
   Philippot P, 2012, CLIN PSYCHOL PSYCHOT, V19, P411, DOI 10.1002/cpp.756
   Price J, 2009, INTRODUCTION TO QUANTITATIVE EEG AND NEUROFEEDBACK: ADVANCED THEORY AND APPLICATIONS, 2ND EDITION, P453, DOI 10.1016/B978-0-12-374534-7.00017-4
   Richardson KM, 2008, J OCCUP HEALTH PSYCH, V13, P69, DOI 10.1037/1076-8998.13.1.69
   Roquet CD, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188616
   Rus-Calafell M, 2018, PSYCHOL MED, V48, P362, DOI 10.1017/S0033291717001945
   Ruths F, 2009, BRIT J PSYCHIAT, V194, P93, DOI 10.1192/bjp.bp.107.047134
   Sahin MD, 2019, INT J ASSESS TOOLS E, V6, P670, DOI 10.21449/ijate.661803
   Sedlmeier P, 2012, PSYCHOL BULL, V138, P1139, DOI 10.1037/a0028168
   Sherlin L, 2009, INT J STRESS MANAGE, V16, P233, DOI 10.1037/a0016047
   Sherlin L, 2010, APPL PSYCHOPHYS BIOF, V35, P219, DOI 10.1007/s10484-010-9132-z
   Freitas JRS, 2021, PSYCHIAT QUART, V92, P1685, DOI 10.1007/s11126-021-09935-6
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Smith M. L., 2014, EEG ERP ANAL METH AP, P184, DOI [10.4324/9780203795132-10, DOI 10.4324/9780203795132-10]
   Tang YY, 2009, P NATL ACAD SCI USA, V106, P8865, DOI 10.1073/pnas.0904031106
   Tarrant J., 2018, NeuroRegulation, V5, P57, DOI [10.15540/nr.5.2.57, DOI 10.15540/NR.5.2.57]
   Tarrant J., 2017, Meditation interventions to rewire the brain: Integrating neuroscience strategies for ADHD, anxiety, depression
   Tarrant J., 2019, Schol. J. Psychol. Behav. Sci, V2, P254
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Taylor S, 2020, J AFFECT DISORDERS, V277, P94, DOI 10.1016/j.jad.2020.08.002
   Teasdale JD, 2000, J CONSULT CLIN PSYCH, V68, P615, DOI 10.1037//0022-006X.68.4.615
   Travis F, 2010, CONSCIOUS COGN, V19, P1110, DOI 10.1016/j.concog.2010.01.007
   Tussyadiah IP, 2018, TOURISM MANAGE, V66, P140, DOI 10.1016/j.tourman.2017.12.003
   Valmaggia LR, 2016, PSYCHIAT RES, V236, P189, DOI 10.1016/j.psychres.2016.01.015
   van Lutterveld R, 2017, NEUROIMAGE, V151, P117, DOI 10.1016/j.neuroimage.2016.02.047
   Veling W, 2014, CYBERPSYCH BEH SOC N, V17, P191, DOI 10.1089/cyber.2012.0497
   Viczko J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.618381
   Wang Jing, 2020, Wuhan Daxue Xuebao (Yixue Ban), V41, P547, DOI 10.14188/j.1671-8852.2020.0098
   Wang XD, 2000, AM J PSYCHIAT, V157, P1260, DOI 10.1176/appi.ajp.157.8.1260
   Williams JMG, 2006, J CLIN PSYCHOL, V62, P201, DOI 10.1002/jclp.20223
   Yang E, 2018, J ALTERN COMPLEM MED, V24, P505, DOI 10.1089/acm.2015.0301
   Zhang Z.J., 2004, NANFANG J NURS, V11, P9, DOI [10.16460/j.issn1008-9969.2004.04.005, DOI 10.16460/J.ISSN1008-9969.2004.04.005]
NR 80
TC 8
Z9 9
U1 2
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 26
PY 2022
VL 3
AR 764745
DI 10.3389/frvir.2022.764745
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OG4
UT WOS:001021697700001
OA gold
DA 2024-07-18
ER

PT J
AU Buckingham, G
AF Buckingham, Gavin
TI Hand Tracking for Immersive Virtual Reality: Opportunities and
   Challenges
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE VR; embodiment; psychology; communcation; inclusivity
ID UNCANNY VALLEY; VISUAL-FIELDS; LEAP MOTION; EYE; GESTURE; SENSE; SKIN
AB Hand tracking has become an integral feature of recent generations of immersive virtual reality head-mounted displays. With the widespread adoption of this feature, hardware engineers and software developers are faced with an exciting array of opportunities and a number of challenges, mostly in relation to the human user. In this article, I outline what I see as the main possibilities for hand tracking to add value to immersive virtual reality as well as some of the potential challenges in the context of the psychology and neuroscience of the human user. It is hoped that this paper serves as a roadmap for the development of best practices in the field for the development of subsequent generations of hand tracking and virtual reality technologies.
C1 [Buckingham, Gavin] Univ Exeter, Dept Sport & Hlth Sci, Exeter, Devon, England.
C3 University of Exeter
RP Buckingham, G (corresponding author), Univ Exeter, Dept Sport & Hlth Sci, Exeter, Devon, England.
EM g.buckingham@exeter.ac.uk
CR Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Birhane A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100205
   Brenton H., 2005, P C HUM COMP INT WOR
   Buckingham G, 2019, PSYCHON B REV, V26, P1295, DOI 10.3758/s13423-019-01612-x
   Buckingham G, 2016, J NEUROPHYSIOL, V115, P1946, DOI 10.1152/jn.00587.2015
   Buolamwini J., 2018, FACCT, P77
   Carlton B., 2021, VRScout
   Clarence A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P150, DOI 10.1109/VR50410.2021.00036
   D'Alonzo M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55478-z
   Danckert J, 2001, EXP BRAIN RES, V137, P303
   Desmurget M, 1998, NEUROSCI BIOBEHAV R, V22, P761, DOI 10.1016/S0149-7634(98)00004-9
   Destephe M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00204
   Dieter KC, 2014, PSYCHOL SCI, V25, P66, DOI 10.1177/0956797613497968
   Farmer H, 2012, CONSCIOUS COGN, V21, P1242, DOI 10.1016/j.concog.2012.04.011
   Furmanek MP, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0525-9
   Fussell Sidney, 2017, GIZMODO
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Hepperle D, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2020), P41, DOI 10.1109/CW49994.2020.00014
   Inside Facebook Reality Labs, 2021, WRIST BAS INT NEXT C
   Iverson JM, 1998, NATURE, V396, P228, DOI 10.1038/24300
   Johansson RS, 2001, J NEUROSCI, V21, P6917, DOI 10.1523/JNEUROSCI.21-17-06917.2001
   Kätsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   Khan MA, 2005, EXP BRAIN RES, V164, P395, DOI 10.1007/s00221-005-2325-7
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kreylos O., 2019, QUANTITATIVE COMP VR
   Kreylos O., 2016, Optical Properties of Current VR HMDs
   Krigolson A, 2006, EXP BRAIN RES, V170, P127, DOI 10.1007/s00221-006-0386-x
   Land MF, 2009, VISUAL NEUROSCI, V26, P51, DOI 10.1017/S0952523808080899
   Lavoie E, 2021, NEUROSCI CONSCIOUS, V7, DOI 10.1093/nc/niaa027
   Lavoie EB, 2018, J VISION, V18, DOI 10.1167/18.6.18
   Lira M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16137-3
   MacDorman KF, 2009, COMPUT HUM BEHAV, V25, P695, DOI 10.1016/j.chb.2008.12.026
   Mangalam M, 2021, EXP BRAIN RES, V239, P1651, DOI 10.1007/s00221-021-06079-8
   Masurovsky A, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040091
   McDonnell R., 2010, ACM SIGGRAPH ASIA 2010 Sketches, P1, DOI [DOI 10.1145/1899950.1899991, 10.1145/1899950, DOI 10.1145/1899950]
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Özçaliskan S, 2016, PSYCHOL SCI, V27, P737, DOI 10.1177/0956797616629931
   Ozana A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.573352
   Poliakoff E, 2018, PROSTHET ORTHOT INT, V42, P21, DOI 10.1177/0309364617744083
   Poliakoff E, 2013, PERCEPTION, V42, P998, DOI 10.1068/p7569
   PREVIC FH, 1990, BEHAV BRAIN SCI, V13, P519, DOI 10.1017/S0140525X00080018
   Pyasik M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62394-0
   Rakkolainen I, 2019, IEEE INT SYM MULTIM, P94, DOI 10.1109/ISM46123.2019.00022
   Rao AK, 2001, EXP BRAIN RES, V138, P438, DOI 10.1007/s002210100717
   Ross P, 2020, PERCEPTION, V49, P98, DOI 10.1177/0301006619893229
   Rossit S, 2013, CORTEX, V49, P2525, DOI 10.1016/j.cortex.2012.12.014
   Saygin AP, 2012, SOC COGN AFFECT NEUR, V7, P413, DOI 10.1093/scan/nsr025
   Schmidtmann G, 2015, J VISION, V15, DOI 10.1167/15.5.18
   Schorr SB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3115, DOI 10.1145/3025453.3025744
   Schwartz G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392493
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Seinfeld S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79255-5
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Strait MK, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01366
   Voigt-Antons J.-N., 2020, ARXIV200412642 CS
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Wang SS, 2015, REV GEN PSYCHOL, V19, P393, DOI 10.1037/gpr0000056
   Whitwell RL, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00216
   Zhou Y, 2017, J VISION, V17, DOI 10.1167/17.1.9
NR 62
TC 19
Z9 23
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 20
PY 2021
VL 2
AR 728461
DI 10.3389/frvir.2021.728461
PG 6
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WY3
UT WOS:001019197900001
OA Green Published, Green Submitted, gold
DA 2024-07-18
ER

PT J
AU de Siqueira, A
   Feijóo-García, PG
   Stuart, J
   Lok, B
AF de Siqueira, Alexandre
   Feijoo-Garcia, Pedro Guillermo
   Stuart, Jacob
   Lok, Benjamin
TI Toward Facilitating Team Formation and Communication Through Avatar
   Based Interaction in Desktop-Based Immersive Virtual Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE avatars; collaboration; communication; teamwork; Mozilla Hubs; online
   learning; immersive virtual environments; social virtual environments
ID MEDIATED COMMUNICATION; FACE
AB Millions of students worldwide have adopted online learning due to the isolation restrictions imposed by the Covid-19 pandemic. In this context, video conferencing platforms have garnered immense popularity as tools for teaching. However, these tools have several limitations compared to real-world encounters, especially in activities involving collaboration and teamwork. A growing number of researchers and educators have turned to avatar-based communication platforms, such as Mozilla Hubs, as alternatives that can complement video conferencing in social and teaching activities. Several previous research efforts have focused on developing tools that implement avatar-based communication systems or have explored creating activities in these 3D virtual spaces, such as poster sessions in scientific conferences or the classroom environment. In this work, we describe our semester-long efforts to develop Mozilla Hubs rooms toward promoting interaction and communication to help students self-form teams in the context of an introductory virtual reality course at the University of Florida. We describe hands-on activities to prepare students to use Mozilla Hubs effectively, including teaching them skills to customize and create avatars. We describe the implementation of three virtual rooms developed based on researchers' observations and students' survey responses. By observing students' behavior and communication patterns in those rooms, we propose a set of guidelines for building virtual rooms that can promote communication, interaction, and teamwork. We discuss the rooms' design, students' attendance, and avatar choices. Our findings suggest that highly detailed, small, closed spaces are preferred over large, open spaces with few details when promoting interaction and collaboration among students.
C1 [de Siqueira, Alexandre; Feijoo-Garcia, Pedro Guillermo; Stuart, Jacob; Lok, Benjamin] Univ Florida, Herbert Wertheim Coll Engn, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP de Siqueira, A (corresponding author), Univ Florida, Herbert Wertheim Coll Engn, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
EM agomesdesiqueira@ufl.edu
OI Feijoo Garcia, Pedro Guillermo/0000-0002-3024-1257; Gomes de Siqueira,
   Alexandre/0000-0002-9213-9602; Lok, Benjamin/0000-0002-1190-3729
CR Alt, 2020, ALTSP BE THER TOG
   [Anonymous], 2006, Environ Educ Res, DOI [DOI 10.1080/13504620601053571, 10.1080/ 13504620601053571]
   [Anonymous], 2009, ASQ Higher Education Brief, DOI DOI 10.14201/EKS2016171718
   [Anonymous], 2012, Proceedings of the Designing Interactive Systems Conference. DIS'12, DOI [DOI 10.1145/2317956.2318078, 10.1145/2317956.2318078]
   Applegate R, 2009, J ACAD LIBR, V35, P341, DOI 10.1016/j.acalib.2009.04.004
   ARE, 2020, UN RES 71 313
   Barrett P., 2015, Clever classrooms
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Ble, 2020, BLEND ORG HOM BLEND
   Bogicevic V, 2018, INT J CONTEMP HOSP M, V30, P874, DOI [10.1108/IJCHM-08-2016-0450, 10.1108/ijchm-08-2016-0450]
   Boustila S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P860, DOI [10.1109/VR.2019.8798238, 10.1109/vr.2019.8798238]
   Bowden J. A., 1998, U1 LEARNING
   Bredikhina L., 2020, 25 INT C 3D WEB TECH, P1
   Curry O, 2013, HUM NATURE-INT BIOS, V24, P336, DOI 10.1007/s12110-013-9174-z
   Damer B., 1997, Avatars! Exploring and Building Virtual Worlds on the Internet
   Delaney G, 2004, Australas Radiol, V48, P487, DOI 10.1111/j.1440-1673.2004.01349.x
   Delwiche A, 2006, EDUC TECHNOL SOC, V9, P160
   Dickey M. D., 1999, PHD THESIS
   Dis, 2020, DISC YOUR PLAC TALK
   DohertySneddon G, 1997, J EXP PSYCHOL-APPL, V3, P105, DOI 10.1037/1076-898X.3.2.105
   Eiris R, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: COMPUTER APPLICATIONS, P1106, DOI 10.1061/9780784482865.117
   FOLEY JD, 1987, SCI AM, V257, P126, DOI 10.1038/scientificamerican1087-126
   Frecon E., 1998, Distributed Systems Engineering, V5, P91, DOI 10.1088/0967-1846/5/3/002
   glT, 2020, GLTF WIK
   Heilig M, 1962, Patent No. [3,050,870, 3050870]
   Herring S.C., 1996, Computer-mediated communication: Linguistic, social, and cross-cultural perspectives, V39
   Heydarian Arsalan, 2015, Computing in Civil Engineering 2015. International Workshop on Computing in Civil Engineering. Proceedings, P475
   Holt EA, 2020, ECOL EVOL, V10, P12423, DOI 10.1002/ece3.6756
   Hub, 2020, HUBS PRIV SOC VR YOU
   Isaacs E.A., 1997, Video-mediated communication, P173
   Isaacs E.A., 1994, Multimedia systems, V2, P63, DOI [DOI 10.1007/BF01274181, 10.1007/bf01274181]
   Jerald Jason, 2014, 2014 IEEE Virtual Reality (VR), P1, DOI 10.1109/VR.2014.6802117
   Khadka R., 2018, P PRACTICE EXPERIENC, P1, DOI 10.1145/3219104.3229283
   Knipe D, 2002, BRIT J EDUC TECHNOL, V33, P301, DOI 10.1111/1467-8535.00265
   Kolesnichenko A, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P241, DOI 10.1145/3322276.3322352
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   MacKenzie I. S., 2012, Human-computer interaction: An empirical research perspective
   Mayrath M., 2007, P WORLD C ED MULTIME, P4219
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   Menzner T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1080, DOI 10.1109/VR.2019.8797754
   Messenger F., 2020, MESSENGER FACEBOOK
   Motamedi V., 2001, EDUCATION, V122, P386
   Nardi B. A., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P79, DOI 10.1145/358916.358975
   Nardi B., 2002, DISTRIBUTED WORK
   Neale D. C., 1998, MAKING MEDIA SPACES, P28
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Onl, 2020, MICR TEAMS
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Plenert G., 2011, Lean management principles for information technology
   Pol, 2020, POLY
   Qui, 2020, ABOUT US
   Rea, 2020, READ PLAYER ME PERS
   Scavarelli A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1148, DOI [10.1109/vr.2019.8798100, 10.1109/VR.2019.8798100]
   Serhan D., 2020, International Journal of Technology in Education and Science, V4, P335, DOI [https://doi.org/10.46328/ijtes.v4i4.148, DOI 10.46328/IJTES.V4I4.148, 10.46328/ijtes.v4i4.148]
   Ske, 2020, SKETCHF BEST 3D VIEW
   Spo, 2020, SPOK MOZ
   Sutherland IE, 1965, MULTIMEDIA WAGNER VI
   Usi, 2021, US MOZ HUBS SCREEN R
   USR, 2020, US REM WORK SURV PWC
   Vergara D., 2019, INT C METHODOLOGIES, P146
   Vid, 2020, VID C ZOOM
   Vilhjalmsson H. H., 2003, PHD THESIS
   VRC, 2020, VRCHAT
   VRF, 2020, VR SOC GOOD
   WEF, 2020, RIS ONL LEARN COVID
   Wel, 2020, SLACK
   Wen J, 2020, CONSTR INNOV-ENGL, V20, P509, DOI 10.1108/CI-11-2019-0122
   Wha, 2020, WHATSAPP
   Whittaker S., 1997, VIDEO MEDIATED COMMU, P23
   Williams L, 2012, COMMUN ACM, V55, P71, DOI 10.1145/2133806.2133823
   Williamson JR, 2021, Arxiv, DOI arXiv:2101.05300
NR 71
TC 7
Z9 7
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 13
PY 2021
VL 2
AR 647801
DI 10.3389/frvir.2021.647801
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4SC8
UT WOS:001023170800001
OA gold
DA 2024-07-18
ER

PT J
AU Hoeg, ER
   Povlsen, TM
   Bruun-Pedersen, JR
   Lange, B
   Nilsson, NC
   Haugaard, KB
   Faber, SM
   Hansen, SW
   Kimby, CK
   Serafin, S
AF Hoeg, Emil Rosenlund
   Povlsen, Tina Myung
   Bruun-Pedersen, Jon Ram
   Lange, Belinda
   Nilsson, Niels Christian
   Haugaard, Kristian Birkemose
   Faber, Sune Molgard
   Hansen, Soren Willer
   Kimby, Charlotte Kira
   Serafin, Stefania
TI System Immersion in Virtual Reality-Based Rehabilitation of Motor
   Function in Older Adults: A Systematic Review and Meta-Analysis
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; rehabilitation; immersive displays; older adults;
   balance; functional mobility; pain; systematic review
ID EXPOSURE THERAPY; BALANCE; PAIN; HEALTH; WII; INTERVENTION; FEASIBILITY;
   DISORDERS; ADHERENCE; EXERCISES
AB Background: As the elderly population continues to grow, so does the demand for new and innovative solutions to tackle age-related chronic diseases and disabilities. Virtual Reality (VR) has been explored as a novel therapeutic tool for numerous health-related applications. Although findings frequently favors VR, methodological shortcomings prevent clinical recommendations. Moreover, the term "VR" is frequently used ambiguously to describe e.g., video games; the distinction remains vague between immersive VR (IVR) systems and non-immersive VR (NVR). With no distinct demarcation, results of outcome measures are often pooled in meta-analyses, without accounting for the immersiveness of the system.Objective: This systematic review focused on virtual reality-based rehabilitation of older adults (+60) in motor rehabilitation programs. The review aims to retrospectively classify previous studies according to the level of immersion, in order to get an overview of the ambiguity-phenomenon, and to utilize meta-analyses and subgroup analyses to evaluate the comparative efficacy of system immersion in VR-based rehabilitation.Methods: Following PRISMA guidelines, we conducted a systematic search for randomized controlled trials, describing virtual rehabilitation or video games interventions for older adults (+60). Main outcomes were pain, motivation, mobility, balance, and adverse events.Results: We identified 15 studies which included 743 patients. Only three studies utilized IVR. The rest used various NVR-equipment ranging from commercial products (e.g., Nintendo Wii), to bespoke systems that combine tracking devices, software, and displays. A random effects meta-analysis of 10 studies analyzed outcome measures of mobility, balance, and pain. Protocols and dosage varied widely, but outcome results were in favor of immersive and non-immersive interventions, however, dropout rates and adverse events were mostly in favor of the control.Conclusions: We initialize a call-for-action, to distinguish between types of VR-technology and propose a taxonomy of virtual rehabilitation systems based on our findings. Most interventions use NVR-systems, which have demonstrably lower cybersickness-symptoms than IVR-systems. Therefore, adverse events may be under-reported in RCT-studies. An increased demand for IVR-systems highlight this challenge. Care should be given, when applying the results of existing NVR tools to new IVR-technologies. Future studies should provide more detail about their interventions, and future reviews should differentiate between NVR and IVR.
C1 [Hoeg, Emil Rosenlund; Bruun-Pedersen, Jon Ram; Nilsson, Niels Christian; Serafin, Stefania] Aalborg Univ, Tech Fac IT & Design, Dept Architecture Design & Media Technol, Multisensory Experience Lab, Copenhagen, Denmark.
   [Povlsen, Tina Myung; Haugaard, Kristian Birkemose; Faber, Sune Molgard; Hansen, Soren Willer; Kimby, Charlotte Kira] VihTek Res & Test Ctr Hlth Technol Capital Reg Den, Glostrup, Denmark.
   [Lange, Belinda] Flinders Univ S Australia, Caring Futures Inst, Coll Nursing & Hlth Sci, Adelaide, SA, Australia.
C3 Aalborg University; Flinders University South Australia
RP Hoeg, ER (corresponding author), Aalborg Univ, Tech Fac IT & Design, Dept Architecture Design & Media Technol, Multisensory Experience Lab, Copenhagen, Denmark.
EM erh@create.aau.dk
OI Nilsson, Niels Chr./0000-0001-7495-8754; Hoeg, Emil
   Rosenlund/0000-0001-9567-4291; Lange, Belinda/0000-0002-2330-2699;
   Serafin, Stefania/0000-0001-6971-1132
FU Aalborg University; VihTek Research and Test Center for Health
   Technologies; municipality of Frederiksberg
FX This systematic review was funded as a joined effort between Aalborg
   University and VihTek Research and Test Center for Health Technologies.
   The systematic review was written as part of a Ph.D. study undertaken by
   Emil Rosenlund Hoeg, funded by the municipality of Frederiksberg.
CR Anderson E, 2019, SPORTS MED HLTH SCI, V1, P3, DOI 10.1016/j.smhs.2019.08.006
   [Anonymous], 2019, World Population Prospects 2019: Highlights
   Anson E, 2018, GAIT POSTURE, V62, P342, DOI 10.1016/j.gaitpost.2018.03.044
   Bonell C, 2015, J EPIDEMIOL COMMUN H, V69, P95, DOI 10.1136/jech-2014-204671
   Bourbeau J, 2008, THORAX, V63, P831, DOI 10.1136/thx.2007.086041
   Burdea G, 2003, Yearb Med Inform, P170
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Christensen K, 2009, LANCET, V374, P1196, DOI 10.1016/S0140-6736(09)61460-4
   de Amorim JSC, 2018, ADV RHEUMATOL, V58, DOI 10.1186/s42358-018-0013-0
   Dahdah MN, 2017, NEUROREHABILITATION, V41, P721, DOI 10.3233/NRE-172183
   de Bruin ED, 2010, Z GERONTOL GERIATR, V43, P229, DOI 10.1007/s00391-010-0124-7
   De la Rosa A, 2020, J SPORT HEALTH SCI, V9, P394, DOI 10.1016/j.jshs.2020.01.004
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Deutsch JE, 2008, PHYS THER, V88, P1196, DOI 10.2522/ptj.20080062
   Difede J, 2007, J CLIN PSYCHIAT, V68, P1639, DOI 10.4088/JCP.v68n1102
   Donath L, 2016, SPORTS MED, V46, P1293, DOI 10.1007/s40279-016-0485-1
   Duncan LR, 2010, INT J BEHAV NUTR PHY, V7, DOI 10.1186/1479-5868-7-7
   Duque G, 2013, CLIN INTERV AGING, V8, P257, DOI 10.2147/CIA.S41453
   Erhardsson M, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00788-x
   Fontana L, 2014, AGING CELL, V13, P391, DOI 10.1111/acel.12207
   Fu AS, 2015, ARCH PHYS MED REHAB, V96, P2096, DOI 10.1016/j.apmr.2015.08.427
   García-Betances RI, 2015, AM J ALZHEIMERS DIS, V30, P49, DOI 10.1177/1533317514545866
   Gianola S, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000019136
   Gold JI, 2005, SEMIN ANESTH PERIO M, V24, P203, DOI 10.1053/j.sane.2005.10.005
   Higgins JPT, 2002, STAT MED, V21, P1539, DOI 10.1002/sim.1186
   Hoffman HG, 2008, CLIN J PAIN, V24, P299, DOI 10.1097/AJP.0b013e318164d2cc
   Iosa M, 2012, STROKE RES TREAT, V2012, DOI 10.1155/2012/187965
   Jin C, 2018, INT J CLIN EXP MED, V11, P6119
   Karamians R, 2020, ARCH PHYS MED REHAB, V101, P885, DOI 10.1016/j.apmr.2019.10.195
   Karanicolas PJ, 2010, CAN J SURG, V53, P345
   Kennedy BK, 2014, CELL, V159, P708, DOI 10.1016/j.cell.2014.10.039
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshner EA, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0552-6
   Khymeia Group (), VIRT REAL REH SYST V
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kim N G, 1999, IEEE Trans Rehabil Eng, V7, P482, DOI 10.1109/86.808952
   Kothgassner OD, 2019, EUR J PSYCHOTRAUMATO, V10, DOI 10.1080/20008198.2019.1654782
   Kwok BC, 2016, AGE AGEING, V45, P621, DOI 10.1093/ageing/afw108
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Laver K, 2012, DISABIL REHABIL, V34, P1802, DOI 10.3109/09638288.2012.662570
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee S, 2013, DIABETES TECHNOL THE, V15, P489, DOI 10.1089/dia.2013.0050
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Maclean N, 2000, BMJ-BRIT MED J, V321, P1051, DOI 10.1136/bmj.321.7268.1051
   Maier M, 2019, NEUROREHAB NEURAL RE, V33, P112, DOI 10.1177/1545968318820169
   Maples-Keller JL, 2017, NEUROTHERAPEUTICS, V14, P554, DOI 10.1007/s13311-017-0534-y
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Molina KI, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-156
   Monteiro RS, 2015, CNS NEUROL DISORD-DR, V14, P1157, DOI 10.2174/1871527315666151111120131
   Morone G, 2016, AGING CLIN EXP RES, V28, P1187, DOI 10.1007/s40520-016-0578-6
   Mugueta-Aguinaga I, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14121439
   nDreams, 2016, PERF
   Neri SGR, 2017, CLIN REHABIL, V31, P1292, DOI 10.1177/0269215517694677
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [10.17011/ht/urn.201611174652, DOI 10.17011/HT/URN.201611174652]
   Oesch P, 2017, BMC GERIATR, V17, DOI 10.1186/s12877-017-0467-7
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Cacau LDP, 2013, REV BRAS CIR CARDIOV, V28, P281, DOI 10.5935/1678-9741.20130039
   Porras DC, 2018, NEUROLOGY, V90, P1017, DOI 10.1212/WNL.0000000000005603
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reis E, 2019, PHYS THER REV, V24, P84, DOI 10.1080/10833196.2019.1639012
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   Rothbaum BO, 2006, BEHAV THER, V37, P80, DOI 10.1016/j.beth.2005.04.004
   Rothbaum BO, 2001, J CLIN PSYCHIAT, V62, P617, DOI 10.4088/JCP.v62n0808
   Salinas GD, 2011, INT J CHRONIC OBSTR, V6, P171, DOI 10.2147/COPD.S16396
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schwenk M, 2016, GERONTOLOGY, V62, P553, DOI 10.1159/000442253
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Skip Rizzo Albert, 2011, J Diabetes Sci Technol, V5, P256
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stewart JC, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-21
   Teixeira PJ, 2012, INT J BEHAV NUTR PHY, V9, DOI 10.1186/1479-5868-9-78
   The Nordic Cochrane Centre The Cochrane Collaboration, 2020, REV MAN REVMAN COMP
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   Tsang W W N, 2016, Hong Kong Med J, V22 Suppl 2, pS19
   Wittkopf PG, 2020, DISABIL REHABIL, V42, P3722, DOI 10.1080/09638288.2019.1610803
   Yesilyaprak SS, 2016, PHYSIOTHER THEOR PR, V32, P191, DOI 10.3109/09593985.2015.1138009
NR 84
TC 24
Z9 24
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 12
PY 2021
VL 2
AR 647993
DI 10.3389/frvir.2021.647993
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UZ7
UT WOS:001023246000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Keshner, EA
   Lamontagne, A
AF Keshner, Emily A.
   Lamontagne, Anouk
TI The Untapped Potential of Virtual Reality in Rehabilitation of Balance
   and Gait in Neurological Disorders
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE posture; locomotion; sensorimotor; avatar; intervention
ID WHOLE-BODY VIBRATION; VISUALLY CONTROLLED LOCOMOTION;
   COLLISION-AVOIDANCE BEHAVIOR; REDUCE FALL RISK; OPTIC-FLOW; SELF-MOTION;
   POSTURAL RESPONSES; BIOLOGICAL MOTION; STROKE PATIENTS; PACED TREADMILL
AB Dynamic systems theory transformed our understanding of motor control by recognizing the continual interaction between the organism and the environment. Movement could no longer be visualized simply as a response to a pattern of stimuli or as a demonstration of prior intent; movement is context dependent and is continuously reshaped by the ongoing dynamics of the world around us. Virtual reality is one methodological variable that allows us to control and manipulate that environmental context. A large body of literature exists to support the impact of visual flow, visual conditions, and visual perception on the planning and execution of movement. In rehabilitative practice, however, this technology has been employed mostly as a tool for motivation and enjoyment of physical exercise. The opportunity to modulate motor behavior through the parameters of the virtual world is often ignored in practice. In this article we present the results of experiments from our laboratories and from others demonstrating that presenting particular characteristics of the virtual world through different sensory modalities will modify balance and locomotor behavior. We will discuss how movement in the virtual world opens a window into the motor planning processes and informs us about the relative weighting of visual and somatosensory signals. Finally, we discuss how these findings should influence future treatment design.
C1 [Keshner, Emily A.] Temple Univ, Dept Hlth & Rehabil Sci, Philadelphia, PA 19122 USA.
   [Lamontagne, Anouk] McGill Univ, Sch Phys & Occupat Therapy, Montreal, PQ, Canada.
   [Lamontagne, Anouk] CISSS Laval Jewish Rehabil Hosp Site, Virtual Real & Mobil Lab, Ctr Interdisciplinary Res Rehabil Greater Montreal, Laval, PQ, Canada.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple
   University; McGill University
RP Keshner, EA (corresponding author), Temple Univ, Dept Hlth & Rehabil Sci, Philadelphia, PA 19122 USA.
EM ekeshner@temple.edu
FU NIH National Institute of Aging; National Institute of Deafness and
   Communication Disorders; Canadian Institutes of Health Research
   [PJT-148917]; Natural Sciences and Engineering Research Council of
   Canada [RGPIN-2016-04471]
FX EK has received funding from the NIH National Institute of Aging and
   National Institute of Deafness and Communication Disorders for her
   research. AL has received funding from the Canadian Institutes of Health
   Research (PJT-148917) and the Natural Sciences and Engineering Research
   Council of Canada (RGPIN-2016-04471).
CR Aburub AS, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-80
   Acerbi L, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006110
   Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Alchalabi B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P776, DOI [10.1109/VR.2019.8798263, 10.1109/vr.2019.8798263]
   Almajid R, 2020, ARCH GERONTOL GERIAT, V87, DOI 10.1016/j.archger.2019.104004
   Almajid R, 2019, J MOTOR BEHAV, V51, P681, DOI 10.1080/00222895.2019.1565528
   Angelaki DE, 2011, J PHYSIOL-LONDON, V589, P825, DOI 10.1113/jphysiol.2010.194720
   Aravind G, 2018, ANN PHYS REHABIL MED, V61, P197, DOI 10.1016/j.rehab.2017.05.002
   Aravind G, 2017, RESTOR NEUROL NEUROS, V35, P423, DOI 10.3233/RNN-160709
   Aravind G, 2015, IEEE T NEUR SYS REH, V23, P179, DOI 10.1109/TNSRE.2014.2369812
   Aravind G, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-38
   Ash A, 2013, PERCEPTION, V42, P562, DOI 10.1068/p7449
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Banks MS, 1996, VISION RES, V36, P431, DOI 10.1016/0042-6989(95)00122-0
   Bao T, 2019, J VESTIBUL RES-EQUIL, V29, P323, DOI 10.3233/VES-190683
   Basili P, 2013, GAIT POSTURE, V37, P385, DOI 10.1016/j.gaitpost.2012.08.003
   Berard J., 2012, J NEUROLOGY NEUROPHY, ps8, DOI DOI 10.4172/2155-9562.S8-001
   Berard JR, 2009, EXP BRAIN RES, V194, P183, DOI 10.1007/s00221-008-1685-1
   Billington J, 2010, J EXP PSYCHOL HUMAN, V36, P1495, DOI 10.1037/a0018728
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Booth AT, 2019, ARCH PHYS MED REHAB, V100, P598, DOI 10.1016/j.apmr.2018.10.013
   Bourgaize SM, 2021, J MOTOR BEHAV, V53, P166, DOI 10.1080/00222895.2020.1742083
   Brandt T, 1998, BRAIN, V121, P1749, DOI 10.1093/brain/121.9.1749
   Brandt T, 2002, ANN NY ACAD SCI, V956, P230, DOI 10.1111/j.1749-6632.2002.tb02822.x
   Brantley JA, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.133
   Bronstein Adolfo M, 2013, Handb Clin Neurol, V110, P189, DOI 10.1016/B978-0-444-52901-5.00016-2
   Bruggeman H, 2007, CURR BIOL, V17, P2035, DOI 10.1016/j.cub.2007.10.059
   Bryant MS, 2016, PM&R, V8, P1151, DOI 10.1016/j.pmrj.2016.05.001
   Bühler MA, 2019, GAIT POSTURE, V68, P201, DOI 10.1016/j.gaitpost.2018.10.004
   Bühler MA, 2018, IEEE T NEUR SYS REH, V26, P1813, DOI 10.1109/TNSRE.2018.2865907
   Burr D, 2011, VISION RES, V51, P1431, DOI 10.1016/j.visres.2011.02.008
   Calabro FJ, 2012, EXP BRAIN RES, V221, P177, DOI 10.1007/s00221-012-3159-8
   Chaplin TA, 2020, CURR OPIN NEUROBIOL, V60, P122, DOI 10.1016/j.conb.2019.11.013
   Chou YH, 2009, J GERONTOL B-PSYCHOL, V64, P222, DOI 10.1093/geronb/gbp003
   Cleworth TW, 2012, GAIT POSTURE, V36, P172, DOI 10.1016/j.gaitpost.2012.02.010
   Crowell JA, 1998, NAT NEUROSCI, V1, P732, DOI 10.1038/3732
   CUTTING JE, 1995, PSYCHOL REV, V102, P627, DOI 10.1037/0033-295X.102.4.627
   Darekar A, 2018, J NEUROPHYSIOL, V119, P990, DOI 10.1152/jn.00857.2016
   Darekar A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0265-7
   Darekar A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0264-8
   Davidsdottir S, 2008, BRAIN, V131, P2882, DOI 10.1093/brain/awn237
   de Winkel KN, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127104
   DeAngelis G.C., 2012, The Neural Bases of Multisensory Processes, P629
   Deblock-Bellamy A, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00834-2
   DICHGANS J, 1972, SCIENCE, V178, P1217, DOI 10.1126/science.178.4066.1217
   Dichgans J, 1972, Bibl Ophthalmol, V82, P327
   Dieterich M, 2000, CURR OPIN NEUROL, V13, P13, DOI 10.1097/00019052-200002000-00004
   Dokka K, 2015, CEREB CORTEX, V25, P619, DOI 10.1093/cercor/bht247
   Dokka K, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000680
   Dokka K, 2009, GAIT POSTURE, V30, P211, DOI 10.1016/j.gaitpost.2009.05.001
   Ducourant T, 2005, NEUROSCI LETT, V389, P6, DOI 10.1016/j.neulet.2005.06.052
   Duffy CJ, 1998, J NEUROPHYSIOL, V80, P1816, DOI 10.1152/jn.1998.80.4.1816
   Dukelow SP, 2001, J NEUROPHYSIOL, V86, P1991, DOI 10.1152/jn.2001.86.4.1991
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Fajen BR, 2013, FRONT BEHAV NEUROSCI, V7, DOI 10.3389/fnbeh.2013.00085
   Field DT, 2007, J NEUROSCI, V27, P8002, DOI 10.1523/JNEUROSCI.2130-07.2007
   Finley JM, 2014, J NEUROPHYSIOL, V111, P969, DOI 10.1152/jn.00513.2013
   Fiset F, 2020, NEUROSCI LETT, V736, DOI 10.1016/j.neulet.2020.135278
   Garrett B, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/10839
   Gennaro F, 2018, FRONT PUBLIC HEALTH, V6, DOI 10.3389/fpubh.2018.00039
   Gérin-Lajoie M, 2008, GAIT POSTURE, V27, P239, DOI 10.1016/j.gaitpost.2007.03.015
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   GIBSON JJ, 1958, BRIT J PSYCHOL, V49, P182, DOI 10.1111/j.2044-8295.1958.tb00656.x
   Gorman AD, 2013, ATTEN PERCEPT PSYCHO, V75, P835, DOI 10.3758/s13414-013-0423-3
   Gramann K, 2011, REV NEUROSCIENCE, V22, P593, DOI 10.1515/RNS.2011.047
   Grèzes J, 2003, NEUROIMAGE, V18, P928, DOI 10.1016/S1053-8119(03)00042-9
   Guo C, 2015, CNS NEUROL DISORD-DR, V14, P1110, DOI 10.2174/1871527315666151111124937
   Guterstam A, 2019, CEREB CORTEX, V29, P1328, DOI 10.1093/cercor/bhy285
   Hamzei F, 2003, NEUROIMAGE, V19, P637, DOI 10.1016/S1053-8119(03)00087-9
   Hanna M, 2017, J VESTIBUL RES-EQUIL, V27, P17, DOI 10.3233/VES-170603
   Haran F J, 2008, J Neurol Phys Ther, V32, P186, DOI 10.1097/NPT.0b013e31818dee39
   Hedges JH, 2011, CURR BIOL, V21, P2023, DOI 10.1016/j.cub.2011.10.049
   Huang RS, 2015, J NEUROSCI, V35, P4258, DOI 10.1523/JNEUROSCI.2647-14.2015
   Huber M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089589
   Israely S, 2016, TOP STROKE REHABIL, V23, P116, DOI 10.1179/1945511915Y.0000000007
   Jahn K, 2001, EXP BRAIN RES, V141, P370, DOI 10.1007/s002210100884
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kang HK, 2012, CLIN REHABIL, V26, P246, DOI 10.1177/0269215511419383
   Kannape OA, 2013, J NEUROPHYSIOL, V110, P1837, DOI 10.1152/jn.01042.2012
   Kenyon Robert V, 2004, J Neuroeng Rehabil, V1, P13, DOI 10.1186/1743-0003-1-13
   Keshner EA, 2008, GAIT POSTURE, V28, P127, DOI 10.1016/j.gaitpost.2007.11.003
   Keshner EA, 2004, J VESTIBUL RES-EQUIL, V14, P307
   Keshner EA, 2000, J VESTIBUL RES-EQUIL, V10, P207
   Keshner EA, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-24
   Keshner EA, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.01160
   Keshner EA, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0552-6
   Keshner EA, 2011, IEEE ENG MED BIO, P1379, DOI 10.1109/IEMBS.2011.6090324
   Keshner EA, 2009, STUD HEALTH TECHNOL, V145, P209, DOI 10.3233/978-1-60750-018-6-209
   Kim CS, 2020, JMIR SERIOUS GAMES, V8, P89, DOI 10.2196/21879
   King CE, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-77
   Kleinschmidt A, 2002, NEUROIMAGE, V16, P873, DOI 10.1006/nimg.2002.1181
   Knorr AG, 2016, J EXP PSYCHOL HUMAN, V42, P1332, DOI 10.1037/xhp0000223
   Koilias A, 2020, BEHAV SCI-BASEL, V10, DOI 10.3390/bs10090130
   KONCZAK J, 1994, J MOTOR BEHAV, V26, P225, DOI 10.1080/00222895.1994.9941678
   Koritnik T, 2010, GAIT POSTURE, V32, P540, DOI 10.1016/j.gaitpost.2010.07.017
   Lalonde-Parsi MJ, 2015, MOTOR CONTROL, V19, P191, DOI 10.1123/mc.2014-0010
   Lambrey Simon, 2007, Journal of Integrative Neuroscience, V6, P379, DOI 10.1142/S021963520700157X
   Lamontagne A., 2019, NEUROPHYSIOL CLINCLI, V49, P434, DOI [10.1016/j.neucli.2019.10.077, DOI 10.1016/J.NEUCLI.2019.10.077]
   Lamontagne A., 2019, IEEE P INT C VIRT RE, DOI [10.1109/ICVR46560.2019.8994733, DOI 10.1109/ICVR46560.2019.8994733]
   Lamontagne A, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-22
   Lamontagne A, 2010, NEUROREHAB NEURAL RE, V24, P457, DOI 10.1177/1545968309355985
   Leplaideur S, 2016, EXP BRAIN RES, V234, P2643, DOI 10.1007/s00221-016-4668-7
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Levin MF, 2015, PHYS THER, V95, P415, DOI 10.2522/ptj.20130579
   Liu A., 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P254, DOI 10.1109/ICVR.2013.6662070
   Liu L. Y., 2020, P 11 WORLD C WFNR LY
   Liu LY, 2020, IEEE T NEUR SYS REH, V28, P878, DOI 10.1109/TNSRE.2020.2979830
   Liu LY, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0408-5
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Lopez C, 2008, NEUROPHYSIOL CLIN, V38, P149, DOI 10.1016/j.neucli.2007.12.006
   Lopez C, 2012, NEUROSCI LETT, V511, P120, DOI 10.1016/j.neulet.2012.01.055
   Lu J, 2015, TOP STROKE REHABIL, V22, P161, DOI 10.1179/1074935714Z.0000000005
   Lynch SD, 2018, IEEE T VIS COMPUT GR, V24, P2078, DOI 10.1109/TVCG.2017.2718514
   Madhavan S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37982-w
   Marmelat V, 2014, NEUROSCI LETT, V564, P67, DOI 10.1016/j.neulet.2014.02.010
   Meerhoff LA, 2017, HUM MOVEMENT SCI, V54, P377, DOI 10.1016/j.humov.2017.06.005
   Meerhoff LA, 2019, HUM MOVEMENT SCI, V66, P173, DOI 10.1016/j.humov.2019.04.003
   Mirelman A, 2016, LANCET, V388, P1170, DOI 10.1016/S0140-6736(16)31325-3
   Mirelman A, 2011, J GERONTOL A-BIOL, V66, P234, DOI 10.1093/gerona/glq201
   Molenberghs P, 2012, NEUROSCI BIOBEHAV R, V36, P341, DOI 10.1016/j.neubiorev.2011.07.004
   Morrone MC, 2000, NAT NEUROSCI, V3, P1322, DOI 10.1038/81860
   Mulavara AP, 2005, EXP BRAIN RES, V166, P210, DOI 10.1007/s00221-005-2356-0
   Nero H, 2019, PARKINSONS DIS-US, V2019, DOI 10.1155/2019/8769141
   Nierula B, 2021, J PHYSIOL-LONDON, V599, P2419, DOI 10.1113/JP278167
   Nordin AD, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41131-2
   Ogourtsova T, 2020, NEUROPSYCHOL REHABIL, V30, P207, DOI 10.1080/09602011.2018.1454328
   Okazaki S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137126
   Olivier AH, 2018, IEEE T VIS COMPUT GR, V24, P2251, DOI 10.1109/TVCG.2017.2714665
   Olivier AH, 2012, GAIT POSTURE, V36, P399, DOI 10.1016/j.gaitpost.2012.03.021
   PAILHOUS J, 1990, BEHAV BRAIN RES, V38, P275, DOI 10.1016/0166-4328(90)90181-D
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Patla AE, 1999, J AGING PHYS ACTIV, V7, P7, DOI 10.1123/japa.7.1.7
   Pavlou M, 2012, J VESTIBUL RES-EQUIL, V22, P273, DOI 10.3233/VES-120462
   Pavlou M, 2013, NEUROREHAB NEURAL RE, V27, P208, DOI 10.1177/1545968312461715
   Pavlou M, 2011, GAIT POSTURE, V33, P113, DOI 10.1016/j.gaitpost.2010.10.085
   Pavone EF, 2016, J NEUROSCI, V36, P268, DOI 10.1523/JNEUROSCI.0494-15.2016
   Peruzzi A, 2017, DISABIL REHABIL, V39, P1557, DOI 10.1080/09638288.2016.1224935
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Peuskens H, 2001, J NEUROSCI, V21, P2451, DOI 10.1523/JNEUROSCI.21-07-02451.2001
   Pfaff LM, 2018, EXP BRAIN RES, V236, P3169, DOI 10.1007/s00221-018-5371-7
   Pitzalis S, 2020, HUM BRAIN MAPP, V41, P1084, DOI 10.1002/hbm.24862
   Prokop T, 1997, EXP BRAIN RES, V114, P63, DOI 10.1007/PL00005624
   Pyasik M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62394-0
   Rennie L, 2021, CLIN REHABIL, V35, P200, DOI 10.1177/0269215520956503
   Reynolds RF, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2014.0751
   Rhea CK, 2014, HUM MOVEMENT SCI, V36, P20, DOI 10.1016/j.humov.2014.04.006
   Richards CL, 2018, PHYSIOTHER CAN, V70, P221, DOI 10.3138/ptc.2016-97
   Riecke BE, 2012, COGN PROCESS, V13, pS293, DOI 10.1007/s10339-012-0491-7
   Rio KW, 2014, J VISION, V14, DOI 10.1167/14.2.4
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Robitaille N, 2017, DISABIL REHABIL-ASSI, V12, P758, DOI 10.1080/17483107.2016.1229048
   Roerdink M, 2007, PHYS THER, V87, P1009, DOI 10.2522/ptj.20050394
   Saleh S, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00452
   Salinas MM, 2017, GAIT POSTURE, V57, P15, DOI 10.1016/j.gaitpost.2017.05.002
   Sanz FA, 2015, P IEEE VIRT REAL ANN, P75, DOI 10.1109/VR.2015.7223327
   Sarre G, 2008, NEUROSCI LETT, V436, P96, DOI 10.1016/j.neulet.2008.02.049
   Saunders DH, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003316.pub6
   Schouten B, 2010, ATTEN PERCEPT PSYCHO, V72, P1256, DOI 10.3758/APP.72.5.1256
   Schubert M, 2005, MOVEMENT DISORD, V20, P141, DOI 10.1002/mds.20281
   Serino A, 2019, NEUROSCI BIOBEHAV R, V99, P138, DOI 10.1016/j.neubiorev.2019.01.016
   Shockley K, 2003, J EXP PSYCHOL HUMAN, V29, P326, DOI 10.1037/0096-1523.29.2.326
   Shokur S, 2016, SCI REP-UK, V6, DOI 10.1038/srep32293
   Shumway-Cook A, 2003, J AM GERIATR SOC, V51, P393, DOI 10.1046/j.1532-5415.2003.51114.x
   Sienko KH, 2017, J VESTIBUL RES-EQUIL, V27, P63, DOI 10.3233/VES-170606
   Silva WS, 2020, GAIT POSTURE, V76, P290, DOI 10.1016/j.gaitpost.2019.11.017
   Silva WS, 2019, GERONTOLOGY, V65, P524, DOI 10.1159/000499067
   Silva WS, 2018, GAIT POSTURE, V61, P294, DOI 10.1016/j.gaitpost.2018.01.028
   Slaboda JC, 2012, J NEUROL, V259, P2664, DOI 10.1007/s00415-012-6566-7
   Slaboda JC, 2011, EXP BRAIN RES, V211, P87, DOI 10.1007/s00221-011-2655-6
   Slaboda JC, 2011, NEUROSCI LETT, V491, P138, DOI 10.1016/j.neulet.2011.01.024
   Slaboda JC, 2009, PERCEPT MOTOR SKILL, V109, P121, DOI 10.2466/PMS.109.1.121-132
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Soni S, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00787-y
   Spaulding SJ, 2013, ARCH PHYS MED REHAB, V94, P562, DOI 10.1016/j.apmr.2012.10.026
   Spinelli G, 2018, NEUROIMAGE, V167, P1, DOI 10.1016/j.neuroimage.2017.11.019
   Streepey JW, 2007, EXP BRAIN RES, V176, P182, DOI 10.1007/s00221-006-0677-2
   Streepey JW, 2007, GAIT POSTURE, V25, P49, DOI 10.1016/j.gaitpost.2005.12.013
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   TELFORD L, 1995, EXP BRAIN RES, V104, P502
   Terrier P, 2016, ANN BIOMED ENG, V44, P2785, DOI 10.1007/s10439-016-1573-y
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   Tieri G, 2017, EUR J NEUROSCI, V45, P1141, DOI 10.1111/ejn.13545
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P2740, DOI 10.1016/j.neuropsychologia.2010.05.021
   Turano KA, 2005, VISION RES, V45, P3117, DOI 10.1016/j.visres.2005.06.017
   Ustinova KI, 2010, ACTA PSYCHOL, V133, P180, DOI 10.1016/j.actpsy.2009.11.006
   Vaina LM, 2010, J NEUROPSYCHOL, V4, P121, DOI 10.1348/174866409X471760
   van der Hoorn A, 2012, MOVEMENT DISORD, V27, P580, DOI 10.1002/mds.24011
   van Nes IJW, 2004, AM J PHYS MED REHAB, V83, P867, DOI 10.1097/01.PHM.0000140801.23135.09
   van Nes IJW, 2006, STROKE, V37, P2331, DOI 10.1161/01.STR.0000236494.62957.f3
   Varraine E, 2002, EXP BRAIN RES, V142, P374, DOI 10.1007/s00221-001-0934-3
   Wagner J, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0223-2
   Wagner J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00093
   Wall MB, 2008, CURR BIOL, V18, P191, DOI 10.1016/j.cub.2007.12.053
   Wang PT, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/5/056016
   Wang Y, 2010, EXP BRAIN RES, V201, P663, DOI 10.1007/s00221-009-2082-0
   Warren WH, 2001, NAT NEUROSCI, V4, P213, DOI 10.1038/84054
   WARREN WH, 1990, NATO ADV SCI I D-BEH, V56, P23
   Warren WH, 2009, BRIT J PSYCHOL, V100, P277, DOI 10.1348/000712609X414150
   Weiss P.L., 2014, Virtual Reality for Physical and Motor Rehabilitation, P217, DOI DOI 10.1007/978-1-4939-0968-1_11
   Wilkie RM, 2003, J VISION, V3, P677, DOI 10.1167/3.11.3
   Willaert I., 2020, 2020 IEEE C VIRT REA, DOI [10.1109/VRW50115.2020.00210, DOI 10.1109/VRW50115.2020.00210]
   Wright WG, 2013, IEEE T NEUR SYS REH, V21, P191, DOI 10.1109/TNSRE.2012.2237040
   Wutzke CJ, 2015, PHYS THER, V95, P1244, DOI 10.2522/ptj.20140482
   Wutzke CJ, 2013, TOP STROKE REHABIL, V20, P233, DOI 10.1310/tsr2003-233
   Xerri C., 1988, PROG BRAIN RES, V76, P193, DOI 10.1016/s0079-6123(08)64505-7
   Yang YR, 2008, GAIT POSTURE, V28, P201, DOI 10.1016/j.gaitpost.2007.11.007
   Young DE, 2010, VISION RES, V50, P2495, DOI 10.1016/j.visres.2010.08.029
   Yu YW, 2020, J MOTOR BEHAV, V52, P249, DOI 10.1080/00222895.2019.1610860
   Yu YW, 2018, DEV NEUROREHABIL, V21, P531, DOI 10.1080/17518423.2018.1424265
   Zivotofsky AZ, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-28
   Zivotofsky AZ, 2012, HUM MOVEMENT SCI, V31, P1268, DOI 10.1016/j.humov.2012.01.003
NR 216
TC 14
Z9 16
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 11
PY 2021
VL 2
AR 641650
DI 10.3389/frvir.2021.641650
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PX0
UT WOS:001021740500001
PM 33860281
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Pallavicini, F
   Orena, E
   di Santo, S
   Greci, L
   Caragnano, C
   Ranieri, P
   Vuolato, C
   Pepe, A
   Veronese, G
   Dakanalis, A
   Rossini, A
   Caltagirone, C
   Clerici, M
   Mantovani, F
AF Pallavicini, Federica
   Orena, Eleonora
   di Santo, Simona
   Greci, Luca
   Caragnano, Chiara
   Ranieri, Paolo
   Vuolato, Costanza
   Pepe, Alessandro
   Veronese, Guido
   Dakanalis, Antonios
   Rossini, Angelo
   Caltagirone, Carlo
   Clerici, Massimo
   Mantovani, Fabrizia
TI MIND-VR: Design and Evaluation Protocol of a Virtual Reality
   Psychoeducational Experience on Stress and Anxiety for the Psychological
   Support of Healthcare Workers Involved in the COVID-19 Pandemic
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; stress; anxiety; healthcare workers; COVID-19;
   psychoeducation; user-centered design
ID USER-CENTERED DESIGN; MENTAL-HEALTH; EXPOSURE THERAPY;
   POSTTRAUMATIC-STRESS; MOBILE APPLICATION; PSYCHO-EDUCATION; TECHNOLOGY;
   SYSTEM; INTERVENTION; PREVALENCE
AB To ensure the continuity of healthcare and to counter the spread of the COVID-19 pandemic, doctors and nursing staff at hospitals must face an insidious, invisible danger that is stretching the healthcare system far past its capacity. Excessive workload, inadequate protection from contamination, the need to manage patients experiencing extreme suffering and being kept apart from their families put medical personnel at high risk to experience stress and anxiety. Numerous scientific studies have shown that, among various therapeutic programs, virtual reality represents a highly specialized and effective tool for the prevention and treatment of stress and anxiety. However, the solutions developed using this technology for the management of stress and anxiety induced by the COVID-19 pandemic are still very limited, and none of these have been developed specifically for use with healthcare professionals. Therefore, this paper will detail the design and evaluation protocol of MIND-VR, a virtual reality-based psychoeducational experience on stress and anxiety developed following a user-centered design approach. The virtual experience will be tested on a sample of Italian hospital healthcare personnel involved in the COVID-19 pandemic emergency. MIND-VR is available free of charge, both in Italian and English, on the project website ().
C1 [Pallavicini, Federica; Pepe, Alessandro; Veronese, Guido; Mantovani, Fabrizia] Univ Milano Bicocca, Dept Human Sci Educ Riccardo Massa, Milan, Italy.
   [Orena, Eleonora; Vuolato, Costanza] IRCCS Neurol Inst Carlo Besta, Milan, Italy.
   [di Santo, Simona; Rossini, Angelo; Caltagirone, Carlo] IRCCS Fdn St Lucia, Rome, Italy.
   [di Santo, Simona] Univ Roma Tor Vergata, Dept Syst Med, Rome, Italy.
   [Greci, Luca] Natl Res Council Italy CNR, Inst Intelligent Ind Technol & Syst Adv Mfg STIIMA, Lecce, Italy.
   [Caragnano, Chiara] Univ Milano Bicocca, Dept Psychol, Milan, Italy.
   [Ranieri, Paolo] Univ Milano Bicocca, Specializat Sch Psychol, Monza, Italy.
   [Dakanalis, Antonios; Clerici, Massimo] Univ Milano Bicocca, Dept Med & Surg, Monza, Italy.
C3 University of Milano-Bicocca; Fondazione IRCCS Istituto Neurologico
   Carlo Besta; IRCCS Santa Lucia; University of Rome Tor Vergata;
   Consiglio Nazionale delle Ricerche (CNR); University of Milano-Bicocca;
   University of Milano-Bicocca; University of Milano-Bicocca
RP Pallavicini, F (corresponding author), Univ Milano Bicocca, Dept Human Sci Educ Riccardo Massa, Milan, Italy.
EM federica.pallavicini@unimib.it
RI Mantovani, Fabrizia/AFM-7854-2022; Pallavicini, Federica/ABF-4660-2021;
   Orena, Eleonora Francesca/K-7809-2016; Greci, Luca/AAX-5522-2020;
   Dakanalis Antonios Ntakanales, MD, MSc, PsyD, PhD, FNASc,
   Antonios/I-5105-2013
OI Pallavicini, Federica/0000-0003-2064-3823; Orena, Eleonora
   Francesca/0000-0002-2262-6093; Greci, Luca/0000-0003-1234-783X; Rossini,
   Angelo/0000-0002-0173-7325; Dakanalis Antonios Ntakanales, MD, MSc,
   PsyD, PhD, FNASc, Antonios/0000-0002-2328-3862
CR Abend R, 2014, J BEHAV THER EXP PSY, V45, P447, DOI 10.1016/j.jbtep.2014.06.004
   AITKEN RCB, 1969, P ROY SOC MED, V62, P989, DOI 10.1177/003591576906201005
   Alkhawaldeh JMA, 2020, NURS CRIT CARE, V25, P84, DOI 10.1111/nicc.12489
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   Babore A, 2020, PSYCHIAT RES, V293, DOI 10.1016/j.psychres.2020.113366
   Baharom S.N., 2014, International Journal of Multimedia and Ubiquitous Engineering, V9, P387, DOI [DOI 10.14257/IJMUE.2014.9.10, 10.14257/ijmue.2014.9.10.37, DOI 10.14257/IJMUE.2014.9.10.37]
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Barbieri L, 2018, INT J INTERACT DES M, V12, P561, DOI 10.1007/s12008-017-0414-z
   Bohlken J, 2020, PSYCHIAT PRAX, V47, P190, DOI 10.1055/a-1159-5551
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Briki W, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00252
   Brooks SK, 2020, LANCET, V395, P912, DOI 10.1016/S0140-6736(20)30460-8
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Brox E, 2017, JMIR SERIOUS GAMES, V5, DOI 10.2196/games.6254
   Cai HZ, 2020, MED SCI MONITOR, V26, DOI 10.12659/MSM.924171
   Cai X, 2020, AM J GERIAT PSYCHIAT, V28, P1030, DOI 10.1016/j.jagp.2020.07.003
   Carmassi C, 2020, PSYCHIAT RES, V292, DOI 10.1016/j.psychres.2020.113312
   Chen QN, 2020, LANCET PSYCHIAT, V7, pE15, DOI 10.1016/S2215-0366(20)30078-X
   Cheng P, 2020, COMMUNITY MENT HLT J, V56, P786, DOI 10.1007/s10597-020-00624-5
   Chirico F, 2021, BJPSYCH INT, V18, DOI 10.1192/bji.2020.39
   Chittaro L, 2007, COMPUT EDUC, V49, P3, DOI 10.1016/j.compedu.2005.06.002
   Clough BA, 2017, SYST REV-LONDON, V6, DOI 10.1186/s13643-017-0526-3
   Conway PM, 2008, APPL ERGON, V39, P630, DOI 10.1016/j.apergo.2008.01.007
   Coulthard K, 2013, BMC PSYCHIATRY, V13, DOI [10.1155/2013/159850, 10.1186/1471-244X-13-301]
   de Clerk M, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00013
   de Freitas S, 2010, BRIT J EDUC TECHNOL, V41, P69, DOI 10.1111/j.1467-8535.2009.01024.x
   de Paula DFO, 2014, LECT NOTES COMPUT SC, V8518, P313, DOI 10.1007/978-3-319-07626-3_29
   de Witte M, 2020, HEALTH PSYCHOL REV, V14, P294, DOI 10.1080/17437199.2019.1627897
   Dekker MR, 2017, GAMES HEALTH J, V6, P327, DOI 10.1089/g4h.2017.0058
   Dellve L, 2011, J ADV NURS, V67, P1918, DOI 10.1111/j.1365-2648.2011.05630.x
   DeSmet A, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.4444
   Desmet P, 2007, INT J DES, V1, P57
   Dewey J., 1916, DEMOCRACY ED
   Di Tella M, 2020, J EVAL CLIN PRACT, V26, P1583, DOI 10.1111/jep.13444
   Dimitropoulos K., 2007, INT J SOC SCI, V2, P62, DOI [10.5281/zenodo.1330935, DOI 10.5281/ZENODO.1330935]
   Donker T, 2009, BMC MED, V7, DOI 10.1186/1741-7015-7-79
   Du J, 2020, GEN HOSP PSYCHIAT, V67, P144, DOI 10.1016/j.genhosppsych.2020.03.011
   Eisapour M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3174362
   Farao J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237910
   Fidopiastis CM, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-11
   Fiorella L, 2015, LEARNING AS A GENERATIVE ACTIVITY: EIGHT LEARNING STRATEGIES THAT PROMOTE UNDERSTANDING, P1, DOI 10.1017/CBO9781107707085
   Fischer X., 2007, RES INTERACTIVE DESI, V2
   Flint A, 2000, INT J OBESITY, V24, P38, DOI 10.1038/sj.ijo.0801083
   Flobak E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300799
   Gabbard JL, 1999, IEEE COMPUT GRAPH, V19, P51, DOI 10.1109/38.799740
   Gaggioli A, 2014, J MED INTERNET RES, V16, P54, DOI 10.2196/jmir.3235
   Gandi Joshua C, 2011, Ment Health Fam Med, V8, P181
   Gerardi M, 2008, J TRAUMA STRESS, V21, P209, DOI 10.1002/jts.20331
   GIFT AG, 1989, NURS RES, V38, P286
   Gladden Matthew E., 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2040080
   Gomes Neil, 2020, Human Interaction and Emerging Technologies. Proceedings of the 1st International Conference on Human Interaction and Emerging Technologies (IHIET 2019). Advances in Intelligent Systems and Computing (AISC 1018), P289, DOI 10.1007/978-3-030-25629-6_45
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Gotsis M, 2018, 22ND PAN-HELLENIC CONFERENCE ON INFORMATICS (PCI 2018), P213, DOI 10.1145/3291533.3291562
   Grace SL, 2005, PSYCHOSOMATICS, V46, P385, DOI 10.1176/appi.psy.46.5.385
   Gradl S, 2018, INT CONF WEARAB IMPL, P152, DOI 10.1109/BSN.2018.8329681
   Greenberg N, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m1211
   Gulliver A, 2010, BMC PSYCHIATRY, V10, DOI 10.1186/1471-244X-10-113
   Hardy A, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/11222
   Hix D, 1999, P IEEE VIRT REAL ANN, P96, DOI 10.1109/VR.1999.756939
   Houghton S, 2007, PATIENT EDUC COUNS, V68, P107, DOI 10.1016/j.pec.2007.05.010
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huang JZ, 2020, ZHONGHUA LAO DONG WE, V38, pE001, DOI DOI 10.3760/CMA.J.CN121094-20200219-00063
   Imperatori C, 2020, CYBERPSYCH BEH SOC N, V23, P782, DOI 10.1089/cyber.2020.0339
   ISO/IEC, 2020, 13407 HUM CTR DES PR
   Italian National Institute of Health, 2020, STRESS MAN HEALTHC W
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Johns Hopkins Coronavirus Resource Center, 2020, COVID 19 MAP
   Jorm AF, 2000, BRIT J PSYCHIAT, V177, P396, DOI 10.1192/bjp.177.5.396
   Julian LJ, 2011, ARTHRIT CARE RES, V63, pS467, DOI 10.1002/acr.20561
   Kahn PH, 2009, CURR DIR PSYCHOL SCI, V18, P37, DOI 10.1111/j.1467-8721.2009.01602.x
   Kang LJ, 2020, LANCET PSYCHIAT, V7, pE14, DOI 10.1016/S2215-0366(20)30047-X
   Kazdin A. E., 2000, ENCY PSYCHOL, V2
   Koenig S.T., 2012, P 9 INT C DIS VIRT R
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Kozhevnikov M, 2013, INTERDDISC ENG DES, P168, DOI 10.1109/IEDEC.2013.6526781
   Krystal JH, 2020, NAT MED, V26, P639, DOI 10.1038/s41591-020-0878-4
   Kuan G, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00014
   Kurt S, 2014, SAGE OPEN, V4, DOI 10.1177/2158244014525423
   Lai JB, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3976
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Lindner P, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00132
   Litleskare S, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17051738
   Liu CY, 2020, EPIDEMIOL INFECT, V148, DOI 10.1017/S0950268820001107
   Llema CF, 2019, PROCEDIA COMPUT SCI, V161, P1002, DOI 10.1016/j.procs.2019.11.210
   Lopes Adriana, 2018, Journal of Software Engineering Research and Development, V6, DOI 10.1186/s40411-018-0049-1
   Lotko A., 2015, CENTRAL EUROPEAN REV, V8, P5
   LURIA RE, 1975, J PSYCHIATR RES, V12, P51, DOI 10.1016/0022-3956(75)90020-5
   Ma YF, 2020, J AFFECT DISORDERS, V275, P145, DOI 10.1016/j.jad.2020.06.033
   Malone T.W., 1982, P 1982 C HUM FACT CO, P63, DOI DOI 10.1145/800049.801756
   Malone TW., 1980, P 3 ACM SIGSMALL S 1, P162, DOI DOI 10.1145/800088.802839
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Mayring P, 2015, ADVNCS MTHMTCS EDUC, P365, DOI 10.1007/978-94-017-9181-6_13
   McAlonan GM, 2007, CAN J PSYCHIAT, V52, P241, DOI 10.1177/070674370705200406
   Migoya-Borja M, 2020, CYBERPSYCH BEH SOC N, V23, P246, DOI 10.1089/cyber.2019.0497
   Minguillon J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186399
   Müller MR, 2009, RESUSCITATION, V80, P919, DOI 10.1016/j.resuscitation.2009.04.027
   Mummah SA, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5927
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   Norberg-Schulz C., 1980, Genius loci: Towards a phenomenology of architecture
   Norman D.A., 2007, EMOTIONAL DESIGN WHY
   Oculus V. R., 2020, HLTH SAFETY WARNINGS
   Oflaz F, 2008, J CLIN NURS, V17, P677, DOI 10.1111/j.1365-2702.2007.02047.x
   Oing Theodore, 2018, JMIR Serious Games, V6, pe10965, DOI 10.2196/10965
   Orman EK, 2017, J MUSIC TEACH EDUC, V27, P24, DOI 10.1177/1057083717697962
   Pallavicini F., 2009, Journal of CyberTherapy and Rehabilitation, P315, DOI DOI 10.3233/978-1-60750-561-7-39
   Pallavicini F, 2018, PRESENCE-VIRTUAL AUG, V27, P183, DOI 10.1162/PRES_a_00325
   Pallavicini F, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/15635
   Pallavicini F, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02763
   Pallavicini F, 2013, TRIALS, V14, DOI 10.1186/1745-6215-14-191
   Panahi-Shahri M., 2009, J BEHAV SCI, V3, P27
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pedram S, 2020, COMPUT HUM BEHAV, V105, DOI 10.1016/j.chb.2019.106223
   Pizzoli SFM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00479
   Poux F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162583
   Qiu JY, 2020, GEN PSYCHIAT, V33, DOI 10.1136/gpsych-2020-100213
   Reichheld FF, 2003, HARVARD BUS REV, V81, P46
   Repetto Claudia, 2009, J Vis Exp, DOI 10.3791/1554
   Richardson KM, 2017, J OCCUP HEALTH PSYCH, V22, P423, DOI 10.1037/ocp0000066
   Rickwood D, 2005, ADV MENT HEALTH, V4, P218, DOI 10.5172/jamh.4.3.218
   Riva G, 2020, CYBERPSYCH BEH SOC N, V23, P581, DOI 10.1089/cyber.2020.29194.gri
   Riva G, 2020, CYBERPSYCH BEH SOC N, V23, P277, DOI 10.1089/cyber.2020.29183.gri
   Riva Giuseppe, 2012, Stud Health Technol Inform, V173, P369
   Rizzo A, 2009, 2009 VIRTUAL REHABILITATION INTERNATIONAL CONFERENCE, P8, DOI 10.1109/ICVR.2009.5174198
   Rizzo A, 2010, ANN NY ACAD SCI, V1208, P114, DOI 10.1111/j.1749-6632.2010.05755.x
   Rogers JP, 2020, LANCET PSYCHIAT, V7, P611, DOI 10.1016/S2215-0366(20)30203-0
   ROMANO JL, 1992, J COUNS DEV, V71, P199, DOI 10.1002/j.1556-6676.1992.tb02200.x
   Rossi V, 2012, ANXIETY STRESS COPIN, V25, P603, DOI 10.1080/10615806.2011.582948
   Sauro J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2215, DOI 10.1145/1978942.1979266
   Schnall R, 2016, J BIOMED INFORM, V60, P243, DOI 10.1016/j.jbi.2016.02.002
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Seabrook E, 2020, J MED INTERNET RES, V22, DOI 10.2196/16106
   SELYE H, 1973, AM SCI, V61, P692
   Serrano B, 2016, COMPUT HUM BEHAV, V55, P1, DOI 10.1016/j.chb.2015.08.007
   Shechter A, 2020, GEN HOSP PSYCHIAT, V66, P1, DOI 10.1016/j.genhosppsych.2020.06.007
   Shin DH, 2017, TELEMAT INFORM, V34, P1826, DOI 10.1016/j.tele.2017.05.013
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Spielberger CD, 2010, The Corsini Encyclopedia of Psychology, DOI [DOI 10.1002/9780470479216.CORPSY0943, 10.1002/9780470479216.corpsy0943]
   Spoorthy MS, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102119
   Stamm O, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00753-8
   Stetz MC, 2011, MIL MED, V176, P1065, DOI 10.7205/MILMED-D-10-00393
   Tam CWC, 2004, PSYCHOL MED, V34, P1197, DOI 10.1017/S0033291704002247
   Taylor HA, 2011, J BIOMED INFORM, V44, P897, DOI 10.1016/j.jbi.2011.03.001
   Taylor-Rodgers E, 2014, J AFFECT DISORDERS, V168, P65, DOI 10.1016/j.jad.2014.06.047
   Tielman ML, 2017, TECHNOL HEALTH CARE, V25, P1081, DOI 10.3233/THC-170899
   Triberti S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01773
   Vagni M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12145592
   Vailland G, 2019, INT C REHAB ROBOT, P77, DOI [10.1109/icorr.2019.8779496, 10.1109/ICORR.2019.8779496]
   Van Daele T, 2012, HEALTH EDUC BEHAV, V39, P474, DOI 10.1177/1090198111419202
   Vandekerckhove P, 2020, J MED INTERNET RES, V22, DOI 10.2196/13780
   Verschueren S, 2019, JMIR SERIOUS GAMES, V7, DOI 10.2196/11565
   Villani D., 2009, E MINDS INTERATIONAL, V1, P1
   Villani D, 2008, PSYCHNOLOGY J, V6, P7
   Vindegaard N, 2020, BRAIN BEHAV IMMUN, V89, P531, DOI 10.1016/j.bbi.2020.05.048
   Vinstrup J, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.00297
   Virvou M, 2008, COMPUT EDUC, V50, P154, DOI 10.1016/j.compedu.2006.04.004
   Watkins LE, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00258
   Webster R, 2016, INTERACT LEARN ENVIR, V24, P1319, DOI 10.1080/10494820.2014.994533
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Weerasekara M, 2019, INT C ADV COMP SCI I, P285, DOI [10.1109/icacsis47736.2019.8979813, 10.1109/ICACSIS47736.2019.8979813]
   Weiner L, 2020, TRIALS, V21, DOI 10.1186/s13063-020-04772-7
   Wilson W, 2020, INDIAN J PSYCHOL MED, V42, P353, DOI 10.1177/0253717620933992
   Woodson W.E., 1992, HUMAN FACTORS DESIGN, VSecond
   Wu KK, 2005, J TRAUMA STRESS, V18, P39, DOI 10.1002/jts.20004
   Zhang MWB, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00040
   Zhao HY, 2020, J AFFECT DISORDERS, V276, P446, DOI 10.1016/j.jad.2020.07.085
   Zheng W, 2020, J AFFECT DISORDERS, V269, P201, DOI 10.1016/j.jad.2020.03.041
   Zhu JH, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00386
NR 175
TC 9
Z9 10
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 2
PY 2021
VL 2
AR 620225
DI 10.3389/frvir.2021.620225
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WW9
UT WOS:001023295500001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Elor, A
   Kurniawan, S
AF Elor, Aviv
   Kurniawan, Sri
TI The Ultimate Display for Physical Rehabilitation: A Bridging Review on
   Immersive Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE immersive virtual reality; virtual reality therapy; immersion; presence;
   emotion; perception; multimodal displays; biofeedback
ID EXPOSURE THERAPY; STROKE REHABILITATION; EMOTION RECOGNITION;
   SOCIAL-SKILLS; SYSTEM; EEG; ENVIRONMENTS; BEHAVIOR; BALANCE; GAMMA
AB Physical rehabilitation is often an intensive process that presents many challenges, including a lack of engagement, accessibility, and personalization. Immersive media systems enhanced with physical and emotional intelligence can address these challenges. This review paper links immersive virtual reality with the concepts of therapy, human behavior, and biofeedback to provide a high-level overview of health applications with a particular emphasis on physical rehabilitation. We examine each of these crucial areas by reviewing some of the most influential published case studies and theories while also considering their limitations. Lastly, we bridge our review by proposing a theoretical framework for future systems that utilizes various synergies between each of these fields.
C1 [Elor, Aviv; Kurniawan, Sri] Univ Calif Santa Cruz, Jack Baskin Sch Engn, Dept Computat Media, Santa Cruz, CA 95064 USA.
C3 University of California System; University of California Santa Cruz
RP Elor, A (corresponding author), Univ Calif Santa Cruz, Jack Baskin Sch Engn, Dept Computat Media, Santa Cruz, CA 95064 USA.
EM aelor@ucsc.edu
RI Elor, Aviv/AAR-3282-2020
OI Elor, Aviv/0000-0001-5356-3948
FU National Science Foundation [1521532]; University of California Global
   Community Health Wellbeing
FX This material is based upon work supported by the National Science
   Foundation under Grant No. #1521532. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of the National
   Science Foundation. Additionally, AE was supported by the University of
   California Global Community Health Wellbeing 2020 Fellows program.
CR Abdessalem H. B., 2018, 31 INT FLAIRS C MELB
   Aiken MP, 2015, VIRTUAL REAL-LONDON, V19, P95, DOI 10.1007/s10055-015-0260-x
   Al-Nafjan A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7121239
   Amores J, 2018, INT CONF WEARAB IMPL, P98, DOI 10.1109/BSN.2018.8329668
   [Anonymous], 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P1
   [Anonymous], 2000, PRES 2000 3 INT WORK
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Bailenson JN, 2007, HUM-COMPUT INTERACT, V22, P325
   Baldominos A, 2015, PROCEDIA COMPUT SCI, V64, P10, DOI 10.1016/j.procs.2015.08.457
   Bamberg SJM, 2008, IEEE T INF TECHNOL B, V12, P413, DOI 10.1109/TITB.2007.899493
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baumeister J, 2008, NUTR NEUROSCI, V11, P103, DOI 10.1179/147683008X301478
   Beccue M., 2016, RES REPORT VIRTUAL R
   Badia SBI, 2019, IEEE J BIOMED HEALTH, V23, P1877, DOI 10.1109/JBHI.2018.2878846
   Bernard T., 2017, AIAA SPACE and Astronautics Forum and Exposition, P5113, DOI DOI 10.2514/6.2017-5113
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bonnet D., 2011, 2011 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2011), P81, DOI 10.1109/HAVE.2011.6088396
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brigo F, 2011, EPILEPSY BEHAV, V20, P254, DOI 10.1016/j.yebeh.2010.11.009
   Burdea GC, 2003, METHOD INFORM MED, V42, P519
   Byl NN, 2013, J HAND THER, V26, P343, DOI 10.1016/j.jht.2013.06.001
   Bynion T-M., 2020, ENCY PERSONALITY IND, DOI [10.1007/978-3-319-28099-8_77-1, DOI 10.1007/978-3-319-28099-8_77-1]
   Cameirao M., 2008, Journal of CyberTherapy Rehabilitation, V1, P63
   Cameirao MS, 2009, STUD HEALTH TECHNOL, V145, P65, DOI 10.3233/978-1-60750-018-6-65
   Campbell R, 2001, J EPIDEMIOL COMMUN H, V55, P132, DOI 10.1136/jech.55.2.132
   Centers for Disease Control and Prevention, 2019, BRFSS SURV DAT DOC 2
   Chalmers A., 2008, P 24 SPRING C COMP G, P19
   Chittaro L, 2017, INT J HUM-COMPUT ST, V101, P10, DOI 10.1016/j.ijhcs.2017.01.002
   Cohen R.A., 2011, Encyclopedia of Clinical Neuropsychology, P2737, DOI DOI 10.1007/978-0-387-79948-31340
   Collet C, 1997, INT J PSYCHOPHYSIOL, V25, P53, DOI 10.1016/S0167-8760(97)85486-4
   Corbetta D, 2015, J PHYSIOTHER, V61, P117, DOI 10.1016/j.jphys.2015.05.017
   Costello P.J., 1997, HLTH SAFETY ISSUES A
   Critchley HD, 2002, NEUROSCIENTIST, V8, P132, DOI 10.1177/107385840200800209
   Crosbie JH, 2007, DISABIL REHABIL, V29, P1139, DOI 10.1080/09638280600960909
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Csikszentmihalyi M., 1975, BOREDOM ANXIETY EXPE, DOI DOI 10.2307/2065805
   Dascal Julieta, 2017, Innov Clin Neurosci, V14, P14
   de Assis GA, 2016, DISABIL REHABIL-ASSI, V11, P521, DOI 10.3109/17483107.2014.979330
   Deutsch JE, 2007, IEEE T NEUR SYS REH, V15, P30, DOI 10.1109/TNSRE.2007.891384
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Doukakis E, 2019, IEEE T VIS COMPUT GR, V25, P1865, DOI 10.1109/TVCG.2019.2898823
   Eimer M, 2003, COGN AFFECT BEHAV NE, V3, P97, DOI 10.3758/CABN.3.2.97
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elor A, 2018, ACM T ACCESS COMPUT, V11, DOI 10.1145/3265755
   Foster JJ, 2017, PSYCHOL SCI, V28, P929, DOI 10.1177/0956797617699167
   Fox K., 2009, The Smell Report
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Frenkel KA., 1989, COMMUN ACM, V32, P712, DOI DOI 10.1145/63526.63531
   Geethanjali B., 2017, Biomed. Res, V28, P18
   Geldard F.A., 1953, The human senses
   Goedschalk L., 2017, Benelux Conference on Artificial Intelligence, P61
   Gold JI, 2006, CYBERPSYCHOL BEHAV, V9, P207, DOI 10.1089/cpb.2006.9.207
   Goshvarpour A, 2017, BIOMED J, V40, P355, DOI 10.1016/j.bj.2017.11.001
   GREEN JD, 1954, J NEUROPHYSIOL, V17, P533, DOI 10.1152/jn.1954.17.6.533
   Grillon H., 2006, Int. J. Disability Hum. Develop., V5, P243
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Haas L F, 2003, J Neurol Neurosurg Psychiatry, V74, P9, DOI 10.1136/jnnp.74.1.9
   Hasselmo ME, 2005, NEURAL NETWORKS, V18, P1172, DOI 10.1016/j.neunet.2005.08.007
   Hirsch A., 1999, J Neurol Orthop Med Surg, V19, P14
   Hobson JA, 2002, NAT REV NEUROSCI, V3, P679, DOI 10.1038/nrn915
   Hoffman HG, 2011, ANN BEHAV MED, V41, P183, DOI 10.1007/s12160-010-9248-7
   Howden LM, 2010, Age and sex composition; 2010 census briefs
   Hughes JR, 2008, EPILEPSY BEHAV, V13, P25, DOI 10.1016/j.yebeh.2008.01.011
   Iber C., 2007, AASM MANUAL SCORING
   InteraXon, 2019, FEAT RES MUS
   Iruthayarajah J, 2017, TOP STROKE REHABIL, V24, P68, DOI 10.1080/10749357.2016.1192361
   Ischer M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00736
   Jack K, 2010, MANUAL THER, V15, P220, DOI 10.1016/j.math.2009.12.004
   Kairy D, 2013, INT J ENV RES PUB HE, V10, P3998, DOI 10.3390/ijerph10093998
   Kandalaft MR, 2013, J AUTISM DEV DISORD, V43, P34, DOI 10.1007/s10803-012-1544-6
   Kim K., 2014, EMOTION MODELING MAC
   Krönert D, 2019, ADV INTELL SYST, V762, P539, DOI 10.1007/978-3-319-91211-0_47
   Krogmeier C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1032, DOI [10.1109/VR.2019.8798139, 10.1109/vr.2019.8798139]
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lang P.J., 1997, INT AFFECTIVE PICTUR, P39, DOI DOI 10.1027/0269-8803/A000147
   Levac DE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168311
   Lindeman RW, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P337
   Liu MY, 2016, 2016 INTERNATIONAL CONFERENCE ON SMART CITY AND SYSTEMS ENGINEERING (ICSCSE), P157, DOI [10.1109/ICSCSE.2016.16, 10.1109/ICSCSE.2016.0051]
   Liu YS, 2011, LECT NOTES COMPUT SC, V6670, P256, DOI 10.1007/978-3-642-22336-5_13
   Llinás RR, 2014, FRONT CELL NEUROSCI, V8, DOI 10.3389/fncel.2014.00320
   Lloréns R, 2015, ARCH PHYS MED REHAB, V96, P418, DOI 10.1016/j.apmr.2014.10.019
   Lohse KR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093318
   Lubar J., 1995, J PSYCHOEDUCATIONAL, P143
   LUBAR JF, 1991, BIOFEEDBACK SELF-REG, V16, P201, DOI 10.1007/BF01000016
   Lum PS, 2006, J REHABIL RES DEV, V43, P391, DOI 10.1682/JRRD.2005.02.0042
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Marzbani H, 2016, BASIC CLIN NEUROSCI, V7, P143, DOI 10.15412/J.BCN.03070208
   Mazzoni A, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P64, DOI 10.4108/icst.intetain.2015.259625
   McGee-Lennon Marilyn R., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P495, DOI 10.4108/icst.pervasivehealth.2011.246032
   Mellecker RR, 2014, J SCI MED SPORT, V17, P288, DOI 10.1016/j.jsams.2013.05.008
   Mertz L, 2019, IEEE PULSE, V10, P3, DOI 10.1109/MPULS.2019.2911819
   Meuleman B, 2021, IEEE T AFFECT COMPUT, V12, P189, DOI 10.1109/TAFFC.2018.2864730
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   Miri P, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3365107
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Mousavi Hondori Hossein, 2014, J Med Eng, V2014, P846514, DOI 10.1155/2014/846514
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   O'Keefe J, 1999, TRENDS COGN SCI, V3, P403, DOI 10.1016/S1364-6613(99)01396-0
   O'Nuallain S., 2009, Journal of Cognitive Sciences, V4, P46
   Obrist M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2053, DOI 10.1145/2702123.2702361
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pearce PZ, 2008, CURR SPORT MED REP, V7, P171, DOI 10.1097/01.CSMR.0000319712.63793.5f
   Peiris RL, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5452, DOI 10.1145/3025453.3025824
   Picard RW., 2000, AFFECTIVE COMPUTING, DOI [10.7551/mitpress/1140.001.0001, DOI 10.7551/MITPRESS/1140.001.0001]
   Piron L, 2009, J REHABIL MED, V41, P1016, DOI 10.2340/16501977-0459
   Rajae-Joordens RJE, 2008, PHILIPS RES BOOK SER, V8, P77, DOI 10.1007/978-1-4020-6593-4_7
   Ramirez Rafael, 2012, Brain Informatics. International Conference, BI 2012. Proceedings, P175, DOI 10.1007/978-3-642-35139-6_17
   Rangaswamy M, 2002, BIOL PSYCHIAT, V52, P831, DOI 10.1016/S0006-3223(02)01362-8
   REDD WH, 1994, JMRI-J MAGN RESON IM, V4, P623, DOI 10.1002/jmri.1880040419
   Richman LS, 2005, HEALTH PSYCHOL, V24, P422, DOI 10.1037/0278-6133.24.4.422
   Rizzo A, 2014, COMPUTER, V47, P31, DOI 10.1109/MC.2014.199
   Rothbaum BO, 2014, AM J PSYCHIAT, V171, P640, DOI 10.1176/appi.ajp.2014.13121625
   Rus-Calafell M, 2014, J BEHAV THER EXP PSY, V45, P81, DOI 10.1016/j.jbtep.2013.09.002
   Salem Y, 2012, PHYSIOTHERAPY, V98, P189, DOI 10.1016/j.physio.2012.06.003
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Salminen K., 2008, Conference on Human Factors in Computing Systems - Proceedings, P1555, DOI DOI 10.1145/1357054.1357298
   Salovey P, 2000, AM PSYCHOL, V55, P110, DOI 10.1037/0003-066X.55.1.110
   Sandler H., 2012, INACTIVITY PHYSL EFF
   Saposnik G, 2011, STROKE, V42, P1380, DOI 10.1161/STROKEAHA.110.605451
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schweizer T, 2018, J ANXIETY DISORD, V59, P42, DOI 10.1016/j.janxdis.2018.08.005
   Seligman Martin E. P., 2002, HDB POSITIVE PSYCHOL, P4
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Shiban Y, 2015, BEHAV RES THER, V71, P45, DOI 10.1016/j.brat.2015.05.014
   SINGER W, 1995, ANNU REV NEUROSCI, V18, P555, DOI 10.1146/annurev.ne.18.030195.003011
   SIUIJS EM, 1993, PHYS THER, V73, P771, DOI 10.1093/ptj/73.11.771
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Soares R., 2016, Simposio Brasileiro de Jogos e Entretenimento Digital, P81
   Statista, 2020, FOR UN SHIPM AUGM AR
   Steinicke F., 2016, Being Really Virtual: Immersive Natives and the Future of Virtual Reality, P1, DOI DOI 10.1007/978-3-319-43078-2
   Straudi S, 2017, BMC NEUROL, V17, DOI 10.1186/s12883-017-0871-9
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   TEIGEN KH, 1994, THEOR PSYCHOL, V4, P525, DOI 10.1177/0959354394044004
   van Rooij M., 2016, J. Anxiety Disord., P1989, DOI [10.1145/2851581.2892452, DOI 10.1145/2851581.2892452]
   Vanderwolf CH, 2000, BRAIN RES, V855, P217, DOI 10.1016/S0006-8993(99)02351-3
   Walker Peter., 1999, CHAMBERS DICT SCI TE
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Warnock D, 2011, LECT NOTES COMPUT SC, V6947, P572, DOI 10.1007/978-3-642-23771-3_43
   Westwood J. D., 2002, MED MEETS VIRTUAL RE
   WHISHAW IQ, 1973, BEHAV BIOL, V8, P461, DOI 10.1016/S0091-6773(73)80041-0
   Whitham EM, 2008, CLIN NEUROPHYSIOL, V119, P1166, DOI 10.1016/j.clinph.2008.01.024
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf D, 2019, IEEE T VIS COMPUT GR, V25, P3169, DOI 10.1109/TVCG.2019.2932215
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuval-Greenberg S, 2008, NEURON, V58, P429, DOI 10.1016/j.neuron.2008.03.027
NR 155
TC 18
Z9 19
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 12
PY 2020
VL 1
AR 585993
DI 10.3389/frvir.2020.585993
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4TJ8
UT WOS:001023204000001
OA gold
DA 2024-07-18
ER

PT J
AU Rack, C
   Fernando, T
   Yalcin, M
   Hotho, A
   Latoschik, ME
AF Rack, Christian
   Fernando, Tamara
   Yalcin, Murat
   Hotho, Andreas
   Latoschik, Marc Erich
TI Who is Alyx? A new behavioral biometric dataset for user identification
   in XR
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE dataset; behaviometric; deep learning; user identification;
   physiological dataset
AB Introduction: This paper addresses the need for reliable user identification in Extended Reality (XR), focusing on the scarcity of public datasets in this area.Methods: We present a new dataset collected from 71 users who played the game "Half-Life: Alyx" on an HTC Vive Pro for 45 min across two separate sessions. The dataset includes motion and eye-tracking data, along with physiological data from a subset of 31 users. Benchmark performance is established using two state-of-the-art deep learning architectures, Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU).Results: The best model achieved a mean accuracy of 95% for user identification within 2 min when trained on the first session and tested on the second.Discussion: The dataset is freely available and serves as a resource for future research in XR user identification, thereby addressing a significant gap in the field. Its release aims to facilitate advancements in user identification methods and promote reproducibility in XR research.
C1 [Rack, Christian; Fernando, Tamara; Yalcin, Murat; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
   [Hotho, Andreas] Univ Wurzburg, Data Sci Chair, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Rack, C (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
EM christian.rack@uni-wuerzburg.de
OI Rack, Christian/0000-0002-0022-0711
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Ajit A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P9, DOI 10.1109/AIVR46125.2019.00012
   Bhalla A., 2021, P 7 ACM CYBER PHYS S, P41, DOI DOI 10.1145/3457339.3457983
   Biewald L., 2020, Experiment tracking with weights and biases
   Bruns C., 2022, Pyopenvr
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dube T. J., 2019, HUMAN COMPUTER INTER, P419, DOI [DOI 10.1007/978-3-030-22643-5, 10.1007/978-3-030-22643-5\33/TABLES/5, https://doi.org/10.1007/978-3-030-22643-5_33, DOI 10.1007/978-3-030-22643-5_33]
   Falcon William, 2020, Zenodo
   Jain Anil K., 2011, Introduction to Biometrics, DOI [DOI 10.1007/978-0-387-77326-1, 10.1007/978-0-387-77326-1_1]
   Kapoor S, 2022, ARXIV
   Kern F, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.684498
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   Kupin A., 2019, Task-driven biometric authentication of users in virtual reality (VR) environments
   Lee G, 2019, IEEE I CONF COMP VIS, P763, DOI 10.1109/ICCV.2019.00085
   Li SQ, 2016, AER ADV ENG RES, V90, P1
   Liebers J., 2021, Conference on human factors in computing systems-proceedings, P1, DOI DOI 10.1145/3411764.3445528
   Mathis F, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382799
   Miller R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P409, DOI 10.1109/VR51125.2022.00060
   Miller R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P563, DOI 10.1109/VR51125.2022.00076
   Miller R, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P140, DOI 10.1109/VR50410.2021.00035
   Miller R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P311, DOI [10.1109/VRW50115.2020.00070, 10.1109/VRW50115.2020.0-206]
   Moore AG, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P556, DOI 10.1109/VRW52623.2021.00160
   Mustafa T, 2018, IWSPA '18: PROCEEDINGS OF THE FOURTH ACM INTERNATIONAL WORKSHOP ON SECURITY AND PRIVACY ANALYTICS, P23, DOI 10.1145/3180445.3180450
   Nair V., 2023, arXiv, DOI [10.25350/B5NP4V, DOI 10.25350/B5NP4V]
   Olade I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102944
   OpenAI, 2023, Large language model
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Pineau J., 2020, arXiv
   Rack C., 2022, 2022 IEEE INT C ARTI
   Rack C., 2023, arXiv
   Ramesh A., 2022, arXiv
   Rogers CE, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P143, DOI 10.1145/2802083.2808391
   Serra-Garcia M, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abd1705
   Shen YR, 2019, IEEE T DEPEND SECURE, V16, P484, DOI 10.1109/TDSC.2018.2800048
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stephenson S, 2022, P IEEE S SECUR PRIV, P267, DOI [10.1109/SP46214.2022.9833742, 10.1109/SP46214.2022.00123]
   Valve Corportation, 2020, Half-Life: Alyx
   Wang CY, 2021, Arxiv, DOI arXiv:2105.04206
   Wenninger S., 2020, 26 ACM S VIRTUAL REA, P1, DOI [DOI 10.1145/3385956.3418940, 10.1145/3385956.3418940]
NR 39
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 10
PY 2023
VL 4
AR 1272234
DI 10.3389/frvir.2023.1272234
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Y7AY0
UT WOS:001106761700001
OA gold, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Dahmani, L
   Idriss, M
   Konishi, K
   West, GL
   Bohbot, VD
AF Dahmani, Louisa
   Idriss, Miryam
   Konishi, Kyoko
   West, Greg L.
   Bohbot, Veronique D.
TI Considering environmental factors, navigation strategies, and age
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE hippocampus; aging; navigation; sex; navigation strategies
ID OBJECT-LOCATION MEMORY; WATER MAZE PERFORMANCE; RADIAL-ARM MAZE;
   SEX-DIFFERENCES; GENDER-DIFFERENCES; VIRTUAL NAVIGATION; SPATIAL MEMORY;
   CAUDATE-NUCLEUS; ALZHEIMERS-DISEASE; COGNITIVE MAPS
AB Sex differences in navigation have been a topic of investigation for decades and has been subjected to various contradictory findings and debates. The aim of this work was to compare the spatial memory of men and women tested in various different types of spatial tasks, while controlling for navigation strategies and aging. It is generally thought that men outperform women in navigation and that women have higher scores on object location tasks. However, many studies fail to control for different factors that may bias one sex or the other. We aggregated the data of 465 participants (349 young adults, 127 older adults) who took part in various studies conducted in our laboratory, which include both published and original unpublished data, in order to investigate sex differences. In these studies, we used a number of different paradigms: virtual radial arm mazes, a virtual wayfinding task, an object location task, a virtual Morris Water Maze, and the invisible sensor task which is a real-life model of the Morris Water Maze. While our results may seem discordant at first glance, they demonstrate that several factors can impact the performance of men and women on spatial tasks, including spontaneous navigation strategies, environmental characteristics, and age. We replicated findings showing that women favor proximal landmarks compared to men who favor distal landmarks, women have better memory than men for the position of objects in the absence of reference frames, but they will have poorer scores when navigation requires specific angles, distances and polar coordinates. Moreover, we found that in aging, women who avoid the use of landmarks when navigating a radial maze show stronger reliance on these non-spatial strategies than men. On the other hand, women who rely on landmarks, do so to the same extent as men. Our findings highlight the need to carefully take into consideration these factors in order to produce a more harmonious understanding of sex differences in navigation. Finally, the interaction between spontaneous navigation strategies, sex, and age is discussed in terms of its implications for risk of Alzheimer's disease.
C1 [Dahmani, Louisa; Idriss, Miryam; Konishi, Kyoko; Bohbot, Veronique D.] McGill Univ, Douglas Mental Hlth Univ Inst, Fac Med, Dept Psychiat, Verdun, PQ, Canada.
   [West, Greg L.] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
   [Dahmani, Louisa; Konishi, Kyoko] Massachusetts Gen Hosp, Dept Psychiat, Cambridge, MA USA.
   [Dahmani, Louisa; Konishi, Kyoko] Harvard Med Sch, Cambridge, MA USA.
C3 McGill University; Universite de Montreal; Harvard University;
   Massachusetts General Hospital
RP Bohbot, VD (corresponding author), McGill Univ, Douglas Mental Hlth Univ Inst, Fac Med, Dept Psychiat, Verdun, PQ, Canada.
EM veronique.bohbot@mcgill.ca
FU CFI [9357]; CIHR [64381, 82638, 86727, GSD-121804]; NSERC [239896,
   CGSM409063-2011]; FRSQ [2828]; McDonnell Foundation [97-34EE, 9838];
   CNS-QUA Grant Agency of the Czech Republic [309/02/1218/A]
FX Maris Kalnins, Oliver Hardt, Kate Conrad, Rosalind Sham, Kathleen
   MacDonald, Katarina Stepankova. CFI #9357 CIHR 64381, #82638, #86727,
   #GSD-121804 NSERC #239896, #CGSM409063-2011 FRSQ: #2828 McDonnell
   Foundation #97-34EE, #9838 CNS-QUA Grant Agency of the Czech Republic
   #309/02/1218/A.
CR Aguilar-Latorre A, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.838407
   Andersen NE, 2012, NEUROBIOL LEARN MEM, V97, P81, DOI 10.1016/j.nlm.2011.09.007
   Astur RS, 2004, BEHAV BRAIN RES, V151, P103, DOI 10.1016/j.bbr.2003.08.024
   Astur RS, 1998, BEHAV BRAIN RES, V93, P185, DOI 10.1016/S0166-4328(98)00019-9
   Banner H, 2011, EUR J NEUROSCI, V33, P968, DOI 10.1111/j.1460-9568.2010.07550.x
   Barkley CL, 2007, BEHAV NEUROSCI, V121, P291, DOI 10.1037/0735-7044.121.2.291
   Barnes LL, 2005, ARCH GEN PSYCHIAT, V62, P685, DOI 10.1001/archpsyc.62.6.685
   Bohbot VD, 1997, J NEUROL, V244, P529, DOI 10.1007/s004150050139
   Bohbot VD, 2004, NEUROPSYCHOLOGY, V18, P418, DOI 10.1037/0894-4105.18.3.418
   Bohbot VD, 1998, NEUROPSYCHOLOGIA, V36, P1217, DOI 10.1016/S0028-3932(97)00161-9
   Bohbot VD, 2007, J NEUROSCI, V27, P10078, DOI 10.1523/JNEUROSCI.1763-07.2007
   Bohbot VD, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14415
   Brunec IK, 2023, COGNITION, V233, DOI 10.1016/j.cognition.2022.105360
   Caffò AO, 2018, AGING MENT HEALTH, V22, P1372, DOI 10.1080/13607863.2017.1354973
   Castelli L, 2008, COMPUT HUM BEHAV, V24, P1643, DOI 10.1016/j.chb.2007.06.005
   Chai XJ, 2009, BEHAV NEUROSCI, V123, P276, DOI 10.1037/a0014722
   Chamizo VD, 2011, BEHAV PROCESS, V88, P20, DOI 10.1016/j.beproc.2011.06.007
   Chen CH, 2009, J ENVIRON PSYCHOL, V29, P220, DOI 10.1016/j.jenvp.2008.07.003
   Chrastil ER, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112544
   Dabbs JM, 1998, EVOL HUM BEHAV, V19, P89, DOI 10.1016/S1090-5138(97)00107-4
   Dahmani L, 2015, NEUROBIOL LEARN MEM, V117, P42, DOI 10.1016/j.nlm.2014.07.002
   Dahmani L, 2012, BEHAV RES METHODS, V44, P447, DOI 10.3758/s13428-011-0158-9
   den Heijer T, 2006, ARCH GEN PSYCHIAT, V63, P57, DOI 10.1001/archpsyc.63.1.57
   Driscoll I, 2005, HORM BEHAV, V47, P326, DOI 10.1016/j.yhbeh.2004.11.013
   Du AT, 2001, J NEUROL NEUROSUR PS, V71, P441, DOI 10.1136/jnnp.71.4.441
   Etchamendy N, 2007, HIPPOCAMPUS, V17, P595, DOI 10.1002/hipo.20303
   Etchamendy N, 2012, HIPPOCAMPUS, V22, P869, DOI 10.1002/hipo.20948
   Fox NC, 1996, BRAIN, V119, P2001, DOI 10.1093/brain/119.6.2001
   Gamberini L, 2000, CYBERPSYCHOL BEHAV, V3, P337, DOI 10.1089/10949310050078779
   HABIB M, 1987, CORTEX, V23, P73, DOI 10.1016/S0010-9452(87)80020-5
   Hartley T, 2003, NEURON, V37, P877, DOI 10.1016/S0896-6273(03)00095-3
   Head D, 2010, BEHAV BRAIN RES, V209, P49, DOI 10.1016/j.bbr.2010.01.012
   HENDERSON VW, 1994, ARCH NEUROL-CHICAGO, V51, P896, DOI 10.1001/archneur.1994.00540210068014
   HOLDING CS, 1989, J GEN PSYCHOL, V116, P29, DOI 10.1080/00221309.1989.9711108
   Holdstock JS, 2000, NEUROPSYCHOLOGIA, V38, P410, DOI 10.1016/S0028-3932(99)00099-8
   Hussain D, 2016, PSYCHONEUROENDOCRINO, V70, P108, DOI 10.1016/j.psyneuen.2016.05.008
   Iachini T, 2005, BRAIN COGNITION, V59, P52, DOI 10.1016/j.bandc.2005.04.004
   Iaria G, 2003, J NEUROSCI, V23, P5945
   Iaria G, 2008, HIPPOCAMPUS, V18, P335, DOI 10.1002/hipo.20400
   Jagust W, 2006, ANN NEUROL, V59, P673, DOI 10.1002/ana.20799
   Kaye JA, 1997, NEUROLOGY, V48, P1297, DOI 10.1212/WNL.48.5.1297
   Konishi K, 2013, HIPPOCAMPUS, V23, P1005, DOI 10.1002/hipo.22181
   Konishi K, 2013, FRONT AGING NEUROSCI, V5, DOI 10.3389/fnagi.2013.00001
   Lawton CA, 1999, SEX ROLES, V40, P73, DOI 10.1023/A:1018830401088
   Ledoux AA, 2013, PSYCHIAT RES-NEUROIM, V211, P47, DOI 10.1016/j.pscychresns.2012.10.005
   Levy LJ, 2005, BEHAV NEUROSCI, V119, P853, DOI 10.1037/0735-7044.119.4.853
   Lopez A, 2022, NEUROL INT, V14, P771, DOI 10.3390/neurolint14040064
   Lopez A, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10110774
   Lopez A, 2020, J ENVIRON PSYCHOL, V68, DOI 10.1016/j.jenvp.2020.101392
   Maguire EA, 1999, CURR OPIN NEUROBIOL, V9, P171, DOI 10.1016/S0959-4388(99)80023-3
   Maguire EA, 1998, J NEUROL NEUROSUR PS, V65, P903, DOI 10.1136/jnnp.65.6.903
   Marighetto A, 1999, EUR J NEUROSCI, V11, P3312, DOI 10.1046/j.1460-9568.1999.00741.x
   McCarthy RA, 1996, J NEUROL NEUROSUR PS, V60, P318, DOI 10.1136/jnnp.60.3.318
   Mielke MM, 2012, ALZHEIMERS DEMENT, V8, P105, DOI 10.1016/j.jalz.2011.05.2416
   Moffat SD, 2007, CEREB CORTEX, V17, P1274, DOI 10.1093/cercor/bhl036
   Montello DR, 2017, KUNSTL INTELL, V31, P193, DOI 10.1007/s13218-016-0473-5
   Montello DR, 1999, ANN ASSOC AM GEOGR, V89, P515, DOI 10.1111/0004-5608.00160
   MORRIS RGM, 1981, LEARN MOTIV, V12, P239, DOI 10.1016/0023-9690(81)90020-5
   Mueller SC, 2008, BEHAV BRAIN RES, V193, P209, DOI 10.1016/j.bbr.2008.05.017
   Nadel L, 2004, NEUROPSYCHOLOGY, V18, P473, DOI 10.1037/0894-4105.18.3.473
   Newhouse P, 2007, BEHAV BRAIN RES, V183, P1, DOI 10.1016/j.bbr.2007.05.011
   Nowak NT, 2011, ARCH SEX BEHAV, V40, P575, DOI 10.1007/s10508-010-9668-2
   O'Keefe J., 1978, HIPPOCAMPUS COGNITIV, V3
   OLTON DS, 1976, J EXP PSYCHOL-ANIM B, V2, P97, DOI 10.1037/0097-7403.2.2.97
   Overman WH, 1996, BEHAV NEUROSCI, V110, P1205, DOI 10.1037/0735-7044.110.6.1205
   PACKARD MG, 1989, J NEUROSCI, V9, P1465
   Piccardi L, 2011, NEUROSCI LETT, V503, P181, DOI 10.1016/j.neulet.2011.08.031
   Postma A, 1998, BRAIN COGNITION, V36, P334, DOI 10.1006/brcg.1997.0974
   Postma A, 2004, BRAIN COGNITION, V54, P24, DOI 10.1016/S0278-2626(03)00238-0
   Pruessner JC, 2001, J NEUROSCI, V21, P194, DOI 10.1523/JNEUROSCI.21-01-00194.2001
   Reiman EM, 1998, ANN NEUROL, V44, P288, DOI 10.1002/ana.410440226
   Rizk-Jackson AM, 2006, BEHAV BRAIN RES, V173, P181, DOI 10.1016/j.bbr.2006.06.029
   Roof RL, 1999, PHYSIOL BEHAV, V68, P81, DOI 10.1016/S0031-9384(99)00162-6
   Ruggiero G, 2008, MEMORY, V16, P821, DOI 10.1080/09658210802307695
   Sandstrom NJ, 1998, COGNITIVE BRAIN RES, V6, P351, DOI 10.1016/S0926-6410(98)00002-0
   Saucier D, 2007, J INT NEUROPSYCH SOC, V13, P683, DOI 10.1017/S1355617707070865
   Saucier DM, 2002, BEHAV NEUROSCI, V116, P403, DOI 10.1037//0735-7044.116.3.403
   Silverman I., 1992, M INT SOC HUM ETH BR
   Sodums DJ, 2020, HIPPOCAMPUS, V30, P892, DOI 10.1002/hipo.23210
   Spiers HJ, 2001, HIPPOCAMPUS, V11, P715, DOI 10.1002/hipo.1087
   Spiers HJ, 2023, TOP COGN SCI, V15, P120, DOI 10.1111/tops.12590
   Stepankova K, 2004, NEUROPSYCHOLOGIA, V42, P1017, DOI 10.1016/j.neuropsychologia.2004.01.002
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   van Gerven DJH, 2012, BEHAV NEUROSCI, V126, P465, DOI 10.1037/a0027992
   Voyer D, 2007, PSYCHON B REV, V14, P23, DOI 10.3758/BF03194024
   WERTLIEB D, 1979, DEV PSYCHOL, V15, P478, DOI 10.1037/h0078085
   West GL, 2018, MOL PSYCHIATR, V23, P1566, DOI 10.1038/mp.2017.155
   White NM, 2002, NEUROBIOL LEARN MEM, V77, P125, DOI 10.1006/nlme.2001.4008
   Wolbers T, 2010, TRENDS COGN SCI, V14, P138, DOI 10.1016/j.tics.2010.01.001
   Woolley DG, 2010, BEHAV BRAIN RES, V208, P408, DOI 10.1016/j.bbr.2009.12.019
NR 90
TC 1
Z9 1
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 4
PY 2023
VL 4
AR 1166364
DI 10.3389/frvir.2023.1166364
PG 27
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA R8PJ9
UT WOS:001066918800001
OA gold
DA 2024-07-18
ER

PT J
AU Gil-López, C
   Guixeres, J
   Marín-Morales, J
   Torrecilla, C
   Williams, E
   Alcañiz, M
AF Gil-Lopez, Cristina
   Guixeres, Jaime
   Marin-Morales, Javier
   Torrecilla, Carmen
   Williams, Edu
   Alcaniz, Mariano
TI Is mixed reality technology an effective tool for retail? A vividness
   and interaction perspective
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; interactivity; immersion; consumer behavior; smart
   glasses in retail; instore experience
ID AUGMENTED REALITY; LOCAL PRESENCE; SHOPPING VALUE; ACCEPTANCE;
   EXPERIENCE; IMPACT; MEDIA; ADOPTION; GLASSES; STORES
AB There is increasing interest in studies analyzing the influence of technologies that integrate virtual and real-world components on consumer behavior. These technologies include augmented reality, virtual reality and mixed reality. Mixed reality is a user environment in which physical reality and digital content are combined in a way that enables interaction with and among real-world and virtual objects. In spite of previous works related with MR and retails spaces, little is known about how consumers respond to MR features and which elements of the MR-based experience, such as vividness and novelty, impact behavior. In this study, we have explored the relative advantage of mixed reality in retail shopping practices over a traditional-based purchase. Implicit reactions of shoppers when interacting with products with and without MR glasses were compared. The results reveal that participants wearing MR glasses exhibited different patterns of interaction (i.e., frequency and interaction with product duration) that differed from those indicated by participants who did not wear the MR technology. At the level of purchase decision, our results show that the use of MR smart glasses has an impact on decision times that relates to a utilitarian purchase type. Based on participants' explicit answers to questionnaires, the reported findings further show that the perceived hedonic and utilitarian values of the purchase experience were higher when MR was used, which also affected future purchase intentions and perceived emotional state as reported by consumers' experience and satisfaction in the context of retail.
C1 [Gil-Lopez, Cristina; Guixeres, Jaime; Marin-Morales, Javier; Torrecilla, Carmen; Alcaniz, Mariano] Univ Politecn Valencia, Inst Invest & Innovac Bioingn i3B, Valencia, Spain.
   [Williams, Edu] Univ Las Palmas Gran Canaria, Dept Econ & Direcc Empresas, Las Palmas Gran Canaria, Spain.
C3 Universitat Politecnica de Valencia; Universidad de Las Palmas de Gran
   Canaria
RP Guixeres, J (corresponding author), Univ Politecn Valencia, Inst Invest & Innovac Bioingn i3B, Valencia, Spain.
EM jaiguipr@i3b.upv.es
RI Marin, Javier/AAL-1463-2020; Alcaniz, Mariano/I-9659-2016
OI Marin, Javier/0000-0003-1271-2892; Alcaniz, Mariano/0000-0001-9207-0636;
   Gil-Lopez, Cristina/0000-0001-5024-1716
FU European Commission [RHUMBO H2020-MSCA-ITN-2018-813234]; Generalitat
   Valenciana [PROMETEU/2019/105]; European Regional Development Fund
   program of the Valencian Community 2014-2020 project "Interfaces de
   Realidad mixta Aplicada a Salud y toma de decisiones"
   [IDIFEDER/2018/029]
FX This work was supported by the European Commission (Project RHUMBO
   H2020-MSCA-ITN-2018-813234), by the Generalitat Valenciana funded
   project "Rebrand", grant number PROMETEU/2019/105, and by the European
   Regional Development Fund program of the Valencian Community 2014-2020
   project "Interfaces de Realidad mixta Aplicada a Salud y toma de
   decisiones", grant number IDIFEDER/2018/029.
CR Alcañiz M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01530
   [Anonymous], 2016, LUXURY DAILY
   Arghashi V, 2022, ELECTRON COMMER R A, V54, DOI 10.1016/j.elerap.2022.101166
   Arghashi V, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102756
   Barnes S. J., 2019, Progress in IS, P17, DOI [10.1007/978-3-030-06246-0_2, DOI 10.1007/978-3-030-06246-0_2]
   Bonetti F., 2019, International Journal of Technology Marketing, V13, P260
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brengman M, 2019, VIRTUAL REAL-LONDON, V23, P269, DOI 10.1007/s10055-018-0335-6
   Caboni F, 2019, INT J RETAIL DISTRIB, V47, P1125, DOI 10.1108/IJRDM-12-2018-0263
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Childers TL, 2001, J RETAILING, V77, P511, DOI 10.1016/S0022-4359(01)00056-2
   Chiu CL, 2021, J RETAIL CONSUM SERV, V61, DOI 10.1016/j.jretconser.2021.102561
   Daassi M, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103453
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   de Amorim IP, 2022, INT J CONSUM STUD, V46, P2351, DOI 10.1111/ijcs.12790
   Dehghani M, 2020, TECHNOL SOC, V63, DOI 10.1016/j.techsoc.2020.101394
   Elboudali A, 2020, INT J INTERACT DES M, V14, P551, DOI 10.1007/s12008-020-00645-0
   Endsley Tristan C., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2100, DOI 10.1177/1541931213602007
   Fan XJ, 2020, J RETAIL CONSUM SERV, V53, DOI 10.1016/j.jretconser.2019.101986
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Friard O, 2016, METHODS ECOL EVOL, V7, P1325, DOI 10.1111/2041-210X.12584
   Garaus M, 2015, J BUS RES, V68, P1003, DOI 10.1016/j.jbusres.2014.10.002
   Grand View Research, 2020, AUG REAL MARK SIZ SH
   Grewal D, 2020, J ACAD MARKET SCI, V48, P96, DOI 10.1007/s11747-019-00697-z
   Grewal D, 2017, J RETAILING, V93, P1, DOI 10.1016/j.jretai.2016.12.008
   Hauser JR, 2014, J BUS RES, V67, P1688, DOI 10.1016/j.jbusres.2014.02.015
   He JB, 2015, ACCIDENT ANAL PREV, V81, P218, DOI 10.1016/j.aap.2015.03.033
   Hertzum M, 2013, INT J HUM-COMPUT INT, V29, P26, DOI 10.1080/10447318.2012.676538
   Herz M, 2019, TECHNOL FORECAST SOC, V138, P228, DOI 10.1016/j.techfore.2018.09.008
   Hilken T, 2017, J ACAD MARKET SCI, V45, P884, DOI 10.1007/s11747-017-0541-x
   Hoffmann S, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.961236
   Hoffmann S, 2022, J ACAD MARKET SCI, V50, P743, DOI 10.1007/s11747-022-00855-w
   Holdack E, 2022, J RETAIL CONSUM SERV, V65, DOI 10.1016/j.jretconser.2020.102259
   Inman JJ, 2017, J RETAILING, V93, P7, DOI 10.1016/j.jretai.2016.12.006
   Jain S, 2021, LECT NOTES COMPUT SC, V13017, P504, DOI 10.1007/978-3-030-90439-5_40
   Jain S, 2019, LECT NOTES COMPUT SC, V11588, P22, DOI 10.1007/978-3-030-22335-9_2
   Javaheri Hamraz, 2020, MobiQuitous '20: MobiQuitous 2020 - 17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services, P464, DOI 10.1145/3448891.3448930
   Javornik A, 2016, J RETAIL CONSUM SERV, V30, P252, DOI 10.1016/j.jretconser.2016.02.004
   Jeffri NFS, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06277
   Jessen A, 2020, J BUS RES, V116, P85, DOI 10.1016/j.jbusres.2020.05.002
   Joerss T, 2021, J BUS RES, V128, P510, DOI 10.1016/j.jbusres.2021.02.019
   Jones MA, 2006, J BUS RES, V59, P974, DOI 10.1016/j.jbusres.2006.03.006
   Kalantari Mahdokht, 2017, International Journal of Technology Marketing, V12, P274
   Kalantari M, 2018, PROGR IS, P229, DOI 10.1007/978-3-319-64027-3_16
   Kang HJ, 2020, J INTERACT MARK, V49, P70, DOI 10.1016/j.intmar.2019.07.002
   Kazmi SHA, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132414064
   Kim M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153171
   King WR, 2006, INFORM MANAGE-AMSTER, V43, P740, DOI 10.1016/j.im.2006.05.003
   Lavoye V, 2021, INT REV RETAIL DISTR, V31, P299, DOI 10.1080/09593969.2021.1901765
   Lecointre-Erickson D, 2018, INT J RETAIL DISTRIB, V46, P802, DOI 10.1108/IJRDM-05-2017-0111
   Lei X, 2023, INT J HUM-COMPUT INT, V39, P1280, DOI 10.1080/10447318.2022.2062548
   Libai B, 2020, J INTERACT MARK, V51, P44, DOI 10.1016/j.intmar.2020.04.002
   McFarland DJ, 2006, COMPUT HUM BEHAV, V22, P427, DOI 10.1016/j.chb.2004.09.009
   McLean G, 2019, COMPUT HUM BEHAV, V101, P210, DOI 10.1016/j.chb.2019.07.002
   Meegahapola Lakmal, 2017, 2017 Seventeenth International Conference on Advances in ICT for Emerging Regions (ICTer), P1, DOI 10.1109/ICTER.2017.8257810
   Microsoft, 2020, HOL 2 WEB PAG INF
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milgram P., 2006, M P TOR U
   Monteiro P, 2019, INT J WINE BUS RES, V32, P161, DOI 10.1108/IJWBR-03-2019-0017
   Morozova D, 2021, INT J CONSUM STUD, V45, P1335, DOI 10.1111/ijcs.12656
   Morwitz V, 2012, FOUND TRENDS MARKET, V7, P181, DOI 10.1561/1700000036
   Nikhashemi SR, 2021, J RETAIL CONSUM SERV, V60, DOI 10.1016/j.jretconser.2021.102464
   Olsson T, 2013, PERS UBIQUIT COMPUT, V17, P287, DOI 10.1007/s00779-011-0494-x
   Omar S, 2021, J RETAIL CONSUM SERV, V60, DOI 10.1016/j.jretconser.2021.102468
   Oyman M, 2022, COMPUT HUM BEHAV, V128, DOI 10.1016/j.chb.2021.107127
   Pantano E, 2017, J RETAIL CONSUM SERV, V38, P81, DOI 10.1016/j.jretconser.2017.05.011
   Pantano Eleonora, 2012, Journal of Technology Management & Innovation, V7, P1
   Park M, 2020, J RETAIL CONSUM SERV, V52, DOI 10.1016/j.jretconser.2019.101912
   Peukert C, 2019, J MANAGE INFORM SYST, V36, P755, DOI 10.1080/07421222.2019.1628889
   Plotkina D, 2019, J RETAIL CONSUM SERV, V51, P362, DOI 10.1016/j.jretconser.2019.07.002
   Poushneh A, 2017, J RETAIL CONSUM SERV, V34, P229, DOI 10.1016/j.jretconser.2016.10.005
   Rauschnabel Philipp A., 2016, International Journal of Technology Marketing, V11, P123
   Rauschnabel PA, 2018, J BUS RES, V92, P374, DOI 10.1016/j.jbusres.2018.08.008
   Rejeb A, 2021, INT J PROD RES, V59, P3747, DOI 10.1080/00207543.2021.1876942
   Rese A, 2017, TECHNOL FORECAST SOC, V124, P306, DOI 10.1016/j.techfore.2016.10.010
   Riar M, 2023, INTERNET RES, V33, P242, DOI 10.1108/INTR-08-2021-0611
   Robertson Jeandri, 2018, Journal of Wine Research, V29, P159, DOI 10.1080/09571264.2018.1505605
   Romano B, 2021, AUSTRALAS MARK J, V29, P354, DOI 10.1016/j.ausmj.2020.06.010
   Scholz J, 2016, BUS HORIZONS, V59, P149, DOI 10.1016/j.bushor.2015.10.003
   Shankar V, 2016, J INTERACT MARK, V34, P37, DOI 10.1016/j.intmar.2016.03.002
   Skinner E.A., 2009, Handbook of motivation at school, P223, DOI DOI 10.1037/0003-066X.55.1.68
   Sohn D, 2011, NEW MEDIA SOC, V13, P1320, DOI 10.1177/1461444811405806
   Tan YC, 2022, J MARKETING, V86, P48, DOI 10.1177/0022242921995449
   van Esch P, 2019, J RETAIL CONSUM SERV, V49, P35, DOI 10.1016/j.jretconser.2019.03.002
   Verhagen T, 2014, COMPUT HUM BEHAV, V39, P270, DOI 10.1016/j.chb.2014.07.036
   Vonkeman C, 2017, INFORM MANAGE-AMSTER, V54, P1038, DOI 10.1016/j.im.2017.02.008
   Wang RJH, 2020, COMPUT HUM BEHAV, V106, DOI 10.1016/j.chb.2020.106245
   Watson A, 2020, INT J RETAIL DISTRIB, V48, P433, DOI 10.1108/IJRDM-06-2017-0117
   Whang JB, 2021, J BUS RES, V133, P275, DOI 10.1016/j.jbusres.2021.04.057
   Xie JH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218333
   Yim MYC, 2017, J INTERACT MARK, V39, P89, DOI 10.1016/j.intmar.2017.04.001
NR 92
TC 0
Z9 0
U1 4
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 11
PY 2023
VL 4
AR 1067932
DI 10.3389/frvir.2023.1067932
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UW2
UT WOS:001023242500001
OA gold
DA 2024-07-18
ER

PT J
AU Cunha, F
   Campos, S
   Simoes-Silva, V
   Brugada-Ramentol, V
   Sá-Moura, B
   Jalali, H
   Bozorgzadeh, A
   Trigueiro, MJ
AF Cunha, Filipa
   Campos, Sara
   Simoes-Silva, Vitor
   Brugada-Ramentol, Victoria
   Sa-Moura, Bebiana
   Jalali, Hossein
   Bozorgzadeh, Amir
   Trigueiro, Maria Joao
TI The effect of a virtual reality based intervention on processing speed
   and working memory in individuals with ADHD-A pilot-study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE attention deficit and hyperactivity disorder; executive functions;
   processing speed; working memory; virtual reality; cognitive training
ID ATTENTION-DEFICIT/HYPERACTIVITY DISORDER; DEFICIT HYPERACTIVITY
   DISORDER; EXECUTIVE FUNCTIONS; ADULTS; CHILDREN; INATTENTION; CLASSROOM;
   STUDENTS
AB Introduction: This study aimed to evaluate the effectiveness of a virtual reality based intervention in processing speed and working memory in students with ADHD symptomatology.Methods: A randomized experimental study was conducted, with a sample consisting of 25 adult participants recruited from the Escola Superior de Saude do Politecnico do Porto. The participants were allocated into two groups: a passive control group and an intervention group that completed 10 sessions using virtual reality-based games from the Enhance VR app. The intervention included 6 games: Whack-a-mole, Shuffled, Assembly, React, Memory Wall, and Maestro. The participants underwent pre- and post-intervention evaluations using the Southwestern Assessment of Processing Speed (SWAPS) and the Sequence of Letters and Numbers and Spatial Location of the Wechsler Adult Intelligence Scale - 3(rd) Edition - WAIS-III. Descriptive statistics were used to characterize the sample and a mixed ANOVA was used to test the effectiveness of the intervention.Results: There was an improvement in the results of processing speed in the group exposed to the intervention (p < 0.001) and the value of the interaction between intervention and time was also significant (p = 0.004). There were no statistically significant differences between the participants' working memory in the different variables under study, except for the values of the Spatial location test in the experimental group that improved relative to the initial assessment (p = 0.034).Discussion: A virtual reality cognitive training intervention resulted in improvements in the processing speed measures, which were not found in the control group. Although we cannot make the same conclusions regarding working memory, these results suggest that the VR intervention resulted in progress in the experimental group, possibly influenced by the intervention, which should be verified in future studies with longer interventions.
C1 [Cunha, Filipa; Campos, Sara; Simoes-Silva, Vitor; Trigueiro, Maria Joao] Polytech Inst Porto, Ctr Rehabil Res, Psychosocial Rehabil Unit, Sch Hlth, Porto, Portugal.
   [Brugada-Ramentol, Victoria; Sa-Moura, Bebiana; Jalali, Hossein; Bozorgzadeh, Amir] Virtuleap, Lisbon, Portugal.
C3 Instituto Politecnico do Porto
RP Trigueiro, MJ (corresponding author), Polytech Inst Porto, Ctr Rehabil Res, Psychosocial Rehabil Unit, Sch Hlth, Porto, Portugal.
EM mjtrigueiro@ess.ipp.pt
RI Trigueiro, Maria/AAJ-7805-2021; Simões-Silva, Vítor/HSH-5170-2023
OI Trigueiro, Maria/0000-0003-4439-7196; Simões-Silva,
   Vítor/0000-0003-2831-9729; Sa-Moura, Bebiana/0000-0003-2943-8818
CR Aaker D., 2019, MARK RES
   Adalio CJ, 2018, J ABNORM CHILD PSYCH, V46, P701, DOI 10.1007/s10802-017-0336-z
   Akshoomoff N, 2018, NEUROPSYCHOLOGY, V32, P777, DOI 10.1037/neu0000476
   Al-Yagon M, 2018, PERS RELATIONSHIP, V25, P280, DOI 10.1111/pere.12232
   Alaghband-rad J, 2021, J NERV MENT DIS, V209, P35, DOI 10.1097/NMD.0000000000001247
   Alloway T. P., 2006, Academic Journals, V1, P134
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], 2013, Bull World Health Organ, V79, P373
   AppSorteos, 2022, ABOUT US
   Areces D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201039
   Association American Psychiatric, 2014, DSM 5 MAN DIAGN EST
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Barati Z., 2021, Journal of Arak University of Medical Sciences, V24, DOI [10.32598/jams.24.5.6493.1, DOI 10.32598/JAMS.24.5.6493.1]
   Barkley RA, 2016, J ABNORM PSYCHOL, V125, P248, DOI 10.1037/abn0000125
   Bashiri Azadeh, 2017, Korean J Pediatr, V60, P337, DOI 10.3345/kjp.2017.60.11.337
   Beins B. C., 2018, RES METHODS STAT PSY
   Bian ZX, 2011, ANN INTERN MED, V154, P290, DOI 10.7326/0003-4819-154-4-201102150-00016
   Biederman J, 2010, PSYCHIAT RES, V177, P299, DOI 10.1016/j.psychres.2009.12.010
   Bioulac S, 2020, J ATTEN DISORD, V24, P326, DOI 10.1177/1087054718759751
   Bioulac S, 2012, EUR J PAEDIATR NEURO, V16, P514, DOI 10.1016/j.ejpn.2012.01.006
   Birx H., 2016, J NUCL MED, V52, P26
   Blume F, 2019, LEARN INSTR, V61, P138, DOI 10.1016/j.learninstruc.2018.10.004
   Brugada-Ramentol V., 2022, FRONT DIGIT HEALTH, P4
   Bul KCM, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5173
   Butzbach M, 2019, J NEURAL TRANSM, V126, P1347, DOI 10.1007/s00702-019-02049-1
   Caye A, 2019, MOL PSYCHIATR, V24, P390, DOI 10.1038/s41380-018-0116-3
   Chamberlain SR, 2017, CNS SPECTRUMS, V22, P22, DOI 10.1017/S1092852915000875
   Chen SX, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.810298
   Cho BH, 2004, CYBERPSYCHOL BEHAV, V7, P519, DOI 10.1089/cpb.2004.7.519
   Cho BH, 2002, P IEEE VIRT REAL ANN, P156, DOI 10.1109/VR.2002.996518
   Cho BH, 2002, CYBERPSYCHOL BEHAV, V5, P129, DOI 10.1089/109493102753770516
   Coelho RM, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245113
   Coleman B, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01851
   Cook NE, 2019, CHILD PSYCHIAT HUM D, V50, P1049, DOI 10.1007/s10578-019-00904-6
   Cook NE, 2018, CHILD NEUROPSYCHOL, V24, P598, DOI 10.1080/09297049.2017.1307952
   Cross-Villasana F, 2015, BIOL PSYCHIAT, V78, P107, DOI 10.1016/j.biopsych.2015.01.016
   Cullum CM, 2022, CLIN NEUROPSYCHOL, V36, P2260, DOI 10.1080/13854046.2021.1970229
   De Crescenzo F, 2017, EVID-BASED MENT HEAL, V20, P4, DOI 10.1136/eb-2016-102415
   Dentz A, 2020, J ATTEN DISORD, V24, P918, DOI 10.1177/1087054717723987
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Díaz-Orueta U, 2014, CHILD NEUROPSYCHOL, V20, P328, DOI 10.1080/09297049.2013.792332
   Georgiev DD, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11020221
   Gibson K., 2015, Vis Dev Rehab, V1, P120, DOI DOI 10.31707/VDR2015.1.2.P120
   Goharinejad S, 2022, BMC PSYCHIATRY, V22, DOI 10.1186/s12888-021-03632-1
   Goldberg A. E., 2016, SAGE ENCY LGBTQ STUD, P44
   Gropper RJ, 2014, J ATTEN DISORD, V18, P331, DOI 10.1177/1087054713516490
   Hervey AS, 2004, NEUROPSYCHOLOGY, V18, P485, DOI 10.1037/0894-4105.18.3.485
   Hong N, 2022, J ATTEN DISORD, V26, P358, DOI 10.1177/1087054720986229
   IBM, 2021, IBM STAT PACK SOC SC, P2021
   Jjs Kooij., 2010, DIAGNOSTIC INTERVIEW
   Kastner L, 2022, AM J OCCUP THER, V76, DOI 10.5014/ajot.2022.046417
   Kibby MY, 2019, CHILD NEUROPSYCHOL, V25, P964, DOI 10.1080/09297049.2018.1556625
   Kooij J. J. S., 2007, DIAGNOSTIC INTERVIEW
   Lee JM, 2001, P ANN INT IEEE EMBS, V23, P3754, DOI 10.1109/IEMBS.2001.1019654
   Leib SI, 2021, DEV NEUROPSYCHOL, V46, P574, DOI 10.1080/87565641.2021.1999454
   Lopez PL, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010840.pub2
   Maroco J., 2014, ANALISE ESTATISTICA
   Martinussen R, 2005, J AM ACAD CHILD PSY, V44, P377, DOI 10.1097/01.chi.0000153228.72591.73
   Mawjee K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137173
   Milla-Cano C, 2020, AV PSICOL LATINOAM, V38, DOI 10.12804/revistas.urosario.edu.co/apl/a.7743
   Mohamed SMH, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256228
   Mukherjee P, 2021, NEUROIMAGE-CLIN, V30, DOI 10.1016/j.nicl.2021.102662
   Nimmo-Smith V, 2020, PSYCHOL MED, V50, P529, DOI 10.1017/S0033291720000069
   Owen AM, 2010, NATURE, V465, P775, DOI 10.1038/nature09042
   Palacios-Cruz L, 2018, SALUD MENT, V41, P297, DOI [10.17711/sm.0185-3325.2018.042, 10.17711/SM.0185-3325.2018.042]
   Park JS, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8030335
   Plowden KO, 2022, ARCH PSYCHIAT NURS, V38, P29, DOI 10.1016/j.apnu.2021.12.003
   Polanczyk GV, 2014, INT J EPIDEMIOL, V43, P434, DOI 10.1093/ije/dyt261
   Pollak Y, 2009, J DEV BEHAV PEDIATR, V30, P2, DOI 10.1097/DBP.0b013e3181969b22
   Quintero J, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-017-1581-y
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Robiner WN, 2005, CONTEMP CLIN TRIALS, V26, P59, DOI 10.1016/j.cct.2004.11.015
   Rodrigo-Yanguas M, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/26824
   Rösler M, 2010, WORLD J BIOL PSYCHIA, V11, P684, DOI 10.3109/15622975.2010.483249
   Romero-Ayuso D, 2021, CHILDREN-BASEL, V8, DOI 10.3390/children8020070
   Roselló B, 2020, BMC PSYCHIATRY, V20, DOI 10.1186/s12888-020-02542-y
   Roshannia S., 2021, INT CLIN NEUROSCI J, V8, P60, DOI [10.34172/icnj.2021.14, DOI 10.34172/ICNJ.2021.14]
   Sabhlok A, 2022, DEVELOPMENTAL SCI, V25, DOI 10.1111/desc.13168
   Salomone S, 2020, J ATTEN DISORD, V24, P1413, DOI 10.1177/1087054715623045
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sandhu A, 2021, AUSTRALAS PSYCHIATRY, V29, P75, DOI 10.1177/1039856220947941
   Savci U., 2019, PSIKIYATRIDE GUNCEL, V11, P223, DOI [10.18863/pgy.424793, DOI 10.18863/PGY.424793]
   Schiffman L., 2000, CONSUM BEHAV, P3
   Sheard J, 2018, RESEARCH METHODS: INFORMATION, SYSTEMS, AND CONTEXTS, 2ND EDITION, P429, DOI 10.1016/B978-0-08-102220-7.00018-2
   Shema-Shiratzky S, 2019, DEV NEUROREHABIL, V22, P431, DOI 10.1080/17518423.2018.1476602
   Smith P., 2015, AUST NZ J PUBL HEAL, V41, P452
   Stern A, 2016, J ATTEN DISORD, V20, P991, DOI 10.1177/1087054714529815
   Tabrizi M, 2020, INT ARCH HEALTH SCI, V7, P37, DOI 10.4103/iahs.iahs_66_19
   Tulsky D.S., 2003, CLIN INTERPRETATION, P43
   Wechsler D., 2008, WAIS-III: Manual da Escala de Inteligencia de Wechsler para Adultos, V3
   Weibel S, 2020, ENCEPHALE, V46, P30, DOI 10.1016/j.encep.2019.06.005
   WELSH MC, 1988, DEV NEUROPSYCHOL, V4, P199, DOI 10.1080/87565648809540405
   Zhao XX, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00348
   Zweben A, 2009, DRUG INF J, V43, P459, DOI 10.1177/009286150904300411
NR 96
TC 2
Z9 2
U1 5
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 24
PY 2023
VL 4
AR 1108060
DI 10.3389/frvir.2023.1108060
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4SB0
UT WOS:001023169000001
OA gold
DA 2024-07-18
ER

PT J
AU Takahashi, M
   Nagano, H
   Tazaki, Y
   Yokokohji, Y
AF Takahashi, Minami
   Nagano, Hikaru
   Tazaki, Yuichi
   Yokokohji, Yasuyoshi
TI Effective haptic feedback type for robot-mediated material
   discrimination depending on target properties
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE vibrotactile display; force display; material perception; haptic
   feedback; robot teleoperation
ID CONTACT; TELEOPERATION; PERCEPTION
AB Haptic feedback enables material perception via remote robotics. Both force and vibration information are essential for haptic feedback, and it is important to understand their applicability in different situations. In this study, the relationship between the effective type of haptic feedback and target properties in robot-mediated material discrimination was investigated. A remote-control system including a force presentation device and a wearable vibrotactile display was constructed. In the first experiment, the discrimination performance of material hardness was compared between two types of feedback, force and hybrid (vibrotactile and force) conditions. The results show that both feedback systems allow statistically-significant discrimination of the stimuli, and a significant difference in correct-answer rates between the two feedback conditions was not observed. This indicates that the force system was effective for hardness discrimination, and that there was no superimposed effect of the hybrid system. In the second experiment, the discrimination performance of material roughness was compared between three types of feedback (force, vibrotactile, and hybrid). The results indicate that the rate of correct responses for hybrid feedback condition are significantly higher than those for the force condition. This suggests that hybrid feedback is effective for roughness discrimination. Therefore, the effective type of feedback depends on the properties of target materials, and the superimposed effect of hybrid feedback was only observed in roughness discrimination. These findings play an important role in selecting the best feedback method for a given situation or constructing multiple feedback methods that achieve high discrimination performance.
C1 [Takahashi, Minami; Nagano, Hikaru; Tazaki, Yuichi; Yokokohji, Yasuyoshi] Kobe Univ, Grad Sch Engn, Dept Mech Engn, Kobe, Japan.
C3 Kobe University
RP Nagano, H (corresponding author), Kobe Univ, Grad Sch Engn, Dept Mech Engn, Kobe, Japan.
EM nagano@mech.kobe-u.ac.jp
RI Tazaki, Yuichi/P-1605-2016; Yokokohji, Yasuyoshi/Q-9134-2016
OI Yokokohji, Yasuyoshi/0000-0001-8869-7102; Nagano,
   Hikaru/0000-0001-5230-6288
FU JSPS KAKENHI [JP20K04398]
FX Funding This work was supported by JSPS KAKENHI Grant Number JP20K04398.
CR Ambrosi G, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P305, DOI 10.1109/ROBOT.1999.769996
   Bicchi A, 2000, IEEE T ROBOTIC AUTOM, V16, P496, DOI 10.1109/70.880800
   Bodner J, 2004, EUR J CARDIO-THORAC, V25, P844, DOI 10.1016/j.ejcts.2004.02.001
   Bolopion A, 2013, IEEE T AUTOM SCI ENG, V10, P496, DOI 10.1109/TASE.2013.2245122
   Cavdan M, 2021, IEEE T HAPTICS, V14, P603, DOI 10.1109/TOH.2021.3069626
   Chang CM, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00091
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Crundall DE, 1998, ERGONOMICS, V41, P448, DOI 10.1080/001401398186937
   Culbertson H, 2017, IEEE T HAPTICS, V10, P63, DOI 10.1109/TOH.2016.2598751
   D'Antonio E, 2021, IEEE ASME INT C ADV, P1237, DOI 10.1109/AIM46487.2021.9517707
   El Radaf IM, 2020, J MATER SCI-MATER EL, V31, P18151, DOI 10.1007/s10854-020-04364-w
   Elobaid M, 2020, ADV INTELL SYST COMP, V1038, P1106, DOI 10.1007/978-3-030-29513-4_80
   Fernando CL, 2012, IEEE INT C INT ROBOT, P5112, DOI 10.1109/IROS.2012.6385814
   Hannaford B, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1063
   Higashi K, 2018, IEEE T HAPTICS, V11, P646, DOI 10.1109/TOH.2018.2841820
   Higashi K, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P37, DOI 10.1109/WHC.2017.7989853
   Hughes JAE, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aau3098
   Iizuka S., 2016, INT ASIAHAPTICS C, P157
   Jansen SEM, 2013, IEEE T HAPTICS, V6, P464, DOI [10.1109/TOH.2013.22, 10.1109/ToH.2013.22]
   Kappassov Z, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1697, DOI 10.1109/ICMA.2013.6618171
   Khurshid RP, 2017, IEEE T HAPTICS, V10, P40, DOI 10.1109/TOH.2016.2573301
   KIM WS, 1987, IEEE T ROBOTIC AUTOM, V3, P426, DOI 10.1109/JRA.1987.1087117
   Klamt T, 2020, J FIELD ROBOT, V37, P889, DOI 10.1002/rob.21895
   Klatzky RL, 2013, P IEEE, V101, P2081, DOI 10.1109/JPROC.2013.2248691
   Kristoffersson A, 2013, ADV HUM-COMPUT INTER, V2013, DOI 10.1155/2013/902316
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   LAWRENCE DA, 1993, IEEE T ROBOTIC AUTOM, V9, P624, DOI 10.1109/70.258054
   Lin PH, 2018, LECT NOTES COMPUT SC, V10894, P169, DOI 10.1007/978-3-319-93399-3_16
   McMahan W, 2011, IEEE T HAPTICS, V4, P210, DOI [10.1109/ToH.2011.31, 10.1109/TOH.2011.31]
   Michaud F, 2007, AAAI SPRING S MULT C, P50
   Morosi F, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102848
   Nagano H, 2020, ADV ROBOTICS, V34, P730, DOI 10.1080/01691864.2020.1769725
   Nagano H, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P389, DOI [10.1109/whc.2019.8816156, 10.1109/WHC.2019.8816156]
   Nagano H, 2014, IEEE T HAPTICS, V7, P345, DOI 10.1109/TOH.2014.2321575
   Okamoto S, 2013, IEEE T HAPTICS, V6, P81, DOI [10.1109/ToH.2012.32, 10.1109/TOH.2012.32]
   Okamura AM, 2001, IEEE-ASME T MECH, V6, P245, DOI 10.1109/3516.951362
   Onishi Yuya, 2016, P 4 INT C HUM AG INT, P171
   Pacchierotti C, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00053
   Park CH, 2015, IEEE T HAPTICS, V8, P327, DOI 10.1109/TOH.2015.2460253
   Seungmoon Choi, 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3577
   Stuart Meg, 2003, BMC Geriatr, V3, P1, DOI 10.1186/1471-2318-3-1
   Stückler J, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00058
   Tiest WMB, 2010, VISION RES, V50, P2775, DOI 10.1016/j.visres.2010.10.005
   Trahanias P, 2005, IEEE ROBOT AUTOM MAG, V12, P77, DOI 10.1109/MRA.2005.1458329
   VERRILLO RT, 1980, J GERONTOL, V35, P185, DOI 10.1093/geronj/35.2.185
   Wang LH, 2014, CIRP ANN-MANUF TECHN, V63, P1, DOI 10.1016/j.cirp.2014.03.013
   WEINSTEIN SIDNEY, 1968, P195
   Yamauchi Takahiro, 2010, 2010 IEEE International Conference on Robotics and Automation (ICRA 2010), P1753, DOI 10.1109/ROBOT.2010.5509926
   YOKOKOHJI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P605, DOI 10.1109/70.326566
   Yokosaka T, 2017, IEEE T HAPTICS, V10, P217, DOI 10.1109/TOH.2016.2613055
   Yoshinada H., 2019, DISASTER ROBOTICS, P195
NR 51
TC 2
Z9 2
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 3
PY 2023
VL 4
AR 1070739
DI 10.3389/frvir.2023.1070739
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0IA8
UT WOS:001020164800001
OA gold
DA 2024-07-18
ER

PT J
AU van der Waal, NE
   van Bokhorst, JAW
   van der Laan, LN
AF van der Waal, Nadine Elisa
   van Bokhorst, Julie A. W.
   van der Laan, Laura Nynke
TI Identifying emotions toward an overweight avatar in Virtual Reality: The
   moderating effects of visuotactile stimulation and drive for thinness
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE negative affect; body-size perception; visuotactile stimulation; drive
   for thinness; virtual body ownership
ID BODY-IMAGE; EXPOSURE; MIRROR; WOMEN; DISCREPANCIES; OWNERSHIP; BULIMIA;
   FAT
AB Virtual reality technologies can be used to alter one's body image by inducing ownership of an overweight virtual body. This illusion can possibly lead to both negative affective responses toward the virtual body as well as perceptual changes of one's own body size, which are both scarcely examined with regard to the embodiment of an overweight avatar. This study's fundamental aim is to investigate, among healthy weight participants, whether negative affect toward a virtual body and changes in body-size perception can be evoked when embodying an overweight virtual avatar. Additionally, the study investigates whether applying visuotactile stimulation (which has been identified as a proxy for virtual body ownership by previous studies) and drive for thinness influence the strength of these effects. A 2 (healthy weight vs. overweight virtual body) x 2 (congruent vs. incongruent visuotactile stimulation) between-subjects design was employed, with participants' drive for thinness measured to test its potential moderating effect. ANOVAs revealed that participants (N = 114) experienced significantly more negative affect toward the virtual body when embodying one that was overweight compared to a healthy weight virtual body. Visuotactile stimulation did not moderate this effect, even though the manipulation of visuotactile stimulation worked as intended (i.e., the experience of ownership over the virtual body was significantly higher in the congruent compared to incongruent visuotactile stimulation condition). Additionally, participants with a high drive for thinness did not experience significantly more negative affect than participants with a low drive for thinness. Embodiment of an overweight avatar did not affect body-size perceptions, nor did visuotactile stimulation or the drive for thinness moderate this effect. Knowing that embodiment of an overweight avatar results in negative affective responses toward it, future studies could deepen our understanding of the role of negative affect in the transfer of emotions to one's own body, and the interplay between negative affect toward a virtual body and body-size perceptions.
C1 [van der Waal, Nadine Elisa; van Bokhorst, Julie A. W.; van der Laan, Laura Nynke] Tilburg Univ, Tilburg Sch Humanities & Digital Sci, Dept Commun & Cognit, Tilburg, Netherlands.
C3 Tilburg University
RP van der Waal, NE (corresponding author), Tilburg Univ, Tilburg Sch Humanities & Digital Sci, Dept Commun & Cognit, Tilburg, Netherlands.
EM n.e.vdwaal@tilburguniversity.edu
OI van der Laan, Laura Nynke/0000-0003-4307-0888
CR Battan JF, 1998, J AM HIST, V85, P194, DOI 10.2307/2568446
   Biefeld SD, 2022, BODY IMAGE, V42, P84, DOI 10.1016/j.bodyim.2022.05.002
   Boldero JM, 2005, AUST J PSYCHOL, V57, P139, DOI 10.1080/00049530500048730
   Cardoso A, 2020, CLIN PSYCHOL-UK, V24, P176, DOI 10.1111/cp.12224
   Cash T.F., 2004, Body Image, V1, P363, DOI DOI 10.1016/J.BODYIM.2004.10.001
   Castonguay AL, 2012, BODY IMAGE, V9, P488, DOI 10.1016/j.bodyim.2012.07.003
   Cuesta-Zamora C, 2018, PERS INDIV DIFFER, V126, P1, DOI 10.1016/j.paid.2017.12.021
   DELROSARIO MW, 1984, PERS SOC PSYCHOL B, V10, P369, DOI 10.1177/0146167284103004
   Ferrer-Garcia M, 2017, ANN REV CYBERTHERAPY, V15, P147
   Ferrer-García M, 2012, BODY IMAGE, V9, P1, DOI 10.1016/j.bodyim.2011.10.001
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gardner RM, 2010, PERS INDIV DIFFER, V48, P107, DOI 10.1016/j.paid.2009.08.017
   Gleeson K, 2006, J HEALTH PSYCHOL, V11, P79, DOI 10.1177/1359105306058851
   Guterstam A, 2015, SCI REP-UK, V5, DOI 10.1038/srep09831
   Hewig J, 2008, PSYCHOSOM MED, V70, P729, DOI 10.1097/PSY.0b013e31817e41d3
   Higgins E.T., 1989, Advances in experimental social psychology, V22, P93, DOI [DOI 10.1016/S0065-2601(08)60306-8, 10.1016/S0065-2601(08)60306-8]
   Jun J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174175
   Keizer A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163921
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Levinson CA, 2020, J AFFECT DISORDERS, V277, P146, DOI 10.1016/j.jad.2020.08.012
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Perez-Marcos D, 2018, BODY IMAGE, V24, P55, DOI 10.1016/j.bodyim.2017.11.002
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Garcia BP, 2019, J CLIN MED, V8, DOI 10.3390/jcm8070925
   Preston C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199426
   Preston C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085773
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Scarpina F, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091330
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Serino S, 2016, CYBERPSYCH BEH SOC N, V19, P127, DOI 10.1089/cyber.2015.0229
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Smith KE, 2017, INT J EAT DISORDER, V50, P769, DOI 10.1002/eat.22716
   Trentowska M, 2013, BEHAV RES THER, V51, P1, DOI 10.1016/j.brat.2012.03.012
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Tuschen-Caffier B, 2003, BEHAV RES THER, V41, P573, DOI 10.1016/S0005-7967(02)00030-X
   van Berlo ZMC, 2021, J BUS RES, V122, P458, DOI 10.1016/j.jbusres.2020.09.006
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   van der Waal N. E., EFFECTS EMBODYING OV
   van Strien T, 2003, EUR J PSYCHOL ASSESS, V19, P66, DOI 10.1027//1015-5759.19.1.66
   van Strien T., 2002, EATING DISORDER INVE
   Vartanian LR, 2010, INT J OBESITY, V34, P1302, DOI 10.1038/ijo.2010.45
   Vocks S, 2008, EUR EAT DISORD REV, V16, P147, DOI 10.1002/erv.825
   Vocks S, 2007, J PSYCHOSOM RES, V62, P231, DOI 10.1016/j.jpsychores.2006.08.007
   Voedingscentrum, 2022, OV VOED
   Waal NEV, 2021, FOOD QUAL PREFER, V90, DOI 10.1016/j.foodqual.2020.104167
   Wiederman MW, 2000, INT J EAT DISORDER, V27, P90, DOI 10.1002/(SICI)1098-108X(200001)27:1<90::AID-EAT10>3.0.CO;2-0
   ZILLMANN D, 1971, J EXP SOC PSYCHOL, V7, P419, DOI 10.1016/0022-1031(71)90075-8
NR 50
TC 2
Z9 2
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 13
PY 2022
VL 3
AR 989676
DI 10.3389/frvir.2022.989676
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VP5
UT WOS:001023261800001
OA gold
DA 2024-07-18
ER

PT J
AU Eckhoff, D
   Sandor, C
   Cheing, GLY
   Schnupp, J
   Cassinelli, A
AF Eckhoff, Daniel
   Sandor, Christian
   Cheing, Gladys L. Y.
   Schnupp, Jan
   Cassinelli, Alvaro
TI Thermal pain and detection threshold modulation in augmented reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; thermoception; nociception; pain; embodiment;
   presence
ID PHANTOM LIMB PAIN; VIRTUAL-REALITY; HEAT; PERCEPTION; TEMPERATURE;
   RUBBER; BODY; MECHANISMS; EMPATHY; ILLUSION
AB Augmented Reality (AR) overlays computer-generated visual, auditory or other sensory information onto the real world. Due to recent technological advancement in the field, it can become increasingly difficult for the user to differentiate between sensory information coming from real and virtual objects, leading to interesting perceptual phenomena. For example, an AR experience in which users can experience their own hands in flames has been shown to elicit heat illusions on the affected hands. In this study, we investigate the potential that AR has for top-down modulation of pain and thermal perception. We assessed thermal pain and detection thresholds on the participant's right hand while covering it with realistic virtual flames. We compared this experience to a baseline condition with no additional stimuli. We also report on a condition in which the hand is covered by a blue fluid not instantly associated with fire. We found that experiencing a virtual burning hand induces analgesic as well hyperalgesic effects as participants begin to feel heat related pain at lower temperatures and cold related pain at higher temperatures. The experience also impacts significantly on the lowest temperature at which participants starts perceiving warmth. The blue fluid do not affect the thresholds corresponding to the baseline condition. Our research thus confirms previous experiments showing that pain and thermal perception can be manipulated by by AR, while providing quantitative results on the magnitude of this effect.
C1 [Eckhoff, Daniel; Cassinelli, Alvaro] City Univ Hong Kong, Sch Creat Media, Kowloon, Hong Kong, Peoples R China.
   [Sandor, Christian] Univ Paris Saclay, Gif Sur Yvette, France.
   [Cheing, Gladys L. Y.] Hong Kong Polytech Univ, Dept Rehabil Sci, Kowloon, Hong Kong, Peoples R China.
   [Schnupp, Jan] City Univ Hong Kong, Dept Neurosci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong; Universite Paris Cite; Universite Paris
   Saclay; Hong Kong Polytechnic University; City University of Hong Kong
RP Eckhoff, D (corresponding author), City Univ Hong Kong, Sch Creat Media, Kowloon, Hong Kong, Peoples R China.
EM daniel.eckhoff@gmail.com
OI CASSINELLI, ALVARO/0000-0002-1671-1777; SANDOR,
   Christian/0000-0002-3990-2728; schnupp, jan w h/0000-0002-2604-0057
CR Agostinho CMS, 2009, EUR J PAIN, V13, P779, DOI 10.1016/j.ejpain.2008.10.002
   Averbeck B, 2017, BIOL SEX DIFFER, V8, DOI 10.1186/s13293-017-0147-5
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Barcatta K, 2022, FRONT PAIN RES, V2, DOI 10.3389/fpain.2021.800258
   Bauer A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00712
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Botella C, 2010, BEHAV THER, V41, P401, DOI 10.1016/j.beth.2009.07.002
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Carrino Francesco, 2014, Virtual, Augmented and Mixed Reality. Applications of Virtual and Augmented Reality. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8526, P248, DOI 10.1007/978-3-319-07464-1_23
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Collins J, 2017, PRESENCE-TELEOP VIRT, V26, P16, DOI 10.1162/PRES_a_00284
   CURKOVIC B, 1993, Z RHEUMATOL, V52, P289
   Davis ET, 1999, HUM FAC ERG SOC P, P1197
   Defrin R, 2006, CLIN J PAIN, V22, P130, DOI 10.1097/01.ajp.0000154048.68273.d8
   Demeter N, 2018, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00070
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Dunn J, 2017, NEUROREHABILITATION, V40, P595, DOI 10.3233/NRE-171447
   Eckhoff Daniel, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P83, DOI 10.1007/978-3-030-62655-6_5
   Erlich N, 2013, DEVELOPMENTAL SCI, V16, P894, DOI 10.1111/desc.12091
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Fan Y, 2008, NEUROPSYCHOLOGIA, V46, P160, DOI 10.1016/j.neuropsychologia.2007.07.023
   Gandy M., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P127, DOI 10.1109/ISMAR.2010.5643560
   Giummarra MJ, 2015, EUR J PAIN, V19, P807, DOI 10.1002/ejp.607
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   González-Franco M, 2014, EXP BRAIN RES, V232, P875, DOI 10.1007/s00221-013-3800-1
   Green BG, 2004, J NEUROBIOL, V61, P13, DOI 10.1002/neu.20081
   Greffrath W, 2007, PAIN, V132, P301, DOI 10.1016/j.pain.2007.04.026
   HAMALAINEN H, 1982, BRAIN RES, V251, P77, DOI 10.1016/0006-8993(82)91275-6
   Hegedüs G, 2014, EUR J PAIN, V18, P1173, DOI 10.1002/j.1532-2149.2014.00466.x
   Heldestad V, 2010, CLIN NEUROPHYSIOL, V121, P1878, DOI 10.1016/j.clinph.2010.03.055
   Ho HN, 2014, SCI REP-UK, V4, DOI 10.1038/srep05527
   Hoffman HG, 2004, NEUROREPORT, V15, P1245, DOI 10.1097/01.wnr.0000127826.73576.91
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89526-4
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Juan MC, 2005, IEEE COMPUT GRAPH, V25, P31, DOI 10.1109/MCG.2005.143
   Käthner I, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55407-0
   Kanayama N, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80807-y
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Lamm C, 2011, NEUROIMAGE, V54, P2492, DOI 10.1016/j.neuroimage.2010.10.014
   Longo MR, 2009, J NEUROSCI, V29, P12125, DOI 10.1523/JNEUROSCI.3072-09.2009
   Martini M, 2016, CONSCIOUS COGN, V43, P143, DOI 10.1016/j.concog.2016.06.005
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Martini M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00438
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   MORGAN GA, 1975, AM J PSYCHOL, V88, P125, DOI 10.2307/1421671
   Moseley GL, 2007, PAIN, V133, P64, DOI 10.1016/j.pain.2007.03.002
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Mühlberger A, 2007, CYBERPSYCHOL BEHAV, V10, P516, DOI 10.1089/cpb.2007.9996
   Ortiz-Catalan M, 2016, LANCET, V388, P2885, DOI 10.1016/S0140-6736(16)31598-7
   Patapoutian A, 2003, NAT REV NEUROSCI, V4, P529, DOI 10.1038/nrn1141
   Perani D, 2001, NEUROIMAGE, V14, P749, DOI 10.1006/nimg.2001.0872
   Pertovaara A, 1996, EXP BRAIN RES, V107, P497
   Pimentel D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.643938
   Regenbrecht H., 2021, ARXIV, P1, DOI [10.48550/ARXIV.2103.02831, DOI 10.48550/ARXIV.2103.02831]
   Rhudy JL, 2001, J PAIN, V2, P57, DOI 10.1054/jpai.2000.19947
   Rolke R, 2006, PAIN, V123, P231, DOI 10.1016/j.pain.2006.01.041
   ROLLAND JP, 1994, P SOC PHOTO-OPT INS, V2351, P293
   RUGGIERI V, 1988, PERCEPT MOTOR SKILL, V66, P435, DOI 10.2466/pms.1988.66.2.435
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Shams L, 2010, TRENDS COGN SCI, V14, P425, DOI 10.1016/j.tics.2010.07.001
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Strigo IA, 2000, ANESTHESIOLOGY, V92, P699, DOI 10.1097/00000542-200003000-00014
   Vachon-Presseau E, 2011, PAIN, V152, P1525, DOI 10.1016/j.pain.2011.02.039
   Valenzuela-Moguillansky C, 2011, J CONSCIOUSNESS STUD, V18, P110
   Weir P, 2013, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2013.6549357
   Weiss S, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489885
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Wilson K, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.695449
   YARNITSKY D, 1990, PAIN, V40, P85, DOI 10.1016/0304-3959(90)91055-N
NR 71
TC 1
Z9 1
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 14
PY 2022
VL 3
AR 952637
DI 10.3389/frvir.2022.952637
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YJ8
UT WOS:001023334600001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Buche, H
   Michel, A
   Blanc, N
AF Buche, Helene
   Michel, Aude
   Blanc, Nathalie
TI Use of virtual reality in oncology: From the state of the art to an
   integrative model
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cancer; anxiety; pain; immersion; presence; interaction; equipment
ID DISTRACTION INTERVENTION; CANCER; PAIN; DEPRESSION; ANXIETY;
   METAANALYSIS; PREVALENCE; MANAGEMENT; ATTENTION; CHILDREN
AB Over the past 20 years, virtual reality (VR) has been the subject of growing interest in oncology. More and more researchers are studying the effects of virtual environments to contribute to current thinking on technologies likely to support patients undergoing oncological treatment. Recent research highlights how VR can divert attention while reducing anxiety in stressful healthcare situations through its multisensory and participative nature. VR appears to be a promising tool capable of reducing cancer-related anxiety symptoms, improving treatment adherence, and increasing satisfaction with oncology care. While the literature reports these positive effects in the therapeutic management of cancer, few studies have focused on theoretical models capable of explaining the psychological benefits of virtual immersion. This literature review provides a theoretical framework combining results from all relevant empirical work in oncology. The review can help researchers identify the optimal conditions for using VR in oncology and bridge the gap between divergent devices, modalities, and practices (e.g., headmounted displays, environments, interactivity, immersion time).
C1 [Buche, Helene; Michel, Aude; Blanc, Nathalie] Univ Paul Valery Montpellier 3, Epsylon Ea 4556, Montpellier, France.
   [Michel, Aude] Montpellier Inst Sein Clin Clementville, Montpellier, France.
C3 Universite de Montpellier; Universite Paul-Valery
RP Buche, H; Michel, A (corresponding author), Univ Paul Valery Montpellier 3, Epsylon Ea 4556, Montpellier, France.; Michel, A (corresponding author), Montpellier Inst Sein Clin Clementville, Montpellier, France.
EM buchehelene@gmail.com; aude.michel@univ-montp3.fr
RI Blanc, Nathalie/H-3912-2012
OI Buche, Helene/0009-0005-2176-4418; Blanc, Nathalie/0000-0003-1327-0280
CR Ahmad M, 2020, PAIN MANAG NURS, V21, P601, DOI 10.1016/j.pmn.2020.04.002
   Ahmadpour N, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/14565
   Alawneh Alia, 2017, Gulf J Oncolog, V1, P37
   Arane K, 2017, CAN FAM PHYSICIAN, V63, P932
   Arrieta O, 2013, ANN SURG ONCOL, V20, P1941, DOI 10.1245/s10434-012-2793-5
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02508
   Baños RM, 2013, SUPPORT CARE CANCER, V21, P263, DOI 10.1007/s00520-012-1520-x
   Birnie KA, 2018, J PEDIATR ONCOL NURS, V35, P406, DOI 10.1177/1043454218782138
   Bouvier P., 2009, Ph.D. Thesis
   Buche H, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.631186
   Burle B, 2001, J EXP PSYCHOL HUMAN, V27, P195, DOI 10.1037/0096-1523.27.1.195
   Chirico A, 2020, J CELL PHYSIOL, V235, P5353, DOI 10.1002/jcp.29422
   Chirico A, 2016, J CELL PHYSIOL, V231, P275, DOI 10.1002/jcp.25117
   Chirico A, 2015, PEERJ, V3, DOI 10.7717/peerj.1107
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Czech O, 2022, COMPLEMENT THER MED, V68, DOI 10.1016/j.ctim.2022.102837
   de Loor P., 2011, J ASS FRANCAISE REAL, V3
   Defossez G., 2019, Report No.: Volume 1 Tumeurs solides, V1, P372
   Droit-Volet S, 2009, PHILOS T R SOC B, V364, P1943, DOI 10.1098/rstb.2009.0013
   Du Q, 2022, BRAIN BEHAV, V12, DOI 10.1002/brb3.2600
   Eccleston C, 1999, PSYCHOL BULL, V125, P356, DOI 10.1037/0033-2909.125.3.356
   Espinoza M, 2012, STUD HEALTH TECHNOL, V181, P53, DOI 10.3233/978-1-61499-121-2-53
   Fredrickson BL, 2001, AM PSYCHOL, V56, P218, DOI 10.1037/0003-066X.56.3.218
   Garrett BM, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03916
   Gerçeker GÖ, 2021, EUR J ONCOL NURS, V50, DOI 10.1016/j.ejon.2020.101886
   Glennon C, 2018, ONCOL NURS FORUM, V45, P545, DOI 10.1188/18.ONF.545-552
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gupta N., 2019, INT J MULTIDISCIP RE, V6, P32
   Higgins S, 2019, DERMATOL SURG, V45, P1009, DOI 10.1097/DSS.0000000000001854
   Indovina P, 2018, CLIN J PAIN, V34, P858, DOI 10.1097/AJP.0000000000000599
   Institut National du Cancer, 2019, CANC FRANC ESS FAITS
   Johnson T, 2020, J PALLIAT MED, V23, P1233, DOI 10.1089/jpm.2019.0411
   Kaplan R., 1989, EXPERIENCE NATURE PS
   Kleiber C, 1999, NURS RES, V48, P44, DOI 10.1097/00006199-199901000-00007
   Kleiber Charmaine, 2006, J Pediatr Nurs, V21, P99, DOI 10.1016/j.pedn.2005.06.008
   Koller D, 2012, J PEDIATR NURS, V27, P652, DOI 10.1016/j.pedn.2011.08.001
   Lazarus R. S., 1984, BEHAV RES THER, DOI [10.1016/0005.7967(85)90087.7, DOI 10.1016/0005.7967(85)90087.7]
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Li WHC, 2011, J CLIN NURS, V20, P2135, DOI 10.1111/j.1365-2702.2011.03733.x
   Li Z, 2016, CLIN REHABIL, V30, P432, DOI 10.1177/0269215515593611
   Melzack R, 1996, PAIN FORUM, V5, P3
   Michel A, 2019, PSYCHO-ONCOLOGIE, V13, P69, DOI 10.3166/pson-2019-0087
   Michel A, 2019, GERIATR PSYCHOL NEUR, V17, P415, DOI 10.1684/pnv.2019.0832
   Mohammad EB, 2019, PALLIAT SUPPORT CARE, V17, P29, DOI 10.1017/S1478951518000639
   Nikbakhsh N, 2014, CASP J INTERN MED, V5, P167
   Niki K, 2019, J PALLIAT MED, V22, P702, DOI 10.1089/jpm.2018.0527
   O'Connor M, 2010, MED J AUSTRALIA, V193, pS44
   Oyama H, 1999, Cyberpsychol Behav, V2, P81, DOI 10.1089/cpb.1999.2.81
   Pittara M, 2020, IEEE ACCESS, V8, P225475, DOI 10.1109/ACCESS.2020.3044233
   Pizzoli SFM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00479
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   PRATT DR, 1995, COMPUTER, V28, P17
   Ramirez S, 2015, NATURE, V522, P335, DOI 10.1038/nature14514
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Scates D, 2020, ENVIRON BEHAV, V52, P895, DOI 10.1177/0013916520916259
   Schneider S M, 1999, Cyberpsychol Behav, V2, P125, DOI 10.1089/cpb.1999.2.125
   Schneider SM, 2004, ONCOL NURS FORUM, V31, P81, DOI 10.1188/04.ONF.81-88
   Schneider SM, 2003, CYBERPSYCHOL BEHAV, V6, P301, DOI 10.1089/109493103322011605
   Schneider SM, 2007, ONCOL NURS FORUM, V34, P39, DOI 10.1188/07.ONF.39-46
   Schneider SM, 2011, SUPPORT CARE CANCER, V19, P555, DOI 10.1007/s00520-010-0852-7
   Semerci R, 2021, J PEDIATR ONCOL NURS, V38, P142, DOI 10.1177/1043454220975702
   Sharifpour S, 2021, COUNS PSYCHOTHER RES, V21, P218, DOI 10.1002/capr.12311
   Stassart C., 2022, OPEN J MED PSYCHOL, V11, P89, DOI [10.4236/ojmp.2022.113007, DOI 10.4236/OJMP.2022.113007]
   Tennant M, 2020, EUR J ONCOL NURS, V48, DOI 10.1016/j.ejon.2020.101804
   Tsai F., 2016, HERMES WIESB, V74, P188, DOI [10.3917/herm.074.0188, DOI 10.3917/HERM.074.0188]
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   van den Beuken-van Everdingen MHJ, 2016, J PAIN SYMPTOM MANAG, V51, P1070, DOI 10.1016/j.jpainsymman.2015.12.340
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wittmann M, 2008, TRENDS COGN SCI, V12, P7, DOI 10.1016/j.tics.2007.10.004
   Zeng YC, 2019, INTEGR CANCER THER, V18, DOI 10.1177/1534735419871108
NR 70
TC 8
Z9 8
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 4
PY 2022
VL 3
AR 894162
DI 10.3389/frvir.2022.894162
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XI6
UT WOS:001023307200001
OA gold
DA 2024-07-18
ER

PT J
AU Slater, M
   Banakou, D
   Beacco, A
   Gallego, J
   Macia-Varela, F
   Oliva, R
AF Slater, Mel
   Banakou, Domna
   Beacco, Alejandro
   Gallego, Jaime
   Macia-Varela, Francisco
   Oliva, Ramon
TI A Separate Reality: An Update on Place Illusion and Plausibility in
   Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; presence; place illusion; plausibility; body ownership;
   questionnaires; measurement
ID SMALL-GROUP BEHAVIOR; SPATIAL PRESENCE; SOCIAL PRESENCE; SENSE;
   ENVIRONMENTS; COPRESENCE; EEG; APPEARANCE; RESPONSES; CORRELATE
AB We review the concept of presence in virtual reality, normally thought of as the sense of "being there" in the virtual world. We argued in a 2009 paper that presence consists of two orthogonal illusions that we refer to as Place Illusion (PI, the illusion of being in the place depicted by the VR) and Plausibility (Psi, the illusion that the virtual situations and events are really happening). Both are with the proviso that the participant in the virtual reality knows for sure that these are illusions. Presence (PI and Psi) together with the illusion of ownership over the virtual body that self-represents the participant, are the three key illusions of virtual reality. Copresence, togetherness with others in the virtual world, can be a consequence in the context of interaction between remotely located participants in the same shared virtual environments, or between participants and virtual humans. We then review several different methods of measuring presence: questionnaires, physiological and behavioural measures, breaks in presence, and a psychophysics method based on transitions between different system configurations. Presence is not the only way to assess the responses of people to virtual reality experiences, and we present methods that rely solely on participant preferences, including the use of sentiment analysis that allows participants to express their experience in their own words rather than be required to adopt the terminology and concepts of researchers. We discuss several open questions and controversies that exist in this field, providing an update to the 2009 paper, in particular with respect to models of Plausibility. We argue that Plausibility is the most interesting and complex illusion to understand and is worthy of significant more research. Regarding measurement we conclude that the ideal method would be a combination of a psychophysical method and qualitative methods including sentiment analysis.
C1 [Slater, Mel; Banakou, Domna; Beacco, Alejandro; Gallego, Jaime; Macia-Varela, Francisco; Oliva, Ramon] Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.
   [Slater, Mel; Banakou, Domna] Univ Barcelona, Inst Neurosci, Barcelona, Spain.
C3 University of Barcelona; University of Barcelona
RP Slater, M (corresponding author), Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.; Slater, M (corresponding author), Univ Barcelona, Inst Neurosci, Barcelona, Spain.
EM melslater@ub.edu
OI Banakou, Domna/0000-0002-0974-6971; Gallego Vila,
   Jaime/0000-0003-3332-619X
FU Horizon 2020 European Research Council (ERC) Advanced Grant (MoTIVE)
   [742989]; Ministerio de Ciencia e Innovacin, Spain
   [PDI2020-117108RB-100-TEDIX, AEI/10.13039/501100011033]; European
   Research Council (ERC) [742989] Funding Source: European Research
   Council (ERC)
FX Funding This research is supported by the Horizon 2020 European Research
   Council (ERC) Advanced Grant (MoTIVE) (#742989) and Ministerio de
   Ciencia e Innovacion, Spain, PDI2020-117108RB-100-TEDIX (financed by
   AEI/10.13039/501100011033).
CR Archer NS, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0265039
   Azevedo AS, 2015, PRESENCE-TELEOP VIRT, V23, P354, DOI 10.1162/PRES_a_00205
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P452
   Banakou D, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201848
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Barberia I, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203358
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Beacco A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/VR50410.2021.00078
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Biocca F, 2002, NARRATIVE IMPACT: SOCIAL AND COGNITIVE FOUNDATIONS, P97
   Biocca F., 2003, EU FUTURE EMERGING T, P13
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169343
   Brubach L, 2022, IEEE T VIS COMPUT GR, V28, P2267, DOI 10.1109/TVCG.2022.3150496
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Chalmers DJ, 2017, DISPUTATIO, V9, P309, DOI 10.1515/disp-2017-0009
   Chalmers David J., 2022, Reality +: Virtual Worlds and the Problems of Philosophy
   Clemente M, 2014, EXPERT SYST APPL, V41, P1584, DOI 10.1016/j.eswa.2013.08.055
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Deutsch D., 2011, The Fabric of Reality
   Durlach N, 2000, PRESENCE-TELEOP VIRT, V9, P214, DOI 10.1162/105474600566736
   Ellis S. R., 1991, Computing Systems in Engineering, V2, P321, DOI 10.1016/0956-0521(91)90001-L
   Fadeev KA, 2020, BEHAV NEUROL, V2020, DOI 10.1155/2020/5758038
   Felton WM, 2022, INT J HUM-COMPUT INT, V38, P1, DOI 10.1080/10447318.2021.1921368
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Freeman D, 2019, TRIALS, V20, DOI 10.1186/s13063-019-3198-6
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Galvandebarba H., 2020, IEEE T VIS COMPUT GR
   Gao B., 2018, P COMP GRAPH INT, V2018, P201, DOI [DOI 10.1145/3208159.3208171, https://doi.org/10.1145/3208159.3208171]
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   Garau M., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P309, DOI 10.1145/365024.365121
   Garau M., 2004, TEMP SPAT VAR PRES Q
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Gorisse G, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03373-x
   Graf S., 2020, 26th ACM Symposium on Virtual Reality Software and Technology, P1, DOI DOI 10.1145/3385956.3422105
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Hall E., 1973, LEONARDO, V6, P94, DOI [DOI 10.2307/1572461, 10.2307/1572461]
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Held R. M., 1992, Presence: Teleoperators and Virtual Environments, V1, P109, DOI [https://doi.org/10.1162/pres.1992.1.1.109, 10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI [10.3389/frvir.2020.00002, DOI 10.3389/FRVIR.2020.00002]
   Kastanis I, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2134203.2134206
   Kober SE, 2012, INT J HUM-COMPUT ST, V70, P577, DOI 10.1016/j.ijhcs.2012.03.004
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Latoschik ME, 2022, Arxiv, DOI arXiv:2104.04846
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Liebold B, 2017, MEDIA PSYCHOL, V20, P477, DOI 10.1080/15213269.2016.1206829
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Llobera J, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210537
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Martens MAG, 2019, J PSYCHOPHARMACOL, V33, P1264, DOI 10.1177/0269881119860156
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mottelson A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.681482
   Murcia-López M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P747, DOI [10.1109/VR46266.2020.000-6, 10.1109/VR46266.2020.1581156939194]
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Ochs M, 2022, FRONT COMP SCI-SWITZ, V4, DOI 10.3389/fcomp.2022.746804
   Pan X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146837
   Parola S., 2016, EI, V28, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.4.ERVR-418
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Petukhov IV, 2020, INT J MED INFORM, V136, DOI 10.1016/j.ijmedinf.2019.103977
   Poeschl S, 2015, STUD HEALTH TECHNOL, V219, P58, DOI 10.3233/978-1-61499-595-1-58
   Putze S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376144
   Regenbrecht H, 2021, Arxiv, DOI arXiv:2103.02831
   Rey B, 2011, PRESENCE-TELEOP VIRT, V20, P273, DOI 10.1162/PRES_a_00049
   Ríos A, 2020, VIRTUAL REAL-LONDON, V24, P683, DOI 10.1007/s10055-020-00428-8
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Rovira A, 2009, FRONT BEHAV NEUROSCI, V3, DOI 10.3389/neuro.08.059.2009
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Sheridan TB, 1996, PRESENCE-TELEOP VIRT, V5, P241, DOI 10.1162/pres.1996.5.2.241
   Skarbez R., 2018, P 24 ACM S VIRT REAL, P1
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M., 2003, 6 ANN INT WORKSH PRE
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2023, VIRTUAL REAL-LONDON, V27, P651, DOI 10.1007/s10055-022-00685-9
   Slater M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.787523
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052766
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Souza V, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3466817
   Spanlang B., 2007, PRESENCE 2007 10 ANN
   Steed A, 1999, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.1999.756941
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Tromp J, 1998, IEEE COMPUT GRAPH, V18, P53, DOI 10.1109/38.734980
   Welch RB, 1999, PRESENCE-TELEOP VIRT, V8, P574, DOI 10.1162/105474699566387
   Williamson J., 2021, C HUM FACT COMP SYST, P1, DOI DOI 10.1145/3411764.3445729
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 105
TC 46
Z9 47
U1 5
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 27
PY 2022
VL 3
AR 914392
DI 10.3389/frvir.2022.914392
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TM3
UT WOS:001021834600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Redweik, GAJ
   Millman, ST
   Parsons, RL
   Terminel, ANH
   Radkowski, R
   Daniels, K
   Lyte, M
   Oliver, J
   Mellata, M
AF Redweik, Graham A. J.
   Millman, Suzanne T. T.
   Parsons, Rebecca L. L.
   Terminel, Alejandro N. Hurtado N.
   Radkowski, Rafael
   Daniels, Karrie
   Lyte, Mark
   Oliver, James
   Mellata, Melha
TI Exposure to a Virtual Environment Induces Biological and Microbiota
   Changes in Onset-of-Lay Hens
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; chickens; corticosterone; neurochemicals; gut
   microbiota; APEC; salsolinol
ID STRESS-INDUCED IMMUNOSUPPRESSION; REALITY; ENDOCRINOLOGY; EXPLORATION;
   HETEROPHIL; RESISTANT; RESPONSES; BUTYRATE; BACTERIA; SEQUENCE
AB Increasing demand for cage-free eggs arises from goals to provide hens with better welfare, particularly in terms of natural behavior. However, most laying hens are kept in conventional cages, and cage-free systems can present challenges, such as injuries, floor eggs, and bacterial infections. We proposed using virtual reality (VR) as a feasible means for combining the positive attributes of natural environments while mitigating health risks. To our knowledge, no animal study has provided evidence that VR can trigger biological changes to improve animal health and well-being nor whether VR can affect the gut microbiota. In this study, we used VR technology to simulate a natural environment in laying hen housing. Early-lay White Leghorn hens were placed in pens with (VR) or without (CON) video projections displaying free-range chickens interacting with indoor and outdoor environmental features over 5 days. Using in vitro blood bactericidal assays, VR hens exhibited higher resistance against avian pathogenic Escherichia coli versus CON (p < 0.05), which was positively associated with corticosterone levels (p < 0.01). Analyzing intestinal neurochemicals via ultra-high pressure liquid chromatography, salsolinol was the only neurochemical metabolite affected by VR, being greater in CON ileal content (p < 0.0001), in VR ileal mucus (p < 0.01), and in VR ceca tissue (p < 0.05). Using 16S rRNA sequencing and QIIME2 analyses, no differences in alpha nor beta diversity were determined between groups. Although several genera (Megamonas, Ruminococcus, Slackia) were reduced in VR hens versus CON, Mucispirillum schaedleri (member of Deferribacteres Phylum) was the only taxon increased in VR hens, being elevated in ileal mucus (p < 0.05). Lastly, using the QIIME2 plugin mmvec to map microbe-metabolite co-occurrences, we identified several positive relationships between bacterial phyla and neurochemical metabolites, notably finding dopamine and salsolinol levels were related to Deferribacteres and Tenericutes levels. In conclusion, we found that several biological parameters were influenced by VR treatment in hens, suggesting that VR can be used to improve host resistance to pathogens and gut health in poultry.
C1 [Redweik, Graham A. J.; Mellata, Melha] Iowa State Univ, Dept Food Sci & Human Nutr, Ames, IA 50011 USA.
   [Redweik, Graham A. J.; Mellata, Melha] Iowa State Univ, Interdept Microbiol Grad Program, Ames, IA 50011 USA.
   [Millman, Suzanne T. T.; Parsons, Rebecca L. L.; Terminel, Alejandro N. Hurtado N.] Iowa State Univ, Dept Vet Diagnost & Prod Anim Med, Ames, IA USA.
   [Millman, Suzanne T. T.] Iowa State Univ, Dept Biomed Sci, Ames, IA USA.
   [Radkowski, Rafael; Oliver, James] Iowa State Univ, Virtual Real Applicat Ctr, Ames, IA USA.
   [Daniels, Karrie; Lyte, Mark] Iowa State Univ, Dept Vet Microbiol & Preventat Med, Ames, IA USA.
C3 Iowa State University; Iowa State University; Iowa State University;
   Iowa State University; Iowa State University; Iowa State University
RP Mellata, M (corresponding author), Iowa State Univ, Dept Food Sci & Human Nutr, Ames, IA 50011 USA.; Mellata, M (corresponding author), Iowa State Univ, Interdept Microbiol Grad Program, Ames, IA 50011 USA.
EM mmellata@iastate.edu
RI Lyte, Mark/AAI-7602-2020
OI Lyte, Mark/0000-0001-8512-2581
FU Iowa State University Presidential Interdisciplinary Research Seed
   Grant; United States Department of Agriculture (USDA) [IOW03902];
   USDA-National Institute of Food and Agriculture (NIFA) project
   [021069-00001]
FX This research was supported by Iowa State University Presidential
   Interdisciplinary Research Seed Grant (PIRS) to MM, ML, JO, and SM.
   Start-up funding and the United States Department of Agriculture (USDA)
   Hatch project IOW03902 to MM, USDA-National Institute of Food and
   Agriculture (NIFA) project #021069-00001 to GR.
CR Barbieri NL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072322
   Bestman M, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10020177
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   BROOM DM, 1969, ANIM BEHAV, V17, P307, DOI 10.1016/0003-3472(69)90015-3
   Clarke C. H., 1999, BRIT POULTRY SCI, V40, P8, DOI [10.1080/00071669986530, DOI 10.1080/00071669986530]
   Clarke CH, 2001, APPL ANIM BEHAV SCI, V70, P285, DOI 10.1016/S0168-1591(00)00161-1
   Clarke G, 2013, MOL PSYCHIATR, V18, P666, DOI 10.1038/mp.2012.77
   Coutinho AE, 2011, MOL CELL ENDOCRINOL, V335, P2, DOI 10.1016/j.mce.2010.04.005
   Cui LY, 2020, BMC VET RES, V16, DOI 10.1186/s12917-020-2231-z
   DAVISON TF, 1988, DEV COMP IMMUNOL, V12, P131, DOI 10.1016/0145-305X(88)90031-6
   Dawkins MS, 2000, NATURE, V403, P652, DOI 10.1038/35001064
   de Macchi BM, 2013, VET RES, V44, DOI 10.1186/1297-9716-44-8
   El-Lethey H, 2003, VET IMMUNOL IMMUNOP, V95, P91, DOI 10.1016/S0165-2427(02)00308-2
   Freestone PPE, 2008, TRENDS MICROBIOL, V16, P55, DOI 10.1016/j.tim.2007.11.005
   Galperin MY, 2013, MICROBIOL SPECTR, V1, DOI 10.1128/microbiolspectrum.TBS-0015-2012
   Gershon MD, 2007, GASTROENTEROLOGY, V132, P397, DOI 10.1053/j.gastro.2006.11.002
   GROSS WB, 1983, AVIAN DIS, V27, P972, DOI 10.2307/1590198
   Heerkens JLT, 2015, POULTRY SCI, V94, P2008, DOI 10.3382/ps/pev187
   Janczak AM, 2015, POULTRY SCI, V94, P1454, DOI 10.3382/ps/pev123
   Johnson TJ, 2007, J BACTERIOL, V189, P3228, DOI 10.1128/JB.01726-06
   Johnson TJ, 2006, J BACTERIOL, V188, P745, DOI 10.1128/JB.188.2.745-758.2006
   KEELING LJ, 1993, APPL ANIM BEHAV SCI, V36, P223, DOI 10.1016/0168-1591(93)90012-E
   Lien RJ, 2008, POULTRY SCI, V87, P853, DOI 10.3382/ps.2007-00277
   Louis P, 2017, ENVIRON MICROBIOL, V19, P29, DOI 10.1111/1462-2920.13589
   Loy A, 2017, MSYSTEMS, V2, DOI 10.1128/mSystems.00171-16
   Lyte M, 2014, ADV EXP MED BIOL, V817, P3, DOI 10.1007/978-1-4939-0897-4_1
   Maier M, 2019, NEUROREHAB NEURAL RE, V33, P112, DOI 10.1177/1545968318820169
   Maples-Keller JL, 2017, NEUROTHERAPEUTICS, V14, P554, DOI 10.1007/s13311-017-0534-y
   Mellata M, 2013, FOODBORNE PATHOG DIS, V10, P916, DOI 10.1089/fpd.2013.1533
   Morton JT, 2019, NAT METHODS, V16, P1306, DOI 10.1038/s41592-019-0616-3
   Naoi M, 2002, NEUROTOXICOL TERATOL, V24, P579, DOI 10.1016/S0892-0362(02)00211-8
   Oliveira JL, 2019, POULTRY SCI, V98, P1664, DOI 10.3382/ps/pey525
   Venegas DP, 2019, FRONT IMMUNOL, V10, DOI 10.3389/fimmu.2019.00277
   Scanes CG, 2016, POULTRY SCI, V95, P2208, DOI 10.3382/ps/pew137
   Shini S, 2010, POULTRY SCI, V89, P841, DOI 10.3382/ps.2009-00483
   Singh M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187057
   Stacy AK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086565
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Stowers JR, 2017, NAT METHODS, V14, P995, DOI [10.1038/NMETH.4399, 10.1038/nmeth.4399]
   Takahashi K, 2016, DIGESTION, V93, P59, DOI 10.1159/000441768
   Valles-Colomer M, 2019, NAT MICROBIOL, V4, P623, DOI 10.1038/s41564-018-0337-x
   Villageliú DN, 2018, FRONT MICROBIOL, V9, DOI 10.3389/fmicb.2018.03092
   Villageliú DN, 2018, FEMS MICROBIOL ECOL, V94, DOI 10.1093/femsec/fiy096
   Wen CL, 2019, ISME J, V13, P1422, DOI 10.1038/s41396-019-0367-2
   YAMANAKA Y, 1970, NATURE, V227, P1143, DOI 10.1038/2271143a0
   Yang YJD, 2018, AUTISM RES, V11, P713, DOI 10.1002/aur.1941
   Yano JM, 2015, CELL, V161, P264, DOI 10.1016/j.cell.2015.02.047
   Zhao J, 2017, EUR J CLIN MICROBIOL, V36, P1463, DOI 10.1007/s10096-017-2955-2
NR 48
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 2
PY 2022
VL 3
AR 891584
DI 10.3389/frvir.2022.891584
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2RY4
UT WOS:001021794500001
OA gold
DA 2024-07-18
ER

PT J
AU Bellini, M
AF Bellini, Mattia
TI Interactive Digital Narratives as Complex Expressive Means
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Interactive Digital Narratives (IDN); Complex Systems Theory; Expressive
   Complexity; Complex Representations; Representation of Complexity; Game
   Studies
ID VIRTUAL-REALITY; COGNITION
AB Is our way of expressing meanings through digital interactive artifacts simple? How does our sensemaking work when we try to understand Interactive Digital Narratives? To answer these and other questions, the present article discusses a complex-systemic understanding of the expressive mechanisms of Interactive Digital Narratives, to argue the expressive complexity of these artifacts. Interactors of Interactive Digital Narratives necessarily base their hermeneutic processes mainly on what is conveyed in the artifact itself; yet the question of how meaning is expressed in (and sense-making is guided by) Interactive Digital Narratives remains significantly open. I contend that sense-making in such artifacts works by synthetizing the knowledge coming from a number of layers of information, which are intercurrent, interdependent and interoperating, and which concurrently participate in the creation of an overall meaning of a higher order. According to complex systems theory, these layers are therefore elements of a complex system: this justifies the understanding. Even though largely unexplored, this understanding may help advance our knowledge of the representational capabilities and affordances of Interactive Digital Narrarives, not least in representing multifaceted worlds and complex phenomena. A complex-systemic view can also improve our comprehension of the interpretative processes involved in the sense-making of Interactive Digital Narratives. Furthermore, the awareness gained through this understanding could be useful to get a better sense of the impact of the narratives featured in these artifacts, and ultimately to create more engaging and more powerful experiences that can help foster the societal impact of Interactive Digital Narratives.
C1 [Bellini, Mattia] Univ Tartu, Inst Cultural Res, Res Grp Narrat Culture & Cognit, Tartu, Estonia.
C3 University of Tartu
RP Bellini, M (corresponding author), Univ Tartu, Inst Cultural Res, Res Grp Narrat Culture & Cognit, Tartu, Estonia.
EM mattia.bellini@ut.ee
RI Bellini, Mattia/CAI-0180-2022
OI Bellini, Mattia/0000-0003-4050-5970
FU University of Tartu [PHVKU21921]
FX The research for this article was supported by the University of Tartu
   (Basic Funding PHVKU21921, 2021-2022).
CR Abbott HP, 2008, POETICS TODAY, V29, P227, DOI 10.1215/03335372-2007-024
   Adami E., 2017, The Oxford Handbook of Language and Society
   Anable Aubrey., 2018, Playing with Feelings: Video Games and Affect
   [Anonymous], 2005, Theory of fun for game design
   [Anonymous], 2009, Expressive Processing: Digital Fictions, Computer Games, and Software Studies
   Arnavas F., 2021, L CARROLLS ALICE COG, DOI [10.1515/9783110689273/html, DOI 10.1515/9783110689273/HTML]
   Backe H.-J., 2020, GESAMTKUNSTWERK SYNE
   Battey T., 2017, VIDEOGAMES CAN DO SH
   Bellini M., 2018, CEUR WORKSHOP P
   Beltrami, 2021, SPATIAL PLOTS VIRTUA
   Bogost Ian., 2007, Persuasive Games: The Expressive Power of Videogames
   Bosco FM, 2013, J CHILD LANG, V40, P741, DOI 10.1017/S0305000913000081
   Burn A, 2016, LEARN MEDIA TECHNOL, V41, P310, DOI 10.1080/17439884.2015.1107096
   Caracciolo M., 2014, The Experientiality of Narrative: An Enactivist Approach
   Caracciolo Marco., 2021, With Bodies: Narrative Theory and Embodied Cognition
   Cheng P., 2007, DIGRA C
   Ciccoricco D., 2010, Intermediality and Storytelling, P232
   Ciccoricco David., 2015, Refiguring Minds in Narrative Media
   Clarke A, 2007, VIDEOGAMES AND ART, P1
   Craig MJ, 2020, ACMIEEE INT CONF HUM, P169, DOI 10.1145/3371382.3378298
   Danielsson K, 2016, LINGUIST EDUC, V35, P88, DOI 10.1016/j.linged.2016.07.005
   Denzin N. K, 1970, Sociological methods, DOI [10.4324/9781315129945, DOI 10.4324/9781315129945]
   Di Paolo Ezequiel., 2018, The Oxford Handbook of 4E Cognition, P71, DOI 10.1093/oxfordhb/9780198735410.013.4
   Domsch S., 2013, Storyplaying: Agency and Narrative in Video Games
   Douglas Y., 2000, ACM 2000 Hypertext. Proceedings of the Eleventh ACM Conference on Hypertext and Hypermedia, P153, DOI 10.1145/336296.336354
   Dunne D., 2014, PROC 16 ANN LEAN CON, P1, DOI 10.1145/2677758.2677785
   Egenfeldt-Nielsen S., 2008, Understanding Video Games: The Essential Introduction
   Eladhari MP, 2018, LECT NOTES COMPUT SC, V11318, P65, DOI 10.1007/978-3-030-04028-4_5
   Elson M, 2014, HANDBOOK OF DIGITAL GAMES, P362
   Elson M, 2014, J COMMUN, V64, P521, DOI 10.1111/jcom.12096
   Eysenck M. W., 2005, COGNITIVE PSYCHOL ST, V5th ed, pix646
   Faulstich Werner., 2013, Grundkurs Filmanalyse, V3
   Fiadotau M., 2015, Journal of Comparative Research in Anthropology and Sociology, V6, P85
   Fullerton T., 2008, GAM DES WORKSHOPA PL
   Game Freak and ILCA, 2021, POK SER ROL PLAYING
   Geslin Erik, 2016, International Journal of Computer Games Technology, V2016, DOI 10.1155/2016/5182768
   Goggin J., 2006, PUBLIC
   Gomez Romero-Borquez Jesus, 2020, Advances in Usability, User Experience, Wearable and Assistive Technology. Proceedings of the AHFE 2020 Virtual Conferences on Usability and User Experience, Human Factors and Assistive Technology, Human Factors and Wearable Technologies, and Virtual Environments and Game Design. Advances in Intelligent Systems and Computing (AISC 1217), P627, DOI 10.1007/978-3-030-51828-8_82
   Grishakova M., 2022, ROUTLEDGE COMPANION, P423
   Grishakova Marina., 2019, Narrative Complexity: Cognition, Embodiment, Evolution
   Hayles NK, 2016, CRIT INQUIRY, V43, P32, DOI 10.1086/688293
   Hello Games, 2016, NO MANS SKY ACT ADV
   Herman D, 2007, CAMBR COMPANION LIT, P245, DOI 10.1017/CCOL0521856965.017
   Herman David., 2002, Story Logic: Problems and Possibilities of Narrative
   Hjaltason K., 2015, GAME MECH TELLING ST
   Holl E., 2019, The 69th annual International Communication Association (ICA) Conference, Washington DC, USA
   Jarvinen A., 2002, P COMP GAM DIG CULT
   Jenkins H., 2003, GAME DESIGN NARRATIV
   Karhulahti V.-M., 2012, P 4 INT C FUN GAMES, DOI DOI 10.1145/2367616.2367619
   Karhulahti VM, 2020, MEDIA CULT SOC, V42, P471, DOI 10.1177/0163443720907010
   Knez I, 2008, CYBERPSYCHOL BEHAV, V11, P129, DOI 10.1089/cpb.2007.0006
   Knoller Noam, 2012, Interactive Storytelling. Proceedings of the 5th International Conference, ICIDS 2012, P30, DOI 10.1007/978-3-642-34851-8_3
   Knoller N, 2019, FRONT NARRAT, P98
   Knudsen L. V., 2018, ROUTLEDGE HDB MUSEUM
   Koenitz H., 2015, NTERACTIVE DIGITAL N
   Koenitz H., 2015, INTERACTIVE DIGITAL, P91
   Koenitz H, 2021, LECT NOTES COMPUT SC, V13138, P488, DOI 10.1007/978-3-030-92300-6_49
   Koenitz Hartmut, 2021, Trans. Digit. Games Res. Assoc., V5, P3
   Kress G., 2010, MULTIMODALITY SOCIAL
   Kuvich G, 2005, P SOC PHOTO-OPT INS, V5807, P409, DOI 10.1117/12.603026
   Kuvich G, 2013, NEW MATH NAT COMPUT, V9, P301, DOI 10.1142/S1793005713400097
   Lahti M., 2004, VIDEO GAME THEORY RE
   Lakoff George, 1980, METAPHORS WE LIVE BY
   Laurel Brenda., 2013, Computers as Theatre, VSecond
   Leach CW, 2000, BRIT J SOC PSYCHOL, V39, P449, DOI 10.1348/014466600164507
   Lee D, 2000, SOCIOL THEOR, V18, P320, DOI 10.1111/0735-2751.00102
   Lee L., 2016, GRAPHIC STYLES APPEA
   Lehto O., 2009, COMPUTER GAMES TEXT, P21
   Lindley C.A., 2002, Proceedings of the Computer Games and Digital Cultures Conference, P6
   Magliano JP, 2019, FRONT NARRAT, P149
   Maitlis S, 2014, ACAD MANAG ANN, V8, P57, DOI 10.1080/19416520.2014.873177
   Marquard O., 1983, HANG ZUM GESAMTKUNST
   McLaughlin T., 2010, Proceedings of the Fifth International Conference on the Foundations of Digital Games, P132
   Meier M.-L., 2021, JOINT P 4 WORKSH GAM
   Merleau-Ponty M., 2013, Phenomenology of Perception
   Milesi L., 2019, INSCRIBING LONE LEVE, DOI [10.5040/9781501330520, DOI 10.5040/9781501330520]
   Miller C.H., 2019, Digital Storytelling 4e: A creator's guide to interactive entertainment
   Mojang, 2011, MIN SANDB SURV WIND
   Morton Timothy., 2013, HYPEROBJECTS PHILOS, DOI DOI 10.5749/J.CTT4CGGM7
   Munday Rod., 2007, Music, Sound and Multimedia: From the Live to the Virtual, P51
   Murray JH, 2017, HAMLET ON THE HOLODECK: THE FUTURE OF NARRATIVE IN CYBERSPACE, P1
   Nintendo R., 1985, SUP MAR BROS PLATF N
   NOE Alva, 2006, Action in Perception
   Pallavicini Federica, 2020, Universal Access in Human-Computer Interaction. Applications and Practice. 14th International Conference, UAHCI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12189), P212, DOI 10.1007/978-3-030-49108-6_16
   Pearson J, 2019, NAT REV NEUROSCI, V20, P624, DOI 10.1038/s41583-019-0202-9
   Perlovsky L I, 2010, Open Neuroimag J, V4, P70, DOI 10.2174/1874440001004010070
   Perron B., 2009, Horror Video Games: Essays on the Fusion of Fear and Play
   Polvinen M, 2021, STYLE, V55, P385, DOI 10.5325/style.55.3.0385
   Quantic Dream, 2018, DETR BEC HUM ADV PLA
   Reyes M. C., 2017, ZENA INTERACTIVE VR
   Rockstar North Digital Eclipse Rockstar Leeds and Rockstar Canada, 2021, GRAND THEFT AUT ACT
   Roth C, 2018, LECT NOTES COMPUT SC, V11318, P93, DOI 10.1007/978-3-030-04028-4_7
   Roth Christian., 2016, Proceedings of the 1st International Workshop on Multimedia Alternate Realities. AltMM'16, P31, DOI DOI 10.1145/2983298.2983302
   Rumelhart D.E., 1980, Schemata: The building blocks of cognition
   Ryan ML, 1999, SUB-STANCE, P110
   Salen Katie., 2005, HDB COMPUTER GAME ST
   Schacter DL, 2012, NEURON, V76, P677, DOI 10.1016/j.neuron.2012.11.001
   Schank Roger C., 1977, SCRIPTS PLANS GOALS
   Schell J., 2014, The Art of Game Design: A book of lenses
   Seif El-Nasr M., 2006, Dynamic lighting for tension in games
   Sheldon L., 2004, CHARACTER DEV STORYT
   Shibolet Y., 2018, PRESS START, V4, P21
   Sinding Michael, 2012, Cognitive Literary Studies: Current Theme and New Directions, P145
   Slade D., 2018, Black Mirror: Bandersnatch
   Smith MatthewWilson., 2007, The Total Work of Art: From Bayreuth to Cyberspace
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stockwell Peter., 2002, Cognitive Poetics: An Introduction
   Tavinor G., 2009, The art of videogames
   The Global Fund Office of the Inspector General, 2019, Guia de bolsillo para el manejo y la prevencion del asma, P1
   Toh Weimin., 2018, A Multimodal Approach to Video Games and the Player Experience
   Traninger A., 2012, TRAVELLING CONCEPTS, DOI [10.1515/9783110227628.67, DOI 10.1515/9783110227628.67]
   Ubisoft Montpellier, 2005, KING KONG ACT ADV GA
   Walsh R., 2018, NARRATING COMPLEXITY, DOI [10.1007/978-3-319-64714-2, DOI 10.1007/978-3-319-64714-2]
   Walsh Richard, 2018, Narrating complexity
   Zehnder SM, 2006, LEA COMMUN SER, P241
   Zwaan R. A., 2008, SYMBOLS EMBODIMENT D, DOI [10.1093/acprof:oso/9780199217274.003.0009, DOI 10.1093/ACPROF:OSO/9780199217274.003.0009]
NR 116
TC 3
Z9 3
U1 6
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 26
PY 2022
VL 3
AR 854960
DI 10.3389/frvir.2022.854960
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PH2
UT WOS:001021724700001
OA gold
DA 2024-07-18
ER

PT J
AU Kangas, J
   Spakov, O
   Raisamo, R
   Koskinen, O
   Järvenpää, T
   Salmimaa, M
AF Kangas, Jari
   Spakov, Oleg
   Raisamo, Roope
   Koskinen, Olli
   Jarvenpaa, Toni
   Salmimaa, Marja
TI Head and Gaze Orientation in Hemispheric Image Viewing
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; head pointing; gaze orientation; head orientation;
   image viewing in VR
ID EYE-MOVEMENTS; VARIABLE INTERACTIONS; COORDINATION; TRACKING;
   ALLOCATION; ATTENTION; TESTS
AB Head mounted displays provide a good platform for viewing of immersive 360 & DEG; or hemispheric images. A person can observe an image all around, just by turning his/her head and looking at different directions. The device also provides a highly useful tool for studying the observer's gaze directions and head turns. We aimed to explore the interplay between participant's head and gaze directions and collected head and gaze orientation data while participants were asked to view and study hemispheric images. In this exploration paper we show combined visualizations of both the head and gaze orientations and present two preliminary models of the relation between the gaze and the head orientations. We also show results of an analysis of the gaze and head behavior in relation to the given task/question.
C1 [Kangas, Jari; Spakov, Oleg; Raisamo, Roope; Koskinen, Olli] Tampere Univ, TAUCHI Res Ctr, Tampere, Finland.
   [Jarvenpaa, Toni; Salmimaa, Marja] Nokia Bell Labs, Tampere, Finland.
C3 Tampere University; Nokia Corporation; Nokia Finland
RP Kangas, J (corresponding author), Tampere Univ, TAUCHI Res Ctr, Tampere, Finland.
EM jari.a.kangas@tuni.fi
RI Raisamo, Roope/P-8398-2018
OI Raisamo, Roope/0000-0003-3276-7866; Spakov, Oleg/0000-0002-7679-4631
CR Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   Bates Richard, 2007, Universal Access in the Information Society, V6, P159, DOI 10.1007/s10209-007-0077-9
   BIGUER B, 1982, EXP BRAIN RES, V46, P301
   Biswas P, 2016, INT J HUM-COMPUT INT, V32, P23, DOI 10.1080/10447318.2015.1084112
   Brennan SE, 2008, COGNITION, V106, P1465, DOI 10.1016/j.cognition.2007.05.012
   Bretzner L, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY PROCEEDINGS, P161
   Bulling A, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P41
   Coutrot A, 2018, BEHAV RES METHODS, V50, P362, DOI 10.3758/s13428-017-0876-8
   David EJ, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P432, DOI 10.1145/3204949.3208139
   Doshi A, 2012, J VISION, V12, DOI 10.1167/12.2.9
   Dugard P, 2014, J CONTEXT BEHAV SCI, V3, P65, DOI 10.1016/j.jcbs.2013.10.001
   Edgington E., 2007, RANDOMIZATION TESTS
   Falck-Ytter T, 2013, J NEURODEV DISORD, V5, DOI 10.1186/1866-1955-5-28
   Foulsham T, 2011, VISION RES, V51, P1920, DOI 10.1016/j.visres.2011.07.002
   Freedman EG, 2008, EXP BRAIN RES, V190, P369, DOI 10.1007/s00221-008-1504-8
   Gegenfurtner A, 2011, EDUC PSYCHOL REV, V23, P523, DOI 10.1007/s10648-011-9174-7
   Goossens HHLM, 1997, EXP BRAIN RES, V114, P542, DOI 10.1007/PL00005663
   GUITTON D, 1992, TRENDS NEUROSCI, V15, P174, DOI 10.1016/0166-2236(92)90169-9
   GUITTON D, 1987, J NEUROPHYSIOL, V58, P427, DOI 10.1152/jn.1987.58.3.427
   Hanna JE, 2007, J MEM LANG, V57, P596, DOI 10.1016/j.jml.2007.01.008
   Howell D. C., 2010, Statistical methods for psychology
   HU B, 2018, P IEEE INT C COMM IC, DOI DOI 10.1109/CISS.2018.8362264
   Hu B, 2017, 2017 51ST ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)
   Hu ZM, 2019, IEEE T VIS COMPUT GR, V25, P2002, DOI 10.1109/TVCG.2019.2899187
   Ishimaru S, 2014, P 5 AUGM HUM INT C N
   Itti, 2007, Scholarpedia, V2, P3327, DOI DOI 10.4249/SCHOLARPEDIA.3327
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jarvenpaa T., 2017, P IDW INT DISPL WORK, P1060
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   Kangas J, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875209
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Koehler K, 2014, J VISION, V14, DOI 10.1167/14.3.14
   Kollenberg Tobit., 2010, P 2010 S EYE TRACKIN, P121, DOI [10.1145/1743666.1743696, DOI 10.1145/1743666.1743696]
   Konrad R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3361330
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kowler E., 1992, The head-neck sensory motor system, P419, DOI 10.1093/acprof:oso/9780195068207.003.0065
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   LAND MF, 1992, NATURE, V359, P318, DOI 10.1038/359318a0
   Law B., 2004, P 2004 S EYE TRACKIN, P41, DOI [10.1145/968363.968370, DOI 10.1145/968363.968370]
   Li R, 2020, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR50242.2020.00033
   Liversedge SP, 2000, TRENDS COGN SCI, V4, P6, DOI 10.1016/S1364-6613(99)01418-7
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Ohn-Bar E, 2014, INT C PATT RECOG, P660, DOI 10.1109/ICPR.2014.124
   Oommen BS, 2004, EXP BRAIN RES, V155, P9, DOI 10.1007/s00221-003-1694-z
   Padmanaban N, 2017, P NATL ACAD SCI USA, V114, P2183, DOI 10.1073/pnas.1617251114
   Pelz J, 2001, EXP BRAIN RES, V139, P266, DOI 10.1007/s002210100745
   Pelz JB, 2001, VISION RES, V41, P3587, DOI 10.1016/S0042-6989(01)00245-0
   Pfeil K, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225157
   Poole A., 2006, Encyclopedia of human computer interaction, P211, DOI [10.4018/978-1-59140-562-7.ch034, DOI 10.4018/978-1-59140-562-7.CH034]
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Rantala J, 2020, HUM-COMPUT INTERACT, V35, P1, DOI 10.1080/07370024.2017.1306444
   Rayner K, 2009, Q J EXP PSYCHOL, V62, P1457, DOI 10.1080/17470210902816461
   RON S, 1991, EXP BRAIN RES, V85, P196
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   't Hart BM, 2009, VIS COGN, V17, P1132, DOI 10.1080/13506280902812304
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Wedel M., 2008, Review of Marketing Research, V4, P123, DOI 10.4324/9781351550932-5
   Wilson MR, 2011, SURG ENDOSC, V25, P3731, DOI 10.1007/s00464-011-1802-2
   ZANGEMEISTER WH, 1982, EXP NEUROL, V75, P389, DOI 10.1016/0014-4886(82)90169-8
   ZANGEMEISTER WH, 1982, EXP NEUROL, V77, P563, DOI 10.1016/0014-4886(82)90228-X
NR 63
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 24
PY 2022
VL 3
AR 822189
DI 10.3389/frvir.2022.822189
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AC8
UT WOS:001019281600001
OA gold
DA 2024-07-18
ER

PT J
AU Eubanks, JC
   Moore, AG
   Fishwick, PA
   McMahan, RP
AF Eubanks, James Coleman
   Moore, Alec G.
   Fishwick, Paul A.
   McMahan, Ryan P.
TI A Preliminary Embodiment Short Questionnaire
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE embodiment; self-location; agency; body ownership; questionnaire;
   virtual reality
ID VIRTUAL BODY OWNERSHIP; REALITY; AVATAR; SENSE; 5-POINT; IMPACT; AGENCY;
   FEEL
AB Consumer virtual reality (VR) technologies have made embodying a virtual avatar during an immersive experience more feasible. The sense of embodiment toward that virtual avatar can be characterized and measured along three factors: self-location, agency, and body ownership. Some measures of embodiment have been previously proposed, but most have not been validated or do not measure the three individual factors of embodiment. In this paper, we present the construction and validation of a preliminary version of a short questionnaire that not only addresses these factors of embodiment but can also be used as an in-VR questionnaire, which we call the pESQ. By using and validating the pESQ, we provide results indicating that foot tracking significantly improves self-location and agency, and that an avatar significantly improves body ownership.
C1 [Eubanks, James Coleman; Fishwick, Paul A.] Univ Texas Dallas, Sch Arts Technol & Emerging Commun, Richardson, TX USA.
   [Moore, Alec G.; McMahan, Ryan P.] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32826 USA.
C3 University of Texas System; University of Texas Dallas; State University
   System of Florida; University of Central Florida
RP McMahan, RP (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32826 USA.
EM rpm@ucf.edu
CR Alexandrovsky D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376260
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Arzy S, 2006, J NEUROSCI, V26, P8074, DOI 10.1523/JNEUROSCI.0745-06.2006
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169343
   Clark LA, 1995, PSYCHOL ASSESSMENT, V7, P309, DOI 10.1037/1040-3590.7.3.309
   Dawes J, 2008, INT J MARKET RES, V50, P61, DOI 10.1177/147078530805000106
   DeVellis R. F., 2016, Scale development: Theory and applications, DOI DOI 10.1037/CCP0000482
   Dobricki M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083840
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Falconer CJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111933
   Finstad K, 2010, J USABILITY STUD, V5, P104
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2014, EXP BRAIN RES, V232, P875, DOI 10.1007/s00221-013-3800-1
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Heydrich L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00946
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kline P, 2014, An easy guide to factor analysis, DOI [10.4324/9781315788135, DOI 10.4324/9781315788135]
   Koilias A, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020018
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kondo R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25951-2
   Lakens D, 2017, SOC PSYCHOL PERS SCI, V8, P355, DOI 10.1177/1948550617697177
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P73, DOI 10.1145/2993369.2993399
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lopez C, 2010, CONSCIOUS COGN, V19, P33, DOI 10.1016/j.concog.2009.12.003
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   MacCallum RC, 1999, PSYCHOL METHODS, V4, P84, DOI 10.1037/1082-989x.4.1.84
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Padrao G, 2016, NEUROIMAGE, V124, P147, DOI 10.1016/j.neuroimage.2015.08.022
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1964, DOI 10.1109/TVCG.2020.2973061
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Pomés A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00908
   Roth D., 2019, ARXIV 1911 10176, VarXiv, p1911.10176
   Roth D., 2017, C HUM FACTORS COMPUT, VPart F1276, P2875, DOI DOI 10.1145/3027063.3053272
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Roth D, 2016, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2016.7504760
   Satyavolu S.K., 2014, PROC ACM S APPL PERC, P95, DOI DOI 10.1145/2628257.2628272
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Toothman N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P756, DOI [10.1109/vr.2019.8798108, 10.1109/VR.2019.8798108]
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
NR 70
TC 8
Z9 8
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 1
PY 2021
VL 2
AR 647896
DI 10.3389/frvir.2021.647896
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WZ3
UT WOS:001023297900001
OA gold
DA 2024-07-18
ER

PT J
AU Lewis, JE
   Trojovsky, M
   Jameson, MM
AF Lewis, Joanna E.
   Trojovsky, Mia
   Jameson, Molly M.
TI New Social Horizons: Anxiety, Isolation, and Animal Crossing During the
   COVID-19 Pandemic
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE anxiety; loneliness; COVID-19; isolation; video games
ID VIDEO GAMES; HEALTH; LONELINESS; WORLD; ADOLESCENTS; WARCRAFT; SUPPORT;
   IMPACT; PLAY
AB Increased participation in activities has been associated with improved positive mental health outcomes. However, there is much debate regarding the net effects of video games on individuals. Typified as a socially isolating activity, many games inherently contain socialization within the environment with game-generated characters or other players. Coinciding with the time of the initial pandemic/quarantine period was the release of a popular socializing and life simulation game, Animal Crossing: New Horizons. We investigated whether participation in this game was related to emotional outcomes associated with pandemics (e.g., loneliness and anxiety). The relationship between deleterious mental health and social gaming, amid a time of enforced reduction in socializing, would allow us to isolate the impact of the introduction of a social video game on improving the quality of life for players of this game. Participants (n = 1053) were asked about their time spent playing video games via an online survey, their socialization in game play, loneliness, and anxiety. We predicted that participants with higher levels of social interaction within the game would report less loneliness and anxiety. Utilizing multiple linear regression analyses, the research found that increased gaming and related activities were predictive of higher anxiety and somewhat related to increased loneliness. However, increased visits to another island were associated with lower levels of loneliness. As such, players may be utilizing gaming as a coping mechanism for anxiety. This research may inform generalized research regarding the influence that social games may have on feelings of loneliness and anxiety.
C1 [Lewis, Joanna E.; Trojovsky, Mia; Jameson, Molly M.] Univ Northern Colorado, Sch Psychol Sci, Greeley, CO 80639 USA.
C3 University of Northern Colorado
RP Lewis, JE (corresponding author), Univ Northern Colorado, Sch Psychol Sci, Greeley, CO 80639 USA.
EM joanna.lewis@unco.edu
OI Lewis, Joanna/0000-0003-0974-2230
CR Ammar A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240204
   Ammar A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176237
   [Anonymous], 2020, ANIMAL CROSSING NEW
   Banerjee D, 2020, INT J SOC PSYCHIATR, V66, P525, DOI 10.1177/0020764020922269
   BECK AT, 1988, J CONSULT CLIN PSYCH, V56, P893, DOI 10.1037/0022-006X.56.6.893
   Cacioppo J. T., 2008, LONELINESS HUMAN NAT, DOI DOI 10.1007/S11126-022-10006-7
   Cacioppo JT, 2014, SOC PERSONAL PSYCHOL, V8, P58, DOI 10.1111/spc3.12087
   Carras MC, 2017, COMPUT HUM BEHAV, V68, P472, DOI 10.1016/j.chb.2016.11.060
   Cole H, 2007, CYBERPSYCHOL BEHAV, V10, P575, DOI 10.1089/cpb.2007.9988
   Czaja SJ, 2018, GERONTOLOGIST, V58, P467, DOI 10.1093/geront/gnw249
   Desai RA, 2010, PEDIATRICS, V126, pE1414, DOI 10.1542/peds.2009-2706
   El-Zoghby SM, 2020, J COMMUN HEALTH, V45, P689, DOI 10.1007/s10900-020-00853-5
   Entertainment Software Association, 2020, 2020 ESS FACTS VID G
   Fasce F., 2020, ANIMAL CROSSING AGE
   Fish MT, 2018, SIMULAT GAMING, V49, P553, DOI 10.1177/1046878118773126
   Galea S, 2020, JAMA INTERN MED, V180, P817, DOI 10.1001/jamainternmed.2020.1562
   Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857
   Greitemeyer T, 2014, PERS SOC PSYCHOL B, V40, P578, DOI 10.1177/0146167213520459
   Halbrook YJ, 2019, PERSPECT PSYCHOL SCI, V14, P1096, DOI 10.1177/1745691619863807
   Hawthorne G, 2008, SOC PSYCH PSYCH EPID, V43, P140, DOI 10.1007/s00127-007-0279-8
   Heinrichs M, 2003, BIOL PSYCHIAT, V54, P1389, DOI 10.1016/S0006-3223(03)00465-7
   Hou TY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233831
   Jin YC, 2017, COMPUT HUM BEHAV, V68, P556, DOI 10.1016/j.chb.2016.11.059
   Jun HJ, 2017, J GERONTOL B-PSYCHOL, V72, P846, DOI 10.1093/geronb/gbw163
   KNIGHT RG, 1988, J CLIN PSYCHOL, V44, P203, DOI 10.1002/1097-4679(198803)44:2<203::AID-JCLP2270440218>3.0.CO;2-5
   Kowert R, 2014, COMPUT HUM BEHAV, V36, P385, DOI 10.1016/j.chb.2014.04.003
   Leigh-Hunt N, 2017, PUBLIC HEALTH, V152, P157, DOI 10.1016/j.puhe.2017.07.035
   Lenhart A., 2008, Teens' gaming experiences are diverse and include significant social interaction and civic engagement
   Martoncik M, 2016, COMPUT HUM BEHAV, V56, P127, DOI 10.1016/j.chb.2015.11.035
   Merchant RM, 2020, JAMA-J AM MED ASSOC, V323, P2011, DOI 10.1001/jama.2020.4469
   Neria Y, 2008, PSYCHOL MED, V38, P467, DOI 10.1017/S0033291707001353
   Odrowska AM, 2014, COMPUT HUM BEHAV, V34, P235, DOI 10.1016/j.chb.2014.02.005
   Peever N., 2012, P 8 AUSTRALASIAN C I
   Pine R, 2020, GAMES HEALTH J, V9, P255, DOI 10.1089/g4h.2019.0132
   Prescott AT, 2018, P NATL ACAD SCI USA, V115, P9882, DOI 10.1073/pnas.1611617114
   Qi M, 2020, J ADOLESCENT HEALTH, V67, P514, DOI 10.1016/j.jadohealth.2020.07.001
   Reynolds DL, 2008, EPIDEMIOL INFECT, V136, P997, DOI 10.1017/S0950268807009156
   Robb CE, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.591120
   RUSSELL D, 1980, J PERS SOC PSYCHOL, V39, P472, DOI 10.1037/0022-3514.39.3.472
   Saltzman LY, 2020, PSYCHOL TRAUMA-US, V12, pS55, DOI 10.1037/tra0000703
   Spira AP, 2004, J ANXIETY DISORD, V18, P309, DOI 10.1016/S0887-6185(02)00249-9
   Yue CY, 2021, INT J SOC PSYCHIATR, V67, P120, DOI 10.1177/0020764020941567
NR 42
TC 22
Z9 24
U1 3
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 30
PY 2021
VL 2
AR 627350
DI 10.3389/frvir.2021.627350
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TJ4
UT WOS:001021831700001
OA gold
DA 2024-07-18
ER

PT J
AU Pieterse, AD
   Hierck, BP
   de Jong, PGM
   Kroese, J
   Willems, LNA
   Reinders, MEJ
AF Pieterse, Arianne D.
   Hierck, Beerend P.
   de Jong, Peter G. M.
   Kroese, Jelger
   Willems, Luuk N. A.
   Reinders, Marlies E. J.
TI Design and Implementation of "<i>AugMedicine</i>: <i>Lung Cases</i>," an
   Augmented Reality Application for the Medical Curriculum on the
   Presentation of Dyspnea
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; mixed reality; medical education; technology enhanced
   learning; active learning; collaborative learning; pulmonary medicine;
   internal medicine
ID SIMULATED PATIENTS; EDUCATION; AUSCULTATION
AB Introduction: Augmented Reality is a technique that enriches the real-life environment with 3D visuals and audio. It offers possibilities to expose medical students to a variety of clinical cases. It provides unique opportunities for active and collaborative learning in an authentic but safe environment. We developed an Augmented Reality application on the clinical presentation of shortness of breath (dyspnea), grounded on a theoretical instructional design model.Methods: A team of various stakeholders (including medical teachers and students) was formed to design the application and corresponding small group learning session, grounded on principles of instruction as described by Merrill. Evaluation was performed by an explorative questionnaire, consisting of open and closed questions (Likert scales), covering user experience, content and physical discomfort.Results: Multiple interactive cases of dyspnea were designed. The application plays back audio samples of abnormal lung sounds corresponding to a specific clinical case of dyspnea and displays a 3D model of the related pulmonary pathologies. It was implemented in the medical curriculum as an obligatory small group learning session scheduled preceding clinical clerkships. Prior knowledge was activated prior to the learning session. New knowledge was acquired with the application by solving an authentic problem based on a real patient case. In total 110 students participated in the study and 104 completed the questionnaire. 85% of the students indicated that the virtually auscultated lung sounds felt natural. 90% reported that the augmented reality experience helped them to better understand the clinical case. The majority of the students (74%) indicated that the experience improved their insight in the portrayed illness. 94.2% reported limited or no physical discomfort.Discussion: An Augmented Reality application on the presentation of dyspnea was successfully designed and implemented in the medical curriculum. Students confirm the value of the application in terms of content and usability. The extension of this Augmented Reality application for education of other healthcare professionals in currently under consideration.
C1 [Pieterse, Arianne D.; Reinders, Marlies E. J.] Leiden Univ, Med Ctr, Dept Internal Med, Leiden, Netherlands.
   [Hierck, Beerend P.] Leiden Univ, Med Ctr, Dept Anat & Embryol, Leiden, Netherlands.
   [Hierck, Beerend P.; de Jong, Peter G. M.] Leiden Univ, Med Ctr, Ctr Innovat Med Educ, Leiden, Netherlands.
   [Kroese, Jelger] Leiden Univ, Ctr Innovat, The Hague, Netherlands.
   [Willems, Luuk N. A.] Leiden Univ, Med Ctr, Dept Pulm, Leiden, Netherlands.
   [Reinders, Marlies E. J.] Leiden Univ, Med Ctr, Dept Nephrol, Leiden, Netherlands.
C3 Leiden University; Leiden University Medical Center (LUMC); Leiden
   University - Excl LUMC; Leiden University; Leiden University Medical
   Center (LUMC); Leiden University - Excl LUMC; Leiden University - Excl
   LUMC; Leiden University; Leiden University Medical Center (LUMC); Leiden
   University - Excl LUMC; Leiden University; Leiden University; Leiden
   University Medical Center (LUMC); Leiden University - Excl LUMC; Leiden
   University - Excl LUMC; Leiden University; Leiden University Medical
   Center (LUMC)
RP Pieterse, AD (corresponding author), Leiden Univ, Med Ctr, Dept Internal Med, Leiden, Netherlands.
EM a.d.pieterse@lumc.nl
OI Reinders, Marlies/0000-0001-9543-567X
CR Barmaki R, 2019, ANAT SCI EDUC, V12, P599, DOI 10.1002/ase.1858
   Bernardi S, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1708-6
   Bogomolova K, 2021, MED EDUC, V55, P317, DOI 10.1111/medu.14352
   Bogomolova K, 2020, ANAT SCI EDUC, V13, P558, DOI 10.1002/ase.1941
   Cleland JA, 2009, MED TEACH, V31, P477, DOI 10.1080/01421590903002821
   Eckert M, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/10967
   Edelbring S, 2011, ADV HEALTH SCI EDUC, V16, P331, DOI 10.1007/s10459-010-9265-0
   Freeman S, 2014, P NATL ACAD SCI USA, V111, P8410, DOI 10.1073/pnas.1319030111
   Friederichs H, 2014, ADV PHYSIOL EDUC, V38, P343, DOI 10.1152/advan.00039.2013
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Gerup J, 2020, INT J MED EDUC, V11, DOI 10.5116/ijme.5e01.eb1a
   Kamphuis C, 2014, PERSPECT MED EDUC, V3, P300, DOI 10.1007/s40037-013-0107-7
   Kaufmann H, 2003, COMPUT GRAPH-UK, V27, P339, DOI 10.1016/S0097-8493(03)00028-1
   Kotranza A, 2012, IEEE T VIS COMPUT GR, V18, P1101, DOI 10.1109/TVCG.2011.132
   Lamounier E, 2010, IEEE ENG MED BIO, P610, DOI 10.1109/IEMBS.2010.5628019
   McKinney J, 2013, J GEN INTERN MED, V28, P283, DOI 10.1007/s11606-012-2198-y
   Merrill MD, 2002, ETR&D-EDUC TECH RES, V50, P43, DOI 10.1007/BF02505024
   Miles M. B., 1984, Qualitative data analysis: An expanded sourcebook
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Nilsson S., 2008, Proc. ACM CHI 2008 Conf. Hum. Factors Comput. Syst, V2, P2025
   Nischelwitzer A, 2007, UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND SERVICES, PT 3, PROCEEDINGS, P728
   plato.stanford, 2020, WEBS STANF ENC PHIL
   Pretto F, 2009, SAC 09 P 2009 ACM S, P836
   Rosenbaum E., 2007, Journal of Science Education and Technology, V16, P31, DOI DOI 10.1007/S10956-006-9036-0
   Sakellariou S, 2009, LECT NOTES COMPUT SC, V5622, P605, DOI 10.1007/978-3-642-02771-0_67
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schwaber Ken, 2008, AGILE SOFTWARE DEV S
   SESTINI P, 1995, EUR RESPIR J, V8, P783
   Sheik-Ali Sharaf, 2019, Surg Technol Int, V35, P27
   Tang Kevin S, 2020, Can Med Educ J, V11, pe81, DOI 10.36834/cmej.61705
   Uruthiralingam U, 2020, ADV EXP MED BIOL, V1235, P89, DOI 10.1007/978-3-030-37639-0_5
   von Jan U, 2012, BIOMED ENG-BIOMED TE, V57, P67, DOI 10.1515/bmt-2012-4252
   Vovk A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173783
   Ward JJ, 2011, RESP CARE, V56, P834, DOI 10.4187/respcare.01072
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   youtu.be, 2020, DEM AUGMEDICINE LUNG
   youtube, 2020, HOL APP AUGMEDICINE
   Yusoff Rasimah Che Mohd, 2011, Australasian Journal of Educational Technology, V27, P1369
   Zhu EG, 2014, PEERJ, V2, DOI 10.7717/peerj.469
NR 40
TC 2
Z9 2
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 28
PY 2020
VL 1
AR 577534
DI 10.3389/frvir.2020.577534
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L6UA3
UT WOS:001024580000001
OA gold
DA 2024-07-18
ER

PT J
AU Sakurada, K
   Kondo, R
   Nakamura, F
   Kitazaki, M
   Sugimoto, M
AF Sakurada, Kuniharu
   Kondo, Ryota
   Nakamura, Fumihiko
   Kitazaki, Michiteru
   Sugimoto, Maki
TI Investigating the perceptual attribution of a virtual robotic limb
   synchronizing with hand and foot simultaneously
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; embodiment; perceptual attribution; wearable robotic
   limbs; proprioceptive drift; sense of agency; sense of body ownership;
   error correction frequency
ID OWNERSHIP; BODY; ILLUSION; SENSE
AB Introduction: Incorporating an additional limb that synchronizes with multiple body parts enables the user to achieve high task accuracy and smooth movement. In this case, the visual appearance of the wearable robotic limb contributes to the sense of embodiment. Additionally, the user's motor function changes as a result of this embodiment. However, it remains unclear how users perceive the attribution of the wearable robotic limb within the context of multiple body parts (perceptual attribution), and the impact of visual similarity in this context remains unknown.Methods: This study investigated the perceptual attribution of a virtual robotic limb by examining proprioceptive drift and the bias of visual similarity under the conditions of single body part (synchronizing with hand or foot motion only) and multiple body parts (synchronizing with average motion of hand and foot). Participants in the conducted experiment engaged in a point-to-point task using a virtual robotic limb that synchronizes with their hand and foot motions simultaneously. Furthermore, the visual appearance of the end-effector was altered to explore the influence of visual similarity.Results: The experiment revealed that only the participants' proprioception of their foot aligned with the virtual robotic limb, while the frequency of error correction during the point-to-point task did not change across conditions. Conversely, subjective illusions of embodiment occurred for both the hand and foot. In this case, the visual appearance of the robotic limbs contributed to the correlations between hand and foot proprioceptive drift and subjective embodiment illusion, respectively.Discussion: These results suggest that proprioception is specifically attributed to the foot through motion synchronization, whereas subjective perceptions are attributed to both the hand and foot.
C1 [Sakurada, Kuniharu; Kondo, Ryota; Sugimoto, Maki] Keio Univ, Grad Sch Sci & Technol, Yokohama, Kanagawa, Japan.
   [Nakamura, Fumihiko] Ritsumeikan Univ, Coll Informat & Sci, Kusatsu, Shiga, Japan.
   [Kitazaki, Michiteru] Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi, Japan.
C3 Keio University; Ritsumeikan University; Toyohashi University of
   Technology
RP Sakurada, K (corresponding author), Keio Univ, Grad Sch Sci & Technol, Yokohama, Kanagawa, Japan.
EM kh.sakurada@imlab.ics.keio.ac.jp
RI Nakamura, Fumihiko/N-5476-2016
FU This study was supported by JST ERATO, Grant Number JPMJER1701, by JST
   SPRING, Grant Number JPMJSP2123, and by JSPS KAKENHI, Grant Number
   JP22KK0158. [JPMJER1701]; JST ERATO [JPMJSP2123]; JST SPRING
   [JP22KK0158]; JSPS KAKENHI
FX This study was supported by JST ERATO, Grant Number JPMJER1701, by JST
   SPRING, Grant Number JPMJSP2123, and by JSPS KAKENHI, Grant Number
   JP22KK0158.
CR Abdi E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134501
   Abdulkarim Z, 2016, ATTEN PERCEPT PSYCHO, V78, P707, DOI 10.3758/s13414-015-1016-0
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Dingwell JB, 2002, J NEUROPHYSIOL, V88, P222, DOI 10.1152/jn.2002.88.1.222
   Farrer C, 2008, BEHAV NEUROL, V19, P53, DOI 10.1155/2008/425267
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Hagiwara T, 2021, PROCEEDINGS OF SIGGRAPH ASIA 2021 EMERGING TECHNOLOGIES, DOI 10.1145/3476122.3484841
   Hagiwara T, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101732
   Hagiwara T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P954, DOI [10.1109/vr.2019.8798222, 10.1109/VR.2019.8798222]
   Holle H, 2011, COGN NEUROSCI-UK, V2, P171, DOI 10.1080/17588928.2011.603828
   Iwasaki Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON CYBORG AND BIONIC SYSTEMS (CBS), P662, DOI 10.1109/CBS.2018.8612275
   Kalckert A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00344
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kasuga S, 2015, NEUROSCI RES, V94, P62, DOI 10.1016/j.neures.2014.12.010
   Khazoom C, 2020, IEEE ROBOT AUTOM LET, V5, P5143, DOI 10.1109/LRA.2020.3005629
   Kieliba P, 2021, SCI ROBOT, V6, DOI 10.1126/scirobotics.abd7935
   Kojima A, 2017, IEEE/SICE I S SYS IN, P1022, DOI 10.1109/SII.2017.8279357
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Krom BN, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P49, DOI [10.1109/WHC.2019.8816112, 10.1109/whc.2019.8816112]
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Llorens-Bonilla B, 2012, IEEE INT C INT ROBOT, P3936, DOI 10.1109/IROS.2012.6386055
   Marasco PD, 2018, SCI TRANSL MED, V10, DOI 10.1126/scitranslmed.aao6990
   Maravita A, 2003, CURR BIOL, V13, pR531, DOI 10.1016/S0960-9822(03)00449-4
   Mazzoni P, 2006, J NEUROSCI, V26, P3642, DOI 10.1523/JNEUROSCI.5317-05.2006
   Oh J, 2020, SYMP VLSI CIRCUITS, DOI 10.1109/vlsicircuits18222.2020.9162917
   Pakkanen T., 2004, CHI 04 EXTENDED ABST, P1123, DOI [10.1145/985921.986004., DOI 10.1145/985921.986004]
   Parietti F, 2014, IEEE INT CONF ROBOT, P1176, DOI 10.1109/ICRA.2014.6907002
   Prattichizzo D, 2021, PROG BIOMED ENG, V3, DOI 10.1088/2516-1091/ac2294
   Preston C, 2013, ACTA PSYCHOL, V142, P177, DOI 10.1016/j.actpsy.2012.12.005
   Sakurada K, 2022, PROCEEDINGS OF AUGMENTED HUMANS CONFERENCE 2022 (AHS 2022), P104, DOI 10.1145/3519391.3522754
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Saraiji Y, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P65, DOI 10.1145/3242587.3242665
   Sasaki Tomoya, 2017, P ACM SIGGRAPH EM TE, DOI DOI 10.1145/3084822.3084837
   Schiefer M, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/1/016001
   Shibuya S, 2017, EXP BRAIN RES, V235, P121, DOI 10.1007/s00221-016-4777-3
   Takizawa R, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P25, DOI 10.1109/AIVR46125.2019.00014
   Tosi G, 2023, Q J EXP PSYCHOL, DOI 10.1177/17470218231156849
   Umezawa K, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06040-x
NR 41
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 7
PY 2023
VL 4
AR 1210303
DI 10.3389/frvir.2023.1210303
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Y4JF8
UT WOS:001104934900001
OA gold
DA 2024-07-18
ER

PT J
AU Li, JJ
   Wider, W
   Ochiai, Y
   Fauzi, MA
AF Li, Jingjing
   Wider, Walton
   Ochiai, Yoichi
   Fauzi, Muhammad Ashraf
TI A bibliometric analysis of immersive technology in museum exhibitions:
   exploring user experience
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive technology; virtual reality (VR); augmented reality (AR);
   cultural heritage; museum exhibitions; user experience; bibliometric
   analysis; Web of Science
ID VIRTUAL-REALITY TECHNOLOGY; MOBILE AUGMENTED REALITY; CULTURAL-HERITAGE;
   MIXED REALITY; DESIGN; ACCEPTANCE; VISIT; ART
AB Introduction: This study aims to comprehensively understand the existing literature on immersive technology in museum exhibitions, focusing on virtual reality (VR), augmented reality (AR), and the visitor experience. The research utilizes a bibliometric approach by examining a dataset of 722 articles with two main research objectives. Firstly, it seeks to analyze current trends in immersive technology literature, specifically emphasizing VR and the user experience in museum exhibitions through co-citation analysis. Secondly, it aims to identify emerging research trends using co-word analysis.Methods: The study employs a bibliometric approach, specifically co-citation and co-word analysis, to investigate trends and forecast emerging areas in the field, particularly the role of VR in the museum context.Results: The analysis reveals the presence of five interconnected thematic clusters in the literature. These clusters include (1) VR and AR-enhanced heritage tourism, (2) VR and AR-enabled virtual museums, (3) interactive digital art education in immersive environments, (4) immersive storytelling in virtual heritage spaces, and (5) mobile AR heritage revival.Discussion: The article highlights influential works within these areas, showcasing the historical evolution of the field and the current emphasis on utilizing VR to create immersive, educational, and engaging experiences for museum visitors. The findings indicate that research on VR applications for museum exhibitions has predominantly focused on profound game-driven experiences and interactive 3D heritage, resulting in improved visitor engagement and access to cultural content. The adoption of VR technology holds the potential to revolutionize user experiences within the cultural heritage sector and reshape the overall landscape of museums and exhibitions. By presenting these research trends, this study contributes to a deeper understanding of the vital role of VR in enhancing visitor experiences in museum settings. Furthermore, it paves the way for further exploration and innovation in immersive technology.
C1 [Li, Jingjing] Univ Tsukuba, Grad Sch Comprehens Human Sci, Tsukuba, Japan.
   [Li, Jingjing; Ochiai, Yoichi] Univ Tsukuba, Inst Lib Informat & Media Sci, Tsukuba, Japan.
   [Li, Jingjing; Ochiai, Yoichi] Univ Tsukuba, R&D Ctr Digital Nat, Tsukuba, Japan.
   [Wider, Walton] INTI Int Univ, Fac Business & Commun, Nilai, Negeri Sembilan, Malaysia.
   [Fauzi, Muhammad Ashraf] Univ Malaysia Pahang, Fac Ind Management, Gambang, Malaysia.
C3 University of Tsukuba; University of Tsukuba; University of Tsukuba;
   INTI International University; Universiti Malaysia Pahang Al-Sultan
   Abdullah (UMPSA)
RP Ochiai, Y (corresponding author), Univ Tsukuba, Inst Lib Informat & Media Sci, Tsukuba, Japan.; Ochiai, Y (corresponding author), Univ Tsukuba, R&D Ctr Digital Nat, Tsukuba, Japan.; Wider, W (corresponding author), INTI Int Univ, Fac Business & Commun, Nilai, Negeri Sembilan, Malaysia.
EM walton.wider@newinti.edu.my; wizard@slis.tsukuba.ac.jp
RI Wider, Walton/AAD-7072-2022; Yang, Li/JMP-4403-2023; Fauzi, Muhammad
   Ashraf/D-3663-2019
OI Wider, Walton/0000-0002-0369-4082; Fauzi, Muhammad
   Ashraf/0000-0003-2137-4602; Jingjing, Li/0000-0002-6524-3105
FU This research was supported by the Japan Science and Technology Agency,
   SPRING, Grant number JPMJSP2124, and Pixie Dust Technologies.
   [JPMJSP2124]; Japan Science and Technology Agency, SPRING; Pixie Dust
   Technologies
FX The authors acknowledge the contributions of their colleagues from other
   fields who shared their knowledge about how immersive technology (such
   as VR and AR) can be used in various fields.r This research was
   supported by the Japan Science and Technology Agency, SPRING, Grant
   number JPMJSP2124, and Pixie Dust Technologies.
CR Anastasovitis E., 2023, Digit. Appl. Archaeol. Cult. Herit, V28, pe00259, DOI [10.1016/j.daach.2023.e00259, DOI 10.1016/J.DAACH.2023.E00259]
   Anderson EF, 2010, VIRTUAL REAL-LONDON, V14, P255, DOI 10.1007/s10055-010-0177-3
   Arayaphan Watsaporn, 2022, Digital Applications in Archaeology and Cultural Heritage, DOI 10.1016/j.daach.2022.e00233
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma R., 2015, Location-Based mixed and augmented reality storytelling
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barbieri L, 2018, INT J INTERACT DES M, V12, P561, DOI 10.1007/s12008-017-0414-z
   Bec A, 2021, TOURISM MANAGE, V83, DOI 10.1016/j.tourman.2020.104256
   Bec A, 2019, TOURISM MANAGE, V72, P117, DOI 10.1016/j.tourman.2018.10.033
   Bekele MK, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00091
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Birkle C, 2020, QUANT SCI STUD, V1, P363, DOI 10.1162/qss_a_00018
   Boboc RG, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199859
   Borda A., 2017, P EVA BCS LOND UK JU
   Bozzelli Guido, 2019, Digital Applications in Archaeology and Cultural Heritage, V15, DOI 10.1016/j.daach.2019.e00124
   Bronk KC, 2023, J POSIT PSYCHOL, V18, P1012, DOI 10.1080/17439760.2023.2168563
   Bruno F, 2010, J CULT HERIT, V11, P42, DOI 10.1016/j.culher.2009.02.006
   Burlingame K, 2022, TOURISM GEOGR, V24, P263, DOI 10.1080/14616688.2019.1696882
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Cecotti H., 2022, Virtual Worlds, V1, P82, DOI [DOI 10.3390/VIRTUALWORLDS1010006, 10.3390/virtualworlds1010006]
   Cesário V, 2023, MUS MANAGE CURATOR, DOI 10.1080/09647775.2023.2209896
   Chang CY, 2023, VIRTUAL REAL-LONDON, V27, P2461, DOI 10.1007/s10055-023-00817-9
   Chang KE, 2014, COMPUT EDUC, V71, P185, DOI 10.1016/j.compedu.2013.09.022
   Chang YL, 2015, EDUC TECHNOL SOC, V18, P166
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen SX, 2023, J HOSP TOUR MANAG, V54, P128, DOI 10.1016/j.jhtm.2022.12.008
   Chiu MC, 2023, BRIT J EDUC TECHNOL, V54, P603, DOI 10.1111/bjet.13265
   Chung N, 2018, J TRAVEL RES, V57, P627, DOI 10.1177/0047287517708255
   Chung N, 2015, COMPUT HUM BEHAV, V50, P588, DOI 10.1016/j.chb.2015.02.068
   Craig A.B., 2013, UNDERSTANDING AUGMEN, DOI DOI 10.1016/B978-0-240-82408-6.00001-1
   Cranmer EE, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103551
   Dahroug A, 2021, J INF SCI, V47, P82, DOI 10.1177/0165551519871823
   Dal Falco F, 2017, DES J, V20, pS3975, DOI 10.1080/14606925.2017.1352900
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   De Luca V, 2022, INFORMATION, V13, DOI 10.3390/info13070339
   Dieck MCT, 2018, CURR ISSUES TOUR, V21, P2014, DOI 10.1080/13683500.2016.1224818
   Dieck MCT, 2017, J DESTIN MARK MANAGE, V6, P110, DOI 10.1016/j.jdmm.2017.03.002
   Dieck MCT, 2018, CURR ISSUES TOUR, V21, P154, DOI 10.1080/13683500.2015.1070801
   Dogan E, 2020, ADV HOSP TOUR RES-AH, V8, P76, DOI 10.30519/ahtr.630783
   Dwivedi YK, 2022, INT J INFORM MANAGE, V66, DOI 10.1016/j.ijinfomgt.2022.102542
   Errichiello L, 2019, INT J TOUR RES, V21, P590, DOI 10.1002/jtr.2283
   Eswaran M, 2022, J MANUF SYST, V65, P260, DOI 10.1016/j.jmsy.2022.09.016
   Evangelidis K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113826
   Fan XJ, 2022, TOURISM MANAGE, V91, DOI 10.1016/j.tourman.2022.104534
   Farooq B, 2018, TRANSPORT RES REC, V2672, P35, DOI 10.1177/0361198118776810
   Fenu C, 2018, INT J HUM-COMPUT ST, V114, P20, DOI 10.1016/j.ijhcs.2018.01.009
   Ferdani D, 2020, J CULT HERIT, V43, P129, DOI 10.1016/j.culher.2019.12.004
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Geroimenko V., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P445, DOI 10.1109/IV.2012.77
   Hammady R, 2020, MULTIMED TOOLS APPL, V79, P3465, DOI 10.1007/s11042-019-08026-w
   Han D., 2019, Augmented Reality and Virtual Reality - The Power of AR and VR for Business, P113, DOI [DOI 10.1007/978-3-030-06246-09, 10.1007/978-3-030-06246-0_9, DOI 10.1007/978-3-030-06246-0_9]
   Haugstvedt AC, 2012, INT SYM MIX AUGMENT, P247, DOI 10.1109/ISMAR.2012.6402563
   HAWKEY R., 2004, Learning with Digital Technologies in Museums, Science Centers and Galleries
   He ZY, 2018, TOURISM MANAGE, V68, P127, DOI 10.1016/j.tourman.2018.03.003
   Jung T, 2015, TOURISM MANAGE, V49, P75, DOI 10.1016/j.tourman.2015.02.013
   Jung Timothy., 2016, INFORM COMMUNICATION, P621, DOI [DOI 10.1007/978-3-319-28231-2_45, 10.1007/978-3-319-28231-245, DOI 10.1007/978-3-319-28231-245]
   Jung TH, 2018, INT J CONTEMP HOSP M, V30, P1621, DOI [10.1108/ijchm-02-2017-0084, 10.1108/IJCHM-02-2017-0084]
   Jung TH, 2017, J PLACE MANAG DEV, V10, P140, DOI 10.1108/JPMD-07-2016-0045
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   Kennedy AAU, 2021, INT J SCI EDUC PART, V11, P242, DOI 10.1080/21548455.2021.1946619
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kersten TP, 2017, INT ARCH PHOTOGRAMM, V42-2, P361, DOI 10.5194/isprs-archives-XLII-2-W3-361-2017
   Khan MA, 2021, J REAL-TIME IMAGE PR, V18, P321, DOI 10.1007/s11554-020-01038-y
   Kidd J., 2014, Museums in the New Mediascape: Transmedia, Participation, Ethics
   Kim H, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202005692
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim Y, 2022, INT J HUM-COMPUT INT, V38, P371, DOI 10.1080/10447318.2021.1944534
   Kiourt C, 2016, J CULT HERIT, V22, P984, DOI 10.1016/j.culher.2016.06.007
   Konstantakis M, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3354002
   Kozinets RV, 2023, J SERV MANAGE, V34, P100, DOI 10.1108/JOSM-12-2021-0481
   Kulakli A, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15020081
   Kwok AOJ, 2021, CURR ISSUES TOUR, V24, P1935, DOI 10.1080/13683500.2020.1798896
   Lee HG, 2013, NEW MEDIA SOC, V15, P930, DOI 10.1177/1461444812464033
   Lee H, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103229
   Leow FT, 2021, MUS MANAGE CURATOR, V36, P342, DOI 10.1080/09647775.2021.1914136
   Leung R., 2022, HDB E TOURISM, P1, DOI [10.1007/978-3-030-05324-6_2-1, DOI 10.1007/978-3-030-05324-6_2-1]
   Lion-Bailey C., 2023, Immersive education: Designing for learning, P123
   Lisney E, 2013, CURATOR, V56, P353, DOI 10.1111/cura.12034
   Longo M.C., 2023, Sinergie Ital. J. Manag, V41, P147, DOI [10.7433/s120.2023.08, DOI 10.7433/S120.2023.08]
   Lu JY, 2022, CURR ISSUES TOUR, V25, P441, DOI 10.1080/13683500.2021.1959526
   Lu SJ, 2015, ENVIRON EDUC RES, V21, P525, DOI 10.1080/13504622.2014.911247
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Man SH, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.1.011208
   Marchal, 2008, P 3 INT C DIG INT ME
   Margetis G, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010338
   Marques D, 2018, CURATOR, V61, P541, DOI 10.1111/cura.12279
   Martín-Martín A, 2021, SCIENTOMETRICS, V126, P871, DOI 10.1007/s11192-020-03690-4
   McGivern H., 2019, Art Newsp, P532
   Meinecke C, 2022, ACM J COMPUT CULT HE, V15, DOI 10.1145/3527619
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Miyashita T, 2008, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2008.4637334
   Mortara M, 2014, J CULT HERIT, V15, P318, DOI 10.1016/j.culher.2013.04.004
   Okanovic V, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031241
   Olaz X, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6070059
   Panhale T, 2023, J MARKET MANAG-UK, V39, P470, DOI 10.1080/0267257X.2022.2120061
   Paul Christiane., 2023, Digital art
   Pears M, 2020, SCOT MED J, V65, P112, DOI 10.1177/0036933020956317
   Pedersen I, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3051480
   Pellas N, 2021, VIRTUAL REAL-LONDON, V25, P835, DOI 10.1007/s10055-020-00489-9
   Pence H.E., 2010, Reference Librarian, V52, P136, DOI DOI 10.1080/02763877.2011.528281
   Pietroni E., 2018, Stud. Digit. Herit., V2, P13, DOI [10.14434/sdh.v2i1.24634, DOI 10.14434/SDH.V2I1.24634]
   Puig A, 2020, VIRTUAL REAL-LONDON, V24, P343, DOI 10.1007/s10055-019-00391-z
   Pursey T, 2018, SENSES SOC, V13, P354, DOI 10.1080/17458927.2018.1516026
   Ramm R, 2022, J CULT HERIT, V53, P165, DOI 10.1016/j.culher.2021.11.006
   Ranjan A., 2023, Embracing Business Sustainability Through Innovation and Creativity in the Service Sector, P14
   Rauschnabel PA, 2022, J BUS RES, V142, P1140, DOI 10.1016/j.jbusres.2021.12.084
   Rogage K, 2021, INT J HUM-COMPUT INT, V37, P1028, DOI 10.1080/10447318.2020.1865004
   Rogers Y., 2023, Interaction design: Beyond human-computer interaction
   Sanabria JC, 2017, EURASIA J MATH SCI T, V13, P487, DOI 10.12973/eurasia.2017.00627a
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schnack A, 2019, FOOD RES INT, V117, P40, DOI 10.1016/j.foodres.2018.01.028
   Schofield G, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P805, DOI 10.1145/3196709.3196714
   Sharma D, 2023, RESULTS CONTROL OPTI, V10, DOI 10.1016/j.rico.2023.100204
   Shehade M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10114031
   Shiau WL, 2023, INFORM MANAGE-AMSTER, V60, DOI 10.1016/j.im.2023.103774
   Snoswell AaronJ., 2019, JMIR BIOMEDICAL ENG, V4, DOI DOI 10.2196/15025
   Stylianidis E, 2022, HERITAGE-BASEL, V5, P2818, DOI 10.3390/heritage5040146
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Sylaiou S, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P595, DOI 10.1109/IS.2018.8710530
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Sylaiou Stella., 2020, Visual Computing for Cultural Heritage, P369, DOI DOI 10.1007/978-3-030-37191-3_19
   Sylaiou S, 2009, J CULT HERIT, V10, P520, DOI 10.1016/j.culher.2009.03.003
   Trunfio M, 2022, INFORM MANAGE-AMSTER, V59, DOI 10.1016/j.im.2022.103698
   Trunfio M, 2022, J HERIT TOUR, V17, P1, DOI 10.1080/1743873X.2020.1850742
   Tsepapadakis M, 2023, PERVASIVE MOB COMPUT, V92, DOI 10.1016/j.pmcj.2023.101797
   Tussyadiah IP, 2018, J TRAVEL RES, V57, P597, DOI 10.1177/0047287517709090
   Tussyadiah IP, 2018, TOURISM MANAGE, V66, P140, DOI 10.1016/j.tourman.2017.12.003
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Vas R., 2018, Handbook of research on technological developments for cultural heritage and etourism applications, P30
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Verhulst I, 2021, COMPUT HUM BEHAV, V125, DOI 10.1016/j.chb.2021.106951
   Verma S, 2023, LIBR HI TECH, DOI 10.1108/LHT-10-2022-0477
   Waern A., 2022, Hybrid museum experiences: Theory and design
   Yan L, 2023, SAGE OPEN, V13, DOI 10.1177/21582440231158562
   Zhao LM, 2023, J BUS ETHICS, V182, P135, DOI 10.1007/s10551-022-05035-y
   Zhu R, 2023, CURR ISSUES TOUR, V26, P617, DOI 10.1080/13683500.2022.2033181
   Zidianakis E, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030363
NR 140
TC 5
Z9 5
U1 67
U2 113
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 12
PY 2023
VL 4
AR 1240562
DI 10.3389/frvir.2023.1240562
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA S7BY3
UT WOS:001072696100001
OA gold
DA 2024-07-18
ER

PT J
AU Chard, I
   Van Zalk, N
   Picinali, L
AF Chard, Ian
   Van Zalk, Nejra
   Picinali, Lorenzo
TI Virtual reality exposure therapy for reducing social anxiety associated
   with stuttering: the role of outcome expectancy, therapeutic alliance,
   presence and social presence
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; exposure therapy; social anxiety; stuttering; outcome
   expectancy; therapeutic alliance; presence
ID COGNITIVE-BEHAVIOR THERAPY; WORKING ALLIANCE; DISORDER; FEAR;
   VALIDATION; PHOBIA; METAANALYSIS; CLIENTS; SCALE
AB Introduction: Although several trials have demonstrated the effectiveness of Virtual Reality Exposure Therapy (VRET) for reducing social anxiety, there is little understanding about the factors that lead to symptom reduction across different treatment designs. Such factors may include outcome expectancy, therapeutic alliance, presence (perception of being in the virtual environment) and social presence (perception of interacting with others). We report on findings from a pilot trial of VRET targeting social anxiety in people who stutter, and examine the association of these four factors with treatment outcome.Methods: People who stutter reporting heightened social anxiety (n = 22) took part in the trial after being recruited via online adverts. Remotely delivered VRET was administered to participants in three sessions across three weeks. Each session targeted both performative and interactive anxiety. A virtual therapist helped participants to engage with treatment strategies, whilst also guiding them through exercises.Results: Findings showed that presence and social presence were both negatively related to changes in fear of negative evaluation between pre- and post-treatment. However, presence, outcome expectancy and therapeutic alliance were positively related to changes in social anxiety symptoms. Furthermore, outcome expectancy and therapeutic alliance were quadratically related to fear of negative evaluation change. Nevertheless, the effect of presence on social anxiety, and the effects of presence and therapeutic alliance on fear of negative evaluation must be interpreted with caution as these were not large enough to reach sufficient statistical power. Therapeutic alliance did not mediate the relationship between outcome expectancy and treatment outcome.Discussion: These findings suggest that the current VRET protocol affected social anxiety and fear of negative evaluation differently. We discuss how presence may underlie these mixed associations. We also suggest that the unexpected positive effects on social anxiety symptoms may have resulted from insufficient treatment strategies which inadvertently encouraged maladaptive learning.
C1 [Chard, Ian; Van Zalk, Nejra] Imperial Coll London, Dyson Sch Design Engn, Design Psychol Lab, London, England.
   [Picinali, Lorenzo] Imperial Coll London, Dyson Sch Design Engn, Audio Experience Design Grp, London, England.
C3 Imperial College London; Imperial College London
RP Chard, I (corresponding author), Imperial Coll London, Dyson Sch Design Engn, Design Psychol Lab, London, England.
EM i.chard18@imperial.ac.uk
OI Chard, Ian/0000-0003-0539-6289
FU UK Research and Innovation; Imperial College London [EP/R513052/1]
FX The research was funded by a training grant from UK Research and
   Innovation and Imperial College London (No. EP/R513052/1).
CR American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Anderson PL, 2013, J CONSULT CLIN PSYCH, V81, P751, DOI 10.1037/a0033559
   [Anonymous], 1995, SOCIAL PHOBIA DIAGNO
   Asher M, 2017, CLIN PSYCHOL REV, V56, P1, DOI 10.1016/j.cpr.2017.05.004
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Bloodstein O., 2008, A Handbook on Stuttering, V6th Edn
   BORKOVEC TD, 1972, J BEHAV THER EXP PSY, V3, P257, DOI 10.1016/0005-7916(72)90045-6
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Bouchard S, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P81, DOI 10.5772/46417
   Brundage SB, 2006, J FLUENCY DISORD, V31, P325, DOI 10.1016/j.jfludis.2006.08.003
   Chard I., 2022, VIRTUAL REALITY EXPO
   Chard I, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1061323
   Chard I, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.842460
   Chesham RK, 2018, BEHAV CHANGE, V35, P152, DOI 10.1017/bec.2018.15
   Constantino MJ, 2011, J CLIN PSYCHOL, V67, P184, DOI 10.1002/jclp.20754
   Craig A, 2002, J SPEECH LANG HEAR R, V45, P1097, DOI 10.1044/1092-4388(2002/088)
   Craig A, 2014, J FLUENCY DISORD, V40, P35, DOI 10.1016/j.jfludis.2014.01.001
   Craske MG, 2008, BEHAV RES THER, V46, P5, DOI 10.1016/j.brat.2007.10.003
   Craske MG, 2014, BEHAV RES THER, V58, P10, DOI 10.1016/j.brat.2014.04.006
   Devilly GJ, 2000, J BEHAV THER EXP PSY, V31, P73, DOI 10.1016/S0005-7916(00)00012-4
   Draheim AA, 2019, COGN BEH THER, V12, DOI 10.1017/S1754470X19000266
   Ezrati-Vinacour R, 2004, J FLUENCY DISORD, V29, P135, DOI 10.1016/j.jfludis.2004.02.003
   Felnhofer A, 2014, CYBERPSYCH BEH SOC N, V17, P310, DOI 10.1089/cyber.2013.0472
   FOA EB, 1986, PSYCHOL BULL, V99, P20, DOI 10.1037/0033-2909.99.1.20
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Greenberg RP, 2006, CLIN PSYCHOL REV, V26, P657, DOI 10.1016/j.cpr.2005.03.002
   Harms C., 2004, 7 ANN INT WORKSH PRE
   Haug T, 2016, BEHAV RES THER, V77, P40, DOI 10.1016/j.brat.2015.12.004
   Hayes A.F., 2022, METHODOLOGY SOCIAL S, V3rd ed.
   Hayes Sarah A., 2007, Cognitive Behaviour Therapy, V36, P34, DOI 10.1080/16506070600947624
   Horigome T, 2020, PSYCHOL MED, V50, P2487, DOI 10.1017/S0033291720003785
   HORVATH AO, 1989, J COUNS PSYCHOL, V36, P223, DOI 10.1037/0022-0167.36.2.223
   Iverach L, 2017, AM J SPEECH-LANG PAT, V26, P540, DOI 10.1044/2016_AJSLP-16-0033
   Iverach L, 2014, J FLUENCY DISORD, V40, P69, DOI 10.1016/j.jfludis.2013.08.003
   Jakobsen JC, 2017, BMC MED RES METHODOL, V17, DOI 10.1186/s12874-017-0442-1
   Jazaieri H, 2018, MINDFULNESS, V9, P1381, DOI 10.1007/s12671-017-0877-9
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Kampmann IL, 2016, J ANXIETY DISORD, V42, P71, DOI 10.1016/j.janxdis.2016.06.007
   Kampmann IL, 2016, BEHAV RES THER, V77, P147, DOI 10.1016/j.brat.2015.12.016
   Kivity Y, 2021, PSYCHOTHER RES, V31, P589, DOI 10.1080/10503307.2020.1836423
   Klinger E, 2005, CYBERPSYCHOL BEHAV, V8, P76, DOI 10.1089/cpb.2005.8.76
   LEARY MR, 1983, PERS SOC PSYCHOL B, V9, P371, DOI 10.1177/0146167283093007
   Lindsay A, 2017, J FLUENCY DISORD, V52, P1, DOI 10.1016/j.jfludis.2017.01.003
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Luborsky L., 1976, SUCCESSFUL PSYCHOTHE, P92
   Mattes A, 2020, BMC MED RES METHODOL, V20, DOI 10.1186/s12874-020-01176-8
   Mattick RP, 1998, BEHAV RES THER, V36, P455, DOI 10.1016/S0005-7967(97)10031-6
   Miloff A, 2020, J MED INTERNET RES, V22, DOI 10.2196/16660
   Miragall M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01531
   Montgomery P, 2018, TRIALS, V19, DOI 10.1186/s13063-018-2733-1
   Morina N, 2014, PEERJ, V2, DOI 10.7717/peerj.337
   Mörtberg E, 2014, PSYCHIAT RES, V220, P716, DOI 10.1016/j.psychres.2014.07.004
   Ngai I, 2015, BEHAV COGN PSYCHOTH, V43, P167, DOI 10.1017/S135246581300088X
   Peperkorn HM, 2015, COMPUT HUM BEHAV, V48, P542, DOI 10.1016/j.chb.2015.02.028
   Pfaller M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.741138
   Price M, 2011, J ANXIETY DISORD, V25, P763, DOI 10.1016/j.janxdis.2011.03.004
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Rapee RM, 1997, BEHAV RES THER, V35, P741, DOI 10.1016/S0005-7967(97)00022-3
   Reeves R, 2021, J ANXIETY DISORD, V83, DOI 10.1016/j.janxdis.2021.102451
   Robillard G, 2010, STUD HEALTH TECHNOL, V154, P57, DOI 10.3233/978-1-60750-561-7-57
   Sauer-Zavala S, 2018, COGNITIVE THER RES, V42, P135, DOI 10.1007/s10608-017-9855-8
   Scheurich JA, 2019, J FLUENCY DISORD, V59, P21, DOI 10.1016/j.jfludis.2018.12.001
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Selya AS, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00111
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sonsterud H, 2019, INT J LANG COMM DIS, V54, P606, DOI 10.1111/1460-6984.12465
   Stein MB, 2008, LANCET, V371, P1115, DOI 10.1016/S0140-6736(08)60488-2
   Strojny PM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01252
   Thompson T, 2019, PSYCHIAT RES, V273, P725, DOI 10.1016/j.psychres.2019.01.103
   Vîsla A, 2018, PSYCHOTHER RES, V28, P446, DOI 10.1080/10503307.2016.1218089
   Walkom G, 2016, 2016 9TH INTERNATIONAL CONFERENCE ON INTERACTIVE TECHNOLOGIES AND GAMES (ITAG), P36, DOI 10.1109/iTAG.2016.13
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Weeks JW, 2005, PSYCHOL ASSESSMENT, V17, P179, DOI 10.1037/1040-3590.17.2.179
   WHO, 2022, World Mental Health Report: Transforming Mental Health for All
   Wiederhold B. K., 2005, Virtual reality therapy for anxiety disorders: Advances in evaluation and treatment, P77, DOI [10.1037/10858-006, DOI 10.1037/10858-006]
   Woody SR, 2002, BEHAV THER, V33, P5, DOI 10.1016/S0005-7894(02)80003-X
   Zainal NH, 2021, BEHAV RES THER, V147, DOI 10.1016/j.brat.2021.103984
NR 80
TC 0
Z9 0
U1 12
U2 21
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 6
PY 2023
VL 4
AR 1159549
DI 10.3389/frvir.2023.1159549
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA R9HJ2
UT WOS:001067386700001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Rettinger, M
   Rigoll, G
AF Rettinger, Maximilian
   Rigoll, Gerhard
TI Touching the future of training: investigating tangible interaction in
   virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; tangible free hand interaction; training; user studies;
   explosive ordnance disposal training; EOD; collaborative training;
   interaction methods
AB Virtual reality offers exciting new opportunities for training. This inspires more and more training fields to move from the real world to virtual reality, but some modalities are lost in this transition. In the real world, participants can physically interact with the training material; virtual reality offers several interaction possibilities, but do these affect the training's success, and if yes, how? To find out how interaction methods influence the learning outcome, we evaluate the following four methods based on ordnance disposal training for civilians: 1) Real-World, 2) Controller-VR, 3) Free-Hand-VR, and 4) Tangible-VR in a between-subjects experiment (n = 100). We show that the Free-Hand-VR method lacks haptic realism and has the worst training outcome. Training with haptic feedback, e.g., Controller-VR, Tangible-VR, and Real-World, lead to a better overall learning effect and matches the participant's self-assessment. Overall, the results indicate that free-hand interaction is improved by the extension of a tracked tangible object, but the controller-based interaction is most suitable for VR training.
C1 [Rettinger, Maximilian; Rigoll, Gerhard] Tech Univ Munich, Chair Human Machine Commun, TUM Sch Computat Informat & Technol, Munich, Germany.
C3 Technical University of Munich
RP Rettinger, M (corresponding author), Tech Univ Munich, Chair Human Machine Commun, TUM Sch Computat Informat & Technol, Munich, Germany.
EM maximilian.rettinger@tum.de
OI Rettinger, Maximilian/0009-0005-8170-7343
CR Allgaier M, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105429
   Bajrami F., 2022, WASHINGTON TIMES
   Ban Y., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P211, DOI 10.1109/HAPTIC.2012.6183793
   Bergström J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1175, DOI 10.1145/3332165.3347939
   Bozgeyikli L, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P812, DOI 10.1109/VR51125.2022.00103
   Caggianese Giuseppe, 2019, Intelligent Interactive Multimedia Systems and Services. Proceedings of 2018 Conference. Smart Innovation, Systems and Technologies (SIST 98), P24, DOI 10.1007/978-3-319-92231-7_3
   Chung J. C., 1996, GRAPHICAL SYSTEMS EX
   Clifford RMS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P181, DOI [10.1109/VR.2019.8797889, 10.1109/vr.2019.8797889]
   Cuendet Sebastien, 2012, NORDICHI 2012, P99, DOI [10.1145/2399016.2399032, DOI 10.1145/2399016.2399032]
   Englmeier D., 2020, TANGIBLESPHERE INTER
   Franzluebbers A, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P16, DOI 10.1145/3267782.3267790
   Funk M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P934, DOI 10.1145/2971648.2971706
   Gisler J, 2021, 2021 7TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN), P244, DOI [10.23919/ILRN52045.2021.9459332, 10.23919/iLRN52045.2021.9459332]
   Gusai E, 2017, LECT NOTES COMPUT SC, V10590, P290, DOI 10.1007/978-3-319-70742-6_27
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Insko B.E., 2001, Passive Haptics Significantly Enhances Virtual Environ- ments
   Khamvongsa C, 2009, CRIT ASIAN STUD, V41, P281, DOI 10.1080/14672710902809401
   Kim M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051141
   Kovacs Robert, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1046, DOI 10.1145/3379337.3415854
   Kwon E, 2009, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2009.5336463
   Masurovsky A, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040091
   Mazalek A., 2009, P SANDB 2009 ACM SIG, V1, P161, DOI DOI 10.1145/1581073.1581098
   Muender T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300903
   Rettinger M, 2022, INT SYM MIX AUGMENT, P695, DOI 10.1109/ISMAR55827.2022.00087
   Rettinger M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P77, DOI 10.1109/VR51125.2022.00025
   Rettinger M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P414, DOI 10.1109/VRW55335.2022.00092
   Rettinger M, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451766
   Salthouse TA, 1998, DEV PSYCHOL, V34, P851, DOI 10.1037/0012-1649.34.5.851
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Strandholt PL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376303
   Strasnick E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174218
   SWELLER J, 1994, COGNITION INSTRUCT, V12, P185, DOI 10.1207/s1532690xci1203_1
   Sweller J, 2010, EDUC PSYCHOL REV, V22, P123, DOI 10.1007/s10648-010-9128-5
   Tan A., 2014, J EXPLOSIVE REMNANTS, P39
   Tan A. D., 2020, J CONVENTIONAL WEAPO, V23, P4
   Tocu A., 2020, P 12 INT C ED NEW LE, P3084, DOI [10.21125/edulearn.2020.0905, DOI 10.21125/EDULEARN.2020.0905]
   Ulmer J, 2020, PROCEEDINGS OF THE 2020 19TH INTERNATIONAL CONFERENCE ON MECHATRONICS - MECHATRONIKA (ME), P186, DOI 10.1109/me49197.2020.9286661
   Wang P, 2020, INT J HUM-COMPUT INT, V36, P1242, DOI 10.1080/10447318.2020.1732140
   Yang J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P889, DOI 10.1145/3242587.3242643
   Yu K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P392, DOI 10.1109/VR50410.2021.00062
   Zhao Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173690
NR 43
TC 0
Z9 0
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 4
PY 2023
VL 4
AR 1187883
DI 10.3389/frvir.2023.1187883
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA P4SM7
UT WOS:001050561100001
OA gold
DA 2024-07-18
ER

PT J
AU Badr, AS
   De Amicis, R
AF Shahbaz Badr, Arash
   De Amicis, Raffaele
TI An empirical evaluation of enhanced teleportation for navigating large
   urban immersive virtual environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Metaverse; urban; smart cities; teleportation; navigation; 3D
   interactions; virtual reality
ID REALITY; LOCOMOTION; METAVERSE; WALKING; CITIES; FORM
AB Navigation is the most prevalent interaction in large urban virtual environments (VEs). Any Metaverse application that foresees navigating or exploring virtual cities requires an effective and efficient navigation technique. These environments, however, have distinct characteristics that make the navigation more challenging and the design of the interactions more critical. We have conducted an empirical study to assess how enhancing the teleportation technique with additional capabilities affects the performance of navigating large urban VEs. For this purpose, three interactions have been developed that extend the conventional point-and-click teleportation. The first one is named Mini-Map and provides a top-down view of the user's surroundings. Portal Preview provides a preview of the selected target location and allows users to choose their desired orientation at that location. The last technique, called X-Ray Vision, makes the buildings around the user translucent and allows teleporting to locations that would otherwise be obscured. A within-subject controlled lab study with twenty five participants has been conducted, where each extension is evaluated individually as well as in combination with others. Our results show that extending the teleportation can significantly improve its performance when navigating large urban VEs. Overall, the X-Ray Vision was the most successful extension with respect to both task metrics and usability measures. Mini-Map was able to improve some of the task metrics, but did not have a significant effect on most self-reported measures. Portal Preview was the least effective extension, however, multiple participants liked the fact that they could define their desired orientation with the controller. Combining all interactions together performed well with respect to the task metrics, but this option was not favored by the participants. Extending the teleportation with X-Ray Vision and Mini-Map was by far the most favored option.
C1 [Shahbaz Badr, Arash; De Amicis, Raffaele] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
C3 Oregon State University
RP Badr, AS (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
EM shahbaar@oregonstate.edu
CR Adhikari A, 2023, IEEE T VIS COMPUT GR, V29, P5265, DOI 10.1109/TVCG.2022.3207157
   Allam Z, 2022, SMART CITIES-BASEL, V5, P771, DOI 10.3390/smartcities5030040
   Atkins A, 2021, ADJUNCT PROCEEDINGS OF THE 34TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2021, P51, DOI 10.1145/3474349.3480227
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bhandari J., 2018, P GRAPH INTERFACE, V6, P230, DOI [10.20380/GI2018.22, DOI 10.20380/GI2018.22]
   Bibri SE, 2022, SMART CITIES-BASEL, V5, P715, DOI 10.3390/smartcities5020037
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Boletsis C, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6090072
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Caputo A., 2019, GCH 2019 EUROGRAPHIC, V8, P1348, DOI [10.2312/GCH.20191348, DOI 10.2312/GCH.20191348]
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/ICSENS.2015.7370446, 10.1109/GLOCOM.2015.7417476]
   Chen SY, 2022, IEEE T VIS COMPUT GR, V28, P4685, DOI 10.1109/TVCG.2021.3099012
   Chittaro Luca., 2001, Proceedings of the ACM symposium on Virtual reality software and technology, P159
   Cmentowski S, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P287, DOI 10.1145/3311350.3347183
   Çöltekin A, 2019, INT J DIGIT EARTH, V12, P119, DOI 10.1080/17538947.2018.1560986
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dalton RC, 2003, ENVIRON BEHAV, V35, P107, DOI 10.1177/0013916502238867
   Danyluk K, 2019, LECT NOTES COMPUT SC, V11542, P203, DOI 10.1007/978-3-030-22514-8_17
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Darken RP, 1999, P IEEE VIRT REAL ANN, P133, DOI 10.1109/VR.1999.756944
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Elvezio C, 2017, P IEEE VIRT REAL ANN, P475, DOI 10.1109/VR.2017.7892386
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   Funk M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300377
   Ghani I., 2018, PLAN MALAYS J, V16, P408, DOI [10.21837/pmjournal.v16.i5.408, DOI 10.21837/PMJOURNAL.V16.I5.408]
   Giannopoulos I., 2015, P 17 INT C HUMAN COM, P337, DOI [10.1145/2785830.2785873, DOI 10.1145/2785830.2785873]
   Griffin NN, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364243
   Halik L, 2021, INT J DIGIT EARTH, DOI 10.1080/17538947.2021.1984595
   Huynh-The T, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105581
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Iwata H, 1999, P IEEE VIRT REAL ANN, P286, DOI 10.1109/VR.1999.756964
   Kemec A., 2022, From Reality to Virtuality: Re-discussing Cities with the Concept of the Metaverse, V4, P12, DOI DOI 10.34104/IJMA.022.00120020
   Kraus M, 2020, INT SYM MIX AUGMENT, P227, DOI 10.1109/ISMAR50242.2020.00046
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Mahalil I, 2019, 2019 IEEE CONFERENCE ON GRAPHICS AND MEDIA (GAME), P1, DOI [10.1109/GAME47560.2019.8980987, 10.1109/game47560.2019.8980987]
   McCullough M, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P107, DOI 10.1145/2804408.2804416
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Ning Huansheng., A Survey on Metaverse: The State-of-the-Art, Technologies, Applications, and Challenges, P2021, DOI DOI 10.48550/ARXIV.2111.09673
   Nyström M, 2013, BEHAV RES METHODS, V45, P272, DOI 10.3758/s13428-012-0247-4
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   Razzaque Sharif, 2001, EUROGRAPHICS 2001 SH
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Stähli L, 2021, ENVIRON PLAN B-URBAN, V48, P1728, DOI 10.1177/2399808320949538
   Tseng CM, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501890
   Turner A, 2009, LECT NOTES COMPUT SC, V5756, P489, DOI 10.1007/978-3-642-03832-7_30
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Wolf D, 2021, Arxiv, DOI arXiv:2106.04257
   Zagata K, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020096
   Zhang Chenkai, 2021, OzCHI '21: 33rd Australian Conference on Human-Computer Interaction, P252, DOI 10.1145/3520495.3520528
NR 56
TC 4
Z9 4
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 10
PY 2023
VL 3
AR 1075811
DI 10.3389/frvir.2022.1075811
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XP7
UT WOS:001023314300001
OA gold
DA 2024-07-18
ER

PT J
AU Gasparello, PS
   Facenza, G
   Vanni, F
   Nicoletti, A
   Piazza, F
   Monica, L
   Anastasi, S
   Cristaudo, A
   Bergamasco, M
AF Gasparello, Paolo Simone
   Facenza, Gabriele
   Vanni, Federico
   Nicoletti, Alessandro
   Piazza, Fabio
   Monica, Luigi
   Anastasi, Sara
   Cristaudo, Alfonso
   Bergamasco, Massimo
TI Use of mixed reality for the training of operators of mobile elevating
   work platforms with the aim of increasing the level of health and safety
   at work and reducing training costs
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual environments; mixed reality; occupational safety; simulator;
   mobile elevating work platforms; training
ID VIRTUAL-REALITY; ENVIRONMENT
AB The article presents an immersive multisensory simulator developed in a project co-financed by INAIL (the Italian Workers' Compensation Authority) as part of a collaborative research program for the application of innovative technologies and systems to the management of health and safety at work. Specifically, the program provides for the development of simulators for the structuring of skills qualification paths for operators in charge of running and maintaining the most dangerous work equipment. The simulator we present reproduces all the aspects that contribute to a complete driving experience of the simulated machine in an artificial working environment that replicates typical and atypical operations and hazards involved in the use of self-propelled mobile elevating work platforms (MEWPs) with an extendable articulated boom. The simulator has been designed following the analysis of the most critical working routines with aerial work platforms and using physical components of a real MEWP combined with immersive Virtual Reality technologies. The use of Extended Reality technologies to simulate challenging work scenarios makes it possible to train operators by confronting them with very risky situations without any real danger, both in terms of damage to machinery, and above all in terms of user's safety. The presented simulation system has been designed as a high-TRL prototype to demonstrate the feasibility of developing training programs in the context of occupational safety and health, based on a mixed-reality simulator targeting MEWP operators and verifiers.
C1 [Gasparello, Paolo Simone; Facenza, Gabriele; Vanni, Federico; Nicoletti, Alessandro; Piazza, Fabio; Bergamasco, Massimo] St Anna Sch Adv Studies, Inst Mech Intelligence, Pisa, Italy.
   [Monica, Luigi; Anastasi, Sara] Italian Workers Compensat Author INAIL, Dept Technol Innovat & Safety Plants Prod & Anthro, Rome, Italy.
   [Cristaudo, Alfonso] Univ Pisa, Dept Translat Res & New Surg & Med Technol, Pisa, Italy.
C3 Scuola Superiore Sant'Anna; Istituto Nazionale per l'Assicurazione
   Contro gli Infortuni sul Lavoro (INAIL); University of Pisa
RP Gasparello, PS; Vanni, F (corresponding author), St Anna Sch Adv Studies, Inst Mech Intelligence, Pisa, Italy.
EM paolo.gasparello@santannapisa.it; federico.vanni@santannapisa.it
FU INAIL (the Italian Workers' Compensation Authority), BRiC 2019
   collaborative research program [35/1-2019]
FX The work presented in this manuscript is co-funded by INAIL (the Italian
   Workers' Compensation Authority) as part of the BRiC 2019 collaborative
   research program, Project ID 35/1-2019.
CR Bergamasco M., 2012, Skill Training in Multimodal Virtual Environments
   Badia SBI, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111726
   Casini M, 2022, ENERGIES, V15, DOI 10.3390/en15103785
   Cooper N, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248225
   Garcia CA, 2019, IFAC PAPERSONLINE, V52, P285, DOI 10.1016/j.ifacol.2019.08.222
   Gasparello PS, 2014, MED C CONTR AUTOMAT, P334, DOI 10.1109/MED.2014.6961393
   Gopher D, 2012, WORK, V41, P2284, DOI 10.3233/WOR-2012-0452-2284
   Grassini S., 2020, P 30 EUR SAF REL C 1, P4964, DOI [10.3850/978-981-14-8593-03975-cd, DOI 10.3850/978-981-14-8593-03975-CD]
   Greci L., 2022, Roadmapping Extended Reality: Fundamentals and Applications, P309
   Haskins J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P57, DOI [10.1109/VRW50115.2020.0-258, 10.1109/VRW50115.2020.00018]
   Ipaf, 2022, REP GLOB SIC PLE CRO
   Isleyen E, 2019, INT J MIN SCI TECHNO, V29, P603, DOI 10.1016/j.ijmst.2019.06.003
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Mourtzis D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051855
   Norris MW., 2019, Professional Safety, V64, P36
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Philippe S., 2020, VIRTUAL REALITY INTE, V2, P421, DOI [DOI 10.1016/J.VRIH.2020.07.008, 10.1016/j.vrih.2020.07.008]
   Schroeter R., 2018, ADJ P 10 INT C AUT U, P248, DOI 10.1145/3239092.3267418
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Zhao D, 2015, INT J INJ CONTROL SA, V22, P57, DOI 10.1080/17457300.2013.861853
NR 22
TC 1
Z9 1
U1 5
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 7
PY 2022
VL 3
AR 1034500
DI 10.3389/frvir.2022.1034500
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4TH9
UT WOS:001023202100001
OA gold
DA 2024-07-18
ER

PT J
AU Weller, R
   Cepok, J
   Arzaroli, R
   Marnholz, K
   Grosse, CS
   Reuter, H
   Zachmann, G
AF Weller, Rene
   Cepok, Joscha
   Arzaroli, Roman
   Marnholz, Kevin
   Grosse, Cornelia S.
   Reuter, Hauke
   Zachmann, Gabriel
TI Effects of immersion and navigation agency in virtual environments on
   emotions and behavioral intentions
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE behavior change; virtual reality; presence; environmental consciousness;
   coral reef ecosystem; simulation
ID CLIMATE-CHANGE; REALITY EXPOSURE; ANXIETY; EXPERIENCE; HEAD;
   HELPLESSNESS; INCREASES; PEOPLE; IMPACT; SENSE
AB We present a study investigating the question whether and how people's intention to change their environmental behavior depends on the degrees of immersion and freedom of navigation when they experience a deteriorating virtual coral reef. We built the virtual reef on top of a biologically sound model of the ecology of coral reefs, which allowed us to simulate the realistic decay of reefs under adverse environmental factors. During their experience, participants witnessed those changes while they also explored the virtual environment. In a two-factorial experiment (N = 224), we investigated the effects of different degrees of immersion and different levels of navigation freedom on emotions, the feeling of presence, and participants' intention to change their environmental behavior. The results of our analyses show that immersion and navigation have a significant effect on the participants' emotions of sadness and the feeling of helplessness. In addition, we found a significant effect, mediated by the participants' emotions, on the intention to change their behavior. The most striking result is, perhaps, that the highest level of immersion combined with the highest level of navigation did not lead to the highest intentions to change behavior. Overall, our results show that it is possible to raise awareness of environmental threats using virtual reality; it also seems possible to change people's behavior regarding these threats. However, it seems that the VR experience must be carefully designed to achieve these effects: a simple combination of all affordances offered by VR technology might potentially decrease the desired effects.
C1 [Weller, Rene; Arzaroli, Roman; Marnholz, Kevin; Zachmann, Gabriel] Univ Bremen, Fac Comp Sci & Math, Bremen, Germany.
   [Cepok, Joscha] Neuland BfI GmbH, Bremen, Germany.
   [Grosse, Cornelia S.] Johannes Kepler Univ Linz, Linz, Austria.
   [Reuter, Hauke] Leibniz Ctr Trop Marine Res, Bremen, Germany.
C3 University of Bremen; Johannes Kepler University Linz; Leibniz Zentrum
   fur Marine Tropenforschung (ZMT)
RP Zachmann, G (corresponding author), Univ Bremen, Fac Comp Sci & Math, Bremen, Germany.
EM zach@informatik.uni-bremen.de
RI Große, Cornelia S/JAC-6223-2023; Zachmann, Gabriel/AAI-9685-2020
OI Große, Cornelia S/0000-0001-5851-4678; Zachmann,
   Gabriel/0000-0001-8155-1127
FU Leibniz Center for Tropical Marine Research [SAW-2014-ZMT-1 317]
FX The Leibniz Center for Tropical Marine Research generously provided
   funding for conducting the user study (SAW-2014-ZMT-1 317).
CR Achtziger A., 2018, MOTIVATION ACTION, P485, DOI [10.1007/978-3-319-65094-4_12, DOI 10.1007/978-3-319-65094-4_12]
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Ahn SJ, 2015, COMMUN RES, V42, P839, DOI 10.1177/0093650214534973
   Ahn SJ, 2014, COMPUT HUM BEHAV, V39, P235, DOI 10.1016/j.chb.2014.07.025
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Ajzen I, 2011, PSYCHOL HEALTH, V26, P1113, DOI 10.1080/08870446.2011.613995
   Akerlof K, 2013, GLOBAL ENVIRON CHANG, V23, P81, DOI 10.1016/j.gloenvcha.2012.07.006
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Bjorner T, 2016, NORD REV, V37, P1, DOI 10.1515/nor-2016-0004
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Boker SM, 2009, PHILOS T R SOC B, V364, P3485, DOI 10.1098/rstb.2009.0152
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brosch T, 2021, CURR OPIN BEHAV SCI, V42, P15, DOI 10.1016/j.cobeha.2021.02.001
   Carrus G, 2008, J ENVIRON PSYCHOL, V28, P51, DOI 10.1016/j.jenvp.2007.09.003
   Cheng T, 2011, SOC MARK Q, V17, P48, DOI 10.1080/15245004.2011.570859
   DAVIS JJ, 1995, JOURNALISM MASS COMM, V72, P285, DOI 10.1177/107769909507200203
   Dunn ME, 2020, CONSERV SCI PRACT, V2, DOI 10.1111/csp2.280
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fonseca D., 2016, Proceedings of the 20th International Mindtrek Conference, P287, DOI [DOI 10.1145/2994310.2994334, 10.1145/2994310.2994334, 10.1145/2994310.2994334,96]
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Freeman J., 2005, PRESENCE, P213
   Gifford R, 2014, ANNU REV PSYCHOL, V65, P541, DOI 10.1146/annurev-psych-010213-115048
   Gorini A, 2010, ANN GEN PSYCHIATR, V9, DOI 10.1186/1744-859X-9-30
   Hayes A. F., 2018, METHODOL SOC SCI
   Heimlich JE, 2008, ENVIRON EDUC RES, V14, P215, DOI 10.1080/13504620802148881
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hoegh-Guldberg O, 2007, SCIENCE, V318, P1737, DOI 10.1126/science.1152509
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   Ibanez L, 2017, J BEHAV EXP ECON, V66, P150, DOI 10.1016/j.socec.2016.04.003
   Karnaze M. M., 2018, SADNESS ARCHITECT CO
   Khojasteh N, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.643331
   Kollmuss Anja., 2002, Environmental Education Research, V8, P239, DOI [10.1080/13504620220145401, DOI 10.1080/13504620220145401, https://doi.org/10.1080/13504620220145401]
   Kubicek A, 2016, ECOL MODEL, V329, P29, DOI 10.1016/j.ecolmodel.2016.02.018
   Kubicek A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002791
   Landry N, 2018, J ENVIRON PSYCHOL, V55, P18, DOI 10.1016/j.jenvp.2017.12.003
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Mado M, 2021, CYBERPSYCH BEH SOC N, V24, P839, DOI 10.1089/cyber.2020.0802
   MALONEY MP, 1973, AM PSYCHOL, V28, P583, DOI 10.1037/h0034936
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Nichols E. N., 2017, THESIS LANCASTER U L
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Peck TC, 2021, IEEE T VIS COMPUT GR, V27, P2502, DOI 10.1109/TVCG.2021.3067767
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Preacher KJ, 2008, BEHAV RES METHODS, V40, P879, DOI 10.3758/BRM.40.3.879
   Raij A, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P99, DOI 10.1109/VR.2009.4811005
   Rajecki D.W., 1982, Attitudes Themes and Advances
   Rees JH, 2015, CLIMATIC CHANGE, V130, P439, DOI 10.1007/s10584-014-1278-x
   Regenbrecht HT, 1998, INT J HUM-COMPUT INT, V10, P233, DOI 10.1207/s15327590ijhc1003_2
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Roberts D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P135, DOI 10.1109/VR.2009.4811013
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Rothbaum BO, 1999, BEHAV MODIF, V23, P507, DOI 10.1177/0145445599234001
   ROTTER JB, 1966, PSYCHOL MONOGR, V80, P1, DOI 10.1037/h0092976
   Salomon E, 2017, J EXP PSYCHOL-APPL, V23, P15, DOI 10.1037/xap0000105
   Schneider CR, 2021, CURR OPIN BEHAV SCI, V42, P114, DOI 10.1016/j.cobeha.2021.04.009
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Schulz M, 2000, 2000 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, PROCEEDINGS, P271, DOI 10.1109/PACT.2000.888351
   Schwartz D, 2017, J PUBLIC POLICY MARK, V36, P255, DOI 10.1509/jppm.16.132
   Senel Gizem, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P216, DOI 10.1007/978-3-030-62655-6_14
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   United Nations, 2015, PROC PERSUASIVE
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Villalba EE, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107272
   Weber EU, 2006, CLIMATIC CHANGE, V77, P103, DOI 10.1007/s10584-006-9060-3
   Zaalberg R, 2010, LECT NOTES COMPUT SC, V6137, P205, DOI 10.1007/978-3-642-13226-1_21
NR 75
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 5
PY 2022
VL 3
AR 893052
DI 10.3389/frvir.2022.893052
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UZ3
UT WOS:001023245600001
OA gold
DA 2024-07-18
ER

PT J
AU Gaugne, R
   Barreau, JB
   Duc-Martin, P
   Esnault, E
   Gouranton, V
AF Gaugne, Ronan
   Barreau, Jean-Baptiste
   Duc-Martin, Pierre
   Esnault, Elen
   Gouranton, Valerie
TI Sport heritage in VR: Real tennis case study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE sport heritage; virtual reality; intangible heritage and popular
   culture; real tennis; intangible heritage virtual reconstruction method
AB Traditional Sports and Games (TSG) are as varied as human cultures. Preserving knowledge of these practices is essential as they are an expression of intangible cultural heritage as emphasized by UNESCO (General Conference of United Nations Educational, Scientific and Cultural Organization, at its 25th session, 1989). With the increasing development of virtual reconstructions in the domain of Cultural Heritage, and thank to advances in the production and 3D animation of virtual humans, interactive simulations and experiences of these activities have emerged to preserve this intangible heritage. We propose a methodological approach to design an immersive reconstitution of a TSG in Virtual Reality, with a formalization of the elements involved in such a reconstitution and we illustrate this approach with the example of real tennis. Real tennis is a racket sport that has been played for centuries and is considered the ancestor of tennis. It was a very popular sport in Europe during the Renaissance period, practiced by every layer of the society. It is still practiced today in few courts in world, especially in France, United Kingdom, Australia and USA. It has been listed in the Inventory of Intangible Cultural Heritage in France since 2012.
C1 [Gaugne, Ronan; Duc-Martin, Pierre] Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
   [Barreau, Jean-Baptiste] CNRS, UMR ArchAm, Paris, France.
   [Esnault, Elen] Inrap, Rennes, France.
   [Gouranton, Valerie] Univ Rennes, INSA Rennes, Inria, CNRS,IRISA, Rennes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   de Rennes; Centre National de la Recherche Scientifique (CNRS); Institut
   National des Sciences Appliquees de Rennes; Inria; Universite de Rennes;
   Centre National de la Recherche Scientifique (CNRS)
RP Gaugne, R (corresponding author), Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
EM ronan.gaugne@irisa.fr
RI BARREAU, Jean-Baptiste/JFA-7608-2023
OI Gaugne, Ronan/0000-0002-4762-4342
FU Equipex + Continuum [ANR-18-EURE-0022]; EUR Digisport; 
   [ANR-21-ESRE-0030]
FX The work was partially funded by EUR Digisport under reference
   ANR-18-EURE-0022. EUR Digisport funded a Master internship grant for
   PD-M. The work was partially funded by Equipex + Continuum under
   reference ANR-21-ESRE-0030. Continuum funded the access to VR equipment,
   including the Immersia platform.
CR Baneat P., 1972, VIEUX RENNES DITIONS
   Barreau Jean-Baptiste, 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P547
   Barreau J.-B., 2020, SITU REV PATRIMOINES
   Barreau JB, 2020, VIRTUAL ARCHAEOL REV, V11, P41, DOI 10.4995/var.2020.12653
   Bideau B, 2010, IEEE COMPUT GRAPH, V30, P14, DOI 10.1109/MCG.2009.134
   Billing J. E., 1975, P ANN M PHOEN JAN 9, P34
   Bronson MaryAnn., 2015, DEGREES ARE FOREVER, P1
   Butnariu S, 2018, ACTA POLYTECH HUNG, V15, P185
   Carlier Y., 2002, DIX HUITIEME SIECLE, V34, P605
   Chen Kim Lim, 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P589
   Clastres Patrick, 2009, Paume et tennis en France, XVe-XXe siecle
   Claude G., 2014, ICAT EGVE INT C ARTI, P1
   Colleter R., 2021, Louise de Quengo: une bretonne du XVIIe siecle. Archeologie, anthropologie, histoire
   Doulamis A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P451, DOI 10.5220/0006347304510460
   Farley ORL, 2020, J HUM SPORT EXERC, V15, P535, DOI 10.14198/jhse.2020.153.06
   Ferrette R., 2016, RENNES
   Ferrette R., 2015, ARCHEOLOGIE MEDIEVAL, P188, DOI [10.4000/archeomed.7630, DOI 10.4000/ARCHEOMED.7630]
   Gaugne R., 2019, ICAT EGVE 2019 INT C, P1
   Gaugne R, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3383782
   Geiger C., 2010, MENSCH COMPUTER 2010, P37
   Andreu JH, 2021, REV HIST INDUST, P177
   Katz L., 2006, INT J COMPUTER SCI S, V4, P4
   Linaza M. T., 2013, CEUR WORKSHOP PROC, V997
   Mehl Jean-Michel., 1990, JEUX ROYAUME FRANCE
   Nussipbekov AK, 2014, J PHYS CONF SER, V495, DOI 10.1088/1742-6596/495/1/012036
   O'Connor NE, 2014, EUR SIGNAL PR CONF, P351
   Plante TG, 2003, COMPUT HUM BEHAV, V19, P495, DOI 10.1016/S0747-5632(02)00074-2
   Potts R., 2007, JURASSIC TENNIS
   Selmanovic E., 2018, GCH 2018 - Eurographics Workshop on Graphics and Cultural Heritage, Vienna, Austria, November 12-15, 2018, P57, DOI DOI 10.2312/GCH.20181341
   Setiawan A., 2017, ComTech: Comput. Math. Eng. Appl., V8, P183
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Tang T., 2002, CONN REAL VIRT DES E, P603
   Thiele S, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P67, DOI 10.1109/3DUI.2013.6550199
   UNESCO, 1989, Recommendation on the Safeguarding of Traditional Culture and Folklore
   Vlahakis Vassilios, 2001, VIRTUAL REALITY ARCH, V9
NR 35
TC 4
Z9 4
U1 6
U2 17
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 17
PY 2022
VL 3
AR 922415
DI 10.3389/frvir.2022.922415
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XO1
UT WOS:001023312700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Suwa, T
   Sato, Y
   Wada, T
AF Suwa, Tsukasa
   Sato, Yuki
   Wada, Takahiro
TI Reducing Motion Sickness When Reading With Head-Mounted Displays By
   Using See-Through Background Images
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE motion sickness; carsickness; cybersickness; head-mounted display; video
   see-through images; self-motion perception; 2D VR content;
   visual-vestibular conflict
ID MAGNITUDE
AB With the development of virtual reality technology, head-mounted displays (HMDs) have been increasingly used to view or read 2D content while in vehicles. When 2D content is displayed in a fixed position on an HMD, the visual appearance does not change even with head movements, and body movements cannot be perceived while watching 2D content. This may cause visual-vestibular conflict and severe motion sickness. This study investigates whether motion sickness when reading 2D content fixed to the HMD coordinate system can be reduced by allowing readers to perceive body movements through video see-through images obtained from the front camera of the HMD in situations where the body vibrates. Twenty participants performed 20-minutes reading tasks in which they read a book fixed to the HMD coordinate while seated in a vibration device. Two background conditions of the book were explored: 1) the white background condition-not allowing participants to perceive their movements visually, and 2) the camera background condition-allowing participants to perceive their movements visually through see-through images. Evaluation of motion sickness using the Misery Scale, which is an 11-point questionnaire, showed that motion sickness after task completion was significantly lower in the camera background condition than in the white background condition. This result suggests that motion sickness can be relieved, provided that the users perceive their motion in the peripheral vision through the camera image, even if they gaze at 2D content fixed in the HMD coordinate system in the central vision. This study helps promote the use of HMDs by alleviating motion sickness.
C1 [Suwa, Tsukasa] Ritsumeikan Univ, Grad Sch Informat Sci & Engn, Kusatsu, Japan.
   [Sato, Yuki; Wada, Takahiro] Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Japan.
   [Sato, Yuki; Wada, Takahiro] Ritsumeikan Univ, Res Org Sci & Technol, Kusatsu, Japan.
C3 Ritsumeikan University; Nara Institute of Science & Technology;
   Ritsumeikan University
RP Suwa, T (corresponding author), Ritsumeikan Univ, Grad Sch Informat Sci & Engn, Kusatsu, Japan.; Sato, Y (corresponding author), Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Japan.; Sato, Y (corresponding author), Ritsumeikan Univ, Res Org Sci & Technol, Kusatsu, Japan.
EM is0414if@ed.ritsumei.ac.jp; sato.yuki@is.naist.jp
FU Japan Science and Technology Agency [JPMJTR20RR]
FX Funding This study was funded by Japan Science and Technology Agency
   (JPMJTR20RR).
CR BLES W, 1980, ACTA OTO-LARYNGOL, V89, P534, DOI 10.3109/00016488009127171
   Bos JE, 2005, AVIAT SPACE ENVIR MD, V76, P1111
   Butler CA, 2006, AVIAT SPACE ENVIR MD, V77, P1236
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   GOLDING JF, 1995, AVIAT SPACE ENVIR MD, V66, P1046
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Griffin MJ, 2004, AVIAT SPACE ENVIR MD, V75, P739
   Hatayama R., 2021, HARRIS SCI REV DOSHI, V62, P27, DOI [10.14988/00028198, DOI 10.14988/00028198]
   Hock P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4034, DOI 10.1145/3025453.3025665
   Isu N, 2014, DISPLAYS, V35, P90, DOI 10.1016/j.displa.2014.01.003
   Karjanto J, 2018, TRANSPORT RES F-TRAF, V58, P678, DOI 10.1016/j.trf.2018.06.046
   Kato K., 2006, SAE TECHNICAL PAPERS, DOI [10.4271/2006-01-0096, DOI 10.4271/2006-01-0096]
   Kato K., 2006, REV AUTOMOTIVE ENG, V27, P465
   Kato K., 2008, SAE Technical Paper, DOI [10.4271/2008-01-0565, DOI 10.4271/2008-01-0565]
   Krueger WWO, 2011, LARYNGOSCOPE, V121, pS17, DOI 10.1002/lary.21373
   Kuiper OX, 2018, APPL ERGON, V68, P169, DOI 10.1016/j.apergo.2017.11.002
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Li JY, 2021, AUTOMOTIVEUI '21: 13TH INTERNATIONAL ACM CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P28, DOI [10.1145/3409118.3475137, 10.1145/34091183475137]
   Li Jingyi, 2020, 12 INT C AUT US INT, DOI [10.1145/3409251.3411732, DOI 10.1145/3409251.3411732]
   Mayo AM, 2011, PSYCHOL SCI, V22, P118, DOI 10.1177/0956797610392927
   McGill M, 2019, AUTOMOTIVE UI 19 ADJ, DOI DOI 10.1145/3349263.3351330
   McGill M., 2017, P 2017 CHI C EXTENDE, P469
   Meschtscherjakov A, 2019, LECT NOTES COMPUT SC, V11747, P660, DOI 10.1007/978-3-030-29384-0_39
   Morimoto A., 2008, 15 WORLD C INT TRANS
   Morimoto A., 2008, P FISITA 2008 WORLD
   Munafo J, 2016, EXP BRAIN RES, V234, P2721, DOI 10.1007/s00221-016-4676-7
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   ROLNICK A, 1989, AVIAT SPACE ENVIR MD, V60, P779
   Sato H, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.909005
   Schwind Valentin., 2018, Proceedings of the 20th international conference on human-computer interaction with mobile devices and services adjunct, P111, DOI [10.1145/3236112.3236127, DOI 10.1145/3236112.3236127]
   Stoffregen TA, 1999, J EXP PSYCHOL HUMAN, V25, P1641
   Stoffregen TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066949
   TELFORD L, 1993, PERCEPT PSYCHOPHYS, V53, P682, DOI 10.3758/BF03211744
NR 34
TC 6
Z9 6
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 15
PY 2022
VL 3
AR 910434
DI 10.3389/frvir.2022.910434
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WB2
UT WOS:001019174600001
OA gold
DA 2024-07-18
ER

PT J
AU Martinez, JS
   Tan, HZ
   Cholewiak, RW
AF Martinez, Juan S.
   Tan, Hong Z. Z.
   Cholewiak, Roger W.
TI Psychophysical Studies of Interleaving Narrowband Tactile Stimuli to
   Achieve Broadband Perceptual Effects
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE actuator; broadband; haptic; narrowband; psychophysics; tactile;
   validation; vibrotactile
ID FLUTTER-VIBRATION; MECHANORECEPTIVE AFFERENTS; VIBROTACTILE
   LOCALIZATION; INFORMATION-TRANSMISSION; HAIRY SKIN; FREQUENCY;
   DISCRIMINATION; MASKING; INTENSITY; THRESHOLD
AB Despite the ubiquitous presence of tactile actuators (tactors) in mobile devices, there is a continuing need for more advanced tactors that can cover the entire frequency range of human tactile perception. Broadband tactors can increase information transmission and enrich sensory experience. The engineering challenges are multifold in that the ideal tactors should exhibit an effective bandwidth of at least 300 Hz, small form factor, robustness, power efficiency and low cost. For wearable applications, there are the additional challenges of ease of mounting and maintaining adequate skin contact during body movements. We propose an approach to interleave narrowband tactile stimuli to achieve broadband effects, taking advantage of the limited spatial resolution of the skin on the torso and limbs. Three psychophysical experiments were conducted to assess the validity of this approach. Participants performed pairwise discriminations of two broadband stimuli delivered using one or two tactors. The broadband stimuli consisted of one mid-frequency and one high-frequency component delivered through one tactor by mixing the two components, or through two tactors (one component per tactor). The first two experiments revealed extraneous cues such as localization and mutual masking of mid- and high-frequency components that were subsequently eliminated in the third experiment. Results from 12 participants confirmed that performance on pairwise comparisons was below the discrimination threshold, confirming that broadband haptic effects can be achieved through narrowband tactors placed within the skin's two-point limen.
C1 [Martinez, Juan S.; Tan, Hong Z. Z.] Purdue Univ, Sch Elect & Comp Engn, Coll Engn, Hapt Interface Res Lab, W Lafayette, IN 47907 USA.
   [Cholewiak, Roger W.] Princeton Univ, Cutaneous Commun Lab, Princeton, NJ USA.
C3 Purdue University System; Purdue University; Princeton University
RP Martinez, JS (corresponding author), Purdue Univ, Sch Elect & Comp Engn, Coll Engn, Hapt Interface Res Lab, W Lafayette, IN 47907 USA.
EM mart1304@purdue.edu
OI Martinez, Juan/0000-0002-5457-3790
CR BOLANOWSKI SJ, 1994, SOMATOSENS MOT RES, V11, P279, DOI 10.3109/08990229409051395
   Brown L.M., 2006, Proceedings of the 8th conference on HCI with mobile devices and services, P231, DOI [10.1145/1152215.1152265, DOI 10.1145/1152215.1152265, https://doi.org/10.1145/1152215.1152265]
   Chen HY, 2008, LECT NOTES COMPUT SC, V5024, P209, DOI 10.1007/978-3-540-69057-3_25
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Cholewiak RW, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P413
   Cholewiak RW, 2004, PERCEPT PSYCHOPHYS, V66, P970, DOI 10.3758/BF03194989
   Cholewiak RW, 2003, PERCEPT PSYCHOPHYS, V65, P1058, DOI 10.3758/BF03194834
   Cholewiak RW, 2000, PERCEPT PSYCHOPHYS, V62, P1220, DOI 10.3758/BF03212124
   Cholewiak SA, 2010, IEEE T HAPTICS, V3, P3, DOI 10.1109/ToH.2009.36
   CRAIG JC, 1972, PERCEPT PSYCHOPHYS, V11, P150, DOI 10.3758/BF03210362
   Craig JC, 2000, CURR DIR PSYCHOL SCI, V9, P29, DOI 10.1111/1467-8721.00054
   Culbertson H, 2018, IEEE HAPTICS SYM, P32, DOI 10.1109/HAPTICS.2018.8357149
   Eberhardt S.P., 1994, Proceedings of ASME Dynamic Systems and Control, V55, P345
   Elliott Linda R., 2013, Human Interface and the Management of Information. Information and Interaction for Health, Safety, Mobility and Complex Environments. 15th International Conference, HCI International 2013. Proceedings: LNCS 8017, P46, DOI 10.1007/978-3-642-39215-3_6
   Ertan S, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P164, DOI 10.1109/ISWC.1998.729547
   FRANZEN O, 1975, PERCEPT PSYCHOPHYS, V17, P480, DOI 10.3758/BF03203298
   Friesen RF, 2018, IEEE HAPTICS SYM, P290, DOI 10.1109/HAPTICS.2018.8357190
   GESCHEID.GA, 1970, PERCEPT PSYCHOPHYS, V8, P433, DOI 10.3758/BF03207041
   GESCHEIDER GA, 1978, SENS PROCESS, V2, P99
   GESCHEIDER GA, 1982, J ACOUST SOC AM, V72, P1421, DOI 10.1121/1.388449
   GOFF GD, 1967, J EXP PSYCHOL, V74, P294, DOI 10.1037/h0024561
   Green D. M., 1966, SIGNAL DETECTION THE
   Gunhyuk Park, 2011, 2011 IEEE World Haptics Conference (WHC 2011), P59, DOI 10.1109/WHC.2011.5945462
   Hayward V, 2007, IEEE ROBOT AUTOM MAG, V14, P88, DOI 10.1109/M-RA.2007.907921
   Hsieh MJ, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P29, DOI 10.1145/2935334.2935358
   Humphrey R., 2008, PLAYREC
   Israr A, 2006, J ACOUST SOC AM, V120, P2789, DOI 10.1121/1.2354022
   Israr A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2019
   Jones LA, 2008, HUM FACTORS, V50, P90, DOI 10.1518/001872008X250638
   Jones LA, 2013, IEEE T HAPTICS, V6, P268, DOI 10.1109/TOH.2012.74
   Jones LA, 2009, PERCEPTION, V38, P52, DOI 10.1068/p5914
   Kaufmann M, 2012, AUDIOLOGY NEUROTOL E, V2, P9, DOI 10.1159/000336159
   Lee SY, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P433
   Lévêque JL, 2000, J INVEST DERMATOL, V115, P454, DOI 10.1046/j.1523-1747.2000.00055.x
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Liao YC, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P595, DOI 10.1145/2984511.2984522
   LINVILL JG, 1966, PR INST ELECTR ELECT, V54, P40, DOI 10.1109/PROC.1966.4572
   Macmillan N. A., 2004, DETECTION THEORY USE, DOI [DOI 10.4324/9781410611147, 10.4324/9781410611147]
   Mahns DA, 2006, J NEUROPHYSIOL, V95, P1442, DOI 10.1152/jn.00483.2005
   MAKOUS JC, 1995, J NEUROSCI, V15, P2808
   Mancini F, 2014, ANN NEUROL, V75, P917, DOI 10.1002/ana.24179
   MARKS LE, 1979, SENS PROCESS, V3, P188
   Martinez JS, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P709, DOI 10.1109/WHC49131.2021.9517268
   Matscheko Michael, 2010, 2010 International Symposium on Wearable Computers (ISWC 2010), DOI 10.1109/ISWC.2010.5665867
   MERZENICH MM, 1969, EXP BRAIN RES, V9, P236
   MOUNTCASTLE VB, 1969, J NEUROPHYSIOL, V32, P452, DOI 10.1152/jn.1969.32.3.452
   Park G, 2019, IEEE T HAPTICS, V12, P43, DOI 10.1109/TOH.2018.2859955
   Park J, 2016, LECT NOTES COMPUT SC, V9774, P47, DOI 10.1007/978-3-319-42321-0_5
   Pawluk D. T. V., 1998, Proceedings of the ASME Dynamic Systems and Control Division-1998, P97
   Perez CA, 2000, MED BIOL ENG COMPUT, V38, P74, DOI 10.1007/BF02344692
   Reed CM, 2019, IEEE T HAPTICS, V12, P2, DOI 10.1109/TOH.2018.2861010
   ROGERS CH, 1970, IEEE T MAN MACHINE, VMM11, P5, DOI 10.1109/TMMS.1970.299954
   Rupert AH, 2000, IEEE ENG MED BIOL, V19, P71, DOI 10.1109/51.827409
   Sang-Won Shim, 2020, Design, User Experience, and Usability. Interaction Design. 9th International Conference, DUXU 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12200), P532, DOI 10.1007/978-3-030-49713-2_37
   SHERRICK CE, 1990, J ACOUST SOC AM, V88, P169, DOI 10.1121/1.399937
   TALBOT WH, 1968, J NEUROPHYSIOL, V31, P301, DOI 10.1152/jn.1968.31.2.301
   Tan H. Z., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P515
   Tan HZ, 2020, P IEEE, V108, P945, DOI 10.1109/JPROC.2020.2992561
   Tan HZ, 2020, IEEE T HAPTICS, V13, P745, DOI 10.1109/TOH.2020.2973135
   Tan HZ, 1999, PERCEPT PSYCHOPHYS, V61, P993, DOI 10.3758/BF03207608
   van Erp JBF, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P80
   Van Erp JBF, 2005, ERGONOMICS, V48, P302, DOI 10.1080/0014013042000327670
   VANDOREN CL, 1990, J ACOUST SOC AM, V87, P2655, DOI 10.1121/1.399550
   Verrillo R.T., 1992, TACTILE AIDS HEARING, P1
   VERRILLO RT, 1963, J ACOUST SOC AM, V35, P1962, DOI 10.1121/1.1918868
   VERRILLO RT, 1969, PERCEPT PSYCHOPHYS, V6, P366, DOI 10.3758/BF03212793
   VERRILLO RT, 1983, PERCEPT PSYCHOPHYS, V33, P379, DOI 10.3758/BF03205886
   WEBER EH, 1834, SENSE TOUCH
   WEINSTEIN A, 1968, BUS HIST REV, V42, P195, DOI 10.2307/3112215
   Yoo Y, 2014, IEEE T HAPTICS, V7, P3, DOI 10.1109/TOH.2013.57
NR 70
TC 0
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 31
PY 2022
VL 3
AR 894575
DI 10.3389/frvir.2022.894575
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZZ2
UT WOS:001019277900001
OA gold
DA 2024-07-18
ER

PT J
AU Weber, S
   Rudolph, L
   Liedtke, S
   Eichhorn, C
   Dyrda, D
   Plecher, DA
   Klinker, G
AF Weber, Sandro
   Rudolph, Linda
   Liedtke, Sven
   Eichhorn, Christian
   Dyrda, Daniel
   Plecher, David A. A.
   Klinker, Gudrun
TI Frameworks Enabling Ubiquitous Mixed Reality Applications Across
   Dynamically Adaptable Device Configurations
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE mixed reality; tracking; visualization; interaction; frameworks
ID TRACKING
AB If Mixed Reality applications are supposed to become truly ubiquitous, they face the challenge of an ever evolving set of hardware and software systems - each with their own standards and APIs-that need to work together and become part of the same shared environment (the application). A unified standard is unlikely so we can not rely on a single software development stack to incorporate all necessary parts. Instead we need frameworks that are modular and flexible enough to be adapted to the needs of the application at hand and are able to incorporate a wide range of setups for devices, services, etc. We identified a set of common questions that can be used to characterize and analyze Mixed Reality applications and use these same questions to identify challenges as well as present solutions in the form of three frameworks tackling the fields of tracking and inference (UbiTrack), interaction (Ubi-Interact) and visualization (UbiVis). Tracking and inference has been addressed for quite some time now while interaction is a current topic with existing solutions. Visualization will be focused more in the future. We present several applications in development together with their future vision and explain how the frameworks help realize these and other potential apps.
C1 [Weber, Sandro; Rudolph, Linda; Liedtke, Sven; Eichhorn, Christian; Dyrda, Daniel; Plecher, David A. A.; Klinker, Gudrun] Tech Univ Munich, FAR Augmented Real Res Grp, Munich, Germany.
C3 Technical University of Munich
RP Weber, S (corresponding author), Tech Univ Munich, FAR Augmented Real Res Grp, Munich, Germany.
EM webers@in.tum.de
RI Klinker, Gudrun/JVP-3665-2024
OI Klinker, Gudrun/0000-0003-0971-5726
FU European Union's Horizon 2020 Framework Programme for Research and
   Innovation under the Specific Grant [945539]; project "Zentrales
   Innovationsprogramm Mittelstand" of the German Federation of Industrial
   Research Associations [FKZ 01EA 1807A]; project "Enable 2.0" of the
   Federal Ministry of Education of Research;  [ZF4086002SS7]
FX This project/research has received funding from the European Union's
   Horizon 2020 Framework Programme for Research and Innovation under the
   Specific Grant Agreement No. 945539 (Human Brain Project SGA3), from the
   project "Zentrales Innovationsprogramm Mittelstand" of the German
   Federation of Industrial Research Associations (ZF4086002SS7) as well as
   the project "Enable 2.0" of the Federal Ministry of Education of
   Research (FKZ 01EA 1807A).
CR Alt T., 2012, VIRTUELLE TECHNIKEN, P4, DOI [10.1007/978-3-642-20636-8_2, DOI 10.1007/978-3-642-20636-8_2]
   [Anonymous], 2004, P INT WORKSH EXPL DE
   [Anonymous], 2006, PROC IEEE INT S MIXE, DOI DOI 10.1109/ISMAR.2006.297799
   Bauer M, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P45, DOI 10.1109/ISAR.2001.970514
   Bauer Martin, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P43, DOI 10.1109/ISMAR.2006.297793
   Behr J., 2017, WEB BASIERTE ANWENDU, P117, DOI [10.1007/978-3-662-52956-0_3, DOI 10.1007/978-3-662-52956-0_3]
   Blanco-Novoa O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113328
   Bondi A. B., 2000, Proceedings Second International Workshop on Software and Performance. WOSP2000, P195, DOI 10.1145/350391.350432
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203
   Browne D., 2016, Adaptive user interfaces
   Casarin Julien, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274298
   Chen LJ, 2018, ADV NEUR IN, V31
   Cutolo F, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P52, DOI 10.1109/ISMAR-Adjunct.2017.31
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Daniilidis K, 1999, INT J ROBOT RES, V18, P286, DOI 10.1177/02783649922066213
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   De Guzman JA, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3359626
   Durrant-Whyte H, 2016, SPRINGER HANDBOOK OF ROBOTICS, P867
   Eck U, 2015, IEEE T VIS COMPUT GR, V21, P1427, DOI 10.1109/TVCG.2015.2480087
   Eichhorn C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P548, DOI 10.1109/VRW52623.2021.00156
   Eichhorn C, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P24, DOI 10.1109/ISMAR-Adjunct51615.2020.00022
   Eichhorn C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1801, DOI 10.1109/VR.2019.8798056
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614
   Figueroa P., 2002, P 7 INT C 3D WEB TEC, P53
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Huber M., 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, P211, DOI DOI 10.1109/ISMAR.2007.4538849
   Huber M., 2014, J VIRTUAL REALITY BR, P11
   Huber M, 2009, INT SYM MIX AUGMENT, P195, DOI 10.1109/ISMAR.2009.5336465
   Itoh Y, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P75, DOI 10.1109/3DUI.2014.6798846
   Keitler Peter, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P73, DOI 10.1109/ISMAR.2010.5643553
   Keitler P, 2010, HUM-COMPUT INT-SPRIN, P251, DOI 10.1007/978-1-84882-733-2_13
   Keitler P, 2008, LECT NOTES COMPUT SC, V5359, P224, DOI 10.1007/978-3-540-89646-3_22
   Klein George, 2007, P1
   Klinker G., 2012, ASIA PACIFIC C COMPU, P149, DOI [10.1145/2350046.2350078, DOI 10.1145/2350046.2350078]
   Krekhov A., 2016, 24 INT C CENTR EUR C
   Lacoche J., 2015, P 7 ACM SIGCHI S ENG, P28
   Lacoche J, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P23, DOI 10.1109/3DUI.2016.7460026
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Mantzios V.-M., 2014, HCI INT 2014 POSTERS, P613, DOI [10.1007/978-3-319-07857-1_108, DOI 10.1007/978-3-319-07857-1_108]
   Marchesi G, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10110772
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mitchell D., 2012, 2012 RICS COBR C
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Newman J., 2007, WORKSH TRENDS ISS TR
   Normand JM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048331
   Ohlenburg J, 2007, LECT NOTES COMPUT SC, V4554, P497
   OpenJS Foundation Contributors, 2013, NOD RED
   Pankratz F, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P140, DOI 10.1109/ISMAR.2015.41
   Pereira N, 2021, INT SYM MIX AUGMENT, P479, DOI 10.1109/ISMAR52148.2021.00065
   Pielot M, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P233, DOI 10.1145/2628363.2628364
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139200
   Plecher D. A., 2020, GI VR AR WORKSH
   Plecher D. A., 2020, ICAT EGVE 2020 INT C, DOI [10.2312/egve.20201258, DOI 10.2312/EGVE.20201258]
   Plecher DA, 2019, LECT NOTES COMPUT SC, V11899, P550, DOI 10.1007/978-3-030-34350-7_53
   Pustka D., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P37, DOI 10.1109/ISMAR.2010.5643548
   Pustka D., 2007, TUMI0718 I INF
   Pustka D., 2006, P DRITT WORKSH VIRT, P13
   Pustka D, 2012, INT SYM MIX AUGMENT, P81, DOI 10.1109/ISMAR.2012.6402542
   Pustka D, 2011, IEEE PERVAS COMPUT, V10, P68, DOI 10.1109/MPRV.2010.50
   Pustka D, 2008, INT SYM MIX AUGMENT, P13, DOI 10.1109/ISMAR.2008.4637317
   Quigley A., 2014, P 16 INT C HUM COMP, DOI [10.1145/2628363, DOI 10.1145/2628363]
   Quigley M., 2009, ICRA WORKSH OP SOURC, V3, P5, DOI DOI 10.1109/IECON.2015.7392843
   Russell S, 2009, ARTIFICIAL INTELLIGE, Vthird
   Sandor C, 2005, PERS UBIQUIT COMPUT, V9, P169, DOI 10.1007/S00779-004-0328-1
   Schwerdtfeger B, 2008, INT SYM MIX AUGMENT, P91, DOI 10.1109/ISMAR.2008.4637331
   Shimbun NikkanKogyo., 1989, POKA YOKE IMPROVING
   Sielhorst T, 2007, LECT NOTES COMPUT SC, V4792, P652
   Sosin A, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P71, DOI 10.1109/ISMAR-Adjunct.2019.00032
   Swan II J. E., 2018, 2018 IEEE INT S MIXE, pxxxvi
   Tahara T, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P249, DOI 10.1109/ISMAR-Adjunct51615.2020.00072
   Thevenin D, 1999, HUMAN-COMPUTER INTERACTION - INTERACT '99, P110
   Tönnis M, 2013, COMPUT GRAPH-UK, V37, P997, DOI 10.1016/j.cag.2013.09.002
   Waechter C., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P275, DOI 10.1109/ISMAR.2010.5643604
   Waechter C. A. L., 2013, P 6 INT C COMP VIS C, P4, DOI [10.1145/2466715.2466728, DOI 10.1145/2466715.2466728]
   Waechter CAL, 2009, INT SYM MIX AUGMENT, P221, DOI 10.1109/ISMAR.2009.5336452
   Waldow K., 2019, MENSCH COMPUTER 2019
   Weber S., 2021, ICST T MOBILE COMMUN, V6, P170291, DOI [10.4108/eai.14-7-2021.170291, DOI 10.4108/EAI.14-7-2021.170291]
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Welch G, 2002, IEEE COMPUT GRAPH, V22, P24, DOI 10.1109/MCG.2002.1046626
NR 81
TC 2
Z9 2
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 4
PY 2022
VL 3
AR 765959
DI 10.3389/frvir.2022.765959
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OG6
UT WOS:001021697900001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Zhang, JY
   Kajimoto, H
AF Zhang, Jianyao
   Kajimoto, Hiroyuki
TI A Robust Approach for Reproducing the Haptic Sensation of Sandpaper With
   Different Roughness During Bare Fingertip Interaction
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE bare finger interaction; haptic device; roughness; surface measurement;
   texture rendering
AB When reproducing realistic virtual textures for bare finger interaction, an accelerometer attached to a fingernail is commonly used. This measurement depends on the dynamic conditions during the exploration action, and slight differences in roughness are difficult to acquire accurately because of masking by shivering, low-pass filtering by the finger tissue, and sensor accuracy. We propose a simpler yet robust approach based on the 3D measurement of the surface and compare it with the conventional approach. The 3D surface images of sandpaper with different degrees of roughness were captured using a 3D microscope, and the line roughness curve was transformed into an acceleration curve by quadratic differential transformation. The real-time acceleration and frictional force were measured by an accelerometer and force sensor for comparison. A haptic device replaying acceleration-based vibrations by two audio speakers and producing tangential force by a motor-controlled liner slide was developed for reproduction. We conducted experiments with participants to evaluate the reproduction approach. Experimental results showed that the conventional approach obtained sufficient discriminability with the assistance of force, whereas the proposed approach achieved higher reproducibility and discriminability by sole vibration. Thus, our approach provides a new reference for studies of bare finger interaction with rough surfaces.
C1 [Zhang, Jianyao; Kajimoto, Hiroyuki] Univ Electrocommun, Dept Informat, Chofu, Japan.
C3 University of Electro-Communications - Japan
RP Zhang, JY (corresponding author), Univ Electrocommun, Dept Informat, Chofu, Japan.
EM zhang@kaji-lab.jp
CR [Anonymous], 2013, 6344 ISO 3
   Asano S, 2015, IEEE T HUM-MACH SYST, V45, P393, DOI 10.1109/THMS.2014.2376519
   Basdogan C, 2020, IEEE T HAPTICS, V13, P450, DOI 10.1109/TOH.2020.2990712
   Bau O., 2010, P 23 ANN ACM S US IN, P283, DOI DOI 10.1145/1866029.1866074
   Biswas A, 2015, IEEE T HAPTICS, V8, P102, DOI 10.1109/TOH.2014.2369422
   Burns DA, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P415, DOI 10.1109/WHC49131.2021.9517265
   Culbertson H. M., 2015, THESIS U PENNSYLVANI
   Culbertson H, 2017, IEEE T HAPTICS, V10, P63, DOI 10.1109/TOH.2016.2598751
   Culbertson H, 2014, IEEE T HAPTICS, V7, P381, DOI 10.1109/TOH.2014.2316797
   Delhaye B, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2015.0874
   Delhaye B, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2014.0698
   Fischer-Cripps AC, 1999, J MATER SCI, V34, P129, DOI 10.1023/A:1004490230078
   Hasegawa H, 2020, IEEE T HAPTICS, V13, P11, DOI 10.1109/TOH.2019.2960021
   Hertz H., 1882, VERHANDLUNGEN VEREIN, V61, P410
   Ito K, 2017, IEEE SYS MAN CYBERN, P2343, DOI 10.1109/SMC.2017.8122972
   Kuchenbecker KJ, 2011, SPRINGER TRAC ADV RO, V70, P245
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Maeda T., 2016, SIGGRAPH ASIA 2016 Emerging Technologies, P4, DOI DOI 10.1145/2988240.2988253
   Martel E, 2017, ENTERTAIN COMPUT, V21, P19, DOI 10.1016/j.entcom.2017.04.004
   Poupyrev I., 2003, UIST 03, P217, DOI DOI 10.1145/964696.964721
   Preechayasomboon P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376512
   Seokhee Jeon, 2011, 2011 IEEE World Haptics Conference (WHC 2011), P227, DOI 10.1109/WHC.2011.5945490
   Strese M, 2018, IEEE HAPTICS SYM, P247, DOI 10.1109/HAPTICS.2018.8357184
   Takasaki M, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1115, DOI 10.1109/IROS.2005.1545129
   Ujitoko Y, 2020, IEEE HAPTICS SYM, P882, DOI 10.1109/HAPTICS45997.2020.ras.HAP20.80.00957e94
NR 25
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 2
PY 2022
VL 3
AR 829946
DI 10.3389/frvir.2022.829946
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AD2
UT WOS:001019282000001
OA gold
DA 2024-07-18
ER

PT J
AU Kelly, RM
   Seabrook, EM
   Foley, F
   Thomas, N
   Nedeljkovic, M
   Wadley, G
AF Kelly, Ryan M. M.
   Seabrook, Elizabeth M. M.
   Foley, Fiona
   Thomas, Neil
   Nedeljkovic, Maja
   Wadley, Greg
TI Design Considerations for Supporting Mindfulness in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE design; meditation; mental health; mindfulness; virtual environment;
   virtual reality
ID EMOTION REGULATION; STRESS REDUCTION; FOCUS GROUPS; MEDITATION;
   INTERVENTIONS; ENVIRONMENTS; ASSOCIATIONS; MECHANISMS; CONSTRUCT;
   SYMPTOMS
AB Mindfulness practice involves bringing one's attention to the present moment and noticing events as they unfold with a non-judgmental attitude of acceptance. Although mindfulness has been shown to reduce stress and improve mental health, it can be challenging to learn mindfulness techniques. Recent years have seen an interest in using virtual reality (VR) to help people learn mindfulness by immersing users in virtual settings that support an external focus of attention and reduce everyday environmental distraction. However, the literature currently lacks an understanding of how VR should be designed to support mindfulness. In this paper we describe the iterative design and evaluation of Place, a VR app that supports mindfulness practice by situating the user in a virtual forest environment. We present findings from our design process in which prospective users trialled Place and provided feedback on the design in focus groups. Our findings draw attention to factors that influenced the user experience and acceptance of VR for mindfulness, and we describe how the design was altered to address these factors. We end by discussing key design choices that designers should consider when creating VR for mindfulness. Our contributions include insight into the importance of following an iterative design process when creating a VR mindfulness app, and a framework that can be used to inform the design of future VR apps for mindfulness practice.
C1 [Kelly, Ryan M. M.; Wadley, Greg] Univ Melbourne, Sch Comp & Informat Syst, Parkville, Vic, Australia.
   [Seabrook, Elizabeth M. M.; Foley, Fiona; Thomas, Neil; Nedeljkovic, Maja] Swinburne Univ Technol, Ctr Mental Hlth, Hawthorn, Vic, Australia.
C3 University of Melbourne; Swinburne University of Technology
RP Kelly, RM (corresponding author), Univ Melbourne, Sch Comp & Informat Syst, Parkville, Vic, Australia.
EM ryan.kelly@unimelb.edu.au
RI Thomas, Neil/H-6268-2016
OI Thomas, Neil/0000-0001-7006-6361; Kelly, Ryan/0000-0002-8773-6656
CR Ahmed MMH, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4960, DOI 10.1145/3025453.3026000
   Anderson ND, 2007, CLIN PSYCHOL PSYCHOT, V14, P449, DOI 10.1002/cpp.544
   Anderson T, 2019, J COGN ENHANCE, V3, P207, DOI 10.1007/s41465-018-00119-y
   Baer RA, 2008, ASSESSMENT, V15, P329, DOI 10.1177/1073191107313003
   Bahng S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376582
   Birtwell K, 2019, MINDFULNESS, V10, P89, DOI 10.1007/s12671-018-0951-y
   Blandford A, 2018, DIGIT HEALTH, V4, DOI 10.1177/2055207618770325
   Blom KJ, 2014, VIRTUAL REAL-LONDON, V18, P101, DOI 10.1007/s10055-013-0232-y
   Bohlmeijer E, 2010, J PSYCHOSOM RES, V68, P539, DOI 10.1016/j.jpsychores.2009.10.005
   Bränström R, 2011, BRIT J HEALTH PSYCH, V16, P300, DOI 10.1348/135910710X501683
   BreatheVR, 2021, BREATHEVR HLTH MIND
   Bruun-Pedersen J.R., 2018, Journal For Virtual Worlds Research, V9, DOI DOI 10.4101/JVWR.V9I3.7224
   Carlsen B, 2011, BMC MED RES METHODOL, V11, DOI 10.1186/1471-2288-11-26
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Cochrane KA, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P298, DOI 10.1145/3292147.3292215
   Crane R. S., 2012, BANGOR EXETER UNPUB
   Crane RS, 2013, ASSESSMENT, V20, P681, DOI 10.1177/1073191113490790
   Dao E., 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764.3445435, 10.1145/3411764.3445435]
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Deep VR, 2021, DEEP MED VIRT REAL G
   Demarzo M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01343
   Depledge MH, 2011, ENVIRON SCI TECHNOL, V45, P4660, DOI 10.1021/es103907m
   FERN EF, 1982, J MARKETING RES, V19, P1, DOI 10.2307/3151525
   Flores A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00531
   Freudenthaler L, 2017, MINDFULNESS, V8, P1339, DOI 10.1007/s12671-017-0709-y
   Gomez J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01611
   Gutteling JJ, 2008, BMC GASTROENTEROL, V8, DOI 10.1186/1471-230X-8-25
   Hayes AM, 2004, CLIN PSYCHOL-SCI PR, V11, P255, DOI 10.1093/clipsy/bph080
   Healium, 2021, MENT FITN HUM PERF P
   Hölzel BK, 2011, PERSPECT PSYCHOL SCI, V6, P537, DOI 10.1177/1745691611419671
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Jo H, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16234739
   Kabat-Zinn J, 2003, CLIN PSYCHOL-SCI PR, V10, P144, DOI 10.1093/clipsy/bpg016
   KABATZINN J, 1982, GEN HOSP PSYCHIAT, V4, P33, DOI 10.1016/0163-8343(82)90026-3
   KABATZINN J, 1985, J BEHAV MED, V8, P163, DOI 10.1007/BF00845519
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khoury B, 2017, MINDFULNESS, V8, P1160, DOI 10.1007/s12671-017-0700-7
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Lindsay EK, 2017, CLIN PSYCHOL REV, V51, P48, DOI 10.1016/j.cpr.2016.10.011
   Lippelt DP, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01083
   Luberto Christina M, 2020, Glob Adv Health Med, V9, p2164956120905597, DOI 10.1177/2164956120905597
   Lukoff K, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P1551, DOI [10.1145/3357236.3395444, 10.1145/10.1145/3357236.3395444]
   Lutz A, 2007, CAMB HANDB PSYCHOL, P499
   Lymeus F, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01560
   Lymeus F, 2019, J ENVIRON PSYCHOL, V64, P98, DOI 10.1016/j.jenvp.2019.05.008
   Monti DA, 2006, PSYCHO-ONCOL, V15, P363, DOI 10.1002/pon.988
   Mott ME, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI [10.1145/3396956.3396969, 10.1145/3373625.3416998]
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Niksirat KS, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3359593
   Patibanda R, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P19, DOI 10.1145/3116595.3116621
   Pradhan EK, 2007, ARTHRIT RHEUM-ARTHR, V57, P1134, DOI 10.1002/art.23010
   Prpa M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P71, DOI 10.1145/3196709.3196765
   Reina CS, 2020, ORGAN BEHAV HUM DEC, V159, P78, DOI 10.1016/j.obhdp.2019.11.008
   Roquet CD, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188616
   Seabrook E, 2020, J MED INTERNET RES, V22, DOI 10.2196/16106
   Sephton SE, 2007, ARTHRIT RHEUM-ARTHR, V57, P77, DOI 10.1002/art.22478
   Sevilla-Llewellyn-Jones J, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10278
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sliwinski J, 2015, LECT NOTES COMPUT SC, V9298, P167, DOI 10.1007/978-3-319-22698-9_12
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sutcliffe AG, 2019, INT J HUM-COMPUT INT, V35, P168, DOI 10.1080/10447318.2018.1443898
   Tang KC, 1995, FAM PRACT, V12, P474, DOI 10.1093/fampra/12.4.474
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Terzimehic N., 2019, P 2019 CHI C HUM FAC, P113, DOI [10.1145/3290605.3300687, DOI 10.1145/3290605.3300687]
   Thomas DR, 2006, AM J EVAL, V27, P237, DOI 10.1177/1098214005283748
   Tremblay MC, 2010, COMMUN ASSOC INF SYS, V26, P599
   Vidyarthi J., 2013, CHI '13 Extended Abstracts on Human Factors in Computing Systems (CHI EA '13), P2305, DOI [DOI 10.1145/2468356.2468753, 10.1145/2468356.2468753]
NR 72
TC 2
Z9 2
U1 3
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 21
PY 2022
VL 2
AR 672556
DI 10.3389/frvir.2021.672556
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TB5
UT WOS:001021823800001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Stellmacher, C
   Bonfert, M
   Kruijff, E
   Schöning, J
AF Stellmacher, Carolin
   Bonfert, Michael
   Kruijff, Ernst
   Schoening, Johannes
TI Triggermuscle: Exploring Weight Perception for Virtual Reality Through
   Adaptive Trigger Resistance in a Haptic VR Controller
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptics; virtual reality; weight perception; adaptive trigger;
   controller design; psychophysics
ID PRECISION; INFORMATION; MECHANISMS; DOMINANCE; FORCES; CUES
AB It is challenging to provide users with a haptic weight sensation of virtual objects in VR since current consumer VR controllers and software-based approaches such as pseudo-haptics cannot render appropriate haptic stimuli. To overcome these limitations, we developed a haptic VR controller named Triggermuscle that adjusts its trigger resistance according to the weight of a virtual object. Therefore, users need to adapt their index finger force to grab objects of different virtual weights. Dynamic and continuous adjustment is enabled by a spring mechanism inside the casing of an HTC Vive controller. In two user studies, we explored the effect on weight perception and found large differences between participants for sensing change in trigger resistance and thus for discriminating virtual weights. The variations were easily distinguished and associated with weight by some participants while others did not notice them at all. We discuss possible limitations, confounding factors, how to overcome them in future research and the pros and cons of this novel technology.
C1 [Stellmacher, Carolin; Bonfert, Michael] Univ Bremen, Fac Math & Comp Sci, Bremen, Germany.
   [Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, St Augustin, Germany.
   [Schoening, Johannes] Univ St Gallen, Sch Comp Sci, St Gallen, Switzerland.
C3 University of Bremen; Hochschule Bonn Rhein Sieg; University of St
   Gallen
RP Stellmacher, C (corresponding author), Univ Bremen, Fac Math & Comp Sci, Bremen, Germany.
EM cstellma@uni-bremen.de
OI Schoning, Johannes/0000-0002-8823-4607; Bonfert,
   Michael/0000-0002-3605-6693
FU Lichtenberg Professorship of the Volkswagen Foundation; BMBF project
   InviDas [16SV853]; Klaus Tschira Foundation
FX This work was partially funded by a Lichtenberg Professorship of the
   Volkswagen Foundation as well as the BMBF project InviDas (16SV853). In
   addition, the Klaus Tschira Foundation supported a co-author with a PhD
   scholarship.
CR 3D Systems, 2021, PHANT PREM
   [Anonymous], 1994, P ASME WINT ANN M S
   [Anonymous], 1994, DYNAMICS SYSTEMS CON
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Ban Y., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P211, DOI 10.1109/HAPTIC.2012.6183793
   Ben-Tzvi P, 2015, IEEE T NEUR SYS REH, V23, P992, DOI 10.1109/TNSRE.2014.2378171
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Bonfert M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P604, DOI [10.1109/VR.2019.8797824, 10.1109/vr.2019.8797824]
   Bouzit M, 2002, IEEE-ASME T MECH, V7, P256, DOI 10.1109/TMECH.2002.1011262
   BRODIE EE, 1984, PERCEPT PSYCHOPHYS, V36, P477, DOI 10.3758/BF03207502
   Burdea G., 1992, Presence, V1, P18
   CDC, 2020, HAPTX GLOV
   Chen CW, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351436
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   Degraen D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300479
   Dominjon L, 2005, P IEEE VIRT REAL ANN, P19
   Ellis RR, 1999, PERCEPT PSYCHOPHYS, V61, P1564, DOI 10.3758/BF03213118
   ELLIS RR, 1993, PERCEPT PSYCHOPHYS, V53, P315, DOI 10.3758/BF03205186
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   FLANAGAN JR, 1995, PERCEPT PSYCHOPHYS, V57, P282, DOI 10.3758/BF03213054
   Gabardi M, 2016, IEEE HAPTICS SYM, P140, DOI 10.1109/HAPTICS.2016.7463168
   Giannopoulos Elias, 2012, International Journal of Virtual Reality, V11, P19
   Girard Adrien., 2016, FRONT ROBOT AI, V3, P1, DOI DOI 10.3389/FICT.2016.00006
   GORDON AM, 1991, EXP BRAIN RES, V83, P477
   Gu XC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1991, DOI 10.1145/2858036.2858487
   Guilford J. P., 1955, PSYCHOMETRIC METHODS, V2nd edn.
   Hecht D, 2009, EXP BRAIN RES, V193, P307, DOI 10.1007/s00221-008-1626-z
   Heo S, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186544
   Hirose M, 2001, P IEEE VIRT REAL ANN, P123, DOI 10.1109/VR.2001.913778
   Ishii M., 1994, PRESENCE, V3, P81, DOI DOI 10.L162/PRES.1994.3.1.81
   Je SWO, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P763, DOI 10.1145/3332165.3347926
   Jenmalm P, 1997, J NEUROSCI, V17, P4486
   JOHANSSON RS, 1984, EXP BRAIN RES, V56, P550
   JOHANSSON RS, 1988, EXP BRAIN RES, V71, P59
   Jones LA, 2013, IEEE T HAPTICS, V6, P268, DOI 10.1109/TOH.2012.74
   KACZMAREK KA, 1991, IEEE T BIO-MED ENG, V38, P1, DOI 10.1109/10.68204
   Kurita Y., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2127, DOI 10.1109/IROS.2011.6048180
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Leonardis D, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P388, DOI 10.1109/WHC.2015.7177743
   Liu YH, 2019, ACM SIGGRAPH 2019 EMERGING TECHNOLOGIES (SIGGRAPH '19), DOI 10.1145/3305367.3327991
   Loomis J.M., 1986, Handbook of Perception and Human Performance, VII, P1, DOI DOI 10.1167/9.8.1126
   Lopes P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1471, DOI 10.1145/3025453.3025600
   Maereg AT, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00042
   Maiero J, 2019, IEEE T HAPTICS, V12, P483, DOI 10.1109/TOH.2019.2911519
   Maisto M, 2017, IEEE T HAPTICS, V10, P511, DOI 10.1109/TOH.2017.2691328
   Manus, 2020, PRIM 2 MOC GLOV
   Marquardt A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281525
   Martínez J, 2016, IEEE COMPUT GRAPH, V36, P42, DOI 10.1109/MCG.2014.81
   MCCLOSKEY DI, 1974, NEUROPSYCHOLOGIA, V12, P513, DOI 10.1016/0028-3932(74)90081-5
   Microsoft, 2021, XBOX EL WIR CONTR
   Minamizawa K., 2007, ACM SIGGRAPH 2007 EM, P8, DOI DOI 10.1145/1278280.1278289
   Minamizawa K, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P133
   Mizuno T, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON)
   Neung Ryu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1035, DOI 10.1145/3379337.3415862
   Nisar S, 2019, IEEE ROBOT AUTOM LET, V4, P351, DOI 10.1109/LRA.2018.2890198
   Pacchierotti C, 2016, IEEE HAPTICS SYM, P134, DOI 10.1109/HAPTICS.2016.7463167
   POSNER MI, 1976, PSYCHOL REV, V83, P157, DOI 10.1037/0033-295X.83.2.157
   Provancher WilliamR., 2014, IQT Quarterly, V6, P18
   Rietzler M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173702
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Sato M., 2002, 8 INT C VIRTUAL SYST, P1034
   Scheggi Stefano, 2010, 2010 RO-MAN: The 19th IEEE International Symposium on Robot and Human Interactive Communication, P44, DOI 10.1109/ROMAN.2010.5598632
   Schorr SB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3115, DOI 10.1145/3025453.3025744
   Schutt H. H., 2019, PSIGNIFIT
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Shigeyama J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300241
   SIMPSON WA, 1988, PERCEPT PSYCHOPHYS, V44, P433, DOI 10.3758/BF03210427
   Sinclair M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P815, DOI 10.1145/3332165.3347891
   Solazzi M, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P409
   Sony, 2020, DUALS WIR CONTR
   Stellmacher C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P201, DOI 10.1109/VRW52623.2021.00044
   Strasnick E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174218
   Suchoski JM, 2018, IEEE INT CONF ROBOT, P484
   Sun YQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300682
   Tsai HR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300450
   van Polanen V, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00700
   VOGEL GERMANY, 2021, EL DIG VIBR MET
   WESTLING G, 1984, EXP BRAIN RES, V53, P277
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Yu R, 2020, IEEE T VIS COMPUT GR, V26, P2094, DOI 10.1109/TVCG.2020.2973056
   Zenner A, 2021, IEEE T VIS COMPUT GR, V27, P2627, DOI 10.1109/TVCG.2021.3067777
   Zenner A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300441
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
NR 84
TC 4
Z9 4
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 14
PY 2022
VL 2
AR 754511
DI 10.3389/frvir.2021.754511
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TY8
UT WOS:001021847100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Appel, L
   Appel, E
   Kisonas, E
   Pasat, Z
   Mozeson, K
   Vemulakonda, J
   Sheng, LC
AF Appel, Lora
   Appel, Eva
   Kisonas, Erika
   Pasat, Zain
   Mozeson, Khrystyna
   Vemulakonda, Jaydev
   Sheng, Lacey (Qing)
TI Virtual Reality for Veteran Relaxation (VR<SUP>2</SUP>) - Introducing
   VR-Therapy for Veterans With Dementia - Challenges and Rewards of the
   Therapists Behind the Scenes
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; long term care; non-pharmacologic; recreational
   therapist; recreational therapy; activities; dementia; behavioural and
   psychiatric symptoms of dementia; responsive behaviour
ID PSYCHOLOGICAL SYMPTOMS; MANAGEMENT; RISK; CARE; PAIN
AB Background: Many veterans with dementia placed in long term care exhibit responsive behaviours such as physical and verbal responsiveness (e.g., shouting, hitting, biting, grabbing). Responsive behaviours lead to negative clinical outcomes, staff burnout, contribute to absenteeism, low engagement, and an elevated risk of abuse or neglect. Virtual Reality (VR) has shown great promise in relieving stress and improving quality of life in frail older adults and has been increasingly explored as a non-pharmacological therapy for people with dementia. Ongoing studies are evaluating the clinical outcomes of VR-therapy for this population, but the challenges and learnings of the healthcare providers who administer VR-therapy remain under-reported.Objective: Capture the experiences of Recreational Therapists (RTs) who conducted study sessions and administered VR-therapy to residents with dementia as part of a clinical trial that took place at the Perley and Rideau Veterans' Health Centre. We collected: RTs' feedback on the process of conducting research, specifically with respect to technical, environmental and personal challenges, learnings, and recommendations.Methods: In-depth interviews were conducted with all seven RTs who administered VR-therapy and collected data for a trial that took place from January-December 2019. Interviews were audio-recorded, transcribed, anonymized, and imported into the NVivo analysis tool, where two independent researchers coded the interviews into themes.Results: RTs reported ease in learning to use the VR-technology, main challenges were unfamiliarity with, and insufficient time allocated to, conducting research. Scheduled VR-therapy sessions were physically and emotionally easier for the RTs to administer. Despite RTs hesitations to place the VR-equipment on frail individuals in distress, RTs reported positive impacts on managing responsive behaviours during these few targeted sessions, especially for participants for whom the trigger was related to physical pain rather than emotional distress. Staff have continued to offer scheduled VR-therapy sessions beyond the duration of the study.Conclusion: The experience of using VR in the veteran resident population is generally positive. Areas for improvements including better support to the RTs regarding to novel interventions and research method. Feedback received from RTs in this study provides critical information to support successful, sustainable implementation of VR-therapy, both for further evaluation and as a regular activity program. Failure to consider the experiences of these vital stakeholders when developing novel interventions contributes to the gap between efficacy in research and effectiveness in practice.
C1 [Appel, Lora; Pasat, Zain; Mozeson, Khrystyna; Vemulakonda, Jaydev] York Univ, Fac Hlth, Sch Hlth Policy & Management, Toronto, ON, Canada.
   [Appel, Lora; Appel, Eva; Kisonas, Erika] Univ Hlth Network UHN, OpenLab, Toronto, ON, Canada.
   [Sheng, Lacey (Qing)] Perley & Rideau Vet Hlth Ctr, Ottawa, ON, Canada.
C3 York University - Canada; University of Toronto; University Health
   Network Toronto
RP Appel, L (corresponding author), York Univ, Fac Hlth, Sch Hlth Policy & Management, Toronto, ON, Canada.; Appel, L (corresponding author), Univ Hlth Network UHN, OpenLab, Toronto, ON, Canada.
EM lora.appel@uhn.ca
OI Kisonas, Erika/0000-0001-7806-2285
CR [Anonymous], 1996, USABILITY EVALUATION, DOI [10.1201/9781498710411-35, DOI 10.1201/9781498710411-35]
   Appel L, 2021, JMIR FORM RES, V5, DOI 10.2196/22406
   Appel L, 2020, PILOT FEASIBILITY ST, V6, DOI 10.1186/s40814-020-00708-9
   Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Beason-Held LL, 2013, J NEUROSCI, V33, P18008, DOI 10.1523/JNEUROSCI.1402-13.2013
   Bourbonnais A, 2010, INT PSYCHOGERIATR, V22, P1172, DOI 10.1017/S1041610209991670
   Canadian Institute for Health Information, 2018, Dementia in Canada-Summary
   Canadian Institute for Health Information, 2019, INT RAI MDS RE UNPUB
   Carr DB, 1999, LANCET, V353, P2051, DOI 10.1016/S0140-6736(99)03313-9
   Cerejeira J, 2012, Front Neurol, V3, P73, DOI 10.3389/fneur.2012.00073
   Charles J., 2020, HOSP NEWS
   Charmaz K., 2012, HDB INTERVIEW RES CO, V2, P347, DOI DOI 10.4135/9781452218403.N25
   Chun Tie Y, 2019, SAGE OPEN MED, V7, DOI 10.1177/2050312118822927
   Clay F, 2020, J ALZHEIMERS DIS, V75, P23, DOI 10.3233/JAD-191218
   D'Cunha NM, 2019, GERONTOLOGY, V65, P430, DOI 10.1159/000500040
   Dornyei Z., 2007, RES METHODS APPL LIN, P140
   Dunt D., 2012, IMPACT WAR EXPERIENC
   Dyer SM, 2018, INT PSYCHOGERIATR, V30, P295, DOI 10.1017/S1041610217002344
   Fuh Jong-Ling, 2006, Acta Neurol Taiwan, V15, P154
   Hammersley M., 2008, QUESTIONING QUALITAT, DOI DOI 10.4135/9780857024565.D7
   Hertogh CMPM, 2004, SOC SCI MED, V59, P1685, DOI 10.1016/j.socscimed.2004.02.015
   Islam MS, 2017, BMC NURS, V16, DOI 10.1186/s12912-017-0216-4
   Khandkar S. H., 2021, OPEN CODING, DOI [10.3390/ifou2018-05936, DOI 10.3390/IFOU2018-05936]
   Lewis-Beck M.S., 2004, SAGE ENCY SOCIAL SCI, V1-0, DOI DOI 10.4135/9781412950589
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Liu Y, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00280
   Makris UE, 2014, JAMA-J AM MED ASSOC, V312, P825, DOI 10.1001/jama.2014.9405
   Matsangidou Maria, 2020, Universal Access in Human-Computer Interaction. Design Approaches and Supporting Technologies. 14th International Conference, UAHCI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12188), P366, DOI 10.1007/978-3-030-49282-3_26
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Miyamoto Y, 2010, GERIATR NURS, V31, P246, DOI 10.1016/j.gerinurse.2010.01.002
   Morgan DG, 2012, J AM MED DIR ASSOC, V13, P220, DOI 10.1016/j.jamda.2011.07.003
   Oculus Go, EXP NEXT LEV WIR VR
   Phu S, 2019, CLIN INTERV AGING, V14, P1567, DOI 10.2147/CIA.S220890
   Richards K, 2003, QUALITATIVE INQUIRY IN TESOL, P1, DOI 10.1057/9780230505056
   Scales K, 2018, GERONTOLOGIST, V58, pS88, DOI 10.1093/geront/gnx167
   Snowdon DA, 1997, GERONTOLOGIST, V37, P150, DOI 10.1093/geront/37.2.150
   Song JA, 2015, ARCH PSYCHIAT NURS, V29, P346, DOI 10.1016/j.apnu.2015.06.004
   Tanaka K, 2015, INT J GERONTOL, V9, P161, DOI 10.1016/j.ijge.2015.04.001
   University of South Australia, 2007, ANT DEM VET MATES
   Veterans Affairs Canada, 2019, INTR VET AFF CAN 1 0
   Yaffe K, 2010, ARCH GEN PSYCHIAT, V67, P608, DOI 10.1001/archgenpsychiatry.2010.61
NR 41
TC 3
Z9 3
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 2
PY 2021
VL 2
AR 720523
DI 10.3389/frvir.2021.720523
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SZ5
UT WOS:001021821800001
OA gold
DA 2024-07-18
ER

PT J
AU Neuwirth, LS
   Ros, M
AF Neuwirth, Lorenz S.
   Ros, Maxime
TI Comparisons Between First Person Point-of-View 180° Video Virtual
   Reality Head-Mounted Display and 3D Video Computer Display in Teaching
   Undergraduate Neuroscience Students Stereotaxic Surgeries
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE stereotaxic surgery; virtual reality; Revinax; video virtual reality
   head-mounted display; 3D video computer display
AB Introduction: Students interested in neuroscience surgical applications learn about stereotaxic surgery mostly through textbooks that introduce the concepts but lack sufficient details to provide students with applied learning skills related to biomedical research. The present study employed a novel pedagogical approach which used an immersive virtual reality (VR) alternative to teach students stereotaxic surgery procedures through the point of view (POV) of the neuroscientist conducting the research procedures.Methods: The study compared the 180 & DEG; video virtual reality head-mounted display (180 & DEG; video VR HMD) and the 3D video computer display groups to address the learning gaps created by textbooks that insufficiently teach stereotaxic surgery, by bringing students into the Revinax(& REG;) Virtual Training Solutions educational instruction platform/technology. Following the VR experience, students were surveyed to determine their ratings of the learning content and comprehension of the material and how it compared to a traditional lecture, an online/hybrid lecture, and YouTube/other video content, as well as whether they would have interest in such a pedagogical tool.Results: The 180 & DEG; video VR HMD and the 3D video computer display groups helped students attend to and learn the material equally, it improved their self-study, and they would recommend that their college/university invest in this type of pedagogy. Students reported that both interventions increased their rate of learning, their retention of the material, and its translatability. Students equally preferred both interventions over traditional lectures, online/hybrid courses, textbooks, and YouTube/other video content to learn stereotaxic surgery.Conclusion: Students preferred to learn in and achieve greater learning outcomes from both the 180 & DEG; video VR HMD and the 3D video computer display over other pedagogical instructional formats and thought that it would be a more humane alternative to show how to conduct the stereotaxic surgical procedure without having to unnecessarily use/practice and/or demonstrate on an animal. Thus, this pedagogical approach facilitated their learning in a manner that was consistent with the 3-Rs in animal research and ethics. The 180 & DEG; video VR HMD and the 3D video computer display can be a low-cost and effective pedagogical option for distance/remote learning content for students as we get through the COVID-19 pandemic or for future alternative online/hybrid classroom instruction to develop skills/reskill/upskill in relation to neuroscience techniques.
C1 [Neuwirth, Lorenz S.] SUNY Old Westbury, Dept Psychol, Old Westbury, NY 11568 USA.
   [Neuwirth, Lorenz S.] SUNY Neurosci Res Inst, Old Westbury, NY 11568 USA.
   [Ros, Maxime] Montpellier Univ, Educt Sci Sch, LIRDEF, Montpellier, France.
C3 State University of New York (SUNY) System; SUNY Old Westbury;
   Universite de Montpellier
RP Neuwirth, LS (corresponding author), SUNY Old Westbury, Dept Psychol, Old Westbury, NY 11568 USA.; Neuwirth, LS (corresponding author), SUNY Neurosci Res Inst, Old Westbury, NY 11568 USA.
EM neuwirthl@oldwestbury.edu
RI Neuwirth, Lorenz S./AAE-3879-2019
OI Neuwirth, Lorenz S./0000-0002-8194-522X
CR Ai ZM, 2002, STUD HEALTH TECHNOL, V85, P24
   Alfalah SFM, 2019, VIRTUAL REAL-LONDON, V23, P229, DOI 10.1007/s10055-018-0359-y
   Andersen SAW, 2016, J SURG EDUC, V73, P45, DOI 10.1016/j.jsurg.2015.09.010
   Angevine J.B., 1981, Principles of neuroanatomy
   [Anonymous], [No title captured]
   [Anonymous], 2002, SPINAL CORD GESTATIO, DOI DOI 10.1201/9781420040180
   [Anonymous], 2003, GUIDELINES CARE USE
   Bergeron L., 2005, Rite of passage for first-year medical school students: Meeting their cadavers
   Bogdanske J. J., 2011, LAB RAT PROCEDURAL T
   Bradley W. G., 1989, MRI ATLAS BRAIN
   Cardon AD, 2012, J AM ASSOC LAB ANIM, V51, P301
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Committee for the Update of the Guide for the Care and Use of Laboratory Animals IfLAR Division on Earth and Life Studies and National Research Council, 2010, Guide for the Care and Use of Laboratory Animals, V8th edn
   Cooley R. K., 1978, STEREOTAXIC SURG RAT
   DeArmond SJ., 1989, Structure of the human brain. A photographic atlas
   DeLucchi M.R., 1965, A stereotaxic atlas of the chimpanzee brain [Pan satyrus
   Eadens D. M., 2021, HDB RES LESSONS LEAR, P277
   Fiorella L, 2017, J EDUC PSYCHOL, V109, P653, DOI 10.1037/edu0000161
   Foster G. A., 1988, CHEM NEUROANATOMY PR
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Gelles LA, 2020, EDUC SCI, V10, DOI 10.3390/educsci10110304
   [Gergen JA. National Institutes of Health (U.S.) National Institutes of Health (U.S.)], 1962, STEREOTAXIC ATLAS SQ
   Gilman S., 1991, MANTER GATZS ESSENTI, V7th Edn
   Izard SG, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0900-2
   Gould D. G., 2008, SIDMANS NEUROANATOMY, V2nd Edn
   Haines DE., 2008, Neuroanatomy: An atlas of structures, sections, and systems, V7th
   Harpe SE, 2015, CURR PHARM TEACH LEA, V7, P836, DOI 10.1016/j.cptl.2015.08.001
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Jacobson S., 2018, NEUROANATOMY NEUROSC, V3rd Edn, DOI [10.1007/978-3-319-60187-8, DOI 10.1007/978-3-319-60187-8]
   Karten H. J., 1967, A Stereotaxic Atlas of the Brain of the Pigeon (Columba livia)
   Kourtesis P, 2020, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00012
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Kurillo G, 2011, STUD HEALTH TECHNOL, V163, P290, DOI 10.3233/978-1-60750-706-2-290
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Lawrence A. J., 1997, NEUROSCIENCE METHODS
   Lim RobertK. S., 1960, STEREOTAXIC ATLAS DO
   Lysenko E., 2021, SHS WEB C UL, V92, P01026, DOI [10.1051/shsconf/20219201026, DOI 10.1051/SHSCONF/20219201026]
   Mamun M. A. A., 2021, RES SQUARE, P1, DOI [10.21203/rs.3.rs-374991/v1, DOI 10.21203/RS.3.RS-374991/V1]
   Martin J.H., 1996, Neuroanatomy, text and atlas
   Martin R., 1998, NEUROSCIENCE METHODS
   McCormack TJ., 2021, Journal of Education and Development, V5, P10, DOI DOI 10.20849/JED.V5I1.848
   Montemurro DG, 1972, STEREOTAXIC ATLAS DI
   Mukherji BR, 2017, SAGE OPEN, V7, DOI 10.1177/2158244017707796
   Neuwirth L.S., 2018, VISUAL APPROACHES CO, P283, DOI [DOI 10.4018/978-1-5225-5332-8.CH012, 10.4018/978-1-5225-5332-8.ch012]
   Neuwirth Lorenz S, 2018, J Undergrad Neurosci Educ, V16, pE26
   NEUWIRTH LS, 2019, VIRTUAL REALITY ED B, P511
   O'Rahilly R., 1994, EMBRYONIC HUMAN BRAI
   O'Sullivan S., 2021, SSRN, DOI [10.2139/ssrn.3787260, DOI 10.2139/SSRN.3787260]
   Office of Laboratory Animal Welfare, 2015, PHS POL HUM CAR US L
   Paxinos G, 1998, RAT BRAIN IN STEREOTAXIC COORDINATES, FOURTH ED., pix
   Paxinos G., 1985, RAT NERVOUS SYSTEM
   Perrett S. P., 1997, NEUROSCIENCE METHODS
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Pritchett-Corning K., 2010, HDB CLIN SIGNS RODEN
   Prus A., 2020, DRUGS NEUROSCIENCE B, V3rd Edn
   Ramachandra R., 2011, Atlas of the Neonatal Rat Brain
   Ros M, 2020, NEUROCHIRURGIE, V66, P212, DOI 10.1016/j.neuchi.2020.05.006
   Ros M, 2017, NEUROCHIRURGIE, V63, P1, DOI 10.1016/j.neuchi.2016.08.004
   Ros M., 2020, CASES INSTRUCTIONAL
   Ros M., 2020, US Patent App., Patent No. [16/341,070, 16341070]
   Ros M, 2021, ETR&D-EDUC TECH RES, V69, P1529, DOI 10.1007/s11423-021-10003-w
   Ros M, 2020, NURS EDUC TODAY, V91, DOI 10.1016/j.nedt.2020.104479
   RUSSELL W. M. S., 1959
   Schild J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P775, DOI 10.1109/VR.2018.8446160
   Sharp P. E., 1998, LAB RAT VOLUME LAB A
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slotnick B.M., 1975, STEREOTAXIC ATLAS AL
   Snider R., 1961, A stereotaxic atlas of the cat brain
   Somrak A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041185
   Ward J., 2015, The student's guide to cognitive neuroscience
   Woolsey T.A., 2008, The brain atlas: A visual guide to the human central nervous system, V3rd
   Zilles K., 1985, P1
NR 74
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 15
PY 2021
VL 2
AR 706653
DI 10.3389/frvir.2021.706653
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZL2
UT WOS:001019263800001
OA gold
DA 2024-07-18
ER

PT J
AU Niu, MT
   Lo, CH
   Yu, ZY
AF Niu, Mutian
   Lo, Cheng-Hung
   Yu, Zhiyuan
TI Embedding Virtual Reality Technology in Teaching 3D Design for Secondary
   Education
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE education technology; virtual reality; dual coding theory; design
   education; student creativity; pedagogical framework
ID MODELS LEARNING STYLES; DUAL CODING THEORY; STUDENTS; TEACHERS; DEMANDS;
   VR
AB As a new medium in modern education, virtual reality technology has stimulated the changes of pedagogical practice and added further opportunities for experiential learning. The immersive and interactive experience of VR fits seemingly well with practical subjects such as Creative Design. Design-related courses in secondary education usually appeal to the students with their practical elements, which also help in developing a student's creative and cognitive ability. The dual coding learning theory states that the learning process can be improved by using the symmetrical visual and language systems of the left and right hemispheres. This paper presents a novel teaching framework that combines classroom learning with VR technology. We devise the course structure based on Bloom's Taxonomy and fill in knowledge and skills related to 3D Design. In collaboration with a local school, we implemented and delivered the proposed course to a group of students. After the course, we use questionnaires and interviews to collect and analyze the attendees' feedback. The results show that the interactive experience in VR coincides better with the students' perception of 3D conceptual design. The teaching methods are also well-received by them. Based on the findings, we suggest that immersive VR technology is a promising tool for developing practical courses such as product design and development.
C1 [Niu, Mutian; Lo, Cheng-Hung; Yu, Zhiyuan] Xian Jiaotong Liverpool Univ, Sch Film & TV Arts, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University
RP Lo, CH (corresponding author), Xian Jiaotong Liverpool Univ, Sch Film & TV Arts, Suzhou, Peoples R China.
EM ch.lo@xjtlu.edu.cn
RI Yu, Zhiyuan/AAO-9155-2021
OI Yu, Zhiyuan/0000-0002-3880-1669; Lo, Cheng-Hung/0000-0002-7199-9339; Yu,
   Zhiyuan/0009-0001-4494-0833
FU External Research Project [RDS10120190074]; XJTLU Research Development
   Fund [RDF-16-02-22]
FX This project is partially-funded by the External Research Project
   (RDS10120190074) and XJTLU Research Development Fund (RDF-16-02-22).
CR Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Amran N, 2011, EDUC INFORM, V28, P325, DOI 10.3233/EFI-2010-0915
   Anderson L. W., 2001, A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives
   Barari N, 2022, INTERACT LEARN ENVIR, V30, P1640, DOI 10.1080/10494820.2020.1739078
   Bevins S, 2016, INT J SCI EDUC, V38, P17, DOI 10.1080/09500693.2015.1124300
   Bloom B.S., 1956, Taxonomy of educationalobjectives. HandbookI: The cognitive domain, DOI DOI 10.7312/DEBA15396-004
   Bogusevschi D., 2020, J COMPUT MATH SCI TE, V39, P5
   Brinson JR, 2015, COMPUT EDUC, V87, P218, DOI 10.1016/j.compedu.2015.07.003
   Bruno F., 2007, DS 42 P ICED 2007 16, P827
   Cai S, 2019, BRIT J EDUC TECHNOL, V50, P248, DOI 10.1111/bjet.12718
   Camba JD, 2017, LECT NOTES COMPUT SC, V10295, P3, DOI 10.1007/978-3-319-58509-3_1
   Chung CC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101673
   Cuevas J, 2018, THEORY RES EDUC, V16, P40, DOI 10.1177/1477878517731450
   Cuevas J, 2016, J EDUC SCI PSYCHOL, V6, P1
   Dabbagh N., 2003, TECH TRENDS, V47, P39, DOI DOI 10.1007/BF02763424
   Dahlstrom E., 2014, Educause
   Demirbas O. O., 2003, Design studies, V24, P437, DOI DOI 10.1016/S0142-694X(03)00013-9
   Demirkan H, 2008, DESIGN STUD, V29, P254, DOI 10.1016/j.destud.2008.01.002
   Dinis FM, 2017, IEEE GLOB ENG EDUC C, P1683, DOI 10.1109/EDUCON.2017.7943075
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Funnell MG, 2003, BRAIN COGNITION, V53, P218, DOI 10.1016/S0278-2626(03)00113-1
   Funnell MG, 2001, BRAIN COGNITION, V46, P135, DOI 10.1016/S0278-2626(01)80051-8
   Gazzaniga MS, 2005, NAT REV NEUROSCI, V6, P653, DOI 10.1038/nrn1723
   Graham M.A., 2020, Art Education, V73, P6, DOI DOI 10.1080/00043125.2020.1717820
   Gubrium JaberF., 2002, HDB INTERVIEW RES CO, DOI DOI 10.4135/9781412973588
   Guerrero G, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111775
   Hamurcu A., 2018, USER INSIGHTS USING, P1
   Hodes C.L., 1998, J VISUAL LITERACY, V18, P131
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jessen F, 2000, BRAIN LANG, V74, P103, DOI 10.1006/brln.2000.2340
   Jimeno-Morenilla A, 2016, BEHAV INFORM TECHNOL, V35, P897, DOI 10.1080/0144929X.2016.1215525
   Jones MG, 2016, INT J EDUC INF TECH, V10, P73
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kuo HC, 2017, THINK SKILLS CREAT, V24, P186, DOI 10.1016/j.tsc.2017.02.005
   Kvan T, 2005, DESIGN STUD, V26, P19, DOI 10.1016/j.destud.2004.06.004
   Laurillard D, 2013, J COMPUT ASSIST LEAR, V29, P15, DOI 10.1111/j.1365-2729.2011.00458.x
   Lee EAL, 2008, LECT NOTES COMPUT SC, V5080, P231
   Liang YW, 2016, EURASIA J MATH SCI T, V12, P1205
   Lin CH, 2017, MATEC WEB CONF, V104, DOI 10.1051/matecconf/201710403007
   Liu XH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050701
   Lovelace MK, 2005, J EDUC RES, V98, P176, DOI 10.3200/JOER.98.3.176-183
   Maheshwari I, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY TRENDS (ITT 2020), P7, DOI [10.1109/ITT51279.2020.9320779, 10.1109/itt51279.2020.9320779]
   Mahlios M.C., 2001, Children and stress. Understanding and helping, P65
   MAYER RE, 1991, J EDUC PSYCHOL, V83, P484, DOI 10.1037/0022-0663.83.4.484
   Mazoyer B, 2002, INT J PSYCHOL, V37, P204, DOI 10.1080/00207590244000007
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Muscat Martin, 2012, International Journal of Mechanical Engineering Education, V40, P66, DOI 10.7227/IJMEE.40.1.10
   Naimie Z, 2010, TURK ONLINE J EDUC T, V9, P83
   Nguyen V. T., 2017, SETTING VIRTUAL REAL, P315, DOI [10.1109/ISMAR-Adjunct.2017.97, DOI 10.1109/ISMAR-ADJUNCT.2017.97]
   Noel L.-A., 2016, DRS2016 FUTURE FOCUS, V2, DOI DOI 10.21606/DRS.2016.200
   Ogden W.R., 2003, Journal of Instructional Psychology, V30, P22
   PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295
   Pashler Harold, 2008, Psychol Sci Public Interest, V9, P105, DOI 10.1111/j.1539-6053.2009.01038.x
   Pellas N, 2017, EDUC INF TECHNOL, V22, P939, DOI 10.1007/s10639-016-9465-1
   Prezhdarova V., 2020, TRAKIA J SCI, V18, P183, DOI [10.15547/tjs.2020.03.001, DOI 10.15547/tjs.2020.03.001]
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Sampaio AZ, 2010, AUTOMAT CONSTR, V19, P819, DOI 10.1016/j.autcon.2010.05.006
   Sharps MJ, 1996, J GEN PSYCHOL, V123, P123, DOI 10.1080/00221309.1996.9921266
   Shih SL, 2019, ICEMT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON EDUCATION AND MULTIMEDIA TECHNOLOGY, P269, DOI 10.1145/3345120.3345150
   Siew N.M., 2017, The Eurasia Proceedings of Educational and Social Sciences, V6, P128
   Sims Ellen., 2012, EXPLORING MORE SIGNA, P55
   Stanberry AM, 2001, EDUC GERONTOL, V27, P639, DOI 10.1080/036012701317117884
   Stone R, 2001, INT J HUM-COMPUT ST, V55, P699, DOI 10.1006/ijhc.2001.0497
   Suh JM, 2007, PME CONFERENCE PROCE, P209
   Sulaiman Hidayah, 2020, 2020 IEEE Conference on e-Learning, e-Management and e-Services (IC3e), P1, DOI 10.1109/IC3e50159.2020.9288464
   Takala TM, 2016, INFORM EDUC, V15, P287, DOI 10.15388/infedu.2016.15
   Tang YM, 2020, VIRTUAL REAL-LONDON, V24, P797, DOI 10.1007/s10055-020-00427-9
   Vande Zande R., 2014, ART EDUC, V67, P20, DOI [10.1080/00043125.2014.11519294, DOI 10.1080/00043125.2014.11519294]
   Wang E., 2001, TEACHING FRESHMEN DE, V3, pF3G
   Welcome SE, 2011, EXP BRAIN RES, V212, P347, DOI 10.1007/s00221-011-2734-8
   Zhang H, 2020, INTERACT LEARN ENVIR, V28, P635, DOI 10.1080/10494820.2019.1709211
   Zhang R., 2018, P 2018 8 INT C SOC S, DOI [10.2991/sser-18.2018.143, DOI 10.2991/SSER-18.2018.143]
NR 72
TC 1
Z9 1
U1 10
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 28
PY 2021
VL 2
AR 661920
DI 10.3389/frvir.2021.661920
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SL6
UT WOS:001021807800001
OA gold
DA 2024-07-18
ER

PT J
AU Willis, D
   Stevens, B
   Powell, W
AF Willis, Dion
   Stevens, Brett
   Powell, Wendy
TI Visual Capture of a Tactile Sensation is Influenced by Repeated,
   Structured Exposure of a Visual Stimulus in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Visuo-tactile; Multisensory; Virtual reality; Phantom limb pain;
   Rehabilitation; Visual capture; Tactile localisation; Tactile acuity
ID PHANTOM LIMB PAIN; VENTRILOQUISM
AB Phantom limb pain is commonly known as a neurological condition, where an amputee will continue to feel a limb that is no longer present in a painful fashion. Virtual mirror therapy (VMT) has been suggested as a method for alleviating phantom limb pain. The inclusion of tactile sensation in VMT has shown to be beneficial; however, delivering a tactile sensation to a phantom limb, without the use of invasive procedures, can be difficult. The current approach for transferring a tactile sensation to a phantom limb is called visual capture. The ability to establish visual capture has been demonstrated in VMT applications. However, there is little research into whether an established visual capture effect can be relocated to a more distal location for phantom limb pain management. This paper investigates whether a passive vibrotactile sensation can be moved to a distal location from its veridical location using a series of distally located lights presented in either a random or a structured fashion. Eight non-amputee participants were tasked with localising a static tactile sensation on a virtual arm. These vibrotactile sensations were presented simultaneously with a visual light stimulus, either co-located or located distally at three different locations. Findings show that a tactile sensation without a visual stimulus was difficult for participants to localise; however, when a visual stimulus was added, they were better able to locate the veridical tactile position. The structured group exhibited a larger range of tactile relocation responses than the random group. However, this result was unreliable, with the majority of the responses situated at the vibrotactile actuator. There was a significant difference between the random and structured group's ability to retain a visual capture at the veridical vibrotactile location when the lights were located distally. The random group did not express a visual capture response when the lights were presented distally while the structured group did, suggesting the structured group developed a more robust association between the visual stimulus and the vibrotactile stimulus. Findings may be of use where increasing tactile acuity without significant alteration of a veridical location is a desired therapeutic outcome.
C1 [Willis, Dion; Stevens, Brett] Univ Portsmouth, Creat & Cultural Ind, Creat Technol, Portsmouth, England.
   [Powell, Wendy] Tilburg Univ, Tilburg Sch Humanities & Digital Sci, Dept Cognit Sci & Artificial Intelligence, MindLabs, Tilburg, Netherlands.
C3 University of Portsmouth; Tilburg University
RP Willis, D (corresponding author), Univ Portsmouth, Creat & Cultural Ind, Creat Technol, Portsmouth, England.
EM dion.willis@port.ac.uk
OI Stevens, Brett/0000-0003-1822-489X
CR Ackerley R, 2012, FRONT BEHAV NEUROSCI, V6, DOI 10.3389/fnbeh.2012.00051
   Badde S, 2020, COGNITION, V197, DOI 10.1016/j.cognition.2019.104170
   Barghout A, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENT AND GAMES, P19, DOI 10.1109/HAVE.2009.5356122
   Bosen AK, 2017, EXP BRAIN RES, V235, P585, DOI 10.1007/s00221-016-4820-4
   Carey M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39168-4
   Dunn J, 2017, NEUROREHABILITATION, V40, P595, DOI 10.3233/NRE-171447
   Finn SB, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00267
   Flor H, 2009, NEUROREHABILITATION, V25, P19, DOI 10.3233/NRE-2009-0496
   Frissen I, 2012, SEEING PERCEIVING, V25, P1, DOI 10.1163/187847611X620883
   Kuner R, 2017, NAT REV NEUROSCI, V18, P20, DOI 10.1038/nrn.2016.162
   Lamp G, 2019, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.01129
   Lee HJ, 2015, SENSORS-BASEL, V15, P7913, DOI 10.3390/s150407913
   Lee MWL, 2008, CLIN ANAT, V21, P363, DOI 10.1002/ca.20636
   Moseley GL, 2008, PAIN, V137, P600, DOI 10.1016/j.pain.2007.10.021
   Niijima A., 2014, INT C COLLABORATION, P86, DOI [10.1007/978-3-662-44651-5_8, DOI 10.1007/978-3-662-44651-5_8]
   Odegaard B, 2016, NEUROSCI LETT, V614, P24, DOI 10.1016/j.neulet.2015.12.039
   Ortiz-Catalan M, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00024
   Osumi M, 2020, NEUROCASE, V26, P55, DOI 10.1080/13554794.2019.1696368
   Osumi M, 2019, PAIN MED, V20, P1038, DOI 10.1093/pm/pny269
   Perry BN, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00770
   Pirowska A, 2014, NEUROL NEUROCHIR POL, V48, P52, DOI 10.1016/j.pjnns.2013.03.002
   Purves D., 2014, NEUROSCIENCE 2008
   Richardson C, 2017, J PAIN RES, V10, P1861, DOI 10.2147/JPR.S124664
   Samad M, 2018, PEERJ, V6, DOI 10.7717/peerj.4504
   Sano Y, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0161-6
   Shankar H, 2015, PAIN MED, V16, P777, DOI 10.1111/pme.12635
   Simoes-Franklin C, 2011, HUM BRAIN MAPP, V32, P1067, DOI 10.1002/hbm.21091
   Ueda S, 2008, ELECTR COMMUN JPN, V91, P29, DOI 10.1002/ecj.10000
   Wake N, 2015, I IEEE EMBS C NEUR E, P787, DOI 10.1109/NER.2015.7146741
   Weeks SR, 2010, NEUROLOGIST, V16, P277, DOI 10.1097/NRL.0b013e3181edf128
   Willis Dion, 2021, Figshare, DOI 10.6084/m9.figshare.14527068.v1
   Willis D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P484, DOI [10.1109/vr.2019.8798257, 10.1109/VR.2019.8798257]
   Zhang JJQ, 2018, NEURAL PLAST, V2018, DOI 10.1155/2018/2321045
NR 33
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 28
PY 2021
VL 2
AR 642061
DI 10.3389/frvir.2021.642061
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2ST0
UT WOS:001021815300001
OA gold
DA 2024-07-18
ER

PT J
AU Do, TD
   Zelenty, S
   Gonzalez-Franco, M
   Mcmahan, RP
AF Do, Tiffany D.
   Zelenty, Steve
   Gonzalez-Franco, Mar
   Mcmahan, Ryan P.
TI VALID: a perceptually validated Virtual Avatar Library for Inclusion and
   Diversity
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual avatars; race; perception; diversity; embodiment
ID IMPLICIT RACIAL BIAS; REALITY; FACES; CATEGORIZATION; RECOGNITION;
   IMPACT; AGENTS
AB As consumer adoption of immersive technologies grows, virtual avatars will play a prominent role in the future of social computing. However, as people begin to interact more frequently through virtual avatars, it is important to ensure that the research community has validated tools to evaluate the effects and consequences of such technologies. We present the first iteration of a new, freely available 3D avatar library called the Virtual Avatar Library for Inclusion and Diversity (VALID), which includes 210 fully rigged avatars with a focus on advancing racial diversity and inclusion. We also provide a detailed process for creating, iterating, and validating avatars of diversity. Through a large online study (n = 132) with participants from 33 countries, we provide statistically validated labels for each avatar's perceived race and gender. Through our validation study, we also advance knowledge pertaining to the perception of an avatar's race. In particular, we found that avatars of some races were more accurately identified by participants of the same race.
C1 [Do, Tiffany D.; Zelenty, Steve; Mcmahan, Ryan P.] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
   [Gonzalez-Franco, Mar] Google, Seattle, WA USA.
C3 State University System of Florida; University of Central Florida;
   Google Incorporated
RP Do, TD (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
EM tiffany.do@ucf.edu
FU University of Central Florida10.13039/100007900
FX No Statement Available
CR Ali MR, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423900
   Anzures G, 2013, CURR DIR PSYCHOL SCI, V22, P173, DOI 10.1177/0963721412474459
   Bainbridge WA, 2013, J EXP PSYCHOL GEN, V142, P1323, DOI 10.1037/a0033872
   Baylor A. L., 2003, Journal of Educational Computing Research, V28, P373, DOI 10.2190/V0WQ-NWGN-JB54-FAT4
   Baylor AL, 2009, PHILOS T R SOC B, V364, P3559, DOI 10.1098/rstb.2009.0148
   Bengfort Benjamin, 2018, Zenodo
   Bickmore T, 2021, PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA), P25, DOI 10.1145/3472306.3478365
   Blascovich J, 1997, J PERS SOC PSYCHOL, V72, P1364, DOI 10.1037/0022-3514.72.6.1364
   Blom KJ, 2014, PRESENCE-VIRTUAL AUG, V23, P287, DOI 10.1162/PRES_a_00194
   Boberg M., 2008, P 3 INT C DIG INT ME, P232, DOI DOI 10.1145/1413634.1413679
   Booth S., 2010, Challenging gender stereotypes using virtual pedagogical characters, P113, DOI DOI 10.4018/978-1-61520-813-5.CH007
   Butler C, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P773, DOI 10.1145/3126594.3126640
   Chapman EN, 2013, J GEN INTERN MED, V28, P1504, DOI 10.1007/s11606-013-2441-1
   Cheng YF, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517452
   Civile C, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17294-w
   DeBruine L., 2018, Debruine/webmorph: Beta release 2
   Dewez D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445379
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Gamberini L, 2015, COMPUT HUM BEHAV, V48, P104, DOI 10.1016/j.chb.2015.01.040
   Ge LZ, 2009, PERCEPTION, V38, P1199, DOI 10.1068/p6136
   Gilbert Juan E., 2008, International Journal of Virtual Reality, V7, P21
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Gonzalez-Franco M, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P91, DOI 10.1109/AIVR50618.2020.00026
   Gonzalez-Franco M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209704
   Gonzalez-Franco M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00392
   Groom V, 2009, SOC INFLUENCE, V4, P231, DOI 10.1080/15534510802643750
   Halan S, 2015, LECT NOTES ARTIF INT, V9238, P239, DOI 10.1007/978-3-319-21996-7_24
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Huang A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517593
   Hughes R., 2011, Real-time wrinkles for expressive virtual characters
   Iwabuchi K, 2010, ASIAN J COMMUN, V20, P197, DOI 10.1080/01292981003693385
   Jeong DC, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P274, DOI 10.1109/AIVR50618.2020.00056
   Jin D., 2021, Asian cultural studies: transnational and dialogic approaches
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   Jung S, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P60, DOI 10.1145/3267782.3267920
   Kawakami K., 2017, An integrative framework for understanding the causes and consequences of social categorization, P1, DOI [10.1016/bs.aesp.2016.10.001, DOI 10.1016/BS.AESP.2016.10.001]
   Kim Y, 2013, J EDUC PSYCHOL, V105, P1164, DOI 10.1037/a0031027
   Li JJ, 2021, ADJUNCT PROCEEDINGS OF THE 34TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2021, P17, DOI 10.1145/3474349.3480216
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   MacLin OH, 2001, PSYCHOL PUBLIC POL L, V7, P98, DOI 10.1037//1076-8971.7.1.98
   Maisuwong W., 2012, Int. J. Eng. Res. Technol. (IJERT), V1, P1
   Malik M., 2022, Comput. Commun. Res, V4, P208, DOI [DOI 10.33767/OSF.IO/3S7ND, 10.5117/ccr2022.1.006.mali, DOI 10.5117/CCR2022.1.006.MALI]
   Matthews K., 2017, National content test race and ethnicity analysis report
   McIntosh J., 2020, P 33 ANN ACM S US IN, P709, DOI DOI 10.1145/3379337.3415832
   Meissner CA, 2001, PSYCHOL PUBLIC POL L, V7, P3, DOI 10.1037//1076-8971.7.1.3
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Moreno R, 2006, CONTEMP EDUC PSYCHOL, V31, P186, DOI 10.1016/j.cedpsych.2005.05.002
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nag P, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423876
   Nicolas G, 2019, SOC PSYCHOL PERS SCI, V10, P532, DOI 10.1177/1948550618769591
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2021, IEEE T VIS COMPUT GR, V27, P2502, DOI 10.1109/TVCG.2021.3067767
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Peer E, 2017, J EXP SOC PSYCHOL, V70, P153, DOI 10.1016/j.jesp.2017.01.006
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Rhodes G, 2010, J EXP PSYCHOL LEARN, V36, P217, DOI 10.1037/a0017680
   Rhodes G, 2009, PERCEPTION, V38, P232, DOI 10.1068/p6110
   Salmanowitz N, 2018, J LAW BIOSCI, V5, P174, DOI 10.1093/jlb/lsy005
   Saneyoshi A, 2022, INT J HUM-COMPUT ST, V166, DOI 10.1016/j.ijhcs.2022.102871
   Scarpina F, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091330
   Setoh P, 2019, CHILD DEV, V90, P162, DOI 10.1111/cdev.12851
   Shapiro A, 2014, COMPUT ANIMAT VIRT W, V25, P201, DOI 10.1002/cav.1579
   Sheskin D.J., 2011, Handbook of Parametric and Nonparametric Statistical Procedures, DOI DOI 10.1201/9780429186196
   Sra Misha., 2015, INADJUNCT P 28 ANNUA, P47, DOI DOI 10.1145/2815585.2817802
   Taylor VJ, 2020, POL INS BEH BRAIN SC, V7, P132, DOI 10.1177/2372732220943638
   Thanikachalam S, 2019, DERMATOLOGY, V235, P260, DOI 10.1159/000497156
   Volonte M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P39, DOI 10.1109/VRW55335.2022.00015
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zipp SA, 2019, ETR&D-EDUC TECH RES, V67, P1385, DOI 10.1007/s11423-019-09647-6
NR 74
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 23
PY 2023
VL 4
AR 1248915
DI 10.3389/frvir.2023.1248915
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Z8RK6
UT WOS:001114690900001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Hadjipanayi, C
   Banakou, D
   Michael-Grigoriou, D
AF Hadjipanayi, Christos
   Banakou, Domna
   Michael-Grigoriou, Despina
TI Art as therapy in virtual reality: A scoping review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; art; psychotherapy; therapy; rehabilitation; wellbeing;
   new media
ID ILLUSORY OWNERSHIP; ENVIRONMENTS; TECHNOLOGY
AB This scoping review focuses on therapeutic interventions, which involve the creation of artworks in virtual reality. The purpose of this research is to survey possible directions that traditional practices of art therapy and therapeutic artmaking could take in the age of new media, with emphasis on fully immersive virtual reality. After the collection of papers from online databases, data from the included papers were extracted and analyzed using thematic analysis. The results reveal that virtual reality introduces novel opportunities for artistic expression, self-improvement, and motivation for psychotherapy and neurorehabilitation. Evidence that artmaking in virtual reality could be highly beneficial in therapeutic settings can be found in many aspects of virtual reality, such as its virtuality, ludicity, telepresence capacity, controlled environments, utility of user data, and popularity with digital natives. However, deficiencies in digital literacy, technical limitations of the current virtual reality devices, the lack of tactility in virtual environments, difficulties in the maintenance of the technology, interdisciplinary concerns, as well as aspects of inclusivity should be taken into consideration by therapy practitioners, researchers, and software developers alike. Finally, the reported results reveal implications for future practice.
C1 [Hadjipanayi, Christos; Banakou, Domna; Michael-Grigoriou, Despina] Cyprus Univ Technol, Dept Multimedia & G Arts, GET Lab, Limassol, Cyprus.
   [Banakou, Domna] New York Univ Abu Dhabi, Arts & Humanities Div, Abu Dhabi, U Arab Emirates.
C3 Cyprus University of Technology; New York University Abu Dhabi
RP Michael-Grigoriou, D (corresponding author), Cyprus Univ Technol, Dept Multimedia & G Arts, GET Lab, Limassol, Cyprus.
EM despina.grigoriou@cut.ac.cy
OI Hadjipanayi, Christos/0000-0001-7444-5406; Banakou,
   Domna/0000-0002-0974-6971
FU scholarship of academic excellence; Cyprus University of Technology
   [MICHAIL-300155-310200-3319]
FX This work has been funded through the scholarship of academic excellence
   granted to CH for his doctoral studies and the research and other
   activities budget ED-DESPINA MICHAIL-300155-310200-3319 of the Cyprus
   University of Technology.
CR Adams R., 2008, TRANSDISCIPLINARY DI, V7
   Alex M, 2021, INT J HUM-COMPUT ST, V145, DOI 10.1016/j.ijhcs.2020.102481
   Alqahtani AS, 2017, INT J ADV COMPUT SC, V8, P77
   Angheluta A. M., 2011, CAN J COUNS PSYCHOTH, V45
   Arkhipova S., 2022, REV TEMPOS ESPACOS E, V15, pe17214, DOI [10.20952/revtee.v15i34.17214, DOI 10.20952/REVTEE.V15I34.17214]
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Baldursson B. R., 2022, ADJ P 2022 NORD HUM, P1
   Bamodu Oluleke, 2013, Advanced Materials Research, V765-767, P1169, DOI 10.4028/www.scientific.net/AMR.765-767.1169
   Banakou D, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201848
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Baron Lauren, 2021, SUI '21: Symposium on Spatial User Interaction, DOI 10.1145/3485279.3485285
   Berkman M.I., 2019, ENCY COMPUTER GRAPHI, P1, DOI DOI 10.1007/978-3-319-08234-9_162-1
   Bertrand S, 2021, FRONT COMMUN, V6, DOI 10.3389/fcomm.2021.676446
   Biocca Frank, 2013, COMMUNICATION AGE VI
   Brahnam S, 2014, STUD HEALTH TECHNOL, V207, P153, DOI 10.3233/978-1-61499-474-9-153
   Brahnam S, 2014, LECT NOTES COMPUT SC, V8510, P273, DOI 10.1007/978-3-319-07233-3_26
   Brien SE, 2010, IMPLEMENT SCI, V5, DOI 10.1186/1748-5908-5-2
   Buk A, 2009, ART PSYCHOTHER, V36, P61, DOI 10.1016/j.aip.2009.01.008
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Carlton NR, 2014, ART PSYCHOTHER, V41, P41, DOI 10.1016/j.aip.2013.11.006
   Cheng C, 2023, IRISH J PSYCHOL MED, V40, P500, DOI 10.1017/ipm.2021.20
   Cheung KL., 2014, VIRTUAL REALITY PHYS, P5
   Christofi M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01242
   Coogan CG, 2018, IEEE ACCESS, V6, P10840, DOI 10.1109/ACCESS.2018.2809453
   Czamanski-Cohen J, 2014, ART PSYCHOTHER, V41, P320, DOI 10.1016/j.aip.2014.05.002
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Farmer H, 2018, MIND LANG, V33, P378, DOI 10.1111/mila.12189
   Farokhi M., 2011, Procedia-Social and Behavioral Sciences, V30, P2088, DOI [https://doi.org/10.1016/j.sbspro.2011.10.406, DOI 10.1016/J.SBSPRO.2011.10.406]
   Feniger-Schaal R, 2022, ART PSYCHOTHER, V78, DOI 10.1016/j.aip.2022.101898
   Finisguerra A, 2021, COGNITION, V212, DOI 10.1016/j.cognition.2021.104663
   Frewen P, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00858
   Gatto C, 2020, LECT NOTES COMPUT SC, V12243, P147, DOI 10.1007/978-3-030-58468-9_11
   Geraets CNW, 2021, CURR OPIN PSYCHOL, V41, P40, DOI 10.1016/j.copsyc.2021.02.004
   Hacmun I, 2021, ART PSYCHOTHER, V72, DOI 10.1016/j.aip.2020.101745
   Hacmun I, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02082
   Hadjipanayi C, 2022, VIRTUAL REAL-LONDON, V26, P343, DOI 10.1007/s10055-021-00568-5
   Haeyen S, 2021, ART PSYCHOTHER, V76, DOI 10.1016/j.aip.2021.101855
   Haeyen S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.704613
   Harley D, 2020, CONVERGENCE-US, V26, P1144, DOI 10.1177/1354856519860237
   HODGES LF, 1995, COMPUTER, V28, P27, DOI 10.1109/2.391038
   Iosa M, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.611956
   Jin R, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103287
   Joachimczak M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P847, DOI 10.1109/VRW55335.2022.00279
   Kaimal G, 2022, ART THER, V39, P128, DOI 10.1080/07421656.2021.1957341
   Kaimal G, 2020, ART THER, V37, P16, DOI 10.1080/07421656.2019.1659662
   Kaimal G, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.589461
   Kim G, 2018, LECT NOTES COMPUT SC, V10910, P94, DOI 10.1007/978-3-319-91584-5_8
   Kim Y, 2022, INT J HUM-COMPUT INT, V38, P371, DOI 10.1080/10447318.2021.1944534
   Kumarapeli D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P641, DOI 10.1109/VRW55335.2022.00176
   Kyrlitsias C, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.786665
   Li BL, 2022, EVID-BASED COMPL ALT, V2022, DOI 10.1155/2022/7358597
   Li G, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P151, DOI 10.1109/AIVR50618.2020.00034
   Liu YC, 2018, PROCEEDINGS OF THE 2018 1ST IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE INNOVATION AND INVENTION (ICKII 2018), P47, DOI 10.1109/ICKII.2018.8569081
   Liu Z, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19010232
   Maggio MG, 2022, APPL NEUROPSYCH-ADUL, V29, P59, DOI 10.1080/23279095.2019.1708364
   Malchiodi C., 2002, SOULS PALETTE DRAWIN
   Malchiodi C.A., 2020, TRAUMA EXPRESSIVE AR
   Malchiodi CA., 2011, Handbook of art therapy
   Marks K., 2017, AUST N J ARTS THER, V12, P99
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mishina AV, 2018, HELIX, V8, P2307, DOI 10.29042/2018-2307-2311
   Moller Henry J., 2020, Distributed, Ambient and Pervasive Interactions. 8th International Conference, DAPI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12203), P593, DOI 10.1007/978-3-030-50344-4_43
   Montana JI, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020500
   Moon CH, 2010, MATERIALS AND MEDIA IN ART THERAPY: CRITICAL UNDERSTANDINGS OF DIVERSE ARTISTIC VOCABULARIES, P1
   Mozgai S, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375219
   Orr P, 2012, ART PSYCHOTHER, V39, P234, DOI 10.1016/j.aip.2012.03.010
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Ouzzani M, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0384-4
   Pendse A, 2016, ACM SIGGRAPH 2016 VR VILLAGE (SIGGRAPH '16), DOI 10.1145/2929490.2932421
   Pifalo T, 2007, ART THER, V24, P170, DOI 10.1080/07421656.2007.10129471
   Pissini J., 2020, THESIS OHIO STATE U
   Richesin MT, 2021, ART PSYCHOTHER, V75, DOI 10.1016/j.aip.2021.101823
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Rosal M.L., 2018, Cognitive behavioral art therapy: From behaviorism to the third wave
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Rzeszewski M., 2020, ROZWOJ REGIONALNY PO, VRegionalna, P57, DOI DOI 10.14746/RRPR.2020.51.06
   Saffo David., 2021, P 2021 CHI C HUMAN F, DOI [10.1145/3411764.3445426, DOI 10.1145/3411764.3445426]
   Salles J, 2020, ANN MED-PSYCHOL, V178, P43, DOI 10.1016/j.amp.2019.11.009
   Sandmire DA, 2012, ART THER, V29, P68, DOI 10.1080/07421656.2012.683748
   Sandmire DA, 2016, ANXIETY STRESS COPIN, V29, P561, DOI 10.1080/10615806.2015.1076798
   Sarid O, 2010, ART PSYCHOTHER, V37, P8, DOI 10.1016/j.aip.2009.11.004
   SCHAVERIEN J., 2000, CHANGING SHAPE ART T
   Zeevi LS, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.584943
   Skinner M K, 1996, Rehabil Nurs, V21, P63
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slobounov SM, 2015, INT J PSYCHOPHYSIOL, V95, P254, DOI 10.1016/j.ijpsycho.2014.11.003
   Song M, 2019, ICIGP 2019: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING / 2019 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, P150, DOI 10.1145/3313950.3313978
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Vallance M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.779148
   Vizcay Sebastian, 2021, ARXIV, DOI [10.2312/egve.20211331, DOI 10.2312/EGVE.20211331]
   Wagener N, 2021, LECT NOTES COMPUT SC, V12935, P262, DOI 10.1007/978-3-030-85610-6_16
   Walker MS, 2016, ART PSYCHOTHER, V49, P10, DOI 10.1016/j.aip.2016.05.015
   Worden M., 2020, 17 JUNE DIFFERENCE A
   Xiong ZY, 2022, ART PSYCHOTHER, V80, DOI 10.1016/j.aip.2022.101934
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zhang YW, 2021, IEEE ENG MED BIO, P4513, DOI 10.1109/EMBC46164.2021.9629654
NR 100
TC 3
Z9 3
U1 10
U2 22
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 9
PY 2023
VL 4
AR 1065863
DI 10.3389/frvir.2023.1065863
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XK7
UT WOS:001023309300001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Plecher, DA
   Keil, L
   Kost, G
   Fiederling, M
   Eichhorn, C
   Klinker, G
AF Plecher, David A. A.
   Keil, Leonard
   Kost, Guy
   Fiederling, Max
   Eichhorn, Christian
   Klinker, Gudrun
TI Exploring underwater archaeology findings with a diving simulator in
   virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; archeology; diving simulator; cultural heritage;
   underwater archeology
ID IMMERSION
AB With Virtual Reality (VR) technology maturing and spreading widely in recent years, it is becoming an increasingly useful tool for entertainment and education alike. Its potential to simulate hard to reach environments and emulate unique experiences believably is of great interest for the scientific study of Underwater Cultural Heritage (UCH), in particular for the simulation of real-world dives. VR enriched with techniques from immersive Serious Games (SG) provide an authentic way to enjoy Underwater Cultural Heritage (UCH) and the sport of diving from the comfort of the user's home or as a museum exhibit. In this paper we are focusing on the exploration of the wreck of a Roman merchant ship from the 5th century AD, which was found near Veliki Piruzi (Croatia). The images taken by the underwater archaeologists enable a 3D reconstruction of the excavation site. The modular structure of the application makes it very easy to transfer the techniques presented to other excavation sites including information and objects.
C1 [Plecher, David A. A.; Keil, Leonard; Kost, Guy; Eichhorn, Christian; Klinker, Gudrun] TUM, FAR Augmented Real Res Grp, Munich, Germany.
   [Fiederling, Max] LMU, Fac Study Culture, Munich, Germany.
C3 Technical University of Munich; University of Munich
RP Plecher, DA (corresponding author), TUM, FAR Augmented Real Res Grp, Munich, Germany.
EM plecher@in.tum.de
RI Klinker, Gudrun/JVP-3665-2024
OI Klinker, Gudrun/0000-0003-0971-5726
CR Angelov V, 2020, 2ND INTERNATIONAL CONGRESS ON HUMAN-COMPUTER INTERACTION, OPTIMIZATION AND ROBOTIC APPLICATIONS (HORA 2020), P520, DOI 10.1109/hora49412.2020.9152604
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bruno F, 2017, INT ARCH PHOTOGRAMM, V42-2, P121, DOI 10.5194/isprs-archives-XLII-2-W3-121-2017
   Bruno F., 2016, Digital Heritage. Progress in Cultural Heritage: Documentation, Preservation, and Protection, P269
   Bruno F, 2018, VIRTUAL REAL-LONDON, V22, P91, DOI 10.1007/s10055-017-0318-z
   Canale N, 2022, J HAPPINESS STUD, V23, P727, DOI 10.1007/s10902-021-00421-1
   Caola B, 2018, PERCEPTION, V47, P477, DOI 10.1177/0301006618758211
   Cejka J, 2021, IEEE ACCESS, V9, P45017, DOI 10.1109/ACCESS.2021.3059978
   Chapman P., 2006, P JOINT EV CIPA VAST
   Clark C Abt, 1987, Serious Games
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Ding R, 2021, VISUAL COMPUT, V37, P2797, DOI 10.1007/s00371-021-02175-6
   Fauville G, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80100-y
   Fels S, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.20
   Fiederling M., 2019, BRODOLOM VELIKI PIRU, V2
   Froschauer J., 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P253, DOI 10.1109/VSMM.2010.5665978
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P227, DOI 10.1145/2984511.2984535
   Guidi G., 2007, WORKSH 3D VIRT REC V
   Hatsushika D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P962, DOI [10.1109/vr.2019.8798052, 10.1109/VR.2019.8798052]
   Haydar M, 2011, VIRTUAL REAL-LONDON, V15, P311, DOI 10.1007/s10055-010-0176-4
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Jain D, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P729, DOI 10.1145/2984511.2984519
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   Laha B, 2012, IEEE T VIS COMPUT GR, V18, P597, DOI 10.1109/TVCG.2012.42
   Liarokapis Fotis, 2020, HCI International 2020 - Late Breaking Papers. Virtual and Augmented Reality. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12428), P178, DOI 10.1007/978-3-030-59990-4_15
   Liarokapis F, 2017, INT ARCH PHOTOGRAMM, V42-2, P425, DOI 10.5194/isprs-archives-XLII-2-W3-425-2017
   Lindquist M, 2020, LANDSCAPE URBAN PLAN, V202, DOI 10.1016/j.landurbplan.2020.103884
   Miyashita T, 2008, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2008.4637334
   PADI, 2015, OP WAT DIV MAN PADI
   Parger M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281529
   Peiris RL, 2018, LECT NOTES COMPUT SC, V10894, P366, DOI 10.1007/978-3-319-93399-3_32
   Plecher D. A., 2020, ICAT EGVE 2020 INT C, DOI [10.2312/egve.20201258, DOI 10.2312/EGVE.20201258]
   Plecher DA, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3418038
   Plecher DA, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION EXTENDED ABSTRACTS (CHI PLAY 2018), P577, DOI 10.1145/3270316.3271536
   Plecher DA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1618, DOI [10.1109/VR.2019.8797846, 10.1109/vr.2019.8797846]
   De Lope RP, 2017, J EDUC COMPUT RES, V55, P629, DOI 10.1177/0735633116681301
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
NR 40
TC 3
Z9 3
U1 5
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 14
PY 2022
VL 3
AR 901335
DI 10.3389/frvir.2022.901335
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UZ5
UT WOS:001023245800001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Kruijff, E
   Riecke, BE
   Trepkowski, C
   Lindeman, RW
AF Kruijff, Ernst
   Riecke, Bernhard E. E.
   Trepkowski, Christina
   Lindeman, Robert W. W.
TI First insights in perception of feet and lower-body stimuli for
   proximity and collision feedback in 3D user interfaces
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptics; vibration; 3D user interface; perception; proximity; collision;
   feedback
ID PERIPERSONAL SPACE; MULTISENSORY INTEGRATION; REPRESENTATION; HAND;
   VIBRATION; VISION; THRESHOLDS; CONGRUENCY; LOCOMOTION; AVOIDANCE
AB The visual and auditory quality of computer-mediated stimuli for virtual and extended reality (VR/XR) is rapidly improving. Still, it remains challenging to provide a fully embodied sensation and awareness of objects surrounding, approaching, or touching us in a 3D environment, though it can greatly aid task performance in a 3D user interface. For example, feedback can provide warning signals for potential collisions (e.g., bumping into an obstacle while navigating) or pinpointing areas where one's attention should be directed to (e.g., points of interest or danger). These events inform our motor behaviour and are often associated with perception mechanisms associated with our so-called peripersonal and extrapersonal space models that relate our body to object distance, direction, and contact point/impact. We will discuss these references spaces to explain the role of different cues in our motor action responses that underlie 3D interaction tasks. However, providing proximity and collision cues can be challenging. Various full-body vibration systems have been developed that stimulate body parts other than the hands, but can have limitations in their applicability and feasibility due to their cost and effort to operate, as well as hygienic considerations associated with e.g., Covid-19. Informed by results of a prior study using low-frequencies for collision feedback, in this paper we look at an unobtrusive way to provide spatial, proximal and collision cues. Specifically, we assess the potential of foot sole stimulation to provide cues about object direction and relative distance, as well as collision direction and force of impact. Results indicate that in particular vibration-based stimuli could be useful within the frame of peripersonal and extrapersonal space perception that support 3DUI tasks. Current results favor the feedback combination of continuous vibrotactor cues for proximity, and bass-shaker cues for body collision. Results show that users could rather easily judge the different cues at a reasonably high granularity. This granularity may be sufficient to support common navigation tasks in a 3DUI.
C1 [Kruijff, Ernst; Trepkowski, Christina] Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, St Augustin, Germany.
   [Kruijff, Ernst; Riecke, Bernhard E. E.] Simon Faser Univ, Sch Interact Arts & Technol, Burnaby, BC, Canada.
   [Lindeman, Robert W. W.] Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
C3 Hochschule Bonn Rhein Sieg; University of Canterbury
RP Kruijff, E (corresponding author), Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, St Augustin, Germany.; Kruijff, E (corresponding author), Simon Faser Univ, Sch Interact Arts & Technol, Burnaby, BC, Canada.
EM ernst.kruijff@h-brs.de
FU DAAD [57130136]
FX This work was partly supported by funding from the DAAD (57130136).
CR Afonso C., 2011, AM 11 P 6 AUDIO MOST, P101
   Aguerrevere D., 2004, P 2 LACCEI C IEEE
   Ariza O, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P327, DOI 10.1109/VR.2018.8446317
   Avillac M, 2007, J NEUROSCI, V27, P1922, DOI 10.1523/JNEUROSCI.2646-06.2007
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Beckhaus S, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P387, DOI 10.1109/PCCGA.2000.883963
   Bernasconi F, 2018, CEREB CORTEX, V28, P3385, DOI 10.1093/cercor/bhy156
   Berning M, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P31, DOI 10.1145/2802083.2802088
   Blom KJ, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P35, DOI 10.1109/3DUI.2010.5444723
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   Brozzoli C, 2014, NEUROSCIENTIST, V20, P122, DOI 10.1177/1073858413511153
   Bufacchi RJ, 2018, TRENDS COGN SCI, V22, P1076, DOI 10.1016/j.tics.2018.09.004
   Burdea GRIGORE, 1996, Force and touch feedback for virtual reality
   Canzoneri E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044306
   Cinelli ME, 2008, GAIT POSTURE, V28, P596, DOI 10.1016/j.gaitpost.2008.04.006
   de Haan AM, 2016, EXP BRAIN RES, V234, P1875, DOI 10.1007/s00221-016-4571-2
   Oliveira VAD, 2017, IEEE T VIS COMPUT GR, V23, P1340, DOI 10.1109/TVCG.2017.2657238
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Fajen B.R., 2013, J VISION, V13, P120, DOI DOI 10.1167/13.9.120
   Feng M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P95, DOI 10.1109/3DUI.2016.7460037
   Field A., 2013, DISCOVERING STAT USI
   Gabbard C., 2015, PERCEPTION ACTION SP, DOI [10.1016/B978-0-08-097086-8.57009-3, DOI 10.1016/B978-0-08-097086-8.57009-3]
   Galli G, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00639
   Göschl F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106896
   Graziano MSA, 1998, CURR OPIN NEUROBIOL, V8, P195, DOI 10.1016/S0959-4388(98)80140-2
   Graziano MSA, 1999, P NATL ACAD SCI USA, V96, P10418, DOI 10.1073/pnas.96.18.10418
   Greenberg S., 2011, Interactions, V18, P42, DOI [DOI 10.1145/1897239.1897250, 10.1145/1897239.1897250]
   Grivaz P, 2017, NEUROIMAGE, V147, P602, DOI 10.1016/j.neuroimage.2016.12.052
   Gu C, 2011, SOMATOSENS MOT RES, V28, P86, DOI 10.3109/08990220.2011.622493
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   HART S G, 1988, P139
   Hartcher-O'Brien J, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P7, DOI 10.1109/WHC.2015.7177683
   Hazenberg SJ, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516664530
   Hennig EM, 2009, FOOT ANKLE INT, V30, P986, DOI 10.3113/FAI.2009.0986
   Higuchi T, 2006, JPN PSYCHOL RES, V48, P126, DOI 10.1111/j.1468-5884.2006.00314.x
   Hoehn K., 2016, HUMAN ANATOMY PHYSL
   Holbert B. J., 2007, THESIS ACM, pAAI3277666
   Holmes Nicholas P, 2004, Cogn Process, V5, P94, DOI 10.1007/s10339-004-0013-3
   Iachini T, 2017, COGNITION, V166, P107, DOI 10.1016/j.cognition.2017.03.024
   Israr A., 2012, CHI 12 EXTENDED ABST, P1087
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Jakobsen M., 2012, CHI 12 EXTENDED ABST, P2519, DOI [10.1145/2212776.2223829, DOI 10.1145/2212776.2223829]
   Jansen SEM, 2011, EXP BRAIN RES, V212, P449, DOI 10.1007/s00221-011-2757-1
   Jones B., 2020, FEETBACK AUGMENTING
   Jones J.A., 2011, Proc. Symposium on Applied perception in Graphics and Visualization, P29
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Jung Sungchul., 2016, P 26 INT C ART REAL, P107, DOI DOI 10.2312/EGVE.20161442
   KACZMAREK KA, 1991, IEEE T BIO-MED ENG, V38, P1, DOI 10.1109/10.68204
   Karns CM, 2009, J COGNITIVE NEUROSCI, V21, P669, DOI 10.1162/jocn.2009.21037
   Kaul O. B., 2016, 2016 CHI EA SAN JOS, P2533
   Kennedy PM, 2002, J PHYSIOL-LONDON, V538, P995, DOI 10.1113/jphysiol.2001.013087
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kruijff E., 2005, P 3D US INT WORKSH I
   Kruijff E., 2006, P ACM S VIRTUAL REAL, P316, DOI DOI 10.1145/1180495.1180558
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Kruijff Ernst, 2015, P 21 ACM S VIRTUAL R, DOI [10.1145/2821592.2821626, DOI 10.1145/2821592.2821626]
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee DV, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.1779
   Legge GE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150708
   Lehtinen V, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P445
   Lewis CH, 2002, J SOUND VIB, V253, P295, DOI 10.1006/jsvi.2001.4261
   Li S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10145014
   Lindeman R.W., 2004, ACM Symposium on Virtual Reality Software and Technology, P146, DOI DOI 10.1145/1077534.1077562
   Lindeman R.W., 2003, PROCEDURES 9 IFIP TC, P89
   Macaluso E, 2010, NEUROPSYCHOLOGIA, V48, P782, DOI 10.1016/j.neuropsychologia.2009.10.010
   MAGNUSSON M, 1990, ACTA OTO-LARYNGOL, V110, P182, DOI 10.3109/00016489009122535
   Makin TR, 2007, J NEUROSCI, V27, P731, DOI 10.1523/JNEUROSCI.3653-06.2007
   Maravita A, 2003, CURR BIOL, V13, pR531, DOI 10.1016/S0960-9822(03)00449-4
   Marchal M., 2013, HUMAN WALKING VIRTUA, P263, DOI DOI 10.1007/978-1-4419-8432-6_12
   Marquardt A., VRST 18 P 24 ACM S V
   Marquardt A., 2018, VRST 18 P ACM S VIRT
   Marquardt A, 2019, INT SYM MIX AUGMENT, P190, DOI 10.1109/ISMAR.2019.000-3
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Mateevitsi V., 2013, Proceedings of the 4th Augmented Human International Conference, AH '13, P51, DOI [DOI 10.1145/2459236.2459246, 10.1145/2459236]
   Matsuda Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90784-5
   Meng FX, 2015, HUM FACTORS, V57, P329, DOI 10.1177/0018720814542651
   Menger R, 2021, EXP BRAIN RES, V239, P1715, DOI 10.1007/s00221-021-06072-1
   Noel JP, 2015, NEUROPSYCHOLOGIA, V70, P375, DOI 10.1016/j.neuropsychologia.2014.08.030
   Nordahl R, 2010, LECT NOTES COMPUT SC, V6192, P123, DOI 10.1007/978-3-642-14075-4_18
   Nosaka K, 2011, EUR J APPL PHYSIOL, V111, P2427, DOI 10.1007/s00421-011-2086-x
   Occelli V, 2011, NEUROSCI BIOBEHAV R, V35, P589, DOI 10.1016/j.neubiorev.2010.07.004
   PADDAN GS, 1988, J BIOMECH, V21, P191, DOI 10.1016/0021-9290(88)90169-8
   PARSONS LM, 1987, COGNITIVE PSYCHOL, V19, P178, DOI 10.1016/0010-0285(87)90011-9
   Pederson T., 2012, PROXIMITY KEY PROPER
   Piateski E, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P90
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Randall JM, 1997, ERGONOMICS, V40, P879, DOI 10.1080/001401397187711
   Rasmussen G., 1983, J. Acoust. Soc. Am., V73, P1, DOI [10.1121/1.389513, DOI 10.1121/1.389513]
   Regan D, 2000, TRENDS COGN SCI, V4, P99, DOI 10.1016/S1364-6613(99)01442-4
   Riecke BE, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1577755.1577763
   RIZZOLATTI G, 1981, BEHAV BRAIN RES, V2, P147, DOI 10.1016/0166-4328(81)90053-X
   Rupert A. H., 2009, USE TACTILE CUES MOD
   Scavarelli A., 2017, P 2017 CHI C EXT ABS, P2915, DOI DOI 10.1145/3027063
   Schicke T, 2006, P NATL ACAD SCI USA, V103, P11808, DOI 10.1073/pnas.0601486103
   Schicke T, 2009, EXP BRAIN RES, V192, P703, DOI 10.1007/s00221-008-1587-2
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Schönauer C, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P133
   Serino A, 2015, SCI REP-UK, V5, DOI 10.1038/srep18603
   Serino A, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006582
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Spelmezan D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2243
   Spence C, 2004, COGN AFFECT BEHAV NE, V4, P148, DOI 10.3758/CABN.4.2.148
   Stanley AA, 2012, IEEE T HAPTICS, V5, P240, DOI 10.1109/TOH.2012.33
   Stanton TR, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03001
   Stettler BA, 2017, ATTEN PERCEPT PSYCHO, V79, P298, DOI 10.3758/s13414-016-1225-1
   Stone KD, 2018, EXP BRAIN RES, V236, P161, DOI 10.1007/s00221-017-5115-0
   Stone KD, 2021, PSYCHOL RES-PSYCH FO, V85, P1221, DOI 10.1007/s00426-020-01316-1
   Strzalkowski N., 2015, THESIS MCLAUGHLIN LI, DOI [10.13140/RG.2.2.12911.02721, DOI 10.13140/RG.2.2.12911.02721]
   Terziman L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P19, DOI 10.1109/3DUI.2012.6184179
   Toezeren A., 2000, HUMAN BODY DYNAMICS
   TOLMAN EC, 1946, J EXP PSYCHOL, V36, P13, DOI 10.1037/h0053944
   Tonelli A, 2019, EXP BRAIN RES, V237, P855, DOI 10.1007/s00221-019-05469-3
   Toward MGR, 2011, J SOUND VIB, V330, P6526, DOI 10.1016/j.jsv.2011.07.033
   Toward MGR, 2011, J SOUND VIB, V330, P827, DOI 10.1016/j.jsv.2010.08.041
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   TWERSKY V, 1951, AM J PSYCHOL, V64, P409, DOI 10.2307/1419004
   Uchiyama H., 2008, P 46 ANN SE REGIONAL, P336, DOI DOI 10.1145/1593105.1593195
   Uematsu Haruya Daichi, 2016, SIGGRAPH EMERGING TE
   Vagnoni E, 2017, EXP BRAIN RES, V235, P2729, DOI 10.1007/s00221-017-5008-2
   van Elk M, 2013, CONSCIOUS COGN, V22, P545, DOI 10.1016/j.concog.2013.02.006
   Van Hulle L, 2013, EXP BRAIN RES, V224, P295, DOI 10.1007/s00221-012-3311-5
   Velázquez R, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/52653
   Vitense H. S., 2002, ASSETS 2002. Proceedings of the Fifth International ACM SIGCAPH Conference on Assistive Technologies, P49, DOI 10.1145/638249.638260
   Wang MJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2814, DOI 10.1145/3025453.3025634
   Wentink EC, 2011, IEEE ENG MED BIO, P1668, DOI 10.1109/IEMBS.2011.6090480
   Yasuda K, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01008
   Zhong X, 2017, J ACOUST SOC AM, V141, P2882, DOI 10.1121/1.4981118
NR 128
TC 1
Z9 1
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 18
PY 2022
VL 3
AR 954587
DI 10.3389/frvir.2022.954587
PG 22
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XK4
UT WOS:001023309000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Aeschbach, LF
   Opwis, K
   Brühlmann, F
AF Aeschbach, Lena Fanya
   Opwis, Klaus
   Bruhlmann, Florian
TI Breaking immersion: A theoretical framework of alienated play to
   facilitate critical reflection on interactive media
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE play; immersion; alienation; epic theater; theory; interactive media;
   critical reflection; video games
ID ENGAGEMENT; COMPLEXITY
AB There is a growing interest in understanding how to best represent complexity using IDNs. We conceptualize this as the aim to make players of such IDNs reflect critically on the complexity being represented. We argue that current understandings of player experience do not lend themselves to this aim. Research on interactive media has assumed immersion to be a universal positive for the player experience. However, in this article we argue that immersion into the Magic Circle of an IDN could be antagonistic to a critical experience. This is because immersion persuades players into suspending their disbelief, rather than facilitating critical reflection. Instead we propose, on the basis of the Epic Theater, an alternative form of play called alienated play. Meaning, a form of play in which the player is playing, while also observing themselves play. This form of play should allow for players to benefit from the enjoyable nature of play, while simultaneously remaining at a critical distance. To illustrate our theory we design two models, one for immersed play and one for alienated play. Furthermore, we present examples of the design for alienation in commercial video games, as well as hypotheses to test out theory in future research. Therefore, this work contributes an initial theoretical and practical informed form of play, specifically designed to facilitate critical reflection on IDNs representing complexity.
C1 [Aeschbach, Lena Fanya; Opwis, Klaus; Bruhlmann, Florian] Univ Basel, Dept Gen Psychol & Methodol, Basel, Switzerland.
C3 University of Basel
RP Aeschbach, LF (corresponding author), Univ Basel, Dept Gen Psychol & Methodol, Basel, Switzerland.
EM lena.aeschbach@unibas.ch
RI Aeschbach, Lena Fanya/JOK-6351-2023
OI Aeschbach, Lena Fanya/0000-0001-9092-6103
CR Adams C. J., 1978, MONOPOLY BERKS BOARD
   Alter M. P., 1964, CLA J, V8, P60
   [Anonymous], 2015, UND
   Birk MV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2982, DOI 10.1145/2858036.2858062
   Bogost Ian., 2007, Persuasive Games: The Expressive Power of Videogames
   Brecht Bertolt., 1961, TULANE DRAMA REV, V6, P2
   Brockmyer JH, 2009, J EXP SOC PSYCHOL, V45, P624, DOI 10.1016/j.jesp.2009.02.016
   Caillois Roger, 2001, Man, Play and Games
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   DeLahunta S, 2002, PAJ, P105
   EAGLETON T, 1985, NEW LITERARY HIST, V16, P633, DOI 10.2307/468845
   Engstrom Henrik, 2016, Adv Simul (Lond), V1, P8, DOI 10.1186/s41077-016-0009-y
   Everything Unlimited Ltd, 2015, BEG GUID
   FERAL J, 1987, THEATRE J, V39, P461, DOI 10.2307/3208248
   Fleck R., 2010, P 22 C COMP HUM INT, P216, DOI [DOI 10.1145/1952222.1952269, 10.1145/1952222.1952269, https://doi.org/10.1145/1952222.1952269]
   G71] Team Salvato, 2017, DOK DOK LIT CLUB
   Galactic Cafe, 2013, STANL PAR
   Gowler CPR, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P325, DOI 10.1145/3311350.3347179
   Green MC, 2014, J COMMUN, V64, P479, DOI 10.1111/jcom.12093
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Hasbro, 1986, MONOPOLY PROPERTY TR
   Huizinga J., 1949, Homo Ludens: a Study of the Play-Element in Culture
   Hymovich D P, 1993, J Pediatr Oncol Nurs, V10, P75, DOI 10.1177/104345429301000237
   Ice-Pick Lodge, 2006, PATH
   Jesse Venbrux, 2008, EXECUTION
   Kelley B, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365701
   Kleinman E, 2020, ENTERTAIN COMPUT, V33, DOI 10.1016/j.entcom.2019.100322
   Klimmt C, 2009, COMMUN THEOR, V19, P351, DOI 10.1111/j.1468-2885.2009.01347.x
   Koenitz H, 2016, LECT NOTES COMPUT SC, V10045, P51, DOI 10.1007/978-3-319-48279-8_5
   Konami Computer Entertainment Japan Silicon Knights, 2004, MET GEAR SOL TWIN SN
   Lantz F., 2005, IMMERSIVE FALLACY
   Lea M., 1992, FLAMING COMPUTER MED, P89
   Little RM, 2010, COMMUNITY DEV J, V45, P458, DOI 10.1093/cdj/bsp017
   Lu AS, 2012, GAMES HEALTH J, V1, P199, DOI 10.1089/g4h.2011.0012
   Magie L. J., 1904, LANDLORDS GAME 1904
   Marshall T, 2019, REFLECT PRACT, V20, P396, DOI 10.1080/14623943.2019.1622520
   Mekler ED, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P315, DOI 10.1145/3242671.3242691
   Mitchell DM, 2013, ASIA-PAC J TEACH EDU, V41, P414, DOI 10.1080/1359866X.2013.838618
   Muckler VC, 2017, CLIN SIMUL NURS, V13, P3, DOI 10.1016/j.ecns.2016.09.004
   Murray Janet H., 1997, Hamlet on the Holodeck: The Future of Narrative in Cyberspace
   Olmos P, 2014, ARGUM LIB, V25, P189, DOI 10.1007/978-3-319-06334-8_11
   Rivera J., 2019, ID HAVE THESE EXTREM
   Rizvic S, 2017, INT CONF GAMES VIRTU, P253, DOI 10.1109/VS-GAMES.2017.8056610
   Roth Christian., 2016, Proceedings of the 1st International Workshop on Multimedia Alternate Realities. AltMM'16, P31, DOI DOI 10.1145/2983298.2983302
   Spiel K, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P397, DOI 10.1145/3311350.3347189
   Stevenson J., 2011, DESIGNING GAMES ETHI, DOI [10.4018/978-1-60960-120-1.ch003, DOI 10.4018/978-1-60960-120-1.CH003]
   Tavinor G., 2008, Contemporary Aesthetics (Journal Archive), V6, P16
   Tomé FD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300861
   Tyack A., 2017, P 10 DIG GAM RES ASS
   Tyack A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445230
   Tyack A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376723
   van Enschot R, 2019, LECT NOTES COMPUT SC, V11869, P158, DOI 10.1007/978-3-030-33894-7_17
   van Rooij I, 2020, SOC PSYCHOL-GERMANY, V51, P285, DOI 10.1027/1864-9335/a000428
   Whitby MA, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P339, DOI 10.1145/3311350.3347192
   Willet John., 1964, BRECHT THEATRE
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xu Y., 2011, PROTOCOL ANALYTICAL, P1, DOI DOI 10.1109/ICMSS.2011.5998938
   ZA/UM, 2019, Disco Elysium
NR 58
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 19
PY 2022
VL 3
AR 846490
DI 10.3389/frvir.2022.846490
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WJ0
UT WOS:001023281600001
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Krogmeier, C
   Coventry, BS
   Mousas, C
AF Krogmeier, Claudia
   Coventry, Brandon S.
   Mousas, Christos
TI Affective Image Sequence Viewing in Virtual Reality Theater Environment:
   Frontal Alpha Asymmetry Responses From Mobile EEG
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; mobile EEG; frontal alpha asymmetry; affective images;
   valence; arousal; emotion; frontal alpha asymmetry burst analysis
AB Background: Numerous studies have investigated emotion in virtual reality (VR) experiences using self-reported data in order to understand valence and arousal dimensions of emotion. Objective physiological data concerning valence and arousal has been less explored. Electroencephalography (EEG) can be used to examine correlates of emotional responses such as valence and arousal in virtual reality environments. Used across varying fields of research, images are able to elicit a range of affective responses from viewers. In this study, we display image sequences with annotated valence and arousal values on a screen within a virtual reality theater environment. Understanding how brain activity responses are related to affective stimuli with known valence and arousal ratings may contribute to a better understanding of affective processing in virtual reality.Methods: We investigated frontal alpha asymmetry (FAA) responses to image sequences previously annotated with valence and arousal ratings. Twenty-four participants viewed image sequences in VR with known valence and arousal values while their brain activity was recorded. Participants wore the Oculus Quest VR headset and viewed image sequences while immersed in a virtual reality theater environment.Results: Image sequences with higher valence ratings elicited greater FAA scores than image sequences with lower valence ratings (F [1, 23] = 4.631, p = 0.042), while image sequences with higher arousal scores elicited lower FAA scores than image sequences with low arousal (F [1, 23] = 7.143, p = 0.014). The effect of valence on alpha power did not reach statistical significance (F [1, 23] = 4.170, p = 0.053). We determined that only the high valence, low arousal image sequence elicited FAA which was significantly higher than FAA recorded during baseline (t [23] = -3.166, p = 0.002), suggesting that this image sequence was the most salient for participants.Conclusion: Image sequences with higher valence, and lower arousal may lead to greater FAA responses in VR experiences. While findings suggest that FAA data may be useful in understanding associations between valence and arousal self-reported data and brain activity responses elicited from affective experiences in VR environments, additional research concerning individual differences in affective processing may be informative for the development of affective VR scenarios.
C1 [Krogmeier, Claudia; Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
   [Coventry, Brandon S.] Univ Wisconsin Madison, Dept Biomed Engn, Madison, WI USA.
   [Coventry, Brandon S.] Univ Wisconsin Madison, Wisconsin Inst Translat Neuroengn, Madison, WI USA.
C3 Purdue University System; Purdue University; University of Wisconsin
   System; University of Wisconsin Madison; University of Wisconsin System;
   University of Wisconsin Madison
RP Krogmeier, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM ckrogmei@purdue.edu
RI Mousas, Christos/AGV-3533-2022
OI Mousas, Christos/0000-0003-0955-7959; Coventry,
   Brandon/0000-0001-5524-0261
CR Allen JJB, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00232
   Bobrov P, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020674
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen Jun-Cheng, 2006, P 14 ACM INT C MULTI, P25
   Cohen J., 1988, STAT POWER ANAL BEHA
   David OA, 2021, INT J COGN THER, V14, P399, DOI 10.1007/s41811-020-00077-4
   DAVIDSON RJ, 1990, J PERS SOC PSYCHOL, V58, P330, DOI 10.1037/0022-3514.58.2.330
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Ding N, 2018, TELEMAT INFORM, V35, P1572, DOI 10.1016/j.tele.2018.04.003
   Duvinage M, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-56
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gorini A, 2010, ANN GEN PSYCHIATR, V9, DOI 10.1186/1744-859X-9-30
   Harmon-Jones E, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.12879
   Hayes DJ, 2014, NEUROSCI BIOBEHAV R, V45, P350, DOI 10.1016/j.neubiorev.2014.06.018
   Kerous B, 2020, INT J HUM-COMPUT INT, V36, P505, DOI 10.1080/10447318.2019.1661608
   Kim A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P601, DOI 10.1109/VR.2018.8446046
   Kisker J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.716318
   Kuper N, 2019, EUR J PERSONALITY, V33, P154, DOI 10.1002/per.2197
   Kuppens P, 2013, PSYCHOL BULL, V139, P917, DOI 10.1037/a0030811
   Kurdi B, 2017, BEHAV RES METHODS, V49, P457, DOI 10.3758/s13428-016-0715-3
   Lacey MF, 2020, INT J PSYCHOPHYSIOL, V147, P18, DOI 10.1016/j.ijpsycho.2019.09.013
   Le TP, 2020, COGN NEUROPSYCHIATRY, V25, P371, DOI 10.1080/13546805.2020.1813096
   Lin JHT, 2017, COMPUT HUM BEHAV, V72, P350, DOI 10.1016/j.chb.2017.02.057
   Lindstrom Madelene, 2006, CHI 06 HUM FACT COMP, P1037
   Lingjun H., 2018, Practical Assessment, Research Evaluation, V23, P1
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Mousas Christos., 2021, ACM Transactions on Interactive Intelligent Systems (TiiS), V11, P1, DOI DOI 10.1145/3458844
   Papousek I, 2014, BIOL PSYCHOL, V103, P184, DOI 10.1016/j.biopsycho.2014.09.001
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Quigley KS, 2014, HANDBOOK OF RESEARCH METHODS IN SOCIAL AND PERSONALITY PSYCHOLOGY, SECOND EDITION, P220
   Robinson Raquel, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P132, DOI 10.1145/3410404.3414227
   Rodrigues J, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.12908
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sawangjai P, 2020, IEEE SENS J, V20, P3996, DOI 10.1109/JSEN.2019.2962874
   Schöne B, 2023, CURR PSYCHOL, V42, P5366, DOI 10.1007/s12144-021-01841-1
   Schöne B, 2016, EXP BRAIN RES, V234, P559, DOI 10.1007/s00221-015-4483-6
   Sinha Saurabh R, 2016, Neurodiagn J, V56, P235, DOI 10.1080/21646821.2016.1245527
   Smith EE, 2017, INT J PSYCHOPHYSIOL, V111, P98, DOI 10.1016/j.ijpsycho.2016.11.005
   Templeton GF, 2011, COMMUN ASSOC INF SYS, V28, P41
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Voigt-Antons JN, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P679, DOI 10.1109/VR50410.2021.00094
NR 46
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 19
PY 2022
VL 3
AR 895487
DI 10.3389/frvir.2022.895487
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VL1
UT WOS:001019158300001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Costes, A
   Lécuyer, A
AF Costes, Antoine
   Lecuyer, Anatole
TI The "Kinesthetic HMD": Inducing Self-Motion Sensations in Immersive
   Virtual Reality With Head-Based Force Feedback
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; force feedback; haptics; vection; simulator
ID PERCEPTION; CUES
AB The sensation of self-motion is essential in many virtual reality applications, from entertainment to training, such as flying and driving simulators. If the common approach used in amusement parks is to actuate the seats with cumbersome systems, multisensory integration can also be leveraged to get rich effects from lightweight solutions. In this paper, we introduce a novel approach called the "Kinesthetic HMD": actuating a head-mounted display with force feedback in order to provide sensations of self-motion. We discuss its design considerations and demonstrate an augmented flight simulator use case with a proof-of-concept prototype. We conducted a user study assessing our approach's ability to enhance self-motion sensations. Taken together, our results show that our Kinesthetic HMD provides significantly stronger and more egocentric sensations than a visual-only self-motion experience. Thus, by providing congruent vestibular and proprioceptive cues related to balance and self-motion, the Kinesthetic HMD represents a promising approach for a variety of virtual reality applications in which motion sensations are prominent.
C1 [Costes, Antoine; Lecuyer, Anatole] Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   de Rennes
RP Lécuyer, A (corresponding author), Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
EM anatole.lecuyer@inria.fr
OI Costes, Antoine/0000-0002-6739-9402
CR Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bouyer G, 2017, P IEEE VIRT REAL ANN, P84, DOI 10.1109/VR.2017.7892234
   Britton Z, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00063
   Chang HY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P927, DOI 10.1145/3242587.3242588
   Crane BT, 2014, JARO-J ASSOC RES OTO, V15, P87, DOI 10.1007/s10162-013-0423-y
   Cullen KE, 2012, TRENDS NEUROSCI, V35, P185, DOI 10.1016/j.tins.2011.12.001
   Danieau F, 2015, IEEE T HAPTICS, V8, P114, DOI 10.1109/TOH.2014.2381652
   Danieau Fabien, 2012, P 18 ACM S VIRTUAL R, P69, DOI DOI 10.1145/2407336.2407350
   Farkhatdinov I, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P677, DOI 10.1109/WHC.2013.6548490
   Fetsch CR, 2009, J NEUROSCI, V29, P15601, DOI 10.1523/JNEUROSCI.2574-09.2009
   Funk JR, 2011, ANN BIOMED ENG, V39, P766, DOI 10.1007/s10439-010-0183-3
   Gallagher M, 2019, EUR J NEUROSCI, V50, P3557, DOI 10.1111/ejn.14499
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P227, DOI 10.1145/2984511.2984535
   Guillotel P., 2016, P EUROGRAPHICS WORKS, P15
   Harris LR, 2000, EXP BRAIN RES, V135, P12, DOI 10.1007/s002210000504
   Kim K., 2016, EUROPEAN SCI J ESJ, V12
   Kon Y., 2017, In proceedings of the ACM SIGGRAPH 2017 emerging Technologies, P1, DOI [10.1145/3084822.3084842, DOI 10.1145/3084822.3084842]
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Lecompte J., 2007, THESIS ARTS METIERS
   Lécuyer A, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P208, DOI 10.1109/HAPTIC.2004.1287198
   Nilsson Niels C., 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P349, DOI 10.1007/978-3-642-31401-8_32
   Ouarti N, 2014, IEEE HAPTICS SYM, P167, DOI 10.1109/HAPTICS.2014.6775450
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Peng YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376847
   PROTHERO JD, 1995, HUM FAC ERG SOC P, P1410
   Reiner M, 2004, IEEE T CIRC SYST VID, V14, P392, DOI 10.1109/TCSVT.2004.823399
   Riecke B. E., 2005, P 2 S APPL PERC GRAP, P111, DOI DOI 10.1145/1080402.1080422
   Riecke B. E., 2005, P HCI INT 2005 LAS V, P1, DOI DOI 10.HTTP://EN.SCIENTI-
   Riecke B.E., 2006, P ACM S VIRTUAL REAL, P104, DOI DOI 10.1145/1180495.1180517
   Rietzler M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P99, DOI 10.1145/3196709.3196755
   Soave F, 2020, LECT NOTES COMPUT SC, V12242, P461, DOI 10.1007/978-3-030-58465-8_34
   TENG SY, 2019, P 2019 CHI C HUMAN F, P1
   Vailland G, 2020, ACMIEEE INT CONF HUM, P171, DOI 10.1145/3319502.3374825
   Väljamäe A, 2006, J AUDIO ENG SOC, V54, P954
   Wang C, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P439, DOI 10.1145/3332165.3347898
   Wang DX, 2020, IEEE T IND ELECTRON, V67, P610, DOI 10.1109/TIE.2019.2920602
   Wolf D, 2019, IEEE T VIS COMPUT GR, V25, P3169, DOI 10.1109/TVCG.2019.2932215
NR 37
TC 1
Z9 1
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2022
VL 3
AR 838720
DI 10.3389/frvir.2022.838720
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AR8
UT WOS:001019296600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Appel, L
   Appel, E
   Kisonas, E
   Lewis, S
   Sheng, LQ
AF Appel, Lora
   Appel, Eva
   Kisonas, Erika
   Lewis, Samantha
   Sheng, Lacey Qing
TI Virtual Reality for Veteran Relaxation: Can VR Therapy Help Veterans
   Living With Dementia Who Exhibit Responsive Behaviors?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; dementia; veterans; behavioral and psychological
   symptoms in dementia; responsive behaviors; recreational therapist;
   non-pharmacological; behavioral and psychological symptoms
ID POSTTRAUMATIC-STRESS-DISORDER; MUSIC-THERAPY; PREVALENCE; RISK
AB Background: Due to the high prevalence of post-traumatic stress disorder (PTSD) among veterans, as this population ages, they are more likely to develop dementia and exhibit behavioral and psychological symptoms of dementia (BPSD), including responsive behaviors. BPSDs are linked to adverse clinical outcomes, hospitalization, and earlier mortality and are directly related to increased cost and burden of care. In long-term care institutions, residents' behaviors such as physical (striking out, biting, grabbing, etc.) and/or verbal (cursing, screaming, etc.) reactions are associated with higher staff burnout levels which contribute to absenteeism, high turnover, low engagement, and elevated risk of patient abuse or neglect. Despite their limited effectiveness and association with hastening of cognitive and physical decline, medications (neuroleptic/sedating drugs) are commonly used for people with dementia who exhibit responsive behaviors. In long-term care settings, more than 30% of veterans with high-care needs and 20% of those with low-care needs are prescribed drugs to manage their symptoms and behaviors. There is growing pressure from the medical community to engage in non-pharmacological strategies as the first-line of treatment to reduce BPSDs. Virtual reality (VR) presents a unique opportunity to transport people away from environmental factors that amplify feelings of loneliness, boredom, and discomfort, which are known to trigger responsive behaviors, into natural calming settings (such as a peaceful lake, or a colorful forest). Using immersive VR as a non-pharmacological therapy has been piloted with frail older adults in both community and acute-care settings with promising results. However, to date, there have been no rigorous longitudinal studies of VR therapy in long-term care, in particular, studies that evaluate its potential to reduce responsive behaviors related to triggering events. The current study provided novel opportunities for Perley and Rideau Veterans' Health Centre (Perley Health), which has prioritized reducing resident responsive behaviors and maintaining a healthy workforce.Objective: The purpose of this study was to evaluate the feasibility and potential benefits of introducing VR therapy in a veterans' long-term care health center, with the main goal of reducing responsive behaviors for veterans living with dementia, including responsive behaviors related to experiencing physical and emotional pain. This includes evaluating VR therapy with respect to acceptability, comfort, enjoyment, relaxation, and its ability to promote reminiscence. Of special interest was the impact of VR therapy in cases where responsive behaviors were triggered by a predictable environmental event (e.g., bathing, toileting, etc.).Methods: This was a prospective, longitudinal, non-randomized interventional study that employed convenience sampling. Veterans residing in this long-term care setting who exhibited responsive behaviors were recruited and grouped into two categories according to how they usually exhibited responsive behaviors: Group T-responsive behaviors were triggered by known activities or events in a relatively predictable way (e.g., sundowning, wound care), and Group S-initiation of responsive behaviors did not follow specific predictable patterns. Residents in both groups received the VR therapy intervention, which consisted of watching 360 & DEG; VR video footage of natural and social scenes using an Oculus Go head-mounted-display.
   Group T received "targeted" VR therapy sessions occurring just before or during events that could trigger responsive behaviors (e.g., before bathing). Group S received "scheduled" VR therapy sessions akin to other recreational activities (e.g., at a mutually convenient time during the day). Intended data collection consisted of baseline scores from validated tools including the Pain Assessment for Advanced Dementia (PAINAD), Resident Assessment Instrument-Minimum Data Set 2.0 (RAI-MDS), and Palliative Performance Scale and daily clinical progress notes extracted from patients' electronic records during the study period, as well as intervention data-collection tool comprising a quantitative survey (for residents' feedback when possible) and qualitative structured observations during the intervention by recreational therapists (RTs). Also described are the changes implemented to data collection and analyses as a number of methodological challenges arose during the study.Results: Thirty-three veterans (mean age 91.6 years, SD 5.9) with varying degrees of cognitive impairment: 3% (1/33) borderline intact, 15% (5/33) mild impairment, 61% (20/33) moderate impairment, 12% (4/33) moderately severe impairment, and 6% (2/33) severe impairment participated in the study. The number of sessions per participant ranged from 2 to 6, with an average of 3.3 (SD = 1) sessions per participant. A total of 111 VR therapy sessions took place, 98 of which were scheduled (88%) and 13 were targeted (12%). The RTs reported that targeted sessions were particularly difficult to conduct due to staffing/resource constraints. In 61% (68/111) of all sessions, no responsive behaviors were observed during, or soon after, the VR therapy, and no pro re nata (PRN) medications had to be administered during the sessions. In 46% (6/13) of targeted sessions, participants did not exhibit responsive behaviors usually triggered by a specific environmental event. The majority (63%, 70/111) of participants found the technology comfortable, and in 47% (52/111) of sessions, the RTs reported that VR therapy made the resident feel good or better than they felt before the session. In 33% (37/111) of all sessions, residents reminisced about the past and in 67% (74/111) of sessions residents reported wanting to try VR again.Conclusion: Findings indicate that VR therapy is overall acceptable and enjoyable for veterans living with dementia with varying degrees of cognitive and physical impairments. Staff at the veterans' center continued to use scheduled VR therapy as a recreational tool beyond the study period. Notwithstanding the difficulties in administering targeted sessions, there was observational evidence of the potential to reduce environmentally triggered responsive behaviors; this warrants further exploration of approaches to improve protocol feasibility in support of studying treatment effectiveness. Finally, manufacturers and providers of VR therapy should consider ways in which content, equipment, and administration can be customized and optimized for this particularly frail and diverse population.
C1 [Appel, Lora] York Univ, Fac Hlth, Toronto, ON, Canada.
   [Appel, Lora; Appel, Eva; Kisonas, Erika; Lewis, Samantha] Univ Hlth Network UHN, OpenLab, Toronto, ON, Canada.
   [Sheng, Lacey Qing] Perley Hlth Rideau Veretans Hlth Ctr, Ottawa, ON, Canada.
C3 York University - Canada; University of Toronto; University Health
   Network Toronto
RP Appel, L (corresponding author), York Univ, Fac Hlth, Toronto, ON, Canada.; Appel, L (corresponding author), Univ Hlth Network UHN, OpenLab, Toronto, ON, Canada.
EM lora.appel@uhn.ca
OI Lewis-Fung, Samantha/0000-0002-6724-9383
CR Agens J. E. Jr., 2010, British Journal of Medical Practitioners, V3, P34
   [Anonymous], 2007, Dementia: A NICE-SCIE Guideline on Supporting People With Dementia and Their Carers in Health and Social Care
   [Anonymous], 2019, CONV DEM RESP BEH
   Appel L., 2021, CLIN TRIALS ALZH DIS
   Appel L, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.720523
   Appel L, 2021, J REHABIL ASSIST TER, V8, DOI 10.1177/20556683211053952
   Appel L, 2021, JMIR FORM RES, V5, DOI 10.2196/22406
   Appel L, 2020, PILOT FEASIBILITY ST, V6, DOI 10.1186/s40814-020-00708-9
   Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Beason-Held LL, 2013, J NEUROSCI, V33, P18008, DOI 10.1523/JNEUROSCI.1402-13.2013
   Brimelow RE, 2020, CYBERPSYCH BEH SOC N, V23, P165, DOI 10.1089/cyber.2019.0286
   Canadian Institute for Health Informatics, 2013, DESCR OUTC SCAL RAI
   Canadian Institute for Health Information, 2018, CONT CAR REP SYST, P2018
   Canadian Institute for Health Information, 2019, INT RAI MDS RE UNPUB
   Casey David A, 2010, P T, V35, P208
   Clay F, 2020, J ALZHEIMERS DIS, V75, P23, DOI 10.3233/JAD-191218
   Connor DJ, 2008, ALZHEIMERS DEMENT, V4, P390, DOI 10.1016/j.jalz.2008.09.002
   D'Cunha NM, 2019, GERONTOLOGY, V65, P430, DOI 10.1159/000500040
   Dermody G, 2020, J MED INTERNET RES, V22, DOI 10.2196/17331
   Dyer SM, 2018, INT PSYCHOGERIATR, V30, P295, DOI 10.1017/S1041610217002344
   Edvardsson D, 2008, INT PSYCHOGERIATR, V20, P764, DOI 10.1017/S1041610208006716
   Erkes J, 2022, CLIN GERONTOLOGIST, V45, P870, DOI 10.1080/07317115.2021.1924333
   Finkel S I, 1996, Int Psychogeriatr, V8 Suppl 2, P151
   Fulton JJ, 2015, J ANXIETY DISORD, V31, P98, DOI 10.1016/j.janxdis.2015.02.003
   García-Betances RI, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00080
   Gastmans C, 2006, J MED ETHICS, V32, P148, DOI 10.1136/jme.2005.012708
   Gómez-Romero M, 2017, NEUROLOGIA, V32, P253, DOI 10.1016/j.nrl.2014.11.001
   Guideline Adaptation Committee, 2016, CLIN PRACTICE GUIDEL, V1
   Gunak MM, 2020, BRIT J PSYCHIAT, V217, P600, DOI 10.1192/bjp.2020.150
   Gunawardena R, 2019, GERIATRICS-BASEL, V4, DOI 10.3390/geriatrics4030050
   Islam MS, 2017, BMC NURS, V16, DOI 10.1186/s12912-017-0216-4
   Kishita N, 2020, J GERIATR PSYCH NEUR, V33, P28, DOI 10.1177/0891988719856690
   Liu Y, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00280
   Matsangidou Maria, 2020, Universal Access in Human-Computer Interaction. Design Approaches and Supporting Technologies. 14th International Conference, UAHCI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12188), P366, DOI 10.1007/978-3-030-49282-3_26
   Meyer C, 2020, DEMENTIA-LONDON, V19, P1927, DOI 10.1177/1471301218813234
   Miyamoto Y, 2010, GERIATR NURS, V31, P246, DOI 10.1016/j.gerinurse.2010.01.002
   Moore CG, 2011, CTS-CLIN TRANSL SCI, V4, P332, DOI 10.1111/j.1752-8062.2011.00347.x
   O'Neil M., 2011, A systematic evidence review of non-pharmacological interventions for behavioral symptoms of dementia
   Paletta L., 2020, ALZHEIMERS DEMEN, V16, pe047344, DOI [10.1002/alz.047344, DOI 10.1002/ALZ.047344]
   Pelletier Isabelle Chantale, 2007, BMC Geriatr, V7, P27, DOI 10.1186/1471-2318-7-27
   Pinciotti CM, 2017, J NERV MENT DIS, V205, P106, DOI 10.1097/NMD.0000000000000560
   Pressman SD, 2009, PSYCHOSOM MED, V71, P725, DOI 10.1097/PSY.0b013e3181ad7978
   Qureshi SU, 2010, J AM GERIATR SOC, V58, P1627, DOI 10.1111/j.1532-5415.2010.02977.x
   Rusted J., 2006, Group Analysis, V39, P517, DOI DOI 10.1177/0533316406071447
   Silva R. S., 2019, INT J VIRTUAL REALIT, V19, P11, DOI DOI 10.20870/IJVR.2019.19.1.2908
   Thabane L, 2010, BMC MED RES METHODOL, V10, DOI 10.1186/1471-2288-10-1
   University of South Australia, 2007, ANT DEM
   Victoria Hospice Society, 2006, PALL PERF SCAL PPS
   Wang QS, 2016, CURVED LAYER STRUCT, V3, P105, DOI 10.1515/cls-2016-0010
   Warden Victoria, 2003, J Am Med Dir Assoc, V4, P9, DOI 10.1016/S1525-8610(04)70258-3
   White MP, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44097-3
   Wijma EM., 2018, AGING MENT HEALTH, V22, P1121, DOI DOI 10.1080/13607863.2017.1348470
   Yaffe K, 2010, ARCH GEN PSYCHIAT, V67, P608, DOI 10.1001/archgenpsychiatry.2010.61
   Zhang YS, 2017, AGEING RES REV, V35, P1, DOI 10.1016/j.arr.2016.12.003
NR 54
TC 5
Z9 5
U1 4
U2 16
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 11
PY 2022
VL 2
AR 724020
DI 10.3389/frvir.2021.724020
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AI9
UT WOS:001019287700001
OA gold
DA 2024-07-18
ER

PT J
AU Ratan, R
   Boumis, JK
   Kuang, SR
   Gambino, A
   Huang, KT
AF Ratan, Rabindra
   Boumis, Josephine K.
   Kuang, Sarah
   Gambino, Andrew
   Huang, Kuo-Ting
TI Reality Stems From Modality: Stereotype Threat Effects of a STEM Game in
   Augmented and Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented and virtual reality; experiment; video games; STEM games;
   stereotype threat and reactance
ID HIGHER-EDUCATION; GENDER-ROLES; VIDEO GAMES; METAANALYSIS; PERFORMANCE;
   TECHNOLOGY; CHARACTERS; REACTANCE; COMPUTER; WOMEN
AB This study examined the relationship between stereotype threat, game modality (augmented reality, virtual reality), and stereotypic beliefs about STEM fields. Results of a 2 [modality] x 2 [stereotype threat] factorial, between-subjects experiment with women participants (N = 64) suggest that gender stereotypes primed before playing the STEM game in AR induced stereotype threat, but induced stereotype reactance in VR. Specifically, for participants who played in AR, the stereotype-reinforcing prompt (compared to a counter-stereotype prompt) was associated with worse STEM-game performance, which mediated an increase in stereotypical beliefs about women in STEM. Conversely, for participants who played in VR, the stereotype-reinforcing prompt was associated with better STEM-game performance and more positive (i.e., counter-stereotypic) beliefs about women in STEM, though without mediation. These findings support the claim that stereotypes triggered in a STEM-gaming context have the potential to reinforce stereotypes in STEM fields. Researchers and practitioners should consider the implication that VR is potentially more male-stereotyped than AR, while AR makes stereotyped identity characteristics more accessible than VR.
C1 [Ratan, Rabindra] Michigan State Univ, Dept Media & Informat, E Lansing, MI 48824 USA.
   [Boumis, Josephine K.] Univ S Florida, Dept Commun, Tampa, FL USA.
   [Kuang, Sarah] Michigan State Univ, Dept Psychol, E Lansing, MI USA.
   [Gambino, Andrew] Penn State Univ, Coll Commun, State Coll, PA USA.
   [Huang, Kuo-Ting] Ball State Univ, Dept Journalism, Muncie, IN USA.
C3 Michigan State University; State University System of Florida;
   University of South Florida; Michigan State University; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); Pennsylvania State
   University; Ball State University
RP Ratan, R (corresponding author), Michigan State Univ, Dept Media & Informat, E Lansing, MI 48824 USA.
EM rar@msu.edu
FU Honors College at Michigan State University
FX This research was partially supported by the Honors College at Michigan
   State University. The funding came in the form of a gift and the funders
   were not involved in the study design in any way. We would also like to
   thank the AT & amp;T endowment to the Media and Information Department
   at MSU for supporting Dr. Ratan's AT & amp;T Scholar position.
CR [Anonymous], 2017, Women in STEM: 2017 Update. ESA Issue Brief# 06-17
   [Anonymous], 2012, STEREOTYPE THREAT TH
   [Anonymous], 2018, ESS FACTS COMP VID G
   Ansara YG., 2016, WILEY BLACKWELL ENCY, P1, DOI DOI 10.1002/9781118663219.WBEGSS426
   Azzarito L, 2008, INT REV SOCIOL SPORT, V43, P347, DOI 10.1177/1012690208099871
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Beckwith L, 2007, VL/HCC 2007: IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P119, DOI 10.1109/VLHCC.2007.15
   Behm-Morawitz E, 2009, SEX ROLES, V61, P808, DOI 10.1007/s11199-009-9683-8
   BEM SL, 1981, PSYCHOL REV, V88, P354, DOI 10.1037/0033-295X.88.4.354
   Bin Mohd Nasir M. F., 2015, USING MOBILE AUGMENT
   Biocca F., 2006, Journal of Computer-Mediated Communication., V3, DOI DOI 10.1111/J.1083-6101.1997.TB00070.X
   Brehm Jack W., 1966, THEORY PSYCHOL REACT
   Christ Marc, 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8086914
   Clement J., 2021, VIRTUAL REALITY VR A
   Collette M., 2013, Games the Key to Girls' STEM Education
   Correll SJ, 2001, AM J SOCIOL, V106, P1691, DOI 10.1086/321299
   Crawford G, 2005, SOCIOL RES ONLINE, V10
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dill KE, 2007, SEX ROLES, V57, P851, DOI 10.1007/s11199-007-9278-1
   Farmer H, 2017, SOC JUSTICE RES, V30, P323, DOI 10.1007/s11211-017-0294-1
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fordham J., 2020, Is Gender Disparity in STEM Fields Related to Gender Stereotypes in Videogames? An Experimental Examination of Stereotype Threat Context Transfer
   Fox J, 2009, PRESENCE-TELEOP VIRT, V18, P294, DOI 10.1162/pres.18.4.294
   Foxman Maxwell, 2020, CHI PLAY '20: Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play, P237, DOI 10.1145/3383668.3419881
   Giammarco EA, 2015, PERS INDIV DIFFER, V73, P98, DOI 10.1016/j.paid.2014.09.036
   Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Greenberg BS, 2010, SIMULAT GAMING, V41, P238, DOI 10.1177/1046878108319930
   Gunderson EA, 2012, SEX ROLES, V66, P153, DOI 10.1007/s11199-011-9996-2
   Hargittai E, 2006, SOC SCI QUART, V87, P432, DOI 10.1111/j.1540-6237.2006.00389.x
   Hartmann T, 2006, J COMPUT-MEDIAT COMM, V11, P910, DOI 10.1111/j.1083-6101.2006.00301.x
   Huang KT, 2019, CYBERPSYCH BEH SOC N, V22, P105, DOI 10.1089/cyber.2018.0150
   Huffman AH, 2013, COMPUT HUM BEHAV, V29, P1779, DOI 10.1016/j.chb.2013.02.012
   Jenson J., 2007, P 2007 C FUTURE PLAY, P9, DOI DOI 10.1145/1328202.1328205
   Kaye LK, 2016, COMPUT HUM BEHAV, V59, P202, DOI 10.1016/j.chb.2016.02.020
   Kockro RA, 2015, ANN ANAT, V201, P91, DOI 10.1016/j.aanat.2015.05.006
   Kosa M, 2020, INT J GAMING COMPUT-, V12, P43, DOI 10.4018/IJGCMS.2020010103
   Kray LJ, 2004, PERS SOC PSYCHOL B, V30, P399, DOI 10.1177/0146167203261884
   Kuznekoff JH, 2013, NEW MEDIA SOC, V15, P541, DOI 10.1177/1461444812458271
   Larson P, 1999, Cyberpsychol Behav, V2, P113, DOI 10.1089/cpb.1999.2.113
   Lin TJ, 2013, COMPUT EDUC, V68, P314, DOI 10.1016/j.compedu.2013.05.011
   Lips HM, 2017, SEX ROLES, V76, P627, DOI 10.1007/s11199-016-0664-4
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Miron AM, 2006, Z SOZIALPSYCHOL, V37, P9, DOI 10.1024/0044-3514.37.1.9
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nam-Hyun Um, 2020, International Journal of Contents, V16, P78, DOI 10.5392/IJoC.2020.16.4.078
   Near CE, 2013, SEX ROLES, V68, P252, DOI 10.1007/s11199-012-0231-6
   Nguyen HHD, 2008, J APPL PSYCHOL, V93, P1314, DOI 10.1037/a0012702
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pennington CR, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146487
   Ratan R, 2020, AM BEHAV SCI, V64, P1031, DOI 10.1177/0002764220919147
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Rodán A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01050
   Serino M, 2016, CURR OPIN PEDIATR, V28, P673, DOI 10.1097/MOP.0000000000000409
   Shapiro JR, 2007, PERS SOC PSYCHOL REV, V11, P107, DOI 10.1177/1088868306294790
   Shen CH, 2016, J COMPUT-MEDIAT COMM, V21, P312, DOI 10.1111/jcc4.12159
   Smith JL, 2013, PERS SOC PSYCHOL B, V39, P131, DOI 10.1177/0146167212468332
   Spence I, 2010, REV GEN PSYCHOL, V14, P92, DOI 10.1037/a0019491
   Spencer SJ, 1999, J EXP SOC PSYCHOL, V35, P4, DOI 10.1006/jesp.1998.1373
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Steele CM, 1997, AM PSYCHOL, V52, P613, DOI 10.1037/0003-066X.52.6.613
   Tan C. T., 2010, AUGMENTED REALITY GA, DOI [10.1115/icone18-29100, DOI 10.1115/ICONE18-29100]
   Terlecki MS, 2005, SEX ROLES, V53, P433, DOI 10.1007/s11199-005-6765-0
   van Deursen AJAM, 2014, NEW MEDIA SOC, V16, P507, DOI 10.1177/1461444813487959
   Vermeulen L, 2016, COMPUT HUM BEHAV, V57, P377, DOI 10.1016/j.chb.2015.12.042
   Wiest L.R., 2017, OUT OF SCH TIME STEM
   Wohn Donghee Yvette, 2020, HCI in Games. Second International Conference, HCI-Games 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12211), P233, DOI 10.1007/978-3-030-50164-8_16
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yee N., 2017, QUANTIC FOUNDRY
NR 71
TC 1
Z9 2
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 12
PY 2021
VL 2
AR 636643
DI 10.3389/frvir.2021.636643
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PN0
UT WOS:001021730500001
OA gold
DA 2024-07-18
ER

PT J
AU Brun, C
   Pinard, AM
   McCabe, CS
   Mercier, C
AF Brun, Clementine
   Pinard, Anne Marie
   McCabe, Candida S.
   Mercier, Catherine
TI Virtual Reality-Induced Sensorimotor Conflict Evokes Limb-Specific
   Sensory Disturbances in Complex Regional Pain Syndrome
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE sensory disturbances; CRPS; chronic pain; virtual reality; robotics;
   sensorimotor integration
ID PRIMARY SOMATOSENSORY CORTEX; BODY PERCEPTION DISTURBANCE; GENERALIZED
   HYPERVIGILANCE; CORTICAL REORGANIZATION; FIBROMYALGIA; DYSFUNCTION; HAND
AB The origin of sensory disturbances in complex regional pain syndrome (CRPS) remains unclear. It has been hypothesized that such disturbances are due to attentional effects and/or sensorimotor integration deficits. If sensory disturbances are explained by sensorimotor integration deficits, they would be expected to be specific in terms of the category of sensation evoked and in terms of localization. Objective 1: To test whether sensory disturbances evoked by a unilateral sensorimotor conflict are specific to the painful limb and differ according to the category of sensory disturbances in individuals with a unilateral CRPS compared to healthy controls (HC). Objective 2: To assess the association between clinical characteristics and conflict-induced sensory disturbances. Objective 3: To assess conflict-induced motor disturbances. Ten adults with upper limb (UL) CRPS and 23 HC were recruited. Sensorimotor conflict was elicited with a KINARM exoskeleton interfaced with a 2D virtual environment allowing the projection of a virtual UL that was moving in either a congruent or incongruent manner relative to the actual UL movement. Participants rated sensory disturbances from 0 (no change) to 3 (high change) on a 8-item questionnaire. Items were classified into two Categories (Category 1: pain, discomfort, the feeling of losing a limb, change in weight and temperature; Category 2: feelings of peculiarity, the impression of gaining a limb and losing control). Motor disturbances were quantified as mediolateral drift and changes in amplitude of UL movement. Clinical characteristics included the intensity and duration of pain, proprioception, and body perception. CRPS participants report higher Category 1 than Category 2 disturbances for the Affected limb (while the reverse was observed for HC and for the Unaffected limb). In addition, no difference was observed between the Unaffected limb in CRPS and the Dominant limb in HC for Category 2 disturbances, while higher conflict sensitivity was observed for Category 1 disturbances. Conflict sensitivity was only related to higher pain for Category 1 disturbances in the Affected limb. Finally, no effect on motor disturbances was observed. While they do not completely rule out the attentional hypothesis, these results support the hypothesis of sensorimotor integration deficits.
C1 [Brun, Clementine; Mercier, Catherine] Ctr Interdisciplinary Res Rehabil & Social Integra, Quebec City, PQ, Canada.
   [Brun, Clementine; Mercier, Catherine] Laval Univ, Dept Rehabil, Quebec City, PQ, Canada.
   [Pinard, Anne Marie] Laval Univ, Dept Anesthesiol, Quebec City, PQ, Canada.
   [Pinard, Anne Marie] Univ Laval, Dept Anesthesiol & Intens Care, CHU Quebec, Quebec City, PQ, Canada.
   [McCabe, Candida S.] Dorothy House Hosp, Winsley, England.
   [McCabe, Candida S.] Univ West England, HAS Nursing & Midwifery, Bristol, England.
   [McCabe, Candida S.] Florence Nightingale Fdn, London, England.
C3 Laval University; Laval University; Laval University; University of West
   England
RP Mercier, C (corresponding author), Ctr Interdisciplinary Res Rehabil & Social Integra, Quebec City, PQ, Canada.; Mercier, C (corresponding author), Laval Univ, Dept Rehabil, Quebec City, PQ, Canada.
EM catherine.mercier@rea.ulaval.ca
CR Bank PJM, 2014, EUR J PAIN, V18, P1013, DOI 10.1002/j.1532-2149.2013.00446.x
   Bank PJM, 2013, J PAIN, V14, P1460, DOI 10.1016/j.jpain.2013.07.009
   Bean DJ, 2015, PAIN, V156, P2310, DOI 10.1097/j.pain.0000000000000282
   Broadbent P, 2021, PAIN, V162, P332, DOI 10.1097/j.pain.0000000000002040
   Brun C, 2020, NEUROSCIENCE, V434, P55, DOI 10.1016/j.neuroscience.2020.03.017
   Brun C, 2019, EUR J PAIN, V23, P483, DOI 10.1002/ejp.1322
   Brun C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203206
   Brun C, 2019, J PAIN, V20, P17, DOI 10.1016/j.jpain.2018.07.008
   Brun C, 2017, FRONT INTEGR NEUROSC, V11, DOI 10.3389/fnint.2017.00014
   Bultitude JH, 2021, BEHAV BRAIN RES, V397, DOI 10.1016/j.bbr.2020.112922
   Cisler JM, 2010, CLIN PSYCHOL REV, V30, P203, DOI 10.1016/j.cpr.2009.11.003
   Di Pietro F, 2013, J PAIN, V14, P1001, DOI 10.1016/j.jpain.2013.04.001
   Don S, 2017, PAIN PRACT, V17, P115, DOI 10.1111/papr.12456
   Drummond PD, 2018, PAIN, V159, P1824, DOI 10.1097/j.pain.0000000000001280
   Dukelow SP, 2010, NEUROREHAB NEURAL RE, V24, P178, DOI 10.1177/1545968309345267
   Förderreuther S, 2004, PAIN, V110, P756, DOI 10.1016/j.pain.2004.05.019
   Frettlöh J, 2006, PAIN, V124, P184, DOI 10.1016/j.pain.2006.04.010
   Harden RN, 2007, PAIN MED, V8, P326, DOI 10.1111/j.1526-4637.2006.00169.x
   Harden RN, 2010, PAIN, V150, P268, DOI 10.1016/j.pain.2010.04.030
   Harris AJ, 1999, LANCET, V354, P1464, DOI 10.1016/S0140-6736(99)05003-5
   Hollins M, 2009, PAIN, V141, P215, DOI 10.1016/j.pain.2008.10.003
   Knudsen L, 2011, J PAIN, V12, P985, DOI 10.1016/j.jpain.2011.03.001
   Kuczynski A, 2014, STROKE, V45, pE261
   Lewis JS, 2012, EUR J PAIN, V16, P1320, DOI 10.1002/j.1532-2149.2012.00120.x
   Lewis J. S., 2010, PRACT PAIN MANAG, P60
   Lewis JS, 2007, PAIN, V133, P111, DOI 10.1016/j.pain.2007.03.013
   Maihöfner C, 2003, NEUROLOGY, V61, P1707, DOI 10.1212/01.WNL.0000098939.02752.8E
   McCabe CS, 2008, RHEUMATOLOGY, V47, P1612, DOI 10.1093/rheumatology/ken254
   McCabe CS, 2007, RHEUMATOLOGY, V46, P1587, DOI 10.1093/rheumatology/kem204
   McCabe Candida S, 2009, Curr Rheumatol Rep, V11, P461
   McDermid AJ, 1996, PAIN, V66, P133, DOI 10.1016/0304-3959(96)03059-X
   Michal M, 2017, PAIN MED, V18, P764, DOI 10.1093/pm/pnw214
   Noguchi K, 2012, J STAT SOFTW, V50, P1, DOI 10.18637/jss.v050.i12
   Palmer S, 2019, CLIN J PAIN, V35, P894, DOI 10.1097/AJP.0000000000000751
   Reinersmann A, 2013, PAIN, V154, P1519, DOI 10.1016/j.pain.2013.03.039
   Rommel O, 2001, PAIN, V93, P279, DOI 10.1016/S0304-3959(01)00332-3
   Scott S., 2013, SCOTT S
   Tajadura-Jiménez A, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00379
   Tajadura-Jiménez A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2943, DOI 10.1145/2702123.2702374
   Turton AJ, 2007, PAIN, V127, P270, DOI 10.1016/j.pain.2006.08.021
   Vartiainen N, 2009, J PAIN, V10, P854, DOI 10.1016/j.jpain.2009.02.006
   Verfaille C, 2021, PAIN, V162, P811, DOI 10.1097/j.pain.0000000000002068
   Wang AP, 2019, J PAIN, V20, P171, DOI 10.1016/j.jpain.2018.08.008
NR 43
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 7
PY 2021
VL 2
AR 694293
DI 10.3389/frvir.2021.694293
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8UZ9
UT WOS:001019146900001
OA gold
DA 2024-07-18
ER

PT J
AU Khojasteh, N
   Won, AS
AF Khojasteh, Negar
   Won, Andrea Stevenson
TI Working Together on Diverse Tasks: A Longitudinal Study on Individual
   Workload, Presence and Emotional Recognition in Collaborative Virtual
   Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE VR; virtual reality; remote collaboration; presence; social presence
ID COMPUTER-MEDIATED COMMUNICATION; VOCAL COMMUNICATION; SOCIAL PRESENCE;
   REALITY; PERFORMANCE; PERSONALITY; EXPERIENCE; BEHAVIOR; WORLDS; SPACE
AB Numerous studies have shown the potential benefits of collaborative virtual environments (CVEs) for distributed teams. However, there are few longitudinal studies on collaboration in immersive virtual environments, and existing studies mostly examine how pairs or groups adapt over time. In a longitudinal study, we examined what does and does not change over time as individual users adapt to collaboration in virtual environments. In our mixed-methods, exploratory study, we matched 20 participants in random pairs over five sessions. We assigned each participant to complete a different collaborative task, with a different partner, in each session. Our quantitative data analysis and qualitative interview data show that adaptation to VR increased significantly over time. Presence ratings did not show change over time, but participants reported developing new ways to communicate in VR. We also identified patterns indicating a relationship between a person's emotional state and their partner's ability to recognize their emotion. We conclude with a discussion of our findings and provide design implications and future directions for designers and researchers in the field.
C1 [Khojasteh, Negar] Cornell Univ, Dept Informat Sci, IIthaca, NY 14850 USA.
   [Won, Andrea Stevenson] Cornell Univ, Dept Commun, Ithaca, NY USA.
C3 Cornell University
RP Khojasteh, N (corresponding author), Cornell Univ, Dept Informat Sci, IIthaca, NY 14850 USA.
EM nk586@cornell.edu
FU Cornell Open Access Publication Fund
FX We would like to thank Stephen Parry (Cornell Statistical Consulting
   Unit for his support with the statistical analysis of the data, Susan R.
   Fussell for her feedback on the earlier drafts of this paper, and Leslie
   Park and Katherine Miller for their support during the data collection
   phase. We also thank Jacob Grippin and Florio Arguillas of the Cornell
   Institute for Social and Economic Research (CISER) for their support as
   we prepared the code and data for public access on OSF. We appreciate
   the Cornell Open Access Publication Fund for the financial support that
   covered the publication expenses of this paper. Finally, we thank our
   participants, the reviewers and the editor of our work, and others who
   helped us in this project.
CR Akaike H, 1973, 2 INT S INF THEOR, P267, DOI [DOI 10.1007/978-1-4612-1694-0_15, 10.1007/978-1-4612-0919-5_38, DOI 10.1007/978-1-4612-0919-5_38]
   Andrist S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2571, DOI 10.1145/3025453.3026033
   [Anonymous], 1974, LIFEBOAT ETHICS
   Axelsson A.-S., 1999, P 6 UKVRSIG C, P107
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   Bhattacherjee A., 2012, Textbooks Collection
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Bleakley A.E., 2020, Mensch und Computer 2020-Workshopband
   Bosch-Sijtsema PM, 2013, IEEE T PROF COMMUN, V56, P160, DOI 10.1109/TPC.2012.2237256
   Bowers J., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P58, DOI 10.1145/238386.238404
   Chirico A, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02351
   Courage C., 2009, CHI 09 HUM FACT COMP, P4791
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   De Dreu CKW, 2003, J APPL PSYCHOL, V88, P741, DOI 10.1037/0021-9010.88.4.741
   Ditton T., 1997, J COMPUTER MEDIATED, V3, pJCMC321, DOI [10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X]
   Dresner E, 2010, COMMUN THEOR, V20, P249, DOI 10.1111/j.1468-2885.2010.01362.x
   Ducheneaut N, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1151
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Endsley MR, 1999, ERGONOMICS, V42, P462, DOI 10.1080/001401399185595
   Engel D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115212
   Forlizzi J., 2004, P 5 C DES INT SYST P, P261, DOI [10.1145/1013115.1013152, DOI 10.1145/1013115.1013152]
   Freeman G, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382923
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Fruchter R., 2018, Transforming Engineering Education: Innovative, Computer-Mediated Learning Technologies, P229
   Fussell SusanR., 2014, The Oxford Handbook of Language and Social Psychology, P471
   Ge Gao, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134683
   Gerken J., 2007, INFOVIS WORKSHOP MET
   Goyal N, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P288, DOI 10.1145/2818048.2820071
   Greenwald S W., 2017, Communications in Computer and Information Science, V725, DOI DOI 10.1007/978-3-319-60633-0_7
   Gunkel SNB, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P498, DOI 10.1145/3204949.3208115
   Hammick JK, 2014, COMPUT HUM BEHAV, V33, P302, DOI 10.1016/j.chb.2013.01.046
   Hancock JT, 2001, COMMUN RES, V28, P325, DOI 10.1177/009365001028003004
   Harris H, 2009, PRESENCE-VIRTUAL AUG, V18, P434, DOI 10.1162/pres.18.6.434
   Harris R.B., 2007, J APPL SCI RES, V3, P2081
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Nguyen H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1098, DOI [10.1109/VR.2019.8797845, 10.1109/vr.2019.8797845]
   Jaeger BC, 2017, J APPL STAT, V44, P1086, DOI 10.1080/02664763.2016.1193725
   Jiang J., 2019, PEW RES
   Kaber DavidB., 2004, THEOR ISS ERGON SCI, V5, P113, DOI DOI 10.1080/1463922021000054335
   Karapanos E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P729
   Koutsabasis P, 2012, DESIGN STUD, V33, P357, DOI 10.1016/j.destud.2011.11.004
   Krueger Charlene, 2004, Biol Res Nurs, V6, P151, DOI 10.1177/1099800404267682
   Larsen CR, 2009, BMJ-BRIT MED J, V338, DOI 10.1136/bmj.b1802
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Lohse M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1459, DOI 10.1145/2556288.2557274
   Luong T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P662, DOI [10.1109/VR46266.2020.00-15, 10.1109/VR46266.2020.1581086856229]
   Ma X, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P33, DOI 10.1145/3178876.3186034
   Maloney D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P343, DOI [10.1109/VRW50115.2020.00075, 10.1109/VRW50115.2020.0-201]
   Manstead AS., 2011, FACE TO FACE COMMUNI, P144, DOI DOI 10.1017/CBO9780511977589.009
   Mark G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P107
   MATTHEWS G, 1990, BRIT J PSYCHOL, V81, P17, DOI 10.1111/j.2044-8295.1990.tb02343.x
   Mboya A. M., 2020, THESIS MIT CAMBRIDGE
   McGrath J.E., 1984, GROUPS INTERACTION P
   McLellan S, 2012, J USABILITY STUD, V7, P56
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Mott M., 2020, 22 INT ACM SIGACCESS, P1
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Neustaedter C., 2012, Proceedings of the SIGCHI Conference on, P753, DOI https://doi.org/10.1145/2207676.2207785
   Nguyen DT, 2014, DISCOURSE PROCESS, V51, P468, DOI 10.1080/0163853X.2014.912544
   Nowak Kristen., 2001, PRESENCE 2001 C PHIL, P1, DOI 10.1.1.19.5482
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   Otto O., 2006, VRCIA 06, P145, DOI DOI 10.1145/1128923.1128947
   Paes D, 2017, AUTOMAT CONSTR, V84, P292, DOI 10.1016/j.autcon.2017.09.016
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Pek J, 2018, PSYCHOL METHODS, V23, P208, DOI 10.1037/met0000126
   Porter J, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P277, DOI 10.1145/3311350.3347159
   Pouliquen-Lardy L, 2016, VIRTUAL REAL-LONDON, V20, P213, DOI 10.1007/s10055-016-0294-8
   Rajanna V, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204541
   Rights JD, 2019, PSYCHOL METHODS, V24, P309, DOI 10.1037/met0000184
   Sallnäs EL, 2005, PRESENCE-VIRTUAL AUG, V14, P434, DOI 10.1162/105474605774785253
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Sonalkar N., 2020, Design thinking research: Investigating design team performance, DOI [https://doi.org/10.1007/978-3-030-28960-7_5, DOI 10.1007/978-3-030-28960-7_5]
   Steed A, 1999, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.1999.756941
   Steed A., 2020, Interactions, V27, P62, DOI DOI 10.1145/3406098
   Steed Anthony., 2003, P ACM SIGGRAPH S INT, P51
   Steptoe W, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1039
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   STRUTZEL E, 1968, NURS RES, V17, P364
   Sun Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221803
   Tamborini R, 2006, LEA COMMUN SER, P225
   Tanenbaum J., 2014, Nonverbal Communication in Virtual Worlds: Understanding and Designing Expressive Characters
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Tree JEF, 2001, MEM COGNITION, V29, P320, DOI 10.3758/BF03194926
   van der Land S, 2013, COMPUT HUM BEHAV, V29, P1054, DOI 10.1016/j.chb.2012.09.006
   Walther J. B., 1995, Journal of Organizational Computing, V5, P355, DOI 10.1080/10919399509540258
   Walther JB, 2005, J LANG SOC PSYCHOL, V24, P36, DOI 10.1177/0261927X04273036
   Walther JB, 1996, COMMUN RES, V23, P3, DOI 10.1177/009365096023001001
   Walther JB, 2010, MEDIA PSYCHOL, V13, P364, DOI 10.1080/15213269.2010.524913
   Warburton S, 2009, BRIT J EDUC TECHNOL, V40, P414, DOI 10.1111/j.1467-8535.2009.00952.x
   Wei SE, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323030
   Wetsch L.R., 2008, Journal of Virtual Worlds Research, V1
   Wickens CD, 2008, HUM FACTORS, V50, P449, DOI 10.1518/001872008X288394
   Widestrom J., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P165, DOI 10.1145/351006.351035
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Woolley AW, 2010, SCIENCE, V330, P686, DOI 10.1126/science.1193147
   Xu B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3743, DOI 10.1145/2556288.2557171
   Yee N, 2008, PRESENCE-TELEOP VIRT, V17, P594, DOI 10.1162/pres.17.6.594
   Yee N, 2011, SOC PSYCHOL PERS SCI, V2, P5, DOI 10.1177/1948550610379056
NR 112
TC 12
Z9 12
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 10
PY 2021
VL 2
AR 643331
DI 10.3389/frvir.2021.643331
PG 24
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2RT0
UT WOS:001021789000001
OA gold
DA 2024-07-18
ER

PT J
AU Nolet, K
   Viel, A
   Bouchard, S
AF Nolet, Kevin
   Viel, Alexandre
   Bouchard, Stephane
TI "I Like the Way You Move": Validating the Use of Point-Light Display
   Animations in Virtual Reality as a Methodology for Manipulating Levels
   of Sexualization in the Study of Sexual Objectification
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; biological movement perception; point-light display;
   sexual objectification; sexualization
ID BIOLOGICAL MOTION; BODY; PERCEPTION; RECOGNITION; INCREASES; EMOTION;
   PEOPLE; MEDIA; EXPOSURE; BLAME
AB Sexual objectification of others has seen a growing research interest in recent years. While promising, the field lacks standardized stimuli, resulting in a confusion between sexualization and sexual objectification, which limits the interpretability of published results. In this study, we propose to use point-light display (PLD) as a novel methodology for manipulating sexualization levels as a first step toward isolating movement from other visual cues (e.g., clothing or physical appearance) for studying effects of sexual objectification of others. To do so, we first developed 8 virtual reality animations varying on 3 dimensions: 1) nature of movement (dance vs. walk), 2) level of sexualization (low vs. high), and 3) animation speed (slow and fast). Then, we validated these stimuli with perception ratings from 211 participants via an online survey. Using mixed linear regression models, we found evidence that our manipulation was successful: while participants took longer, were less accurate, and less confident in their response when confronted with a dancing, sexualized PLD, they also rated it as significantly more sexualized. This latter effect was stronger for participants perceiving a woman dancing compared to participants who perceived other genders. Overall, participants who reported more frequent sexual objectification behaviors also perceived the animations as more sexualized. Taken together, these results suggest that sexual suggestiveness can be manipulated by rather simple movement cues, thus validating the use of PLD as a stepping stone to systematically study processes of sexual objectification. From there, it is now possible to manipulate other variables more precisely during immersions in virtual reality, whether by adding a skin to the animated skeleton, by situating the PLD into different context, by varying the amplitude and the nature of the movements, or by modifying the context of the virtual environment.
C1 [Nolet, Kevin; Viel, Alexandre; Bouchard, Stephane] Univ Quebec Outaouais, Dept Psychoeduc & Psychol, Cyberpsychol Lab UQO, Gatineau, PQ, Canada.
C3 University of Quebec; University Quebec Outaouais
RP Nolet, K (corresponding author), Univ Quebec Outaouais, Dept Psychoeduc & Psychol, Cyberpsychol Lab UQO, Gatineau, PQ, Canada.
EM kevin.nolet@umontreal.ca
OI Bouchard, Stephane/0000-0002-5995-340X
CR Alaerts K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020989
   Ambady N, 2010, PSYCHOL INQ, V21, P271, DOI 10.1080/1047840X.2010.524882
   [Anonymous], 2007, REP APA TASK FORC SE, DOI [10.1177/0898264310393339, DOI 10.1177/0898264310393339]
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Baus O, 2017, VIRTUAL REAL-LONDON, V21, P59, DOI 10.1007/s10055-016-0299-3
   Bernard P, 2020, CURR DIR PSYCHOL SCI, V29, P134, DOI 10.1177/0963721419898187
   Bernard P, 2019, SAGE OPEN, V9, DOI 10.1177/2158244019828230
   Bernard P, 2018, EUR REV SOC PSYCHOL, V29, P82, DOI 10.1080/10463283.2018.1471949
   Bernard P, 2019, PERS SOC PSYCHOL B, V45, P16, DOI 10.1177/0146167218775690
   Bernard P, 2018, PSYCHOL POP MEDIA CU, V7, P99, DOI 10.1037/ppm0000114
   Bernard P, 2018, SOC PSYCHOL PERS SCI, V9, P550, DOI 10.1177/1948550617714582
   Bernard P, 2015, PSYCHOL WOMEN QUART, V39, P432, DOI 10.1177/0361684315580125
   Bernard P, 2012, PSYCHOL SCI, V23, P469, DOI 10.1177/0956797611434748
   Bläsing BE, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01909
   Brownlow S, 1997, PSYCHOL REC, V47, P411, DOI 10.1007/BF03395235
   Chouchourelou A, 2006, SOC NEUROSCI-UK, V1, P63, DOI 10.1080/17470910600630599
   Clarke TJ, 2005, PERCEPTION, V34, P1171, DOI 10.1068/p5203
   Cogoni C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193944
   Costello TH, 2020, PERSONAL DISORD, V11, P237, DOI 10.1037/per0000377
   D'Amours-Raymond J., 2011, VERSION ABREGEE TRAN
   DITTRICH WH, 1993, PERCEPTION, V22, P15, DOI 10.1068/p220015
   Dittrich WH, 1996, PERCEPTION, V25, P727, DOI 10.1068/p250727
   Fasoli F, 2018, SEX ROLES, V78, P338, DOI 10.1007/s11199-017-0808-1
   Federici A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61252-3
   Fink B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00220
   Fredrickson BL, 1997, PSYCHOL WOMEN QUART, V21, P173, DOI 10.1111/j.1471-6402.1997.tb00108.x
   Gervais SJ, 2018, PSYCHOL VIOLENCE, V8, P546, DOI 10.1037/vio0000148
   Gervais SJ, 2013, SEX ROLES, V69, P557, DOI 10.1007/s11199-013-0316-x
   Gervais SJ, 2013, NEBR SYM MOTIV, V60, P1, DOI 10.1007/978-1-4614-6959-9_1
   Gervais SJ, 2012, EUR J SOC PSYCHOL, V42, P743, DOI 10.1002/ejsp.1890
   Gramazio S, 2021, J INTERPERS VIOLENCE, V36, P6073, DOI 10.1177/0886260518816326
   Gray K, 2011, J PERS SOC PSYCHOL, V101, P1207, DOI 10.1037/a0025883
   Gummer T, 2021, SOCIOL METHOD RES, V50, P238, DOI 10.1177/0049124118769083
   Gunns RE, 2002, J NONVERBAL BEHAV, V26, P129, DOI 10.1023/A:1020744915533
   Heflick NA, 2011, J EXP SOC PSYCHOL, V47, P572, DOI 10.1016/j.jesp.2010.12.020
   Heflick NA, 2009, J EXP SOC PSYCHOL, V45, P598, DOI 10.1016/j.jesp.2009.02.008
   Hill H, 2000, PSYCHOL SCI, V11, P223, DOI 10.1111/1467-9280.00245
   Holland E, 2013, PSYCHOL WOMEN QUART, V37, P462, DOI 10.1177/0361684312474800
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Johnson KL, 2007, J PERS SOC PSYCHOL, V93, P321, DOI 10.1037/0022-3514.93.3.321
   Karsay K, 2018, PSYCHOL WOMEN QUART, V42, P9, DOI 10.1177/0361684317743019
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Loughnan S, 2013, PSYCHOL WOMEN QUART, V37, P455, DOI 10.1177/0361684313485718
   Loughnan S, 2010, EUR J SOC PSYCHOL, V40, P709, DOI 10.1002/ejsp.755
   Loula F, 2005, J EXP PSYCHOL HUMAN, V31, P210, DOI 10.1037/0096-1523.31.1.210
   Martinez L, 2016, COGNITION EMOTION, V30, P939, DOI 10.1080/02699931.2015.1035229
   MATHER G, 1994, P ROY SOC B-BIOL SCI, V258, P273, DOI 10.1098/rspb.1994.0173
   Miller L, 2018, VISION RES, V142, P58, DOI 10.1016/j.visres.2017.08.004
   Morrison ER, 2018, VIS COGN, V26, P405, DOI 10.1080/13506285.2018.1471560
   Okruszek L, 2017, SCHIZOPHR RES, V190, P3, DOI 10.1016/j.schres.2017.03.013
   Pacilli MG, 2017, BRIT J SOC PSYCHOL, V56, P293, DOI 10.1111/bjso.12169
   PAULHUS DL, 1984, J PERS SOC PSYCHOL, V46, P598, DOI 10.1037/0022-3514.46.3.598
   Pavlova MA, 2012, CEREB CORTEX, V22, P981, DOI 10.1093/cercor/bhr156
   Prasad S, 2009, J EXP PSYCHOL HUMAN, V35, P39, DOI 10.1037/a0012728
   Quintana P, 2019, CHEM SENSES, V44, P683, DOI 10.1093/chemse/bjz063
   Schmidt AF, 2015, COGNITION, V134, P77, DOI 10.1016/j.cognition.2014.09.003
   Sebanz N, 2009, PSYCHON B REV, V16, P170, DOI 10.3758/PBR.16.1.170
   Tarr MJ, 2013, PSYCHOL SCI, V24, P1069, DOI 10.1177/0956797612474669
   Thoresen JC, 2012, COGNITION, V124, P261, DOI 10.1016/j.cognition.2012.05.018
   Todorova GK, 2019, MOL AUTISM, V10, DOI 10.1186/s13229-019-0299-8
   Vaes J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42928-x
   Ward LM, 2016, J SEX RES, V53, P560, DOI 10.1080/00224499.2016.1142496
   Ward LM, 2016, SEX ROLES, V74, P12, DOI 10.1007/s11199-015-0548-z
   Zogmaister C, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229161
NR 64
TC 0
Z9 0
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 7
PY 2021
VL 2
AR 623660
DI 10.3389/frvir.2021.623660
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9BP1
UT WOS:001019320100001
OA gold
DA 2024-07-18
ER

PT J
AU Wu, YJ
   Wang, Y
   Jung, SC
   Hoermann, S
   Lindeman, RW
AF Wu, Yuanjie
   Wang, Yu
   Jung, Sungchul
   Hoermann, Simon
   Lindeman, Robert W.
TI Using a Fully Expressive Avatar to Collaborate in Virtual Reality:
   Evaluation of Task Performance, Presence, and Attraction
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE avatar; virtual reality; shared virtual environment; communication;
   collaboration
ID SOCIAL PRESENCE; FORM; COPRESENCE
AB Avatar-mediated collaboration in virtual environments is becoming more and more prevalent. However, current consumer systems are not suited to fully replicate real-world nonverbal communication. We present a novel avatar system for collaboration in virtual reality, which supports high levels of nonverbal expression by tracking behavior such as body movement, hand gesture, and facial expression. The system was built using camera tracking technology only. Therefore, in contrast to many other high-level tracking systems, it does not require users to wear additional trackers on their bodies. We compared our highly expressive system with a consumer setup extended with two body-worn trackers in a dyadic study. We investigated users' performance, such as completion time and accuracy, as well as the presence and interpersonal attraction in a virtual charades game using an asymmetric control scheme. The results show that participants interacting with highly expressive avatars felt more social presence and attraction and exhibited better task performance than those interacting with partners represented using low-expressive avatars. Hence, we conclude that virtual reality avatar systems benefit from a higher level of nonverbal expressiveness, which can be achieved without additional body-worn trackers.
C1 [Wu, Yuanjie; Jung, Sungchul; Lindeman, Robert W.] Univ Canterbury, Human Interface Technol Lab New Zealand HIT Lab NZ, Christchurch, New Zealand.
   [Wang, Yu] Beijing Inst Technol, Beijing, Peoples R China.
   [Hoermann, Simon] Univ Canterbury, Coll Engn, Sch Prod Design, Christchurch, New Zealand.
C3 University of Canterbury; Beijing Institute of Technology; University of
   Canterbury
RP Wu, YJ (corresponding author), Univ Canterbury, Human Interface Technol Lab New Zealand HIT Lab NZ, Christchurch, New Zealand.
EM yuanjie.wu@pg.canterbury.ac.nz
OI Wu, Yuanjie/0000-0001-7453-2649; Jung, Sungchul/0000-0003-3633-7767
CR Anjum N, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P201, DOI 10.1109/AVSS.2009.65
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Bailenson JN, 2004, PRESENCE-VIRTUAL AUG, V13, P428, DOI 10.1162/1054746041944803
   Bailenson JN, 2002, J VISUAL COMP ANIMAT, V13, P313, DOI 10.1002/vis.297
   Becker B, 2002, COMP SUPP COMP W SER, P19
   Bishop G., 2001, PROCEEDING SIGGRAPH
   Blender, 2019, BLEND ORG HOM BLEND
   Bombari D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00869
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Crazy Minnow Studio, 2019, SALSA LIPSYNC V2 AN
   Crazy Minnow Studio, 2014, SALSA LIPSYNC V1 AN
   Dana S., 2000, NAU 2000RUL CHAR
   Discord Inc, 2019, DISC CHAT COMM FRIEN
   Facebook, 2019, OCULUS RIFT
   Friston S, 2014, IEEE T VIS COMPUT GR, V20, P616, DOI 10.1109/TVCG.2014.30
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Geoffrey C., 1997, URBANIAK SCOTT
   Gergle D, 2013, HUM-COMPUT INTERACT, V28, P1, DOI 10.1080/07370024.2012.678246
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   HTC, 2018, VIV PROTH PROF GRAD
   HubPages Inc, 2020, CHAR TOP ID WORD LIS
   Jung S, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P3, DOI 10.1145/3131277.3132186
   Jung S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P267, DOI 10.1109/VR.2018.8447562
   Jung Sungchul., 2016, P 26 INT C ART REAL, P107, DOI DOI 10.2312/EGVE.20161442
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kwon B, 2017, IEEE ACCESS, V5, P12496, DOI 10.1109/ACCESS.2017.2723039
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P73, DOI 10.1145/2993369.2993399
   MakeHuman, 2018, MAKEHUMAN
   Matsumoto D., 2012, Nonverbal communication: Science and applications
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   Nilsson A, 2002, COMP SUPP COMP W SER, P112
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Oculus Lipsync, 2019, VIS REF
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Placidi G, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P184, DOI 10.5220/0006197801840192
   Radu B., 2011, IEEE INT C ROBOTICS
   RICE RE, 1993, HUM COMMUN RES, V19, P451, DOI 10.1111/j.1468-2958.1993.tb00309.x
   RootMotion, 2019, FIN IK ROOTMOTION
   Roth D, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364269
   Roth D, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P69, DOI 10.1145/3267782.3267791
   Roth D, 2017, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2017.7892275
   Roth D, 2016, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2016.7504760
   Rugland Development Group, 2010, RUG OSC LIBR
   Schroeder R, 2002, COMP SUPP COMP W SER, P1
   Schroeder Ralph, 2012, The social life of avatars: Presence and interaction in shared virtual environments
   Short J., 1976, The social psychology of telecommunications
   Slater M, 2002, COMP SUPP COMP W SER, P146
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Steed A, 1999, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.1999.756941
   Steed Anthony, 2015, Collaboration in Immersive and Non-immersive Virtual Environments, P263, DOI [DOI 10.1007/978-3-319-10190-3{_}11, 10.1007/978-3-319-10190-3_11, DOI 10.1007/978-3-319-10190-3_11]
   The Game Gal, 2020, GAM WORD GEN
   Ultrahaptics Ltd, 2017, UN LEAP MOT DEV
   Unity Technologies, 2019, UN REAL TIM DEV PLAT
   Valve Corporation, 2019, ABOUT US
   Walther JB, 1996, COMMUN RES, V23, P3, DOI 10.1177/009365096023001001
   Wu YJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364267
   Wu YJ, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100303
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 65
TC 16
Z9 17
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 7
PY 2021
VL 2
AR 641296
DI 10.3389/frvir.2021.641296
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WW1
UT WOS:001023294700001
OA gold
DA 2024-07-18
ER

PT J
AU König, SU
   Keshava, A
   Clay, V
   Rittershofer, K
   Kuske, N
   König, P
AF Koenig, Sabine U.
   Keshava, Ashima
   Clay, Viviane
   Rittershofer, Kirsten
   Kuske, Nicolas
   Koenig, Peter
TI Embodied Spatial Knowledge Acquisition in Immersive Virtual Reality:
   Comparison to Map Exploration
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE spatial cognition; embodied cognition; virtual reality; pointing task;
   cardinal direction; alignment; navigation
ID REFERENCE FRAMES; COGNITIVE MAP; NAVIGATION; REPRESENTATIONS;
   EXPERIENCE; ROUTE; ORIENTATION; INTEGRATION; VALIDATION; MEMORY
AB Investigating spatial knowledge acquisition in virtual environments allows studying different sources of information under controlled conditions. Therefore, we built a virtual environment in the style of a European village and investigated spatial knowledge acquisition by experience in the immersive virtual environment and compared it to using an interactive map of the same environment. The environment was well explored, with both exploration sources covering the whole village area. We tested knowledge of cardinal directions, building-to-building orientation, and judgment of direction between buildings in a pointing task. The judgment of directions was more accurate after exploration of the virtual environment than after map exploration. The opposite results were observed for knowledge of cardinal directions and relative orientation between buildings. Time for cognitive reasoning improved task accuracies after both exploration sources. Further, an alignment effect toward the north was only visible after map exploration. Taken together, our results suggest that the source of spatial exploration differentially influenced spatial knowledge acquisition.
C1 [Koenig, Sabine U.; Keshava, Ashima; Clay, Viviane; Rittershofer, Kirsten; Kuske, Nicolas; Koenig, Peter] Univ Osnabruck, Inst Cognit Sci, Osnabruck, Germany.
   [Koenig, Peter] Univ Med Ctr Hamburg Eppendorf, Dept Neurophysiol & Pathophysiol, Hamburg, Germany.
C3 University Osnabruck; University of Hamburg; University Medical Center
   Hamburg-Eppendorf
RP König, SU (corresponding author), Univ Osnabruck, Inst Cognit Sci, Osnabruck, Germany.
EM sabkoeni@uos.de
RI Clay, Viviane/AAR-8308-2021
OI Clay, Viviane/0000-0001-9152-0666
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [GRK-2340/1, GRK-2185/1]; ErgoVR (BMBF Call: KMU innovative:
   Technologiebereich Mensch-Technik-Interaction) [V5KMU17/221]
FX & nbsp;The study was funded by the Deutsche Forschungsgemeinschaft (DFG,
   German Research Foundation)-project number GRK-2340/1 (DFG Research
   Training Group Computational Cognition) (AK, PK); the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation)-project number
   GRK-2185/1 (DFG Research Training Group on Situated Cognition) (NK, PK);
   and ErgoVR (BMBF Call: KMU innovative: Technologiebereich
   Mensch-Technik-Interaction)-joint research project number V5KMU17/221
   (AK, PK).
CR Aldaba CN, 2020, MED BIOL ENG COMPUT, V58, P143, DOI 10.1007/s11517-019-02070-2
   Bellmund JLS, 2018, SCIENCE, V362, DOI 10.1126/science.aat6766
   Bohbot VD, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14415
   Brunyé TT, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135803
   Burte H., 2014, Spatial Cognition IX, P46, DOI DOI 10.1007/978-3-319-11215-2_4
   Byagowi A, 2014, J EXP NEUROSCI, V8, P7, DOI 10.4137/JEN.S13448
   Chadwick MJ, 2015, CURR BIOL, V25, P87, DOI 10.1016/j.cub.2014.11.001
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Coutrot A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213272
   Coutrot A, 2018, CURR BIOL, V28, P2861, DOI 10.1016/j.cub.2018.06.009
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Doeller CF, 2010, NATURE, V463, P657, DOI 10.1038/nature08704
   Ehinger BV, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00071
   Ekstrom A, 2010, ENCYCLOPEDIA OF BEHAVIORAL NEUROSCIENCE, VOL 2: H-O, P286
   Ekstrom AD, 2017, J NEUROPHYSIOL, V118, P3328, DOI 10.1152/jn.00531.2017
   Engel AK, 2013, TRENDS COGN SCI, V17, P202, DOI 10.1016/j.tics.2013.03.006
   Epstein RA, 2017, NAT NEUROSCI, V20, P1504, DOI 10.1038/nn.4656
   EVANS GW, 1980, J EXP PSYCHOL-HUM L, V6, P13, DOI 10.1037/0278-7393.6.1.13
   Evans JSBT, 2008, ANNU REV PSYCHOL, V59, P255, DOI 10.1146/annurev.psych.59.103006.093629
   EVANS JSBT, 1984, BRIT J PSYCHOL, V75, P451, DOI 10.1111/j.2044-8295.1984.tb01915.x
   Finucane ML, 2000, J BEHAV DECIS MAKING, V13, P1, DOI 10.1002/(SICI)1099-0771(200001/03)13:1<1::AID-BDM333>3.0.CO;2-S
   Frankenstein J, 2012, PSYCHOL SCI, V23, P120, DOI 10.1177/0956797611429467
   Goeke CM, 2013, FRONT BEHAV NEUROSCI, V7, DOI 10.3389/fnbeh.2013.00005
   Gramann K, 2005, J EXP PSYCHOL HUMAN, V31, P1199, DOI 10.1037/0096-1523.31.6.1199
   Gramann K, 2013, SPAT COGN COMPUT, V13, P1, DOI 10.1080/13875868.2011.589038
   Gramann K, 2010, J COGNITIVE NEUROSCI, V22, P2836, DOI 10.1162/jocn.2009.21369
   Grant SC, 1998, HUM FACTORS, V40, P489, DOI 10.1518/001872098779591296
   Gwin JT, 2011, NEUROIMAGE, V54, P1289, DOI 10.1016/j.neuroimage.2010.08.066
   Hashemian A. M., 2015, P 3 ACM S SPAT US IN, P123, DOI DOI 10.1145/2788940.2788956
   Hegarty M, 2018, HANDBOOK OF BEHAVIORAL AND COGNITIVE GEOGRAPHY, P231
   Holmes MC, 2005, J EXP PSYCHOL LEARN, V31, P1069, DOI 10.1037/0278-7393.31.5.1069
   Ishikawa T, 2006, COGNITIVE PSYCHOL, V52, P93, DOI 10.1016/j.cogpsych.2005.08.003
   Jungnickel E, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00306
   Kärcher SM, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00037
   Kahneman Daniel., 2002, Kahenman and Frederick, 2002, P1
   Kaspar K, 2014, CONSCIOUS COGN, V28, P47, DOI 10.1016/j.concog.2014.06.006
   Kimura K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18289-8
   Kitson A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01354
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   KLATZKY RL, 1990, J MOTOR BEHAV, V22, P19
   König SU, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00240
   König SU, 2019, PSYCHOL RES-PSYCH FO, V83, P498, DOI 10.1007/s00426-017-0899-x
   König SU, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166647
   Ko''nig SU, 2020, bioRxiv, DOI [10.1101/2020.01.12.903096, 10.1101/2020.01.12.903096, DOI 10.1101/2020.01.12.903096]
   Kose A., 2017, C DAT APPL SEC CAL C, P297, DOI [10.1007/978-3-319-60928-7_26, DOI 10.1007/978-3-319-60928-7_26]
   Liang ML, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.13090
   LOOMIS JM, 1993, J EXP PSYCHOL GEN, V122, P73, DOI 10.1037/0096-3445.122.1.73
   Maguire EA, 2006, BRAIN, V129, P2894, DOI 10.1093/brain/awl286
   Mallot H. A., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P447
   McNamara T. P., 2008, HUMAN SPATIAL MEMORY, DOI [10.1016/b078-012370509-9.00176-5, DOI 10.1016/B078-012370509-9.00176-5]
   McNamara TP, 2003, LECT NOTES ARTIF INT, V2685, P174
   McNamara TP, 2003, PSYCHON B REV, V10, P589, DOI 10.3758/BF03196519
   Meilinger T., 2006, P 29 ANN C COGN SCI, P479
   Meilinger T, 2008, LECT NOTES ARTIF INT, V5248, P344, DOI 10.1007/978-3-540-87601-4_25
   Meilinger T, 2015, PSYCHOL RES-PSYCH FO, V79, P1000, DOI 10.1007/s00426-014-0629-6
   Meilinger T, 2013, COGNITION, V129, P24, DOI 10.1016/j.cognition.2013.05.013
   Montello D.R., 1998, Spatial and temporal reasoning in geographic information systems, chapter A new framework for understanding the acquisition of spatial knowledge in large-scale environments
   Montello DR, 2004, HUMAN SPATIAL MEMORY: REMEMBERING WHERE, P251
   Mou WM, 2002, J EXP PSYCHOL LEARN, V28, P162, DOI 10.1037//0278-7393.28.1.162
   Mou WM, 2004, J EXP PSYCHOL LEARN, V30, P142, DOI 10.1037/0278-7393.30.1.142
   Münzer S, 2016, J ENVIRON PSYCHOL, V47, P66, DOI 10.1016/j.jenvp.2016.04.017
   Münzer S, 2016, DATA BRIEF, V8, P803, DOI 10.1016/j.dib.2016.06.039
   Münzer S, 2011, DIAGNOSTICA, V57, P111, DOI 10.1026/0012-1924/a000040
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Nagel SK, 2005, J NEURAL ENG, V2, pR13, DOI 10.1088/1741-2560/2/4/R02
   NOE Alva, 2006, Action in Perception
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Oliveira AS, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/3/036014
   PRESSON CC, 1984, J EXP PSYCHOL LEARN, V10, P716, DOI 10.1037/0278-7393.10.4.716
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Reiser JE, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49503-4
   Richardson AE, 1999, MEM COGNITION, V27, P741, DOI 10.3758/BF03211566
   Riecke B. E., 2010, PHYS ROTATIONS ALONE, V6222, P234, DOI [10.1007/978-3-642-14749-4_21, DOI 10.1007/978-3-642-14749-4_21]
   Riecke BE, 2002, PRESENCE-VIRTUAL AUG, V11, P443, DOI 10.1162/105474602320935810
   Riecke BE, 2007, PSYCHOL RES-PSYCH FO, V71, P298, DOI 10.1007/s00426-006-0085-z
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2011, MEM COGNITION, V39, P686, DOI 10.3758/s13421-010-0054-z
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Shelton AL, 2004, J EXP PSYCHOL LEARN, V30, P158, DOI 10.1037/0278-7393.30.1.158
   Shelton AL, 1997, PSYCHON B REV, V4, P102, DOI 10.3758/BF03210780
   Shelton AL, 2001, COGNITIVE PSYCHOL, V43, P274, DOI 10.1006/cogp.2001.0758
   Shine JP, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11802-9
   Sholl M.J., 1996, CONSTRUCTION COGNITI, P157, DOI DOI 10.1007/978-0-585-33485-1_8
   Sholl MJ, 2006, J EXP PSYCHOL LEARN, V32, P516, DOI 10.1037/0278-7393.32.3.516
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Somrak A, 2019, FUTURE GENER COMP SY, V94, P302, DOI 10.1016/j.future.2018.11.041
   Spiers HJ, 2007, TRENDS COGN SCI, V11, P356, DOI 10.1016/j.tics.2007.06.002
   Starrett MJ, 2019, J EXP PSYCHOL LEARN, V45, P497, DOI 10.1037/xlm0000597
   Taylor HA, 1999, MEM COGNITION, V27, P309, DOI 10.3758/BF03211414
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   Varela F. J., 1991, EMBODIED MIND COGNIT, DOI [10.1111/j.1468-0149.1965.tb01386.x, DOI 10.1111/J.1468-0149.1965.TB01386.X]
   Waller D, 2004, PSYCHON B REV, V11, P157, DOI 10.3758/BF03206476
   Waller D, 2006, J EXP PSYCHOL LEARN, V32, P867, DOI 10.1037/0278-7393.32.4.867
   Wang RXF, 2000, COGNITION, V77, P215, DOI 10.1016/S0010-0277(00)00105-0
   Wiener JM, 2009, SPAT COGN COMPUT, V9, P152, DOI 10.1080/13875860902906496
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Zhang H, 2014, MEM COGNITION, V42, P1106, DOI 10.3758/s13421-014-0418-x
   Zhang H, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044886
NR 103
TC 2
Z9 2
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 3
PY 2021
VL 2
AR 625548
DI 10.3389/frvir.2021.625548
PG 23
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2QS5
UT WOS:001021762200001
OA Green Published, Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Sampaio, M
   Haro, MVN
   De Sousa, B
   Melo, WV
   Hoffman, HG
AF Sampaio, Mariana
   Navarro Haro, Maria Vicenta
   De Sousa, Bruno
   Vieira Melo, Wilson
   Hoffman, Hunter G.
TI Therapists Make the Switch to Telepsychology to Safely Continue Treating
   Their Patients During the COVID-19 Pandemic. Virtual Reality
   Telepsychology May Be Next
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE COVID-19; virtual reality; mental health; telepsychology;
   burnout-professional; psychology; stress; anxiety
ID POSTTRAUMATIC-STRESS-DISORDER; EXPOSURE THERAPY; SPIDER PHOBIA; PAIN;
   AUGMENTATION; STAFF; CARE
AB Before COVID-19, most therapists had concerns about telepsychology, and only treated patients in person. During the COVID-19 lockdown, patients still needed therapy, but in-person therapy sessions became unsafe. The current study measured how many therapists are using online therapy before vs. during COVID-19, how much training they have received, and their knowledge about legal restrictions on using telepsychology. A sample of 768U.S.A. mental health professionals completed a 29-item online survey. Results show that before COVID-19, most therapists only saw their patients in person (e.g., at the therapists office), but during the COVID-19 pandemic, nearly all therapists used a wide range of telecommunication technologies to communicate with their quarantined patients, including texting, telephones, video conferences, and even virtual reality. According to within-subject related samples comparisons, 39% of survey respondents used telepsychology before COVID-19, vs. 98% during COVID-19 (chi(2) = 450.02, p < 0.001). Therapists reported high treatment effectiveness using telepsychology (7.45 on 0-10 scale). However, overall, on a 010 scale, therapists reported a significant increase in feeling burned out during the COVID-19 pandemic, Mean = 3.93 (SD = 1.93) before vs. 6.22 (SD = 2.27) during the pandemic (Z = -18.57, p < 0.001). Although the APA ethics guidelines encourage therapists to use telepsychology with their patients during the crisis, gaps in respondents' knowledge identify a need for increased specialized training and education. Although the current study showed that virtual reality is rarely used by the therapists surveyed, virtual reality is a promising new telepsychology technology. Billions of dollars are currently being invested in mass producing immersive virtual reality systems. In the future, as networked immersive Virtual Reality becomes more widely available, therapists and patients in physically different locations will be able to "meet" in a shared computer-generated world designed for therapy sessions, potentially including group sessions. Telepsychology and virtual reality have the potential to be increasingly valuable tools to help therapists mitigate the consequences of COVID-19. Research, development and training is recommended.
C1 [Sampaio, Mariana] Univ Coimbra, Dept Psychol, Coimbra, Portugal.
   [Sampaio, Mariana] Catholic Univ Portugal, Dept Social Work, Lisbon, Portugal.
   [Navarro Haro, Maria Vicenta] Univ Zaragoza, Inst Aragones Invest Sanit, Zaragoza, Spain.
   [Navarro Haro, Maria Vicenta] Univ Zaragoza, Fac Econ & Business, Dept Psychol & Sociol, Zaragoza, Spain.
   [De Sousa, Bruno] Univ Coimbra, Fac Psychol & Educ Sci, Coimbra, Portugal.
   [Hoffman, Hunter G.] Univ Washington, Dept Mech Engn Radiol & Psychol, Seattle, WA 98195 USA.
   [Hoffman, Hunter G.] Univ Washington, Virtual Real Res Ctr, Human Photon Lab, Seattle, WA 98195 USA.
C3 Universidade de Coimbra; Universidade Catolica Portuguesa; University of
   Zaragoza; University of Zaragoza; Universidade de Coimbra; University of
   Washington; University of Washington Seattle; University of Washington;
   University of Washington Seattle
RP Hoffman, HG (corresponding author), Univ Washington, Dept Mech Engn Radiol & Psychol, Seattle, WA 98195 USA.; Hoffman, HG (corresponding author), Univ Washington, Virtual Real Res Ctr, Human Photon Lab, Seattle, WA 98195 USA.
EM hoontair@gmail.com
RI Haro, Maria Vicenta Navarro/AAM-8500-2020; de Sousa, Bruno/A-1654-2012
OI Haro, Maria Vicenta Navarro/0000-0001-9726-3250; de Sousa,
   Bruno/0000-0001-9918-8100
FU Mayday Fund; NIH [R01GM042725]; Gobierno de Aragon; Construyendo Europa
   desde Aragon; University of Coimbra
FX During preparation of this manuscript, HH was supported by charitable
   funds from the Mayday Fund, and NIH grant R01GM042725, MN was supported
   by Gobierno de Aragon (Group reference: S31_20D) and by Feder 2014-2020
   Construyendo Europa desde Aragon, and BD is a professor at the
   University of Coimbra.
CR Anderson PL, 2005, DEPRESS ANXIETY, V22, P156, DOI 10.1002/da.20090
   [Anonymous], 1998, Cyberpsychol Behav Soc Netw, DOI [10.1089/cpb.1998.1.195, DOI 10.1089/CPB.1998.1.195]
   [Anonymous], 2021, WHO director-generals' opening remarks at the media briefing on Covid 19
   Atkeson A., 2020, Working Paper 26867, V26867, DOI [10.3386/w26867, DOI 10.3386/W26867]
   Bai Y, 2020, JAMA-J AM MED ASSOC, V323, P1406, DOI 10.1001/jama.2020.2565
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Boeldt D, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00773
   Broughton JP, 2020, NAT BIOTECHNOL, V38, P870, DOI 10.1038/s41587-020-0513-4
   Callan JE., 2017, CAREER PATHS TELEMEN, P63
   Carlin AS, 1997, BEHAV RES THER, V35, P153, DOI 10.1016/S0005-7967(96)00085-X
   Caver KA, 2020, J CLIN PSYCHOL, V76, P1108, DOI 10.1002/jclp.22797
   CDC, 2020, COP STRESS
   Chenneville T, 2020, AM PSYCHOL, V75, P644, DOI 10.1037/amp0000661
   Christofferson JL, 2020, J FAM PSYCHOL, V34, P237, DOI 10.1037/fam0000597
   Difede J, 2002, CYBERPSYCHOL BEHAV, V5, P529, DOI 10.1089/109493102321018169
   Difede J, 2014, NEUROPSYCHOPHARMACOL, V39, P1052, DOI 10.1038/npp.2013.317
   Dilgul M, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.609545
   Dolan ED, 2015, J GEN INTERN MED, V30, P582, DOI 10.1007/s11606-014-3112-6
   Eaton LH, 2014, CONTEMP CLIN TRIALS, V38, P213, DOI 10.1016/j.cct.2014.05.005
   Eccleston C, 2020, PAIN, V161, P889, DOI 10.1097/j.pain.0000000000001885
   Flores A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00531
   FREUDENBERGER HJ, 1974, J SOC ISSUES, V30, P159, DOI 10.1111/j.1540-4560.1974.tb00706.x
   Galea S, 2020, JAMA INTERN MED, V180, P817, DOI 10.1001/jamainternmed.2020.1562
   Garcia-Palacios A, 2002, BEHAV RES THER, V40, P983, DOI 10.1016/S0005-7967(01)00068-7
   Glueckauf RL, 2018, PROF PSYCHOL-RES PR, V49, P205, DOI 10.1037/pro0000188
   Godleski L, 2012, PSYCHIAT SERV, V63, P383, DOI 10.1176/appi.ps.201100206
   Gomez J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01611
   Hoffman HG, 2004, SCI AM, V291, P58, DOI 10.1038/scientificamerican0804-58
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Joint Task Force Dev Telepsycholog, 2013, AM PSYCHOL, V68, P791, DOI 10.1037/a0035001
   Katz AC, 2020, PSYCHOL TRAUMA-US, V12, P756, DOI 10.1037/tra0000567
   Keefe FJ, 2012, PAIN, V153, P2163, DOI 10.1016/j.pain.2012.05.030
   Lai JB, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3976
   Luken M, 2016, AM J OCCUP THER, V70, DOI 10.5014/ajot.2016.016956
   Mahase E, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1872
   McDonald R.P., 1999, Test Theory: A Unified Treatment
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   Navarro-Haro MV, 2019, COMMUNITY MENT HLT J, V55, P100, DOI 10.1007/s10597-018-0254-8
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Ningthoujam Ramananda, 2020, Curr Med Res Pract, V10, P132, DOI 10.1016/j.cmrp.2020.05.003
   Perry K, 2020, J CLIN PSYCHOL, V76, P1125, DOI 10.1002/jclp.22770
   Pfefferbaum B, 2020, NEW ENGL J MED, V383, P510, DOI 10.1056/NEJMp2008017
   Pierce BS, 2021, AM PSYCHOL, V76, P14, DOI 10.1037/amp0000722
   Prime H, 2020, AM PSYCHOL, V75, P631, DOI 10.1037/amp0000660
   Reger GM, 2016, J CONSULT CLIN PSYCH, V84, P946, DOI 10.1037/ccp0000134
   Rehm J, 2020, DRUG ALCOHOL REV, V39, P301, DOI 10.1111/dar.13074
   Rizzo A. S., 2019, Virtual reality for psychological and neurocognitive interventions
   Rizzo A, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1414560
   Singh S, 2020, PSYCHIAT RES, V293, DOI 10.1016/j.psychres.2020.113429
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Wellenius GA, 2020, IMPACTS STATE LEVEL
NR 53
TC 39
Z9 55
U1 0
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 15
PY 2021
VL 1
AR 576421
DI 10.3389/frvir.2020.576421
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WY2
UT WOS:001023296800001
PM 33585834
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Harvie, DS
   Rio, E
   Smith, RT
   Olthof, N
   Coppieters, MW
AF Harvie, Daniel S.
   Rio, Ebonie
   Smith, Ross T.
   Olthof, Nick
   Coppieters, Michel W.
TI Virtual Reality Body Image Training for Chronic Low Back Pain: A Single
   Case Report
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; low back pain; chronic pain; embodiment; body image;
   disability; rehabilitation; body illusions
ID MOVEMENT (RE)INJURY; SELF; FEAR; REPRESENTATIONS; PERCEPTION; PEOPLE
AB Background: Virtual reality (VR) allows people to embody avatars that are different from themselves in appearance and ability. These experiences provide opportunities to challenge bodily perceptions. We devised a novel VR Body Image Training (VR-BIT) approach to target self-perceptions and pain in people with persistent pain.
   Methods: A 45-year old male with a 5-year history of disabling chronic low back pain participated in a 4-week VR-BIT intervention. Pain began following a fall from a first-floor deck. Pain was central and on the right side of his lower back, radiating to his right buttock and thigh. Pain was constant and varying at a 5/10 average intensity. The 4-week intervention consistent of three face-to-face sessions 1-week apart, followed by 1-week of in-home VR-BIT. During the first face-to-face session, the participant embodied three athletic avatars: a superhero (Incredible Hulk), a boxer, and a rock climber. Since the participant strongly identified with the boxer, only boxing experiences were subsequently used. Primary outcomes relating to body image (self-perceived strength, vulnerability, agility, and confidence with activity) and pain intensity were assessed using numerical rating scales (0-10 NRS). Disability, kinesiophobia, overall change, and self-efficacy were assessed as secondary outcomes. Outcomes were assessed during each face-to-face session, and at 1-week and 3-month follow-up.
   Results: The participant reported a high degree of engagement. Positive changes were noted during and after VR for all body image and pain assessments. Improvements were retained at 3-months for body image ratings (mean change: 4.5/10 NRS) and average pain intensity (change: 2/10 NRS). Improvements in disability (45% improvement); self-efficacy (pre: 2/12; post: 10/12); and overall change ("Very much improved") were noted at 3-month follow-up. No change in kinesiophobia was detected. No adverse advents were recorded.
   Conclusion: The participant engaged strongly with the intervention and showed clinically meaningful changes in body image, pain, disability, and self-efficacy. Despite his long history of pain and rapid improvements, reported changes may be due to non-treatment effects. Nonetheless, VR-BIT clearly warrants further investigation as a potential addition to usual care.
C1 [Harvie, Daniel S.; Olthof, Nick; Coppieters, Michel W.] Griffith Univ, Menzies Hlth Inst Queensland, Gold Coast, Qld, Australia.
   [Harvie, Daniel S.; Olthof, Nick] Griffith Univ, Sch Allied Hlth Sci, Gold Coast, Qld, Australia.
   [Harvie, Daniel S.; Smith, Ross T.] Univ South Australia, Australian Ctr Interact & Virtual Environm, Wearable Comp Lab, Adelaide, SA, Australia.
   [Rio, Ebonie] La Trobe Univ, Coll Sci, La Trobe Sport & Exercise Med Ctr, Sch Allied Hlth, Melbourne, Vic, Australia.
   [Coppieters, Michel W.] Vrije Univ Amsterdam, Fac Behav & Movement Sci, Amsterdam Movement Sci, Amsterdam, Netherlands.
C3 Griffith University; Griffith University - Gold Coast Campus; Menzies
   Health Institute Queensland; Griffith University; Griffith University -
   Gold Coast Campus; University of South Australia; La Trobe University;
   Vrije Universiteit Amsterdam
RP Harvie, DS (corresponding author), Griffith Univ, Menzies Hlth Inst Queensland, Gold Coast, Qld, Australia.; Harvie, DS (corresponding author), Griffith Univ, Sch Allied Hlth Sci, Gold Coast, Qld, Australia.; Harvie, DS (corresponding author), Univ South Australia, Australian Ctr Interact & Virtual Environm, Wearable Comp Lab, Adelaide, SA, Australia.
EM d.harvie@griffith.edu.au
RI Rio, Ebonie/S-1962-2019; Coppieters, Michel W/AAW-7326-2021; Harvie,
   Daniel/AAR-2678-2020; Smith, Ross/L-4790-2016
OI Rio, Ebonie/0000-0002-6854-929X; Coppieters, Michel
   W/0000-0002-3958-4408; Harvie, Daniel/0000-0001-7693-4158; Smith,
   Ross/0000-0002-9044-9199
FU Hopkins Centre seeding grant; National Health and Medical Research
   Council of Australia [APP1142929]
FX This project was supported by a Hopkins Centre seeding grant. DH was
   supported by an Early Career Research Fellowship from the National
   Health and Medical Research Council of Australia (APP1142929). The
   funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Costa Mark R., 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P333, DOI 10.1007/978-3-642-39405-8_37
   Crombez G, 2012, CLIN J PAIN, V28, P475, DOI 10.1097/AJP.0b013e3182385392
   Farrar JT, 2001, PAIN, V94, P149, DOI 10.1016/S0304-3959(01)00349-9
   Fischer D, 1999, JAMA-J AM MED ASSOC, V282, P1157, DOI 10.1001/jama.282.12.1157
   Foell J, 2014, EUR J PAIN, V18, P729, DOI 10.1002/j.1532-2149.2013.00433.x
   Gadsby S, 2017, CONSCIOUS COGN, V51, P17, DOI 10.1016/j.concog.2017.02.015
   Giummarra MJ, 2011, NEUROPSYCHOL REV, V21, P320, DOI 10.1007/s11065-011-9184-8
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Kaplan RA, 2013, COGN NEUROPSYCHIATRY, V18, P594, DOI 10.1080/13546805.2012.758878
   Keizer A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163921
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Lee H, 2016, PAIN, V157, P922, DOI 10.1097/j.pain.0000000000000472
   Levenig CG, 2016, SCHMERZ, V30, P437, DOI 10.1007/s00482-016-0122-9
   Levenig CG, 2019, SCAND J PAIN, V19, P147, DOI 10.1515/sjpain-2018-0104
   Lozano Luis M., 2008, Methodology, P73, DOI [10.1027/1614-2241.4.2.73, DOI 10.1027/1614-2241.4.2.73]
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   Moseley GL, 2012, NEUROREHAB NEURAL RE, V26, P646, DOI 10.1177/1545968311433209
   Moseley GL, 2012, NEUROSCI BIOBEHAV R, V36, P34, DOI 10.1016/j.neubiorev.2011.03.013
   Moseley GL, 2004, EUR J PAIN, V8, P39, DOI 10.1016/S1090-3801(03)00063-6
   Moseley GL, 2003, MANUAL THER, V8, P130, DOI 10.1016/S1356-689X(03)00051-1
   Nicholas MK, 2015, J PAIN, V16, P153, DOI 10.1016/j.jpain.2014.11.002
   Nishigami T, 2019, MUSCULOSKEL SCI PRAC, V39, P178, DOI 10.1016/j.msksp.2018.07.002
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Riva G, 2017, ANN REV CYBERTHERAPY, V15, P3
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Samad M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117178
   Schmitz C, 2015, LimeSurvey: An Open Source survey tool
   Serino S, 2019, J CLIN PSYCHOL, V75, P313, DOI 10.1002/jclp.22724
   Serino S, 2017, ANN REV CYBERTHERAPY, V15, P111
   Serino S, 2016, CYBERPSYCH BEH SOC N, V19, P127, DOI 10.1089/cyber.2015.0229
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Slater M, 2014, COMPUTER, V47, P24, DOI 10.1109/MC.2014.198
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Sleijser-Koehorst MLS, 2019, PAIN, V160, P600, DOI 10.1097/j.pain.0000000000001441
   Stanton TR, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09429-1
   Stratford PW, 1996, PHYS THER, V76, P359, DOI 10.1093/ptj/76.4.359
   Verhagen AP, 2016, EUR SPINE J, V25, P2788, DOI 10.1007/s00586-016-4684-0
   Vlaeyen JWS, 1995, J OCCUP REHABIL, V5, P235, DOI 10.1007/BF02109988
   VLAEYEN JWS, 1995, PAIN, V62, P363, DOI 10.1016/0304-3959(94)00279-N
   Wand BM, 2016, J PAIN, V17, P1001, DOI 10.1016/j.jpain.2016.06.003
   Ziser K, 2018, INT J EAT DISORDER, V51, P1121, DOI 10.1002/eat.22946
NR 45
TC 7
Z9 7
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 14
PY 2020
VL 1
AR 13
DI 10.3389/frvir.2020.00013
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XG0
UT WOS:001023304600001
OA Green Accepted, Green Published, gold
DA 2024-07-18
ER

PT J
AU Guy, M
   Normand, JM
   Jeunet-Kelway, C
   Moreau, G
AF Guy, Martin
   Normand, Jean-Marie
   Jeunet-Kelway, Camille
   Moreau, Guillaume
TI The sense of embodiment in Virtual Reality and its assessment methods
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; review; embodiment; evaluation; assessment method
ID OF-BODY EXPERIENCE; SELF-LOCATION; RUBBER HAND; ILLUSORY OWNERSHIP;
   NEURAL SIGNATURES; AGENCY; ATTENUATION; BRAIN; AVATAR; FEEL
AB The sense of embodiment refers to the sensations of being inside, having, and controlling a body. In virtual reality, it is possible to substitute a person's body with a virtual body, referred to as an avatar. Modulations of the sense of embodiment through modifications of this avatar have perceptual and behavioural consequences on users that can influence the way users interact with the virtual environment. Therefore, it is essential to define metrics that enable a reliable assessment of the sense of embodiment in virtual reality to better understand its dimensions, the way they interact, and their influence on the quality of interaction in the virtual environment. In this review, we first introduce the current knowledge on the sense of embodiment, its dimensions (senses of agency, body ownership, and self-location), and how they relate the ones with the others. Then, we dive into the different methods currently used to assess the sense of embodiment, ranging from questionnaires to neurophysiological measures. We provide a critical analysis of the existing metrics, discussing their advantages and drawbacks in the context of virtual reality. Notably, we argue that real-time measures of embodiment, which are also specific and do not require double tasking, are the most relevant in the context of virtual reality. Electroencephalography seems a good candidate for the future if its drawbacks (such as its sensitivity to movement and practicality) are improved. While the perfect metric has yet to be identified if it exists, this work provides clues on which metric to choose depending on the context, which should hopefully contribute to better assessing and understanding the sense of embodiment in virtual reality.
C1 [Guy, Martin; Normand, Jean-Marie] Nantes Univ, Ecole Cent Nantes, AAU CRENAU, UMR 1563, Nantes, France.
   [Normand, Jean-Marie; Moreau, Guillaume] Inria Hybrid, Rennes, France.
   [Jeunet-Kelway, Camille] Univ Bordeaux, Inst Neurosci Cognit & Integrat Aquitaine, CNRS, UMR5287, Bordeaux, France.
   [Moreau, Guillaume] IMT Atlantique, Lab STICC, UMR 6285, Brest, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Humanities & Social Sciences (INSHS); Nantes Universite; Ecole
   Centrale de Nantes; Centre National de la Recherche Scientifique (CNRS);
   Universite de Bordeaux; CNRS - National Institute for Biology (INSB);
   Universite de Bretagne Occidentale; IMT - Institut Mines-Telecom; IMT
   Atlantique
RP Guy, M (corresponding author), Nantes Univ, Ecole Cent Nantes, AAU CRENAU, UMR 1563, Nantes, France.
EM martinguy-crenau@protonmail.com
OI Jeunet, Camille/0000-0001-8619-3082
CR Abdulkarim Z, 2016, ATTEN PERCEPT PSYCHO, V78, P707, DOI 10.3758/s13414-015-1016-0
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Alchalabi B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P776, DOI [10.1109/VR.2019.8798263, 10.1109/vr.2019.8798263]
   Alexandrovsky D., 2020, P 2020 CHI C HUM FAC, P1
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   Atkinson S., 2020, The future of film report 2020, DOI [10.18742/PUB01-020, DOI 10.18742/PUB01-020]
   Bach F, 2012, BIOMED ENG-BIOMED TE, V57, P718, DOI 10.1515/bmt-2012-4084
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bays PM, 2006, PLOS BIOL, V4, P281, DOI 10.1371/journal.pbio.0040028
   Bekrater-Bodmann R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087013
   Blakemore S.-J., 2000, Why can't you tickle yourself?, P6
   Blakemore SJ, 1998, NAT NEUROSCI, V1, P635, DOI 10.1038/2870
   Blakemore SJ, 1999, J COGNITIVE NEUROSCI, V11, P551, DOI 10.1162/089892999563607
   Blanke O, 2005, NEUROSCIENTIST, V11, P16, DOI 10.1177/1073858404270885
   Blanke O, 2004, BRAIN, V127, P243, DOI 10.1093/brain/awh040
   Blanke O, 2015, NEURON, V88, P145, DOI 10.1016/j.neuron.2015.09.029
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Blefari ML, 2011, IEEE T BIO-MED ENG, V58, P12, DOI 10.1109/TBME.2010.2076282
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169343
   Bouville Rozenn, 2015, 2015 IEEE 8th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS), P33, DOI 10.1109/SEARIS.2015.7854099
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   BROWNSTEIN M., 2019, STANFORD ENCY PHILOS
   Burin D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02762
   Cardoso-Leite P, 2010, PSYCHOL SCI, V21, P1740, DOI 10.1177/0956797610389187
   Cauda F, 2011, NEUROIMAGE, V55, P8, DOI 10.1016/j.neuroimage.2010.11.049
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/ICSENS.2015.7370446, 10.1109/GLOCOM.2015.7417476]
   Chen WY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19662-x
   Claude G., 2014, Short paper: #SEVEN, a sensor effector based scenarios model for driving collaborative virtual environment
   Critchley HD, 2004, NAT NEUROSCI, V7, P189, DOI 10.1038/nn1176
   David N, 2008, CONSCIOUS COGN, V17, P523, DOI 10.1016/j.concog.2008.03.004
   David N, 2006, J COGNITIVE NEUROSCI, V18, P898, DOI 10.1162/jocn.2006.18.6.898
   De Preester H, 2009, PHENOMENOL COGN SCI, V8, P307, DOI 10.1007/s11097-009-9121-y
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Dewey JA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110118
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Dobricki M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083840
   Donker T, 2019, JAMA PSYCHIAT, V76, P682, DOI 10.1001/jamapsychiatry.2019.0219
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Ehrsson HH, 2007, P NATL ACAD SCI USA, V104, P9828, DOI 10.1073/pnas.0610011104
   Ehrsson HH, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28177-z
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Eubanks JC, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647896
   Evans N, 2013, NEUROIMAGE, V64, P216, DOI 10.1016/j.neuroimage.2012.09.027
   Farrer C, 2003, NEUROIMAGE, V18, P324, DOI 10.1016/S1053-8119(02)00041-1
   Farrer C, 2002, NEUROIMAGE, V15, P596, DOI 10.1006/nimg.2001.1009
   Felton WM, 2022, INT J HUM-COMPUT INT, V38, P1, DOI 10.1080/10447318.2021.1921368
   Freeling B., 2022, 21 IEEE INT S MIX AU
   Fribourg R, 2021, COMPUT GRAPH-UK, V100, P125, DOI 10.1016/j.cag.2021.07.017
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fribourg R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P273, DOI 10.1109/VR.2018.8448293
   Frith C.D., 1992, COGN NEUROPSYCHOL
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Gallagher S, 2012, NEW IDEAS PSYCHOL, V30, P15, DOI 10.1016/j.newideapsych.2010.03.003
   Gentsch A, 2011, J COGNITIVE NEUROSCI, V23, P3817, DOI 10.1162/jocn_a_00012
   George Laurent, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P124, DOI 10.1007/978-3-642-31401-8_12
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2014, EXP BRAIN RES, V232, P875, DOI 10.1007/s00221-013-3800-1
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Graziano MSA, 2006, NEUROPSYCHOLOGIA, V44, P845, DOI 10.1016/j.neuropsychologia.2005.09.009
   Guy M., 2022, ICAT-EGVE 2022-international conference on artificial reality and telexistence and eurographics symposium on virtual environments, DOI [10.2312/egve.20221281, DOI 10.2312/EGVE.20221281]
   Haggard P, 2003, CONSCIOUS COGN, V12, P695, DOI 10.1016/S1053-8100(03)00052-7
   Haggard P, 2017, NAT REV NEUROSCI, V18, P197, DOI 10.1038/nrn.2017.14
   Haggard P, 2012, CURR BIOL, V22, pR390, DOI 10.1016/j.cub.2012.02.040
   Halligan PW, 2003, TRENDS COGN SCI, V7, P125, DOI 10.1016/S1364-6613(03)00032-9
   Hassan A, 2016, CURR NEUROL NEUROSCI, V16, DOI 10.1007/s11910-016-0676-z
   Hatfield Gary., 1990, The Natural and the Normative: Theories of Spatial Perception from Kant to Helmholtz
   Hohwy J, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009416
   Holmes NP, 2006, PERCEPT PSYCHOPHYS, V68, P685, DOI 10.3758/BF03208768
   Holmes NP, 2004, COGN AFFECT BEHAV NE, V4, P193, DOI 10.3758/CABN.4.2.193
   Horváth J, 2015, BRAIN RES, V1626, P54, DOI 10.1016/j.brainres.2015.03.038
   Ionta S, 2011, NEURON, V70, P363, DOI 10.1016/j.neuron.2011.03.009
   Jahedi S, 2014, J ECON BEHAV ORGAN, V98, P97, DOI 10.1016/j.jebo.2013.12.016
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Kammers MPM, 2011, NEUROPSYCHOLOGIA, V49, P1316, DOI 10.1016/j.neuropsychologia.2011.02.039
   Kang SY, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135261
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kirsch I, 2001, CURR DIR PSYCHOL SCI, V10, P57, DOI 10.1111/1467-8721.00115
   Kirsch I., 1989, HYPNOSIS COGNITIVE B, P360
   Kocur M., 2023, 28 ACM S VIRT REAL S
   Kühn S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0028657
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lenggenhager B, 2011, EUR J NEUROSCI, V33, P1935, DOI 10.1111/j.1460-9568.2011.07647.x
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   LEVENSON RW, 1990, PSYCHOPHYSIOLOGY, V27, P363, DOI 10.1111/j.1469-8986.1990.tb02330.x
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Lindner P, 2021, INT J COGN THER, V14, P23, DOI 10.1007/s41811-020-00090-7
   Llobera J, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0300
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Longo MR, 2008, CONSCIOUS COGN, V17, P1181, DOI 10.1016/j.concog.2008.01.001
   Lopez C, 2008, NEUROPHYSIOL CLIN, V38, P149, DOI 10.1016/j.neucli.2007.12.006
   Lopez C, 2015, NEUROPHYSIOL CLIN, V45, P241, DOI 10.1016/j.neucli.2015.09.001
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Lugrin J.-L., 2015, ICAT EGVE 2015 INT C
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2015.7223377
   Lush P, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18591-6
   Lush P, 2019, Phenomenological control: response to imaginative suggestion predicts measures of mirror touch synaesthesia, vicarious pain and the rubber hand illusion, DOI [10.31234/osf.io/82jav, DOI 10.31234/OSF.IO/82JAV]
   Lush P, 2020, COLLABRA-PSYCHOL, V6, DOI 10.1525/collabra.325
   Ma K, 2015, CONSCIOUS COGN, V36, P75, DOI 10.1016/j.concog.2015.06.003
   Makin TR, 2008, BEHAV BRAIN RES, V191, P1, DOI 10.1016/j.bbr.2008.02.041
   Martikainen MH, 2005, CEREB CORTEX, V15, P299, DOI 10.1093/cercor/bhh131
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Moseley GL, 2008, P NATL ACAD SCI USA, V105, P13169, DOI 10.1073/pnas.0803768105
   Müller-Putz GR, 2006, IEEE T NEUR SYS REH, V14, P30, DOI 10.1109/TNSRE.2005.863842
   Nakul E, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63643-y
   Newport R, 2010, EXP BRAIN RES, V204, P385, DOI 10.1007/s00221-009-2104-y
   Nisbet EK, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00813
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Olson JA, 2020, PSYCHOPHARMACOLOGY, V237, P1371, DOI 10.1007/s00213-020-05464-5
   Ome M.T., 2009, Artifacts in Behavioral Research, P110, DOI DOI 10.1093/ACPROF:OSO/9780195385540.003.0005
   Padrao G, 2016, NEUROIMAGE, V124, P147, DOI 10.1016/j.neuroimage.2015.08.022
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Pomés A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00908
   Rabellino D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.586605
   Reader A. T., 2021, What do participants expect to experience in the rubber hand illusion? a conceptual replication of lush
   Roth D., 2017, C HUM FACTORS COMPUT, VPart F1276, P2875, DOI DOI 10.1145/3027063.3053272
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Sato A, 2008, CONSCIOUS COGN, V17, P1219, DOI 10.1016/j.concog.2008.01.003
   Sauvan JB, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2205
   Seghezzi S, 2019, CORTEX, V121, P169, DOI 10.1016/j.cortex.2019.08.018
   Serino A, 2013, CONSCIOUS COGN, V22, P1239, DOI 10.1016/j.concog.2013.08.013
   Seth A., 2021, PREPRINT, DOI [10.31234/osf.io/b4qcy, DOI 10.31234/OSF.IO/B4QCY]
   Si-Mohammed H, 2020, IEEE T VIS COMPUT GR, V26, P1608, DOI 10.1109/TVCG.2018.2873737
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.834492
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Spangenberger P, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05184-0
   Sperduti M, 2011, BRAIN STRUCT FUNCT, V216, P151, DOI 10.1007/s00429-010-0298-1
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Synofzik M, 2008, CONSCIOUS COGN, V17, P219, DOI 10.1016/j.concog.2007.03.010
   Tauscher JP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1794, DOI [10.1109/VR.2019.8797858, 10.1109/vr.2019.8797858]
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Tsakiris M, 2003, EXP BRAIN RES, V149, P439, DOI 10.1007/s00221-003-1386-8
   Tsakiris M, 2007, CONSCIOUS COGN, V16, P645, DOI 10.1016/j.concog.2007.05.012
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P2740, DOI 10.1016/j.neuropsychologia.2010.05.021
   Tsakiris M, 2010, EXP BRAIN RES, V204, P343, DOI 10.1007/s00221-009-2039-3
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   Tuthill JC, 2018, CURR BIOL, V28, pR194, DOI 10.1016/j.cub.2018.01.064
   Verhulst A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00113
   Vogeley K, 2004, J COGNITIVE NEUROSCI, V16, P817, DOI 10.1162/089892904970799
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Wegner DM, 1999, AM PSYCHOL, V54, P480, DOI 10.1037/0003-066X.54.7.480
   Weiskopf N, 2004, IEEE T BIO-MED ENG, V51, P966, DOI 10.1109/TBME.2004.827063
   WEISKRANTZ L, 1971, NATURE, V230, P598, DOI 10.1038/230598a0
   Weiss C, 2011, COGNITION, V121, P207, DOI 10.1016/j.cognition.2011.06.011
   Weller L, 2017, BIOL PSYCHOL, V123, P241, DOI 10.1016/j.biopsycho.2016.12.015
   Weser V, 2019, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00537
   Wissmath B, 2011, CONSCIOUS COGN, V20, P1808, DOI 10.1016/j.concog.2011.05.008
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zhang J, 2016, PSYCHOL RES-PSYCH FO, V80, P1020, DOI 10.1007/s00426-015-0698-1
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 172
TC 3
Z9 3
U1 8
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 5
PY 2023
VL 4
AR 1141683
DI 10.3389/frvir.2023.1141683
PG 23
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CR3D7
UT WOS:001126922400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Mousavi, SMA
   Powell, W
   Louwerse, MM
   Hendrickson, AT
AF Mousavi, S. M. Ali
   Powell, Wendy
   Louwerse, Max M.
   Hendrickson, Andrew T.
TI Behavior and self-efficacy modulate learning in virtual reality
   simulations for training: a structural equation modeling approach
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE learning; self-efficacy; behavior; virtual reality; structural equation
   modeling
ID PERFORMANCE; DESIGN; SUS
AB Introduction: There is a rising interest in using virtual reality (VR) applications in learning, yet different studies have reported different findings for their impact and effectiveness. The current paper addresses this heterogeneity in the results. Moreover, contrary to most studies, we use a VR application actually used in industry thereby addressing ecological validity of the findings.Methods and Results of Study1: In two studies, we explored the effects of an industrial VR safety training application on learning. In our first study, we examined both interactive VR and passive monitor viewing. Using univariate, comparative, and correlational analytical approaches, the study demonstrated a significant increase in self-efficacy and knowledge scores in interactive VR but showed no significant differences when compared to passive monitor viewing. Unlike passive monitor viewing, however, the VR condition showed a positive relation between learning gains and self-efficacy.Methods and Results of Study2: In our subsequent study, a Structural Equation Model (SEM) demonstrated that self-efficacy and users' simulation performance predicted the learning gains in VR. We furthermore found that the VR hardware experience indirectly predicted learning gains through self-efficacy and user simulation performance factors.Conclusion/Discussion of both studies: Conclusively, the findings of these studies suggest the central role of self-efficacy to explain learning gains generalizes from academic VR tasks to those in use in industry training. In addition, these results point to VR behavioral markers that are indicative of learning.
C1 [Mousavi, S. M. Ali; Powell, Wendy; Louwerse, Max M.; Hendrickson, Andrew T.] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
C3 Tilburg University
RP Mousavi, SMA (corresponding author), Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
EM smousavi@uvt.nl
FU This research is part of the MasterMinds project, funded by the
   RegionDeal Mid- and West-Brabant, and is co-funded by the Ministry of
   Economic Affairs and Municipality of Tilburg awarded to MML.; Ministry
   of Economic Affairs and Municipality of Tilburg
FX We would like to thank Actemium for their help in this research.r This
   research is part of the MasterMinds project, funded by the RegionDeal
   Mid- and West-Brabant, and is co-funded by the Ministry of Economic
   Affairs and Municipality of Tilburg awarded to MML.
CR Alcañiz M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01658
   Bailenson J, 2008, MEDIA PSYCHOL, V11, P354, DOI 10.1080/15213260802285214
   BANDURA A, 1993, EDUC PSYCHOL, V28, P117, DOI 10.1207/s15326985ep2802_3
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Bandura A., 2006, Self-Efficacy Beliefs of Adolescents, P307, DOI DOI 10.1017/CBO9781107415324.004
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Behmadi Saman, 2022, J Adv Med Educ Prof, V10, P48, DOI 10.30476/JAMP.2021.89269.1370
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Bjork R. A., 1994, Metacognition: Knowing about Knowing, P185, DOI [10.7551/mitpress/4561.003.0011, DOI 10.7551/MITPRESS/4561.001.0001, DOI 10.7551/MITPRESS/4561.003.0011]
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Cheng MT, 2015, COMPUT EDUC, V86, P18, DOI 10.1016/j.compedu.2015.03.007
   Chi Michelene TH, 2014, The nature of expertise
   Croasmun J.T., 2011, J ADULT ED, V40, P19, DOI DOI 10.1007/S10640-011-9463-0
   de Back TT, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00228-9
   Dey A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P220, DOI [10.1109/vr.2019.8797840, 10.1109/VR.2019.8797840]
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Gegenfurtner A, 2014, BRIT J EDUC TECHNOL, V45, P1097, DOI 10.1111/bjet.12188
   Gegenfurtner A, 2013, EDUC RES REV-NETH, V8, P75, DOI 10.1016/j.edurev.2012.04.001
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Greenwald SW, 2018, J UNIVERS COMPUT SCI, V24, P220
   Hair JF, 2010, Multivariate data analysis
   Hake RR, 1998, AM J PHYS, V66, P64, DOI 10.1119/1.18809
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Hatcher L, 2013, A step-by-step approach to using SAS for factor analysis and structural equation modeling
   Jia DW, 2014, BEHAV INFORM TECHNOL, V33, P16, DOI 10.1080/0144929X.2012.681067
   Johnson D.M., 2007, Simulator sickness research summary
   Johnson-Glenberg MC, 2021, J COMPUT ASSIST LEAR, V37, P1263, DOI 10.1111/jcal.12567
   Joshi S, 2021, APPL ERGON, V90, DOI 10.1016/j.apergo.2020.103286
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kline R.B., 2016, Principles and Practice of Structural Equation Modeling, VFourth
   Kozhevnikov M, 2013, J SCI EDUC TECHNOL, V22, P952, DOI 10.1007/s10956-013-9441-0
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kyrlitsias C, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00023
   Luszczynska A, 2005, J PSYCHOL, V139, P439, DOI 10.3200/JRLP.139.5.439-457
   Madden J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229788
   Makransky G, 2022, J COMPUT ASSIST LEAR, V38, P1127, DOI 10.1111/jcal.12670
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P691, DOI 10.1111/jcal.12375
   Makransky G, 2019, COMPUT EDUC, V134, P15, DOI 10.1016/j.compedu.2019.02.002
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Mayer R., 2014, The Cambridge handbook of multimedia learning, V2nd, P279, DOI [10.1017/CBO9781139547369.015, DOI 10.1017/CBO9781139547369.015]
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P1, DOI 10.1017/CBO9780511811678
   Mayer R. E., 2014, The Cambridge handbook of multimedia learning, V2nd, P31, DOI [https://doi.org/10.1017/CBO9781139547369.005, DOI 10.1017/CBO9780511816819.004, 10.1017/cbo9780511816819.004]
   Molina-Carmona R, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10041074
   Othman MK, 2022, UNIVERSAL ACCESS INF, V21, P995, DOI 10.1007/s10209-021-00820-4
   Pajares F, 1996, REV EDUC RES, V66, P543, DOI 10.3102/00346543066004543
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pathan R, 2020, SMART LEARN ENVIRON, V7, DOI 10.1186/s40561-020-00143-6
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Peres S. C., 2013, P HUMAN FACTORS ERGO, P192, DOI 10.1177/1541931213571043
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Ragan ED, 2010, PRESENCE-TELEOP VIRT, V19, P527, DOI 10.1162/pres_a_00016
   Read Jacob M., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2105, DOI 10.1177/1541931213602008
   Richardson M, 2012, PSYCHOL BULL, V138, P353, DOI 10.1037/a0026838
   Rupp MA, 2019, COMPUT EDUC, V128, P256, DOI 10.1016/j.compedu.2018.09.015
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Sauro Jef, 2011, A Practical Guide to the System Usability Scale: Background, Benchmarks, and Best Practices
   Schloss KB, 2021, TRANSL ISS PSYCH SCI, V7, P297, DOI 10.1037/tps0000281
   SCHWARZER R, 1995, MEASURES HLTH PSYCHO, P35, DOI DOI 10.1037/T00393-000
   Selzer MN, 2019, DISPLAYS, V59, P9, DOI 10.1016/j.displa.2019.04.002
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Shi YM, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101153
   Shute V.J., 2009, International Journal of Learning, and Media, V1, P1, DOI [10.1162/ijlm.2009.0014, DOI 10.1162/IJLM.2009.0014]
   Simoes B, 2020, PROCEEDINGS OF THE 25TH ACM CONFERENCE ON 3D WEB TECHNOLOGY, WEB3D 2020, DOI 10.1145/3424616.3424711
   Smith SJ, 2018, NURS EDUC PERSPECT, V39, pE10, DOI 10.1097/01.NEP.0000000000000369
   Song H, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103506
   Souchet AD, 2022, VIRTUAL REAL-LONDON, V26, P583, DOI 10.1007/s10055-021-00548-9
   Sowndararajan A., 2008, P 2008 WORKSH IMM PR, P1
   Tai KH, 2022, COMPUT EDUC, V182, DOI 10.1016/j.compedu.2022.104458
   van Limpt-Broers H., 2020, CogSci
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Wang R., 2017, P ACM TUR 50 CEL C C, P1
   Wang SL, 2008, COMPUT EDUC, V51, P1589, DOI 10.1016/j.compedu.2008.03.004
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Yang C, 2018, SURG ENDOSC, V32, P4132, DOI 10.1007/s00464-018-6156-6
   Zell E, 2014, PERSPECT PSYCHOL SCI, V9, P111, DOI 10.1177/1745691613518075
   Zhang X, 2017, BEHAV INFORM TECHNOL, V36, P548, DOI 10.1080/0144929X.2016.1268647
   Zimmerman B. J., 2000, HDB SELF REGULATION, P13, DOI [10.1016/B978-012109890-2/50031-7, DOI 10.1016/B978-012109890-2/50031-7]
NR 81
TC 1
Z9 1
U1 3
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 23
PY 2023
VL 4
AR 1250823
DI 10.3389/frvir.2023.1250823
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA W9NT4
UT WOS:001094830900001
OA gold
DA 2024-07-18
ER

PT J
AU Ghosh, R
   Feijóo-García, PG
   Stuart, J
   Wrenn, C
   Lok, B
AF Ghosh, Rashi
   Feijoo-Garcia, Pedro Guillermo
   Stuart, Jacob
   Wrenn, Chase
   Lok, Benjamin
TI Evaluating face gender cues in virtual humans within and beyond the
   gender binary
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual humans; virtual agent; gender; user studies; design study
ID APPEARANCE; PERCEPTION; NONBINARY
AB Introduction: Virtual human work regarding gender is widely based on binary gender despite recent understandings of gender extending beyond female and male. Additionally, gender stereotypes and biases may be present in virtual human design.Methods: This study evaluates how face gender cues are implemented in virtual humans by conducting an exploratory study where an undergraduate computing population (n = 67) designed three virtual human faces-female, male, and nonbinary.Results: Results showed that face gender cues were implemented in stereotypical ways to represent binary genders (female and male virtual humans). For nonbinary gender virtual humans, stereotypical face gender cues were expressed inconsistently (sometimes feminine, sometimes masculine), and conflicting gender cues (pairs of cues that signal opposing binary gender) occurred frequently. Finally, results revealed that not all face gender cues are leveraged equally to express gender.Discussion: Implications of these findings and future directions for inclusive and representative gender expression in virtual humans are discussed.
C1 [Ghosh, Rashi; Feijoo-Garcia, Pedro Guillermo; Stuart, Jacob; Wrenn, Chase; Lok, Benjamin] Univ Florida, Dept Comp & Informat Sci & Engn, Virtual Experiences Res Grp, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Ghosh, R (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Virtual Experiences Res Grp, Gainesville, FL 32611 USA.
EM rashighosh@ufl.edu
OI Lok, Benjamin/0000-0002-1190-3729; Feijoo Garcia, Pedro
   Guillermo/0000-0002-3024-1257
FU We would like to thank the members of the Virtual Experiences Research
   Group in their help in providing feedback.
FX We would like to thank the members of the Virtual Experiences Research
   Group in their help in providing feedback.
CR Alsharbi Bayan, 2017, P 9 INT C COMP AUT E, P11, DOI [10.1145/3057039.3057080, DOI 10.1145/3057039.3057080]
   Araujo V, 2022, SIGGRAPH ASIA 2022 TECHNICAL COMMUNICATIONS PROCEEDINGS, SIGGRAPH 2022, DOI 10.1145/3550340.3564232
   Beasley B., 2002, MASS COMMUN SOC, V5, P279, DOI [DOI 10.1207/S15327825MCS05033, 10.1207/s15327825mcs0503_3, DOI 10.1207/S15327825MCS0503_3]
   BOHAN JS, 1993, PSYCHOL WOMEN QUART, V17, P5, DOI 10.1111/j.1471-6402.1993.tb00673.x
   Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001
   Darwin H, 2017, SYMB INTERACT, V40, P317, DOI 10.1002/SYMB.316
   Engine U., 2021, Metahuman-unreal engine
   Feijóo-García PG, 2021, PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA), P68, DOI 10.1145/3472306.3478367
   Forlizzi Jodi, 2007, P 2007 C DES PLEAS P, P209, DOI [DOI 10.1145/1314161.1314180, 10.1145/1314161.1314180]
   Fossa F, 2022, SCI ENG ETHICS, V28, DOI 10.1007/s11948-022-00376-3
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   Gestos M, 2018, CYBERPSYCH BEH SOC N, V21, P535, DOI 10.1089/cyber.2017.0376
   Hess U, 2004, EMOTION, V4, P378, DOI 10.1037/1528-3542.4.4.378
   Hyde JS, 2019, AM PSYCHOL, V74, P171, DOI 10.1037/amp0000307
   Jaccheri L, 2020, INT SYMP SYMB NUMERI, P9, DOI 10.1109/SYNASC51798.2020.00014
   Khan R, 2009, LECT NOTES COMPUT SC, V5726, P85, DOI 10.1007/978-3-642-03655-2_10
   Kirsch H., 2022, Effect of conflicting gender cues on the cognitive availability of nonbinary they
   Koda T, 2022, PROCEEDINGS OF THE 10TH CONFERENCE ON HUMAN-AGENT INTERACTION, HAI 2022, P275, DOI 10.1145/3527188.3563909
   Komori M, 2011, J EXP PSYCHOL HUMAN, V37, P626, DOI 10.1037/a0020369
   Kuehlkamp A, 2017, IEEE WINT CONF APPL, P1151, DOI 10.1109/WACV.2017.133
   Liszewski W, 2018, NEW ENGL J MED, V379, P2391, DOI 10.1056/NEJMp1812005
   Loveys K, 2020, INT J SOC ROBOT, V12, P1293, DOI 10.1007/s12369-020-00680-7
   Matsuno E., 2017, CURRENT SEXUAL HLTH, V9, P116, DOI [10.1007/s11930-017-0111-8, DOI 10.1007/s11930-017-0111-8, DOI 10.1007/S11930-017-0111-8]
   MCNEMAR Q, 1951, PSYCHOL BULL, V48, P398, DOI 10.1037/h0060348
   Me R. P., 2015, Metaverse 3d avatar creator
   Miller MK, 2007, SEX ROLES, V57, P733, DOI 10.1007/s11199-007-9307-0
   Morgenroth T, 2021, PERSPECT PSYCHOL SCI, V16, P1113, DOI 10.1177/1745691620902442
   Nag P, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423876
   Niculescu A., 2009, P 13 INT C HUMAN COM, P628
   O'Toole AJ, 1998, MEM COGNITION, V26, P146, DOI 10.3758/BF03211378
   Pathoulas JT, 2022, J AM ACAD DERMATOL, V87, P228, DOI 10.1016/j.jaad.2021.07.060
   Politowski C, 2021, J SYST SOFTWARE, V171, DOI 10.1016/j.jss.2020.110846
   Porcheron A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057985
   Reallusion, 2022, 3d character maker
   Reeves B., 1996, The media equation: How people treat computers, television, and new media like real people, V10, P236605
   Richards C, 2016, INT REV PSYCHIATR, V28, P95, DOI 10.3109/09540261.2015.1106446
   Rosenberg-Kima RB, 2008, COMPUT HUM BEHAV, V24, P2741, DOI 10.1016/j.chb.2008.03.017
   Shiban Y, 2015, COMPUT HUM BEHAV, V49, P5, DOI 10.1016/j.chb.2015.01.077
   Silvervarg Annika, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P153, DOI 10.1007/978-3-642-33197-8_16
   Silvervarg A, 2016, LECT NOTES ARTIF INT, V10011, P420, DOI 10.1007/978-3-319-47665-0_46
   Swidrak J, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P49, DOI 10.1145/3308532.3329467
   ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409
   ter Stal S, 2020, INT J HUM-COMPUT INT, V36, P881, DOI 10.1080/10447318.2019.1699744
   Thorne N, 2019, INT J TRANSGENDERISM, V20, P138, DOI 10.1080/15532739.2019.1640654
   Wessler J, 2022, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS, IVA 2022, DOI 10.1145/3514197.3549682
   Zalake M, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P73, DOI 10.1145/3308532.3329471
NR 46
TC 0
Z9 0
U1 4
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 24
PY 2023
VL 4
AR 1251420
DI 10.3389/frvir.2023.1251420
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Q8EU6
UT WOS:001059807800001
OA gold
DA 2024-07-18
ER

PT J
AU Sinlapanuntakul, P
   Korentsides, J
   Chaparro, BS
AF Sinlapanuntakul, Pitch
   Korentsides, Jenna
   Chaparro, Barbara S. S.
TI Exploring the user experience (UX) of a multi-window augmented reality
   environment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; mixed reality; hand-tracking interaction; user
   experience; user performance; gestures
ID CONSTRUCTION; SYSTEM
AB Augmented reality is an emergent form of technology that allows users to interact with and manipulate virtual objects and information integrated into the physical environment. Whether it is replying to browser-based emails or playing a game, completing such tasks in augmented reality requires the use of hand-tracking gestures or interactions. With the anticipated growth of this technology, future users may experience it for extended periods with a variety of applications (e.g., metaverse). This study explores the perceptions and user experience of individuals when interacting with and maneuvering in a multi-window augmented reality environment, using a range of hand-tracking interactions. The results provide both qualitative and quantitative insights into these interactions, highlighting the impact of perceived usability, subjective user experience, perceived difficulty, and perceived workload on task completion.
C1 [Sinlapanuntakul, Pitch] Univ Washington, Dept Human Ctr Design & Engn, Seattle, WA 98195 USA.
   [Korentsides, Jenna; Chaparro, Barbara S. S.] Embry Riddle Aeronaut Univ, Dept Human Factors & Behav Neurobiol, Daytona Beach, FL USA.
C3 University of Washington; University of Washington Seattle; Embry-Riddle
   Aeronautical University
RP Sinlapanuntakul, P (corresponding author), Univ Washington, Dept Human Ctr Design & Engn, Seattle, WA 98195 USA.
EM wspitch@uw.edu
FU Internal Research Grant from the Office of Undergraduate Research at
   Embry-Riddle Aeronautical University, Daytona Beach, FL
FX This research was partially supported by the Internal Research Grant
   from the Office of Undergraduate Research at Embry-Riddle Aeronautical
   University, Daytona Beach, FL.
CR Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cho J, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178738
   Ekren G., 2017, INT S PROD RES, V9, P1
   Graichen L, 2019, HUM FACTORS, V61, P774, DOI 10.1177/0018720818824253
   Grier R.A., 2015, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P1727, DOI DOI 10.1177/1541931215591373
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Knierim P, 2021, IEEE PERVAS COMPUT, V20, P71, DOI 10.1109/MPRV.2021.3119378
   Knierim P, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382920
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lewis JR, 2018, J USABILITY STUD, V13, P158
   Microsoft, 2023, HOLOLENS 2
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167259
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Rauschnabel PA, 2022, COMPUT HUM BEHAV, V133, DOI 10.1016/j.chb.2022.107289
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Shelstad W. J., 2019, HUM FACT APPL PSYCH
   Sinlapanuntakul Weerachet, 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P1028, DOI 10.1177/1071181322661376
   Sinlapanuntakul W, 2022, SIMULAT GAMING, V53, P237, DOI 10.1177/10468781221094473
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
NR 21
TC 1
Z9 1
U1 4
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 2
PY 2023
VL 4
AR 1194019
DI 10.3389/frvir.2023.1194019
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA P3YA5
UT WOS:001050023000001
OA gold
DA 2024-07-18
ER

PT J
AU Lewis-Fung, S
   Tchao, D
   Gray, HG
   Nguyen, E
   Pardini, S
   Harris, LR
   Calabia, D
   Appel, L
AF Lewis-Fung, Samantha
   Tchao, Danielle
   Gray, Hannah Gabrielle
   Nguyen, Emma
   Pardini, Susanna
   Harris, Laurence R.
   Calabia, Dale
   Appel, Lora
TI Designing virtual reality exposure scenarios to treat anxiety in people
   with epilepsy: Phase 2 of the AnxEpiVR clinical trial
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE epilepsy; anxiety; virtual reality; exposure therapy; cognitive
   behavioural therapy (CBT); nonpharmacological intervention; 360-degree
   video; user-centred design
ID QUALITATIVE RESEARCH; SOCIAL ANXIETY; IN-VIVO; THERAPY; DISORDERS
AB Introduction: Anxiety in people with epilepsy (PwE) is characterized by distinct features related to having the condition and thus requires tailored treatment. Although virtual reality (VR) exposure therapy is widely-used to treat a number of anxiety disorders, its use has not yet been explored in people with epilepsy. The AnxEpiVR study is a three-phase pilot trial that represents the first effort to design and evaluate the feasibility of VR exposure therapy to treat epilepsy-specific interictal anxiety. This paper describes the results of the design phase (Phase 2) where we created a minimum viable product of VR exposure scenarios to be tested with PwE in Phase 3.Methods: Phase 2 employed participatory design methods and hybrid (online and in-person) focus groups involving people with lived experience (n = 5) to design the VR exposure therapy program. 360-degree video was chosen as the medium and scenes were filmed using the Ricoh Theta Z1 360-degree camera.Results: Our minimum viable product includes three exposure scenarios: (A) Social Scene-Dinner Party, (B) Public Setting-Subway, and (C) Public Setting-Shopping Mall. Each scenario contains seven 5-minute scenes of varying intensity, from which a subset may be chosen and ordered to create a customized hierarchy based on appropriateness to the individual's specific fears. Our collaborators with lived experience who tested the product considered the exposure therapy program to 1) be safe for PwE, 2) have a high level of fidelity and 3) be appropriate for treating a broad range of fears related to epilepsy/seizures.Discussion: We were able to show that 360-degree videos are capable of achieving a realistic, immersive experience for the user without requiring extensive technical training for the designer. Strengths and limitations using 360-degree video for designing exposure scenarios for PwE are described, along with future directions for testing and refining the product.
C1 [Lewis-Fung, Samantha; Tchao, Danielle; Pardini, Susanna; Appel, Lora] Univ Hlth Network, OpenLab, Toronto, ON, Canada.
   [Gray, Hannah Gabrielle; Harris, Laurence R.] York Univ, Fac Hlth, Dept Psychol, Toronto, ON, Canada.
   [Gray, Hannah Gabrielle; Calabia, Dale] York Univ, Fac Sci, Dept Biol, Toronto, ON, Canada.
   [Pardini, Susanna] Univ Padua, Dept Gen Psychol, Padua, Italy.
   [Pardini, Susanna] Bruno Kessler Fdn, Ctr Hlth & Wellbeing, Digital Hlth Lab, Trento, Italy.
   [Calabia, Dale; Appel, Lora] York Univ, Fac Hlth, Sch Hlth Policy & Management, Toronto, ON, Canada.
   [Appel, Lora] Michael Garron Hosp, Toronto, ON, Canada.
C3 University of Toronto; University Health Network Toronto; York
   University - Canada; York University - Canada; University of Padua;
   Fondazione Bruno Kessler; York University - Canada; University of
   Toronto; Toronto East General Hospital
RP Appel, L (corresponding author), Univ Hlth Network, OpenLab, Toronto, ON, Canada.; Appel, L (corresponding author), York Univ, Fac Hlth, Sch Hlth Policy & Management, Toronto, ON, Canada.; Appel, L (corresponding author), Michael Garron Hosp, Toronto, ON, Canada.
EM lora.appel@uhn.ca
RI Pardini, Susanna/GMW-5895-2022
OI Pardini, Susanna/0000-0002-6692-8923
FU York University's Faculty of Health; Anxiety Research Fund
FX & nbsp;This pilot trial was possible due to the generosity of York
   University's Faculty of Health through their Junior Faculty Funds/ Minor
   Research Grant, as well as the Anxiety Research Fund powered by Beneva.
   Both funders provided funds based on a competitive review of the study
   protocol, but were not involved in the design, analysis or write-up of
   the manuscript. Thanks to the Frontiers editorial board we will receive
   a 50% discount on open access fees for this special issue.
CR Abramowitz JS, 2013, BEHAV THER, V44, P548, DOI 10.1016/j.beth.2013.03.003
   Andersen NJ, 2023, J BEHAV THER EXP PSY, V81, DOI 10.1016/j.jbtep.2023.101851
   [Anonymous], 2014, AIS EL LIB AISEL ASS
   Baños RM, 2011, INT J HUM-COMPUT ST, V69, P602, DOI 10.1016/j.ijhcs.2011.06.002
   Benbow AA, 2019, J ANXIETY DISORD, V61, P18, DOI 10.1016/j.janxdis.2018.06.006
   Boeldt D, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00773
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Clary HMM, 2023, EPILEPSY RES, V190, DOI 10.1016/j.eplepsyres.2023.107092
   Clary HMM, 2014, CURR NEUROL NEUROSCI, V14, DOI 10.1007/s11910-014-0445-9
   DALLE, 2023, CREATING IMAGES TEXT
   Deacon BJ, 2013, J ANXIETY DISORD, V27, P772, DOI 10.1016/j.janxdis.2013.04.006
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Flobak E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300799
   Gill P, 2008, BRIT DENT J, V204, P291, DOI 10.1038/bdj.2008.192
   Gray HG, 2023, JMIR RES PROTOC, V12, DOI 10.2196/41523
   Hingray C, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1029-9
   Holmberg TT, 2020, CYBERPSYCH BEH SOC N, V23, P495, DOI 10.1089/cyber.2019.0295
   Ionescu Alina., 2021, J. technol. behave. sci, V6, P631, DOI DOI 10.1007/S41347-021-00221-7
   Kaplan J. S., 2011, EXPOSURE THERAPY ANX
   KITZINGER J, 1995, BRIT MED J, V311, P299, DOI 10.1136/bmj.311.7000.299
   Laessoe U, 2023, PHYSIOL BEHAV, V258, DOI 10.1016/j.physbeh.2022.114015
   Lindner P, 2021, INT J COGN THER, V14, P23, DOI 10.1007/s41811-020-00090-7
   Lundin J, 2022, BEHAV COGN PSYCHOTH, V50, P158, DOI 10.1017/S1352465821000473
   Miloff A, 2016, TRIALS, V17, DOI 10.1186/s13063-016-1171-1
   Moore N, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/38669
   News N., 2023, NEUROSCIENCE NEWS
   OpenAI, 2023, OpenAI API
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Radkowski Rafael, 2011, Virtual and Mixed Reality - Systems and Applications. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P44, DOI 10.1007/978-3-642-22024-1_6
   Reeves R, 2021, J ANXIETY DISORD, V83, DOI 10.1016/j.janxdis.2021.102451
   Reeves R, 2022, BEHAV MODIF, V46, P937, DOI 10.1177/0145445521991102
   Rimer E, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.671871
   Riva G., 2022, Comprehensive clinical psychology, V91, DOI [10.1016/B978-0-12-818697-8.00006-6, DOI 10.1016/B978-0-12-818697-8.00006-6, https://doi.org/10.1016/B978-0-12-818697-8.00006-6]
   Seyama J, 2007, PRESENCE-TELEOP VIRT, V16, P337, DOI 10.1162/pres.16.4.337
   Slattery P, 2020, HEALTH RES POLICY SY, V18, DOI 10.1186/s12961-020-0528-9
   Spinuzzi C, 2005, TECH COMMUN-STC, V52, P163
   Stevens TM, 2021, TRANSL ISS PSYCH SCI, V7, P261, DOI 10.1037/tps0000302
   Suganuma S, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10454
   Sutton J., 2020, WHAT IS VIRTUAL REAL
   Tchao D, 2023, EPILEPSY BEHAV REP, V21, DOI 10.1016/j.ebr.2023.100588
   Teal G, 2023, CODESIGN, V19, P110, DOI 10.1080/15710882.2022.2096906
   Teng MQ, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299050
   Thomke S, 2012, HARVARD BUS REV, V90, P84
NR 44
TC 0
Z9 0
U1 5
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 19
PY 2023
VL 4
AR 1209535
DI 10.3389/frvir.2023.1209535
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA O1JU9
UT WOS:001041460200001
OA gold
DA 2024-07-18
ER

PT J
AU Reimer, D
   Podkosova, I
   Scherzer, D
   Kaufmann, H
AF Reimer, Dennis
   Podkosova, Iana
   Scherzer, Daniel
   Kaufmann, Hannes
TI Evaluation and improvement of HMD-based and RGB-based hand tracking
   solutions in VR
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; hand tracking; colocation; RGB tracking; mediapipe
AB Hand tracking has become a state-of-the-art technology in the modern generation of consumer VR devices. However, off-the-shelf solutions do not support hand detection for more than two hands at the same time at distances beyond arm's length. The possibility to track multiple hands at larger distances would be beneficial for colocated multi-user VR scenarios, allowing user-worn devices to track the hands of other users and therefore reducing motion artifacts caused by hand tracking loss. With the global focus of enabling natural hand interactions in colocated multi-user VR, we propose an RGB image input-based hand tracking method, built upon the MediaPipe framework, that can track multiple hands at once at distances of up to 3 m. We compared our method's accuracy to that of Oculus Quest and Leap Motion, at different distances from the tracking device and in static and dynamic settings. The results of our evaluation show that our method provides only slightly less accurate results than Oculus Quest or Leap motion in the near range (with median errors below 1.75 cm at distances below 75 cm); at larger distances, its accuracy remains stable (with a median error of 4.7 cm at the distance of 2.75 m) while Leap Motion and Oculus Quest either loose tracking or produce very inaccurate results. Taking into account the broad choice of suitable hardware (any RGB camera) and the ease of setup, our method can be directly applied to colocated multi-user VR scenarios.
C1 [Reimer, Dennis; Podkosova, Iana; Kaufmann, Hannes] TU Wien, Fac Informat, Res Unit Virtual & Augmented Real, Vienna, Austria.
   [Reimer, Dennis; Scherzer, Daniel] Ravensburg Weingarten Univ, Fac Elect Engn & Comp Sci, Weingarten, Germany.
C3 Technische Universitat Wien
RP Reimer, D (corresponding author), TU Wien, Fac Informat, Res Unit Virtual & Augmented Real, Vienna, Austria.; Reimer, D (corresponding author), Ravensburg Weingarten Univ, Fac Elect Engn & Comp Sci, Weingarten, Germany.
EM reimerde@rwu.de
FU TU Wien Bibliothek
FX The authors acknowledge TU Wien Bibliothek for financial support through
   its Open Access Funding Program.
CR Abdlkarim Diar, 2022, bioRxiv, DOI DOI 10.1101/2022.02.18.481001
   Bauer P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051622
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Che YL, 2021, INT SYM MIX AUGMENT, P386, DOI 10.1109/ISMAR52148.2021.00055
   Ding QC, 2020, ADV MECH ENG, V12, DOI 10.1177/1687814020967573
   Ferstl Y, 2021, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2021), DOI 10.1145/3474451.3476235
   Gong Liang, 2020, Procedia CIRP, V93, P1259, DOI 10.1016/j.procir.2020.04.036
   Han SC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392452
   Huang L., 2021, Virtual Reality & Intelligent Hardware, V3, P207
   Khundam C, 2021, INFORMATICS-BASEL, V8, DOI 10.3390/informatics8030060
   Li Y., 2018, P 2018 3 DIGITAL HER, DOI 10.1109/DigitalHeritage.2018.8810126
   Lin F., 2020, ABS200601320 CORR
   Lugaresi C., 2019, CoRR abs/1906.08172
   Malik J., 2018, ABS180809208 CORR
   Mizera C, 2020, IEEE SENS J, V20, P1642, DOI 10.1109/JSEN.2019.2947612
   Panteleris P., 2017, ABS171203866 CORR
   Pheasant S., 2003, Bodyspace: Anthropometry, Ergonomics and Design, VE
   Schneider D., 2021, ABS210910607 CORR
   Schneider D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P805, DOI [10.1109/VRW50115.2020.00253, 10.1109/VRW50115.2020.00-22]
   Schupp H., 1977, ELEMENTARGEOMETRIE
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Sun ZT, 2021, INT SYM MIX AUGMENT, P248, DOI 10.1109/ISMAR52148.2021.00040
   Tsutsui S., 2020, ARXIV
   Voigt-Antons JN, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123085
   Vysocky A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154088
   Wang JY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417852
   Wang Z, 2011, INT J ADV MANUF TECH, V56, P205, DOI 10.1007/s00170-011-3166-0
   WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.2307/2332510
   Zafar U., 2017, Journal of Medical Sciences (Peshawar), V25, P425
   Zhang F, 2020, Arxiv, DOI arXiv:2006.10214
   Zimmermann C., 2017, IEEE INT C COMPUTER
NR 32
TC 1
Z9 1
U1 2
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 19
PY 2023
VL 4
AR 1169313
DI 10.3389/frvir.2023.1169313
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA O1GQ3
UT WOS:001041376800001
OA gold
DA 2024-07-18
ER

PT J
AU Rachyla, I
   Mor, S
   Botella, C
   Castilla, D
   Quero, S
AF Rachyla, Iryna
   Mor, Sonia
   Botella, Cristina
   Castilla, Diana
   Quero, Soledad
TI Acceptability of an internet-delivered intervention for adjustment
   disorder and its role as predictor of efficacy
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE internet interventions; acceptability; adjustment disorder; adherence;
   expectations; satisfaction
ID COGNITIVE-BEHAVIOR THERAPY; FACE-TO-FACE; MENTAL-HEALTH; PSYCHOLOGICAL
   TREATMENTS; TREATMENT PREFERENCES; SICKNESS ABSENCE; PREVALENCE;
   DEPRESSION; ANXIETY
AB Background: Internet-delivered interventions offer a feasible way to facilitate access to mental healthcare and considerable evidence supports their effectiveness for the treatment of different mental disorders. However, potential users' attitudes toward these interventions are crucial for their successful implementation. A better understanding of factors related to treatment acceptance and adherence is required to exploit the full potential of internet interventions. Hence, the aim of the present work was to analyze the acceptability of a therapist-guided internet-delivered CBT intervention for adjustment disorder and its impact on treatment outcomes.
   Methods: The acceptability was estimated from the acceptance to participate in the randomized controlled trial addressed to explore the effectiveness of the internet intervention in question. Other indicators of acceptability were treatment adherence, expectations, satisfaction, and opinion reported by 34 participants from the trial.
   Results: Willingness to try an internet intervention was observed and 76.5% of participants completed all seven treatment modules. Less positive initial expectations did not reduce treatment effectiveness, yet they might have led to treatment abandonment. Overall, participants were satisfied with the internet intervention and perceived it as a useful, comfortable and attractive way of receiving psychological assistance. Treatment modules aimed at promoting identification with the treatment goals, relapse prevention, and change in the meaning of the stressor were found to be related to posttraumatic growth and increase in positive affect and quality of life. Participants also expressed that the intervention required considerable motivation. In this regard, therapeutic support was perceived as an important adherence facilitator.
   Conclusion: The findings from this work support the suitability of internet interventions for the treatment of adjustment disorder. However, further research is required in order to develop guidelines for the design of more attractive and engaging internet interventions.
C1 [Rachyla, Iryna; Mor, Sonia; Botella, Cristina; Quero, Soledad] Univ Jaume 1, Dept Basic Clin Psychol & Psychobiol, Castellon de La Plana, Spain.
   [Botella, Cristina; Castilla, Diana; Quero, Soledad] CIBER Physiopathol Obes & Nutr CIBERObn, Madrid, Spain.
   [Castilla, Diana] Univ Valencia, Dept Personal Evaluat & Psychol Treatment, Valencia, Spain.
C3 Universitat Jaume I; CIBER - Centro de Investigacion Biomedica en Red;
   CIBEROBN; University of Valencia
RP Rachyla, I; Quero, S (corresponding author), Univ Jaume 1, Dept Basic Clin Psychol & Psychobiol, Castellon de La Plana, Spain.; Quero, S (corresponding author), CIBER Physiopathol Obes & Nutr CIBERObn, Madrid, Spain.
EM irinarachila@gmail.com; squero@uji.es
RI Castilla, Diana/S-3733-2019; Botella, Cristina/F-9230-2010
OI Castilla, Diana/0000-0002-1631-1220; Botella,
   Cristina/0000-0001-8783-6959
FU Ministerio de Economia y Competitividad (Spain; Plan Nacional I + D +
   I); Plan 2018 de Promocion de la Investigacion de la Universitat Jaume I
   [VALi + d: ACIF/2015/181]; Generalitat Valenciana pre-PhD grant program
   [ISC III CB06 03/0052]; CIBERObn, an initiative of the Instituto de
   Salud Carlos III (ISCIII) [RTI2018-100993-B-100]; grant Ministerio de
   Ciencia, Innovacion y Universidades (Spain) by MCIN/AEI [PSI
   2013-41783-R]; European Union; ERDF A way of making Europe; 
   [UJI-2018-57]
FX & nbsp;The study was funded by the following institutions: Ministerio de
   Economia y Competitividad (Spain; Plan Nacional I + D + I, PSI
   2013-41783-R); Plan 2018 de Promocion de la Investigacion de la
   Universitat Jaume I (UJI-2018-57); Generalitat Valenciana pre-PhD grant
   program (VALi + d: ACIF/2015/181); CIBERObn, an initiative of the
   Instituto de Salud Carlos III (ISCIII) (ISC III CB06 03/0052); and the
   grant Ministerio de Ciencia, Innovacion y Universidades (Spain; Programa
   Estatal I+D+i RTI2018-100993-B-100) funded by
   MCIN/AEI/10.13039/501100011033, by "ERDF A way of making Europe" and by
   the "European Union". The aforementioned institutions had no role in the
   design or execution of the study, analyses and interpretation of the
   data, or decision to submit results.
CR Alonso J, 2018, DEPRESS ANXIETY, V35, P195, DOI 10.1002/da.22711
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Andrade LH, 2014, PSYCHOL MED, V44, P1303, DOI 10.1017/S0033291713001943
   Andrews G, 2018, J ANXIETY DISORD, V55, P70, DOI 10.1016/j.janxdis.2018.01.001
   [Anonymous], 2014, Internet Interventions, DOI DOI 10.1016/J.INVENT.2014.08.003
   Bachem R, 2018, J AFFECT DISORDERS, V227, P243, DOI 10.1016/j.jad.2017.10.034
   Bachem R, 2016, COGN BEHAV THERAPY, V45, P397, DOI 10.1080/16506073.2016.1191083
   Batterham PJ, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7722
   BORKOVEC TD, 1972, J BEHAV THER EXP PSY, V3, P257, DOI 10.1016/0005-7916(72)90045-6
   Botella C, 2016, NEUROPSYCH DIS TREAT, V12, P393, DOI 10.2147/NDT.S93315
   Brown SA, 2002, J BEHAV HEALTH SER R, V29, P217, DOI 10.1007/BF02287708
   Campos D, 2018, NEUROPSYCH DIS TREAT, V14, P879, DOI 10.2147/NDT.S153041
   Carlbring P, 2018, COGN BEHAV THERAPY, V47, P1, DOI 10.1080/16506073.2017.1401115
   Carta Mauro Giovanni, 2009, Clin Pract Epidemiol Ment Health, V5, P15, DOI 10.1186/1745-0179-5-15
   Casey P, 2015, J AFFECT DISORDERS, V174, P441, DOI 10.1016/j.jad.2014.12.003
   Di Nardo P.A., 1994, Anxiety Disorders Interview Schedule for DSM-IV
   Ebert DD, 2015, J AFFECT DISORDERS, V176, P9, DOI 10.1016/j.jad.2015.01.056
   Eimontas J, 2018, PSYCHIAT QUART, V89, P451, DOI 10.1007/s11126-017-9547-2
   Eimontas J, 2018, ANXIETY STRESS COPIN, V31, P146, DOI 10.1080/10615806.2017.1385065
   Evans SC, 2013, INT J PSYCHOL, V48, P177, DOI 10.1080/00207594.2013.804189
   Fernández A, 2012, BRIT J PSYCHIAT, V201, P137, DOI 10.1192/bjp.bp.111.096305
   Gradus JL, 2017, CLIN EPIDEMIOL, V9, P251, DOI 10.2147/CLEP.S106250
   Griffiths F, 2006, J MED INTERNET RES, V8, DOI 10.2196/jmir.8.2.e10
   Gun SY, 2011, AUSTRALAS PSYCHIATRY, V19, P259, DOI 10.3109/10398562.2011.562295
   Hedman E, 2014, J AFFECT DISORDERS, V155, P49, DOI 10.1016/j.jad.2013.10.023
   JACOBSON NS, 1991, J CONSULT CLIN PSYCH, V59, P12, DOI 10.1037/0022-006X.59.1.12
   Johansson Olof, 2015, Internet Interventions, V2, P137, DOI 10.1016/j.invent.2015.02.006
   Kaltenthaler E, 2008, PSYCHOL MED, V38, P1521, DOI 10.1017/S0033291707002607
   Kayrouz R, 2015, INT J SOC PSYCHIATR, V61, P484, DOI 10.1177/0020764014553004
   Kohn R, 2004, B WORLD HEALTH ORGAN, V82, P858
   Koopmans PC, 2011, INT ARCH OCC ENV HEA, V84, P193, DOI 10.1007/s00420-010-0540-4
   Maercker A, 2015, JMIR MENT HEALTH, V2, DOI 10.2196/mental.4157
   March S, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9109
   Mathiasen K, 2018, J MED INTERNET RES, V20, DOI 10.2196/10927
   Mira A, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00325
   Mohr DC, 2010, ANN BEHAV MED, V40, P89, DOI 10.1007/s12160-010-9203-7
   Moser C, 2019, J CLIN MED, V8, DOI 10.3390/jcm8101655
   Musiat P, 2014, BMC PSYCHIATRY, V14, DOI 10.1186/1471-244X-14-109
   O'Donnell ML, 2016, AM J PSYCHIAT, V173, P1231, DOI 10.1176/appi.ajp.2016.16010071
   Quero S, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16203842
   Rachyla I, 2021, CLIN PSYCHOL PSYCHOT, V28, P313, DOI 10.1002/cpp.2518
   Rachyla I, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-018-1751-6
   Richards Derek, 2016, Internet Interv, V5, P12, DOI 10.1016/j.invent.2016.06.007
   Saxena S, 2007, LANCET, V370, P878, DOI 10.1016/S0140-6736(07)61239-2
   Schröder J, 2016, DIALOGUES CLIN NEURO, V18, P203
   Swift JK, 2009, J CLIN PSYCHOL, V65, P368, DOI 10.1002/jclp.20553
   Titov N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062873
   Vallejo-Sánchez B, 2017, CLIN PSYCHOL-UK, V21, P245, DOI 10.1111/cp.12064
   van Ballegooijen W, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100674
   van der Klink JJL, 2003, OCCUP ENVIRON MED, V60, P429, DOI 10.1136/oem.60.6.429
   Williams ME, 2008, J BEHAV HEALTH SER R, V35, P107, DOI 10.1007/s11414-007-9091-1
   World Health Organization, 2014, World Health Organ Tech Rep Ser, P1
   Yaseen YA, 2017, ASIAN J PSYCHIATR, V28, P82, DOI 10.1016/j.ajp.2017.03.012
   Yates W. R., 2016, MEDICAL BASIS PSYCHI
   Zelviene P, 2018, NEUROPSYCH DIS TREAT, V14, P375, DOI 10.2147/NDT.S121072
NR 55
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 11
PY 2022
VL 3
AR 931366
DI 10.3389/frvir.2022.931366
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XU5
UT WOS:001023319200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Agnew, CR
AF Agnew, Christopher R.
TI Feeling close to a Crab-Thing in virtual reality: Does avatar appearance
   always matter in forming meaningful connections? A case study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; avatar type; avatar matching; close relationships;
   closeness; affiliative outcomes
ID SELF-DISCLOSURE; LIKING
AB Recent experimental research revealed that people can form meaningful relationships interacting with strangers in virtual reality (VR), with resulting affiliative outcomes (e.g., feelings of closeness) at the same levels as those attained via interactions in other sensory-rich communication modalities. The present preregistered experiment examined whether avatar type and avatar matching in VR influence levels of closeness (and affiliated constructs) generated among previously unacquainted strangers using a validated structured discussion procedure. Based on previous theory and research, we hypothesized that affiliative outcomes would not differ 1) regardless of whether the interacting avatars appeared to be human or not, and 2) regardless of whether there was a (mis)match in avatar type between interactants. Two hundred and four previously unacquainted undergraduate students were randomly assigned to interact in VR as pairs in one of three stylized avatar conditions: both human in appearance, both non-human in appearance (Crab-Things, created for this study), or one human and one Crab-Thing. Results were consistent with hypotheses, suggesting that closeness and related outcomes can be generated and experienced in VR regardless of the stylized avatar types used in the current study. Exploratory analyses of individual difference variables (personality and attachment) as possible moderators of stylized avatar type effects yielded non-significant findings, supporting the generalizability of findings across key intra- and interpersonal dispositions.
C1 [Agnew, Christopher R.] Purdue Univ, Dept Psychol Sci, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Agnew, CR (corresponding author), Purdue Univ, Dept Psychol Sci, W Lafayette, IN 47907 USA.
EM agnew@purdue.edu
RI Agnew, Christopher/GPP-3982-2022
FU Meta
FX This research was supported by a grant from Facebook (now Meta), for
   which the author is grateful. Facebook (Meta) had no role in this
   research other than providing financial support.
CR Agnew C. R., 2022, Technology, Mind, and Behavior, V3, P1, DOI [10.1037/tmb0000091, DOI 10.1037/TMB0000091]
   ALBRIGHT L, 1988, J PERS SOC PSYCHOL, V55, P387, DOI 10.1037/0022-3514.55.3.387
   AMBADY N, 1995, J PERS SOC PSYCHOL, V69, P518, DOI 10.1037/0022-3514.69.3.518
   Aron A, 1997, PERS SOC PSYCHOL B, V23, P363, DOI 10.1177/0146167297234003
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Bidar M., 2022, CBS NEWS 0107
   COLLINS NL, 1994, PSYCHOL BULL, V116, P457, DOI 10.1037/0033-2909.116.3.457
   Cowan K, 2019, EUR J MARKETING, V53, P1585, DOI 10.1108/EJM-10-2017-0733
   Dubosc C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P438, DOI 10.1109/VRW52623.2021.00101
   EAGLY AH, 1991, PSYCHOL BULL, V110, P109, DOI 10.1037/0033-2909.110.1.109
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fysh MC, 2022, BEHAV RES METHODS, V54, P1461, DOI 10.3758/s13428-021-01676-5
   Guegan J, 2020, CYBERPSYCHOLOGY, V14, DOI 10.5817/CP2020-4-1
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   John O.P., 1999, HDB PERSONALITY THEO, P102, DOI DOI 10.1525/FQ.1998.51.4.04A00260
   Lafontaine MF, 2016, EUR J PSYCHOL ASSESS, V32, P140, DOI 10.1027/1015-5759/a000243
   McElvaney TJ, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0249782
   Mikulincer M, 2016, ATTACHMENT IN ADULTHOOD, 2 EDITION, P1
   Reis HT, 2011, J PERS SOC PSYCHOL, V101, P557, DOI 10.1037/a0022885
   Rivu R, 2021, LECT NOTES COMPUT SC, V12936, P234, DOI 10.1007/978-3-030-85607-6_16
   SCARIANO SM, 1987, AM STAT, V41, P123, DOI 10.2307/2684223
   Soto CJ, 2017, J PERS SOC PSYCHOL, V113, P117, DOI 10.1037/pspp0000096
   Sprecher S, 2020, ADV PERS RELATSH, P343
   Sprecher S, 2021, J SOC PERS RELAT, V38, P1452, DOI 10.1177/0265407521996055
   Sprecher S, 2015, PERS RELATIONSHIP, V22, P460, DOI 10.1111/pere.12090
   Sprecher S, 2014, COMPUT HUM BEHAV, V31, P190, DOI 10.1016/j.chb.2013.10.029
   Sprecher S, 2013, J SOC PERS RELAT, V30, P497, DOI 10.1177/0265407512459033
   Sun Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221803
   Torre I., 2019, P MOT INT GAM
   Urbaniak G.C., 2013, Research Randomizer (Version 4.0) Computer software
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Willems YE, 2020, CURR OPIN PSYCHOL, V31, P33, DOI 10.1016/j.copsyc.2019.07.032
   Wirth M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P326, DOI 10.1109/VR50410.2021.00055
NR 35
TC 0
Z9 0
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 5
PY 2022
VL 3
AR 889247
DI 10.3389/frvir.2022.889247
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XV4
UT WOS:001023320100001
OA gold
DA 2024-07-18
ER

PT J
AU Freedman, SA
   Dayan, E
   Eitan, R
AF Freedman, Sara A. A.
   Dayan, Ehud
   Eitan, Renana
TI An internet based virtual reality intervention for preventing
   posttraumatic stress disorder
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE internet; PTSD; prevention; RCT; virtual reality
ID BARRIERS; SCALE; PTSD; K6
AB Introduction: Research examining the prevention of Posttraumatic Stress Disorder (PTSD) has shown that selective treatments to those with high symptom levels, using trauma focused CBT are relatively successful in reducing symptoms and preventing chronic PTSD. However, uptake of these early treatments is often low. This study aimed to provide an internet based Virtual Reality treatment to overcome some of these barriers to early treatment. Method: The study received IRB approval from Hadassah Hospital (HMO 0056013); its ClinicalTrials.gov identifier is NCT01760213. Recent survivors of motor vehicle accidents (N = 1,500) were assessed by telephone and online questionnaires. Patients meeting study criteria were randomly assigned to a Virtual Reality internet-based trauma-focused cognitive behavioral therapy (CBT) or waitlist control. Results: the majority of subjects recruited did not meet study criteria or were unwilling to participate. 14 subjects were randomly assigned to treatment or waitlist control. Results indicate that both groups show a decline in PTSD symptoms at follow up, with no significant differences between groups. Discussion: prevention of PTSD is a challenging goal, and internet-based interventions may play a role in this. The current study was not able to recruit sufficient participants to drawconclusions regarding the efficacy of the treatment. Proving services via the internetmay not reduce barriers to care in this population.
C1 [Freedman, Sara A. A.] Bar Ilan Univ, Sch Social Work, Ramat Gan, Israel.
   [Dayan, Ehud] Sonarion Ltd, Jerusalem, Israel.
   [Eitan, Renana] Hebrew Univ Jerusalem, Jerusalem Mental Hlth Ctr, Neuropsychiat Unit, Jerusalem, Israel.
C3 Bar Ilan University; Hebrew University of Jerusalem; Jerusalem Mental
   Health Center
RP Freedman, SA (corresponding author), Bar Ilan Univ, Sch Social Work, Ramat Gan, Israel.
EM sara.freedman@biu.ac.il
FU Israel Internet Association
FX This study received funding from the Israel Internet Association. The
   funder was not involved in the study design, collection, analysis,
   interpretation of data, the writing of this article or the decision to
   submit it for publication. All authors declare no other competing
   interests.
CR American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Blevins CA, 2015, J TRAUMA STRESS, V28, P489, DOI 10.1002/jts.22059
   First M. B., 2004, Personality assessment, V2, P134, DOI DOI 10.1002/9780471726753
   Freedman SA, 2019, PSYCHIAT ANN, V49, P314, DOI 10.3928/00485713-20190528-01
   Hoge CW, 2004, NEW ENGL J MED, V351, P13, DOI 10.1056/NEJMoa040603
   Kashdan TB, 2011, PERS INDIV DIFFER, V50, P84, DOI 10.1016/j.paid.2010.08.028
   Kazdin AE, 2011, PERSPECT PSYCHOL SCI, V6, P21, DOI 10.1177/1745691610393527
   Lewis C, 2019, ACTA PSYCHIAT SCAND, V140, P508, DOI 10.1111/acps.13079
   Lewis C, 2020, EUR J PSYCHOTRAUMATO, V11, DOI 10.1080/20008198.2020.1729633
   Mewton L, 2016, PSYCHOL ASSESSMENT, V28, P1232, DOI 10.1037/pas0000239
   Mouthaan J, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2460
   Prochaska JJ, 2012, INT J METH PSYCH RES, V21, P88, DOI 10.1002/mpr.1349
   Rothbaurn BO, 2010, ANN NY ACAD SCI, V1208, P126, DOI 10.1111/j.1749-6632.2010.05691.x
   Shalev AY, 2012, ARCH GEN PSYCHIAT, V69, P166, DOI 10.1001/archgenpsychiatry.2011.127
   Shalev AY, 2011, PSYCHIAT SERV, V62, P765, DOI 10.1176/ps.62.7.pss6207_0765
   Shalev AY, 1996, AM J PSYCHIAT, V153, P219
   Titov N, 2015, PSYCHIAT SERV, V66, P1043, DOI 10.1176/appi.ps.201400477
   Weathers FW, 2018, PSYCHOL ASSESSMENT, V30, P383, DOI 10.1037/pas0000486
NR 18
TC 0
Z9 0
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 2
PY 2022
VL 3
AR 831051
DI 10.3389/frvir.2022.831051
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XF6
UT WOS:001023304200001
OA gold
DA 2024-07-18
ER

PT J
AU Björling, E
   Sonney, J
   Rodriguez, S
   Carr, N
   Zade, H
   Moon, SH
AF Bjorling, Elin A.
   Sonney, Jennifer
   Rodriguez, Sofia
   Carr, Nora
   Zade, Himanshu
   Moon, Soo Hyun
TI Exploring the Effect of a Nature-based Virtual Reality Environment on
   Stress in Adolescents
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; adolescents; perceived stress; pilot study;
   mixed-methods
ID MENTAL-HEALTH; DEPRESSION; COVID-19; CHILDREN; ANXIETY; CHILDHOOD;
   SYMPTOMS; VALIDITY
AB Adolescent mental health is a growing public health issue, with 30% of teens reporting increased stress and 20% of adolescents suffering from depression. Given the scarcity and lack of scalability of mental health services available, the use of self-administered, evidence-based technologies to support adolescent mental health is both timely and imperative. We conducted a mixed-methods pilot study with 31 adolescents ages 14-19 (m = 17.97) to explore the self-administration of a nature-based virtual reality tool. Participant use of the VR environment ranged from 1 to 10 sessions (m = 6.6) at home over a 2-week period while reporting their daily stress and mood levels. All participants completed all of the study protocols, indicating our protocol was feasible and the VR environment engaging. Post-study interviews indicated that most participants found the VR tool to be relaxing and helpful with stress. The themes of Calm Down, Relaxation, and Escape emerged to articulate the participants' experiences using the VR environment. Additionally, participants provided rich data regarding their preferences and activity in the VR environment as well as its effect on their emotional states. Although the sample size was insufficient to determine the impact on depression, we found a significant reduction in momentary stress as a result of using the VR tool. These preliminary data inform our own virtual reality environment design, but also provide evidence of the potential for self-administered virtual reality as a promising tool to support adolescent mental health.
C1 [Bjorling, Elin A.; Rodriguez, Sofia; Carr, Nora; Zade, Himanshu; Moon, Soo Hyun] Univ Washington, Human Ctr Design & Engn, Seattle, WA 98195 USA.
   [Sonney, Jennifer] Univ Washington, Dept Child Family & Populat Hlth Nursing, Seattle, WA USA.
C3 University of Washington; University of Washington Seattle; University
   of Washington; University of Washington Seattle
RP Björling, E (corresponding author), Univ Washington, Human Ctr Design & Engn, Seattle, WA 98195 USA.
EM bjorling@uw.edu
RI Zade, Himanshu/GZK-2571-2022
OI Zade, Himanshu/0000-0003-1755-7780
CR Adjorlu Ali, 2019, 16 SOUND MUS COMP C, P261, DOI [10.5281/zenodo., DOI 10.5281/ZENODO]
   Ahmed SP, 2015, DEV COGN NEUROS-NETH, V15, P11, DOI 10.1016/j.dcn.2015.07.006
   American Psychological Association, 2014, STRESS AM 2013 HIGHL
   Antonelli M, 2022, INT J ENVIRON HEAL R, V32, P1842, DOI 10.1080/09603123.2021.1919293
   Anyan F, 2016, J AFFECT DISORDERS, V203, P213, DOI 10.1016/j.jad.2016.05.031
   Baghaei N, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/29681
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bioulac S, 2018, ENCEPHALE, V44, P280, DOI 10.1016/j.encep.2017.06.005
   Bolton JL, 2017, CURR OPIN BEHAV SCI, V14, P133, DOI 10.1016/j.cobeha.2016.12.012
   Bossenbroek R, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/16066
   Cangas A J., 2019, Enhancing Resilience in Youth, P233, DOI DOI 10.1007/978-3-030-25513-8_15
   CDC D.O.A.A.S.H, 2019, Youth risk behavior surveillance system youth high school results
   CELLA DF, 1986, PSYCHOL REP, V59, P827, DOI 10.2466/pr0.1986.59.2.827
   Chen FP, 2020, BRAIN BEHAV IMMUN, V88, P36, DOI 10.1016/j.bbi.2020.05.061
   Clarke Victoria, 2015, Qualitative psychology: a practical guide to research methods, V3rd, DOI 10.1080/17439760.2016.1262613
   Cohen S., 1994, Meas Stress: a Guide Health Soc Sci, V10, P1, DOI DOI 10.1037/T02889-000
   De Berardis D, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10090591
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Denovan A, 2019, STUD HIGH EDUC, V44, P120, DOI 10.1080/03075079.2017.1340445
   Diaz-Orueta U., 2012, J VIRTUAL REALITY, V5, P1
   Donker MH, 2021, DEV PSYCHOL, V57, P1611, DOI 10.1037/dev0001212
   Donker T, 2019, JAMA PSYCHIAT, V76, P682, DOI 10.1001/jamapsychiatry.2019.0219
   Dvir Y, 2014, HARVARD REV PSYCHIAT, V22, P149, DOI 10.1097/HRP.0000000000000014
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   Elliott R, 2021, J CHILD PSYCHOL PSYC, V62, P270, DOI 10.1111/jcpp.13240
   Flores A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00531
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Frewen P, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00858
   Gillanders DT, 2014, BEHAV THER, V45, P83, DOI 10.1016/j.beth.2013.09.001
   Golberstein E, 2020, JAMA PEDIATR, V174, P819, DOI 10.1001/jamapediatrics.2020.1456
   Greener Games, 2020, NAT TREKS
   Guan H, 2017, ANN FOR RES, V60, P327, DOI 10.15287/afr.2017.897
   Halldorsson B, 2021, J CHILD PSYCHOL PSYC, V62, P584, DOI 10.1111/jcpp.13400
   Hamilton JL, 2016, J ABNORM CHILD PSYCH, V44, P495, DOI 10.1007/s10802-015-0049-0
   Hertz MF, 2021, INJURY PREV, V27, P85, DOI 10.1136/injuryprev-2020-044050
   Hides L, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/11482
   Hollis C, 2017, J CHILD PSYCHOL PSYC, V58, P474, DOI 10.1111/jcpp.12663
   Jeffs D, 2014, J BURN CARE RES, V35, P395, DOI 10.1097/BCR.0000000000000019
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Kotera Y, 2022, INT J MENT HEALTH AD, V20, P337, DOI 10.1007/s11469-020-00363-4
   Kothgassner OD, 2021, NEUROPSYCHIATRIE, V35, P68, DOI 10.1007/s40211-020-00349-7
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Kudinova AY, 2022, CHILD YOUTH CARE FOR, V51, P579, DOI 10.1007/s10566-021-09641-1
   Lee M, 2019, SCI TOTAL ENVIRON, V672, P381, DOI 10.1016/j.scitotenv.2019.03.454
   Lennarz HK, 2019, INT J BEHAV DEV, V43, P1, DOI 10.1177/0165025418755540
   Lesage FX, 2012, OCCUP MED-OXFORD, V62, P600, DOI 10.1093/occmed/kqs140
   Lin J, 2019, CURR OPIN PEDIATR, V31, P469, DOI 10.1097/MOP.0000000000000760
   Lipari R.N., 2016, ADOLESCENT MENTAL HL
   Loades ME, 2020, J AM ACAD CHILD PSY, V59, P1218, DOI 10.1016/j.jaac.2020.05.009
   Maarsingh BM, 2019, GAMES HEALTH J, V8, P326, DOI 10.1089/g4h.2018.0145
   Maughan B, 2013, J CAN ACAD CHILD ADO, V22, P35
   McEwen Bruce S, 2017, Chronic Stress (Thousand Oaks), V1, DOI 10.1177/2470547017692328
   Mesa-Gresa P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082486
   Miyazaki Y., 2018, SHINRIN YOKU JAPANES
   NIMH, 2017, NIMH AN ANX DIS
   Nolin P, 2016, COMPUT HUM BEHAV, V59, P327, DOI 10.1016/j.chb.2016.02.023
   Nordby K, 2019, BMC PSYCHOL, V7, DOI 10.1186/s40359-019-0309-9
   Nutsford D, 2013, PUBLIC HEALTH, V127, P1005, DOI 10.1016/j.puhe.2013.08.016
   Orben A, 2020, LANCET CHILD ADOLESC, V4, P634, DOI 10.1016/S2352-4642(20)30186-3
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   Patel NK, 2018, EXPLORE-NY, V14, P443, DOI 10.1016/j.explore.2018.06.008
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Schleider JL, 2019, JMIR RES PROTOC, V8, DOI 10.2196/13368
   Schmitt YS, 2011, BURNS, V37, P61, DOI 10.1016/j.burns.2010.07.007
   Shiri S, 2013, PAIN MED, V14, P621, DOI 10.1111/pme.12083
   Soh D. J. H., 2021, FRONT PSYCHOL, V12, P2143, DOI [10.1016/j.pedhc.2021.01.002, DOI 10.1016/J.PEDHC.2021.01.002]
   Sonney J, 2021, J PEDIATR HEALTH CAR, V35, P552, DOI 10.1016/j.pedhc.2021.01.002
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Tennant M, 2020, J PEDIATR ONCOL NURS, V37, P265, DOI 10.1177/1043454220917859
   Thapar A, 2012, LANCET, V379, P1056, DOI 10.1016/S0140-6736(11)60871-4
   Twenge JM, 2019, J ABNORM PSYCHOL, V128, P185, DOI 10.1037/abn0000410
   Vanaken GJ, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15122668
   Vogel Susanne, 2016, NPJ Sci Learn, V1, P16011, DOI 10.1038/npjscilearn.2016.11
   Wang MT, 2021, J AFFECT DISORDERS, V294, P245, DOI 10.1016/j.jad.2021.06.082
NR 74
TC 7
Z9 8
U1 7
U2 14
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 8
PY 2022
VL 3
AR 831026
DI 10.3389/frvir.2022.831026
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AN8
UT WOS:001019292600001
PM 38846011
OA gold
DA 2024-07-18
ER

PT J
AU Rau, L
   Döring, DC
   Horst, R
   Dörner, R
AF Rau, Linda
   Doering, Dagny C.
   Horst, Robin
   Doerner, Ralf
TI Pattern-Based Augmented Reality Authoring Using Different Degrees of
   Immersion: A Learning Nugget Approach
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; nuggets; authoring; immersion; preview
AB Creating Augmented Reality (AR) applications can be an arduous process. With most current authoring tools, authors must complete multiple authoring steps in a time-consuming process before they can try their AR application and get a first impression of it. Especially for laypersons, complex workflows set a high barrier to getting started with creating AR applications. This work presents a novel authoring approach for creating mobile AR applications. Our idea is to provide authors with small, ready-to-use AR applications that can be executed and tested directly as a starting point. Authors can then focus on customizing these AR applications to their needs without programming knowledge. We propose to use patterns from application domains to further facilitate the authoring process. Our idea is based on the learning nugget approach from the educational sciences, where a nugget is a small and self-contained learning unit. We transfer this approach to the field of AR authoring and introduce an AR nugget authoring tool. The authoring tool provides pattern-based self-contained AR applications, called AR nuggets. AR nuggets use simple geometric objects to give authors an impression of the AR application. By replacing these objects and further adaptions, authors can realize their AR applications. Our authoring tool draws from non-immersive desktop computers and AR devices. It synchronizes all changes to an AR nugget both to an AR device and a non-immersive device. This enables authors to use both devices, e.g., a desktop computer to type text and an AR device to place virtual objects in the 3D environment. We evaluate our proposed authoring approach and tool in a user study with 48 participants. Our users installed the AR nugget authoring tool on their own devices, worked with it for 3 weeks, and filled out a questionnaire. They were able to create AR applications and found the AR nugget approach supportive. The users mainly used the desktop computer for the authoring tasks but found the synchronization to the AR device helpful to experience the AR nuggets at any time. However, the users had difficulties with some interactions and rated the AR nugget authoring tool in a neutral field.
C1 [Rau, Linda; Doering, Dagny C.; Horst, Robin; Doerner, Ralf] Rhein Main Univ Appl Sci, Design Comp Sci Media, Wiesbaden, Germany.
RP Rau, L (corresponding author), Rhein Main Univ Appl Sci, Design Comp Sci Media, Wiesbaden, Germany.
EM linda.rau@hs-rm.de
OI Rau, Linda/0000-0001-7165-0041
FU German Federal Ministry of Education and Research (BMBF) [13FH181PX8]
FX This work has been funded by the German Federal Ministry of Education
   and Research (BMBF), funding program Forschung an Fachhochschulen,
   contract number 13FH181PX8.
CR Apaza-Yllachura Y, 2019, P INT C CHIL COMPUT, DOI 10.1109/sccc49216.2019.8966427
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Gattullo M, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P172, DOI 10.1109/ISMAR-Adjunct51615.2020.00054
   Hampshire A., 2006, Proceedings of the 18th Australia conference on Computer-Human Interaction: Design: Activities, Artefacts and Environments, P409, DOI DOI 10.1145/1228175.1228259
   Hassenzahl M., 2003, Mensch & Computer 2003: Interaktion in Bewegung, P187, DOI [DOI 10.1007/978-3-322-80058, DOI 10.1007/978-3-322-80058-9_19]
   Horst R., 2021, THESIS HOCHSCHULE RH
   Horst R, 2020, J UNIVERS COMPUT SCI, V26, P947
   Horst R, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364261
   Laviola E, 2022, INT J ADV MANUF TECH, V119, P1769, DOI 10.1007/s00170-021-08449-6
   Ledermann F, 2007, EMERGING TECHNOLOGIES OF AUGMENTED REALITY: INTERFACES AND DESIGN, P138
   Lee GA, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P172, DOI 10.1109/ISMAR.2004.34
   Lytridis C, 2018, EDUC SCI, V8, DOI 10.3390/educsci8010006
   Photon, 2022, BOLT OV PHOT ENG
   PTC, 2021, VUF ENT AUGM REAL AR
   Rau L, 2021, INT SYM MIX AUGMENT, P212, DOI 10.1109/ISMAR-Adjunct54149.2021.00051
   Roberto RA, 2016, LECT NOTES COMPUT SC, V9748, P237, DOI 10.1007/978-3-319-40406-6_22
   Speicher Maximilian, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3229089
   Unity, 2021, PLATF CHOIC MULT HIT
   Wang MJ, 2010, IFIP ADV INF COMM TE, V332, P285
   Wilkes C., 2021, LEAN TOUCH
NR 20
TC 2
Z9 2
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 28
PY 2022
VL 3
AR 841066
DI 10.3389/frvir.2022.841066
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OL9
UT WOS:001021703400001
OA gold
DA 2024-07-18
ER

PT J
AU Regateiro, J
   Volino, M
   Hilton, A
AF Regateiro, Joao
   Volino, Marco
   Hilton, Adrian
TI Deep4D: A Compact Generative Representation for Volumetric Video
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE volumetric video; generative networks; motion graphs; animation;
   performance capture
AB This paper introduces Deep4D a compact generative representation of shape and appearance from captured 4D volumetric video sequences of people. 4D volumetric video achieves highly realistic reproduction, replay and free-viewpoint rendering of actor performance from multiple view video acquisition systems. A deep generative network is trained on 4D video sequences of an actor performing multiple motions to learn a generative model of the dynamic shape and appearance. We demonstrate the proposed generative model can provide a compact encoded representation capable of high-quality synthesis of 4D volumetric video with two orders of magnitude compression. A variational encoder-decoder network is employed to learn an encoded latent space that maps from 3D skeletal pose to 4D shape and appearance. This enables high-quality 4D volumetric video synthesis to be driven by skeletal motion, including skeletal motion capture data. This encoded latent space supports the representation of multiple sequences with dynamic interpolation to transition between motions. Therefore we introduce Deep4D motion graphs, a direct application of the proposed generative representation. Deep4D motion graphs allow real-tiome interactive character animation whilst preserving the plausible realism of movement and appearance from the captured volumetric video. Deep4D motion graphs implicitly combine multiple captured motions from a unified representation for character animation from volumetric video, allowing novel character movements to be generated with dynamic shape and appearance detail.
C1 [Regateiro, Joao; Volino, Marco; Hilton, Adrian] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, England.
   [Regateiro, Joao] Univ Grenoble Alpes, Inst Engn, Grenoble INP, Inria,CNRS,LJK, Grenoble, France.
C3 University of Surrey; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Centre National de la Recherche
   Scientifique (CNRS); Inria; Universite Grenoble Alpes (UGA)
RP Regateiro, J (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, England.; Regateiro, J (corresponding author), Univ Grenoble Alpes, Inst Engn, Grenoble INP, Inria,CNRS,LJK, Grenoble, France.
EM j.regateiro@inria.fr
RI Hilton, Adrian/N-3736-2014
OI Hilton, Adrian/0000-0003-4223-238X
CR [Anonymous], 1980, The Face of Man: Expressions of Universal Emotions in a New Guinea Village
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Bordino I, 2008, IEEE DATA MINING, P737, DOI 10.1109/ICDM.2008.109
   Boukhayma A, 2019, IEEE T VIS COMPUT GR, V25, P2270, DOI 10.1109/TVCG.2018.2831233
   Boukhayma A, 2017, INT CONF 3D VISION, P309, DOI 10.1109/3DV.2017.00043
   Boukhayma A, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P478, DOI 10.1109/3DV.2015.60
   Brock A., 2018, INT C LEARN REPR
   Budd C, 2013, INT J COMPUT VISION, V102, P256, DOI 10.1007/s11263-012-0553-4
   Cagniart C, 2010, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2010.5539814
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Casas Dan, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P242, DOI 10.1007/978-3-642-25090-3_21
   Casas D., 2012, P ACM SIGGRAPH S INT, P103, DOI DOI 10.1145/2159616.2159633
   Casas D, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12296
   Casas D, 2013, IEEE T VIS COMPUT GR, V19, P762, DOI 10.1109/TVCG.2012.314
   CMU Graphics Lab, 2001, CMU GRAPH LAB MOT CA
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761
   Esser P., 2019, LEARNING REALISTIC R, P409, DOI [10.1007/978-3-030-11012-3_32, DOI 10.1007/978-3-030-11012-3_32]
   Goodfellow I. J., 2014, ARXIV
   Hilsmann A, 2020, IET COMPUT VIS, V14, P350, DOI 10.1049/iet-cvi.2019.0786
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Huang P, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699643
   Huang P, 2009, PROC CVPR IEEE, P1478, DOI 10.1109/CVPRW.2009.5206626
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma D. P., 2013, ARXIV13126114
   Klaudiny M, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P17, DOI 10.1109/3DIMPVT.2012.67
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Laine S., 2018, INT C LEARN REPR ICL
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Ma L., 2017, DISENTANGLED PERSON
   Miyato T, 2018, INT C LEARN REPR
   Muller M., 2007, Information retrieval for music and motion, P69, DOI [10.1007/978-3-540-74048-3_4, DOI 10.1007/978-3-540-74048-3_4]
   Paier W, 2020, CVMP 2020: THE 17TH ACM SIGGRAPH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, DOI 10.1145/3429341.3429356
   Peng Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3473, DOI 10.1109/CVPR.2011.5995438
   Prada F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925967
   Regateiro J, 2019, INT CONF 3D VISION, P376, DOI 10.1109/3DV.2019.00049
   Regateiro J, 2018, INT CONF 3D VISION, P514, DOI 10.1109/3DV.2018.00065
   Sainburg T., 2018, Generative adversarial interpolative autoencoding: Adversarial training on latent space interpolations encourage convex latent distributions
   Sakoe H., 1990, Dynamic programming algorithm optimization for spoken word recognition, P159, DOI 10.1016/b978-0-08-051584-7.50016-4
   Siarohin A., 2017, DEFORMABLE GANS POSE
   Starck J., 2005, SCA 05, P49, DOI DOI 10.1145/1073368.1073375
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Tan QY, 2018, PROC CVPR IEEE, P5841, DOI 10.1109/CVPR.2018.00612
   Tanco LM, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P137, DOI 10.1109/HUMO.2000.897383
   Tejera M, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P159, DOI 10.1109/3DV.2013.29
   Tulyakov S., 2017, Mocogan: Decomposing motion and content for video generation
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Witkin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P105, DOI 10.1145/218380.218422
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 58
TC 0
Z9 0
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 1
PY 2021
VL 2
AR 739010
DI 10.3389/frvir.2021.739010
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZT0
UT WOS:001019271700001
OA gold
DA 2024-07-18
ER

PT J
AU Vasilevski, N
   Birt, J
AF Vasilevski, Nikolche
   Birt, James
TI Human-Centered Design Science Research Evaluation for Gamified Augmented
   Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; gamification; educational games; design science
   research methodology; design evaluation; design methodology;
   micro-location
ID USABILITY
AB As augmented reality (AR) and gamification design artifacts for education proliferate in the mobile and wearable device market, multiple frameworks have been developed to implement AR and gamification. However, there is currently no explicit guidance on designing and conducting a human-centered evaluation activity beyond suggesting possible methods that could be used for evaluation. This study focuses on human-centered design evaluation pattern for gamified AR using Design Science Research Methodology (DSRM) to support educators and developers in constructing immersive AR games. Specifically, we present an evaluation pattern for a location-based educational indigenous experience that can be used as a case study to support the design of augmented (or mixed) reality interfaces, gamification implementations, and location-based services. This is achieved through the evaluation of three design iterations obtained in the development cycle of the solution. The holistic analysis of all iterations showed that the evaluation process could be reused, evolved, and its complexity reduced. Furthermore, the pattern is compatible with formative and summative evaluation and the technical or human-oriented types of evaluation. This approach provides a method to inform the evaluation of gamified AR apps. At the same time, it will enable a more approachable evaluation process to support educators, designers, and developers.
C1 [Vasilevski, Nikolche; Birt, James] Bond Univ, Fac Soc & Design, Robina, Qld, Australia.
C3 Bond University
RP Vasilevski, N (corresponding author), Bond Univ, Fac Soc & Design, Robina, Qld, Australia.
EM nvasilev@bond.edu.au
RI Birt, James Richard/ABD-6953-2021; Vasilevski, Nikolche/I-7471-2017
OI Birt, James Richard/0000-0002-0422-4867; Vasilevski,
   Nikolche/0000-0003-3356-0090
CR Bacca J, 2015, PROCEDIA COMPUT SCI, V75, P49, DOI 10.1016/j.procs.2015.12.203
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Birt J, 2021, EDUC TECHNOL SOC, V24, P93
   Birt J, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2128
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   El-Masri M., 2015, ECIS
   Geerts Guido L., 2011, International Journal of Accounting Information Systems, V12, P142, DOI 10.1016/j.accinf.2011.02.004
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Hoehle H, 2016, INT J HUM-COMPUT ST, V89, P35, DOI 10.1016/j.ijhcs.2016.02.001
   Hoehle H, 2015, MIS QUART, V39, P435, DOI 10.25300/MISQ/2015/39.2.08
   Irani Z, 2002, EUR J INFORM SYST, V11, P74, DOI 10.1057/palgrave/ejis/3000411
   Klecun E, 2005, EUR J INFORM SYST, V14, P229, DOI 10.1057/palgrave.ejis.3000540
   Koivisto J, 2014, COMPUT HUM BEHAV, V35, P179, DOI 10.1016/j.chb.2014.03.007
   Morschheuser B, 2018, INFORM SOFTWARE TECH, V95, P219, DOI 10.1016/j.infsof.2017.10.015
   Nelson GL, 2018, ICER'18: PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P31, DOI 10.1145/3230977.3230992
   Peffers K, 2007, J MANAGE INFORM SYST, V24, P45, DOI 10.2753/MIS0742-1222240302
   Pernice K., 2018, User Interviews: How, When, and Why to Conduct Them
   Prat N., 2014, PACIS, P23
   Pries-Heje J., 2008, ECIS 2008 P
   Remenyi D., 2012, IT Investment: Making a Business Case
   Simon H., 1982, SCI ARTIFICIAL
   Sommerauer P., 2021, P 54 HAWAII INT C SY, P1623
   Stufflebeam D.L., 2000, EVALUATION MODELSVIE, P279, DOI 10.1007/0-306-47559-6_16
   Vasilevski N., 2019, 12 AUSTRALASIAN SIMU, P77
   Vasilevski N., 2019, 17 INT C VIRT REAL C, P1
   Venable John, 2012, Design Science Research in Information Systems. Advances in Theory and Practice. Proceedings 7th International Conference, DESRIST 2012, P423, DOI 10.1007/978-3-642-29863-9_31
   Venable J, 2016, EUR J INFORM SYST, V25, P77, DOI 10.1057/ejis.2014.36
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Wiliam D., 2006, BRIT EDUC RES J, DOI [10.1080/0141192960220502, DOI 10.1080/0141192960220502]
NR 29
TC 0
Z9 0
U1 4
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 30
PY 2021
VL 2
AR 713718
DI 10.3389/frvir.2021.713718
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SW8
UT WOS:001021819100001
OA gold, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Pinilla, A
   Garcia, J
   Raffe, W
   Voigt-Antons, JN
   Spang, RP
   Möller, S
AF Pinilla, Andres
   Garcia, Jaime
   Raffe, William
   Voigt-Antons, Jan-Niklas
   Spang, Robert P.
   Moeller, Sebastian
TI Affective Visualization in Virtual Reality: An Integrative Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; affect; emotion; electrophysiology; visual design;
   visualization
ID BRAIN-COMPUTER INTERFACES; FACIAL REACTIONS; CONCEPTUAL INFORMATION;
   PERCEPTUAL CUES; EMOTION; RESPONSES; COLOR; RECOGNITION; EXPRESSION;
   EXPERIENCE
AB A cluster of research in Affective Computing suggests that it is possible to infer some characteristics of users' affective states by analyzing their electrophysiological activity in real-time. However, it is not clear how to use the information extracted from electrophysiological signals to create visual representations of the affective states of Virtual Reality (VR) users. Visualization of users' affective states in VR can lead to biofeedback therapies for mental health care. Understanding how to visualize affective states in VR requires an interdisciplinary approach that integrates psychology, electrophysiology, and audio-visual design. Therefore, this review aims to integrate previous studies from these fields to understand how to develop virtual environments that can automatically create visual representations of users' affective states. The manuscript addresses this challenge in four sections: First, theories related to emotion and affect are summarized. Second, evidence suggesting that visual and sound cues tend to be associated with affective states are discussed. Third, some of the available methods for assessing affect are described. The fourth and final section contains five practical considerations for the development of virtual reality environments for affect visualization.
C1 [Pinilla, Andres; Voigt-Antons, Jan-Niklas; Spang, Robert P.; Moeller, Sebastian] Tech Univ Berlin, Inst Software Technol & Theoret Comp Sci, Fac Elect Engn & Comp Sci, Qual & Usabil Lab, Berlin, Germany.
   [Pinilla, Andres; Garcia, Jaime; Raffe, William] Univ Technol Sydney UTS, Fac Engn & IT, UTS Games Studio, Sydney, NSW, Australia.
   [Voigt-Antons, Jan-Niklas; Moeller, Sebastian] German Res Ctr Artificial Intelligence DFKI, Berlin, Germany.
C3 Technical University of Berlin; University of Technology Sydney; German
   Research Center for Artificial Intelligence (DFKI)
RP Pinilla, A (corresponding author), Tech Univ Berlin, Inst Software Technol & Theoret Comp Sci, Fac Elect Engn & Comp Sci, Qual & Usabil Lab, Berlin, Germany.; Pinilla, A (corresponding author), Univ Technol Sydney UTS, Fac Engn & IT, UTS Games Studio, Sydney, NSW, Australia.
EM andres.pinilla@qu.tu-berlin.de
RI Spang, Robert P./AHB-8655-2022; Raffe, William Luke/AAI-2676-2020
OI Spang, Robert P./0000-0001-6580-9060; Raffe, William
   Luke/0000-0001-5310-0943; Pinilla Palacios, Andres/0000-0002-0812-7896;
   Moller, Sebastian/0000-0003-3057-0760; Garcia, Jaime/0000-0001-5718-1605
FU Technische Universitaet Berlin, Germany; University of Technology
   Sydney, Australia
FX & nbsp;This work was supported by the strategic partnership between the
   Technische Universitaet Berlin, Germany and the University of Technology
   Sydney, Australia.
CR [Anonymous], 2015, INTRO EVOLUTIONARY C
   [Anonymous], 2014, Python for signal processing: featuring IPython notebooks
   Antons JN, 2014, T-LAB SER TELECOMMUN, P109, DOI 10.1007/978-3-319-02681-7_8
   Arndt S, 2018, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON MULTIMEDIA CONTENT ANALYSIS IN SPORTS (MMSPORTS'18), P45, DOI 10.1145/3265845.3265848
   Aronoff J, 2006, CROSS-CULT RES, V40, P83, DOI 10.1177/1069397105282597
   ARONOFF J, 1992, J PERS SOC PSYCHOL, V62, P1050, DOI 10.1037/0022-3514.62.6.1050
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bar M, 2006, PSYCHOL SCI, V17, P645, DOI 10.1111/j.1467-9280.2006.01759.x
   Bard P, 1934, PSYCHOL REV, V41, P309, DOI 10.1037/h0070765
   Barrett LF, 2009, ADV EXP SOC PSYCHOL, V41, P167, DOI 10.1016/S0065-2601(08)00404-8
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Belger Julia., 2019, 2019 International Conference on Virtual Rehabilitation (ICVR), P1, DOI [DOI 10.1109/ICVR46560.2019.8994342, 10.1109/ICVR46560.2019.8994342]
   Badia SBI, 2019, IEEE J BIOMED HEALTH, V23, P1877, DOI 10.1109/JBHI.2018.2878846
   Blandon D.Z., 2016, 2016 IEEE 11th Colombian Computing Conference (CCC), P1, DOI DOI 10.1109/COLUMBIANCC.2016.7750788
   Blum J, 2020, APPL PSYCHOPHYS BIOF, V45, P153, DOI 10.1007/s10484-020-09468-x
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Blum S, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00141
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   BULL P, 1978, BRIT J SOC CLIN PSYC, V17, P1, DOI 10.1111/j.2044-8260.1978.tb00888.x
   Burdea GC, 2013, IEEE T NEUR SYS REH, V21, P165, DOI 10.1109/TNSRE.2012.2206055
   Cacioppo J T, 1997, Pers Soc Psychol Rev, V1, P3, DOI 10.1207/s15327957pspr0101_2
   Camgöz N, 2002, COLOR RES APPL, V27, P199, DOI 10.1002/col.10051
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Cannon WB, 1927, AM J PSYCHOL, V39, P106, DOI 10.2307/1415404
   Cassani R, 2018, INT WORK QUAL MULTIM, P246
   Cavazza Marc., 2014, Towards Empathic Neurofeedback for Interactive Storytelling", P1, DOI [10.4230/OASICS.CMN.2014.42, DOI 10.4230/OASICS.CMN.2014.42, 10.4230/oasics.cmn.2014.42]
   Colzato LS, 2017, CORTEX, V92, P95, DOI 10.1016/j.cortex.2017.03.017
   Conati C, 2002, LECT NOTES COMPUT SC, V2363, P944
   Cordaro DT, 2016, EMOTION, V16, P117, DOI 10.1037/emo0000100
   Cosmides L., 1994, Mapping the mind, P85
   Darwin C., 1872, P374
   DAVIDSON RJ, 1992, PSYCHOL SCI, V3, P39, DOI 10.1111/j.1467-9280.1992.tb00254.x
   Desmet PMA, 2015, INT J DES, V9, P1
   Desmet PMA., 2016, Journal of Design Research, V14, P241, DOI DOI 10.1504/JDR.2016.079751
   Dimberg U, 2000, PSYCHOL SCI, V11, P86, DOI 10.1111/1467-9280.00221
   DIMBERG U, 1982, PSYCHOPHYSIOLOGY, V19, P643, DOI 10.1111/j.1469-8986.1982.tb02516.x
   Dimberg U, 2012, PSYCH J, V1, P118, DOI 10.1002/pchj.4
   Drossos K, 2015, IEEE T AFFECT COMPUT, V6, P27, DOI 10.1109/TAFFC.2015.2392768
   Ebe Yurika., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, P1995, DOI DOI 10.1145/2702613.2732768
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   Ekman P., 1973, Darwin and facial expression: A century of research in review, P169
   Feffer M., 2018, INT C MACH LEARN DAT, P316, DOI [10.1007/978-3-319-96133-0_24, DOI 10.1007/978-3-319-96133-0_24]
   Feng C., 2014, Proceedings of the ACM Symposium on Applied Perception-SAP'14, P23, DOI DOI 10.1145/2628257.2628264
   Fernández-Sotos A, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00080
   FISHER RJ, 1993, J CONSUM RES, V20, P303, DOI 10.1086/209351
   Fuhrman O, 2010, COGNITIVE SCI, V34, P1430, DOI 10.1111/j.1551-6709.2010.01105.x
   Gaebler M., 2021, EXCITE O METER
   Gao XP, 2007, COLOR RES APPL, V32, P223, DOI 10.1002/col.20321
   Garcia JA, 2014, IEEE INT CONF SERIOU, DOI 10.1109/SeGAH.2014.7067087
   Georgiou T, 2017, USER MODEL USER-ADAP, V27, P267, DOI 10.1007/s11257-017-9192-3
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   Greinacher Robert, 2020, Human-Computer Interaction. Design and User Experience. Thematic Area, HCI 2020 Held as Part of the 22nd International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12181), P439, DOI 10.1007/978-3-030-49059-1_32
   Greinacher R, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123141
   Haar AJH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77951-w
   Harischandra J., 2012, 2012 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES 2012), P454, DOI 10.1109/IECBES.2012.6498050
   Hernandez J, 2014, 2014 EAI 4TH INTERNATIONAL CONFERENCE ON WIRELESS MOBILE COMMUNICATION AND HEALTHCARE (MOBIHEALTH), P55, DOI [10.1109/MOBIHEALTH.2014.7015908, 10.4108/icst.mobihealth.2014.257219]
   Hofmann SM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P128, DOI 10.1109/AIVR.2018.00026
   Hoppe S, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00105
   Hupont Isabelle., 2015, 2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX), P1, DOI [DOI 10.1109/QOMEX.2015.7148110, 10.1109/QoMEX.2015.7148110]
   Huster RJ, 2009, INT J PSYCHOPHYSIOL, V72, P212, DOI 10.1016/j.ijpsycho.2008.12.009
   Jaques PA, 2007, COMPUT EDUC, V49, P360, DOI 10.1016/j.compedu.2005.09.002
   Kapur A, 2005, LECT NOTES COMPUT SC, V3784, P1
   Kitson A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3311762
   Klug M, 2021, EUR J NEUROSCI, V54, P8406, DOI 10.1111/ejn.14992
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koenig S. T., 2011, VALIDITY EVALUATION
   Kothe CA, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/5/056014
   Lang PJ, 2008, A8 U FLOR
   Lange CarlGeorg., 1922, The emotions, V1, DOI DOI 10.1037/10735-000
   Leslie G., 2015, EEG MOTION CAPTURE B, DOI [10.13140/RG.2.1.4378.6081, DOI 10.13140/RG.2.1.4378.6081]
   Li ZL, 2016, EXP BRAIN RES, V234, P3575, DOI 10.1007/s00221-016-4744-z
   Lipson-Smith R, 2021, VIRTUAL REAL-LONDON, V25, P631, DOI 10.1007/s10055-020-00479-x
   Lockyer M., 2011, P INT S COMPUTATIONA, P89, DOI [DOI 10.2312/COMPAESTH/COMPAESTH11/089-09610.1145/2030441.2030461, 10.1145/2030441.2030461, DOI 10.1145/2030441.2030461]
   Lucassen MP, 2011, COLOR RES APPL, V36, P426, DOI 10.1002/col.20647
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979
   Martínez-Tejada LA, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11030378
   Mattek AM, 2017, PERSPECT PSYCHOL SCI, V12, P508, DOI 10.1177/1745691616685863
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   McDuff D, 2012, IEEE T AFFECT COMPUT, V3, P456, DOI 10.1109/T-AFFC.2012.19
   Mullen TR, 2015, IEEE T BIO-MED ENG, V62, P2553, DOI 10.1109/TBME.2015.2481482
   Ortony A., 1988, COGNITIVE STRUCTURE
   Pagani M, 1984, J Hypertens Suppl, V2, pS383
   Palmer SE, 2010, P NATL ACAD SCI USA, V107, P8877, DOI 10.1073/pnas.0906172107
   Peperkorn HM, 2014, J CLIN PSYCHOL, V70, P704, DOI 10.1002/jclp.22057
   Perkis A., 2020, QUALINET White Paper on Definitions of Immersive Media Experience (IMEx)
   Petri Toiviaine., 2009, Frontiers in Human Neuroscience, V3, DOI [DOI 10.3389/CONF.NEURO.09.2009.02.033, 10.3389/conf.neuro.09.2009.02.033]
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Phillips F, 2010, SEEING PERCEIVING, V23, P263, DOI 10.1163/187847510X516412
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Pinilla A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00097
   Pion-Tonachini L, 2015, IEEE ENG MED BIO, P4114, DOI 10.1109/EMBC.2015.7319299
   Piwek L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00611
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   Polzehl T, 2011, SPEECH COMMUN, V53, P1198, DOI 10.1016/j.specom.2011.05.002
   Porcu S, 2020, IEEE T NETW SERV MAN, V17, P2702, DOI 10.1109/TNSM.2020.3018303
   Putnam H., 1967, ART MIND RELIG, P1
   Raffe WL, 2015, IEEE T COMP INTEL AI, V7, P139, DOI 10.1109/TCIAIG.2014.2341665
   RAY WJ, 1985, SCIENCE, V228, P750, DOI 10.1126/science.3992243
   Renard Y, 2010, PRESENCE-VIRTUAL AUG, V19, P35, DOI 10.1162/pres.19.1.35
   Reuderink Boris, 2013, International Journal of Autonomous and Adaptive Communications Systems, V6, P45, DOI 10.1504/IJAACS.2013.050691
   Robitaille P, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317022
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Ryali CK, 2020, P NATL ACAD SCI USA, V117, P29371, DOI 10.1073/pnas.1912343117
   SCHACHTER S, 1962, PSYCHOL REV, V69, P379, DOI 10.1037/h0046234
   Scherer K.R., 1977, Motivation and Emotion, V1, P331, DOI DOI 10.1007/BF00992539
   Schoeller F, 2019, PHYS LIFE REV, V31, P310, DOI 10.1016/j.plrev.2019.10.008
   Schoeller F, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02741
   Semertzidis N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376599
   Shiban Y, 2016, J BEHAV THER EXP PSY, V51, P19, DOI 10.1016/j.jbtep.2015.11.002
   Shiban Y, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00400
   Shiota M.N., 2012, Emotion, Vsecond
   Sitaram R, 2011, NEUROIMAGE, V56, P753, DOI 10.1016/j.neuroimage.2010.08.007
   Sutherland MR, 2012, EMOTION, V12, P1367, DOI 10.1037/a0027860
   Tajadura-Jimenez A, 2008, CYBERPSYCHOL BEHAV, V11, P33, DOI 10.1089/cpb.2007.0002
   Tajadura-Jiménez A, 2010, EMOTION, V10, P416, DOI 10.1037/a0018423
   Tajadura-Jiménez A, 2010, EMOTION, V10, P216, DOI 10.1037/a0018422
   Thayer JF, 2009, ANN BEHAV MED, V37, P141, DOI 10.1007/s12160-009-9101-z
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Vogt T, 2008, LECT NOTES ARTIF INT, V5078, P188, DOI 10.1007/978-3-540-69369-7_21
   Voigt-Antons Jan-Niklas, 2020, 2020 12 INT C QUAL M, P1, DOI [10.1109/QoMEX48832.2020.9123125, DOI 10.1109/QOMEX48832.2020.9123125]
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Williams D, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3059005
   Wilms L, 2018, PSYCHOL RES-PSYCH FO, V82, P896, DOI 10.1007/s00426-017-0880-8
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Wundt Wilhelm., 1897, Outlines of psychology, DOI DOI 10.1037/12908-000
   Yannakakis GN, 2011, IEEE T AFFECT COMPUT, V2, P147, DOI 10.1109/T-AFFC.2011.6
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
NR 128
TC 6
Z9 8
U1 6
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 6
PY 2021
VL 2
AR 630731
DI 10.3389/frvir.2021.630731
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2QC0
UT WOS:001021745600001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Cao, ZK
   Grandi, J
   Kopper, R
AF Cao, Zekun
   Grandi, Jeronimo
   Kopper, Regis
TI Granulated Rest Frames Outperform Field of View Restrictors on Visual
   Search Performance
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE human performance; visual search; rest frames; virtual reality; HCI
ID VIRTUAL-REALITY; MOTION SICKNESS; MOBILITY PERFORMANCE; VECTION;
   PERCEPTION; GUIDANCE; VISION; OBJECT
AB Dynamic field of view (FOV) restrictors have been successfully used to reduce visually induced motion sickness (VIMS) during continuous viewpoint motion control (virtual travel) in virtual reality (VR). This benefit, however, comes at the cost of losing peripheral awareness during provocative motion. Likewise, the use of visual references that are stable in relation to the physical environment, called rest frames (RFs), has also been shown to reduce discomfort during virtual travel tasks in VR. We propose a new RF-based design called Granulated Rest Frames (GRFs) with a soft-edged circular cutout in the center that leverages the rest frames' benefits without completely blocking the user's peripheral view. The GRF design is application-agnostic and does not rely on context-specific RFs, such as commonly used cockpits. We report on a within-subjects experiment with 20 participants. The results suggest that, by strategically applying GRFs during a visual search session in VR, we can achieve better item searching efficiency as compared to restricted FOV. The effect of GRFs on reducing VIMS remains to be determined by future work.
C1 [Cao, Zekun] Duke Univ, Dept Mech Engn & Mat Sci, Durham, NC USA.
   [Grandi, Jeronimo; Kopper, Regis] Univ North Carolina Greensboro, Dept Comp Sci, Greensboro, NC 27412 USA.
C3 Duke University; University of North Carolina; University of North
   Carolina Greensboro
RP Kopper, R (corresponding author), Univ North Carolina Greensboro, Dept Comp Sci, Greensboro, NC 27412 USA.
EM kopper@uncg.edu
OI Grandi, Jeronimo/0000-0002-9505-7776
CR Alexander RG, 2012, VISION RES, V54, P20, DOI 10.1016/j.visres.2011.12.004
   Alexander RG, 2011, J VISION, V11, DOI 10.1167/11.8.9
   Anderson BL, 2002, COGNITIVE PSYCHOL, V44, P148, DOI 10.1006/cogp.2001.0765
   [Anonymous], 1975, Motion sickness
   Arthur KevinW., 2000, EFFECTS FIELD VIEW P
   Baumann J., 1993, MILITARY APPL VIRTUA, DOI [10.1007/978-3-663-10693-7, DOI 10.1007/978-3-663-10693-7]
   Bubka A, 2008, PERCEPTION, V37, P704, DOI 10.1068/p5781
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   CCP Games, 2017, EV VALK WARZ
   COLLEWIJN H, 1988, J PHYSIOL-LONDON, V404, P157, DOI 10.1113/jphysiol.1988.sp017284
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Cunningham J. A., 1995, INT S AV PSYCH 8 COL, P158
   Dataset Astrofish Games Ltd, 2018, GROUND RUNN TRIALS
   [Dataset] Doc-Ok.org, 2016, OPTICAL PROPERTIES C
   [Dataset] SIGTRAP Ltd, 2019, VR TUNN PRO
   Dichgans J., 1978, HDB SENSORY PHYSL, VVIII., P755
   Duh HBL, 2001, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2001.913791
   Erkelens C.J., 1996, Journal of Videology, V1, P1
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Frey A, 2007, COMPUT HUM BEHAV, V23, P2026, DOI 10.1016/j.chb.2006.02.010
   Fujii Y, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669519899108
   GERBINO W, 1987, ACTA PSYCHOL, V65, P25, DOI 10.1016/0001-6918(87)90045-X
   Geringswald F, 2015, J EXP PSYCHOL LEARN, V41, P1485, DOI 10.1037/xlm0000117
   Geruschat DR, 1998, OPTOMETRY VISION SCI, V75, P525, DOI 10.1097/00006324-199807000-00022
   Hassan SE, 2002, OPTOMETRY VISION SCI, V79, P697, DOI 10.1097/00006324-200211000-00007
   HENN V, 1974, BRAIN RES, V71, P144, DOI 10.1016/0006-8993(74)90198-X
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hogervorst MA, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.4.041106
   Hout MC, 2015, ATTEN PERCEPT PSYCHO, V77, P128, DOI 10.3758/s13414-014-0764-6
   HOWLETT EM, 1990, P SOC PHOTO-OPT INS, V1256, P210, DOI 10.1117/12.19915
   Irwin J. A., 1881, LANCET, V118, P907, DOI DOI 10.1016/S0140-6736(02)38129-7
   Ito H, 2005, VISION RES, V45, P397, DOI 10.1016/j.visres.2004.11.009
   Jang W, 2016, COMPUT METH PROG BIO, V135, P115, DOI 10.1016/j.cmpb.2016.07.026
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI 10.1145/2792790
   Jex H. R., 1991, NASA AMES RES CENT H, P42
   Johnson D. M, 2005, Introduction to and Review of Simulator Sickness Research, DOI [10.1037/e456932006-001, DOI 10.1037/E456932006-001]
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B., 2014, HDB VIRTUAL ENV DESI, P648
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   KOZAK JJ, 1993, ERGONOMICS, V36, P777, DOI 10.1080/00140139308967941
   Kuiper OX, 2019, DISPLAYS, V58, P82, DOI 10.1016/j.displa.2018.10.001
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Larsson P., 2004, Proceedings of 7th Annual Workshop of Presence, P252
   Lin J. J.-W., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2124
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Lin JJW, 2004, P SIGCHI C HUM FACT, P719, DOI DOI 10.1145/985692.985783
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   McElree B, 1999, J EXP PSYCHOL HUMAN, V25, P1517, DOI 10.1037/0096-1523.25.6.1517
   Meng M, 2008, J VISION, V8, DOI 10.1167/8.9.7
   Michotte Albert., 1991, MICHOTTES EXPT PHENO, P140
   Nanay B, 2010, PHILOS STUD, V150, P239, DOI 10.1007/s11098-009-9407-5
   Nooij SAE, 2018, EXP BRAIN RES, V236, P3031, DOI 10.1007/s00221-018-5340-1
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Palmisano S, 2000, PERCEPTION, V29, P57, DOI 10.1068/p2990
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Prothero J.D., 1998, The role of rest frames in vection, presence and motion sickness
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   PROTHERO JD, 1995, HUM FAC ERG SOC P, P1410
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Rajashekar U., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P119, DOI 10.1145/507072.507096
   REASON JT, 1970, ADV SCI, V26, P386
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Robinett R., 1992, P 1992 S INT 3D GRAP, P189, DOI 10.1145/147156.1472012
   Rosenholtz R, 2012, J VISION, V12, DOI 10.1167/12.4.14
   SEKULER AB, 1992, J EXP PSYCHOL GEN, V121, P95, DOI 10.1037/0096-3445.121.1.95
   Seno T, 2009, VISION RES, V49, P2973, DOI 10.1016/j.visres.2009.09.017
   Seya Y, 2014, I-PERCEPTION, V5, P630, DOI 10.1068/i0671
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Seymour NE, 2008, WORLD J SURG, V32, P182, DOI 10.1007/s00268-007-9307-9
   Shen JY, 2003, CAN J EXP PSYCHOL, V57, P76, DOI 10.1037/h0087415
   Sorrentino R. M., 2005, INT J COMPUTER SCI S, V4, P40
   Soska KC, 2010, DEV PSYCHOL, V46, P129, DOI 10.1037/a0014618
   Steele J.E., 1961, Motion Sickness and Spatial perception, A Theoretical Study
   Stratton G.M., 1897, PSYCHOL REV, V4, P341, DOI [DOI 10.1037/H0075482, 10.1037/h0075482]
   TELFORD L, 1993, PERCEPT PSYCHOPHYS, V53, P682, DOI 10.3758/BF03211744
   Treisman A., 1998, VISUAL ATTENTION, V8, P26
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Tse PU, 1999, COGNITIVE PSYCHOL, V39, P37, DOI 10.1006/cogp.1999.0715
   Valjamae A., 2005, Travelling without moving: Auditory scene cues for translational self-motion
   Webb NA, 2003, AVIAT SPACE ENVIR MD, V74, P622
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Weech S, 2017, MULTISENS RES, V30, P65, DOI 10.1163/22134808-00002545
   Wittinghinll D., 2015, GAM DEV C GDC
   Wood R.W., 1895, PSYCHOL REV, V2/3, P277, DOI [DOI 10.1037/H0073333, 10.1037/h0073333]
   Xiao R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1221, DOI 10.1145/2858036.2858212
   Zhaoping L, 2011, J EXP PSYCHOL HUMAN, V37, P997, DOI 10.1037/a0023099
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 90
TC 3
Z9 3
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 31
PY 2021
VL 2
AR 604889
DI 10.3389/frvir.2021.604889
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TC8
UT WOS:001021825100001
OA gold
DA 2024-07-18
ER

PT J
AU Ferdous, SMS
   Chowdhury, TI
   Arafat, IM
   Quarles, J
AF Ferdous, Sharif Mohammad Shahnewaz
   Chowdhury, Tanvir Irfan
   Arafat, Imtiaz Muhammad
   Quarles, John
TI Static Rest Frame to Improve Postural Stability in Virtual and Augmented
   Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE balance; postural stability; accessibility; multiple sclerosis;
   cybersickness; virtual reality; augmented reality; head-mounted display
ID MULTIPLE-SCLEROSIS; BALANCE; EXPOSURE; GAIT; ENVIRONMENTS; SICKNESS;
   EXERCISE; VALIDITY; MOBILITY; DISEASE
AB Many users have shown increased postural instability while using Head-Mounted Displays (HMDs) as HMDs block their real-world vision. People with balance impairments are especially more affected by this as they depend more on their visual cues to maintain their balance. In addition, balance is a good indication of cybersickness according to postural instability theory. In this research, we have investigated how to use additional visual cues to improve postural stability. Through conducting one user study in Virtual Reality (VR) and Augmented Reality (AR), we have studied the effect of a Static Rest Frame (SRF) on postural stability in persons with balance impairments due to Multiple Sclerosis (MS). Results indicate that an SRF significantly improves postural stability in VR and AR for users with MS. Based on these results, we propose guidelines for designing more accessible VR and AR systems for persons with balance impairments.
C1 [Ferdous, Sharif Mohammad Shahnewaz] Coll New Jersey, Dept Comp Sci, Ewing, NJ 08618 USA.
   [Chowdhury, Tanvir Irfan] Marshall Univ, Dept Comp Sci & Elect Engn, Huntington, WV USA.
   [Arafat, Imtiaz Muhammad; Quarles, John] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA.
C3 College of New Jersey; Marshall University; University of Texas System;
   University of Texas at San Antonio (UTSA)
RP Ferdous, SMS (corresponding author), Coll New Jersey, Dept Comp Sci, Ewing, NJ 08618 USA.
EM sharif.shahnewaz@tcnj.edu
RI Chowdhury, Tanvir Irfan/IXD-4222-2023
FU National Science Foundation [IIS-1350995]
FX This work was supported by grants from the National Science Foundation
   under Grant No. IIS-1350995.
CR Abrahamová D, 2008, PHYSIOL RES, V57, P957, DOI 10.33549/physiolres.931238
   Bakshi R, 2003, MULT SCLER J, V9, P219, DOI 10.1191/1352458503ms904oa
   Banou E, 2015, ADV EXP MED BIOL, V822, P165, DOI 10.1007/978-3-319-08927-0_18
   Baram Y, 2006, NEUROLOGY, V66, P178, DOI 10.1212/01.wnl.0000194255.82542.6b
   BERG K, 1989, Physiotherapy Canada, V41, P304
   Bisson E, 2007, CYBERPSYCHOL BEHAV, V10, P16, DOI 10.1089/cpb.2006.9997
   Bouchard Stephane., 2006, Perceived realism has a significant impact on presence
   Champney RK, 2007, HUM FACTORS, V49, P491, DOI 10.1518/001872007X200120
   Chang E, 2013, INT WINT WORKSH BR, P62, DOI 10.1109/IWW-BCI.2013.6506631
   Chang WD, 2013, J PHYS THER SCI, V25, P1251, DOI 10.1589/jpts.25.1251
   Clark RA, 2010, GAIT POSTURE, V31, P307, DOI 10.1016/j.gaitpost.2009.11.012
   Corporaal SHA, 2013, GAIT POSTURE, V37, P55, DOI 10.1016/j.gaitpost.2012.05.025
   Espay AJ, 2010, J REHABIL RES DEV, V47, P573, DOI 10.1682/JRRD.2009.10.0165
   Ferdous SMS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P121, DOI 10.1109/3DUI.2016.7460041
   Fulk George D, 2005, J Neurol Phys Ther, V29, P34
   Guo RK, 2015, COMPUT ANIMAT VIRT W, V26, P509, DOI 10.1002/cav.1610
   HAGEMAN PA, 1995, ARCH PHYS MED REHAB, V76, P961, DOI 10.1016/S0003-9993(95)80075-1
   Hansson EE, 2010, ACTA OTO-LARYNGOL, V130, P1358, DOI 10.3109/00016489.2010.498024
   Horlings CGC, 2009, NEUROSCI LETT, V451, P227, DOI 10.1016/j.neulet.2008.12.057
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Kalron A., 2012, J PHYS THER, V5, P54
   Kalron A, 2017, GAIT POSTURE, V54, P209, DOI 10.1016/j.gaitpost.2017.03.016
   Kaminsky TA, 2007, J REHABIL RES DEV, V44, P437, DOI 10.1682/JRRD.2006.09.0109
   Kaye products inc, 2020, KAYE PROD
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1997, AVIAT SPACE ENVIR MD, V68, P13
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1996, INT J HUM-COMPUT INT, V8, P25, DOI 10.1080/10447319609526139
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khasnis A, 2003, J Postgrad Med, V49, P169
   Kreylos O., 2017, Hololens and field of view in augmented reality
   KURTZKE JF, 1983, NEUROLOGY, V33, P1444, DOI 10.1212/WNL.33.11.1444
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee D. N., 1975, Journal of Human Movement Studies, V1, P87, DOI DOI 10.3758/BF03199297
   Lord SR, 2006, AGE AGEING, V35, P42, DOI 10.1093/ageing/afl085
   Lozano-Quilis JA, 2013, INT CONF PER COMP, P366, DOI 10.4108/icst.pervasivehealth.2013.252208
   Microsoft, 2020, MICR HOL MIX REAL TE
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Ms-Society, 2020, WHO GETS MS NAT MULT
   Newton RA, 2001, J GERONTOL A-BIOL, V56, pM248, DOI 10.1093/gerona/56.4.M248
   Nilsagård YE, 2013, MULT SCLER J, V19, P209, DOI 10.1177/1352458512450088
   Oculus, 2020, OC RIFT VR HEADS VR
   POWELL LE, 1995, J GERONTOL A-BIOL, V50, pM28, DOI 10.1093/gerona/50A.1.M28
   Prothero J.D., 1998, The role of rest frames in vection, presence and motion sickness
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rougier P, 2007, SOMATOSENS MOT RES, V24, P41, DOI 10.1080/08990220701318148
   Salavati M, 2009, GAIT POSTURE, V29, P460, DOI 10.1016/j.gaitpost.2008.11.016
   Samaraweera G, 2015, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2015.7223329
   Samaraweera G, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P23, DOI 10.1109/3DUI.2013.6550192
   Sveistrup H, 2003, CYBERPSYCHOL BEHAV, V6, P245, DOI 10.1089/109493103322011524
   TINETTI ME, 1986, J AM GERIATR SOC, V34, P119, DOI 10.1111/j.1532-5415.1986.tb05480.x
   Van Emmerik REA, 2010, GAIT POSTURE, V32, P608, DOI 10.1016/j.gaitpost.2010.09.002
   Young W, 2011, GAIT POSTURE, V33, P303, DOI 10.1016/j.gaitpost.2010.10.089
   Zuzewicz K, 2011, INT J OCCUP SAF ERGO, V17, P403
NR 54
TC 5
Z9 6
U1 5
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 23
PY 2021
VL 1
AR 582169
DI 10.3389/frvir.2020.582169
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PK9
UT WOS:001021728400001
OA gold
DA 2024-07-18
ER

PT J
AU Donegan, T
   Ryan, BE
   Swidrak, J
   Sanchez-Vives, MV
AF Donegan, Tony
   Ryan, Brenda E. E.
   Swidrak, Justyna
   Sanchez-Vives, Maria V. V.
TI Immersive Virtual Reality for Clinical Pain: Considerations for
   Effective Therapy
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; pain; embodiment; presence; body ownership; HMD;
   immersive; virtual rehabilitation
ID PHYSICAL-THERAPY; REHABILITATION; OWNERSHIP; STROKE; HABITUATION;
   EFFICACY; ILLUSION; MOTION; HAND; VR
AB Immersive virtual reality is transforming medical and psychological research and treatment, including the treatment of clinical pain. In this short perspective paper, we present some of the methodological difficulties that are rarely discussed in the literature of pain research when using virtual reality. These often-unmentioned problems can confound research investigations or interfere with the therapeutic efficacy in clinical trials. We propose practical solutions based on our research experience. We first outline the mechanisms of, and challenges to, the sensations of embodiment and presence, which are critical to creating effective virtual reality illusions, before discussing the particular considerations that need to be contemplated when working with patients with clinical pain. Finally, we discuss some upcoming technological advances that may influence significantly this rapidly expanding field in the near future.
C1 [Donegan, Tony; Ryan, Brenda E. E.; Swidrak, Justyna; Sanchez-Vives, Maria V. V.] Inst Invest Biomed August Pi i Sunyer IDIBAPS, Barcelona, Spain.
   [Swidrak, Justyna; Sanchez-Vives, Maria V. V.] Event Lab, Barcelona, Spain.
   [Swidrak, Justyna] Polish Acad Sci, Inst Psychol, Warsaw, Poland.
   [Sanchez-Vives, Maria V. V.] Inst Catalana Recerca & Estudis Avancats ICREA, Barcelona, Spain.
   [Sanchez-Vives, Maria V. V.] Univ Barcelona, Dept Cognit Dev & Educ Psychol, Barcelona, Spain.
C3 University of Barcelona; Hospital Clinic de Barcelona; IDIBAPS; Polish
   Academy of Sciences; Institute of Psychology of the Polish Academy of
   Sciences; ICREA; University of Barcelona
RP Donegan, T (corresponding author), Inst Invest Biomed August Pi i Sunyer IDIBAPS, Barcelona, Spain.
EM donegan@clinic.cat
RI Swidrak, Justyna/HGU-9131-2022; Ryan, Brenda Elizabeth/ADI-3250-2022;
   Sanchez-Vives, Maria/J-8526-2014
OI Swidrak, Justyna/0000-0003-0141-2667; Donegan, Tony/0000-0002-1856-1020;
   Sanchez-Vives, Maria/0000-0002-8437-9083
FU NEUROVIRTUAL [2017-SGR-01296]; CECH; Commission for Universities and
   Research of the Department of Innovation, Universities, and Enterprise
   of the Generalitat de Catalunya -AGAUR- [IU16-011508]; European Union
   Regional Development Fund within the framework of the ERDF/FEDER
   Operational Program of Catalonia
FX This work was supported by NEUROVIRTUAL 2017-SGR-01296, and by CECH,
   funded by GENCAT_TechEmergent18 by the Commission for Universities and
   Research of the Department of Innovation, Universities, and Enterprise
   of the Generalitat de Catalunya -AGAUR- (IU16-011508) and co-financed by
   the European Union Regional Development Fund within the framework of the
   ERDF/FEDER Operational Program of Catalonia 2014-2020 to MVS-V.
CR Aamer A, 2019, INT C MICROELECTRON, P166, DOI [10.1109/icm48031.2019.9021752, 10.1109/ICM48031.2019.9021752]
   Azañón E, 2016, MULTISENS RES, V29, P635, DOI 10.1163/22134808-00002531
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Boesch E, 2016, PAIN, V157, P516, DOI 10.1097/j.pain.0000000000000423
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Cabibihan John-John, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P348, DOI 10.1007/978-3-642-34103-8_35
   Clark A, 2016, TLS-TIMES LIT SUPPL, P6
   Coburn JQ, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4036921
   Cohen O., 2019, BRAIN COMPUTER INTER, P93, DOI [10.1007/978-3-030-05668-1_9, DOI 10.1007/978-3-030-05668-1_9]
   Corbetta D, 2015, J PHYSIOTHER, V61, P117, DOI 10.1016/j.jphys.2015.05.017
   Crosbie JH, 2007, DISABIL REHABIL, V29, P1139, DOI 10.1080/09638280600960909
   D'Amour S, 2017, EXP BRAIN RES, V235, P2811, DOI 10.1007/s00221-017-5009-1
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Ferracci S, 2019, CONSCIOUS COGN, V73, DOI 10.1016/j.concog.2019.05.004
   Fulvio JM, 2019, VARIABILITY SENSORY, DOI DOI 10.1101/488817
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Harvie DS, 2015, PSYCHOL SCI, V26, P385, DOI 10.1177/0956797614563339
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Kemeny A., 2017, The Engineering Reality of Virtual Reality, P48
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kopec W, 2019, IFAC PAPERSONLINE, V52, P277, DOI 10.1016/j.ifacol.2019.12.110
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Leeb R., 2012, INT C ADV COMP ENT T
   Leeb R, 2020, HAND CLINIC, V168, P183, DOI 10.1016/B978-0-444-63934-9.00014-7
   Llobera J, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0300
   Lotte F., 2012, PRACTICAL BRAINCOMPU, P197, DOI [10.1007/978-3-642-29746-5_10, DOI 10.1007/978-3-642-29746-5_10]
   Lotze Martin, 2007, Curr Rheumatol Rep, V9, P488
   Lupu RG, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/4798359
   Marasco PD, 2018, J PHYSIOL-LONDON, V596, P133, DOI 10.1113/JP275468
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Nierula B., 2019, BRAIN COMPUTER INTER, P103, DOI [10.1007/978-3-030-05668-1_10, DOI 10.1007/978-3-030-05668-1_10]
   Nierula B, 2021, J PHYSIOL-LONDON, V599, P2419, DOI 10.1113/JP278167
   Nierula B, 2017, J PAIN, V18, P645, DOI 10.1016/j.jpain.2017.01.003
   Ortner R, 2012, STUD HEALTH TECHNOL, V181, P319, DOI 10.3233/978-1-61499-121-2-319
   Perez-Marcos Daniel, 2012, Front Neurol, V3, P110, DOI 10.3389/fneur.2012.00110
   Perez-Marcos D, 2009, NEUROREPORT, V20, P589, DOI 10.1097/WNR.0b013e32832a0a2a
   Remsik AB, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00752
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Schmitt YS, 2011, BURNS, V37, P61, DOI 10.1016/j.burns.2010.07.007
   Serrano B, 2016, COMPUT HUM BEHAV, V55, P1, DOI 10.1016/j.chb.2015.08.007
   Sherman WR, 2019, MKS COMP GRAPH GEOME, P781, DOI 10.1016/B978-0-12-800965-9.00010-6
   Slater M, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00003
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Solcà M, 2018, NEUROLOGY, V91, pE479, DOI 10.1212/WNL.0000000000005905
   Soltani M, 2018, REHABIL PSYCHOL, V63, P487, DOI 10.1037/rep0000239
   Spiss S, 2018, P IEEE RAS-EMBS INT, P279, DOI 10.1109/BIOROB.2018.8488133
   Stanton TR, 2018, PEERJ, V6, DOI 10.7717/peerj.5206
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00244
NR 58
TC 14
Z9 14
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 15
PY 2020
VL 1
AR 9
DI 10.3389/frvir.2020.00009
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L6TU0
UT WOS:001024573700001
OA gold
DA 2024-07-18
ER

PT J
AU Toet, A
   Heijn, F
   Brouwer, AM
   Mioch, T
   van Erp, JBF
AF Toet, Alexander
   Heijn, Fabienne
   Brouwer, Anne-Marie
   Mioch, Tina
   van Erp, Jan B. F.
TI An Immersive Self-Report Tool for the Affective Appraisal of 360○ VR
   Videos
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE 360 degrees VR; immersive VR; valence; arousal; emotions; EmojiGrid
ID SIMPLE GEOMETRIC SHAPES; VIRTUAL-REALITY; CIRCUMPLEX MODEL; CORE AFFECT;
   EMOTION; ENVIRONMENTS; CYBERSICKNESS; TECHNOLOGIES; RECOGNITION;
   PERCEPTION
AB Immersive 360 degrees virtual reality (VR) movies can effectively evoke a wide range of different emotional experiences. To this end, they are increasingly deployed in entertainment, marketing and research. Because emotions influence decisions and behavior, it is important to assess the user's affective appraisal of immersive 360 degrees VR movies. Knowledge of this appraisal can serve to tune media content to achieve the desired emotional responses for a given purpose. To measure the affective appraisal of immersive VR movies, efficient immersive and validated instruments are required that minimally interfere with the VR experience itself. Here we investigated the convergent validity of a new efficient and intuitive graphical (emoji-based) affective self-report tool (the EmojiGrid) for the assessment of valence and arousal induced by videos representing 360 degrees VEs (virtual environments). Thereto, 40 participants rated their emotional response (valence and arousal) to 62 videos from a validated public database of 360 degrees VR movies using an EmojiGrid that was embedded in the VE, while we simultaneously assessed their autonomic physiological arousal through electrodermal activity. The mean affective ratings obtained with the EmojiGrid and those provided with the database (measured with an alternative and validated instrument) show excellent agreement for valence and good agreement for arousal. The mean arousal ratings obtained with the EmojiGrid also correlate strongly with autonomic physiological arousal. Thus, the EmojiGrid appears to be a valid and immersive affective self-report tool for measuring VE-induced emotions.
C1 [Toet, Alexander; Heijn, Fabienne; Brouwer, Anne-Marie; Mioch, Tina; van Erp, Jan B. F.] Netherlands Org Appl Sci Res TNO Human Factors, Soesterberg, Netherlands.
   [Heijn, Fabienne] Univ Utrecht, Fac Social & Behav Sci, Appl Cognit Psychol, Utrecht, Netherlands.
   [van Erp, Jan B. F.] Univ Twente, Human Media Interact, Enschede, Netherlands.
C3 Utrecht University; University of Twente
RP Toet, A (corresponding author), Netherlands Org Appl Sci Res TNO Human Factors, Soesterberg, Netherlands.
EM lex.toet@tno.nl
OI Brouwer, Anne-Marie/0000-0003-1961-4291; van Erp,
   Jan/0000-0002-6511-2850
FU TNO Early Research Program (ERP) Social eXtended Reality (Social XR)
FX The research reported in this paper was partly funded by the TNO Early
   Research Program (ERP) Social eXtended Reality (Social XR).
CR Andersen INSK, 2019, FOOD RES INT, V117, P10, DOI 10.1016/j.foodres.2018.01.027
   Andreassi JL., 2013, PSYCHOPHYSIOLOGY HUM, DOI [10.4324/9781410602817, DOI 10.4324/9781410602817]
   Anolli L, 2010, INT J EMERG TECHNOL, V5, P7, DOI 10.3991/ijet.v5s3.1496
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   [Anonymous], 1980, TECHNOLOGY MENTAL HL
   [Anonymous], 2008, 5 AUSTR C INT ENT IE
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   ARONOFF J, 1988, J PERS SOC PSYCHOL, V54, P647, DOI 10.1037/0022-3514.54.4.647
   Bangcuyo RG, 2015, FOOD QUAL PREFER, V41, P84, DOI 10.1016/j.foodqual.2014.11.017
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Beck J., 2018, INFORM COMMUNICATION, P3, DOI [DOI 10.1007/978-3-319-72923-71, 10.1007/978-3-319-72923-71]
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Bonetti F, 2018, PROGR IS, P119, DOI 10.1007/978-3-319-64027-3_9
   Bouchard S, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P59, DOI 10.1109/HAVE.2004.1391882
   Boucsein W., 1999, KOREAN J SCI EMOT SE, V2, P1
   Boucsein W, 2012, PSYCHOPHYSIOLOGY, V49, P1017, DOI 10.1111/j.1469-8986.2012.01384.x
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Broekens J, 2013, INT J HUM-COMPUT ST, V71, P641, DOI 10.1016/j.ijhcs.2013.02.003
   Brouwer AM, 2018, LECT NOTES COMPUT SC, V10727, P7, DOI 10.1007/978-3-319-91593-7_2
   Brouwer AM, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00136
   Calogiuri G, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02321
   Cappallo S, 2019, IEEE T MULTIMEDIA, V21, P402, DOI 10.1109/TMM.2018.2862363
   Chen L, 2008, INTERACT COMPUT, V20, P17, DOI 10.1016/j.intcom.2007.06.003
   Chen Y, 2018, INT J IND ERGONOM, V66, P119, DOI 10.1016/j.ergon.2018.02.013
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Cicchetti D. V., 1994, PSYCHOL ASSESSMENTS, V6, P284, DOI [DOI 10.1037/1040-3590.6.4.284, 10.1037/1040-3590.6.4.284, https://doi.org/10.1037/1040-3590.6.4.284]
   Clore GL, 2007, TRENDS COGN SCI, V11, P393, DOI 10.1016/j.tics.2007.08.005
   Dawson ME, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P159, DOI 10.1017/cbo9780511546396.007
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Ding N, 2018, TELEMAT INFORM, V35, P1572, DOI 10.1016/j.tele.2018.04.003
   Sanchez GME, 2017, LANDSCAPE URBAN PLAN, V167, P98, DOI 10.1016/j.landurbplan.2017.05.018
   Estupiñán S, 2014, LECT NOTES COMPUT SC, V8518, P541, DOI 10.1007/978-3-319-07626-3_51
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Fibbi S., 2015, 33 ANN ACM C EXTENDE, P299, DOI [10.1145/2702613.2725452, DOI 10.1145/2702613.2725452]
   Fleureau J, 2012, IEEE T AFFECT COMPUT, V3, P379, DOI 10.1109/T-AFFC.2012.2
   Freeman J., 2005, PRESENCE, P213
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Gorini A, 2009, CYBERPSYCHOL BEHAV, V12, P699, DOI 10.1089/cpb.2009.0192
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Gutierrez MarioA., 2008, STEPPING VIRTUAL REA, DOI DOI 10.1007/978-1-84800-117-6
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Hallgren Kevin A, 2012, Tutor Quant Methods Psychol, V8, P23
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hayek U W., 2016, Journal of Digital Landscape Architecture, P100, DOI DOI 10.14627/537612012
   Hilfert Thomas, 2016, Visualization in Engineering, V4, DOI 10.1186/s40327-015-0031-5
   Huang YC, 2016, INT J TOUR RES, V18, P116, DOI 10.1002/jtr.2038
   Huisman G., 2013, P SIGCHI C HUM FACT, P351, DOI DOI 10.1145/2470654.2470706
   Kaneko D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204397
   Kaneko D, 2019, FOOD RES INT, V115, P541, DOI 10.1016/j.foodres.2018.09.049
   Kaneko D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00911
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kim S., 2004, FLAIRS 2004 SPECIAL
   King SC, 2010, FOOD QUAL PREFER, V21, P168, DOI 10.1016/j.foodqual.2009.02.005
   Knight Melinda M, 2006, P 3 S APPL PERC GRAP, P162, DOI DOI 10.1145/1140491.1140539
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Kruger C, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123100
   Lang Peter J., 2005, International affective picture system (IAPS): Affective ratings of pictures and instruction manual. (Technical Report A-6.)
   Larson CL, 2012, MOTIV EMOTION, V36, P404, DOI 10.1007/s11031-011-9249-2
   Laurans G., 2012, 8th International Conference on Design and Emotion: Out of Control - Proceedings, P11
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Ling Y, 2012, PRESENCE-TELEOP VIRT, V21, P254, DOI 10.1162/PRES_a_00111
   Liu CL, 2007, LECT NOTES COMPUT SC, V4555, P666
   Lopatovska I, 2011, INFORM PROCESS MANAG, V47, P575, DOI 10.1016/j.ipm.2010.09.001
   Higuera-Trujillo JL, 2017, APPL ERGON, V65, P398, DOI 10.1016/j.apergo.2017.05.006
   Macedonio MF, 2007, CYBERPSYCHOL BEHAV, V10, P508, DOI 10.1089/cpb.2007.9997
   Marasco A, 2018, J DESTIN MARK MANAGE, V9, P138, DOI 10.1016/j.jdmm.2017.12.002
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Mattek AM, 2017, PERSPECT PSYCHOL SCI, V12, P508, DOI 10.1177/1745691616685863
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Mavridou I., 2018, 12 INT C DIS VIRT RE
   Mirk D, 2014, L N INST COMP SCI SO, V136, P144
   Mobach Mark P., 2008, Virtual Reality, V12, P163, DOI 10.1007/s10055-008-0081-2
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nestrud MA, 2016, FOOD QUAL PREFER, V48, P107, DOI 10.1016/j.foodqual.2015.08.005
   Oliveira T., 2020, ADV INTELLIGENT SYST, P462, DOI [10.1007/978-3-030-20227-9_43, DOI 10.1007/978-3-030-20227-9_43]
   Oliveira T, 2018, ADV INTELL SYST, V588, P71, DOI 10.1007/978-3-319-60582-1_8
   Park G.R., 2006, Proceedings of the Human Factors and Ergonomics Society 50 Annual Meeting, P2702, DOI DOI 10.1177/154193120605002607
   Patterson Z, 2017, LANDSCAPE URBAN PLAN, V157, P63, DOI 10.1016/j.landurbplan.2016.05.024
   Peperkorn HM, 2015, COMPUT HUM BEHAV, V48, P542, DOI 10.1016/j.chb.2015.02.028
   Pitt M, 2005, FACILITIES, V23, P343, DOI 10.1108/02632770510600290
   Portman ME, 2015, COMPUT ENVIRON URBAN, V54, P376, DOI 10.1016/j.compenvurbsys.2015.05.001
   Prayag G, 2013, J DESTIN MARK MANAGE, V2, P118, DOI 10.1016/j.jdmm.2013.05.001
   Putze S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376144
   Puyana-Romero V, 2017, ACTA ACUST UNITED AC, V103, P574, DOI 10.3813/AAA.919086
   Ramalho Joao., 2013, Proceedings of the 2013 ACM international workshop on Immersive media experiences, P35, DOI [DOI 10.1145/2512142.2512144, 10.1145/2512142.2512144]
   Regal G., 2019, Quality and User Experience, V4, P1
   Riva G., 2003, Presence Connect
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Roth W.T., 1983, Tutorials in event-related potential research, P177
   Runge N, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P846, DOI 10.1145/2957265.2961836
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Schmitt B.H., 1999, J MARKET MANAG, V15, P53, DOI [10.1362/026725799784870496, DOI 10.1362/026725799784870496]
   SCHWARZ N, 1983, J PERS SOC PSYCHOL, V45, P513, DOI 10.1037/0022-3514.45.3.513
   Schwarz N., 2002, HEURISTICS BIASES, P534, DOI DOI 10.1017/CBO9780511808098.031
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Sester C, 2013, FOOD QUAL PREFER, V28, P23, DOI 10.1016/j.foodqual.2012.07.006
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Sharar SR, 2016, GAMES HEALTH J, V5, P197, DOI 10.1089/g4h.2015.0046
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Simon SC, 2019, COMPUT HUM BEHAV, V93, P141, DOI 10.1016/j.chb.2018.12.018
   Sinesio F, 2019, FOOD QUAL PREFER, V77, P123, DOI 10.1016/j.foodqual.2019.05.004
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Söderman M, 2005, J ENG DESIGN, V16, P311, DOI 10.1080/09544820500128967
   Soleymani M., 2008, P 2 ACM WORKSHOP MUL, P32, DOI DOI 10.1145/1460676.1460684
   Spielberger CD, 1983, State-trait anxiety inventory for adults, DOI DOI 10.1037/T06496-000
   Spinelli S, 2014, FOOD QUAL PREFER, V37, P109, DOI 10.1016/j.foodqual.2013.11.009
   Suhaimi NS, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P167, DOI 10.1109/CSPA.2018.8368706
   Tajadura-Jiménez A, 2008, LECT NOTES COMPUT SC, V4868, P63, DOI 10.1007/978-3-540-85099-1_6
   Toet A., 2019, Psych, V1, P469, DOI [DOI 10.3390/PSYCH1010036, 10.3390/psych1010036]
   Toet A, 2020, CHEMOSENS PERCEPT, V13, P141, DOI 10.1007/s12078-019-09275-7
   Toet A, 2019, LECT NOTES COMPUT SC, V11883, P330, DOI 10.1007/978-3-030-31908-3_24
   Toet A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02396
   Trindade Y, 2018, LECT NOTES COMPUT SC, V10920, P730, DOI 10.1007/978-3-319-91806-8_57
   Tussyadiah I., 2016, 2016 TTRA INT C ADV
   Tussyadiah IP., 2017, Information and Communication Technologies in Tourism 2017: Proceedings of the International Conference. Rome, P229, DOI DOI 10.1007/978-3-319-51168-917
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   Vastenburg MartijnH., 2011, CHI'11 Extended Abstracts on Human Factors in Computing Systems, CHI EA'11, P2155, DOI [DOI 10.1145/1979742.1979933, 10.1145/1979742.1979933]
   Västfjäll D, 2003, CYBERPSYCHOL BEHAV, V6, P181, DOI 10.1089/109493103321640374
   Vettehen PH, 2019, COMPUT HUM BEHAV, V91, P24, DOI 10.1016/j.chb.2018.09.018
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Voigt-Antons JN, 2020, INT WORK QUAL MULTIM
   Walls AR, 2011, J TRAVEL TOUR MARK, V28, P567, DOI 10.1080/10548408.2011.588121
   Wang G, 2018, LECT NOTES COMPUT SC, V10923, P217, DOI 10.1007/978-3-319-91716-0_17
   Waterworth J.A., 2015, Immersed in media: Telepresence theory, measurement and technology, P35, DOI 10.1007/978-3-319-10190-3_3
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Watson DG, 2012, EMOTION, V12, P18, DOI 10.1037/a0024495
   Windhager S, 2008, HUM NATURE-INT BIOS, V19, P331, DOI 10.1007/s12110-008-9047-z
   Xu C., 2008, FRONTIERS WWW RES DE, P759, DOI [10.1007/11610113_70, DOI 10.1007/11610113_70]
   Xue T, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382895
   Zentner M., 2010, Handbook of music and emotion, P187
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
   Zhao S., 2013, INT C MULT MOD MMM 2, P7732, DOI DOI 10.1007/978-3-642-35725-1_34
NR 139
TC 7
Z9 7
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 25
PY 2020
VL 1
AR 552587
DI 10.3389/frvir.2020.552587
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XU9
UT WOS:001023319600001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Nguyen, R
   Gouin-Vallerand, C
   Amiri, M
AF Nguyen, Richard
   Gouin-Vallerand, Charles
   Amiri, Maryam
TI Hand interaction designs in mixed and augmented reality head mounted
   display: a scoping review and classification
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE augmented reality; mixed reality; hand interaction; POST WIMP; hand
   grasp; gestures; machine learning; scoping review
AB Mixed reality has made its first step towards democratization in 2017 with the launch of a first generation of commercial devices. As a new medium, one of the challenges is to develop interactions using its endowed spatial awareness and body tracking. More specifically, at the crossroad between artificial intelligence and human-computer interaction, the goal is to go beyond the Window, Icon, Menu, Pointer (WIMP) paradigm humans are mainly using on desktop computer. Hand interactions either as a standalone modality or as a component of a multimodal modality are one of the most popular and supported techniques across mixed reality prototypes and commercial devices. In this context, this paper presents scoping literature review of hand interactions in mixed reality. The goal of this review is to identify the recent findings on hand interactions about their design and the place of artificial intelligence in their development and behavior. This review resulted in the highlight of the main interaction techniques and their technical requirements between 2017 and 2022 as well as the design of the Metaphor-behavior taxonomy to classify those interactions.
C1 [Nguyen, Richard] Univ Sherbrooke, Dept Comp Sci, DOMUS Lab, Sherbrooke, PQ, Canada.
   [Gouin-Vallerand, Charles] Univ Sherbrooke, Business Sch, DOMUS Lab, Sherbrooke, PQ, Canada.
   [Amiri, Maryam] VMware Canada, Ottawa, ON, Canada.
C3 University of Sherbrooke; University of Sherbrooke
RP Nguyen, R (corresponding author), Univ Sherbrooke, Dept Comp Sci, DOMUS Lab, Sherbrooke, PQ, Canada.
EM richard.nguyen@usherbrooke.ca
FU Canadian funding organization MITACS [IT27213]; company VMware Canada
FX This project is funded by the Canadian funding organization MITACS
   (project IT27213) and the company VMware Canada.
CR Ababsa F, 2020, LECT NOTES COMPUT SC, V12242, P315, DOI 10.1007/978-3-030-58465-8_24
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bautista L., 2018, ACM INT C PROCEEDING, DOI [10.1145/3293578.3293590, DOI 10.1145/3293578.3293590]
   Bautista L, 2020, INT J INTERACT DES M, V14, P1031, DOI 10.1007/s12008-020-00690-9
   Bouchard K., 2014, P 7 INT C PERVASIVE, P1, DOI [10.1145/2674396.2674405, DOI 10.1145/2674396.2674405]
   Caputo A, 2021, COMPUT GRAPH-UK, V99, P201, DOI 10.1016/j.cag.2021.07.007
   Chang YS, 2017, IEEE SYMP 3D USER, P182, DOI 10.1109/3DUI.2017.7893337
   Choudhary Zubin, 2021, SUI '21: Symposium on Spatial User Interaction, DOI 10.1145/3485279.3488286
   Dibene JC, 2022, arXiv
   Frutos-Pascual M, 2019, LECT NOTES COMPUT SC, V11749, P287, DOI 10.1007/978-3-030-29390-1_16
   Glauser O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322957
   Hand C, 1997, COMPUT GRAPH FORUM, V16, P269, DOI 10.1111/1467-8659.00194
   Hu ZX, 2018, NEUROCOMPUTING, V318, P151, DOI 10.1016/j.neucom.2018.08.042
   Jailungka P, 2018, LECT NOTES COMPUT SC, V10903, P269, DOI 10.1007/978-3-319-91250-9_21
   Jang S, 2017, MYCOBIOLOGY, V45, P1, DOI 10.5941/MYCO.2017.45.1.1
   Kim HI, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P428, DOI 10.1109/ISMAR-Adjunct.2018.00130
   Kim M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153171
   Koutsabasis P, 2019, INT J HUM-COMPUT INT, V35, P1747, DOI 10.1080/10447318.2019.1572352
   Lee CJ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281618
   Lee LH, 2019, INT CONF PERVAS COMP, DOI 10.1109/percom.2019.8767420
   Lee TH, 2022, IEEE T HUM-MACH SYST, V52, P725, DOI 10.1109/THMS.2022.3165165
   Lin YC, 2021, 2021 60TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1405
   Liu JY, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448092
   Lu D, 2019, IEEE ICC, DOI 10.1109/icc.2019.8761508
   Macaranas A, 2015, INTERACT COMPUT, V27, P357, DOI 10.1093/iwc/iwv003
   McMahan Ryan P., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P59, DOI 10.1007/978-3-319-39907-2_6
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Min X, 2019, IEEE T VIS COMPUT GR, V25, P3083, DOI 10.1109/TVCG.2019.2932276
   Mo G. B., 2021, P 2021 CHI C HUM FAC, P1, DOI [https://doi.org/10.1145/3411764.3445766, DOI 10.1145/3411764.3445766]
   Mueller F, 2017, IEEE I CONF COMP VIS, P1163, DOI 10.1109/ICCV.2017.131
   Nielsen, 2022, ARXIV
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Plasson Carole, 2020, AVI '20: Proceedings of the International Conference on Advanced Visual Interfaces, DOI 10.1145/3399715.3399836
   Reuters, 1996, WHATS A OK
   Schafer A., 2022, MENSCH COMPUT, V2022, P85, DOI [10.1145/3543758.3543766, DOI 10.1145/3543758.3543766]
   Serrano R, 2022, MULTIMED TOOLS APPL, V81, P31657, DOI 10.1007/s11042-022-12864-6
   Shrestha D., 2018, AR OBJECT, V10, P1, DOI [10.1504/IJCAET.2018.10006394, DOI 10.1504/IJCAET.2018.10006394]
   Su K, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3196121
   Su MC, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115595
   Sun YB, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1738, DOI [10.1109/vr.2019.8798053, 10.1109/VR.2019.8798053]
   Ungureanu D., 2020, ArXiv
   Vuletic T, 2019, INT J HUM-COMPUT ST, V129, P74, DOI 10.1016/j.ijhcs.2019.03.011
   Wachs J., 2019, IEEE INT CONF AUTOMA, P1, DOI DOI 10.1109/fg.2019.8756548
   Wu JT, 2021, INT C PATT RECOG, P3435, DOI 10.1109/ICPR48806.2021.9412548
   Xiao R, 2018, IEEE T VIS COMPUT GR, V24, P1653, DOI 10.1109/TVCG.2018.2794222
   Xiao R, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P85, DOI 10.1145/2992154.2992173
   Yu J, 2017, LECT NOTES COMPUT SC, V10291, P416, DOI 10.1007/978-3-319-58697-7_31
   Zhang ZH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P825, DOI 10.1145/3394171.3413633
   Zhou Q, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376313
NR 49
TC 0
Z9 0
U1 6
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 31
PY 2023
VL 4
AR 1171230
DI 10.3389/frvir.2023.1171230
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA P1MZ0
UT WOS:001048363700001
OA gold
DA 2024-07-18
ER

PT J
AU Ng, P
   Li, YC
   Zhu, ST
   Xu, BG
   van Ameijde, J
AF Ng, Provides
   Li, Yuechun
   Zhu, Shutong
   Xu, Bingge
   van Ameijde, Jeroen
TI Digital common(s): the role of digital gamification in participatory
   design for the planning of high-density housing estates
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE digital commons; participatory design; gamification; community
   engagement; high density housing
ID URBAN DESIGN; COMMUNITY; PLACE; CAD
AB "Digital Commons" explores the intersection between participatory design, digital gamification, and community engagement, contextualised in the planning of high-density housing estates in Hong Kong. The research project investigates how digital gamified participatory design can be applied in decision-making processes for the planning of public facilities in high-density housing estates. Focusing on community engagement methods, the project has engaged with residents of a case study housing estate, Jat Min Chuen in the Shatin Wai area of Hong Kong, to facilitate collective planning discussions about the past, present, and future of community facilities. Using a digital community game approach, it has collected opinions and needs from public housing residents, promoted collaborative design thinking processes, and provided a platform for participants to increase their understanding of the complexity of planning problems through 3D visualisation tools. The experiences documented in this study demonstrate how 3D interactivity, real-time engagement, and bottom-up perspectives may enhance the potential of using immersive digital twins during collective decision-making. The gaming outcomes show a high similarity across all teams in close relationship to users' daily life routines, demonstrating a new powerful role for urban designers as a coordinator of interactive and collaborative planning processes.
C1 [Ng, Provides; Li, Yuechun; Zhu, Shutong; Xu, Bingge; van Ameijde, Jeroen] Chinese Univ Hong Kong, Sch Architecture, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Ng, P (corresponding author), Chinese Univ Hong Kong, Sch Architecture, Hong Kong, Peoples R China.
EM provides.ng@link.cuhk.edu.hk
RI van Ameijde, Jeroen/R-3247-2018; Ng, Provides/AEO-9965-2022
OI van Ameijde, Jeroen/0000-0002-3635-3305; Ng,
   Provides/0000-0001-6975-4642
FU Chinese University of Hong Kong
FX This project was supported by The Chinese University of Hong Kong's Seed
   Funding Support for Thesis Research. We are grateful for the help of all
   experiment participants, HKFYG Jat Min Youth S.P.O.T., and Community
   Development Officer Leung Ho Kai, Eric.
CR Ahlqvist C., 2018, GEOGAMES GEOPLAY GAM
   Al-Kodmany K., 1999, Digital Creativity, V10, P91, DOI 10.1076/digc.10.2.91.3248
   Al-Kodmany K, 2001, J URBAN TECHNOL, V8, P1, DOI 10.1080/106307301316904772
   Ali A.X., 2021, Interactions, V28, P82, DOI [10.1145/3447790, DOI 10.1145/3447790]
   Ali AX, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300485, 10.1109/icocn.2019.8934143]
   Ali AX, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P177, DOI 10.1145/3242587.3242621
   [Anonymous], 1993, Participatory Design: Principles and Practice
   [Anonymous], 1998, HIGH RISE SOC 1 50 Y
   [Anonymous], 2001, ARCHITECTURE PARTICI
   Armstrong H., 2011, PARTICIPATE DESIGNIN
   Bjork S., 2009, 40 ANN C INT SIM GAM
   Bodker S, 1996, HUM-COMPUT INTERACT, V11, P215, DOI 10.1207/s15327051hci1103_2
   Bornat D., 2019, NEIGHBOURHOOD DESIGN
   Brandt E., 2004, P 8 C PART DES ARTF, P121, DOI DOI 10.1145/1011870.1011885
   Centamap, 2016, POP BY CENS
   Chan V, 2023, URBAN HIST, V50, P799, DOI 10.1017/S0963926822000153
   Cleveland A., 2011, PARTICIPATORY DESIGN
   COMERIO MC, 1984, J ARCHIT PLAN RES, V1, P227
   Coombs P., 1973, NEW PATHS LEARNING R
   Corburn J, 2003, J PLAN EDUC RES, V22, P420, DOI 10.1177/0739456X03022004008
   de Lange M, 2019, RIGHT TO THE SMART CITY, P71, DOI 10.1108/978-1-78769-139-120191005
   Dickinson JK, 2005, ROBOT CIM-INT MANUF, V21, P465, DOI 10.1016/j.rcim.2004.11.007
   DiSalvo C., 2012, Routledge International Handbook of Participatory Design, V0, P202, DOI DOI 10.4324/9780203108543
   Driskell D., 2011, CREATING BETTER CITI
   Emerson College, 2010, PART CHIN
   Espinosa V., 2022, PARTICIPATORY DESIGN
   Esther HKY, 2017, LANDSCAPE URBAN PLAN, V165, P39, DOI 10.1016/j.landurbplan.2017.05.006
   Fabricatore C., 2007, Gameplay and game mechanics: a key to quality in videogames
   Fitz-Walter Z., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P138, DOI [DOI 10.1145/2414536.2414560, 10.1145/2414536.2414560]
   Fonseca D, 2016, COMPUT HUM BEHAV, V55, P504, DOI 10.1016/j.chb.2015.05.032
   Fuad-Luke A., 2009, DESIGN ACTIVISM BEAU
   Fuster Morell Mayo, 2010, Governance of online creation communities: Provision of infrastructure for the building of digital commons
   Gaver B., 1999, Interactions, V6, P21, DOI DOI 10.1145/291224.291235
   Gerber A., 2020, ARCHITECTONICS GAME, V50
   Giering S., 2011, PUBLIC PARTICIPATION
   Gill Z., 2013, The experimental nature of new venture creation, P127
   Gou ZH, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15020219
   Guy B. O. Y., 2013, EXPERTISE TECHNOLOGY, P243
   Hess J, 2012, DES ISSUES, V28, P62, DOI 10.1162/DESI_a_00162
   HKHA, 2019, PUBL HOUS DEV
   HKHA, 2011, PLANN DES DEL QUAL P
   HKHS, 2021, PRESS REL MOD BLOCK
   HKHS, 2021, VIS MISS VAL MISS ST
   HKSAR, 2021, LCQ22 MOD INT CONSTR
   HKSAR, 2018, 2018 FA HUI PARK LUN
   HKSAR, 2016, LCQ21 PROM ACT AG EL
   Hoc JH, 2001, INT J HUM-COMPUT ST, V54, P509, DOI 10.1006/ijhc.2000.0454
   Holmlid Stefan., 2012, Conference Proceedings ServDes. 2009; DeThinking Service; ReThinking Design; Oslo Norway 24-26 November 2009, P105
   Hong Kong Housing Bureau, 2021, HOUS FIG 2021
   Hou J, 2003, J ARCHIT EDUC, V57, P19, DOI 10.1162/104648803322336557
   Ismail WAW, 2015, PROCD SOC BEHV, V168, P357, DOI 10.1016/j.sbspro.2014.10.241
   Kan Angela W. S., 1978, Housing in Hong Kong: A Multidisciplinary Study Hong Kong, Asian Studies Series, P160
   Karabinus A, 2019, TECH COMMUN-STC, V66, P257
   Khaled R., 2014, IJCCI, V2, P93, DOI [DOI 10.1016/J.IJCCI.2014.03.001, 10.1016/j.ijcci.2014.03.001]
   Kirriemuir J., 2004, FUTURELAB SERIES, P1
   Kosmadoudi Z, 2013, COMPUT AIDED DESIGN, V45, P777, DOI 10.1016/j.cad.2012.08.001
   Kostakis V, 2019, Critical Digital an, P1, DOI 10.16997/book33
   KUHN S, 1993, COMMUN ACM, V36, P24
   Landers RN, 2017, COMPUT HUM BEHAV, V71, P508, DOI 10.1016/j.chb.2015.08.008
   Lau KY, 2017, HOUSING STUD, V32, P271, DOI 10.1080/02673037.2016.1194376
   Lee J., 2003, J COMP ASIAN DEV, V2, P3, DOI DOI 10.1080/15339114.2003.9678369
   Lee KY, 2021, WIREL TELECOMM SYMP, DOI 10.1109/WTS51064.2021.9433714
   Luck R, 2007, DESIGN STUD, V28, P217, DOI 10.1016/j.destud.2007.02.002
   Luck Rachael., 2003, DESIGN STUD, V24, P523, DOI DOI 10.1016/S0142-694X(03)00040-1
   Martín-Dorta N, 2008, J ENG EDUC, V97, P505, DOI 10.1002/j.2168-9830.2008.tb00996.x
   Maslow A.H., 1958, Understanding human motivation, P26, DOI [10.1037/11305-004, DOI 10.1037/11305-004]
   Mattelmaki T., 2006, DESIGN PROBES
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Morris William., 1891, News from Nowhere; or, an Epoch of Rest
   O'Coill C., 2004, COMPUTER GAME TECHNO
   Panek J, 2019, INFORMATION, V10, DOI 10.3390/info10080255
   Papadonikolaki E., 2020, Digital transformation in constructionSystematic literature review of evolving concepts
   Paulsson G., 1956, KOOPERATIVA FORBUNDE
   Paulsson G., 1919, GOTEBORG SVENSKA SLO
   Pfau N., 2021, INTER AND TRANSDISCI
   Redondo Ernest, 2020, Learning and Collaboration Technologies. Human and Technology Ecosystems. 7th International Conference, LCT 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12206), P296, DOI 10.1007/978-3-030-50506-6_22
   Reich Y., 1996, Design Studies, V17, P165, DOI 10.1016/0142-694X(95)00000-H
   Rice JW, 2012, INT J GAMING COMPUT-, V4, P81, DOI 10.4018/jgcms.2012100106
   Rocha EM, 1997, J PLAN EDUC RES, V17, P31, DOI 10.1177/0739456X9701700104
   Ruggeri D, 2020, ROUTL HANDBK, P197
   Sanchez J., 2015, BLOCKHOOD DEV ARCHIT
   Sánchez-Sepúlveda M, 2018, SIXTH INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ECOSYSTEMS FOR ENHANCING MULTICULTURALITY (TEEM'18), P729, DOI 10.1145/3284179.3286731
   Sanders EBN, 2000, COLLABORATIVE DESIGN, P3
   Sanoff H., 1988, ARCHITECTURAL BEHAV, V4, P27
   Sanoff Henry., 1990, PARTICIPATORY DESIGN
   Saunders P, 2014, SOC POLICY ADMIN, V48, P556, DOI 10.1111/spol.12042
   Schell, 2008, ART GAME DESIGN BOOK, V1st ed., P40
   Scholten H, 2017, QUAL INNOV PROSPER, V21, P119, DOI 10.12776/QIP.V21I1.784
   Schuler D., 1993, Participatory Design: Principles and Practices
   Seixas LD, 2016, COMPUT HUM BEHAV, V58, P48, DOI 10.1016/j.chb.2015.11.021
   Simonsen J, 2012, DES ISSUES, V28, P10, DOI 10.1162/DESI_a_00158
   Steino N., 2003, VISION PLAN REALITY
   Tan, 2019, ABOUT US
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Titlestad Ola Hodne, 2009, Scandinavian Journal of Information Systems, V21, P27
   Turner JohnF. C., 1972, Ekistics, V196, P152
   Urban Council, 1975, URB COUNC POL MAN
   Valls F, 2018, TELEMAT INFORM, V35, P1039, DOI 10.1016/j.tele.2017.09.015
   Vyatkin SI, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P234, DOI 10.1109/SMA.1999.749345
   Wanick V., 2017, QUE SEU TAMBEM NOSSO
   Yenardi A, 2021, Mass participatory design on the web: a voxel-based 3D modelling approach
   Zheng W, 2015, SMART SUSTAIN BUILT, V4, P172, DOI 10.1108/SASBE-09-2014-0047
NR 102
TC 2
Z9 2
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 5
PY 2023
VL 3
AR 1062336
DI 10.3389/frvir.2022.1062336
PG 23
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WQ0
UT WOS:001023288600001
OA gold
DA 2024-07-18
ER

PT J
AU Dong, Z
   Zhang, JJ
   Bai, XL
   Clark, A
   Lindeman, RW
   He, WP
   Piumsomboon, T
AF Dong, Ze
   Zhang, Jingjing
   Bai, Xiaoliang
   Clark, Adrian
   Lindeman, Robert W.
   He, Weiping
   Piumsomboon, Thammathip
TI Touch-Move-Release: Studies of Surface and Motion Gestures for Mobile
   Augmented Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; mobile device; gestures; elicitation study;
   interaction technique
AB Despite a broad range of mobile AR applications available to date, the majority still primarily use surface gestures, i.e., gesturing on the touch screen surface of the device and do not utilise the affordance of three-dimensional user interaction that AR interfaces support. In this research, we compared two methods of gesture interaction for mobile AR applications: Surface Gestures and Motion Gestures, which take advantage of the spatial information of the mobile device. We have conducted two user studies: an elicitation study (n = 21) and a validation study (n = 10). The first study elicited two sets of 504 gestures, surface and motion gestures, for 12 everyday mobile AR tasks. The two sets of gestures were classified and compared in terms of goodness, ease of use, and engagement. As expected, the participants' elicited surface gestures are familiar and easy to use, while motion gestures were found more engaging. Using design patterns derived from the elicited motion gestures, we proposed a novel interaction technique called "TMR" (Touch-Move-Release). Through validation study we found that the TMR motion gesture enhanced engagement and provided a better game experience. In contrast, the surface gesture provided higher precision resulting in higher accuracy and was easier to use. Finally, we discuss the implications of our findings and give our design recommendations for using the elicited gestures.
C1 [Dong, Ze; Zhang, Jingjing; Clark, Adrian; Piumsomboon, Thammathip] Univ Canterbury, Sch Prod Design, Christchurch, New Zealand.
   [Dong, Ze; Zhang, Jingjing; Lindeman, Robert W.] Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
   [Bai, Xiaoliang; He, Weiping] Northwestern Polytech Univ, Cyber Phys Interact Lab, Xian, Peoples R China.
C3 University of Canterbury; University of Canterbury; Northwestern
   Polytechnical University
RP Dong, Z (corresponding author), Univ Canterbury, Sch Prod Design, Christchurch, New Zealand.; Dong, Z (corresponding author), Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
EM ze.dong@pg.canterbury.ac.nz
RI Clark, Adrian/AAF-1993-2021
OI Clark, Adrian/0000-0001-6009-879X
FU National Natural Science Foundation of China (NSFC) [6185041053]
FX This work is supported by National Natural Science Foundation of China
   (NSFC), Grant No: 6185041053.
CR Apple Inc, 2020, AUGM REAL APPL DEV
   Ashbrook D, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2159
   Bai H., 2016, THESIS U CANTERBURY
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bergstrom-Lehtovirta J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1991, DOI 10.1145/2556288.2557354
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Boring S., 2009, P 21 ANN C AUSTR COM, P161
   Chen X, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P159, DOI 10.1145/2556288.2556955
   Chen Z, 2018, INT J HUM-COMPUT INT, V34, P238, DOI 10.1080/10447318.2017.1342943
   Cockburn A, 2013, P SIGCHI C HUM FACT, P955, DOI [10.1145/2468356.2468527, DOI 10.1145/2468356.2468527, DOI 10.1145/2468356]
   Colley A, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P442, DOI 10.1145/2935334.2935384
   COOKE NJ, 1994, INT J HUM-COMPUT ST, V41, P801, DOI 10.1006/ijhc.1994.1083
   Cui Jian., 2016, Proceedings of the 29th International Conference on Computer Animation and Social Agents (CASA'16), P139, DOI [DOI 10.1145/2915926.2919330, 10.1145/2915926, DOI 10.1145/2915926]
   Di Geronimo L, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098530
   Dong Z., 2020, S SPAT US INT, P1, DOI [10.1145/3385959.3422694, DOI 10.1145/3385959.3422694]
   Dong Z, 2020, PROC INT CONF SOFTW, P481, DOI 10.1145/3377811.3380402
   Ens B, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188513
   Ens B, 2017, SIGGRAPH ASIA 2017 POSTERS (SA'17), DOI 10.1145/3145690.3145740
   Epps J., 2006, CHI 06 EXTENDED ABST, P748, DOI DOI 10.1145/1125451.1125601
   FORMAN GH, 1994, COMPUTER, V27, P38, DOI 10.1109/2.274999
   Goel M, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P545
   Goh ES, 2019, IEEE ACCESS, V7, P40581, DOI 10.1109/ACCESS.2019.2906394
   Goldsmith D, 2008, IEEE INT CONF INF VI, P539, DOI 10.1109/IV.2008.72
   Google Inc, 2020, ARC OV GOOG DEV
   Hartmann B, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P145
   Havlucu H, 2017, LECT NOTES COMPUT SC, V10291, P159, DOI 10.1007/978-3-319-58697-7_11
   Henrysson A, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P80
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hinckley K., 2000, UIST. Proceedings of the 13th Annual ACM Symposium on User Interface Software and Technology, P91, DOI 10.1145/354401.354417
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   IJsselsteijn WijnandA., 2013, GAME EXPERIENCE QUES, V46
   inter IKEA Systems B.V, 2020, IK APPS IK
   Jones E, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2173
   Kim M, 2016, MULTIMED TOOLS APPL, V75, P16529, DOI 10.1007/s11042-016-3355-9
   Kurkovsky S., 2012, 2012 International Conference on Communications and Information Technology (ICCIT), P68, DOI 10.1109/ICCITechnol.2012.6285844
   Kyriazakos V, 2016, LECT NOTES COMPUT SC, V9769, P348, DOI 10.1007/978-3-319-40651-0_28
   Lee G.A., 2009, P 16 ACM S VIRTUAL R, P143
   Marzo A., 2014, Proc. 2nd ACM Symp. Spat. user Interact. - SUI '14, P13, DOI [10.1145/2659766.2659775, DOI 10.1145/2659766.2659775]
   May KR, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P74, DOI 10.1145/3122986.3123015
   Morreau M, 2010, CURR RES SEMANT PRAG, V21, P261
   Mossel A., 2013, Proc. Virtual Real. Int. Conf. Laval Virtual - VRIC '13, P1, DOI [10.1145/2466816.2466829, DOI 10.1145/2466816.2466829]
   Niantic Inc., 2020, POK
   Pham T, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P227, DOI 10.1145/3196709.3196719
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   Piumsomboon T, 2013, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2013.6671809
   PTC Inc., 2020, VUF ENG
   Pucihar KC, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P197, DOI 10.1145/2556288.2557125
   QuiverVision, 2020, QUIV 3D AUGM REA COL
   Rico J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P887
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Schiller J., 2004, Location-Based Services
   Sketchar.tech, 2020, START DRAW EAS US AU
   Stanimirovic D, 2014, INT SYM MIX AUGMENT, P373
   Taejin Ha, 2011, 2011 International Symposium on Ubiquitous Virtual Reality, P44, DOI 10.1109/ISUVR.2011.14
   Tanikawa T, 2015, 12TH ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY CONFERENCE (ACE15), DOI 10.1145/2832932.2832956
   Unity Technologies, 2020, UN ENG
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Vatavu RD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1325, DOI 10.1145/2702123.2702223
   Vatavu Radu-Daniel, 2012, P 10 EUR C INT TV VI, P45, DOI [10.1145/2325616.2325626, DOI 10.1145/2325616.2325626]
   Voida Stephen, 2005, P SIGCHI C HUM FACT, P611, DOI [10.1145/1054972.1055056, DOI 10.1145/1054972.1055056]
   Walter R, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P299, DOI 10.1145/2628363.2628368
   Wigdor Daniel., 2003, UIST '03: Proceedings of the 16th annual ACM symposium on User interface software and technology, P81, DOI DOI 10.1145/964696.964705
   Wilson AD, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P67, DOI 10.1145/1449715.1449728
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Wu M, 2006, FIRST IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, P183
NR 66
TC 2
Z9 2
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 17
PY 2022
VL 3
AR 927258
DI 10.3389/frvir.2022.927258
PG 21
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OP2
UT WOS:001021706700001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Batistatou, A
   Vandeville, F
   Delevoye-Turrell, YN
AF Batistatou, Adamantia
   Vandeville, Florentin
   Delevoye-Turrell, Yvonne N. N.
TI Virtual Reality to Evaluate the Impact of Colorful Interventions and
   Nature Elements on Spontaneous Walking, Gaze, and Emotion
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual environment; gait; affective responses; restorative theory;
   vegetation; eye tracking; systematic representative design
ID SPONTANEOUS MOTOR TEMPO; ENVIRONMENTAL PREFERENCE; AFFECTIVE RESPONSES;
   STRESS; RESTORATION; PEDESTRIANS; PERCEPTION; MOVEMENTS; ATTENTION;
   CHILDREN
AB Green environments are said to have a positive impact on spontaneous physical activity and well-being. However, high quality psychological measures in natural settings are difficult to collect. In the present study, we offer a detailed report on how virtual reality may provide a controlled environment for immersive user testing. Virtual Reality (VR) was here used to test the impact of colorful floor markings on the spontaneous speed of walking, gaze behaviour, as well as perceived changes in and physiological mesures of affective states. The reactions of 36 adult participants were evaluated in Grey and Green VR environments of an urban university campus. Results in VR revealed similar results than that reported in natural settings: participants walked slower and had higher heart rates in Green than in Grey urban settings, indicating more pleasurable experiences. VR results provided nevertheless more detailed description of user experience with the possibility to quantify changes in gaze strategy as a function of the presence or absence of color designs. Spontaneous walking was slower with colorful designs than without. Gaze behaviour presented longer fixation times with colorful designs than without. Finally, physiological responses indicated that mean heart rates were similar across environments and predicted the physical effort of the task. However, greater means in heart rates were observed in the environments presenting colorful designs, suggesting that colors may be a powerful tool to trigger alertness and pleasure in Grey urban cities. Virtual reality is reported here as an innovative method to quantify psychological experiences during free exploration in gait. Applicable to a broad range of research topics in the psychological sciences, explicit guidelines are made available to share computer code and data sets for further exploitation.
C1 [Batistatou, Adamantia; Vandeville, Florentin; Delevoye-Turrell, Yvonne N. N.] Univ Lille, UMR 9193 SCALab Sci Cognit & Sci Affect, Lille, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Humanities & Social Sciences (INSHS); Universite de Lille
RP Delevoye-Turrell, YN (corresponding author), Univ Lille, UMR 9193 SCALab Sci Cognit & Sci Affect, Lille, France.
EM yvonne.delevoye@univ-lille.fr
CR Al-Shargie F, 2016, BIOMED OPT EXPRESS, V7, P3882, DOI 10.1364/BOE.7.003882
   An M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155614
   [Anonymous], 2013, Proceedings of Motion on Games, DOI DOI 10.1145/2522628.2522655
   Barbato G, 2007, PHYSIOL BEHAV, V90, P151, DOI 10.1016/j.physbeh.2006.09.023
   Barrett LF, 2009, ADV EXP SOC PSYCHOL, V41, P167, DOI 10.1016/S0065-2601(08)00404-8
   Batson C.D., 1992, Differentiating affect, mood, and emotion: Toward functionally based conceptual distinctions
   Berto R, 2008, J ENVIRON PSYCHOL, V28, P185, DOI 10.1016/j.jenvp.2007.11.004
   Berto R, 2014, BEHAV SCI-BASEL, V4, P394, DOI 10.3390/bs4040394
   Biassoni F, 2018, TRANSPORT RES F-TRAF, V56, P227, DOI 10.1016/j.trf.2018.04.009
   Birenboim A, 2019, LANDSCAPE URBAN PLAN, V189, P129, DOI 10.1016/j.landurbplan.2019.04.011
   Bluhm GL, 2007, OCCUP ENVIRON MED, V64, P122, DOI 10.1136/oem.2005.025866
   Bolten B., 2020, VISIONS SUSTAINAB, V2020, P11, DOI DOI 10.13135/2384-8677/3829
   BORNSTEIN MH, 1976, NATURE, V259, P557, DOI 10.1038/259557a0
   Brossard V., 2022, MEASURING EMBODIED N
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Calogiuri G, 2021, NATURE AND HEALTH, P127
   Chevalier N, 2010, DEV PSYCHOL, V46, P955, DOI 10.1037/a0019674
   Colombo J, 2001, ANNU REV PSYCHOL, V52, P337, DOI 10.1146/annurev.psych.52.1.337
   Davydenko M, 2017, J ENVIRON PSYCHOL, V54, P20, DOI 10.1016/j.jenvp.2017.09.003
   De Coensel B, 2011, J ACOUST SOC AM, V129, pEL148, DOI 10.1121/1.3567073
   Dedovic K, 2005, J PSYCHIATR NEUROSCI, V30, P319
   Delevoye-Turrell Y, 2014, PROCD SOC BEHV, V126, P121, DOI 10.1016/j.sbspro.2014.02.338
   Egorov AI, 2017, ENVIRON RES, V158, P508, DOI 10.1016/j.envres.2017.07.009
   Elsadek M, 2019, URBAN FOR URBAN GREE, V46, DOI 10.1016/j.ufug.2019.126446
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   Engelniederhammer A, 2019, J HUM BEHAV SOC ENVI, V29, P630, DOI 10.1080/10911359.2019.1579149
   Evans D., 2019, COLOUR WALKS UNCOVER
   FLEMING I, 1987, J PERS SOC PSYCHOL, V52, P899, DOI 10.1037/0022-3514.52.5.899
   Focht BC, 2009, RES Q EXERCISE SPORT, V80, P611
   Fotios S, 2015, LIGHTING RES TECHNOL, V47, P133, DOI 10.1177/1477153514522472
   Fraisse P., 1982, Psychology of Music, P149, DOI [10.1016/B978-0-12-213562-0.50010-3, DOI 10.1016/B978-0-12-213562-0.50010-3]
   Franek M, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15040752
   Franek M, 2013, PERCEPT MOTOR SKILL, V116, P992, DOI 10.2466/06.50.PMS.116.3.992-1019
   FUKUDA K, 1994, PERCEPT MOTOR SKILL, V79, P1599, DOI 10.2466/pms.1994.79.3f.1599
   Gillis K, 2015, BUILDINGS, V5, P948, DOI 10.3390/buildings5030948
   Handy SL, 2002, AM J PREV MED, V23, P64, DOI 10.1016/S0749-3797(02)00475-0
   Hartig T, 2006, J ENVIRON PSYCHOL, V26, P215, DOI 10.1016/j.jenvp.2006.07.007
   Himebaugh NL, 2009, OPTOMETRY VISION SCI, V86, P106, DOI 10.1097/OPX.0b013e318194e962
   Huang QY, 2020, LANDSCAPE URBAN PLAN, V193, DOI 10.1016/j.landurbplan.2019.103654
   Jalil NA, 2012, PROCD SOC BEHV, V35, P54, DOI 10.1016/j.sbspro.2012.02.062
   Kalantari S, 2021, HOUSING STUD, V36, P1147, DOI 10.1080/02673037.2020.1752630
   Kaplan R, 2001, ENVIRON BEHAV, V33, P507, DOI 10.1177/00139160121973115
   Kaplan S, 1992, The Restorative Environment: Nature and Human Experience
   Kaya N., 2004, COLL STUD J, V38, P396
   Knöll M, 2018, ENVIRON PLAN B-URBAN, V45, P797, DOI 10.1177/0265813516686971
   Kondo MC, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15030445
   Krassanakis V, 2014, J EYE MOVEMENT RES, V7
   Kutchma T., 2014, J UNDERGRAD RES A T, V3
   Ledger H., 2013, EFFECT COGNITIVE LOA, P19
   Lee T.-R., EXPLORING COLOR PREF, P4
   Lévêque L, 2020, IEEE ACCESS, V8, P164833, DOI 10.1109/ACCESS.2020.3021208
   Lin YH, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00906
   MacKay DG, 2005, PSYCHOL SCI, V16, P25, DOI 10.1111/j.0956-7976.2005.00776.x
   Martínez-Soto J, 2019, IBRO REP, V7, P52, DOI 10.1016/j.ibror.2019.07.1722
   Matthis JS, 2018, CURR BIOL, V28, P1224, DOI 10.1016/j.cub.2018.03.008
   McCullough M, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P107, DOI 10.1145/2804408.2804416
   Meier BP, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040333
   Mentzel SV, 2019, COLOR RES APPL, V44, P957, DOI 10.1002/col.22429
   Miller LC, 2019, PSYCHOL INQ, V30, P173, DOI [10.1080/1047840X.2019.1693866, 10.1080/1047840x.2019.1693866]
   Münzel T, 2018, J AM COLL CARDIOL, V71, P688, DOI 10.1016/j.jacc.2017.12.015
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   ORCHARD L N, 1991, Integrative Physiological and Behavioral Science, V26, P108, DOI 10.1007/BF02691032
   Özgüner H, 2006, LANDSCAPE URBAN PLAN, V74, P139, DOI 10.1016/j.landurbplan.2004.10.003
   Pai YS, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P189, DOI 10.1145/3152832.3152864
   Pedersen E, 2018, LIGHTING RES TECHNOL, V50, P522, DOI 10.1177/1477153516684544
   Richardson DC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68253-2
   Rose D, 2020, J MOV DISORD, V13, P47
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   Savavibool Nattha., 2018, ASIAN J BEHAV STUDIE, V3. 149, DOI DOI 10.21834/AJBES.V3I13.152
   Schiffman H. Richard, 1990, Sensation and Perception: An Integrated Approach
   Thompson CW, 2012, LANDSCAPE URBAN PLAN, V105, P221, DOI 10.1016/j.landurbplan.2011.12.015
   Trefzger M, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3214307
   Turano KA, 2001, OPTOMETRY VISION SCI, V78, P667, DOI 10.1097/00006324-200109000-00012
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   Valtchanov D, 2015, J ENVIRON PSYCHOL, V43, P184, DOI 10.1016/j.jenvp.2015.07.001
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   Van Cauwenberg J, 2016, INT J BEHAV NUTR PHY, V13, DOI 10.1186/s12966-016-0331-8
   van den Berg AE, 2003, J ENVIRON PSYCHOL, V23, P135, DOI 10.1016/S0272-4944(02)00111-1
   Van Gent P., 2018, P 6 HUMANIST C HAG N, P173
   van Gent P, 2019, TRANSPORT RES F-TRAF, V66, P368, DOI 10.1016/j.trf.2019.09.015
   VOLKMANN FC, 1982, VISION RES, V22, P991, DOI 10.1016/0042-6989(82)90035-9
   von Stülpnagel R, 2020, TRANSPORT RES F-TRAF, V75, P222, DOI 10.1016/j.trf.2020.10.007
   Wang CA, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.01029
   White EV, 2011, J ENVIRON PSYCHOL, V31, P89, DOI 10.1016/j.jenvp.2010.11.002
   Wilkie S, 2013, URBAN FOR URBAN GREE, V12, P163, DOI 10.1016/j.ufug.2013.01.004
   Wilson P. T., 2013, P 15 ACM SIGGRAPH C, P243
NR 87
TC 5
Z9 5
U1 3
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 17
PY 2022
VL 3
AR 819597
DI 10.3389/frvir.2022.819597
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZM1
UT WOS:001019264700001
OA gold
DA 2024-07-18
ER

PT J
AU Berger, CC
   Lin, BH
   Lenggenhager, B
   Lanier, J
   Gonzalez-Franco, M
AF Berger, Christopher C.
   Lin, Baihan
   Lenggenhager, Bigna
   Lanier, Jaron
   Gonzalez-Franco, Mar
TI Follow Your Nose: Extended Arm Reach After Pinocchio Illusion in Virtual
   Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE body awareness; multisensory illusion; touch; body schema; reach;
   embodiment; avatars
ID PERI-HAND SPACE; TOOL-USE; ILLUSORY OWNERSHIP; SPATIAL EXTENSION; BODY
   OWNERSHIP; TOUCH; STIMULATION
AB In this study, we recreate the Pinocchio Illusion-a bodily illusion whereby the perceived length of one's nose is extended-in Virtual Reality. Participants (n = 38) self-administered tapping on the tip of the nose of a virtual avatar seen from the first-person perspective (using a hand-held controller) while the nose of the avatar slowly grew with each tap. The stimulating virtual arm and the virtual nose were linked such that while the nose grew the arm extended, and then also grew up to 50%. This produced an extension of the perceived reach of the stimulating arm, and an outward drift in the participants' real arm. A positive correlation between the extent of the outward drift of the participants' arm and the perceived reachability of distal objects was observed. These results were found both with synchronous tactile stimulation on the participants' real nose, and without, but not for control conditions in which the visuomotor synchrony or body schema were violated. These findings open new avenues for hand grasp interactions with virtual objects out of arm's-reach in immersive setups and are discussed in the context of theories of body ownership, body schema, and touch perception.
C1 [Berger, Christopher C.; Lanier, Jaron; Gonzalez-Franco, Mar] Microsoft Res, Redmond, WA 98052 USA.
   [Berger, Christopher C.] CALTECH, Div Biol & Biol Engn, Pasadena, CA USA.
   [Lin, Baihan] Columbia Univ, Mortimer B Zuckerman Mind Brain Behav Inst, Ctr Theoret Neurosci, New York, NY USA.
   [Lenggenhager, Bigna] Univ Zurich, Dept Psychol Cognit Neuropsychol, Zurich, Switzerland.
   [Lenggenhager, Bigna] Univ Konstanz, Dept Psychol, Constance, Germany.
C3 Microsoft; California Institute of Technology; Columbia University;
   University of Zurich; University of Konstanz
RP Gonzalez-Franco, M (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
EM margon@microsoft.com
RI Gonzalez-Franco, Mar/L-4994-2014; Lenggenhager, Bigna/IUO-7775-2023;
   Lin, Baihan/GXF-5198-2022
OI Lenggenhager, Bigna/0000-0003-0418-9931; Lin, Baihan/0000-0002-7979-5509
CR Abdulkarim Z, 2018, EXP BRAIN RES, V236, P551, DOI 10.1007/s00221-017-5137-7
   Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237
   Bonifazi S, 2007, J NEUROPSYCHOL, V1, P101, DOI 10.1348/174866407X180846
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Burrack Anna, 2005, Body Image, V2, P307, DOI 10.1016/j.bodyim.2005.04.002
   Calzolari E, 2017, P NATL ACAD SCI USA, V114, P4555, DOI 10.1073/pnas.1614979114
   Coello Y, 2012, COGN PROCESS, V13, pS131, DOI 10.1007/s10339-012-0470-z
   Cohn BA, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P74, DOI 10.1109/AIVR50618.2020.00024
   Conson M, 2011, EXP BRAIN RES, V215, P115, DOI 10.1007/s00221-011-2877-7
   diPellegrino G, 1997, NATURE, V388, P730, DOI 10.1038/41921
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Farnè A, 2005, NEUROLOGY, V65, P1754, DOI 10.1212/01.wnl.0000187121.30480.09
   Farnè A, 2005, COGN NEUROPSYCHOL, V22, P408, DOI 10.1080/02643290442000112
   Folegatti A, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006920
   Gentile G, 2013, J NEUROSCI, V33, P13350, DOI 10.1523/JNEUROSCI.1363-13.2013
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Guterstam A, 2018, J EXP PSYCHOL GEN, V147, P298, DOI 10.1037/xge0000390
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   LACKNER JR, 1988, BRAIN, V111, P281, DOI 10.1093/brain/111.2.281
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lin B., 2020, P 20 9 INT JOINT C A, P10313, DOI [10.24963/ijcai.2020/766, DOI 10.24963/IJCAI.2020/766]
   Linkenauger SA, 2015, NEUROPSYCHOLOGIA, V70, P393, DOI 10.1016/j.neuropsychologia.2014.10.034
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   Maravita A, 2003, CURR BIOL, V13, pR531, DOI 10.1016/S0960-9822(03)00449-4
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Medina J, 2010, NEUROPSYCHOLOGIA, V48, P645, DOI 10.1016/j.neuropsychologia.2009.08.017
   Miller LE, 2018, NATURE, V561, P239, DOI 10.1038/s41586-018-0460-0
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2011, CURR BIOL, V21, P1118, DOI 10.1016/j.cub.2011.05.022
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Proffitt DR, 2013, ACTION SCIENCE: FOUNDATIONS OF AN EMERGING DISCIPLINE, P171
   Ramachandran VS, 1998, BRAIN, V121, P1603, DOI 10.1093/brain/121.9.1603
   Schütz-Bosbach S, 2009, CONSCIOUS COGN, V18, P2, DOI 10.1016/j.concog.2008.08.003
   Serino A, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00004
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Tajadura-Jiménez A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00689
   Vaesen K, 2012, BEHAV BRAIN SCI, V35, P203, DOI 10.1017/S0140525X11001452
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
NR 51
TC 2
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 24
PY 2022
VL 3
AR 712375
DI 10.3389/frvir.2022.712375
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VN4
UT WOS:001019160700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Zhang, JJ
   Dong, Z
   Bai, XL
   Lindeman, RW
   He, WP
   Piumsomboon, T
AF Zhang, Jingjing
   Dong, Ze
   Bai, Xiaoliang
   Lindeman, Robert W.
   He, Weiping
   Piumsomboon, Thammathip
TI Augmented Perception Through Spatial Scale Manipulation in Virtual
   Reality for Enhanced Empathy in Design-Related Tasks
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE enhanced empathy; risk assessment; interior design; industrial design;
   virtual reality; multi-scale virtual environment
ID INTERPUPILLARY DISTANCE; EXPERIENCE; HAZARDS; IMPACT; SAFETY; SIZE; SELF
AB This research explores augmented perception by investigating the effects of spatial scale manipulation in Virtual Reality (VR) to simulate multiple levels of virtual eye height (EH) and virtual interpupillary distance (IPD) of the VR users in the design context. We have developed a multiscale VR system for design applications, which supports a dynamic scaling of the VR user's EH and IPD to simulate different perspectives of multiple user's groups such as children or persons with disabilities. We strongly believe that VR can improve the empathy of VR users toward the individual sharing or simulating the experience. We conducted a user study comprising two within-subjects designed experiments for design-related tasks with seventeen participants who took on a designer's role. In the first experiment, the participants performed hazards identification and risks assessment tasks in a virtual environment (VE) while experiencing four different end-user perspectives: a two-year-old child, an eight-year-old child, an adult, and an adult in a wheelchair. We hypothesized that experiencing different perspectives would lead to different design outcomes and found significant differences in the perceived level of risks, the number of identified hazards, and the average height of hazards found. The second experiment had the participants scale six virtual chairs to a suitable scale for different target end-user groups. The participants experienced three perspectives: a two-year-old child, an eight-year-old child, and an adult. We found that when the designer's perspective matched that of the intended end-user of the product, it yielded significantly lower variance among the designs across participants and more precise scales suitable for the end-user. We also found that the EH and IPD positively correlate with the resulting scales. The key contribution of this work is the evidence to support that spatial scale manipulation of EH and IPD could be a critical tool in the design process to improve the designer's empathy by allowing them to experience the end-user perspectives. This could influence their design, making a safer or functionally suitable design for various end-user groups with different needs.
C1 [Zhang, Jingjing; Dong, Ze; Lindeman, Robert W.] Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
   [Zhang, Jingjing; Dong, Ze; Piumsomboon, Thammathip] Univ Canterbury, Sch Prod Design, Christchurch, New Zealand.
   [Bai, Xiaoliang; He, Weiping] Northwestern Polytech Univ, Cyber Phys Interact Lab, Xian, Peoples R China.
C3 University of Canterbury; University of Canterbury; Northwestern
   Polytechnical University
RP Zhang, JJ (corresponding author), Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.; Zhang, JJ (corresponding author), Univ Canterbury, Sch Prod Design, Christchurch, New Zealand.
EM jingjing.zhang@pg.canterbury.ac.nz
FU National Natural Science Foundation of China (NSFC) [61850410532]
FX This work is supported by National Natural Science Foundation of China
   (NSFC), Grant No: 61850410532.
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Best S., 1996, Proceedings of the IEEE 1996 National Aerospace and Electronics Conference NAECON 1996 (Cat. No.96CH35934), P429, DOI 10.1109/NAECON.1996.517685
   Cognifit Ltd, 2020, SPAT PERC COGN AB
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Dixon MW, 2000, J EXP PSYCHOL HUMAN, V26, P582, DOI 10.1037/0096-1523.26.2.582
   Dodgson NA, 2004, PROC SPIE, V5291, P36, DOI 10.1117/12.529999
   Donnon T, 2005, CAN J SURG, V48, P387
   Filipovic T, 2003, COLLEGIUM ANTROPOL, V27, P723
   Fleury C., 2010, ICAT 2010 20 INT C A
   Hadikusumo BHW, 2002, AUTOMAT CONSTR, V11, P501, DOI 10.1016/S0926-5805(01)00061-9
   HENRY D, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P33, DOI 10.1109/VRAIS.1993.380801
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Jingjing Zhang, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382876
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Jun E, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2811266
   Jurng Y., 2010, P 41 ANN C ENV DES R, P68
   Kalyanaraman S, 2010, J NERV MENT DIS, V198, P437, DOI 10.1097/NMD.0b013e3181e07d66
   Keall MD, 2008, ACCIDENT ANAL PREV, V40, P887, DOI 10.1016/j.aap.2007.10.003
   Kim J., 2017, P 27 INT C ARTIFICIA, P153, DOI DOI 10.5555/3298830.32988592
   Kopper R, 2006, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2006.47
   Kuczmarski R.J., 2000, CDC growth charts: United States, P314
   Le Chenechal Morgan, 2016, 2016 IEEE Third VR International Workshop on Collaborative Virtual Environments (3DCVE), P18, DOI 10.1109/3DCVE.2016.7563562
   Leyrer M., 2011, P ACM SIGGRAPH S APP, DOI 10.1145/2077451.2077464
   Linkenauger SA, 2015, NEUROPSYCHOLOGIA, V70, P393, DOI 10.1016/j.neuropsychologia.2014.10.034
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   MacLachlan C, 2002, OPHTHAL PHYSL OPT, V22, P175, DOI 10.1046/j.1475-1313.2002.00023.x
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Milk Chris., 2015, Ted Talk
   Nikolic D., 2019, ADV ICT DESIGN CONST
   Nishida J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300926
   Osberg K.M., 1997, Spatial Cognition in the Virtual Environment
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Perlman A, 2014, SAFETY SCI, V64, P22, DOI 10.1016/j.ssci.2013.11.019
   Pinet C., 1997, DESIGN EVALUATION BA, P111
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Pivik J., 2002, Journal of Educational Computing Research, V26, P203, DOI 10.2190/WACX-1VR9-HCMJ-RTKB
   PRYOR HB, 1969, PEDIATRICS, V44, P973
   Sacks R, 2015, CONSTR MANAG ECON, V33, P55, DOI 10.1080/01446193.2015.1029504
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Simmons A., 2003, Philosophical Topics, V31, P395
   So RHY, 2001, PRESENCE-TELEOP VIRT, V10, P193, DOI 10.1162/105474601750216803
   Stefanucci JK, 2015, J EXP PSYCHOL-APPL, V21, P215, DOI 10.1037/xap0000051
   Stevens M, 2001, J AM GERIATR SOC, V49, P1442, DOI 10.1046/j.1532-5415.2001.4911235.x
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Willemsen P, 2008, PRESENCE-TELEOP VIRT, V17, P91, DOI 10.1162/pres.17.1.91
   Yee N., 2006, P PRESENCE 2006 9 AN
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zhang J., 2020, S SPAT US INT SUI 20, P1, DOI [10.1145/3385959.3422697, DOI 10.1145/3385959.3422697]
   Zhang J., 2020, SPATIAL SCALE PERCEP
   Zhang XL, 2005, PRESENCE-TELEOP VIRT, V14, P31, DOI 10.1162/1054746053890288
NR 53
TC 3
Z9 3
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2022
VL 3
AR 672537
DI 10.3389/frvir.2022.672537
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TR9
UT WOS:001021840200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Arnaud, A
   Gouiffès, M
   Ammi, M
AF Arnaud, Adrien
   Gouiffes, Michele
   Ammi, Mehdi
TI Towards Real-Time 3D Editable Model Generation for Existing Indoor
   Building Environments on a Tablet
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE computer vision; mobile device; planes and surfaces; BIM-building
   information modelling; renovation activities
AB This paper describes a mobile application that builds and updates a 3D model of an indoor environment, including walls, floor and openings, by a simple scan performed using a tablet equipped with a depth sensor. This algorithm is fully implemented on the device, does not require internet connection and runs in real-time, i.e., at five frames per second. This is made possible by taking advantage of recent AR frameworks, by assuming that the structure of the room is aligned on an Euclidean grid and by simply starting the scan in front of a wall. The wall detection is achieved in two steps. First, each incoming point cloud is segmented into planar wall candidates. Then, these planes are matched to the previously detected planes and labeled as ground, ceiling, wall, openings or noise depending on their geometric characteristics. Our evaluations show that the algorithm is able to measure a plane-to-plane distance with a mean error under 2 cm, leading to an accurate estimation of a room dimensions. By avoiding the generation of an intermediate 3D model, as a mesh, our algorithm allows a significant performance gain. The 3D model can be exported to a CAD software, in order to plan renovation works or to estimate energetic performances of the rooms. In the user experiments, a good usability score of 75 is obtained.
C1 [Arnaud, Adrien; Gouiffes, Michele] Univ Paris Saclay, LISN, CNRS, St Aubin, France.
   [Ammi, Mehdi] Univ Paris 08, LIASD, St Aubin, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Cite; Universite Paris Saclay; Universite Paris-VIII
RP Gouiffès, M (corresponding author), Univ Paris Saclay, LISN, CNRS, St Aubin, France.
FU Renovation Plaisir Energie (RPE)
FX This work was funded by Renovation Plaisir Energie (RPE).
CR Adan A., 2011, 2011 INT C 3D IM MOD, P275, DOI [DOI 10.1109/3DIMPVT.2011.42, 10.1109/3DIMPVT.2011.42]
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI [DOI 10.1109/CVPR.2006.12, 10.1109/CVPR.2006.12]
   Arnaud A, 2018, IEEE ACCESS, V6, P17643, DOI 10.1109/ACCESS.2018.2817838
   Arnaud A, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P187, DOI 10.1145/2993369.2993403
   Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Borrmann D, 2011, 3D RES, V2, DOI 10.1007/3DRes.02(2011)3
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Coughlan J. M., 1999, P IEEE INT C COMPUTE, DOI DOI 10.1109/ICCV.1999.790349
   Deng Z, 2017, COMPUT VIS IMAGE UND, V154, P127, DOI 10.1016/j.cviu.2016.07.005
   Erdogan C., 2012, 2012 Canadian Conference on Computer and Robot Vision, P32, DOI 10.1109/CRV.2012.12
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fulkerson B, 2009, IEEE I CONF COMP VIS, P670
   Grilli E, 2017, INT ARCH PHOTOGRAMM, V42-2, P339, DOI 10.5194/isprs-archives-XLII-2-W3-339-2017
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Holz Dirk, 2012, RoboCup 2011: Robot Soccer World Cup XV: LNCS 7416, P306, DOI 10.1007/978-3-642-32060-6_26
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jung J, 2014, AUTOMAT CONSTR, V42, P68, DOI 10.1016/j.autcon.2014.02.021
   Jung Y, 2011, AUTOMAT CONSTR, V20, P126, DOI 10.1016/j.autcon.2010.09.010
   Kang ZZ, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9050330
   Klingensmith M, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298
   Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872
   Li MY, 2012, IEEE INT CONF ROBOT, P828, DOI 10.1109/ICRA.2012.6225229
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Macher H, 2015, ISPRS ANN PHOTO REM, P191, DOI 10.5194/isprsannals-II-5-W3-191-2015
   Moreira A, 2007, GRAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL GM/R, P61
   Ochmann S, 2016, COMPUT GRAPH-UK, V54, P94, DOI 10.1016/j.cag.2015.07.008
   Papon J, 2013, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2013.264
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86
   Taneja, 2020, TOP 10 SMARTPHONES D
   Tarsha-Kurdi F., 2007, INT ARCH PHOTOGRAMME, V36, P407
   Tataraidze A., 2017, IEEE SOUTHEASTCON, P1
   Zhang DJ, 2020, INTEGR COMPUT-AID E, V27, P57, DOI 10.3233/ICA-190608
   Zhang J, 2013, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2013.161
NR 41
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 15
PY 2022
VL 3
AR 782564
DI 10.3389/frvir.2022.782564
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TZ7
UT WOS:001021848000001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Dietz, O
   Grubert, J
AF Dietz, Oliver
   Grubert, Jens
TI Towards Open-Source Web-Based 3D Reconstruction for Non-Professionals
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE 3D reconstruction; structure-from-motion; usability; cloud computing;
   user interface; multi-view stereo; extended reality
ID STRUCTURE-FROM-MOTION
AB Structure-from-motion and multi-view stereo can be used to create 3D models from image sequences, but are not widely adopted by consumers. We study how to address two challenges of such systems for non-professional users: 1) their technical complexity, and, 2) the computational demand needed for processing. To this end, we embed an open-source pipeline in a scalable cloud environment and create a user interface aimed at non-professional users of photogrammetry systems. Finally, we evaluate both the cloud-based infrastructure and the user interface and demonstrate its usability.
C1 [Dietz, Oliver; Grubert, Jens] Coburg Univ Appl Sci & Arts, Dept Elect Engn & Comp Sci, Coburg, Germany.
C3 Klinikum Coburg
RP Grubert, J (corresponding author), Coburg Univ Appl Sci & Arts, Dept Elect Engn & Comp Sci, Coburg, Germany.
EM jens.grubert@hs-coburg.de
RI Grubert, Jens/B-1012-2018
CR Abdul A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174156
   Amazon, 2021, AWS DOC
   Andersen D, 2019, IEEE T VIS COMPUT GR, V25, P3073, DOI 10.1109/TVCG.2019.2932172
   Bouck-Standen D., 2018, INT J ADV INTELL SYS, V11, P94
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Fahim G, 2021, COMPUT GRAPH-UK, V94, P164, DOI 10.1016/j.cag.2020.12.004
   Fleck P., 2016, PROCEEDING 2016 IEEE, P1, DOI DOI 10.1109/SEARIS.2016.7551588
   Gomes L, 2014, PATTERN RECOGN LETT, V50, P3, DOI 10.1016/j.patrec.2014.03.023
   Grossman T, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P649
   Heller J, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P30, DOI 10.1109/MVA.2015.7153126
   Hoppe C, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.70
   Iglhaut J, 2019, CURR FOR REP, V5, P155, DOI 10.1007/s40725-019-00094-3
   Isabelle J., 2020, INT C HUM INT EM TEC, P189, DOI [10.1007/978-3-030-55307-4_29, DOI 10.1007/978-3-030-55307-4_29]
   Jiang S, 2020, ISPRS J PHOTOGRAMM, V167, P230, DOI 10.1016/j.isprsjprs.2020.04.016
   Julin A, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8050221
   Laksono D., 2016, THESIS, DOI [10.13140/RG.2.2.34441.29289, DOI 10.13140/RG.2.2.34441.29289]
   Langguth F., 2013, EUROGRAPHICS SHORT P, DOI [10.2312/conf/EG2013/short/093-096, DOI 10.2312/CONF/EG2013/SHORT/093-096]
   Lochy A, 2016, P NATL ACAD SCI USA, V113, P8544, DOI 10.1073/pnas.1520366113
   Muratov O, 2016, IEEE COMPUT SOC CONF, P893, DOI 10.1109/CVPRW.2016.116
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ondrúska P, 2015, IEEE T VIS COMPUT GR, V21, P1251, DOI 10.1109/TVCG.2015.2459902
   Poiesi F, 2017, 14TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION (CVMP), DOI 10.1145/3150165.3150166
   Rieman John, 1995, P C COMP HUM FACT CO, P387, DOI [10.1145/223355.223735, DOI 10.1145/223355.223735]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sheng BY, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/4673849
   Stathopoulou E., 2019, Int. Arch. Photogramm., Remote Sens. Spatial Inf. Sci., VXLII- 2/W17, P331
   Vergauwen M, 2006, MACH VISION APPL, V17, P411, DOI 10.1007/s00138-006-0027-1
   Watson J, 2021, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR46437.2021.00122
   Zhao CQ, 2020, SCI CHINA TECHNOL SC, V63, P1612, DOI 10.1007/s11431-020-1582-8
NR 29
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 3
PY 2022
VL 2
AR 786558
DI 10.3389/frvir.2021.786558
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SY7
UT WOS:001021821000001
OA gold
DA 2024-07-18
ER

PT J
AU Ziabari, SPK
   Ofoghi, Z
   Rodrigues, EA
   Gromala, D
   Moreno, S
AF Ziabari, Seyedeh Pegah Kiaei
   Ofoghi, Zahra
   Rodrigues, Emma A.
   Gromala, Diane
   Moreno, Sylvain
TI Investigating the Role of Having an Avatar in Virtual Reality on Pain
   Alleviation and Embodiment in Patients With Pain Using
   Electroencephalogram: A Neuroimaging Protocol
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; chronic pain; EEG; VR analgesia; embodiment; avatar;
   alpha wave; theta wave
ID DISTORTED BODY-IMAGE; NEUROPATHIC PAIN; EEG; DYNAMICS; HAND
AB Chronic Pain (CP) is prevalent in industrialized countries and stands among the top 10 causes of disability. Given the widespread problems of pharmacological treatments such as opioids, a need to find alternative therapeutic approaches has emerged. Virtual Reality (VR) has shown potential as a non-pharmacological alternative for controlling pain over the past 20 years. The effectiveness of VR has been demonstrated in treating CP, and it has been suggested that VR's analgesic effects may be associated with the Sense of Embodiment (SoE): the sensation of being inside, having and controlling a virtual body in VR. Studies have shown correlations among brain signals, reported pain and a SoE, and correlations have been observed between using an avatar in VR and pain alleviation among CP patients. However, little has been published about the changes in brain physiology associated with having an avatar in VR, and current published studies present methodological issues. Defining a proper methodology to investigate the underlying brain mechanisms of pain, a SoE associated with having an avatar in VR, and its effect on reducing pain in CP patients is key to the emerging field of VR-analgesia. Here, we propose an intervention trial design (test/intervention/test) to evaluate the effects of having a virtual avatar in VR on pain levels and SoE in CP patients using Electroencephalogram (EEG) recordings. Resting-state EEG recordings, perceived pain levels, and SoE scores will be collected before and after the VR intervention. Patients diagnosed with CP will be recruited from local pain clinics and pseudo-randomly assigned to one of two groups-with or without an avatar. Patients will experience a 10-min VR intervention built to treat CP while their EEG signals are recorded. In articulating the study procedure, we propose a framework for future studies that explores the mechanisms of VR-analgesia in patients with chronic pain.
C1 [Ziabari, Seyedeh Pegah Kiaei; Ofoghi, Zahra; Gromala, Diane] Simon Fraser Univ, Sch Interact Arts & Technol, Pain Studies Lab, Surrey, BC, Canada.
   [Rodrigues, Emma A.; Moreno, Sylvain] Simon Fraser Univ, Sch Interact Arts & Technol, Computat Hlth Res Lab, Surrey, BC, Canada.
C3 Simon Fraser University; Simon Fraser University
RP Ziabari, SPK (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, Pain Studies Lab, Surrey, BC, Canada.
EM skaieizi@sfu.ca
CR Abbate S, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/617495
   Alchalabi B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P776, DOI [10.1109/VR.2019.8798263, 10.1109/vr.2019.8798263]
   Alshelh Z, 2016, J NEUROSCI, V36, P1008, DOI 10.1523/JNEUROSCI.2768-15.2016
   Baer RA, 2003, CLIN PSYCHOL-SCI PR, V10, P125, DOI 10.1093/clipsy/bpg015
   Bang JY, 2020, J NEURODEV DISORD, V12, DOI 10.1186/s11689-020-09321-6
   Barry RJ, 2011, CLIN NEUROPHYSIOL, V122, P2010, DOI 10.1016/j.clinph.2011.02.036
   Bennett M., 2010, Neuropathic Pain, V2
   Bes F, 2009, SLEEP, V32, P392, DOI 10.1093/sleep/32.3.392
   Boord P, 2008, SPINAL CORD, V46, P118, DOI 10.1038/sj.sc.3102077
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   Cimtay Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072034
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   Cohen O, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/035006
   Collado-Mateo D, 2015, SOMATOSENS MOT RES, V32, P219, DOI 10.3109/08990220.2015.1074566
   Cuzzolaro M., 2018, Body image, eating, and weight: a guide to assessment, treatment, and prevention, P1
   David N, 2008, CONSCIOUS COGN, V17, P523, DOI 10.1016/j.concog.2008.03.004
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DIMPFEL W, 1993, CLIN INVESTIGATOR, V71, P197
   Pinheiro ESD, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149085
   Duncan NW, 2013, J PSYCHIATR NEUROSCI, V38, P84, DOI 10.1503/jpn.120059
   Ecsy K., 2014, ANALGESIC EFFECTS EE
   Franco M.G., 2014, Neurophysiological Signatures of the Body Representation in the Brain Using Immersive Virtual Reality
   Fu H., 2020, JMIR BIOMED ENG, V6
   Gallagher S, 1995, J MIND BEHAV, V16, P369
   Gallagher Shaun., 2001, HDB PHENOMENOLOGY ME, P147, DOI DOI 10.1007/978-94-010-0536-4_8
   Gatchel RJ, 2007, PSYCHOL BULL, V133, P581, DOI 10.1037/0033-2909.133.4.581
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gold JI, 2018, J PEDIATR PSYCHOL, V43, P266, DOI 10.1093/jpepsy/jsx129
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gromala D., 2011, CHI 2011 Extended Abstracts on Human Factors in Computing Systems, P1171, DOI DOI 10.1145/1979742.1979704
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Gupta A, 2018, PAIN MED, V19, P151, DOI 10.1093/pm/pnx109
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2006, CNS SPECTRUMS, V11, P45, DOI 10.1017/S1092852900024202
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Indovina P, 2018, CLIN J PAIN, V34, P858, DOI 10.1097/AJP.0000000000000599
   International Association for the Study of Pain, 2021, ASS STUD PAIN
   Kabat-Zinn J., 2005, FULL CATASTROPHE LIV, P650
   Korner A., 2016, FRONT PSYCHOL, V6, P1
   Lagopoulos J, 2009, J ALTERN COMPLEM MED, V15, P1187, DOI 10.1089/acm.2009.0113
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Llinás R, 2005, TRENDS NEUROSCI, V28, P325, DOI 10.1016/j.tins.2005.04.006
   Longo MR, 2009, ACTA PSYCHOL, V132, P166, DOI 10.1016/j.actpsy.2009.02.003
   Lotze Martin, 2007, Curr Rheumatol Rep, V9, P488
   Magosso E, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7051079
   Mallari B, 2019, J PAIN RES, V12, P2053, DOI 10.2147/JPR.S200498
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Martini M, 2014, EUR J PAIN, V18, P1040, DOI 10.1002/j.1532-2149.2014.00451.x
   Martini M, 2016, CONSCIOUS COGN, V43, P143, DOI 10.1016/j.concog.2016.06.005
   Matamala-Gomez M., 2020, J CLIN MED
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   MELZACK R, 1968, P423
   MELZACK R, 1975, PAIN, V1, P277, DOI 10.1016/0304-3959(75)90044-5
   Melzack R, 1999, PAIN, pS121, DOI 10.1016/S0304-3959(99)00145-1
   MELZACK R, 1987, PAIN, V30, P191, DOI 10.1016/0304-3959(87)91074-8
   Mills SEE, 2019, BRIT J ANAESTH, V123, pE273, DOI 10.1016/j.bja.2019.03.023
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moseley GL, 2012, NEUROSCI BIOBEHAV R, V36, P34, DOI 10.1016/j.neubiorev.2011.03.013
   Moseley GL, 2005, NEUROLOGY, V65, P773, DOI 10.1212/01.wnl.0000174515.07205.11
   Nierula B, 2017, J PAIN, V18, P645, DOI 10.1016/j.jpain.2017.01.003
   oculus, 2021, HAND TRACK PRIV NOT
   Oculus Quest, 2020, ALL ON VR HEADS OC
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Ploner M, 2017, TRENDS COGN SCI, V21, P100, DOI 10.1016/j.tics.2016.12.001
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Romano D, 2014, NEUROPSYCHOLOGIA, V57, P93, DOI 10.1016/j.neuropsychologia.2014.03.002
   Rosenblum A, 2008, EXP CLIN PSYCHOPHARM, V16, P405, DOI 10.1037/a0013628
   Ryan JJ, 2001, PERSP INDIV, P19
   Scholz J, 2019, PAIN, V160, P53, DOI 10.1097/j.pain.0000000000001365
   Schopflocher D, 2011, PAIN RES MANAG, V16, P445, DOI 10.1155/2011/876306
   Senkowski D, 2016, NEUROSCI BIOBEHAV R, V69, P252, DOI 10.1016/j.neubiorev.2016.08.009
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Stern J, 2006, NEUROIMAGE, V31, P721, DOI 10.1016/j.neuroimage.2005.12.042
   Tong X, 2015, LECT NOTES COMPUT SC, V9179, P388, DOI 10.1007/978-3-319-21067-4_40
   Tromp J., 2017, COMBINED USE VIRTUAL
   Tu YH, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17788-z
   unity, 2021, WORK AN RIGG UN LEAR
   Unity Real-Time Development Platform, 2020, 3D 2D VR AR VIS
   Veehof MM, 2011, PAIN, V152, P533, DOI 10.1016/j.pain.2010.11.002
   Villafaina S, 2019, J CLIN MED, V8, DOI 10.3390/jcm8071015
   Villafaina S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102106
   Wang R., 2015, COGN NEURODYNAMICS, V9
   Waterstone TS, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10090644
NR 84
TC 0
Z9 0
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 10
PY 2022
VL 2
AR 775764
DI 10.3389/frvir.2021.775764
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YL7
UT WOS:001019238000001
OA gold
DA 2024-07-18
ER

PT J
AU Wang, AN
   Thompson, M
   Uz-Bilgin, C
   Klopfer, E
AF Wang, Annie
   Thompson, Meredith
   Uz-Bilgin, Cigdem
   Klopfer, Eric
TI Authenticity, Interactivity, and Collaboration in Virtual Reality Games:
   Best Practices and Lessons Learned
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality1; immersive virtual environments2; learning games3;
   biology4; collaboration5; STEM education6
ID HIGHER-EDUCATION; COGNITIVE LOAD; SCIENCE; ENVIRONMENTS; MANIPULATION;
   INSTRUCTION; MICROSCOPY; DESIGN; WORLDS; K-12
AB Virtual reality has become an increasingly important topic in the field of education research, going from a tool of interest to a tool of practice. In this paper, we document and summarize the studies associated with our 4-year design project, Collaborative Learning Environments in Virtual Reality (CLEVR). Our goal is to share the lessons we gleaned from the design and development of the game so that others may learn from our experiences as they are designing, developing, and testing VR for learning. We translate "lessons learned" from our user studies into "best practices" when developing authentic, interactive, and collaborative experiences in VR. We learned that authentic representations can enhance learning in virtual environments but come at a cost of increased time and resources in development. Interactive experiences can motivate learning and enable users to understand spatial relationships in ways that two dimensional representations cannot. Collaboration in VR can be used to alleviate some of the cognitive load inherent in VR environments, and VR can serve as a context for collaborative problem solving with the appropriate distribution of roles and resources. The paper concludes with a summation of best practices intended to inform future VR designers and researchers.
C1 [Wang, Annie; Thompson, Meredith; Uz-Bilgin, Cigdem; Klopfer, Eric] MIT, Educ Arcade, Comparat Media Studies & Writing, Cambridge, MA 02139 USA.
C3 Massachusetts Institute of Technology (MIT)
RP Thompson, M (corresponding author), MIT, Educ Arcade, Comparat Media Studies & Writing, Cambridge, MA 02139 USA.
EM meredith.m.thompson@gmail.com
RI Klopfer, Eric/KEJ-6120-2024
CR Ahn J., 2017, CYBERLEARNING COMMUN, P12
   Amiel T, 2008, EDUC TECHNOL SOC, V11, P29
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Castaneda L., 2017, IMPLICATIONS VIRTUAL
   Çeliker HD, 2015, J BALT SCI EDUC, V14, P501
   Chiu JL, 2015, COMPUT EDUC, V85, P59, DOI 10.1016/j.compedu.2015.02.007
   Collins A, 2004, J LEARN SCI, V13, P15, DOI 10.1207/s15327809jls1301_2
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Cuseo J., 1992, COOPERATIVE LEARNING, V2, P5
   Cystic Fibrosis Foundation, 2021, BAS CFTR PROT
   Daher S, 2017, LECT NOTES ARTIF INT, V10498, P87, DOI 10.1007/978-3-319-67401-8_10
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   de la Torre-Luque A, 2017, INT J DISABIL DEV ED, V64, P420, DOI 10.1080/1034912X.2016.1274022
   Fiore S.M., 2017, COLLABORATIVE PROBLE
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Hew KF, 2010, BRIT J EDUC TECHNOL, V41, P33, DOI 10.1111/j.1467-8535.2008.00900.x
   Jacobson J, 2017, SMART COMPUT INTELL, P35, DOI 10.1007/978-981-10-5490-7_3
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Johnson DW, 1999, THEOR PRACT, V38, P67, DOI 10.1080/00405849909543834
   Johnson-Glenberg MC, 2017, SMART COMPUT INTELL, P193, DOI 10.1007/978-981-10-5490-7_11
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Johnson-Glenberg MC, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0060-9
   Jones MG, 2003, J RES SCI TEACH, V40, P303, DOI 10.1002/tea.10078
   Kiefer M, 2012, TRENDS NEUROSCI EDUC, V1, P15, DOI 10.1016/j.tine.2012.07.002
   Korbey Holly., 2017, Edutopia
   Laal M, 2013, PROCD SOC BEHV, V93, P1433, DOI 10.1016/j.sbspro.2013.10.058
   Lee MJW, 2009, J E-LEARN KNOWL SOC, V5, P149
   Leinen P, 2015, BEILSTEIN J NANOTECH, V6, P2148, DOI 10.3762/bjnano.6.220
   Lin VSY, 1997, SCIENCE, V278, P840, DOI 10.1126/science.278.5339.840
   Lindgren R, 2016, COMPUT EDUC, V95, P174, DOI 10.1016/j.compedu.2016.01.001
   Lindgren R, 2013, EDUC RESEARCHER, V42, P445, DOI 10.3102/0013189X13511661
   Liu D, 2017, SMART COMPUT INTELL, P1, DOI 10.1007/978-981-10-5490-7
   Lui M, 2014, TECHNOL PEDAGOG EDUC, V23, P57, DOI 10.1080/1475939X.2013.838452
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mayer R. E., 2020, COGNITIVE FDN GAME B
   Mayer RE, 2003, EDUC PSYCHOL-US, V38, P43, DOI 10.1207/S15326985EP3801_6
   Mayer RE, 2019, APPL COGNITIVE PSYCH, V33, P930, DOI 10.1002/acp.3560
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Merchant Z, 2012, COMPUT EDUC, V59, P551, DOI 10.1016/j.compedu.2012.02.004
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Montoro DT, 2018, NATURE, V560, P319, DOI 10.1038/s41586-018-0393-7
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Office of the Commissioner O. of the, 2020, FDA APPR NEW BREAKTH
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Parmar D, 2016, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2016.7504696
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pellas N, 2020, IEEE T LEARN TECHNOL, V13, P748, DOI 10.1109/TLT.2020.3019405
   Pouw WTJL, 2014, EDUC PSYCHOL REV, V26, P51, DOI 10.1007/s10648-014-9255-5
   Rey GD, 2019, EDUC PSYCHOL REV, V31, P389, DOI 10.1007/s10648-018-9456-4
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Sandoval WA, 2004, EDUC PSYCHOL-US, V39, P199, DOI 10.1207/s15326985ep3904_1
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Tan S., 2013, 3D IMMERSIVE INTERAC, DOI [10.1007/978-981-4021-90-6_2, DOI 10.1007/978-981-4021-90-6_2]
   Thompson M., 2021, ILRN 2021 C P, DOI [10.23919/ilrn52045.2021.9459336, DOI 10.23919/ILRN52045.2021.9459336]
   Thompson M., 2018, CHI 2018
   Thompson M M., 2016, Journal of College Science Teaching, V46, P84
   Thompson M, 2020, J UNIVERS COMPUT SCI, V26, P929
   Thompson MM, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00133
   Uz-Bilgin C, 2022, VIRTUAL REAL-LONDON, V26, P649, DOI 10.1007/s10055-021-00528-z
   Uz-Bilgin C, 2020, J SCI EDUC TECHNOL, V29, P813, DOI 10.1007/s10956-020-09861-5
   Venugopalan PL, 2020, ACS NANO, V14, P9423, DOI 10.1021/acsnano.0c05217
   Wang A., 2020, THESIS MASSACHUSETTS
   Wang AN, 2022, INTERACT LEARN ENVIR, V30, P677, DOI 10.1080/10494820.2019.1678489
   Weisberg SM, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0071-6
   Wenger E., 1998, Systems Thinker, V9, P2
   You SX, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04470-8
   Yuan SG, 2017, WIRES COMPUT MOL SCI, V7, DOI 10.1002/wcms.1298
   Zhou Z, 2016, SCI PROGRAMMING-NETH, V2016, DOI 10.1155/2016/5612039
NR 71
TC 11
Z9 12
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 13
PY 2021
VL 2
AR 734083
DI 10.3389/frvir.2021.734083
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AQ7
UT WOS:001019295500001
OA gold
DA 2024-07-18
ER

PT J
AU Lee, JJ
   Hu-Au, E
AF Lee, Joey J.
   Hu-Au, Elliot
TI E3XR: An Analytical Framework for Ethical, Educational and Eudaimonic XR
   Design
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE learning; educational design; mixed reality; augmented reality; virtual
   reality; ethics; extended reality; eudaimonic design
ID IMMERSIVE VIRTUAL-REALITY; SELF-DETERMINATION THEORY; STEREOTYPE THREAT;
   RACIAL EMBODIMENT; MOTION SICKNESS; GAMES; REPRESENTATION; MOTIVATION;
   STUDENTS; WORLD
AB A rapidly growing number of educators and students now embrace XR as a powerful technology with affordances that can support many benefits, including highly immersive learning experiences, empathy and perspectives on social issues; XR can be designed in ways that can provide new pathways to success and opportunity. Yet the mirror image is also true -- XR can be designed in ways that lead to increased risk, perpetuation of inequities and other harmful impacts to individuals and society. We need ways to analyze XR in terms of ethical aspects, educational efficacy and whether it supports or hinders human flourishing (i.e., eudaimonia). In this paper, we discuss XR as a double-edged sword that can be leveraged for positive or negative outcomes, whether intentionally or unintentionally; that is, we highlight various opportunities and benefits at hand, but also risks and possible negative impacts. We introduce E3XR, a framework that serves as an analytical lens to determine the ethics, learning theory and human flourishing aspects of an XR design. For each component of this framework, we review relevant literature and consider the threats and opportunities that can be evaluated. Finally, we conclude with a discussion of the significance of this work and implications for designers and educators.
C1 [Lee, Joey J.; Hu-Au, Elliot] Columbia Univ, Dept Math Sci & Technol, Commun Media & Learning Technol Design, Games Res Lab,Teachers Coll, New York, NY 10027 USA.
C3 Columbia University; Columbia University Teachers College
RP Lee, JJ (corresponding author), Columbia Univ, Dept Math Sci & Technol, Commun Media & Learning Technol Design, Games Res Lab,Teachers Coll, New York, NY 10027 USA.
EM jl3471@tc.columbia.edu
FU Google for Education in the form of a Virtual Reality Research Award
FX This study received funding from Google for Education in the form of a
   Virtual Reality Research Award.
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Al-Gindy Ahmed, 2020, International Journal of Information and Education Technology, V10, P171, DOI 10.18178/ijiet.2020.10.3.1358
   Alsop, 2021, VIRTUAL REALITY VR S
   Alzahrani NM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165660
   Anderson M., 2015, VIEWS GAMING DIFFER
   [Anonymous], 1954, Technology and values: Essential readings
   Aristotle, 1962, NICHOMACHEAN ETHICS
   Ashworth F., 2004, Learning theories and higher education
   Ayers JW, 2016, JAMA INTERN MED, V176, P1865, DOI 10.1001/jamainternmed.2016.6274
   BADDELEY AD, 1983, PHILOS T R SOC B, V302, P311, DOI 10.1098/rstb.1983.0057
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Bailenson JN, 2005, HUM COMMUN RES, V31, P511, DOI 10.1093/hcr/31.4.511
   BANDURA A, 1991, ORGAN BEHAV HUM DEC, V50, P248, DOI 10.1016/0749-5978(91)90022-L
   Baniasadi Tayebeh, 2020, Oman Med J, V35, pe125, DOI 10.5001/omj.2020.43
   Behm-Morawitz E, 2016, COMMUN MONOGR, V83, P396, DOI 10.1080/03637751.2015.1128556
   Bentham Jeremy, 1789, The Works of Jeremy Bentham
   Blackwell L., 2019, PROC ACM HUM COMPUT, V3, P1, DOI [10.1145/3359202, DOI 10.1145/3359202]
   Boda PA, 2020, J SCI EDUC TECHNOL, V29, P691, DOI 10.1007/s10956-020-09849-1
   Bower M, 2020, BRIT J EDUC TECHNOL, V51, P2214, DOI 10.1111/bjet.13009
   Bransford JD, 1999, REV RES EDUC, V24, P61, DOI 10.3102/0091732X024001061
   Brey P., 1999, Ethics and Information Technology, V1, P5, DOI 10.1023/A:1010069907461
   Brignull Harry, 2015, DARK PATTERNS USER I
   Broman K, 2015, INT J SCI MATH EDUC, V13, P1255, DOI 10.1007/s10763-014-9550-0
   Brown J., 1989, Educational Researcher, V18, P32, DOI [DOI 10.3102/0013189X018001032, 10.3102/0013189X018001032, DOI 10.2307/1176008]
   Burke V., 2020, NORSK MUSEUMSTIDSSKR, V6, P117, DOI [10.18261/issn.2464-2525-2020-02-05, DOI 10.18261/ISSN.2464-2525-2020-02-05, https://doi.org/10.18261/issn.2464-2525-2020-02-05]
   Bye K., 2019, GREENL XR STRAT C
   Bye K., 2019, AWE US 2019
   Bye K., 2019, ACM SIGGRAPH 2019 PA, DOI DOI 10.1145/3306212.3328138
   Camilli G, 2010, TEACH COLL REC, V112, P579
   Capps DK, 2013, J SCI TEACH EDUC, V24, P497, DOI 10.1007/s10972-012-9314-z
   Carter M., 2020, Ethical Implications of Emerging Mixed Reality Technologies
   Chang F, 2019, CYBERPSYCH BEH SOC N, V22, P634, DOI 10.1089/cyber.2019.0106
   Charles D, 2020, ADV EXP MED BIOL, V1235, P53, DOI 10.1007/978-3-030-37639-0_4
   Chattha UA, 2020, IEEE ACCESS, V8, P130486, DOI 10.1109/ACCESS.2020.3007076
   Chen J., 2009, ANN M SOC NEUR OCT 1
   Cieslik B, 2020, COMPLEMENT THER MED, V52, DOI 10.1016/j.ctim.2020.102480
   Cogburn Courtney D., 2018, ACM SIGGRAPH, DOI 10.1145/3226552.3226575
   Collins R., 2014, CURRICULUM LEADERSHI, V12
   Connor Joshue O., 2020, Computers Helping People with Special Needs. 17th International Conference, ICCHP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12376), P117, DOI 10.1007/978-3-030-58796-3_15
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Deci EL, 2008, CAN PSYCHOL, V49, P182, DOI 10.1037/a0012801
   Dibbell J., 2005, VILLAGE VOICE
   Duckworth AL, 2007, J PERS SOC PSYCHOL, V92, P1087, DOI 10.1037/0022-3514.92.6.1087
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Flanagan M, 2014, VALUES AT PLAY IN DIGITAL GAMES, P1
   Fox J., 2019, BREATH FRESH AIR VID
   Franks M. A., 2017, UC DAVIS L REV, V51, P499
   Freire P., 2005, Pedagogy of the oppressed: 30th Anniversary of Pedagogy of the oppressed, DOI DOI 10.1215/00382876-1472612
   Friedman Batya, 2017, Foundations and Trends in Human-Computer Interaction, V11, P63, DOI 10.1561/1100000015
   Friedman Batya, 2002, University of Washington Technical Report
   Frontiers in Virtual Reality Seminar, 2020, ETH ISS VIRT AUGM RE
   Gaydos MJ, 2012, CULT STUD SCI EDUCAT, V7, P821, DOI 10.1007/s11422-012-9414-2
   Gee J.P., 2007, What Video Games Have to Teach Us about Learning and Literacy, V2nd
   Gerry LJ, 2017, IEEE T VIS COMPUT GR, V23, P1398, DOI 10.1109/TVCG.2017.2657239
   Griffin T, 2022, TOURISM GEOGR, V24, P934, DOI 10.1080/14616688.2020.1713881
   Groom V, 2009, SOC INFLUENCE, V4, P231, DOI 10.1080/15534510802643750
   Gugenheimer J, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375180
   Harackiewicz Judith M, 2016, Policy Insights Behav Brain Sci, V3, P220, DOI 10.1177/2372732216655542
   Harris Tristan, 2016, Medium Magazine
   Hayes JC, 2017, COGN RES, V2, DOI 10.1186/s41235-016-0046-z
   He QH, 2017, SCI REP-UK, V7, DOI 10.1038/srep45064
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hodent C., 2020, ADDRESSING ETHICS GA
   Hollands F, 2020, ETR&D-EDUC TECH RES, V68, P163, DOI 10.1007/s11423-019-09678-z
   Hosfelt D, 2019, Arxiv, DOI arXiv:1905.06995
   Hu-Au E., 2020, INT C LEARNING SCI
   Hu-Au E., 2017, INT J INNOVATION ED, V4, P215, DOI [DOI 10.1504/IJIIE.2017.10012691, 10.1504/ijiie.2017, DOI 10.1504/IJIIE.2017, https://doi.org/10.1504/IJIIE.2017.10012691]
   Hu-Au E, 2021, J SCI EDUC TECHNOL, V30, P862, DOI 10.1007/s10956-021-09925-0
   Huta V, 2014, J HAPPINESS STUD, V15, P1425, DOI 10.1007/s10902-013-9485-0
   Huttner J. P., 2017, IMMERSIVE MEMORY PAL
   IEEE, 2019, DARK PATT US INT DES
   IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems, 2019, Ethically aligned design: a vision for prioritizing human well-being with autonomous and intelligent systems
   Institute for the Future and Omidyar Network, 2018, ETHICALOS TOOLK
   Iskander J, 2018, IEEE ACCESS, V6, P19345, DOI 10.1109/ACCESS.2018.2815663
   Janonis A., 2020, Information and Software Technologies: 26th International Conference, ICIST 2020, Kaunas, Lithuania, October 15-17, 2020, Proceedings, P273, DOI [10.1007/978-3-030-59506-7_22, DOI 10.1007/978-3-030-59506-7_22]
   JigSpace, 2021, ABOUT US
   Kant Immanuel, 1997, The Cambridge Edition of the Works of Immanuel Kant, DOI [10.1017/CBO9781107049512, DOI 10.1017/CBO9781107049512]
   Kaufmann H., 2000, Education and Information Technologies, V5, P263, DOI 10.1023/A:1012049406877
   Keles B, 2020, INT J ADOLESC YOUTH, V25, P79, DOI 10.1080/02673843.2019.1590851
   Kenwright B, 2018, IEEE TECHNOL SOC MAG, V37, P20, DOI 10.1109/MTS.2018.2876104
   Kidd SH, 2016, LECT N EDUC TECHNOL, P97, DOI 10.1007/978-981-10-0027-0_6
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Klopfer E, 2008, ETR&D-EDUC TECH RES, V56, P203, DOI 10.1007/s11423-007-9037-6
   Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959
   Lakoff G, 1999, PHILOS FLESH EMBODIE
   Lau KW, 2015, INTERACT LEARN ENVIR, V23, P3, DOI 10.1080/10494820.2012.745426
   Lee J. J., 2006, ENCY GENDER INFORM T, P687, DOI [10.4018/978-1-59140-815-4.ch106, DOI 10.4018/978-1-59140-815-4.CH106]
   Lee M, 2015, ARCH GERONTOL GERIAT, V61, P154, DOI 10.1016/j.archger.2015.06.010
   Loke SK, 2015, AUSTRALAS J EDUC TEC, V31, P112
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Makransky G, 2021, J EDUC PSYCHOL, V113, P719, DOI 10.1037/edu0000473
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   MARKUS H, 1986, AM PSYCHOL, V41, P954, DOI 10.1037/0003-066X.41.9.954
   Maslow A., 1962, PSYCHOL BEING, DOI 10.1037/10793-000
   Mayer R. E., 2014, The Cambridge handbook of multimedia learning, V2nd, P31, DOI [https://doi.org/10.1017/CBO9781139547369.005, DOI 10.1017/CBO9780511816819.004, 10.1017/cbo9780511816819.004]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milk C., 2016, VIRTUAL REALITY CAN
   Minocha S., 2017, HCI 2017 DIGITAL MAK, DOI [DOI 10.14236/EWIC/HCI2017.44, 10.14236/EWIC/HCI2017.44]
   Nash P, 2011, J COMPUT ASSIST LEAR, V27, P173, DOI 10.1111/j.1365-2729.2010.00385.x
   Nasir N.S., 2002, MATH THINKING LEARNI, V4, P213, DOI [10.1207/S15327833MTL04023_6, DOI 10.1207/S15327833MTL04023_6, DOI 10.1207/S15327833MTL040236]
   Natl Acad Sci Engn Med, 2018, HOW PEOPLE LEARN II: LEARNERS, CONTEXTS, AND CULTURES, P1, DOI 10.17226/24783
   Naz F, 2017, SAGE OPEN, V7, DOI 10.1177/2158244017734022
   Neely EL, 2021, GAMES CULT, V16, P228, DOI 10.1177/1555412019887658
   Niantic, 2019, POK GO
   O'Dea S., 2021, Number of smartphone users from 2016 to 2021
   Okita S.Y., 2007, The Proceedings of the 29th Meeting of the Cognitive Science Society, P1355, DOI DOI 10.2458/AZU_RANGELANDS_V29I4_SRM3
   Outlaw J., 2019, HIDDEN RISK VIRTUAL
   Oviatt S, 2013, DESIGN FUTURE ED INT, P211, DOI [10.4324/9780203366202-19, DOI 10.4324/9780203366202-19]
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Peña J, 2021, SOC MEDIA SOC, V7, DOI 10.1177/2056305121993765
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Ratan R, 2015, COMPUT HUM BEHAV, V50, P367, DOI 10.1016/j.chb.2015.04.010
   Richards D, 2015, COMPUT EDUC, V86, P157, DOI 10.1016/j.compedu.2015.03.009
   Rizzotto Lucas, 2018, THOUGHTS GO
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Rueda J, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.506984
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   RYFF CD, 1995, CURR DIR PSYCHOL SCI, V4, P99, DOI 10.1111/1467-8721.ep10772395
   Schell Games, 2021, HISTORYMAKER VR
   Schell Games, 2021, HAPP AT
   Schrier K, 2015, J MORAL EDUC, V44, P393, DOI 10.1080/03057240.2015.1095168
   ScienceVR, 2021, SCIENCEVR HOM
   Shriram K, 2017, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2017.7892258
   Singer P., 2021, ETHICS BRITANNICA
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Spencer SJ, 1999, J EXP SOC PSYCHOL, V35, P4, DOI 10.1006/jesp.1998.1373
   Spiegel JS, 2018, SCI ENG ETHICS, V24, P1537, DOI 10.1007/s11948-017-9979-y
   Sujon Z., 2019, DIGITAL CULT ED, V11
   Susser D., 2019, GEORGETOWN L TECHNOL, V1
   Sweller J., 1994, Learning and instruction, P295, DOI DOI 10.1016/0959-4752(94)90003-5
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Turkle S, 1999, CONTEMP SOCIOL, V28, P643, DOI 10.2307/2655534
   Volioti C, 2016, EDUC INF TECHNOL, V21, P1679, DOI 10.1007/s10639-015-9409-1
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Wawro A., 2020, THERES NEW INITIATIV
   Williams D, 2009, NEW MEDIA SOC, V11, P815, DOI 10.1177/1461444809105354
   Wu JS, 2015, NAT CLIM CHANGE, V5, P413, DOI 10.1038/NCLIMATE2566
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zec Milica, 2017, THE TREE
   Zhao Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173690
   Zippia, 2021, GAM DES STAT US
NR 143
TC 4
Z9 4
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 6
PY 2021
VL 2
AR 697667
DI 10.3389/frvir.2021.697667
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TV9
UT WOS:001021844200001
OA gold
DA 2024-07-18
ER

PT J
AU Carroll, J
   Hopper, L
   Farrelly, AM
   Lombard-Vance, R
   Bamidis, PD
   Konstantinidis, EI
AF Carroll, Joanne
   Hopper, Louise
   Farrelly, Aaron Mark
   Lombard-Vance, Richard
   Bamidis, Panagiotis D.
   Konstantinidis, Evdokimos I.
TI A Scoping Review of Augmented/Virtual Reality Health and Wellbeing
   Interventions for Older Adults: Redefining Immersive Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; augmented reality; older adults; physical; mental
   health; scoping review; psychology
ID QUALITY-OF-LIFE; NINTENDO WII FIT; PHYSICAL-ACTIVITY; COGNITIVE
   FUNCTION; ENHANCED EXERCISE; IMPROVING BALANCE; TRAINING-PROGRAM;
   POSTURAL BALANCE; ELDERLY ADULTS; FALL-PRONE
AB Augmented and virtual reality (AR/VR) technologies are regularly used in psychology research to complement psychological interventions and to enable an individual to feel as if they are in an environment other than that of their immediate surroundings. A scoping review was performed to identify how AR/VR was being used with older adult populations to impact their physical and mental health. The review also sought to determine whether the terminology used in AR/VR research was consistent. The results show that 65 studies have been published in the last 20 years that meet the inclusion criteria (virtual/augmented reality) technology to impact older adults' physical/mental health and wellbeing. Participants included healthy, physically, and cognitively impaired, and emotionally vulnerable older adults. We argue that over 70% of the studies included in this review were mislabeled as VR and only six papers included fully immersive VR/AR. The remaining studies use less immersive variants of virtual reality with their populations, and only one study made use of AR, which prompted the suggestion of a new definition for virtual reality. This paper also calls for an updated taxonomy of augmented and virtual reality definitions to address the lack of consistency found in studies that identify themselves as AR/VR when they are using less immersive technical set-ups, including displaying non-interactive videos on 2D screens.
C1 [Carroll, Joanne; Hopper, Louise; Farrelly, Aaron Mark] Dublin City Univ, Sch Psychol, Dublin, Ireland.
   [Carroll, Joanne; Lombard-Vance, Richard] Maynooth Univ, Fac Sci & Engn, Dept Psychol, Maynooth, Ireland.
   [Bamidis, Panagiotis D.; Konstantinidis, Evdokimos I.] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
   [Konstantinidis, Evdokimos I.] WITA, Trento, Italy.
C3 Dublin City University; Maynooth University; Aristotle University of
   Thessaloniki
RP Carroll, J (corresponding author), Dublin City Univ, Sch Psychol, Dublin, Ireland.; Carroll, J (corresponding author), Maynooth Univ, Fac Sci & Engn, Dept Psychol, Maynooth, Ireland.
EM joanne.carroll@dcu.ie
RI Lombard-Vance, Richard/O-7511-2018
OI Lombard-Vance, Richard/0000-0002-3307-9590
FU CAPTAIN Project-Horizon 2020: European Union Funding for Research and
   Innovation [S1-PM-15-2017]
FX This review was undertaken as part of the CAPTAIN Project-Horizon 2020:
   European Union Funding for Research and Innovation Call: S1-PM-15-2017.
CR Agmon M, 2011, J GERIATR PHYS THER, V34, P161, DOI 10.1519/JPT.0b013e3182191d98
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Allport FH, 1920, J EXP PSYCHOL, V3, P159, DOI 10.1037/h0067891
   Anderson JR, 2002, COGNITIVE SCI, V26, P85, DOI 10.1207/s15516709cog2601_3
   Anderson-Hanley C, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00989
   Anderson-Hanley C, 2012, AM J PREV MED, V42, P109, DOI 10.1016/j.amepre.2011.10.016
   Anderson-Hanley C, 2011, CLIN INTERV AGING, V6, P275, DOI 10.2147/CIA.S25337
   Barbosa C. F. M., 2019, FISOTERAPIA BRASIL, V20, P278, DOI [10.33233/fb.v20i2.2846, DOI 10.33233/FB.V20I2.2846]
   Bell CS, 2011, PHYS OCCUP THER GERI, V29, P213, DOI 10.3109/02703181.2011.559307
   Benoit M, 2015, NEUROPSYCH DIS TREAT, V11, P557, DOI 10.2147/NDT.S73179
   Bisson E, 2007, CYBERPSYCHOL BEHAV, V10, P16, DOI 10.1089/cpb.2006.9997
   Blackman T, 2007, AGEING SOC, V27, P811, DOI 10.1017/S0144686X07006253
   Botella C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148237
   Botella C, 2012, CYBERPSYCH BEH SOC N, V15, P78, DOI 10.1089/cyber.2011.0140
   Cacciata M, 2019, INT J NURS STUD, V93, P30, DOI 10.1016/j.ijnurstu.2019.01.010
   Chan CLF, 2010, INT J GERIATR PSYCH, V25, P643, DOI 10.1002/gps.2403
   Choi W, 2019, J AGING PHYS ACTIV, V27, P861, DOI 10.1123/japa.2018-0020
   Corno G, 2014, STUD HEALTH TECHNOL, V199, P168, DOI 10.3233/978-1-61499-401-5-168
   Coyle H, 2015, AM J GERIAT PSYCHIAT, V23, P335, DOI 10.1016/j.jagp.2014.04.009
   de Vries AW, 2018, GAMES HEALTH J, V7, P369, DOI 10.1089/g4h.2018.0008
   Mendes FAD, 2012, PHYSIOTHERAPY, V98, P217, DOI 10.1016/j.physio.2012.06.001
   Eckert M, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/10967
   Eggenberger P, 2015, CLIN INTERV AGING, V10, P1335, DOI 10.2147/CIA.S87732
   Eurostat, 2020, DEM BAL IND TYP PROJ
   Fasilis Th, 2018, Psychiatriki, V29, P42, DOI 10.22365/jpsych.2018.291.42
   Felnhofer A, 2014, COMPUT HUM BEHAV, V31, P272, DOI 10.1016/j.chb.2013.10.045
   Franco JR, 2012, TECHNOL HEALTH CARE, V20, P95, DOI 10.3233/THC-2011-0661
   Gamito P, 2019, CYBERPSYCH BEH SOC N, V22, P69, DOI 10.1089/cyber.2017.0679
   Gamito P, 2010, CYBERPSYCH BEH SOC N, V13, P43, DOI 10.1089/cyber.2009.0237
   Glännfjord F, 2017, SCAND J OCCUP THER, V24, P329, DOI 10.1080/11038128.2016.1267259
   Graffigna G, 2013, HEALTH AFFAIR, V32, DOI 10.1377/hlthaff.2013.0279
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Guisado-Fernandez Estefania, 2019, JMIR Aging, V2, pe12192, DOI 10.2196/12192
   Hall P.A., 2007, Health Psychology Review, V1, P6, DOI [10.1080/17437190701492437, DOI 10.1080/17437190701492437]
   HAVIGHURST RJ, 1961, GERONTOLOGIST, V1, P8, DOI 10.1093/geront/1.1.8
   Hsieh CC, 2018, DEMENT GERIATR COGN, V46, P358, DOI 10.1159/000494659
   Hugues O, 2011, HANDBOOK OF AUGMENTED REALITY, P47, DOI 10.1007/978-1-4614-0064-6_2
   Huth K, 2020, ACAD PEDIATR, V20, P1020, DOI 10.1016/j.acap.2020.05.001
   Kahlbaugh PE, 2011, ACT ADAPT AGING, V35, P331, DOI 10.1080/01924788.2011.625218
   Karahan AY, 2015, CENT EUR J PUBL HEAL, V23, pS14
   Kardong-Edgren S, 2019, CLIN SIMUL NURS, V31, P28, DOI 10.1016/j.ecns.2019.02.006
   Kelman H. C., 1958, J CONFLICT RESOLUT, V2, P51, DOI [10.1177/002200275800200106, DOI 10.1177/002200275800200106]
   Kitson A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01354
   Kizony R., 2006, Proc. of 6th Intl Conf. Disability, P265, DOI DOI 10.1515/IJDHD.2006.5.3.265
   Kizony R, 2010, PHYS THER, V90, P252, DOI 10.2522/ptj.20090061
   Knowles LM, 2017, COMPUT HUM BEHAV, V73, P650, DOI 10.1016/j.chb.2017.04.005
   Korsgaard D, 2019, FOOD RES INT, V117, P30, DOI 10.1016/j.foodres.2018.02.051
   Laver K, 2012, DISABIL REHABIL, V34, P1802, DOI 10.3109/09638288.2012.662570
   Lee M, 2015, ARCH GERONTOL GERIAT, V61, P154, DOI 10.1016/j.archger.2015.06.010
   Lee S, 2013, DIABETES TECHNOL THE, V15, P489, DOI 10.1089/dia.2013.0050
   Lee Y, 2017, J AGING PHYS ACTIV, V25, P621, DOI 10.1123/japa.2015-0271
   Levy F, 2016, NEUROPSYCH DIS TREAT, V12, P877, DOI 10.2147/NDT.S97809
   Liu CL, 2010, COMPUT HUM BEHAV, V26, P1777, DOI 10.1016/j.chb.2010.07.005
   Lokka IE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29029-x
   Man DWK, 2012, INT J GERIATR PSYCH, V27, P513, DOI 10.1002/gps.2746
   Manera V, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151487
   Marivan K, 2016, TECHNOL HEALTH CARE, V24, P169, DOI 10.3233/THC-151114
   Matas NA, 2015, J SAFETY RES, V55, P159, DOI 10.1016/j.jsr.2015.08.004
   Mayer RE, 2003, EDUC PSYCHOL-US, V38, P43, DOI 10.1207/S15326985EP3801_6
   McCloy R, 2001, BRIT MED J, V323, P912, DOI 10.1136/bmj.323.7318.912
   Merriman NA, 2018, BEHAV INFORM TECHNOL, V37, P538, DOI 10.1080/0144929X.2018.1462402
   Merriman NA, 2015, COMPUT HUM BEHAV, V45, P192, DOI 10.1016/j.chb.2014.12.017
   Michie P. S., 2014, ABC BEHAV CHANGE THE
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Mirelman A, 2011, J GERONTOL A-BIOL, V66, P234, DOI 10.1093/gerona/glq201
   Monteiro RS, 2017, AGING CLIN EXP RES, V29, P387, DOI 10.1007/s40520-016-0595-5
   Morone G, 2016, AGING CLIN EXP RES, V28, P1187, DOI 10.1007/s40520-016-0578-6
   Ng YL, 2019, COMPUT HUM BEHAV, V99, P278, DOI 10.1016/j.chb.2019.05.026
   Optale G, 2010, NEUROREHAB NEURAL RE, V24, P348, DOI 10.1177/1545968309353328
   Padala Kalpana P, 2017, J Aging Res, V2017, P4653635, DOI 10.1155/2017/4653635
   Padala KP, 2017, J ALZHEIMERS DIS, V59, P565, DOI 10.3233/JAD-170120
   Padala Kalpana P, 2012, J Aging Res, V2012, P597573, DOI 10.1155/2012/597573
   Parijat P, 2015, IEEE T BIO-MED ENG, V62, P593, DOI 10.1109/TBME.2014.2361324
   Parker MG, 2020, NEUROSCI BIOBEHAV R, V112, P616, DOI 10.1016/j.neubiorev.2020.02.030
   Bacha JMR, 2018, GAMES HEALTH J, V7, P24, DOI 10.1089/g4h.2017.0065
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rodrigues EV, 2018, REJUV RES, V21, P518, DOI 10.1089/rej.2017.2041
   Rosenberg D, 2010, AM J GERIAT PSYCHIAT, V18, P221, DOI 10.1097/JGP.0b013e3181c534b5
   Rowe JW, 1997, GERONTOLOGIST, V37, P433, DOI 10.1093/geront/37.4.433
   Sápi M, 2019, GAMES HEALTH J, V8, P41, DOI 10.1089/g4h.2018.0027
   Sauzéon H, 2016, BRIT J PSYCHOL, V107, P72, DOI 10.1111/bjop.12123
   Smaerup M, 2016, REHABIL RES PRACT, V2016, DOI 10.1155/2016/7026317
   Stadler S., 2019, Augmented Reality and Virtual Reality: The Power of AR and VR for Business, P203, DOI DOI 10.1007/978-3-030-06246-0_15
   Studenski S, 2010, J NUTR HEALTH AGING, V14, P850, DOI 10.1007/s12603-010-0119-5
   Sun RP, 2019, ARCH GERONTOL GERIAT, V82, P94, DOI 10.1016/j.archger.2019.01.022
   SWELLER J, 1980, Q J EXP PSYCHOL, V32, P233, DOI 10.1080/14640748008401159
   Tarnanas I, 2015, FRONT AGING NEUROSCI, V7, DOI [10.3389/fnagi.2015.00050, 10.3385/fnagi.2015.00050]
   Tennyson R.D., 1997, INSTRUCTIONAL DESIGN
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Tsuda K, 2016, INTERNAL MED, V55, P347, DOI 10.2169/internalmedicine.55.5275
   Vallejo V., 2014, VIRTUAL REAL-LONDON, V8
   Velez JA, 2016, CYBERPSYCH BEH SOC N, V19, P721, DOI 10.1089/cyber.2016.0144
   Gomes GCV, 2018, MATURITAS, V118, P20, DOI 10.1016/j.maturitas.2018.10.002
   Vygotsky L., 1978, AM J PSYCHOL, DOI [DOI 10.2307/1421493, 10.2307/j.ctvjf9vz4]
   Wiederhold BK, 2020, CYBERPSYCH BEH SOC N, V23, P141, DOI 10.1089/cyber.2020.29176.bkw
   Wiederhold BK, 2016, CYBERPSYCH BEH SOC N, V19, P577, DOI 10.1089/cyber.2016.29052.bkw
   Wiederhold BK, 2012, CYBERPSYCH BEH SOC N, V15, P67, DOI 10.1089/cyber.2011.1533
   Williams B, 2011, OCCUP THER HEALTH CA, V25, P131, DOI 10.3109/07380577.2011.560627
   Yeh TM, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16030333
   ZAJONC RB, 1965, SCIENCE, V149, P269, DOI 10.1126/science.149.3681.269
NR 103
TC 15
Z9 14
U1 8
U2 25
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 2
PY 2021
VL 2
AR 655338
DI 10.3389/frvir.2021.655338
PG 26
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PO2
UT WOS:001021731700001
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Mottelson, A
   Petersen, GB
   Lilija, K
   Makransky, G
AF Mottelson, Aske
   Petersen, Gustav Bog
   Lilija, Klemen
   Makransky, Guido
TI Conducting Unsupervised Virtual Reality User Studies Online
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; COVID-19; user studies; crowdsourcing; online
   experiments
AB Conducting user studies online and unsupervised instead of in laboratories gives quick access to a large and inexpensive participant pool. It is however unclear if data sourced this way is valid, and what the best practices for conducting unsupervised VR studies are. The restrictions on laboratory access experienced during COVID-19 further necessitate the development of valid procedures for remote data collection, especially for research fields such as VR that heavily rely on laboratory studies. In this paper we report our experiences with conducting two unsupervised VR studies amidst the pandemic, by recruiting participants online on relevant fora and employing participants' own standalone VR equipment. We investigate whether it is feasible to collect valid data across in-VR survey responses and hand tracking. We report a good reliability of collected data, which requires only slightly more sanitation than a comparable laboratory study. We synthesize our experiences into practical recommendations for conducting unsupervised VR user studies using online recruitment, which can greatly reduce barriers to conducting empirical VR research and improve the quantity of VR user studies, regardless of laboratory availability.
C1 [Mottelson, Aske; Petersen, Gustav Bog; Makransky, Guido] Univ Copenhagen, Dept Psychol, Copenhagen, Denmark.
   [Lilija, Klemen] Univ Copenhagen, Dept Comp Sci, Copenhagen, Denmark.
C3 University of Copenhagen; University of Copenhagen
RP Mottelson, A (corresponding author), Univ Copenhagen, Dept Psychol, Copenhagen, Denmark.
EM amot@psy.ku.dk
RI Mottelson, Aske/O-2922-2015
OI Mottelson, Aske/0000-0003-1827-8513; Makransky,
   Guido/0000-0003-1862-7824; Bog Petersen, Gustav/0000-0003-4098-4895
FU Innovation fund Denmark under the agreement "SIPROS"; UCPHs Data+ pool
   under the agreement "Quantifying Body Ownership"
FX This research was supported by Innovation fund Denmark under the
   agreement "SIPROS", UCPHs Data+ pool under the agreement "Quantifying
   Body Ownership".
CR Anderson CA, 2019, PERS SOC PSYCHOL B, V45, P842, DOI 10.1177/0146167218798821
   Anderson L. W., 2001, A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives
   Behrend TS, 2011, BEHAV RES METHODS, V43, P800, DOI 10.3758/s13428-011-0081-0
   Bradesko L, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3086686
   Cheng J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1365, DOI 10.1145/2702123.2702145
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   CLARK RE, 1983, REV EDUC RES, V53, P445, DOI 10.3102/00346543053004445
   Cooper S, 2010, NATURE, V466, P756, DOI 10.1038/nature09304
   Crump MJC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057410
   Daniel F, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148148
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Estellés-Arolas E, 2012, J INF SCI, V38, P189, DOI 10.1177/0165551512437638
   Feyisetan O, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P333, DOI 10.1145/2736277.2741639
   Gadiraju U, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1631, DOI 10.1145/2702123.2702443
   Goodman JK, 2017, J CONSUM RES, V44, P196, DOI 10.1093/jcr/ucx047
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Henze N, 2011, INT J MOB HUM COMPUT, V3, P71, DOI 10.4018/jmhci.2011100105
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Hopp T., 2016, J CURRENT ISSUES RES, V37, P113
   Huber B, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227629
   Insider A. R., 2020, HAS OC QUEST SOLD ON
   Kelly J. W., 2021, PSYARXIV, DOI [10.1109/vr50410.2021.00095, DOI 10.1109/VR50410.2021.00095]
   Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453
   Klas C.-P., 2018, USER STUDIES DIGITAL
   Koch K. Von Luck, 2018, P 16 EUR C COMP SUPP, P1
   Lilija K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P455, DOI 10.1109/VR50410.2021.00069
   Ma X, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P33, DOI 10.1145/3178876.3186034
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Mottelson A, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139141
   Paolacci G, 2010, JUDGM DECIS MAK, V5, P411
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Petersen G. B., 2021, P 2021 CHI C HUM FAC, P1
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rivu R., 2021, Remote vr studies-a framework for running virtual reality studies remotely via participant-owned hmds
   Saffo David, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382829
   Sheehan KB, 2018, COMMUN MONOGR, V85, P140, DOI 10.1080/03637751.2017.1342043
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Stewart N, 2015, JUDGM DECIS MAK, V10, P479
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   World Health Organization, 2021, TEMPL INF CONS FORMS
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
NR 42
TC 19
Z9 21
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 28
PY 2021
VL 2
AR 681482
DI 10.3389/frvir.2021.681482
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TM7
UT WOS:001021835000001
OA gold
DA 2024-07-18
ER

PT J
AU Ahn, SJ
   Levy, L
   Eden, A
   Won, AS
   MacIntyre, B
   Johnsen, K
AF Ahn, Sun Joo (Grace)
   Levy, Laura
   Eden, Allison
   Won, Andrea Stevenson
   MacIntyre, Blair
   Johnsen, Kyle
TI IEEEVR2020: Exploring the First Steps Toward Standalone Virtual
   Conferences
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE social VR; conferences; media appropriateness; social presence; avatars;
   virtual reality
ID SOCIAL PRESENCE; TIME
AB The global COVID-19 pandemic forced all large in-person events to pivot to virtual or online platforms. IEEEVR2020 coincided with rising concerns and restrictions on travel and large gatherings, becoming one of the first academic conferences to rapidly adapt its programming to a completely virtual format. The global pandemic provided an impetus to re-examine the possibility of holding social interactions in virtual worlds. This article aims to: (1) revisit the issues of virtual conferences noted in earlier studies, focusing specifically on academic conferences, (2) introduce new survey and observational data from the recent IEEEVR2020 conference, and (3) present insights and future directions for virtual conferences during and after the COVID-19 pandemic. Findings from a field observation during the conference and a post-conference survey point to complex relationships among users, media platforms selected, and social constraints during the virtual conference.
C1 [Ahn, Sun Joo (Grace)] Univ Georgia, Grady Coll Journalism & Mass Commun, Athens, GA 30602 USA.
   [Levy, Laura] Georgia Inst Technol, Interact Media Technol Ctr, Atlanta, GA USA.
   [Eden, Allison] Michigan State Univ, Dept Commun, E Lansing, MI USA.
   [Won, Andrea Stevenson] Cornell Univ, Dept Commun, Ithaca, NY USA.
   [MacIntyre, Blair] Georgia Inst Technol, Coll Comp, Atlanta, GA USA.
   [Johnsen, Kyle] Univ Georgia, Sch Elect & Comp Engn, Athens, GA USA.
C3 University System of Georgia; University of Georgia; University System
   of Georgia; Georgia Institute of Technology; Michigan State University;
   Cornell University; University System of Georgia; Georgia Institute of
   Technology; University System of Georgia; University of Georgia
RP Ahn, SJ (corresponding author), Univ Georgia, Grady Coll Journalism & Mass Commun, Athens, GA 30602 USA.
EM sjahn@uga.edu
RI Ahn, Sun Joo (Grace)/KHE-5786-2024
OI Ahn, Sun Joo (Grace)/0000-0002-6657-3886
FU National Science Foundation [2032474]
FX Funding. This material was based upon work supported by the National
   Science Foundation under Grant Number 2032474. Any opinions, findings,
   and conclusions or recommendations expressed in this material are those
   of the authors and do not necessarily reflect the views of the National
   Science Foundation.
CR Abbey J. R., 1994, TRAVEL TOURISM HOSPI, P273
   Anderson T., 1993, American Journal of Distance Education, V7, P5, DOI 10.1080/08923649309526819
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Barnes MD, 2012, HEALTH EDUC BEHAV, V39, P719, DOI 10.1177/1090198112464496
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Braun V., 2012, APA HDB RES METHODS, P57, DOI [https://doi.org/10.1037/13620-004, 10.1007/978-981-10-2779-6_103-1, 10.1037/13620-004]
   Cardel MI, 2020, J WOMENS HEALTH, V29, P721, DOI 10.1089/jwh.2019.8027
   Edelheim JR, 2018, J TEACH TRAVEL TOUR, V18, P94, DOI 10.1080/15313220.2017.1407517
   Erickson T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P503
   Foley C., 2014, Event Management, V18, P53, DOI 10.3727/152599514X13883555341887
   FULK J, 1993, ACAD MANAGE J, V36, P921, DOI 10.5465/256641
   Goetz T, 2006, LEARN INSTR, V16, P323, DOI 10.1016/j.learninstruc.2006.07.004
   Gunkel SNB, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P498, DOI 10.1145/3204949.3208115
   Holmes MH, 2016, INNOV HIGH EDUC, V41, P381, DOI 10.1007/s10755-016-9358-7
   Horwitz SK, 2007, J MANAGE, V33, P987, DOI 10.1177/0149206307308587
   Hoyer K.G., 2001, Journal of Environmental Policy Planning, V3, P177, DOI DOI 10.1002/JEPP.84
   Jamison L., 2017, 2 LIFE STILL HAS 600
   Le DA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P485, DOI [10.1109/VRW50115.2020.0-175, 10.1109/VRW50115.2020.00101]
   Leong JJ, 2008, BMJ-BRIT MED J, V337, DOI 10.1136/bmj.a683
   Mair J, 2018, CURR ISSUES TOUR, V21, P2160, DOI 10.1080/13683500.2016.1248909
   Mair J, 2009, TOURISM MANAGE, V30, P400, DOI 10.1016/j.tourman.2008.08.002
   MARKUS ML, 1994, ORGAN SCI, V5, P502, DOI 10.1287/orsc.5.4.502
   Nevins J, 2014, PROF GEOGR, V66, P298, DOI 10.1080/00330124.2013.784954
   Oester S, 2017, FRONT MAR SCI, V4, DOI 10.3389/fmars.2017.00257
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Parsons E.C. M., 2015, Journal of Environmental Studies and Sciences, V5, P735, DOI DOI 10.1007/S13412-015-0327-8
   RICE RE, 1993, HUM COMMUN RES, V19, P451, DOI 10.1111/j.1468-2958.1993.tb00309.x
   Rogers T, 2012, C CONVENTIONS, DOI [10.4324/9780203119402, DOI 10.4324/9780203119402]
   Shami NS, 2011, ECSCW 2011: PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P393
   Shirmohammadi S., 2012, 2012 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2012), P150, DOI 10.1109/HAVE.2012.6374455
   Short J., 1976, The social psychology of telecommunications
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Sousa BJ, 2017, INT J QUAL METH, V16, DOI 10.1177/1609406917740441
   TREVINO LK, 1987, COMMUN RES, V14, P553, DOI 10.1177/009365087014005006
   U.S. Travel Association, 2017, EC IMP M BUS EV
   van den Hooff B., 2005, Journal of Business Communication, V42, P4, DOI 10.1177/0021943604271192
   Walther J.B., 2015, The International Encyclopedia of Interpersonal Communication, P1, DOI [10.1002/9781118540190.wbeic192, DOI 10.1002/9781118540190.WBEIC192]
   Witt SF, 1995, TOURISM MANAGE, V16, P559, DOI 10.1016/0261-5177(95)00079-8
   Yoo JJE, 2010, J TRAVEL TOUR MARK, V27, P179, DOI 10.1080/10548401003590369
   Zhang HQQ, 2007, TOURISM MANAGE, V28, P1123, DOI 10.1016/j.tourman.2006.07.008
NR 41
TC 19
Z9 20
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 7
PY 2021
VL 2
AR 648575
DI 10.3389/frvir.2021.648575
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0HS5
UT WOS:001020156500001
OA gold
DA 2024-07-18
ER

PT J
AU Viczko, J
   Tarrant, J
   Jackson, R
AF Viczko, Jeremy
   Tarrant, Jeff
   Jackson, Ray
TI Effects on Mood and EEG States After Meditation in Augmented Reality
   With and Without Adjunctive Neurofeedback
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; meditation; neurofeedback; loving kindness
   meditation; electroencephalogram; mental health; apps and smartphones
ID VIRTUAL-REALITY; MINDFULNESS MEDITATION; STRESS REDUCTION; DEFAULT MODE;
   FRONTAL EEG; BRAIN; SYSTEM; METAANALYSIS; DEPRESSION; ASYMMETRY
AB Research and design of virtual reality technologies with mental-health focused applications has increased dramatically in recent years. However, the applications and psychological outcomes of augmented reality (AR) technologies still remain to be widely explored and evaluated. This is particularly true for the use of AR for the self-management of stress, anxiety, and mood. In the current study, we examined the impact of a brief open heart meditation AR experience on participants with moderate levels of anxiety and/or depression. Using a randomized between-group design subjects participated in the AR experience or the AR experience plus frontal gamma asymmetry neurofeedback integrated into the experience. Self-reported mood state and resting-state EEG were recorded before and after the AR intervention for both groups. Participants also reported on engagement and perceived use of the experience as a stress and coping tool. EEG activity was analyzed as a function of the frontal, midline, and parietal scalp regions, and with sLORETA current source density estimates of anterior cingulate and insular cortical regions of interest. Results demonstrated that both versions of the AR meditation significantly reduced negative mood and increased positive mood. The changes in resting state EEG were also comparable between groups, with some trending differences observed, in line with existing research on open heart and other loving-kindness and compassion-based meditations. Engagement was favorable for both versions of the AR experience, with higher levels of engagement reported with the addition of neurofeedback. These results provide early support for the therapeutic potential of AR-integrated meditations as a tool for the self-regulation of mood and emotion, and sets the stage for more research and development into health and wellness-promoting AR applications.
C1 [Viczko, Jeremy] Univ Victoria, Dept Psychol, Victoria, BC, Canada.
   [Tarrant, Jeff; Jackson, Ray] Univ Oregon, Eugene, OR 97331 USA.
   [Tarrant, Jeff] NeuroMeditat Inst, Eugene, OR USA.
C3 University of Victoria; University of Oregon
RP Viczko, J (corresponding author), Univ Victoria, Dept Psychol, Victoria, BC, Canada.; Tarrant, J (corresponding author), Univ Oregon, Eugene, OR 97331 USA.
EM jeff@neuromeditationinstitute.com
CR Amihai I, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102990
   Arvanitis TN, 2009, PERS UBIQUIT COMPUT, V13, P243, DOI 10.1007/s00779-007-0187-7
   Athanas AJ, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/12617
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baumel A, 2019, J MED INTERNET RES, V21, DOI 10.2196/14567
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Benyoucef Y, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00491
   Bhayee Sheffy, 2016, BMC Psychol, V4, P60
   Blankertz B, 2010, NEUROIMAGE, V51, P1303, DOI 10.1016/j.neuroimage.2010.03.022
   Bonnstetter R.J., 2015, NeuroRegulation, V2, P70, DOI DOI 10.15540/NR.2.2.70
   Bouchard Stephane., 2007, Handbook of Exposure Therapies Internet, P347, DOI [10.1016/B978-012587421-2/50017-X, DOI 10.1016/B978-012587421-2/50017-X]
   Brown KW, 2003, J PERS SOC PSYCHOL, V84, P822, DOI 10.1037/0022-3514.84.4.822
   Cahn BR, 2006, PSYCHOL BULL, V132, P180, DOI 10.1037/0033-2909.132.2.180
   Carissoli C, 2015, CYBERPSYCH BEH SOC N, V18, P46, DOI 10.1089/cyber.2014.0062
   Carson SH, 2005, CREATIVITY RES J, V17, P37, DOI 10.1207/s15326934crj1701_4
   Cebolla A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01521
   Chen ACN, 2008, NEUROIMAGE, V41, P561, DOI 10.1016/j.neuroimage.2007.12.064
   Chow T, 2017, MINDFULNESS, V8, P572, DOI 10.1007/s12671-016-0631-8
   Craig AD, 2009, NAT REV NEUROSCI, V10, P59, DOI 10.1038/nrn2555
   Pascual-Marqui RD, 2007, Arxiv, DOI [arXiv:0710.3341, DOI 10.48550/ARXIV.0710.3341]
   Dahl CJ, 2015, TRENDS COGN SCI, V19, P515, DOI 10.1016/j.tics.2015.07.001
   Davelaar EJ, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00402
   DAVIDSON RJ, 1992, BRAIN COGNITION, V20, P125, DOI 10.1016/0278-2626(92)90065-T
   De Buck S, 2005, IEEE T MED IMAGING, V24, P1512, DOI 10.1109/TMI.2005.857661
   Dennis TA, 2010, BIOL PSYCHOL, V85, P456, DOI 10.1016/j.biopsycho.2010.09.008
   Eberth J, 2012, MINDFULNESS, V3, P174, DOI 10.1007/s12671-012-0101-x
   Engström M, 2010, J ALTERN COMPLEM MED, V16, P597, DOI 10.1089/acm.2009.0309
   Farb NAS, 2007, SOC COGN AFFECT NEUR, V2, P313, DOI 10.1093/scan/nsm030
   Fell J, 2010, MED HYPOTHESES, V75, P218, DOI 10.1016/j.mehy.2010.02.025
   Ferrarelli F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073417
   Flett JAM, 2019, MINDFULNESS, V10, P863, DOI 10.1007/s12671-018-1050-9
   Fox KCR, 2016, NEUROSCI BIOBEHAV R, V65, P208, DOI 10.1016/j.neubiorev.2016.03.021
   Fox KCR, 2014, NEUROSCI BIOBEHAV R, V43, P48, DOI 10.1016/j.neubiorev.2014.03.016
   Gale A, 2001, PERS INDIV DIFFER, V30, P449, DOI 10.1016/S0191-8869(00)00036-2
   Garrison KA, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00440
   Giglioli IAC, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/862942
   Gilbert P, 2006, CLIN PSYCHOL PSYCHOT, V13, P353, DOI 10.1002/cpp.507
   Gorini A, 2010, STUD HEALTH TECHNOL, V154, P39, DOI 10.3233/978-1-60750-561-7-39
   Gotlib IH, 1998, COGNITION EMOTION, V12, P449, DOI 10.1080/026999398379673
   Goyal M, 2014, JAMA INTERN MED, V174, P357, DOI 10.1001/jamainternmed.2013.13018
   Grossman P, 2004, J PSYCHOSOM RES, V57, P35, DOI 10.1016/S0022-3999(03)00573-7
   Guger C, 2003, IEEE T NEUR SYS REH, V11, P145, DOI 10.1109/TNSRE.2003.814481
   HOAGLIN DC, 1987, J AM STAT ASSOC, V82, P1147, DOI 10.1080/01621459.1987.10478551
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hutcherson CA, 2008, EMOTION, V8, P720, DOI 10.1037/a0013237
   Kabat-Zinn J., 2013, FULL CATASTROPHE LIV
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   Kop WJ, 2011, BIOL PSYCHOL, V86, P230, DOI 10.1016/j.biopsycho.2010.12.003
   Kovacevic N, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130129
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Lane A.M., 2007, Mood and Human Performance: Conceptual, Measurement, and Applied Issues, P119
   Laufs H, 2003, P NATL ACAD SCI USA, V100, P11053, DOI 10.1073/pnas.1831638100
   Laver KE, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub3
   Lezak MD, 2004, Neuropsychological Assessment, DOI DOI 10.1017/S0033291718001599
   Lutz A, 2004, P NATL ACAD SCI USA, V101, P16369, DOI 10.1073/pnas.0407401101
   Lutz A, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001897
   Lutz A, 2008, TRENDS COGN SCI, V12, P163, DOI 10.1016/j.tics.2008.01.005
   Malbos E, 2013, PRESSE MED, V42, P1442, DOI 10.1016/j.lpm.2013.01.065
   Mantini D, 2007, P NATL ACAD SCI USA, V104, P13170, DOI 10.1073/pnas.0700668104
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Marzbani H, 2016, BASIC CLIN NEUROSCI, V7, P143, DOI 10.15412/J.BCN.03070208
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Motraghi TE, 2014, J CLIN PSYCHOL, V70, P197, DOI 10.1002/jclp.22051
   Northoff G, 2006, NEUROIMAGE, V31, P440, DOI 10.1016/j.neuroimage.2005.12.002
   Nyklícek I, 2013, HEALTH PSYCHOL, V32, P1110, DOI 10.1037/a0032200
   Oakes TR, 2004, HUM BRAIN MAPP, V21, P257, DOI 10.1002/hbm.20004
   Olbrich S, 2011, J PSYCHOPHYSIOL, V25, P190, DOI 10.1027/0269-8803/a000061
   Ozbek C. S., 2004, SPIE, V5291
   Pallavicini F, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02763
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Potts D, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P583, DOI 10.1145/3325480.3326584
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Ramsoy TZ, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00138
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Seabrook E, 2020, J MED INTERNET RES, V22, DOI 10.2196/16106
   Sedlmeier P, 2012, PSYCHOL BULL, V138, P1139, DOI 10.1037/a0028168
   Silva BM, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/i2ct45611.2019.9033650
   Singer T, 2004, SCIENCE, V303, P1157, DOI 10.1126/science.1093535
   Singer T, 2009, TRENDS COGN SCI, V13, P334, DOI 10.1016/j.tics.2009.05.001
   Spitzer RL, 2006, ARCH INTERN MED, V166, P1092, DOI 10.1001/archinte.166.10.1092
   Sutton SK, 1997, PSYCHOL SCI, V8, P204, DOI 10.1111/j.1467-9280.1997.tb00413.x
   Tang V, 2015, NEUROLOGY, V85, P1100, DOI 10.1212/WNL.0000000000001967
   Tang YY, 2009, P NATL ACAD SCI USA, V106, P8865, DOI 10.1073/pnas.0904031106
   Tarrant J., 2018, NeuroRegulation, V5, P57, DOI [10.15540/nr.5.2.57, DOI 10.15540/NR.5.2.57]
   Tarrant J., 2017, Meditation interventions to rewire the brain: Integrating neuroscience strategies for ADHD, anxiety, depression
   Tarrant J., 2017, CLIN COMPANION QEEG
   Tarrant J. M., 2015, 1 PRAN HEAL RES DEV
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Teasdale, 2002, MINDFULNESS BASED CO
   Thompson M., 2003, NEUROFEEDBACK BOOK
   Warden-Smith J, 2017, OPEN LIFE SCI, V12, P51, DOI 10.1515/biol-2017-0006
   Waterworth J, 2014, PALGRAVE PIVOT, P1, DOI 10.1057/9781137431677
   Williams JMG, 2008, COGNITIVE THER RES, V32, P721, DOI 10.1007/s10608-008-9204-z
   Zhou HX, 2020, NEUROIMAGE, V206, DOI 10.1016/j.neuroimage.2019.116287
   Zich C, 2015, NEUROIMAGE, V114, P438, DOI 10.1016/j.neuroimage.2015.04.020
NR 96
TC 8
Z9 8
U1 7
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 22
PY 2021
VL 2
AR 618381
DI 10.3389/frvir.2021.618381
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SU1
UT WOS:001021816400001
OA gold
DA 2024-07-18
ER

PT J
AU Nagele, AN
   Bauer, V
   Healey, PGT
   Reiss, JD
   Cooke, H
   Cowlishaw, T
   Baume, C
   Pike, C
AF Nagele, Anna N.
   Bauer, Valentin
   Healey, Patrick G. T.
   Reiss, Joshua D.
   Cooke, Henry
   Cowlishaw, Tim
   Baume, Chris
   Pike, Chris
TI Interactive Audio Augmented Reality in Participatory Performance
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE audio augmented reality; 3D audio; audio-only game; experience design;
   immersive theater; interaction design; participatory performance;
   interactive storytelling
ID MOBILE
AB Interactive Audio Augmented Reality (AAR) facilitates collaborative storytelling and human interaction in participatory performance. Spatial audio enhances the auditory environment and supports real-time control of media content and the experience. Nevertheless, AAR applied to interactive performance practices remains under-explored. This study examines how audio human-computer interaction can prompt and support actions, and how AAR can contribute to developing new kinds of interactions in participatory performance.This study investigates an AAR participatory performance based on the theater and performance practice by theater maker Augusto Boal. It draws from aspects of multi-player audio-only games and interactive storytelling. A user experience study of the performance shows that people are engaged with interactive content and interact and navigate within the spatial audio content using their whole body. Asymmetric audio cues, playing distinctive content for each participant, prompt verbal and non-verbal communication. The performative aspect was well-received and participants took on roles and responsibilities within their group during the experience.
C1 [Nagele, Anna N.; Healey, Patrick G. T.; Reiss, Joshua D.] Queen Mary Univ London, Media & Arts Technol, Elect Engn & Comp Sci, London, England.
   [Bauer, Valentin] Univ Paris Saclay, LISN, CNRS, Orsay, France.
   [Cooke, Henry; Cowlishaw, Tim; Baume, Chris; Pike, Chris] BBC Res & Dev, London, England.
C3 University of London; Queen Mary University London; Universite Paris
   Saclay; Universite Paris Cite; Centre National de la Recherche
   Scientifique (CNRS)
RP Nagele, AN (corresponding author), Queen Mary Univ London, Media & Arts Technol, Elect Engn & Comp Sci, London, England.; Bauer, V (corresponding author), Univ Paris Saclay, LISN, CNRS, Orsay, France.
EM a.n.nagele@qmul.ac.uk; valentin.bauer@limsi.fr
RI Cooke, Henry/IWU-8470-2023
OI BAUER, Valentin/0000-0002-3922-7507
CR Albrecht R., 2011, P INT SOUND WORKSH E, P7
   Ames M. G., 2013, P C COMP SUPP COOP W, P1487
   [Anonymous], 2007, P 2 AUDIO MOSTLY C
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Bluff A, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P279, DOI 10.1145/3322276.3322313
   Boal A., 2002, GAMES ACTORS NONACTO, P301
   Brungart DS, 2006, J AUDIO ENG SOC, V54, P32
   Chatzidimitris T., 2016, 2016 18 MEDITERRANEA, P1, DOI [10.1109/MELCON.2016.7495414, DOI 10.1109/MELCON.2016.7495414]
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Drewes T. M., 2000, SLEUTH AUDIO EXPERIE
   Eckel G., 2003, LISTEN AUGMENTING EV
   Engel I., 2017, 24 INT C SOUND VIBR
   Esparza RPG, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300735
   Galpin A., 2017, HLTH DESIGN UNDERSTA
   Geronazzo M, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/1463204
   Gibbons A., 2014, CAMBRIDGE HDB STYLIS, P410
   Glaser B, 1967, Discovery of grounded theory strategies for qualitative research, DOI [10.4324/9780203793206, DOI 10.4324/9780203793206]
   Gorzel M., 2019, AUD ENG SOC INT C IM, P1
   Härmä A, 2004, J AUDIO ENG SOC, V52, P618
   Hugill A., 2016, EXPANDING HORIZON EL, P355
   Klich R, 2017, CONTEMP THEATRE REV, V27, P366, DOI 10.1080/10486801.2017.1343247
   Kochhar-Lindgren K, 2002, ANGELAKI, V7, P217, DOI 10.1080/09697250220142137
   Lyons K., 2000, P INT C AUD DISPL BO
   Mariette N., 2009, EAA S AURALIZATION, P1
   Mariette Nicholas, 2013, Human Factors Research in Audio Augmented Reality, P11, DOI [10.1007/978-1-4614-4205-92, DOI 10.1007/978-1-4614-4205-92]
   McGinley P., 2006, PERFORM ARTS J, V28, P52, DOI [10.1162/152028106775329642, DOI 10.1162/152028106775329642]
   Moustakas N., 2011, AES 130 CONVENTION, P2
   Peltola M., 2009, AES 35 INT C AUD GAM, P6
   Playlines, 2019, CONSEQUENCES
   Rovithis E., 2018, ASTROSONIC ED AUDIO, P8
   Rovithis E, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3040073
   Saltz DavidZ., 2001, Theatre Topics, V11, P107, DOI DOI 10.1353/TT.2001.0017
   Sawhney N., 2000, ACM Transactions on Computer-Human Interaction, V7, P353, DOI 10.1145/355324.355327
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Shin D, 2019, INFORM COMMUN SOC, V22, P1212, DOI 10.1080/1369118X.2017.1411519
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Tikander M, 2009, J AUDIO ENG SOC, V57, P430
   Vazquez-Alvarez Y, 2012, PERS UBIQUIT COMPUT, V16, P987, DOI 10.1007/s00779-011-0459-0
   White G, 2012, THEATRE RES INT, V37, P221, DOI 10.1017/S0307883312000880
   Wilken R, 2014, MOBILE STORY: NARRATIVE PRACTICES WITH LOCATIVE TECHNOLOGIES, P175
   Zimmermann A, 2008, USER MODEL USER-ADAP, V18, P389, DOI 10.1007/s11257-008-9049-x
NR 41
TC 10
Z9 11
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 12
PY 2021
VL 1
AR 610320
DI 10.3389/frvir.2020.610320
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AA0
UT WOS:001019278700001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Travaglini, A
   Brand, E
   Meier, P
   Christ, O
AF Travaglini, Alessio
   Brand, Esther
   Meier, Pascal
   Christ, Oliver
TI Job relevance or perceived usefulness? What features of immersive
   virtual reality software predict intention to use in a future
   project-based-learning scenario: a mixed method approach
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive virtual reality applications; project-based learning;
   intention to use; perceived usefulness; job relevance; mixed methods
ID SIMULATOR
AB Not only since COVID-19, the topic of decentralized working and learning methods is becoming increasingly important for various reasons. New virtual reality technologies enable learning in immersive scenarios, which is good when learning from home is advised. However, not all immersive Virtual Reality (iVR) training incorporates learning systems that support complex, realistic, practical tasks that lead to a product or enable acquiring knowledge and life-enhancing skills like project-based learning. Although there are many iVR applications available that support project management, the specific features of these applications that lead to the intention to use (and therefore life-enhancing skills) have yet to be discovered. In this exploratory mixed-method study, we investigated the question of the importance of perceived usefulness (PU) and job relevance (JR) as predictors of intention to use (ItU) in a selection of immersive iVR application features. We started with market research and aggregated 88 software features in 13 categories of 34 professional iVR applications. After an expert selection and ranking procedure, a survey was developed. After deriving from the TAM 2 model and with a sample n = 103, we computed the relationship of JR, PU, and ItU. Although high values were generally observed, we found that the importance of PU is higher than JR when it comes to ItU. Limitations of the study are discussed, and suggestions for further research are given.
C1 [Travaglini, Alessio] Swiss Post Ltd, Bern, Switzerland.
   [Brand, Esther] HR Campus, Dubendorf, Switzerland.
   [Meier, Pascal; Christ, Oliver] Univ Appl Sci & Arts Northwestern Switzerland, Inst Humans Complex Syst, Sch Appl Psychol, Olten, Switzerland.
C3 FHNW University of Applied Sciences & Arts Northwestern Switzerland
RP Christ, O (corresponding author), Univ Appl Sci & Arts Northwestern Switzerland, Inst Humans Complex Syst, Sch Appl Psychol, Olten, Switzerland.
EM oliver.christ@fhnw.ch
CR Ahmed I. Y. S., 2017, Media Watch J. Commun, V8, P208, DOI [10.15655/mw/2017/v8i2/49010, DOI 10.15655/MW/2017/V8I2/49010]
   AL-RAHMI WaleedMugahed., 2014, Asian Social Science, V10, P210, DOI DOI 10.5539/ASS.V10N8P210
   Alhalabi WS, 2016, BEHAV INFORM TECHNOL, V35, P919, DOI 10.1080/0144929X.2016.1212931
   Arbenz D., 2016, World Fed. Occup. Ther. Bull, V72, P43, DOI [10.1080/14473828.2016.1151680, DOI 10.1080/14473828.2016.1151680]
   Barron B., 2008, Powerful learning: What we know about teaching for understanding, P11
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen CH, 2019, EDUC RES REV-NETH, V26, P71, DOI 10.1016/j.edurev.2018.11.001
   Chu SKW, 2017, 21ST CENTURY SKILLS DEVELOPMENT THROUGH INQUIRY-BASED LEARNING: FROM THEORY TO PRACTICE, P1, DOI 10.1007/978-981-10-2481-8
   Coban M, 2022, EDUC RES REV-NETH, V36, DOI 10.1016/j.edurev.2022.100452
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cohen L., 2018, Augmented and virtual reality in operations, P1
   Creswell J. W., 2007, DESIGNING CONDUCTING
   Davis F. D., 1985, A technology acceptance model for empirically testing new end-user information systems: Theory and results, DOI DOI 10.1016/S0378-7206(01)00143-4
   Di Natale AF, 2020, BRIT J EDUC TECHNOL, V51, P2006, DOI 10.1111/bjet.13030
   Fishbein M., 1980, UNDERSTANDING ATTITU
   Grimm P., 2013, Virtual und Augmented Reality (VR/AR) - Grundlagen und Methoden der Virtuellen und Augmentierten Realitat, P97
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Huang XY, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13094639
   Jenkins DG, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229345
   Kunst A., 2019, In welchen Bereichen werden Virtual-Reality-Brillen Ihrer Meinung nach hauptsachlich Anwendung finden?
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lang B., 2020, Road to VR
   Lokka IE, 2019, INT J DIGIT EARTH, V12, P137, DOI 10.1080/17538947.2017.1349842
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Marston H. R., 2013, Serious games and virtual worlds in education, P241
   Prado PHM, 2014, REV BRASIL MARK, V13, P4, DOI 10.5585/remark.v13i4.2739
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Passig D, 2016, COMPUT EDUC, V95, P296, DOI 10.1016/j.compedu.2016.01.009
   Pellas N, 2020, IEEE T LEARN TECHNOL, V13, P748, DOI 10.1109/TLT.2020.3019405
   Phé V, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1740
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rojas-Sánchez MA, 2023, EDUC INF TECHNOL, V28, P155, DOI 10.1007/s10639-022-11167-5
   Santos A, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P294, DOI 10.1145/3132272.3132277
   Schinauer T., 2009, Proceedings of Fechner days, P299
   Sobel M.E., 1982, SOCIOLOGICAL METHODO, P290, DOI DOI 10.2307/270723
   Sugand K, 2015, ACTA ORTHOP, V86, P695, DOI 10.3109/17453674.2015.1071111
   Super Data Staff, 2020, Super data XR Q1 2020 update. Super data perspectives
   Tangmanee C., 2019, International Journal of Research in Business and Social Science, V8, P20, DOI DOI 10.20525/IJRBS.V8I1.183
   Thomas J.W., 1999, Project-based learning: A handbook for middle and high school teachers
   Våpenstad C, 2017, MINIM INVASIV THER, V26, P346, DOI 10.1080/13645706.2017.1319866
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Webster R, 2016, INTERACT LEARN ENVIR, V24, P1319, DOI 10.1080/10494820.2014.994533
   Wróblewska D, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12114360
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Zhang YQ, 2022, BEHAV SCI-BASEL, V12, DOI 10.3390/bs12100361
   Ziegler Cyrill, 2020, Human Interaction, Emerging Technologies and Future Applications II. Proceedings of the 2nd International Conference on Human Interaction and Emerging Technologies: Future Applications (IHIET - AI 2020). Advances in Intelligent Systems and Computing (AISC 1152), P328, DOI 10.1007/978-3-030-44267-5_49
NR 47
TC 0
Z9 0
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 14
PY 2023
VL 4
AR 1286877
DI 10.3389/frvir.2023.1286877
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DL5Z5
UT WOS:001132224500001
OA gold
DA 2024-07-18
ER

PT J
AU Lisle, L
   Davidson, K
   Gitre, EJK
   North, C
   Bowman, DA
AF Lisle, Lee
   Davidson, Kylie
   Gitre, Edward J. K.
   North, Chris
   Bowman, Doug A.
TI Different realities: a comparison of augmented and virtual reality for
   the sensemaking process
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; virtual reality; immersive analytics; visualization
   techniques; human-centered interaction; sensemaking
ID MIXED REALITY
AB Analysts perform sensemaking on large complex multimedia datasets in order to extract concepts, themes, and other kinds of insights from them. Immersive analytics, in particular, puts users in virtual environments that allow them to explore data in a unique way where they can interact and move through the data. Previous research using virtual reality immersive analytics tools found users wanting to refer to real-world objects or understand the physical world around them while continuing to perform their analysis. Therefore, we designed and ran a comparative study looking at the tradeoffs between virtual and augmented reality for our immersive analytics approach: Immersive Space to Think. Through two mixed-methods studies we found that virtual reality affords users a space where users can focus more on their task, but augmented reality allows them to use various real-world tools that can increase user satisfaction. In future immersive analytics tools, we recommend a blend of the two-augmented virtuality-with pass-through portals which allow users to see various real-world tools, such as whiteboards or desks and keyboards, while still giving themselves a space to focus.
C1 [Lisle, Lee; Davidson, Kylie; Bowman, Doug A.] Virginia Tech, Ctr Human Comp Interact, Dept Comp Sci, Blacksburg, VA 24061 USA.
   [Gitre, Edward J. K.] Virginia Tech, Ctr Human Comp Interact, Dept Hist, Blacksburg, VA USA.
   [North, Chris] Virginia Tech, Sanghani Ctr, Dept Comp Sci, Blacksburg, VA USA.
C3 Virginia Polytechnic Institute & State University; Virginia Polytechnic
   Institute & State University; Virginia Polytechnic Institute & State
   University
RP Lisle, L (corresponding author), Virginia Tech, Ctr Human Comp Interact, Dept Comp Sci, Blacksburg, VA 24061 USA.
EM llisle@vt.edu
RI Gitre, Edward J.K./M-2906-2016
FU Office of Naval Research; NSF; Global Impact Award from Google; Alfred
   P. Sloan Foundation;  [CSSI-2003387]
FX This work was supported in part by a grant fromtheOffice of Naval
   Research and NSF grant #CSSI-2003387. This publication uses data
   generated via the Zooniverse.org platform, development of which is
   funded by generous support, including a Global Impact Award from Google,
   and by a grant from the Alfred P. Sloan Foundation. The funders had no
   role in the study design, data collection, analysis, interpretation of
   data, the writing of this article, or the decision to submit it for
   publication.
CR Adams H, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P792, DOI 10.1109/VR51125.2022.00101
   Ancona D., 2012, HDB TEACHING LEADERS, P3, DOI DOI 10.5465/AMLE.2011.0007
   Andrews C, 2013, IEEE T VIS COMPUT GR, V19, P2207, DOI 10.1109/TVCG.2013.205
   Andrews C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P55
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bruder G, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P75, DOI 10.1109/3DUI.2009.4811208
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Davidson K., 2022, IEEE Transactions on Visualization and Computer Graphics
   Elm W., 2005, P HUM FACT ERG SOC A, V49, P297
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Galati A, 2021, IEEE T VIS COMPUT GR, V27, P2714, DOI 10.1109/TVCG.2021.3067693
   George C, 2020, INT SYM MIX AUGMENT, P412, DOI 10.1109/ISMAR50242.2020.00067
   Giovannelli A., 2022, 2022 IEEE INT S MIX
   Gitre E, 2018, AM SOLDIER COLLABORA
   Gold L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P428, DOI 10.1109/VR50410.2021.00066
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Kobayashi D., 2021, S SPAT US INT, P1
   Kudo Yoshiki, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3486950
   Lages WS, 2019, INT SYM MIX AUGMENT, P301, DOI 10.1109/ISMAR.2019.00028
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lee C, 2010, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2010.5444820
   Lee JoonHyub., 2021, P S VLSI CIRC KYOT J, P1, DOI [DOI 10.23919/VLSICIRCUITS52068.2021.9492444, 10.23919/VLSICircuits 52068.2021.9492444]
   Lisle L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P331, DOI [10.1109/VRW50115.2020.0-203, 10.1109/VRW50115.2020.00073]
   Lisle L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI 10.1109/VR50410.2021.00077
   Luboschik M, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P47, DOI 10.1145/3009939.3009947
   Luo W., 2022, CHI C HUMAN FACTORS, P1
   Marriott K., 2018, IMMERSIVE ANAL
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Olaosebikan M., 2022, CHI C HUMAN FACTORS, P1
   Park H, 2023, CLOTH TEXT RES J, V41, P91, DOI 10.1177/0887302X21994287
   Ping JM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1124, DOI [10.1109/VR.2019.8798174, 10.1109/vr.2019.8798174]
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Riegler A., 2020, XR ISS, P11
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Satriadi Kadek Ananta, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427329
   Schwandt DR, 2005, ACAD MANAG LEARN EDU, V4, P176, DOI 10.5465/AMLE.2005.17268565
   Scott S. D., 2004, Computer Supported Cooperative Work Conference Proceedings, P294, DOI 10.1145/1031607.1031655
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Skarbez R, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00082
   Steffen JH, 2019, J MANAGE INFORM SYST, V36, P683, DOI 10.1080/07421222.2019.1628877
   Suso-Ribera C, 2019, CYBERPSYCH BEH SOC N, V22, P31, DOI 10.1089/cyber.2017.0672
   Voit A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300737
   Weick KE, 2005, ORGAN SCI, V16, P409, DOI 10.1287/orsc.1050.0133
   Ying Yang, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3567741
   Zhang L., 2019, 2019 11 INT C VIRTUA, P1
NR 51
TC 1
Z9 1
U1 5
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 9
PY 2023
VL 4
AR 1177855
DI 10.3389/frvir.2023.1177855
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA P8QN7
UT WOS:001053262800001
OA gold
DA 2024-07-18
ER

PT J
AU Bilello, D
   Swancott, LJ
   Kloess, JA
   Heyes, SB
AF Bilello, Delfina
   Swancott, Lucy J.
   Kloess, Juliane A.
   Heyes, Stephanie Burnett
TI Adolescent risk-taking and decision making: a qualitative investigation
   of a virtual reality experience of gangs and violence
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive virtual reality; theatre-in-education; tech-in-education;
   criminal exploitation; county lines; antisocial behaviour; peer
   pressure; gang involvement
ID PEER INFLUENCE; NEUROSCIENCE PERSPECTIVE; MORAL EMOTIONS; YOUNG-PEOPLE;
   BEHAVIOR; PREVENTION; DELINQUENCY; PERCEPTIONS; PREDICTORS; PSYCHOLOGY
AB Introduction: Gang involvement poses serious risks to young people, including antisocial and criminal behaviour, sexual and criminal exploitation, and mental health problems. There is a need for research-informed development of preventive interventions. To this end, we conducted a qualitative study of young people's responses to an educational virtual reality (VR) experience of an encounter with a gang, to understand young people's decisions, emotions and consequences.Methods: Young people (N = 24 aged 13-15, 11 female, 13 male) underwent the VR experience followed by semi-structured focus group discussions. Questions focused on virtual decision-making (motivations, thoughts, feelings, consequences) and user experiences of taking part. Data were analysed using Thematic Analysis.Results: Three themes were developed to represent how participants' perceptions of the gang, themselves, and the context influenced virtual decisions. Social pressure from the gang competed with participants' wish to stand by their morals and establish individual identity. The VR setting, through its escalating events and plausible characters, created an "illusion of reality" and sense of authentic decisions and emotions, yielding insights for real-life in a safe, virtual environment.Discussion: Findings shed light on processes influencing adolescent decision-making in a virtual context of risk-taking, peer pressure and contact with a gang. Particularly, they highlight the potential for using VR in interventions with young people, given its engaging and realistic nature.
C1 [Bilello, Delfina; Heyes, Stephanie Burnett] Univ Birmingham, Sch Psychol, Birmingham, England.
   [Swancott, Lucy J.] Univ Leicester, Dept Populat Hlth Sci, Leicester, England.
   [Kloess, Juliane A.] Univ Edinburgh, Sch Hlth Social Sci, Edinburgh, Scotland.
C3 University of Birmingham; University of Leicester; University of
   Edinburgh
RP Heyes, SB (corresponding author), Univ Birmingham, Sch Psychol, Birmingham, England.
EM s.burnettheyes@bham.ac.uk
RI Kloess, Juliane/ABA-6520-2021; Burnett Heyes, Stephanie/ABC-3156-2021;
   Clapcott, Sussana/JPL-6942-2023
OI Kloess, Juliane/0000-0002-8342-7880; Burnett Heyes,
   Stephanie/0000-0002-9049-9559; Swancott, Lucy/0000-0002-8586-3192
FU British Academy/Leverhulme Small Research Grant - Department for
   Business, Energy and Industrial Strategy [SRG19\190169]
FX This research was funded by a British Academy/Leverhulme Small Research
   Grant (SRG19\190169) supported by the Department for Business, Energy
   and Industrial Strategy to SBH and JAK.
CR Abdul Rahim E., 2012, P 24 AUSTR COMP HUM, DOI [10.1145/2414536.2414537, DOI 10.1145/2414536.2414537]
   Adams G., 2003, Blackwell Handbook of Adolescence
   Adler K, 2019, INT J QUAL METH, V18, DOI 10.1177/1609406919887274
   Allen G., 2021, KNIFE CRIME STAT HOU
   Allen JP, 2006, DEV PSYCHOPATHOL, V18, P155, DOI 10.1017/S0954579406060093
   Annan LG, 2022, J COMMUNITY PSYCHOL, V50, P2198, DOI 10.1002/jcop.22767
   Ashton SA, 2020, J CRIM PSYCHOL, V10, P277, DOI 10.1108/JCP-06-2020-0020
   Bandura A., 2006, INSURGENT TERRORISM, P85
   Barreda-Angeles M, 2021, COMPUT EDUC, V161, DOI 10.1016/j.compedu.2020.104065
   Benish-Weisman M, 2015, J ADOLESCENCE, V44, P21, DOI 10.1016/j.adolescence.2015.06.008
   Blankenstein NE, 2016, DEV NEUROPSYCHOL, V41, P77, DOI 10.1080/87565641.2016.1158265
   Boal A., 1993, Theater of the oppressed
   Brantingham PJ, 2021, J QUANT CRIMINOL, V37, P953, DOI 10.1007/s10940-020-09479-1
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Braun V, 2013, Success Qual Res, V1st
   Brechwald WA, 2011, J RES ADOLESCENCE, V21, P166, DOI 10.1111/j.1532-7795.2010.00721.x
   Cavalca E, 2013, DRUG ALCOHOL DEPEN, V129, P163, DOI 10.1016/j.drugalcdep.2012.09.020
   Chein J, 2011, DEVELOPMENTAL SCI, V14, pF1, DOI 10.1111/j.1467-7687.2010.01035.x
   Children's Commissioner, 2019, CHILDR COMM ENGL ANN
   Children's Society, 2022, DISR EXPL PROGR
   Chrysoulakis AP, 2022, EUR J CRIMINOL, V19, P282, DOI 10.1177/1477370819896216
   Clayman S, 2012, POLIC SOC, V22, P460, DOI 10.1080/10439463.2011.641550
   Cruwys T, 2021, J PERS SOC PSYCHOL, V120, P57, DOI 10.1037/pspi0000243
   de Boer A, 2017, J RES ADOLESCENCE, V27, P878, DOI 10.1111/jora.12320
   DeLay D, 2022, INT J BEHAV DEV, V46, P208, DOI 10.1177/01650254221084102
   Densley JA, 2017, PSYCHOL VIOLENCE, V7, P242, DOI 10.1037/vio0000054
   Duell N, 2018, J YOUTH ADOLESCENCE, V47, P1052, DOI 10.1007/s10964-017-0752-y
   Eisenberg N, 2000, ANNU REV PSYCHOL, V51, P665, DOI 10.1146/annurev.psych.51.1.665
   ESBENSEN FA, 2011, J SCH VIOLENCE, V0010
   Forsyth CJ, 2018, CRIM JUSTICE STUD, V31, P178, DOI 10.1080/1478601X.2018.1435618
   Foulkes L, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12666
   Frisby-Osman S, 2020, YOUTH JUSTICE, V20, P93, DOI 10.1177/1473225419893779
   Fryda CM, 2015, J SCH NURS, V31, P167, DOI 10.1177/1059840514544125
   FURBY L, 1992, DEV REV, V12, P1, DOI 10.1016/0273-2297(92)90002-J
   Garandeau CF, 2022, J CLIN CHILD ADOLESC, V51, P515, DOI 10.1080/15374416.2020.1846541
   Graham L, 2018, J YOUTH STUD, V21, P324, DOI 10.1080/13676261.2017.1380301
   Grigorenko E. L., 2011, HDB JUVENILE FORENSI
   Haddad ADM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01476
   Halldorsson B, 2021, J CHILD PSYCHOL PSYC, V62, P584, DOI 10.1111/jcpp.13400
   HM Government, 2022, SAFEGUARDING CHILDRE
   HM Government, 2015, PREVENTING YOUTH VIO
   Home Office, 2015, HAV YOU GOT WHAT IT
   Home Office, 2018, CRIM EXPL CHILDR VUL
   Hsieh MS, 2010, J MED BIOL ENG, V30, P57
   Jackson Anthony., 2013, Learning through Theatre: The Changing Face of Theatre in Education
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   Kelly SE, 2012, J PSYCHOSOC NURS MEN, V50, P20, DOI 10.3928/02793695-20120906-99
   Klein MalcolmW., 2001, The Eurogang Paradox: Street Gangs and Youth Groups in the U. S. and Europe
   Knoll LJ, 2015, PSYCHOL SCI, V26, P583, DOI 10.1177/0956797615569578
   Kozlov MD, 2010, CYBERPSYCH BEH SOC N, V13, P711, DOI 10.1089/cyber.2009.0310
   Krahé B, 2009, J COMMUNITY APPL SOC, V19, P321, DOI 10.1002/casp.1009
   Krettenauer T, 2014, J YOUTH ADOLESCENCE, V43, P583, DOI 10.1007/s10964-013-9994-5
   Kroger J., 2005, Blackwell handbook of adolescence, P205, DOI DOI 10.1002/9780470756607
   Krohn MD, 2011, CRIMINOLOGY, V49, P991, DOI 10.1111/j.1745-9125.2011.00250.x
   Landsheer JA, 2005, ADOLESCENCE, V40, P729
   Lardén M, 2006, PSYCHOL CRIME LAW, V12, P453, DOI 10.1080/10683160500036855
   MAK AS, 1990, CRIM JUSTICE BEHAV, V17, P215, DOI 10.1177/0093854890017002005
   Malti T., 2013, Adolescent emotions: Development, morality, and adaptation: New directions for youth development
   Malti T., 2014, Handbook of moral development, V2nd, P163, DOI [10.4324/9780203581957.ch8, DOI 10.4324/9780203581957.CH8]
   Malti T, 2013, J RES ADOLESCENCE, V23, P389, DOI 10.1111/jora.12005
   Martinez AG, 2014, PERS SOC PSYCHOL B, V40, P1659, DOI 10.1177/0146167214554915
   May H, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.609958
   Moshman D, 2011, ADOLESCENT RATIONALITY AND DEVELOPMENT: COGNITION, MORALITY, AND IDENTITY, THIRD EDITION, P1
   Moyle L, 2019, J DRUG ISSUES, V49, P739, DOI 10.1177/0022042619861938
   Myyry L, 2010, J MORAL EDUC, V39, P213, DOI 10.1080/03057241003754955
   Nelson EE, 2005, PSYCHOL MED, V35, P163, DOI 10.1017/S0033291704003915
   NEWMAN PR, 1976, ADOLESCENCE, V11, P261
   Niebieszczanski R, 2015, PSYCHOL CRIME LAW, V21, P589, DOI 10.1080/1068316X.2015.1008476
   Overbeek G, 2001, J YOUTH ADOLESCENCE, V30, P401, DOI 10.1023/A:1010441131941
   Ramirez EJ, 2018, ETHICS INF TECHNOL, V20, P249, DOI 10.1007/s10676-018-9473-5
   Round Midnight Ltd, 2019, VIRT DEC GANGS 1 0
   Rousseau C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104704
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sommer M, 2014, SOC NEUROSCI-UK, V9, P452, DOI 10.1080/17470919.2014.933714
   Steinberg L, 2008, DEV REV, V28, P78, DOI 10.1016/j.dr.2007.08.002
   Steinberg L, 2007, DEV PSYCHOL, V43, P1531, DOI 10.1037/0012-1649.43.6.1531
   Stets JE, 2011, SOC PSYCHOL QUART, V74, P192, DOI 10.1177/0190272511407621
   Stuewig J, 2010, J RES PERS, V44, P91, DOI 10.1016/j.jrp.2009.12.005
   Sütfeld LR, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00122
   Sullivan TN, 2008, NEW DIR CHILD ADOLES, V122, P33, DOI 10.1002/cd.227
   Swancott L., 2023, COUNTY LINES CHILD C
   Swetnam J, 2001, SOC BEHAV PERSONAL, V29, P197, DOI 10.2224/sbp.2001.29.2.197
   TAJFEL H, 1979, BRIT J SOC CLIN PSYC, V18, P183, DOI 10.1111/j.2044-8260.1979.tb00324.x
   TAJFEL H, 1982, ANNU REV PSYCHOL, V33, P1, DOI 10.1146/annurev.ps.33.020182.000245
   Tangney JP, 2007, ANNU REV PSYCHOL, V58, P345, DOI 10.1146/annurev.psych.56.091103.070145
   Tarry H, 2007, BRIT J DEV PSYCHOL, V25, P169, DOI 10.1348/026151006X113671
   Tsvetkova M, 2015, SOCIOL SCI, V2, P36, DOI 10.15195/v2.a4
   Vasquez EA, 2015, AGGRESSIVE BEHAV, V41, P242, DOI 10.1002/ab.21581
   Walters GD, 2018, LAW HUMAN BEHAV, V42, P520, DOI 10.1037/lhb0000293
   Wood J, 2017, PSYCHIATRY, V80, P30, DOI 10.1080/00332747.2016.1199185
   Wood JL, 2019, CRIM BEHAV MENT HEAL, V29, P69, DOI 10.1002/cbm.2113
   Wooster R., 2016, Theatre in Education in Britain
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Zimring F.E., 1998, CRIME JUSTICE, V24, P477, DOI DOI 10.1086/449285
NR 94
TC 0
Z9 0
U1 11
U2 19
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 17
PY 2023
VL 4
AR 1142241
DI 10.3389/frvir.2023.1142241
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA O0IF0
UT WOS:001040736800001
OA Green Published, Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Winkler, MH
   Li, YH
   Pauli, P
   Muehlberger, A
AF Winkler, Markus H.
   Li, Yonghui
   Pauli, Paul
   Muehlberger, Andreas
TI Modulation of smoking cue reactivity by social context-Implications for
   exposure therapy in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cue reactivity; social context; cue exposure therapy; cue availability;
   smoking; substance use disorders; addiction; virtual reality
ID INCENTIVE-SENSITIZATION THEORY; NICOTINE DEPENDENCE; CIGARETTE
   AVAILABILITY; COCAINE SEEKING; ENVIRONMENTS; ADDICTION; RESPONSES;
   SMOKERS; IMPACT; EXTINCTION
AB Rationale: Social factors are considered important for the initiation and maintenance of drug abuse. Virtual reality (VR) research on cue reactivity and exposure frequently incorporates social stimuli as part of complex drug-intake scenarios. Attempts are rarely made to dissect the impact of the different components and their interactive effects. The present study critically extends this line of research by investigating the modulatory effects of social context on the reactivity evoked by proximal smoking cues.
   Methods: Thirty-two smokers and 33 never-smokers were presented in VR with proximal cues and neutral stimuli, embedded in a social context or a neutral context. A virtual hand model was used to translate real hand movements into VR. Each trial started with the presentation of the different stimulus-context combinations. Discrete stimuli were presented on the table in front of the participants, and contextual stimuli were presented at the end of the table. Afterward, participants were instructed to grasp the target stimulus (a cigarette vs. a pencil) in front of them. After successful contact, the stimulus appeared in the virtual hand. Modulation of cue reactivity by social context was assessed by self-report, physiological measures, and overt approach behavior.
   Results: The results revealed modulatory effects of social context on the responses to proximal smoking cues in smokers. In contrast to never-smokers, smoking cues evoked craving in smokers, which was attenuated in a social context. Furthermore, social context increased the latency to approach and contact the cigarette in the group of smokers but did not affect behavioral approach responses in never-smokers. Other data provided indications for interactive, but also main effects of cues and contexts. Interestingly, cue-evoked craving was increased after contact with the virtual cigarette.
   Conclusion: The present study critically extends previous research by providing evidence for the modulation of cue reactivity by social context. The results are particularly important given the well-established role of drug-associated environmental contexts in the stimulus control of addictive behaviors. Our results emphasize the need to address social context effects on cue reactivity in basic research and treatment and further suggest that changes in the perceived availability of smoking might enhance or inhibit cue-evoked reactivity.
C1 [Winkler, Markus H.; Pauli, Paul] Univ Wurzburg, Dept Psychol Biol Psychol Clin Psychol & Psychothe, Wurzburg, Germany.
   [Li, Yonghui] Chinese Acad Sci, Inst Psychol, Key Lab Mental Hlth, Beijing, Peoples R China.
   [Li, Yonghui] Univ Chinese Acad Sci, Dept Psychol, Beijing, Peoples R China.
   [Pauli, Paul] Univ Wurzburg, Ctr Mental Hlth, Wurzburg, Germany.
   [Muehlberger, Andreas] Univ Regensburg, Dept Psychol Clin Psychol & Psychotherapy, Regensburg, Germany.
C3 University of Wurzburg; Chinese Academy of Sciences; Institute of
   Psychology, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS; University of Wurzburg; University of
   Regensburg
RP Winkler, MH (corresponding author), Univ Wurzburg, Dept Psychol Biol Psychol Clin Psychol & Psychothe, Wurzburg, Germany.
EM markus.winkler@uni-wuerzburg.de
RI li, yong/HDN-3885-2022; li, chunlin/KFS-0761-2024
OI Winkler, Markus H./0000-0001-7198-4025
FU German Research Foundation (DFG); research group "Emotion and Behavior"
   [FOR 605, PA 566/9-1, PA 566/9-2]; Sino-German Center for Research
   Promotion [M-0039]; Open Access Publication Fund of University of
   Wurzburg
FX This study was partially supported by the German Research Foundation
   (DFG), the research group "Emotion and Behavior" (FOR 605, PA 566/9-1,
   PA 566/9-2), and the Sino-German Center for Research Promotion (M-0039).
   This publication was supported by the Open Access Publication Fund of
   the University of Wurzburg.
CR [Anonymous], 2012, Electrodermal Activity Internet, DOI DOI 10.1007/978-1-4614-1126-0
   Babb S, 2017, MMWR-MORBID MORTAL W, V65, P1457, DOI 10.15585/mmwr.mm6552a1
   Bailey SR, 2010, ADDICTION, V105, P364, DOI 10.1111/j.1360-0443.2009.02760.x
   Baker TB, 2004, ANNU REV PSYCHOL, V55, P463, DOI 10.1146/annurev.psych.55.090902.142054
   Bardo MT, 2013, PHARMACOL REV, V65, P255, DOI 10.1124/pr.111.005124
   Berridge KC, 2016, AM PSYCHOL, V71, P670, DOI 10.1037/amp0000059
   Betts JM, 2021, NICOTINE TOB RES, V23, P249, DOI 10.1093/ntr/ntaa147
   Blumenthal TD, 2005, PSYCHOPHYSIOLOGY, V42, P1, DOI 10.1111/j.1469-8986.2005.00271.x
   Boecker L, 2019, NEUROSCI BIOBEHAV R, V103, P230, DOI 10.1016/j.neubiorev.2019.05.019
   Bradley MM, 2009, PSYCHOPHYSIOLOGY, V46, P1, DOI 10.1111/j.1469-8986.2008.00702.x
   Brody AL, 2007, BIOL PSYCHIAT, V62, P642, DOI 10.1016/j.biopsych.2006.10.026
   Carter BL, 2001, EXP CLIN PSYCHOPHARM, V9, P183, DOI 10.1037//1064-1297.9.2.183
   CARVER CS, 1994, J PERS SOC PSYCHOL, V67, P319, DOI 10.1037/0022-3514.67.2.319
   Chesworth R, 2017, ADDICT BIOL, V22, P3, DOI 10.1111/adb.12337
   Cho S, 2008, CYBERPSYCHOL BEHAV, V11, P302, DOI 10.1089/cpb.2007.0149
   Conklin CA, 2006, EXP CLIN PSYCHOPHARM, V14, P12, DOI 10.1037/1064-1297.14.1.12
   Conklin CA, 2002, ADDICTION, V97, P155, DOI 10.1046/j.1360-0443.2002.00014.x
   Conklin CA, 2008, EXP CLIN PSYCHOPHARM, V16, P207, DOI 10.1037/1064-1297.16.3.207
   Conklin CA, 2019, NICOTINE TOB RES, V21, P241, DOI 10.1093/ntr/nty009
   Conklin CA, 2013, NICOTINE TOB RES, V15, P2081, DOI 10.1093/ntr/ntt104
   Conklin CA, 2010, DRUG ALCOHOL DEPEN, V111, P58, DOI 10.1016/j.drugalcdep.2010.03.017
   Connor KM, 2000, BRIT J PSYCHIAT, V176, P379, DOI 10.1192/bjp.176.4.379
   Crombag HS, 2008, PHILOS T R SOC B, V363, P3233, DOI 10.1098/rstb.2008.0090
   Dawson MichaelE., 2011, Journal of Neuroscience, Psychology, and Economics, V4, P111, DOI DOI 10.1037/A0022619
   de Wit H, 2018, PSYCHOPHARMACOLOGY, V235, P935, DOI 10.1007/s00213-018-4854-3
   Dimoff JD, 2017, ADDICTION, V112, P388, DOI 10.1111/add.13503
   Doll R, 2004, BMJ-BRIT MED J, V328, P1519, DOI 10.1136/bmj.38142.554479.AE
   Field M, 2014, CNS SPECTRUMS, V19, P225, DOI 10.1017/S1092852913000321
   Gamito P, 2011, STUD HEALTH TECHNOL, V167, P63, DOI 10.3233/978-1-60750-766-6-63
   García-Rodríguez O, 2013, ADDICT BEHAV, V38, P2551, DOI 10.1016/j.addbeh.2013.05.007
   García-Rodríguez O, 2012, ADDICT BEHAV, V37, P703, DOI 10.1016/j.addbeh.2012.02.013
   Girard B, 2009, CYBERPSYCHOL BEHAV, V12, P477, DOI 10.1089/cpb.2009.0118
   GRAY JA, 1990, COGNITION EMOTION, V4, P269, DOI 10.1080/02699939008410799
   Harakeh Z, 2012, DRUG ALCOHOL DEPEN, V121, P220, DOI 10.1016/j.drugalcdep.2011.08.029
   Harakeh Z, 2011, EUR ADDICT RES, V17, P316, DOI 10.1159/000330318
   HEATHERTON TF, 1991, BRIT J ADDICT, V86, P1119
   Heilig M, 2016, NAT REV NEUROSCI, V17, P592, DOI 10.1038/nrn.2016.67
   Hogarth L, 2010, PSYCHOPHARMACOLOGY, V208, P337, DOI 10.1007/s00213-009-1735-9
   Hone-Blanchet A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00844
   Jha P, 2013, NEW ENGL J MED, V368, P341, DOI 10.1056/NEJMsa1211128
   Kearns DN, 2007, DRUG ALCOHOL DEPEN, V90, P193, DOI 10.1016/j.drugalcdep.2007.03.006
   Kearns DN, 2005, J EXP PSYCHOL-ANIM B, V31, P247, DOI 10.1037/0097-7403.31.2.247
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim DY, 2019, CYBERPSYCH BEH SOC N, V22, P794, DOI 10.1089/cyber.2019.0121
   Koob GF, 2016, LANCET PSYCHIAT, V3, P760, DOI 10.1016/S2215-0366(16)00104-8
   Lang P. J., 1980, TECHNOLOGY MENTAL HL, P119, DOI DOI 10.1111/J.1469-8986.1993.TB03352.X
   LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037/0003-066X.50.5.372
   Langener S, 2021, J CLIN MED, V10, DOI 10.3390/jcm10163658
   Le Foll B, 2005, PSYCHOPHARMACOLOGY, V178, P481, DOI 10.1007/s00213-004-2021-5
   Le TL, 2020, EXP CLIN PSYCHOPHARM, V28, P81, DOI 10.1037/pha0000284
   LeCocq MR, 2020, NEUROTHERAPEUTICS, V17, P43, DOI 10.1007/s13311-019-00824-2
   Lee JS, 2008, PSYCHIAT INVEST, V5, P239, DOI 10.4306/pi.2008.5.4.239
   Löw A, 2008, PSYCHOL SCI, V19, P865, DOI 10.1111/j.1467-9280.2008.02170.x
   Lu WW, 2022, NEUROIMAGE, V252, DOI 10.1016/j.neuroimage.2022.119019
   Machulska A, 2021, BEHAV RES THER, V141, DOI 10.1016/j.brat.2021.103858
   Machulska A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116464
   McClernon FJ, 2016, NEUROPSYCHOPHARMACOL, V41, P877, DOI 10.1038/npp.2015.214
   McRae K, 2020, EMOTION, V20, P1, DOI 10.1037/emo0000703
   Mellentin AI, 2020, BMC PSYCHIATRY, V20, DOI 10.1186/s12888-020-02739-1
   Mucha RF, 1999, PSYCHOPHARMACOLOGY, V147, P306, DOI 10.1007/s002130051172
   Mucha RF, 2008, PSYCHOPHARMACOLOGY, V201, P81, DOI 10.1007/s00213-008-1249-x
   Mueller V, 1998, PHARMACOL BIOCHEM BE, V59, P1031, DOI 10.1016/S0091-3057(97)00508-X
   Müller V, 2001, Z KL PSYCH PSYCHOTH, V30, P164, DOI 10.1026/0084-5345.30.3.164
   Napier TC, 2013, NEUROSCI BIOBEHAV R, V37, P2081, DOI 10.1016/j.neubiorev.2013.05.002
   Panlilio LV, 1996, PSYCHOPHARMACOLOGY, V125, P202, DOI 10.1007/BF02247329
   Paris MM, 2011, ADDICT BEHAV, V36, P696, DOI 10.1016/j.addbeh.2011.01.029
   Peperkorn HM, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00268
   Pericot-Valverde I, 2016, NICOTINE TOB RES, V18, P538, DOI 10.1093/ntr/ntv216
   Pericot-Valverde I, 2014, NICOTINE TOB RES, V16, P1470, DOI 10.1093/ntr/ntu104
   Perusini JN, 2015, LEARN MEMORY, V22, P417, DOI 10.1101/lm.039180.115
   Pfaller M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.741138
   Prochaska JJ, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aay9763
   Reitsma MB, 2017, LANCET, V389, P1885, DOI 10.1016/S0140-6736(17)30819-X
   ROBINSON TE, 1993, BRAIN RES REV, V18, P247, DOI 10.1016/0165-0173(93)90013-P
   RUSSELL MAH, 1974, J ROY STAT SOC A STA, V137, P313, DOI 10.2307/2344953
   Schnoll RA, 2013, ADDICTION, V108, P1989, DOI 10.1111/add.12285
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Sciascia JM, 2015, NEUROPSYCHOPHARMACOL, V40, P2801, DOI 10.1038/npp.2015.130
   Segawa T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01409
   Shiffman S, 2015, DRUG ALCOHOL DEPEN, V154, P184, DOI 10.1016/j.drugalcdep.2015.06.027
   Shiffman S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089911
   Shiffman S, 2011, PSYCHOL ADDICT BEHAV, V25, P501, DOI 10.1037/a0022178
   Siegel S, 2000, EXP CLIN PSYCHOPHARM, V8, P276, DOI 10.1037/1064-1297.8.3.276
   Skewes MC, 2013, PRINCIPLES OF ADDICTION: COMPREHENSIVE ADDICTIVE BEHAVIORS AND DISORDERS, VOL 1, P61, DOI 10.1016/B978-0-12-398336-7.00006-1
   Smith MA, 2016, FRONT BEHAV NEUROSCI, V10, DOI 10.3389/fnbeh.2016.00217
   Sosic Z, 2008, J ANXIETY DISORD, V22, P849, DOI 10.1016/j.janxdis.2007.08.011
   Stevenson JG, 2017, ADDICT BEHAV, V67, P49, DOI 10.1016/j.addbeh.2016.12.007
   Stippekohl B, 2010, NEUROPSYCHOPHARMACOL, V35, P1209, DOI 10.1038/npp.2009.227
   Strickland JC, 2014, EXP CLIN PSYCHOPHARM, V22, P23, DOI 10.1037/a0034669
   Strobel A., 2001, Zeitschrift Fur Differentielle Und Diagnostische Psychologie, V22, P216, DOI [10.1024//0170-1789.22.3.216, DOI 10.1024//0170-1789.22.3.216]
   Thewissen R, 2006, BEHAV RES THER, V44, P1441, DOI 10.1016/j.brat.2005.10.010
   Thompson-Lake DGY, 2015, NICOTINE TOB RES, V17, P796, DOI 10.1093/ntr/ntu245
   TIFFANY ST, 1991, BRIT J ADDICT, V86, P1467, DOI 10.1111/j.1360-0443.1991.tb01732.x
   TIMBERLAKE W, 1994, PSYCHON B REV, V1, P405, DOI 10.3758/BF03210945
   Trahan MH, 2019, RES SOCIAL WORK PRAC, V29, P876, DOI 10.1177/1049731518823073
   US Department of Health and Human Services, 2014, HLTH CONSEQUENCES SM, DOI DOI 10.1037/E510072014-001
   Valyear MD, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17543-4
   Venniro M, 2020, NAT REV NEUROSCI, V21, P625, DOI 10.1038/s41583-020-0378-z
   Vollstädt-Klein S, 2022, medRxiv, DOI [10.1101/2022.07.12.22277347, 10.1101/2022.07.12.22277347, DOI 10.1101/2022.07.12.22277347]
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wechsler TF, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.751272
   Wertz JM, 2001, EXP CLIN PSYCHOPHARM, V9, P3, DOI 10.1037//1064-1297.9.1.3
   Wiers CE, 2013, PSYCHOPHARMACOLOGY, V229, P187, DOI 10.1007/s00213-013-3098-5
   Winkler MH, 2011, PSYCHOPHARMACOLOGY, V213, P781, DOI 10.1007/s00213-010-2033-2
   Wise RA, 2014, NEUROPSYCHOPHARMACOL, V39, P254, DOI 10.1038/npp.2013.261
   Wittekind CE, 2019, BEHAV RES THER, V114, P35, DOI 10.1016/j.brat.2018.12.004
   Wu LD, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01555
   Wu Y, 2014, ADDICT BIOL, V19, P5, DOI 10.1111/j.1369-1600.2012.00443.x
   Yang JM, 2022, EMOTION, V22, P1595, DOI 10.1037/emo0000977
NR 109
TC 1
Z9 1
U1 7
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 8
PY 2023
VL 4
AR 926679
DI 10.3389/frvir.2023.926679
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YS9
UT WOS:001023343700001
OA gold
DA 2024-07-18
ER

PT J
AU Fanourakis, M
   Chanel, G
AF Fanourakis, Marios
   Chanel, Guillaume
TI Attenuation of the dynamic pupil light response during screen viewing
   for arousal assessment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE pupil diameter; luminance correction; pupil light response; dynamic
   model; arousal; affective computing
ID REFLEX; IDENTIFICATION; OSCILLATIONS; PREVALENCE; STIMULUS; LATENCY;
   SIZE
AB Studies on the psychosensory pupil response often carefully control the lighting conditions in the experiment or require a calibration procedure for each subject under different light conditions for a baseline which is later used to attenuate the pupil light response (PLR) effects from the pupil using steady state models, disregarding the dynamic nature of the pupil. Such approaches are not feasible "in the wild" since they require carefully controlled experimental conditions. We address these shortcomings in the context of screen viewing in a dataset containing 140 subjects playing a first person shooter video game and use an existing dynamic PLR model to attenuate the effects of luminance. We compute the perceived luminance using the pixel values of the screen and show that using the dynamic PLR model is more effective in attenuating the effects of luminance compared to steady state models. Subsequently, we show that attenuating the PLR from the pupil size data improves the performance of machine learning models trained to predict arousing game events compared to using the pupil size without attenuating the PLR. The implications are that our approach for estimating the perceived luminance and attenuating its effects from the pupil data can be applied to screen viewing (including VR) to unobtrusively and continuously monitor users' emotional arousal via the pupil size.
C1 [Fanourakis, Marios; Chanel, Guillaume] Univ Geneva, CVML Lab, SIMS Grp, Comp Sci, Geneva, Switzerland.
C3 University of Geneva
RP Fanourakis, M (corresponding author), Univ Geneva, CVML Lab, SIMS Grp, Comp Sci, Geneva, Switzerland.
EM marios.fanourakis@unige.ch
RI Chanel, Guillaume/L-4529-2014
OI Chanel, Guillaume/0000-0002-6184-8924
FU Innosuisse, project [34316.1 IP.ICT]; University of Geneva
FX & nbsp;This work is co-financed by Innosuisse, project 34316.1 IP.ICT.
   Open access funding was provided by the University of Geneva.
CR Bergamin O, 2003, INVEST OPHTH VIS SCI, V44, P1546, DOI 10.1167/iovs.02-0468
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Brunton SL, 2016, P NATL ACAD SCI USA, V113, P3932, DOI 10.1073/pnas.1517384113
   Chanel Guillaume, 2020, Augmented Cognition. Theoretical and Technological Approaches. 14th International Conference, AC 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12196), P3, DOI 10.1007/978-3-030-50353-6_1
   Christy T., 2014, GSTF J COMPUTING JOC, V4, P38
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Crawford BH, 1936, PROC R SOC SER B-BIO, V121, P376, DOI 10.1098/rspb.1936.0072
   Donofrio RL, 2011, J SOC INF DISPLAY, V19, P658, DOI 10.1889/JSID19.10.658
   ELLIS CJK, 1981, BRIT J OPHTHALMOL, V65, P754, DOI 10.1136/bjo.65.11.754
   Fan XF, 2011, IEEE T BIO-MED ENG, V58, P36, DOI 10.1109/TBME.2010.2080678
   Fanourakis M., 2020, FDN DIGITAL GAMES DE
   Gächter S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129478
   Gao Y., 2009, DIGIT SIGNAL PROCESS, DOI [10.25148/etd.FI09120828, DOI 10.25148/ETD.FI09120828]
   Gao Y, 2009, 2009 IEEE 13TH DIGITAL SIGNAL PROCESSING WORKSHOP & 5TH IEEE PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, PROCEEDINGS, P167, DOI 10.1109/DSP.2009.4785915
   George AS, 2019, NEUROL INDIA, V67, P1500, DOI 10.4103/0028-3886.273623
   Gilleade K., 2005, DiGRA 2005, P1
   Greenberg S., 2016, The Open Psychology Journal, V9, P50, DOI DOI 10.2174/1874350101609010050
   Hashemi H, 2019, STRABISMUS, V27, P54, DOI 10.1080/09273972.2019.1604773
   Henderson RR, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.13050
   Holladay LL, 1926, J OPT SOC AM REV SCI, V12, P271, DOI 10.1364/JOSA.12.000271
   John B, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281538
   Juvrud J, 2022, IEEE T GAMES, V14, P308, DOI 10.1109/TG.2021.3073084
   Karpouzis Kostas., 2016, Emotion in Games: Theory and Praxis, DOI DOI 10.1007/978-3-319-41316-7
   Kasthurirangan S, 2006, VISION RES, V46, P1393, DOI 10.1016/j.visres.2005.07.004
   Kivikangas JM, 2011, J GAMING VIRTUAL WOR, V3, P181, DOI 10.1386/jgvw.3.3.181_1
   Koorathota S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.604522
   KORENBERG MJ, 1990, ANN BIOMED ENG, V18, P629, DOI 10.1007/BF02368452
   Kotsia I., 2012, 5th International Symposium on Communications, Control and Signal Processing, P1, DOI DOI 10.1109/ISCCSP.2012.6217768
   Krejtz K, 2020, J EYE MOVEMENT RES, V13, DOI 10.16910/jemr/13.5.2
   LINK N, 1988, IEEE T BIO-MED ENG, V35, P214, DOI 10.1109/10.1365
   LONGTIN A, 1989, BIOL CYBERN, V61, P51, DOI 10.1007/BF00204759
   LONGTIN A, 1989, B MATH BIOL, V51, P605
   LONGTIN A, 1988, MATH BIOSCI, V90, P183, DOI 10.1016/0025-5564(88)90064-8
   Lopes P, 2017, INT CONF AFFECT, P158, DOI 10.1109/ACII.2017.8273594
   Mathot Sebastiaan, 2018, J Cogn, V1, P16, DOI 10.5334/joc.18
   Matthews S, 2020, SYMP VIRTUAL AUGMENT, P398, DOI 10.1109/SVR51698.2020.00066
   Melhart D, 2019, INT CONF AFFECT, DOI [10.1109/ACII.2019.8925434, 10.1109/acii.2019.8925434]
   Mitre-Hernandez H, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/21620
   Moon P, 1944, J OPT SOC AM, V34, P319, DOI 10.1364/JOSA.34.000319
   Napieralski P, 2019, OPEN PHYS, V17, P458, DOI 10.1515/phys-2019-0047
   Pamplona VF, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559763
   Peysakhovich V, 2017, INT J PSYCHOPHYSIOL, V112, P40, DOI 10.1016/j.ijpsycho.2016.12.003
   Rahal RM, 2019, J EXP SOC PSYCHOL, V85, DOI 10.1016/j.jesp.2019.103842
   Raiturkar P., 2016, Proceedings of the ACM Symposium on Applied Perception, P89, DOI DOI 10.1145/2931002.2931009
   Ravaja N, 2006, PRESENCE-TELEOP VIRT, V15, P381, DOI 10.1162/pres.15.4.381
   Robertson A.R., 1977, Color Res. Appl., V2, P7, DOI [10.1002/j.1520-6378.1977.tb00104.x, DOI 10.1002/J.1520-6378.1977.TB00104.X]
   SEMMLOW JL, 1977, MATH BIOSCI, V33, P5, DOI 10.1016/0025-5564(77)90060-8
   Smith J.D., 2006, P 2006 ACM SIGCHI IN, P20, DOI [10.1145/1178823.1178847, DOI 10.1145/1178823.1178847]
   Soufineyestani M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217453
   STANLEY PA, 1995, OPHTHAL PHYSL OPT, V15, P601, DOI 10.1016/0275-5408(94)00019-V
   STARK LW, 1984, IEEE T BIO-MED ENG, V31, P919, DOI 10.1109/TBME.1984.325259
   Tangnimitchok S., 2019, THESIS FLORIDA INT U, DOI [10.25148/etd.FIDC007810, DOI 10.25148/ETD.FIDC007810]
   Tangnimitchok S., 2019, LECT NOTES COMPUTER, V11567, P397, DOI [10.1007/978-3-030-22643-5_31, DOI 10.1007/978-3-030-22643-5_31]
   Vo MLH, 2008, PSYCHOPHYSIOLOGY, V45, P130, DOI 10.1111/j.1469-8986.2007.00606.x
   Wang CA, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.01029
   Watson AB, 2012, J VISION, V12, DOI 10.1167/12.10.12
   Wong HK, 2020, IEEE T COGN DEV SYST, V12, P681, DOI 10.1109/TCDS.2018.2876348
   Yannakakis G, 2008, P 1 WORKSH CHILD COM
   Zandi B, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79908-5
NR 59
TC 2
Z9 2
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 7
PY 2022
VL 3
AR 971613
DI 10.3389/frvir.2022.971613
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VQ4
UT WOS:001023262700001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Rau, L
   Bitter, JL
   Liu, Y
   Spierling, U
   Dörner, R
AF Rau, Linda
   Bitter, Jessica L.
   Liu, Yu
   Spierling, Ulrike
   Doerner, Ralf
TI Supporting the creation of non-linear everyday AR experiences in
   exhibitions and museums: An authoring process based on self-contained
   building blocks
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; museum; authoring tools; non-linear; everyday
   experience; navigation; patterns; authoring
AB The use of Augmented Reality (AR) has the potential to make everyday experiences exciting and educational. For example, AR can augment exhibits in museums with animated and interactive content. The creation of this content, however, is still facing challenges. To meet these, we employ reusable, pattern-based building blocks called AR nuggets. An AR nugget implements one application pattern in a small and self-contained piece of software to provide a complete solution for recurrent AR-based experiences. For example, in the application context of museums and exhibitions, we identify superimposition or visualization of echolocation as general patterns for AR use cases. AR nuggets encapsulate AR-specific knowledge and sophisticated functionalities to support authors and reduce the authoring task to tweaking existing templates to individual exhibits. To connect AR nuggets used in different exhibition rooms, we present novel AR nuggets that encapsulate the functionalities needed for creating a path between the exhibits. Additionally, we provide examples of AR nuggets that implement a virtual character that guides visitors to exhibits of interest. With this new set of AR nuggets, spatial connections can be authored, e.g., in the form of a guided tour with interactive narration. For this authoring task, we introduce an AR nugget manager that supports authors in creating and adapting multiple non-linear AR experiences. We illustrate our approach with the creation of an everyday AR application for a museum of natural history, share our experiences and discuss to what extent our approach can mitigate authoring challenges for everyday AR applications from a museum's point of view. This work contributes to the field of everyday AR with 1) a pattern-based authoring concept to create complex everyday AR experiences based on self-contained building blocks, 2) a set of patterns that allows for spatial connections of these to create non-linear AR content, 3) means for supporting this authoring process in the form of an AR nugget manager, 4) lessons learned in applying our authoring concept in a real application case in a museum, 5) our observation of hurdles that still prevent more widespread use of AR in everyday applications during the realization of this application case.
C1 [Rau, Linda; Bitter, Jessica L.; Liu, Yu; Spierling, Ulrike; Doerner, Ralf] RheinMain Univ Appl Sci, Design, Comp Sci, Media, Wiesbaden, Germany.
RP Rau, L (corresponding author), RheinMain Univ Appl Sci, Design, Comp Sci, Media, Wiesbaden, Germany.
EM linda.rau@hs-rm.de
OI Rau, Linda/0000-0001-7165-0041; Spierling, Ulrike/0009-0006-5423-3880
FU German Federal Ministry of Education and Research (BMBF) [13FH181PX8]
FX This work has been funded by the German Federal Ministry of Education
   and Research (BMBF), funding program Forschung an Fachhochschulen,
   contract number 13FH181PX8.
CR Alexander C., 1997, A Pattern Language: Towns, Buildings and Construction
   Apaza-Yllachura Y, 2019, P INT C CHIL COMPUT, DOI 10.1109/sccc49216.2019.8966427
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Bachras V, 2019, LECT NOTES COMPUT SC, V11749, P309, DOI 10.1007/978-3-030-29390-1_17
   Campbell AG, 2014, VIRTUAL REAL-LONDON, V18, P139, DOI 10.1007/s10055-013-0239-4
   Geronikolakis E., 2020, Visual Computing for Cultural Heritage, P225
   Hammady R, 2020, MULTIMED TOOLS APPL, V79, P3465, DOI 10.1007/s11042-019-08026-w
   Horst R., 2019, IEEE INT C TEACH ASS
   Huang BC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205890
   Kampa A, 2017, P INFORMATIK 2017 GE, P915, DOI [10.18420/in201793, DOI 10.18420/IN201793]
   Krauss V, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445335
   Li W, 2004, PROC GRAPH INTERF, P203
   Luboschik M, 2007, IEEE INT CONF INF VI, P301
   Guarese RLM, 2019, LECT NOTES COMPUT SC, V11542, P431, DOI 10.1007/978-3-030-22514-8_41
   Microsoft, 2021, POW APPS
   Microsoft, 2020, WHAT IS MIX REAL TOO
   Nebeling M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P333, DOI 10.1109/ISMAR-Adjunct.2018.00098
   PTC, 2021, ABOUT US
   Rau L, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.841066
   Rau L, 2021, INT SYM MIX AUGMENT, P212, DOI 10.1109/ISMAR-Adjunct54149.2021.00051
   Singh A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P713, DOI 10.1109/VR50410.2021.00098
   Spierling U., 2016, P INT C CULT COMP SC, P25
   Tarantino E, 2019, INF TECHNOL TOUR, V21, P413, DOI 10.1007/s40558-019-00150-5
   Unity Technologies, 2021, UN GAM ENG
   Vlizos S., 2021, Communications in Computer and Information Science, V1432, P79
   XRTY App, 2021, CREAT AUGM REAL MARK
   Yu Liu, 2021, Intelligent Technologies for Interactive Entertainment. 12th EAI International Conference, INTETAIN 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 377), P229, DOI 10.1007/978-3-030-76426-5_15
NR 27
TC 2
Z9 2
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 26
PY 2022
VL 3
AR 955437
DI 10.3389/frvir.2022.955437
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RZ4
UT WOS:001023167400001
OA gold
DA 2024-07-18
ER

PT J
AU Pohl, H
   Mottelson, A
AF Pohl, Henning
   Mottelson, Aske
TI Hafnia Hands: A Multi-Skin Hand Texture Resource for Virtual Reality
   Research
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE skin tone; virtual reality; hand tracking; avatars; presence
ID EMBODIMENT; OWNERSHIP
AB We created a hand texture resource (with different skin tone versions as well as non-human hands) for use in virtual reality studies. This makes it easier to run lab and remote studies where the hand representation is matched to the participants' own skin tone. We validate that the virtual hands with our textures align with participants' view of their own real hands and allow to create VR applications where participants have an increased sense of body ownership. These properties are critical for a range of VR studies, such as of immersion.
C1 [Pohl, Henning] Aalborg Univ, Dept Comp Sci, Aalborg, Denmark.
   [Mottelson, Aske] IT Univ Copenhagen, Dept Digital Design, Copenhagen, Denmark.
C3 Aalborg University; IT University Copenhagen
RP Pohl, H (corresponding author), Aalborg Univ, Dept Comp Sci, Aalborg, Denmark.
EM henning@cs.aau.dk
RI ; Mottelson, Aske/O-2922-2015
OI Pohl, Henning/0000-0002-1420-4309; Mottelson, Aske/0000-0003-1827-8513
FU UCPH's Data+ pool under the agreement Quantifying Body Ownership'.
FX This research was supported by UCPH's Data+ pool under the agreement
   Quantifying Body Ownership'.
CR Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Commins S, 2020, BEHAV RES METHODS, V52, P1189, DOI 10.3758/s13428-019-01310-5
   FITZPATRICK TB, 1988, ARCH DERMATOL, V124, P869, DOI 10.1001/archderm.124.6.869
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Ma X, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P33, DOI 10.1145/3178876.3186034
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mottelson A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.681482
   Mottelson A, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139141
   Neng Qian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P54, DOI 10.1007/978-3-030-58621-8_4
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Ratcliffe J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445170
   Regal G, 2018, INT WORK QUAL MULTIM, P81
   Saffo David, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382829
   Seinfeld S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79255-5
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Steed A., 2020, Interactions, V27, P62, DOI DOI 10.1145/3406098
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
NR 21
TC 3
Z9 3
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 26
PY 2022
VL 3
AR 719506
DI 10.3389/frvir.2022.719506
PG 6
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XO4
UT WOS:001023313000001
OA gold, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Rolff, T
   Steinicke, F
   Frintrop, S
AF Rolff, Tim
   Steinicke, Frank
   Frintrop, Simone
TI Gaze Mapping for Immersive Virtual Environments Based on Image Retrieval
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE gaze mapping; fixation mapping; free viewing environment; eye fixation
   maps; saliency; gaze re-projection; ground truth fixation estimation
ID VISUAL-ATTENTION; SALIENCY; PREDICTION; MODEL; VR
AB In this paper, we introduce a novel gaze mapping approach for free viewing conditions in dynamic immersive virtual environments (VEs), which projects recorded eye fixation data of users, who viewed the VE from different perspectives, to the current view. This generates eye fixation maps, which can serve as ground truth for training machine learning (ML) models to predict saliency and the user's gaze in immersive virtual reality (VR) environments. We use a flexible image retrieval approach based on SIFT features, which can also map the gaze under strong viewpoint changes and dynamic changes. A vocabulary tree enables to scale to the large amounts of data with typically several hundred thousand frames and a homography transform re-projects the fixations to the current view. To evaluate our approach, we measure the predictive quality of our eye fixation maps to model the gaze of the current user and compare our maps to computer-generated saliency maps on the DGaze and the Saliency in VR datasets. The results show that our method often outperform these saliency predictors. However, in contrast to these methods, our approach collects real fixations from human observers, and can thus serve to estimate ground truth fixation maps in dynamic VR environments, which can be used to train and evaluate gaze predictors.
C1 [Rolff, Tim; Steinicke, Frank] Univ Hamburg, Dept Human Comp Interact, Hamburg, Germany.
   [Rolff, Tim; Frintrop, Simone] Univ Hamburg, Dept Comp Vis, Hamburg, Germany.
C3 University of Hamburg; University of Hamburg
RP Rolff, T (corresponding author), Univ Hamburg, Dept Human Comp Interact, Hamburg, Germany.; Rolff, T (corresponding author), Univ Hamburg, Dept Comp Vis, Hamburg, Germany.
EM Tim.Rolff@uni-hamburg.de
RI Steinicke, Frank/AAC-2976-2020
OI Steinicke, Frank/0000-0001-9879-7414; Rolff, Tim/0000-0001-9038-3196
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benjamins JS, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204568
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Bylinskii Z., 2020, MIT SALIENCY BENCHMA
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Celikcan U, 2020, COMPUT GRAPH-UK, V88, P70, DOI 10.1016/j.cag.2020.03.006
   Che ZH, 2020, IEEE T IMAGE PROCESS, V29, P2287, DOI 10.1109/TIP.2019.2945857
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   De Tommaso D, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319828
   Droste R., 2020, P 16 EUR C COMP VIS, DOI [10.1007/978-3-030-58558-7_25, DOI 10.1007/978-3-030-58558-7_25]
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Foulsham T, 2011, VISION RES, V51, P1920, DOI 10.1016/j.visres.2011.07.002
   Frintrop S, 2015, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2015.7298603
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Hosny YSS, 2020, 2020 IEEE GRAPHICS AND MULTIMEDIA (GAME), P13, DOI 10.1109/GAME50158.2020.9315059
   Hu ZM, 2021, IEEE T VIS COMPUT GR, V27, P2681, DOI 10.1109/TVCG.2021.3067779
   Hu ZM, 2020, IEEE T VIS COMPUT GR, V26, P1902, DOI 10.1109/TVCG.2020.2973473
   Huang YF, 2018, LECT NOTES COMPUT SC, V11208, P789, DOI 10.1007/978-3-030-01225-0_46
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang M., 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298710, DOI 10.1109/CVPR.2015.7298710]
   Kanter David., 2015, Graphics processing requirements for enabling immersive vr
   Kenneth HolmqvistMarcus Nystrom., 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kraus M., 2019, EUROVIS 2019 21 EG V
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacInnes J. J., 2018, Journal of Open Source Software, V3, P984
   Macinnes JJ., 2018, bioRxiv, DOI DOI 10.1101/299925
   Mathe S, 2012, LECT NOTES COMPUT SC, V7573, P842, DOI 10.1007/978-3-642-33709-3_60
   Nakashima R, 2015, VISION RES, V117, P59, DOI 10.1016/j.visres.2015.10.001
   Pashler H.E., 1999, PSYCHOL ATTENTION
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Pfeiffer T, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P189, DOI 10.1145/2857491.2857532
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sculley D., 2010, P INT C WORLD WID WE, V19, P1177, DOI [DOI 10.1145/1772690.1772862, 10.1145/1772690.1772862]
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Stein N, 2021, I-PERCEPTION, V12, DOI 10.1177/2041669520983338
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Treisman AM, 1998, CURR OPIN NEUROBIOL, V8, P218, DOI 10.1016/S0959-4388(98)80143-8
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Uriza E, 2018, IMAGE PROCESS ON LIN, V8, P71, DOI 10.5201/ipol.2018.199
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
NR 47
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 3
PY 2022
VL 3
AR 802318
DI 10.3389/frvir.2022.802318
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TN9
UT WOS:001021836200001
OA gold
DA 2024-07-18
ER

PT J
AU Vuarnesson, L
   Zamplaras, D
   Laroche, J
   Dumit, J
   Lutes, C
   Bachrach, A
   Garnier, F
AF Vuarnesson, Loup
   Zamplaras, Dionysios
   Laroche, Julien
   Dumit, Joseph
   Lutes, Clint
   Bachrach, Asaf
   Garnier, Francois
TI Shared Diminished Reality: A New VR Framework for the Study of Embodied
   Intersubjectivity
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE dance improvisation; research-creation; multi-user experience design;
   enaction; non-anthropomorphic avatars; virtual reality; mixed-reality
   performance; copresence
ID IMMERSIVE VIRTUAL-REALITY; SENSE
AB Shaping both the environment and the embodiment of the users in that virtual world, VR offers designers and cognitive scientists the unprecedented potential to virtually explore a vast set of interactions between persons, and persons and their environment. By design, VR tools offer a formidable opportunity to revisit the links between body movement and lived experiences, and to experiment with them in a controlled, yet engaging and ecologically valid manner. In our multidisciplinary research-creation project we ask, how can we design (virtual) environments that specifically encourage interactions between multiple persons and that allow designers, scientists, and participants (users or "immersants") to explore the very process of interaction itself? Building on our combined experience with dance improvisation research and interactive virtual spatial design, we document a multi-user VR experience design approach we name Shared Diminished Reality (SDR), where immersants are co-present and able to move together while their bodies and the environment are represented in a minimalist way. Our working hypothesis is that non-anthropomorphic embodiment of oneself and one's partner(s), combined with open-ended exploration, focuses the user's attention on the quality of the interaction and encourages playfulness and creativity. We present the articulations VR platform and its design history, as well as design evaluations of SDR in a laboratory setting and through a mixed reality performance, interrogating the impact of our minimalist approach on user experience and on the quality of the interaction. Our results suggest that minimizing (self and other) representation in Shared Diminished Reality positively impacts relational dynamics, induces playful creativity, and fosters the will to move and improvise together.
C1 [Vuarnesson, Loup; Zamplaras, Dionysios; Garnier, Francois] PSL Univ, EnsadLab, Spatial Media, Ensad, Paris, France.
   [Vuarnesson, Loup] EMOTIC, Nantes, France.
   [Zamplaras, Dionysios] Univ Paris 08, Inrev AIAC EA4010, St Denis, France.
   [Laroche, Julien] FondazioneIstituto Italiano Tecnol IIT, Ctr Translat Neurophysiol Speech & Commun CTNSC, Ferrara, Italy.
   [Laroche, Julien; Bachrach, Asaf] Univ Paris 08, EUR ArTec, St Denis, France.
   [Dumit, Joseph] Univ Calif Davis, Sci & Technol Studies, Davis, CA USA.
   [Lutes, Clint] Cie DaPoPa, Paris, France.
   [Bachrach, Asaf] CNRS, UMR 7023, Paris, France.
C3 Universite PSL; Ecole Nationale Superieure des Arts Decoratifs (ENSAD);
   Universite Paris-VIII; Universite Paris-VIII; University of California
   System; University of California Davis; Centre National de la Recherche
   Scientifique (CNRS); CNRS - Institute for Humanities & Social Sciences
   (INSHS)
RP Vuarnesson, L; Zamplaras, D (corresponding author), PSL Univ, EnsadLab, Spatial Media, Ensad, Paris, France.; Vuarnesson, L (corresponding author), EMOTIC, Nantes, France.; Zamplaras, D (corresponding author), Univ Paris 08, Inrev AIAC EA4010, St Denis, France.
EM loup.vuarnesson@gmail.com; dzamplaras@gmail.com
OI garnier, francois/0000-0002-5056-9567; Vuarnesson,
   Loup/0000-0002-1315-1129
FU French national agency of research through the program "Investissements
   d'avenir" [ANR-17-EURE-0008]; Agence Nationale de la Recherche (ANR)
   [ANR-17-EURE-0008] Funding Source: Agence Nationale de la Recherche
   (ANR)
FX This work has been supported by funding provided by the French national
   agency of research through the program "Investissements d'avenir"
   (reference ANR-17-EURE-0008).
CR [Anonymous], 1939, MATIERE MEMOIRE ESSA
   [Anonymous], 2009, Innovate: Journal of Online Education
   Arcier H., 2020, CLINAMEN
   Ascone Leonie, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382918
   Auvray M, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00181
   Auvray M, 2009, NEW IDEAS PSYCHOL, V27, P32, DOI 10.1016/j.newideapsych.2007.12.002
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Boluk Stephanie., 2017, Metagaming: Playing, Competing, Spectating, Cheating, Trading, Making, and Breaking Video Games
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Cohen-Cole J, 2007, BRIT J HIST SCI, V40, P567, DOI 10.1017/S0007087407000283
   Csikszentmihalyi M., 1997, FLOW PSYCHOL DISCOVE, V39, P1
   Davis L, 2003, IEEE COMPUT GRAPH, V23, P10, DOI 10.1109/MCG.2003.1185574
   De Jaegher H., 2007, PHENOMENOL COGN SCI, V6, P485, DOI [10.1007/s11097-007-9076-9, DOI 10.1007/S11097-007-9076-9, https://doi.org/10.1007/s11097-007-9076-9]
   De Jaegher H, 2010, TRENDS COGN SCI, V14, P441, DOI 10.1016/j.tics.2010.06.009
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Deleuze G., 1994, What is Philosophy
   Deschamps L., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P239, DOI 10.1109/HAPTIC.2012.6183797
   Desnoyers-Stewart J, 2020, LEONARDO, V53, P394, DOI [10.1162/LEON_a_01925, 10.1162/leon_a_01925]
   Euphrates, 2011, BALLETROTOSCOPE
   Forbes PAG, 2016, J AUTISM DEV DISORD, V46, P3788, DOI 10.1007/s10803-016-2930-2
   Franke D., 2012, UNNAMED SOUND SCULPT
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Froese T, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01061
   Froese T, 2014, SCI REP-UK, V4, DOI 10.1038/srep03672
   Fuchs P., 2006, TRAITE REALIT VIRTUE
   Garnier F., 2017, INT J VIRTUAL REALIT, V17, P46, DOI [10.20870/ijvr.2017.17.2.2891, DOI 10.20870/IJVR.2017.17.2.2891]
   Georgakopoulou N, 2019, HUCAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 2: HUCAPP, P175, DOI 10.5220/0007573901750182
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Greenwald S.W., 2017, 12 INT C COMPUTER SU
   Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950
   Himberg T, 2018, BEHAV SCI-BASEL, V8, DOI 10.3390/bs8020023
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kimmel M, 2018, BEHAV SCI-BASEL, V8, DOI 10.3390/bs8060052
   Kozel S, 2007, LEONARDO SER, P1
   Laroche J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01180
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Lopez C, 2015, NEUROPHYSIOL CLIN, V45, P241, DOI 10.1016/j.neucli.2015.09.001
   Lugrin JL, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P315, DOI 10.1145/2993369.2996313
   Manning E, 2009, TECHNOL LIVED ABSTR, P1
   McGann M, 2009, PHENOMENOL COGN SCI, V8, P417, DOI 10.1007/s11097-009-9141-7
   Merleau-Ponty M., 1945, PHENOMENOLOGIE PERCE
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Neville S., 2019, SPHERES DANCE VIRTUA
   Noe Alva., 2012, Varieties of Presence
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Okun M. S., 2017, VIRTUAL REALITY TRAI
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Quesnel D, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P200, DOI 10.1109/GEM.2018.8516463
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Sra M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P85, DOI 10.1145/3196709.3196788
   van der Land SF, 2015, HUM COMMUN RES, V41, P128, DOI 10.1111/hcre.12044
   Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1
   Wiederhold BK, 2019, CYBERPSYCH BEH SOC N, V22, P3, DOI 10.1089/cyber.2018.29136.bkw
   Wienrich C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P207, DOI 10.1109/VR.2018.8446575
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 58
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 28
PY 2021
VL 2
AR 646930
DI 10.3389/frvir.2021.646930
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2QX7
UT WOS:001021767500001
OA Green Published, Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Brice, D
   Gibson, Z
   McGuinness, F
   Rafferty, K
AF Brice, Daniel
   Gibson, Zara
   McGuinness, Fintan
   Rafferty, Karen
TI Using Ultrasonic Haptics Within an Immersive Spider Exposure Environment
   to Provide a Multi-Sensorial Experience
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; haptics; immersion; VRET; ultrasonic feedback; spiders
ID NATIONAL EPIDEMIOLOGIC SURVEY; VIRTUAL-REALITY; ANXIETY DISORDERS;
   TACTILE AUGMENTATION; EEG ASYMMETRY; FRONTAL EEG; FEAR; PHOBIA;
   AVOIDANCE; ACCEPTANCE
AB A proof of concept virtual reality system is presented that integrates ultrasonic feedback sensations to provide a demonstrative virtual reality exposure therapy environment containing multiple scenarios with virtual spiders. This system and environment were utilised to conduct a study containing 35 participants with the goal of investigating the effect the environment could have on their level of anxiety. This level of anxiety was measured in three different forms: changes in frontal asymmetry analysis of EEG data, changes in skin conductance levels and subjective units of distress. The Fear of Spiders Questionnaire was used to determine which participants in the study reported to be moderately afraid of spiders. For these participants all three measurement forms for anxiety showed statistically significant increases in a comparison between baseline and scenarios with the virtual spiders. A statistically significant correlation between scores on the Fear of Spiders Questionnaire and changes in anxiety shows the system to have had a greater effect on the anxiety levels of those who were more afraid of spiders, than those who were not. There was also a statistically significant correlation discovered between immersion and increase in anxiety, highlighting the significance of immersion in future virtual reality exposure therapy applications.
C1 [Brice, Daniel; Gibson, Zara; McGuinness, Fintan; Rafferty, Karen] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast, North Ireland.
C3 Queens University Belfast
RP Brice, D (corresponding author), Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast, North Ireland.
EM dbrice01@qub.ac.uk
CR Alsina-Jurnet I, 2011, COMPUT HUM BEHAV, V27, P504, DOI 10.1016/j.chb.2010.09.018
   Benjamin CL, 2010, BEHAV COGN PSYCHOTH, V38, P497, DOI 10.1017/S1352465810000287
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   BOYD JH, 1990, SOC PSYCH PSYCH EPID, V25, P314, DOI 10.1007/BF00782887
   Brouwer A.-M., 2011, J CYBERTHERAPY REHAB, V4, P83
   Carlin AS, 1997, BEHAV RES THER, V35, P153, DOI 10.1016/S0005-7967(96)00085-X
   Carter T., 2013, P 26 ANN ACM S US IN, P505
   Cavrag Miroslav, 2014, 2014 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE). Proceedings, P29, DOI 10.1109/HAVE.2014.6954327
   Cochrane A, 2008, PSYCHOL REC, V58, P585, DOI 10.1007/BF03395639
   DAVIDSON RJ, 1990, J PERS SOC PSYCHOL, V58, P330, DOI 10.1037/0022-3514.58.2.330
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dennis TA, 2010, BIOL PSYCHOL, V85, P456, DOI 10.1016/j.biopsycho.2010.09.008
   Depla MFIA, 2008, SOC PSYCH PSYCH EPID, V43, P200, DOI 10.1007/s00127-007-0291-z
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Garcia-Palacios A, 2007, CYBERPSYCHOL BEHAV, V10, P722, DOI 10.1089/cpb.2007.9962
   Garcia-Palacios A, 2002, BEHAV RES THER, V40, P983, DOI 10.1016/S0005-7967(01)00068-7
   Gibson Z, 2019, ADV INTELL SYST, V775, P14, DOI 10.1007/978-3-319-94866-9_2
   Gollan JK, 2014, BIOL PSYCHOL, V99, P198, DOI 10.1016/j.biopsycho.2014.03.003
   Heinssen R. K.  Jr., 1987, Computers in Human Behaviour, V3, P49, DOI 10.1016/0747-5632(87)90010-0
   Hoffman H. G., 1998, Virtual Reality, V3, P226, DOI 10.1007/BF01408703
   Hoffman H.G., 1996, TACTILE AUGMENTATION
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Hoffman HG, 2003, INT J HUM-COMPUT INT, V16, P283, DOI 10.1207/S15327590IJHC1602_08
   HOMAN RW, 1987, ELECTROEN CLIN NEURO, V66, P376, DOI 10.1016/0013-4694(87)90206-9
   Hoshi T, 2010, IEEE T HAPTICS, V3, P155, DOI [10.1109/ToH.2010.4, 10.1109/TOH.2010.4]
   Iwamoto T, 2008, LECT NOTES COMPUT SC, V5024, P504, DOI 10.1007/978-3-540-69057-3_64
   Iza M, 2013, J CLIN PSYCHIAT, V74, P1093, DOI 10.4088/JCP.13m08361
   Juan MC, 2010, COMPUT GRAPH-UK, V34, P756, DOI 10.1016/j.cag.2010.08.001
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Kurscheidt M., 2019, IEEE INT C HEALTHC I, P1, DOI [10.1109/ICHI.2019.8904800, DOI 10.1109/ICHI.2019.8904800]
   Kwon JH, 2013, INT J HUM-COMPUT ST, V71, P978, DOI 10.1016/j.ijhcs.2013.07.003
   Lombard M., 2000, Resources for the study of presence
   Long B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661257
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Muris P, 1996, J BEHAV THER EXP PSY, V27, P241, DOI 10.1016/S0005-7916(96)00022-5
   Mystkowski JL, 2002, BEHAV THER, V33, P399, DOI 10.1016/S0005-7894(02)80035-1
   NESSE RM, 1985, PSYCHOSOM MED, V47, P320, DOI 10.1097/00006842-198507000-00002
   Ollendick TH, 2004, CLIN PSYCHOL-SCI PR, V11, P289, DOI 10.1093/clipsy/bph083
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Pallavicini F, 2013, BMC PSYCHIATRY, V13, DOI 10.1186/1471-244X-13-52
   Peperkorn HM, 2013, STUD HEALTH TECHNOL, V191, P75, DOI 10.3233/978-1-61499-282-0-75
   Pflugshaupt T, 2005, J ANXIETY DISORD, V19, P105, DOI 10.1016/j.janxdis.2003.12.002
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Rinck M, 2007, J BEHAV THER EXP PSY, V38, P105, DOI 10.1016/j.jbtep.2006.10.001
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Segal R, 2011, CYBERPSYCH BEH SOC N, V14, P29, DOI 10.1089/cyber.2009.0398
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Smith EE, 2017, INT J PSYCHOPHYSIOL, V111, P98, DOI 10.1016/j.ijpsycho.2016.11.005
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Stinson FS, 2007, PSYCHOL MED, V37, P1047, DOI 10.1017/S0033291707000086
   SZYMANSKI J, 1995, J BEHAV THER EXP PSY, V26, P31, DOI 10.1016/0005-7916(94)00072-T
   Teachman BA, 2001, J ABNORM PSYCHOL, V110, P226, DOI 10.1037/0021-843X.110.2.226
   Turner WA, 2014, CLIN PSYCHOL REV, V34, P634, DOI 10.1016/j.cpr.2014.10.003
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vahia VN, 2013, INDIAN J PSYCHIAT, V55, P220, DOI 10.4103/0019-5545.117131
   Wacker J, 2003, EMOTION, V3, P167, DOI 10.1037/1528-3542.3.2.167
   Wagener AL, 2011, PSYCHOL REC, V61, P77, DOI 10.1007/BF03395747
   Wiedemann G, 1999, ARCH GEN PSYCHIAT, V56, P78, DOI 10.1001/archpsyc.56.1.78
   Wolpe J., 1990, PERGAMON GEN PSYCHOL
   Yeh SC, 2018, IEEE T NEUR SYS REH, V26, P1345, DOI 10.1109/TNSRE.2018.2844083
NR 65
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 10
PY 2021
VL 2
AR 707731
DI 10.3389/frvir.2021.707731
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AZ6
UT WOS:001019304500001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Weller, R
   Wegele, W
   Schröder, C
   Zachmann, G
AF Weller, Rene
   Wegele, Waldemar
   Schroeder, Christoph
   Zachmann, Gabriel
TI LenSelect: Object Selection in Virtual Environments by Dynamic Object
   Scaling
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; 3D interaction; object selection techniques; human
   computer interaction; interaction design; user interface
ID 3D SELECTION; FITTS LAW
AB We present a novel selection technique for VR called LenSelect. The main idea is to decrease the Index of Difficulty (ID) according to Fitts' Law by dynamically increasing the size of the potentially selectable objects. This facilitates the selection process especially in cases of small, distant or partly occluded objects, but also for moving targets. In order to evaluate our method, we have defined a set of test scenarios that covers a broad range of use cases, in contrast to often used simpler scenes. Our test scenarios include practically relevant scenarios with realistic objects but also synthetic scenes, all of which are available for download. We have evaluated our method in a user study and compared the results to two state-of-the-art selection techniques and the standard ray-based selection. Our results show that LenSelect performs similar to the fastest method, which is ray-based selection, while significantly reducing the error rate by 44%.
C1 [Weller, Rene; Wegele, Waldemar; Schroeder, Christoph; Zachmann, Gabriel] Univ Bremen, Comp Graph & Virtual Real Res Lab, Bremen, Germany.
C3 University of Bremen
RP Zachmann, G (corresponding author), Univ Bremen, Comp Graph & Virtual Real Res Lab, Bremen, Germany.
EM zach@informatik.uni-bremen.de
RI Zachmann, Gabriel/AAI-9685-2020
OI Zachmann, Gabriel/0000-0001-8155-1127
CR Al Hajri A, 2011, LECT NOTES COMPUT SC, V6947, P141, DOI 10.1007/978-3-642-23771-3_12
   Andujar C., 2006, 12 EUR S VIRT ENV, DOI 10.2312/EGVE/EGVE06/101-108
   Andujar C, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P99
   Argelaguet F., 2008, P VRST 2008, P43
   Argelaguet F., 2008, IMPROVING 3D SELECTI
   Bacim F, 2013, INT J HUM-COMPUT ST, V71, P785, DOI 10.1016/j.ijhcs.2013.03.003
   Benko H, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P79
   Bowman D. A., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P26, DOI 10.1145/323663.323667
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Cashion J, 2012, IEEE T VIS COMPUT GR, V18, P634, DOI 10.1109/TVCG.2012.40
   Cribbie RA, 2012, BRIT J MATH STAT PSY, V65, P56, DOI 10.1111/j.2044-8317.2011.02014.x
   de Araujo e Silva F. B., 2015, THESIS VIRGINIA POLY
   de Haan G., 2006, EUROGRAPHICS S VIRTU, P109
   de Haan Gerwin., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments EGVE'05, P201, DOI DOI 10.2312/EGVE/IPT_EGVE2005/201-209
   Elmqvist N., 2007, INT J VIRTUAL REALIT, V6, P21
   Elmqvist Niklas., 2006, VRST 06, P9, DOI DOI 10.1145/1180495.1180500
   Grossman T, 2004, P SIGCHI C HUM FACT, V6, P447, DOI [10.1145/985692.985749, DOI 10.1145/985692.985749]
   Grossman T., 2006, P UIST 2006, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   HOFFMANN ER, 1991, ERGONOMICS, V34, P211, DOI 10.1080/00140139108967307
   Hornbæk K, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1275511.1275512
   Ian Scott MacKenzie. ., 2013, Open Journal of Applied Sciences, V3, P360, DOI DOI 10.4236/OJAPPS.2013.36046
   JAGACINSKI RJ, 1980, HUM FACTORS, V22, P225, DOI 10.1177/001872088002200211
   Kabbash P., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P273, DOI 10.1145/223904.223939
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Liao HJ, 2016, J MOD APPL STAT METH, V15, P452
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.1581165829725, 10.1109/VR46266.2020.00-83]
   MacKenzie I. S., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P219, DOI 10.1145/142750.142794
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   MacKenzie I.S., 2018, The wiley handbook of human computer interaction, V1, P347, DOI DOI 10.1002/9781118976005.CH17
   Mendes D, 2017, IEEE SYMP 3D USER, P237, DOI 10.1109/3DUI.2017.7893359
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Mircioiu C, 2017, PHARMACY, V5, DOI 10.3390/pharmacy5020026
   Murata A, 2001, HUM MOVEMENT SCI, V20, P791, DOI 10.1016/S0167-9457(01)00058-6
   Naumann A., 2010, Proceedings of the 12th international conference on Human computer interaction with mobile devices and services, P401, DOI [DOI 10.1145/1851600.1851685, https://doi.org/10.1145/1851600.1851685]
   Olwal A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P300, DOI 10.1109/ISMAR.2003.1240730
   Olwal A., 2003, FLEXIBLE POINTER INT, P81
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Poupyrev I., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P21, DOI 10.1145/261135.261141
   Riege K, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P63
   Sarkar M., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P83, DOI 10.1145/142750.142763
   Shoemaker G, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2395131.2395135
   Shoemaker G, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P999
   Steed A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P103, DOI 10.1109/TRIDUI.2006.1618279
   Teather RobertJ., 2013, Conference on Human Factors in Computing Systems - Proceedings, P159, DOI DOI 10.1145/2470654.2470677
   Ullrich D., 2010, Mensch Computer 2010: Interaktive Kulturen, Interdisziplinare Fachtagung, Duisburg, Germany, September 12-15, 2010, P251
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Wingrave C. A., 2001, P VIRT REAL INT C, P181
   Wingrave CA, 2005, P IEEE VIRT REAL ANN, P163
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376876
   Wonner Jonathan, 2012, P 18 ACM S VIRT REAL, P101, DOI 10.1145/2407336.2407356
   Wyss HP, 2006, IEEE Symposium on 3D User Interfaces 2006, Proceedings, P59, DOI 10.1109/TRIDUI.2006.1618271
   Zhai S., 2003, P SIGCHI C HUMAN FAC, P177, DOI [10.1145/642611.642644, DOI 10.1145/642611.642644]
   ZHAI SM, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P459, DOI 10.1145/191666.191822
   Zhao HL, 2009, INT J COMPUT GAMES T, V2009, DOI 10.1155/2009/730894
NR 56
TC 2
Z9 2
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 21
PY 2021
VL 2
AR 684677
DI 10.3389/frvir.2021.684677
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2QV2
UT WOS:001021764900001
OA gold
DA 2024-07-18
ER

PT J
AU Grewe, CM
   Liu, T
   Kahl, C
   Hildebrandt, A
   Zachow, S
AF Grewe, C. Martin
   Liu, Tuo
   Kahl, Christoph
   Hildebrandt, Andrea
   Zachow, Stefan
TI Statistical Learning of Facial Expressions Improves Realism of Animated
   Avatar Faces
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE behavioral realism; animated avatar faces; avatar creation; statistical
   face models; photographic realism
ID PERCEPTION; REGRESSION; MODELS; BODY
AB A high realism of avatars is beneficial for virtual reality experiences such as avatar-mediated communication and embodiment. Previous work, however, suggested that the usage of realistic virtual faces can lead to unexpected and undesired effects, including phenomena like the uncanny valley. This work investigates the role of photographic and behavioral realism of avatars with animated facial expressions on perceived realism and congruence ratings. More specifically, we examine ratings of photographic and behavioral realism and their mismatch in differently created avatar faces. Furthermore, we utilize these avatars to investigate the effect of behavioral realism on perceived congruence between video-recorded physical person's expressions and their imitations by the avatar. We compared two types of avatars, both with four identities that were created from the same facial photographs. The first type of avatars contains expressions that were designed by an artistic expert. The second type contains expressions that were statistically learned from a 3D facial expression database. Our results show that the avatars containing learned facial expressions were rated more photographically and behaviorally realistic and possessed a lower mismatch between the two dimensions. They were also perceived as more congruent to the video-recorded physical person's expressions. We discuss our findings and the potential benefit of avatars with learned facial expressions for experiences in virtual reality and future research on enfacement.
C1 [Grewe, C. Martin; Kahl, Christoph; Zachow, Stefan] Zuse Inst Berlin ZIB, Dept Visual & Data Centr Comp, Computat Diag & Therapy Planning Grp, Berlin, Germany.
   [Liu, Tuo; Hildebrandt, Andrea] Carl von Ossietzky Univ Oldenburg, Dept Psychol, Psychol Methods & Stat Div, Oldenburg, Germany.
C3 Zuse Institute Berlin; Carl von Ossietzky Universitat Oldenburg
RP Grewe, CM (corresponding author), Zuse Inst Berlin ZIB, Dept Visual & Data Centr Comp, Computat Diag & Therapy Planning Grp, Berlin, Germany.
EM grewe@zib.de
OI Grewe, Carl Martin/0000-0001-7140-2849
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Bates D., 2007, The lme4 package, DOI DOI 10.18637/JSS.V067.I01
   Bauer DJ, 2005, MULTIVAR BEHAV RES, V40, P373, DOI 10.1207/s15327906mbr4003_5
   Bente G., 2011, Face-to-Face Communication over the Internet: Issues, Research, Challenges, P176, DOI [DOI 10.1017/CBO9780511977589.010, 10.1017/CBO9780511977589.010]
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bliese PD, 2002, ORGAN RES METHODS, V5, P362, DOI 10.1177/109442802237116
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Brunner E, 2017, J ROY STAT SOC B, V79, P1463, DOI 10.1111/rssb.12229
   Busselle R.W., 2012, ADV CULTIVATION THEO, P168
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   de Borst AW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00576
   Dobs K, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01355
   Egger B, 2020, Arxiv, DOI arXiv:1909.01815
   Ekman P., 2002, FACIAL ACTION CODING
   Estudillo AJ, 2017, Q J EXP PSYCHOL, V70, P944, DOI 10.1080/17470218.2016.1166253
   Ferri F, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.1140
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021
   Gilbert M, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P333, DOI 10.1145/3267851.3267865
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Grewe CM, 2018, IEEE INT CONF AUTOMA, P286, DOI 10.1109/FG.2018.00049
   Grewe CM, 2016, LECT NOTES COMPUT SC, V9914, P552, DOI 10.1007/978-3-319-48881-3_38
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Hays J, 2020, BEHAV RES METHODS, V52, P2604, DOI 10.3758/s13428-020-01421-4
   Herrera F, 2018, PRESENCE-VIRTUAL AUG, V27, P163, DOI 10.1162/PRES_a_00324
   Huber Patrik, 2016, P 11 INT JOINT C COM, DOI DOI 10.5220/0005669500790086
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jeong EJ, 2012, COMPUT HUM BEHAV, V28, P1840, DOI 10.1016/j.chb.2012.05.002
   KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233
   Katsyri J., 2015, NEUROIMAGE, V204, P1
   Kenward MG, 1997, BIOMETRICS, V53, P983, DOI 10.2307/2533558
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Klingenberg CP, 2002, EVOLUTION, V56, P1909
   Kruzic CO, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76672-4
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Lewis JP, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Liepelt R, 2017, PSYCHOL RES-PSYCH FO, V81, P549, DOI 10.1007/s00426-016-0766-1
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Ma K, 2019, PSYCHOL RES-PSYCH FO, V83, P373, DOI 10.1007/s00426-018-1048-x
   Ma K, 2017, JOVE-J VIS EXP, DOI 10.3791/54784
   Mäkäräinen M, 2014, COGN COMPUT, V6, P708, DOI 10.1007/s12559-014-9273-0
   Manaf A. A. A., 2019, INT J APPL CREAT ART, V2, P7, DOI [10.33736/ijaca.1575.2019, DOI 10.33736/IJACA.1575.2019]
   Mullen K. M., 2012, nnls: The Lawson-Hanson Algorithm for Non-Negative Least Squares (NNLS)
   Neumann T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508417
   Noguchi K, 2012, J STAT SOFTW, V50, P1, DOI 10.18637/jss.v050.i12
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Porciello G, 2018, CORTEX, V104, P261, DOI 10.1016/j.cortex.2018.01.007
   Serino A, 2015, EUR J NEUROSCI, V42, P2515, DOI 10.1111/ejn.13029
   Soto FA, 2019, PSYCHOL RES-PSYCH FO, V83, P544, DOI 10.1007/s00426-019-01157-7
   Sungur EA, 2005, COMMUN STAT-THEOR M, V34, P1957, DOI 10.1080/03610920500201228
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182644
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Todorov A, 2013, EMOTION, V13, P724, DOI 10.1037/a0032335
   Valstar MF, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, pJ65
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Weiss S, 2020, PERS INDIV DIFFER, V166, DOI 10.1016/j.paid.2020.110137
   Wood E, 2016, LECT NOTES COMPUT SC, V9905, P297, DOI 10.1007/978-3-319-46448-0_18
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01659
   Zibrek K., 2019, Motion, interaction and games, P1, DOI [DOI 10.1145/3359566.3360064, 10.1145/3359566.3360064]
NR 68
TC 6
Z9 6
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 12
PY 2021
VL 2
AR 619811
DI 10.3389/frvir.2021.619811
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VU0
UT WOS:001019167400001
OA gold
DA 2024-07-18
ER

PT J
AU Pedram, S
   Skarbez, R
   Palmisano, S
   Farrelly, M
   Perez, P
AF Pedram, Shiva
   Skarbez, Richard
   Palmisano, Stephen
   Farrelly, Matthew
   Perez, Pascal
TI Lessons Learned From Immersive and Desktop VR Training of Mines Rescuers
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Immersive technology; Training; High risk industry;
   Mining industry; Regression modelling; Prediction
ID VIRTUAL-REALITY; ENVIRONMENTS; PERFORMANCE; TECHNOLOGY; ACCEPTANCE;
   KNOWLEDGE; FEEDBACK; OUTCOMES; MODEL; INSTRUCTION
AB This paper discusses results from two successive rounds of virtual mines rescue training. The first round was conducted in a surround projection environment (360-VR), and the second round was conducted in desktop virtual reality (Desktop-VR). In the 360-VR condition, trainees participated as groups, making collective decisions. In the Desktop-VR condition, trainees could control their avatars individually. Overall, 372 participants took part in this study, including 284 mines rescuers who took part in 360-VR, and 243 in Desktop-VR. (155 rescuers experienced both.) Each rescuer who trained in 360-VR completed a battery of pre- and post-training questionnaires. Those who attended the Desktop-VR session only completed the post-training questionnaire. We performed principal components analysis on the questionnaire data, followed by a multiple regression analysis, the results of which suggest that the chief factor contributing to positive learning outcome was Learning Context, which extracted information about the quality of the learning content, the trainers, and their feedback. Subjective feedback from the Desktop-VR participants indicated that they preferred Desktop-VR to 360-VR for this training activity, which highlights the importance of choosing an appropriate platform for training applications, and links back to the importance of Learning Context. Overall, we conclude the following: 1) it is possible to train effectively using a variety of technologies but technology that is well-suited to the training task is more useful than technology that is "more advanced," and 2) factors that have always been important in training, such as the quality of human trainers, remain critical for virtual reality training.
C1 [Pedram, Shiva; Perez, Pascal] Univ Wollongong, SMART Infrastructure Facil, Wollongong, NSW, Australia.
   [Skarbez, Richard] Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
   [Palmisano, Stephen] Univ Wollongong, Sch Psychol, Wollongong, NSW, Australia.
   [Farrelly, Matthew] Coal Serv Pty Ltd, Lake Macquarie, NSW, Australia.
C3 University of Wollongong; La Trobe University; University of Wollongong
RP Pedram, S (corresponding author), Univ Wollongong, SMART Infrastructure Facil, Wollongong, NSW, Australia.
EM spedram@uow.edu.au
RI Skarbez, Richard/S-7298-2019; Palmisano, Stephen/O-1553-2018
OI Skarbez, Richard/0000-0002-2783-5257; Pedram, Shiva/0000-0002-5835-4093;
   Palmisano, Stephen/0000-0002-9140-5681
CR Alavi M, 2001, INFORM SYST RES, V12, P1, DOI 10.1287/isre.12.1.1.9720
   Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   Barbosa Mendes J., 2010, 2010 IEEE INT C VIRT, P18
   Benbunan-Fich R, 2003, IEEE T PROF COMMUN, V46, P298, DOI 10.1109/TPC.2003.819639
   Blickensderfer B., 2005, Simulation-based training: Applying lessons learned in aviation to surface transportation modes
   Butler AC, 2008, MEM COGNITION, V36, P604, DOI 10.3758/MC.36.3.604
   Chen IYL, 2009, EDUC TECHNOL SOC, V12, P134
   Chittaro L, 2018, SAFETY SCI, V102, P159, DOI 10.1016/j.ssci.2017.10.012
   Cobb SC, 2009, J INTERACT ONLINE LE, V8, P241
   Dantas AM, 2008, ADV PHYSIOL EDUC, V32, P65, DOI 10.1152/advan.00006.2007
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   Dishaw MT, 1999, INFORM MANAGE-AMSTER, V36, P9, DOI 10.1016/S0378-7206(98)00101-3
   Fulton EA, 2015, ENVIRON SCI POLICY, V48, P44, DOI 10.1016/j.envsci.2014.12.006
   Gazit Elhanan., 2006, VIRTUAL REAL-LONDON, V10, P271, DOI DOI 10.1007/S10055-006-0053-3
   Graafland M, 2012, BRIT J SURG, V99, P1322, DOI 10.1002/bjs.8819
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Hiltz S. R., 1994, VIRTUAL CLASSROOM LE, P384
   Hostetter C., 2006, Journal of Scholarship of Teaching and Learning, V6, P1
   Johnson C.I., 2014, The Cambridge handbook of multimedia learning, P449, DOI DOI 10.1017/CBO9781139547369.023
   Ju U, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00134
   Kowalski-Trakofler KM, 2003, J SAFETY RES, V34, P515, DOI 10.1016/j.jsr.2003.05.004
   Kruglikova I, 2010, GUT, V59, P181, DOI 10.1136/gut.2009.191825
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Lovreglio R., 2017, LEAN COMP CONSTR C H
   Makransky G, 2021, J EDUC PSYCHOL, V113, P719, DOI 10.1037/edu0000473
   Makransky G, 2019, COMPUT EDUC, V134, P15, DOI 10.1016/j.compedu.2019.02.002
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Mansour S., 2010, 8 ED INF SYST TECHN
   Marcus Nadine, 2011, Proceedings of the 2011 Eighth International Conference on Information Technology: New Generations (ITNG), P626, DOI 10.1109/ITNG.2011.111
   Martins LL, 2004, ACAD MANAG LEARN EDU, V3, P7, DOI 10.5465/AMLE.2004.12436815
   Matthews G., 1999, PERSONALITY PSYCHOL, V7, P335, DOI DOI 10.1177/154193120404801107
   MCAULEY E, 1989, J SPORT EXERCISE PSY, V11, P84, DOI 10.1123/jsep.11.1.84
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Meadows D.L., 2001, Simulation Gaming, V32, P522, DOI [10.1177/104687810103200408, DOI 10.1177/104687810103200408]
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Merchant Z, 2012, COMPUT EDUC, V59, P551, DOI 10.1016/j.compedu.2012.02.004
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Nakatsu R, 2000, KES'2000: FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ENGINEERING SYSTEMS & ALLIED TECHNOLOGIES, VOLS 1 AND 2, PROCEEDINGS, P85, DOI 10.1109/KES.2000.885765
   Ornstein A. C., 1988, CURRICULUM FDN PRINC, P348
   Parnell J.A., 2003, J MANAG EDUC, V27, P431
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Pekrun R, 2006, EDUC PSYCHOL REV, V18, P315, DOI 10.1007/s10648-006-9029-9
   Piccoli G, 2001, MIS QUART, V25, P401, DOI 10.2307/3250989
   Richardson M, 2012, PSYCHOL BULL, V138, P353, DOI 10.1037/a0026838
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sitzmann T, 2010, ACAD MANAG LEARN EDU, V9, P169, DOI 10.5465/AMLE.2010.51428542
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Stiggins R. J., 2004, CLASSROOM ASSESSMENT, P460
   Strandbygaard J, 2013, ANN SURG, V257, P839, DOI 10.1097/SLA.0b013e31827eee6e
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Taylor G. S., 2011, TRAINING CAPABILITIE
   Tichon J., 2011, J HLTH SAFETY RES PR, V3, P33
   van Ginkel S, 2019, COMPUT EDUC, V134, P78, DOI 10.1016/j.compedu.2019.02.006
   Vogel J. J., 2006, Journal of Educational Computing Research, V34, P229, DOI 10.2190/FLHV-K4WA-WPVQ-H0YM
   Wan Z., 2006, AMCIS 2006 P, V253, P2036
   Wisniewski B, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03087
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhang C., 2010, Proceedings of the Southern Association for Information Systems Conference, USA, P196
NR 60
TC 4
Z9 4
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 26
PY 2021
VL 2
AR 627333
DI 10.3389/frvir.2021.627333
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZN3
UT WOS:001019265900001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Hemmerich, W
   Keshavarz, B
   Hecht, H
AF Hemmerich, Wanja
   Keshavarz, Behrang
   Hecht, Heiko
TI Visually Induced Motion Sickness on the Horizon
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE reference information; motion sickness; visually induced motion
   sickness; virtual reality; artificial horizon; performance;
   time-to-contact (TTC)
ID HEART-RATE; NYSTAGMUS; VECTION; PERCEPTION; SEVERITY; TIME
AB Visually induced motion sickness is an unpleasant but common side-effect of many simulations and VR-applications. We investigated whether an earth-fixed reference frame provided in the simulation is able to reduce motion sickness. To do so, we created a moving starfield that did not contain any indicators of the spatial orientation of the observer. As the observer was simulated to move through the randomly oscillating starfield, a time-to-contact task had to be carried out. Two colored stars on collision course with each other had to be spotted, then they disappeared and the time of their collision had to be judged. Eye-movements, task performance, and motion sickness were recorded. This condition without visual reference to the observer's upright was supplemented with three conditions containing either an earth-fixed fixation cross, an earth-fixed horizon line, or a line that was yoked to the head. Results show that only the earth-fixed horizon was able to significantly reduce visually induced motion sickness. Thus, a mere earth-stationary anchor does not suffice, a clear indication of earth horizontal seems necessary to reap a modest benefit.
C1 [Hemmerich, Wanja; Hecht, Heiko] Johannes Gutenberg Univ Mainz, Dept Psychol, Mainz, Germany.
   [Keshavarz, Behrang] Univ Hlth Network, Toronto Rehab, KITE Res Inst, Toronto, ON, Canada.
   [Keshavarz, Behrang] Ryerson Univ, Dept Psychol, Toronto, ON, Canada.
C3 Johannes Gutenberg University of Mainz; University of Toronto;
   University Health Network Toronto; Toronto Rehabilitation Institute;
   Toronto Metropolitan University
RP Hemmerich, W; Hecht, H (corresponding author), Johannes Gutenberg Univ Mainz, Dept Psychol, Mainz, Germany.
EM wahemmer@students.uni-mainz.de; hecht@uni-mainz.de
RI Keshavarz, Behrang/AFQ-0294-2022; Hecht, Heiko/H-3106-2011
OI Hecht, Heiko/0000-0001-9418-862X; Keshavarz, Behrang/0000-0002-7763-5325
CR [Anonymous], 1975, Motion sickness
   Bakdash JZ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00456
   Bonato F, 2015, AEROSP MED HUM PERF, V86, P440, DOI 10.3357/AMHP.4105.2015
   Brendel E, 2012, ATTEN PERCEPT PSYCHO, V74, P979, DOI 10.3758/s13414-012-0285-0
   BRUNER J M, 1955, U S Armed Forces Med J, V6, P469
   Burcham P. M., 2002, ARLMR504
   Chen DJ, 2016, ERGONOMICS, V59, P582, DOI 10.1080/00140139.2015.1078501
   Claremont CA., 1931, PSYCHE, V11, P86
   Comstock J. R., 2003, P HUM FACTORS ERGON, V47, P144, DOI [10.1177/154193120304700130, DOI 10.1177/154193120304700130]
   COWINGS PS, 1986, PSYCHOPHYSIOLOGY, V23, P542, DOI 10.1111/j.1469-8986.1986.tb00671.x
   CRAMPTON GH, 1955, J APPL PHYSIOL, V7, P501, DOI 10.1152/jappl.1955.7.5.501
   D'Amour S, 2017, EXP BRAIN RES, V235, P2811, DOI 10.1007/s00221-017-5009-1
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   De Muth J.E., 2006, BASIC STAT PHARM STA, V2nd
   Doweck I, 1997, J AUTONOM NERV SYST, V67, P31, DOI 10.1016/S0165-1838(97)00090-8
   Duan HY, 2018, LECT NOTES COMPUT SC, V10735, P662, DOI 10.1007/978-3-319-77380-3_63
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Elbin RJ, 2019, J ATHL TRAINING, V54, P939, DOI 10.4085/1062-6050-347-18
   Flanagan MB, 2002, AVIAT SPACE ENVIR MD, V73, P1067
   Gray R, 2000, VISION RES, V40, P49, DOI 10.1016/S0042-6989(99)00157-1
   GRAYBIEL A, 1980, AVIAT SPACE ENVIR MD, V51, P211
   GUEDRY F E Jr, 1965, Contrib Sens Physiol, V14, P63
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Gupta VK, 2005, MED HYPOTHESES, V64, P1177, DOI 10.1016/j.mehy.2004.11.031
   Harm DL, 2002, HUM FAC ER, P637
   Harm DL, 1998, BRAIN RES BULL, V47, P497, DOI 10.1016/S0361-9230(98)00096-3
   Hemmerich WA, 2019, DISPLAYS, V58, P27, DOI 10.1016/j.displa.2018.11.005
   Hettinger LJ, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P1, DOI 10.1201/9781410608888.ch1
   Hill J, 1936, BRIT MED J, V1936, P802, DOI 10.1136/bmj.2.3955.802
   Holmes SR, 2001, J PSYCHOPHYSIOL, V15, P35, DOI 10.1027//0269-8803.15.1.35
   HU SQ, 1991, AVIAT SPACE ENVIR MD, V62, P308
   Kennedy R., 1992, Presence: Teleoperators and Virtual Environments, V1, P295, DOI [DOI 10.1162/PRES.1992.1.3.295, 10.1162/pres.1992.1.3.295]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, HUM FACTORS ERGON, P647
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Lackner J., 1990, MOT SICKN VIS DISPL
   Lin JJW, 2004, P SIGCHI C HUM FACT, P719, DOI DOI 10.1145/985692.985783
   Malcolm R., 1983, P PER VIS HOR DISPL
   Mayo AM, 2011, PSYCHOL SCI, V22, P118, DOI 10.1177/0956797610392927
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Mullen TJ, 1998, J VESTIBUL RES-EQUIL, V8, P95, DOI 10.1016/S0957-4271(97)00058-X
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Oldenburg M., 2018, REISEMEDIZIN IMPFEN, P96
   Pal Manoranja, 2019, Applications of Regression Techniques
   Pouke M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P665, DOI 10.1109/VR.2018.8446078
   Prothero J.D., 1998, The role of rest frames in vection, presence and motion sickness
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   Prothero JD, 1999, AVIAT SPACE ENVIR MD, V70, P277
   Quarck G, 2000, NEUROSCI LETT, V287, P49, DOI 10.1016/S0304-3940(00)01140-X
   REASON JT, 1969, INT J MAN MACH STUD, V1, P21, DOI 10.1016/S0020-7373(69)80009-X
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   ROLNICK A, 1989, AVIAT SPACE ENVIR MD, V60, P779
   Santini T, 2018, COMPUT VIS IMAGE UND, V170, P40, DOI 10.1016/j.cviu.2018.02.002
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schroer R., 2003, IEEE Aerospace and Electronic Systems Magazine, V18, P13, DOI 10.1109/MAES.2003.1226529
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Steele J.E., 1961, Motion Sickness and Spatial perception, A Theoretical Study
   STERN RM, 1990, AVIAT SPACE ENVIR MD, V61, P712
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   STOUT CS, 1995, J VESTIBUL RES-EQUIL, V5, P25
   Streiner DL, 2000, CAN J PSYCHIAT, V45, P833, DOI 10.1177/070674370004500908
   Tal D, 2014, J VESTIBUL RES-EQUIL, V24, P17, DOI 10.3233/VES-130505
   Tal D, 2012, OTOL NEUROTOL, V33, P878, DOI 10.1097/MAO.0b013e318255ddab
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   TURNER M, 1995, AVIAT SPACE ENVIR MD, V66, P849
   Vagnoni E, 2012, CURR BIOL, V22, pR826, DOI 10.1016/j.cub.2012.07.053
   Virtual Escapes, 2019, JITT COMP SOFTW
   Webb NA, 2002, AVIAT SPACE ENVIR MD, V73, P351
   Yang SN, 2012, OPTOMETRY VISION SCI, V89, P1068, DOI 10.1097/OPX.0b013e31825da430
NR 71
TC 14
Z9 15
U1 12
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 24
PY 2020
VL 1
AR 582095
DI 10.3389/frvir.2020.582095
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UY2
UT WOS:001023244500001
OA gold
DA 2024-07-18
ER

PT J
AU Best, P
   McKenna, A
   Quinn, P
   Duffy, M
   Van Daele, T
AF Best, Paul
   McKenna, Alison
   Quinn, Paul
   Duffy, Michael
   Van Daele, Tom
TI Can Virtual Reality Ever Be Implemented in Routine Clinical Settings? A
   Systematic Narrative Review of Clinical Procedures Contained Within Case
   Reports for the Treatment of PTSD
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; post-traumatic stress disorder (PSTD); case reports;
   clinical settings; implementation
ID POSTTRAUMATIC-STRESS-DISORDER; COGNITIVE-PROCESSING THERAPY; PROLONGED
   EXPOSURE THERAPY; TRAUMA MANAGEMENT THERAPY; VIETNAM VETERANS; BEHAVIOR
   THERAPY; ANXIETY; CHILDREN; EFFICACY; TRIAL
AB The evidence base for the use of immersive technologies, such as Virtual Reality (VR), for the treatment of Post-Traumatic Stress Disorder (PTSD) is compelling. Despite promising results wide spread use and adoption of this technology within routine clinical practice remains limited. A lack of detailed technical guidelines might be one of the reasons that hamper such uptake. To address this gap, the current review focuses on earlier design types, namely Clinical Case Reports in order to uncover additional detail in relation to clinical presentations and unique technical procedures. Systematic searches returned 419 results with 15 studies meeting inclusion criteria. This included 13 single subject case reports studies and 2 case series, totaling 27 participants. Results show the use of VR technology to treat PTSD is mainly exposure based. When using such interventions clinicians should conduct a thorough assessment of their clients' background, trauma memory, and triggers in order to tailor the VR experience. They should also plan some early orientation work to help clients acclimatize to the new virtual environment. Gathering self-reported data every 5 min throughout exposure will help with client monitoring, alongside physiological data. The use of olfactory or tactile stimuli may also be helpful during exposure, but is not a necessity. In conclusion, the costs of VR equipment have dropped significantly in the past years making this more accessible and affordable for healthcare providers. Nonetheless, a significant gap remains regarding the use of VR interventions for PTSD in clinical practice. The dearth of qualitative data available within the case report literature, might however help to bridge this gap.
C1 [Best, Paul; McKenna, Alison; Quinn, Paul; Duffy, Michael; Van Daele, Tom] Queens Univ Belfast, Sch Social Sci Educ & Social Work, Belfast, North Ireland.
   [Best, Paul; Quinn, Paul; Van Daele, Tom] Queens Univ Belfast, Immers Technol & Digital Mental Hlth Network, Belfast, North Ireland.
   [Van Daele, Tom] Thomas More Univ Appl Sci, Expertise Unit Psychol Technol & Soc, Antwerp, Belgium.
C3 Queens University Belfast; Queens University Belfast
RP Best, P (corresponding author), Queens Univ Belfast, Sch Social Sci Educ & Social Work, Belfast, North Ireland.; Best, P (corresponding author), Queens Univ Belfast, Immers Technol & Digital Mental Hlth Network, Belfast, North Ireland.
EM p.best@qub.ac.uk
RI Van Daele, Tom/AAF-2373-2020
OI Van Daele, Tom/0000-0001-9237-9297; Duffy, MIchael/0000-0003-2194-2411
FU Medical Research Council Proximity to Discovery Award (P2D); Queen's
   University, Belfast
FX & nbsp;This publication was developed as part of funding obtained from a
   Medical Research Council Proximity to Discovery Award (P2D). Open access
   publication funding was provided by Queen's University, Belfast.
CR American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Arens AM, 2015, CLIN CASE STUD, V14, P115, DOI 10.1177/1534650114541324
   Association AP, 2017, CLIN PRACTICE GUIDEL
   Beck JG, 2007, BEHAV THER, V38, P39, DOI 10.1016/j.beth.2006.04.001
   Beidel DC, 2017, J ANXIETY DISORD, V50, P23, DOI 10.1016/j.janxdis.2017.05.001
   Best P, 2014, J INF SCI, V40, P346, DOI 10.1177/0165551514521936
   Bisson JI, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003388.pub4
   BLAKE DD, 1995, J TRAUMA STRESS, V8, P75, DOI 10.1002/jts.2490080106
   Cardenas-Lopez G., 2011, International Journal on Disability and Human Development, V10, P379, DOI DOI 10.1515/IJDHD.2011.061
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Cuijpers P, 2008, J BEHAV MED, V31, P169, DOI 10.1007/s10865-007-9144-1
   Dèttore D, 2015, COGN BEHAV THERAPY, V44, P190, DOI 10.1080/16506073.2015.1005660
   Difede J, 2002, CYBERPSYCHOL BEHAV, V5, P529, DOI 10.1089/109493102321018169
   Difede J, 2014, NEUROPSYCHOPHARMACOL, V39, P1052, DOI 10.1038/npp.2013.317
   Duffy M, 2007, BRIT MED J, V334, P1147, DOI 10.1136/bmj.39021.846852.BE
   Ehlers A, 2005, BEHAV RES THER, V43, P413, DOI 10.1016/j.brat.2004.03.006
   Ehlers A, 2000, BEHAV RES THER, V38, P319, DOI 10.1016/S0005-7967(99)00123-0
   Foa EB, 1999, J CONSULT CLIN PSYCH, V67, P194, DOI 10.1037/0022-006X.67.2.194
   Foa EB, 2005, J CONSULT CLIN PSYCH, V73, P953, DOI 10.1037/0022-006X.73.5.953
   FOA EB, 1986, PSYCHOL BULL, V99, P20, DOI 10.1037/0033-2909.99.1.20
   Foa EB, 2013, PSYCHOL SCI PUBL INT, V14, P65, DOI 10.1177/1529100612468841
   Foa EB, 2011, DEPRESS ANXIETY, V28, P1043, DOI 10.1002/da.20907
   Freedman SA, 2010, CYBERPSYCH BEH SOC N, V13, P95, DOI 10.1089/cyber.2009.0271
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Gagnier JJ, 2013, DTSCH ARZTEBL INT, V110, P603, DOI [10.7453/gahmj.2013.008, 10.1186/1752-1947-7-223, 10.1136/bcr-2013-201554, 10.3238/arztebl.2013.0603]
   Gamito P., 2007, ANN REV CYBERTHER TE, V5, P199
   Garg Rakesh, 2016, J Med Case Rep, V10, P88, DOI 10.1186/s13256-016-0853-3
   Garrett B, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/10839
   Gerardi M, 2008, J TRAUMA STRESS, V21, P209, DOI 10.1002/jts.20331
   Grimes DA, 2002, LANCET, V359, P145, DOI 10.1016/S0140-6736(02)07373-7
   Hollis C, 2018, LANCET PSYCHIAT, V5, P845, DOI 10.1016/S2215-0366(18)30296-7
   Imel ZE, 2013, J CONSULT CLIN PSYCH, V81, P394, DOI 10.1037/a0031474
   Jolstedt M, 2018, INTERNET INTERV, V12, P121, DOI 10.1016/j.invent.2017.11.003
   Lindner P, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00176
   Marks I, 1998, ARCH GEN PSYCHIAT, V55, P317, DOI 10.1001/archpsyc.55.4.317
   McLay RN, 2011, CYBERPSYCH BEH SOC N, V14, P223, DOI 10.1089/cyber.2011.0003
   McLay RN, 2010, CYBERPSYCH BEH SOC N, V13, P37, DOI 10.1089/cyber.2009.0346
   Miyahira SD, 2010, STUD HEALTH TECHNOL, V154, P214, DOI 10.3233/978-1-60750-561-7-214
   Murad MH, 2018, BMJ EVID-BASED MED, V23, P60, DOI 10.1136/bmjebm-2017-110853
   Nissen Trygve, 2014, BMC Res Notes, V7, P264, DOI 10.1186/1756-0500-7-264
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Popay J., 2006, Guidance on the conduct of narrative synthesis in systematic reviews: a product from the ESRC Methods Programme, DOI DOI 10.13140/2.1.1018.4643
   Reger GM, 2008, J CLIN PSYCHOL, V64, P940, DOI 10.1002/jclp.20512
   Resick P.A., 2014, COGN PROCESS
   Resick PA, 2002, J CONSULT CLIN PSYCH, V70, P867, DOI 10.1037//0022-006X.70.4.867
   Resick PA, 2008, J CONSULT CLIN PSYCH, V76, P243, DOI 10.1037/0022-006X.76.2.243
   Riva Giuseppe, 2004, J Neuroeng Rehabil, V1, P9, DOI 10.1186/1743-0003-1-9
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   Rizzo A, 2019, J TECHNOL HUMAN SERV, V37, P51, DOI 10.1080/15228835.2019.1604292
   Rizzo AA, 2007, 2007 VIRTUAL REHABILITATION, P122
   Rizzo A, 2010, ANN NY ACAD SCI, V1208, P114, DOI 10.1111/j.1749-6632.2010.05755.x
   Rooksby M, 2015, J ANXIETY DISORD, V29, P83, DOI 10.1016/j.janxdis.2014.11.006
   Rothbaum B.O., 2003, J COGN PSYCHOTHER, V17, P163, DOI [10.1891/jcop.17.2.163.57438, DOI 10.1891/JCOP.17.2.163.57438]
   Rothbaum BarbaraO., 1999, PTSD Research Quarterly, V10, P1
   Rothbaum BO, 2001, J CLIN PSYCHIAT, V62, P617, DOI 10.4088/JCP.v62n0808
   Rothbaum BO, 1999, J TRAUMA STRESS, V12, P263, DOI 10.1023/A:1024772308758
   Rothbaum BO., 1999, Cognitive and Behavioral Practice, V6, P234, DOI [DOI 10.1016/S1077-7229(99)80081-9, 10.1016/S1077-7229(99)80081-9]
   Roy MJ, 2014, STUD HEALTH TECHNOL, V199, P61, DOI 10.3233/978-1-61499-401-5-61
   Saraiva T., 2007, Annual Review of CyberTherapy and Telemedicine, V5, P199
   Schulz PM, 2006, COGN BEHAV PRACT, V13, P322, DOI 10.1016/j.cbpra.2006.04.011
   Stallard P, 2010, BEHAV COGN PSYCHOTH, V38, P545, DOI 10.1017/S1352465810000421
   Thew Graham R, 2019, JMIR Form Res, V3, pe13446, DOI 10.2196/13446
   Thwaites R, 2005, BEHAV COGN PSYCHOTH, V33, P177, DOI 10.1017/S1352465804001985
   Tworus R, 2010, CYBERPSYCH BEH SOC N, V13, P103, DOI 10.1089/cyber.2009.0329
   van der Vaart R, 2014, BMC PSYCHIATRY, V14, DOI 10.1186/s12888-014-0355-z
   Van Etten ML, 1998, CLIN PSYCHOL PSYCHOT, V5, P126, DOI 10.1002/(SICI)1099-0879(199809)5:3<126::AID-CPP153>3.0.CO;2-H
   van Gemert-Pijnen JEWC, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1672
   Vigerland S., 2014, Internet Interventions, V1, P111, DOI [DOI 10.1016/J.INVENT.2014.06.002, 10.1016/j.invent.2014.06.002]
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Wild J, 2016, EUR J PSYCHOTRAUMATO, V7, DOI 10.3402/ejpt.v7.31019
   Wood DP, 2007, CYBERPSYCHOL BEHAV, V10, P309, DOI 10.1089/cpb.2006.9951
   Wood DP, 2009, MIL MED, V174, P1215, DOI 10.7205/MILMED-D-03-4408
   World Health Organization, 2019, International statistical classification of diseases and related health problems, V11th
NR 73
TC 3
Z9 5
U1 4
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 19
PY 2020
VL 1
AR 563739
DI 10.3389/frvir.2020.563739
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WQ5
UT WOS:001023289100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Jasper, A
   Cone, N
   Meusel, C
   Curtis, M
   Dorneich, MC
   Gilbert, SB
AF Jasper, Angelica
   Cone, Nicholas
   Meusel, Chase
   Curtis, Michael
   Dorneich, Michael C.
   Gilbert, Stephen B.
TI Visually Induced Motion Sickness Susceptibility and Recovery Based on
   Four Mitigation Techniques
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual environment (VE); mitigation; virtual reality (VR);
   cybersickness; visually induced motion sickness (VIMS)
ID VIRTUAL-REALITY; SIMULATOR SICKNESS; TIME-COURSE; CYBERSICKNESS;
   QUESTIONNAIRE; ADAPTATION; PREVENTION; EFFICACY; SWAY
AB Virtual reality (VR) usage continues to grow, but visually induced motion sickness (VIMS) can decrease VR effectiveness for some users. This study seeks to compare methods of VIMS mitigation and explore sickness among gender and video game experience groups. Participant discomfort and early dropout are problems for studies that involve virtual environment (VE) exposure, but previous research has demonstrated that natural decay and physical, real-world hand-eye coordination tasks can serve as effective mitigation strategies. In this study, 57 participants wore a head-mounted display (HMD) and navigated a maze VE designed to induce cybersickness. Participants then experienced one of four mitigation techniques: real natural decay (HMD off), virtual natural decay (HMD on with idyllic VE and no locomotion), real hand-eye coordination task (HMD off), and virtual hand-eye coordination task (HMD on). Simulator Sickness Questionnaire (SSQ) measures were taken periodically throughout maze and mitigation tasks. Results demonstrated that peak sickness during the maze VE occurred after approximately 10 min. Analyses of mitigation techniques showed that real natural decay resulted in significantly more sickness recovery when compared with the virtual hand-eye coordination task for SSQ total score, nausea, and oculomotor constructs, but not disorientation. The real natural decay technique was the most effective at bringing participants' final sickness measure back to their initial baseline measure; however, other mitigation techniques yielded effectiveness, but at a lower rate. This study extends previous research about hand-eye mitigation approaches by demonstrating that natural decay and hand-eye tasks in a virtual and real-world setting were effective in reducing VIMS. Real-world natural decay was the most effective at mitigating VIMS, and the virtual hand-eye task was not as effective as the other three tasks. Women experienced more VIMS than men did but also recovered than men did during mitigation. Video gamers experienced less VIMS than non-gamers. These findings bolster extant knowledge about VIMS mitigation techniques and can inform future development of virtual mitigation techniques.
C1 [Jasper, Angelica; Dorneich, Michael C.; Gilbert, Stephen B.] Iowa State Univ, Coll Engn, Dept Ind & Mfg Syst Engn, Ames, IA 50011 USA.
   [Jasper, Angelica; Meusel, Chase; Curtis, Michael; Dorneich, Michael C.; Gilbert, Stephen B.] Iowa State Univ, Virtual Real Applicat Ctr, Ames, IA 50011 USA.
   [Cone, Nicholas] Iowa State Univ, Human Dev & Family Studies, Ames, IA USA.
C3 Iowa State University; Iowa State University; Iowa State University
RP Jasper, A (corresponding author), Iowa State Univ, Coll Engn, Dept Ind & Mfg Syst Engn, Ames, IA 50011 USA.; Jasper, A (corresponding author), Iowa State Univ, Virtual Real Applicat Ctr, Ames, IA 50011 USA.
EM amjasper@iastate.edu
RI Gilbert, Stephen/F-3138-2018
OI Gilbert, Stephen/0000-0002-5332-029X
FU National Science Foundation [1156841]
FX Thanks to Kayla Dawson, Kelli Jackson, and Liat Litwin for the design of
   the original Corn Maze; to Xin Wang for aiding in data collection; and
   to professors Jonathan Kelly and Richard Stone for consultation during
   this process. This material supported in part by the National Science
   Foundation Grant No. 1156841.
CR Ames SL, 2005, OPTOMETRY VISION SCI, V82, P168, DOI 10.1097/01.OPX.0000156307.95086.6
   BALTZLEY DR, 1989, AVIAT SPACE ENVIR MD, V60, P1043
   Boyd D., 2014, QUARTZ DAILY BRIEF
   Buker TJ, 2012, HUM FACTORS, V54, P235, DOI 10.1177/0018720811428734
   Champney RK, 2007, HUM FACTORS, V49, P491, DOI 10.1518/001872007X200120
   Cohen J., 1988, STAT POWER ANAL BEHA
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Curtis M.K., 2015, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V59, P1839
   Curtis M. K., 2014, THESIS IOWA STATE U
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Estrada A, 2007, AVIAT SPACE ENVIR MD, V78, P408
   Freivalds A., 2013, Niebel's Methods, Standards, and Work Design
   Fulvio J. M., 2020, BIORXIV
   Gálvez-García G, 2017, APPL ERGON, V58, P13, DOI 10.1016/j.apergo.2016.05.004
   Gamito P., 2008, Annual Review of CyberTherapy and Telemedicine: Changing the Face of Healthcare, P83
   Gamito P, 2010, STUD HEALTH TECHNOL, V154, P128, DOI 10.3233/978-1-60750-561-7-128
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Jerome C, 2005, HUM FACTORS, V49, P2258, DOI DOI 10.1177/154193120504902609
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI [DOI 10.1207/S15327108IJAP0201_2, 10.1207/s15327108ijap02012, DOI 10.1207/S15327108IJAP02012]
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2018, TRANSPORT RES F-TRAF, V54, P47, DOI 10.1016/j.trf.2018.01.007
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim S, 2018, J SOC INF DISPLAY, V26, P376, DOI 10.1002/jsid.669
   Klosterhalfen Sibylle, 2006, Gend Med, V3, P236, DOI 10.1016/S1550-8579(06)80211-1
   Knight M. M., 2006, ACM SIGGRAPH 2006 Res Posters, DOI [10.1145/1179622.1179846, DOI 10.1145/1179622.1179846]
   Koslucher F, 2016, EXP BRAIN RES, V234, P2709, DOI 10.1007/s00221-016-4675-8
   Koslucher F, 2015, AEROSP MED HUM PERF, V86, P787, DOI 10.3357/AMHP.4243.2015
   Lackner JR, 2014, EXP BRAIN RES, V232, P2493, DOI 10.1007/s00221-014-4008-8
   Lampton DR., 1994, Presence: Teleoperators and Virtual Environments, V3, P145
   Lewis T., 2015, Live_Science
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Miller KE, 2004, AVIAT SPACE ENVIR MD, V 75, P227
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Mousavi M, 2013, ADV ENG FORUM, V10, P34, DOI 10.4028/www.scientific.net/AEF.10.34
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nachum Z, 2004, LARYNGOSCOPE, V114, P581, DOI 10.1097/00005537-200403000-00036
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   OHANLON JF, 1974, AEROSPACE MED, V45, P366
   Onuki Y, 2017, P IEEE VIRT REAL ANN, P323, DOI 10.1109/VR.2017.7892307
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Regan EC, 1996, AVIAT SPACE ENVIR MD, V67, P222
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Russell MEB, 2014, APPL PSYCHOPHYS BIOF, V39, P269, DOI 10.1007/s10484-014-9265-6
   Shafer D. M., 2017, MEDIA PSYCHOL REV, V11, P1
   Skarbez R, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281530
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stone R. T., 2012, P HUM FACTORS ERGON, V56, P733, DOI [10.1177/1071181312561153, DOI 10.1177/1071181312561153]
   Walter HJ, 2019, HUM MOVEMENT SCI, V64, P389, DOI 10.1016/j.humov.2019.03.006
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
NR 57
TC 14
Z9 16
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 29
PY 2020
VL 1
AR 582108
DI 10.3389/frvir.2020.582108
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0IG8
UT WOS:001020170800001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Chen, E
   Luu, W
   Chen, R
   Rafik, A
   Ryu, Y
   Zangerl, B
   Kim, J
AF Chen, Elizabeth
   Luu, Wilson
   Chen, Rosalie
   Rafik, Ahmed
   Ryu, Yo
   Zangerl, Barbara
   Kim, Juno
TI Virtual Reality Improves Clinical Assessment of the Optic Nerve
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; material perception; 3D shape; optic nerve; optometry;
   ophthalmology
ID TO-DISC RATIO; FRESNEL MEMBRANE PRISMS; LAMINA-CRIBROSA DEPTH; CIRRUS
   HD-OCT; COHERENCE TOMOGRAPHY; FIBER LAYER; HEAD PARAMETERS; GLAUCOMA;
   MOTION; CUP
AB The most common approach to assessing the optic nerve head (ONH) in the detection and management of glaucoma relies on frontal stereoscopic images acquired by a fundus camera. Subjective clinical assessment of ONH parameters from these images (e.g., cup/disc ratio and cup depth) is limited by the absence of monocular perspective cues normally available in oblique viewing. This study examined whether viewing a rotatable 3D reconstruction of the ONH could improve the accuracy of subjective assessments by increasing linear perspective information. Images were reconstructed from optical coherence tomography (OCT) of the ONH. Trained optometry students assessed the cup/disc (C/D) ratio of ONHs with either a flat stereoscopic display or virtual reality (VR) head-mounted display (HMD) with or without dynamic slant control. Dynamic stereoscopic assessment of optic nerve head models in VR resulted in larger estimates of C/D ratio and cup depth compared to static stereoscopic assessments. A follow-up experiment using an external display revealed that relative to static monoscopic viewing, adding either dynamic viewing or stereoscopic viewing to the same display improved subjective estimates of C/D ratio relative to Cirrus HD-OCT defined objective values of C/D ratio. The findings suggest that simply changing the viewing orientation of ONH models improves clinical evaluation of C/D ratio by generating perspective cues to depth without the need for stereo viewing.
C1 [Chen, Elizabeth; Luu, Wilson; Chen, Rosalie; Rafik, Ahmed; Ryu, Yo; Zangerl, Barbara; Kim, Juno] Univ New South Wales, Sch Optometry & Vis Sci, Kensington, NSW, Australia.
   [Luu, Wilson; Zangerl, Barbara] Univ New South Wales, Ctr Eye Hlth, Kensington, NSW, Australia.
C3 University of New South Wales Sydney; University of New South Wales
   Sydney
RP Kim, J (corresponding author), Univ New South Wales, Sch Optometry & Vis Sci, Kensington, NSW, Australia.
EM juno.kim@unsw.edu.au
OI Kim, Juno/0000-0003-1300-9875; Luu, Wilson/0000-0002-5751-274X
FU Australian Research Council (ARC) Future Fellowship [FT140100535]; NHMRC
   [1033224]; Australian Government Research Training Program; Guide Dogs
   NSW/ACT
FX This research was supported by an Australian Research Council (ARC)
   Future Fellowship awarded to JK (FT140100535), and NHMRC 1033224
   partnership grant. WL was a Ph.D. candidate supported by the Australian
   Government Research Training Program and a scholarship from Guide Dogs
   NSW/ACT. Guide Dogs NSW/ACT was a partner on the NHMRC grant. This study
   was aided by the Sensory Processes Innovation Network (SPINet).
CR Aaker Grant D, 2011, Ophthalmic Surg Lasers Imaging, V42 Suppl, pS116, DOI 10.3928/15428877-20110627-11
   ADAMS AJ, 1971, AMER J OPT ARCH AM A, V48, P289
   Agarwal R, 2009, INDIAN J OPHTHALMOL, V57, P257, DOI 10.4103/0301-4738.53049
   Allison RS, 2003, VISION RES, V43, P1879, DOI 10.1016/S0042-6989(03)00298-0
   Anderson BL, 2005, NATURE, V434, P79, DOI 10.1038/nature03271
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Arthur SN, 2006, J GLAUCOMA, V15, P183, DOI 10.1097/01.ijg.0000212216.19804.ee
   Aygar E, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3147914
   Boger Y., 2017, UNDERSTANDING PIXEL
   Burgoyne CF, 2001, J GLAUCOMA, V10, pS16, DOI 10.1097/00061198-200110001-00007
   Calvo P, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/275654
   Chan HHL, 2014, AM J OPHTHALMOL, V157, P936, DOI 10.1016/j.ajo.2014.01.024
   Chauhan BC, 2013, OPHTHALMOLOGY, V120, P535, DOI 10.1016/j.ophtha.2012.09.055
   CNET, 2018, HP LP1965 LCD MON 19
   Draelos M, 2018, BIOMED OPT EXPRESS, V9, P2825, DOI 10.1364/BOE.9.002825
   Farhood H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071125
   Flanders M, 1999, CAN J OPHTHALMOL, V34, P335
   Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10
   Foster DH, 2002, P ROY SOC B-BIOL SCI, V269, P1939, DOI 10.1098/rspb.2002.2119
   Foster PJ, 2002, BRIT J OPHTHALMOL, V86, P238, DOI 10.1136/bjo.86.2.238
   Furlanetto RL, 2013, INVEST OPHTH VIS SCI, V54, P4836, DOI 10.1167/iovs.12-11530
   GIBSON EJ, 1959, J EXP PSYCHOL, V58, P40, DOI 10.1037/h0043883
   Gordon MO, 1999, ARCH OPHTHALMOL-CHIC, V117, P573
   Healey PR, 2004, AM J OPHTHALMOL, V138, P871, DOI 10.1016/j.ajo.2004.05.058
   Honson V, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00485
   HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   JONAS JB, 1993, OPHTHALMOLOGY, V100, P63
   JONAS JB, 1988, INVEST OPHTH VIS SCI, V29, P1151
   Jonas JB, 2003, BRIT J OPHTHALMOL, V87, P189, DOI 10.1136/bjo.87.2.189
   Jung KI, 2016, J GLAUCOMA, V25, pE536, DOI 10.1097/IJG.0000000000000387
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kijima R, 2016, P IEEE VIRT REAL ANN, P203, DOI 10.1109/VR.2016.7504724
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kim J, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281607
   Kim J, 2016, PROC SPIE, V0011, DOI 10.1117/12.2242783
   Kim J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00248
   Koh V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199134
   Krupin T, 2005, OPHTHALMOLOGY, V112, P376, DOI 10.1016/j.ophtha.2004.10.034
   Kuang TM, 2015, OPHTHALMOLOGY, V122, P2002, DOI 10.1016/j.ophtha.2015.06.015
   Laha B, 2012, IEEE T VIS COMPUT GR, V18, P597, DOI 10.1109/TVCG.2012.42
   Lichter P R, 1976, Trans Am Ophthalmol Soc, V74, P532
   Luu W., 2019, P SIGGRAPH AS SIGGRA, DOI [10.1145/3355056.3364590, DOI 10.1145/3355056.3364590]
   Marlow PJ, 2016, J VISION, V16, DOI 10.1167/16.1.5
   Martindale J., 2018, Oculus rift vs. HTC vive: Prices drop
   Medeiros FA, 2008, OPHTHALMOLOGY, V115, P1340, DOI 10.1016/j.ophtha.2007.11.008
   Meditec Z., 2019, CIRRUS PHOTO
   Miglior S, 2003, OPHTHALMOLOGY, V110, P340, DOI 10.1016/S0161-6420(02)01754-2
   Mills RP, 2006, AM J OPHTHALMOL, V141, P24, DOI 10.1016/j.ajo.2005.07.044
   Monsalve B, 2017, EYE, V31, P443, DOI 10.1038/eye.2016.251
   Morgan JE, 2005, BRIT J OPHTHALMOL, V89, P879, DOI 10.1136/bjo.2004.046169
   Mwanza JC, 2011, OPHTHALMOLOGY, V118, P241, DOI 10.1016/j.ophtha.2010.06.036
   Mwanza JC, 2010, INVEST OPHTH VIS SCI, V51, P5724, DOI 10.1167/iovs.10-5222
   Nidek, 2019, OPTICAL COHERENCE TO
   Oculus Rift Specs, 2016, OCULUS RIFT SPECS DK
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2016, J VISION, V16, DOI 10.1167/16.14.7
   Park SC, 2015, INVEST OPHTH VIS SCI, V56, P2059, DOI 10.1167/iovs.14-15540
   Polcar J., 2015, MM Science Journal, P613, DOI [DOI 10.17973/MMSJ.2015_06_201516, 10.17973/MMSJ.2015_06_201516]
   Quigley HA, 1999, PROG RETIN EYE RES, V18, P39, DOI 10.1016/S1350-9462(98)00014-7
   QUIGLEY HA, 1983, AM J OPHTHALMOL, V95, P673, DOI 10.1016/0002-9394(83)90389-6
   QUIGLEY HA, 1981, ARCH OPHTHALMOL-CHIC, V99, P635, DOI 10.1001/archopht.1981.03930010635009
   Reis ASC, 2012, OPHTHALMOLOGY, V119, P738, DOI 10.1016/j.ophtha.2011.09.054
   Savini G, 2009, GRAEF ARCH CLIN EXP, V247, P377, DOI 10.1007/s00417-008-0968-3
   Schulze Jurgen P, 2013, Stud Health Technol Inform, V184, P387
   Sharma A, 2011, OPHTHALMOLOGY, V118, P1348, DOI 10.1016/j.ophtha.2010.12.008
   SOLLENBERGER RL, 1993, HUM FACTORS, V35, P483, DOI 10.1177/001872089303500306
   SOMMER A, 1991, ARCH OPHTHALMOL-CHIC, V109, P77, DOI 10.1001/archopht.1991.01080010079037
   SPERLING G, 1989, J EXP PSYCHOL HUMAN, V15, P826
   Sung KR, 2012, J GLAUCOMA, V21, P498, DOI 10.1097/IJG.0b013e318220dbb7
   Sung KR, 2011, INVEST OPHTH VIS SCI, V52, P2634, DOI 10.1167/iovs.10-6246
   Uchida H, 1996, INVEST OPHTH VIS SCI, V37, P2393
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Ware C., 2005, Proceedings of the 2nd Symposium on Applied Perception in Graphics and Visualization (A Corona, Spain, August 26 - 28, V95, P51, DOI DOI 10.1145/1080402.1080411
   Weinreb RN, 2014, JAMA-J AM MED ASSOC, V311, P1901, DOI 10.1001/jama.2014.3192
   Wong E, 2015, OPTOMETRY VISION SCI, V92, P83, DOI 10.1097/OPX.0000000000000452
   YAN DB, 1994, BRIT J OPHTHALMOL, V78, P643, DOI 10.1136/bjo.78.8.643
NR 78
TC 5
Z9 5
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 5
PY 2020
VL 1
AR 4
DI 10.3389/frvir.2020.00004
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XC4
UT WOS:001023301000001
OA gold
DA 2024-07-18
ER

PT J
AU Baker, NA
   Polhemus, A
   Kenney, M
   Bloch, R
   Ward, N
   Intriligator, J
   Edwards, R
AF Baker, Nancy A.
   Polhemus, Augusta
   Kenney, Megan
   Bloch, Rina
   Ward, Nathan
   Intriligator, James
   Edwards, Robert
TI Examining the difference between 10-and 20-min of immersive virtual
   reality on symptoms, affect, and central sensitization in people with
   chronic back pain
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE chronic pain; dosage; emotion; fatigue; functional somatic syndrome
AB Immersive virtual reality (IVR) is increasingly used as a treatment for chronic pain. In this crossover randomized pilot study, we examined the effect of 10- and 20-min dosages on back pain intensity, affect, and measures of pain sensitization in people with chronic back pain (CBP). Twenty-one people with CBP were seen for two visits of IVR. Participants were randomly assigned to receive either 10- or 20-min of IVR in Visit 1 and the other dosage in Visit 2. Our primary analyses were effect sizes and simple inferential comparisons for pain intensity, affect, fatigue, and measures of pain sensitization assessed using quantitative sensory testing. Overall, IVR had a moderate, significant effect in reducing back pain intensity, negative affect, and painful aftersensations. When dosage was examined, 20-min had a moderate, significant effect on pain while 10-min had a small, non-significant effect, although the between-dosage difference was non-significant. Interestingly, effects were much larger in Visit 1, particularly for 20-min, but this diminished in Visit 2, and both dosages had a smaller effect in Visit 2. We interpret these results to indicate that pain modulation may be associated with novelty and engagement that can attenuate over time if the IVR encounter is not sufficiently engaging. Moreover, that if participants are engaged in a single session, 20-min may be necessary to obtain sufficient competency with IVR, while in subsequent sessions, 10-min of IVR may be sufficient to affect pain.
C1 [Baker, Nancy A.; Polhemus, Augusta] Tufts Univ, Dept Occupat Therapy, Musculoskeletal Hlth & Ergon Lab, Medford, MA 02155 USA.
   [Kenney, Megan] US Dept Vet Affairs, VA Pittsburgh Hlth Syst, Pittsburgh, PA USA.
   [Bloch, Rina] Tufts Med Ctr, Dept Phys Med & Rehabil, Boston, MA USA.
   [Ward, Nathan] Tufts Univ, Dept Psychol, Tufts Appl Cognit Lab, Medford, MA USA.
   [Intriligator, James] Tufts Univ, Dept Mech Engn, Medford, MA USA.
   [Edwards, Robert] Harvard Med Sch, Brigham & Womens Hosp, Pain Management Ctr, Dept Anesthesia & Pain Management, Boston, MA USA.
C3 Tufts University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); VA Pittsburgh Healthcare System; Tufts Medical
   Center; Tufts University; Tufts University; Harvard University; Brigham
   & Women's Hospital; Harvard Medical School
RP Baker, NA (corresponding author), Tufts Univ, Dept Occupat Therapy, Musculoskeletal Hlth & Ergon Lab, Medford, MA 02155 USA.
EM nancy.baker@tufts.edu
FU The 2020 Tufts CTSI Pilot Studies Program Through Tufts CTSI NIH
   Clinical and Translational Science Award [UL1TR002544]
FX The author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. Funding from 2020 Tufts
   CTSI Pilot Studies Program Through Tufts CTSI NIH Clinical and
   Translational Science Award (UL1TR002544).
CR Baker NA, 2022, CLIN J PAIN, V38, P424, DOI 10.1097/AJP.0000000000001029
   Bazzari AH, 2022, EGYPT J NEUROL PSYCH, V58, DOI 10.1186/s41983-022-00472-y
   Deyo RA, 2015, BMJ-BRIT MED J, V350, DOI 10.1136/bmj.g6380
   FoodDrug Administration, 2017, Patient Reported Outcome Measurement Information System
   Freynhagen R, 2006, CURR MED RES OPIN, V22, P1911, DOI 10.1185/030079906X132488
   Garcia L, 2022, J MED INTERNET RES, V24, DOI 10.2196/37480
   Garcia LM, 2021, J MED INTERNET RES, V23, DOI 10.2196/26292
   Gore M, 2012, SPINE, V37, pE668, DOI 10.1097/BRS.0b013e318241e5de
   Greenwald W., 2020, PCMag
   Gupta A, 2018, PAIN MED, V19, P151, DOI 10.1093/pm/pnx109
   HealthMeasures, 2022, PROMIS pain interference scoring manual
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Loreto-Quijada D, 2014, CYBERPSYCH BEH SOC N, V17, P353, DOI 10.1089/cyber.2014.0057
   Marshall E., 2019, Wilcoxon signed-rank test in SPSS
   Meucci RD, 2015, REV SAUDE PUBL, V49, DOI 10.1590/S0034-8910.2015049005874
   Nijs J, 2011, EXPERT OPIN PHARMACO, V12, P1087, DOI 10.1517/14656566.2011.547475
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Schuttert I, 2021, J CLIN MED, V10, DOI 10.3390/jcm10245931
   Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1
   Sullivan MJL, 1995, PSYCHOL ASSESSMENT, V7, P524, DOI 10.1037/1040-3590.7.4.524
   Tack C, 2021, DISABIL REHABIL-ASSI, V16, P637, DOI 10.1080/17483107.2019.1688399
   Thompson ER, 2007, J CROSS CULT PSYCHOL, V38, P227, DOI 10.1177/0022022106297301
   Woolf CJ, 2011, PAIN, V152, pS2, DOI 10.1016/j.pain.2010.09.030
NR 24
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 24
PY 2023
VL 4
AR 1260313
DI 10.3389/frvir.2023.1260313
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA AH5D4
UT WOS:001117577900001
OA gold
DA 2024-07-18
ER

PT J
AU Valls-Ratés, I
   Niebuhr, O
   Prieto, P
AF Valls-Rates, Io
   Niebuhr, Oliver
   Prieto, Pilar
TI Encouraging participant embodiment during VR-assisted public speaking
   training improves persuasiveness and charisma and reduces anxiety in
   secondary school students
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE public speaking; virtual reality; anxiety; persuasion; charisma;
   prosody; gesture; embodiment
ID PHYSICAL-ACTIVITY; HAND GESTURES; NONVERBAL BEHAVIOR; BODY MOVEMENT;
   SPEECH; COMMUNICATION; POWER; DEPRESSION; CHILDREN; SYMPTOMS
AB Practicing public speaking to simulated audiences created in virtual reality environments is reported to be effective for reducing public speaking anxiety. However, little is known about whether this effect can be enhanced by encouraging the use of gestures during VR-assisted public speaking training. In the present study two groups of secondary schools underwent a three-session public speaking training program in which they delivered short speeches to VR-simulated audiences. One group was encouraged to "embody" their speeches through gesture while the other was given no instructions regarding the use of gesture. Before and after the training sessions participants underwent respectively a pre- and a post-training session, which consisted of delivering a similar short speech to a small live audience. At pre- and post-training sessions, participants' levels of anxiety were self-assessed, their speech performances were rated for persuasiveness and charisma by independent raters, and their verbal output was analyzed for prosodic features and gesture rate. Results showed that both groups significantly reduced their self-assessed anxiety between the pre- and post-training sessions. Persuasiveness and charisma ratings increased for both groups, but to a significantly greater extent in the gesture-using group. However, the prosodic and gestural features analyzed showed no significant differences across groups or from pre-to post-training speeches. Thus, our results seem to indicate that encouraging the use of gesture in VR-assisted public speaking practice can help students be more charismatic and their delivery more persuasive before presenting in front of a live audience.
C1 [Valls-Rates, Io; Prieto, Pilar] Univ Pompeu Fabra, Dept Translat & Language Sci, Barcelona, Spain.
   [Valls-Rates, Io; Niebuhr, Oliver] Univ Southern Denmark, Ctr Ind Elect, Sonderborg, Denmark.
   [Prieto, Pilar] Inst Catalana Recerca & Estudis Avancats, ICREA, Barcelona, Catalonia, Spain.
C3 Pompeu Fabra University; University of Southern Denmark; ICREA
RP Valls-Ratés, I (corresponding author), Univ Pompeu Fabra, Dept Translat & Language Sci, Barcelona, Spain.; Valls-Ratés, I (corresponding author), Univ Southern Denmark, Ctr Ind Elect, Sonderborg, Denmark.
EM io.valls@upf.edu
RI Niebuhr, Oliver/O-7639-2018; valls rates, io/ISA-0774-2023
OI Niebuhr, Oliver/0000-0002-8623-1680; valls rates, io/0000-0001-9511-6927
FU This work benefited from funding awarded by the Spanish Ministry of
   Economy and Competitiveness (PGC2018-097007-B-I00 and
   PID2021-123823NB-I00) and the Generalitat de Catalunya (2017 SGR_971).
   We also acknowledge support from the Recercaixa Project (RecerC
   [PGC2018-097007-B-I00, PID2021-123823NB-I00]; Spanish Ministry of
   Economy and Competitiveness [2017 SGR_971]; Generalitat de Catalunya
   [RecerCaixa 2017ACUP 00249]; Recercaixa Project; Department of
   Translation at Universitat Pompeu Fabra
FX This work benefited from funding awarded by the Spanish Ministry of
   Economy and Competitiveness (PGC2018-097007-B-I00 and
   PID2021-123823NB-I00) and the Generalitat de Catalunya (2017 SGR_971).
   We also acknowledge support from the Recercaixa Project (RecerCaixa
   2017ACUP 00249) and the Department of Translation at Universitat Pompeu
   Fabra through a 1-year doctoral grant to the first author.r This work
   benefited from funding awarded by the Spanish Ministry of Economy and
   Competitiveness (PGC2018-097007-B-I00 and PID2021-123823NB-I00) and the
   Generalitat de Catalunya (2017 SGR_971). We also acknowledge support
   from the Recercaixa Project (RecerCaixa 2017ACUP 00249) and the
   Department of Translation at Universitat Pompeu Fabra through a 1-year
   doctoral grant to the first author.
CR ADDINGTON DW, 1971, SPEECH MONOGR, V38, P242
   ADLER RB, 1980, COMMUN EDUC, V29, P215, DOI 10.1080/03634528009378415
   Alibali M.W., 2005, Spatial Cognition and Computation, V5, P307, DOI [10.1207/s15427633scc05042, DOI 10.1207/S15427633SCC0504_2]
   ALIBALI MW, 1993, COGNITIVE PSYCHOL, V25, P468, DOI 10.1006/cogp.1993.1012
   Anderson C, 2006, EUR J SOC PSYCHOL, V36, P511, DOI 10.1002/ejsp.324
   [Anonymous], 1976, Experimenter effects in behavioral research
   [Anonymous], 2000, Language and Gesture, DOI [10.1017/CBO9780511620850.017, DOI 10.1017/CBO9780511620850.017]
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   AYRES J, 1985, COMMUN EDUC, V34, P318, DOI 10.1080/03634528509378623
   Backstrom Tom, 2003, Logoped Phoniatr Vocol, V28, P101, DOI 10.1080/14015430310015237
   Bailey E., 2019, Voice Speech Rev, V13, P31, DOI DOI 10.1080/23268263.2018.1537218
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147
   Bartholomay EM, 2016, PERS INDIV DIFFER, V94, P211, DOI 10.1016/j.paid.2016.01.026
   Berger S., 2017, P 43 ANN C GERMAN AC, P1454
   Bianchi-Berthouze N, 2007, LECT NOTES COMPUT SC, V4738, P102
   Bianchi-Berthouze N, 2013, HUM-COMPUT INTERACT, V28, P40, DOI 10.1080/07370024.2012.688468
   Blume BD, 2010, J OCCUP ORGAN PSYCH, V83, P663, DOI 10.1348/096317909X463652
   Boersma P., 2007, PRAAT: doing phonetics by computer
   Boetje J, 2021, J COMPUT ASSIST LEAR, V37, P253, DOI 10.1111/jcal.12484
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Boyce J.S., 2007, CHILDHOOD EDUC, V83, P142, DOI [10.1080/00094056.2007.10522899, DOI 10.1080/00094056.2007.10522899]
   Bratman GN, 2015, LANDSCAPE URBAN PLAN, V138, P41, DOI 10.1016/j.landurbplan.2015.02.005
   Burgmer P, 2013, SOC PSYCHOL PERS SCI, V4, P224, DOI 10.1177/1948550612452014
   BURGOON JK, 1990, HUM COMMUN RES, V17, P140, DOI 10.1111/j.1468-2958.1990.tb00229.x
   Cannon A, 2017, TESOL QUART, V51, P383, DOI 10.1002/tesq.344
   Carney DR, 2010, PSYCHOL SCI, V21, P1363, DOI 10.1177/0956797610383437
   CHURCH RB, 1986, COGNITION, V23, P43
   Cook SW, 2006, J COGN DEV, V7, P211, DOI 10.1207/s15327647jcd0702_4
   Cuddy A.J., 2012, Harvard Business School Working Paper, 13-027
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Daniels M. M., 2019, INT C INF TECHN DIG
   Dargue N, 2019, PSYCHOL BULL, V145, DOI 10.1037/bul0000202
   Darwin C., 1872, EXPRESSION EMOTIONS, DOI DOI 10.1037/10001-000
   Davis ML, 2017, J ANXIETY DISORD, V52, P1, DOI 10.1016/j.janxdis.2017.09.004
   de Jong NH, 2009, BEHAV RES METHODS, V41, P385, DOI 10.3758/BRM.41.2.385
   Donnelly JE, 2016, MED SCI SPORT EXER, V48, P1197, DOI 10.1249/MSS.0000000000000901
   Ekman P., 1976, SEMIOTICA, V16, P23
   Ekman P., 1969, Semiotica, V1, P49, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]
   Feyereisen P, 1999, J NONVERBAL BEHAV, V23, P153, DOI 10.1023/A:1021487510204
   Fox KR, 2000, INT J SPORT PSYCHOL, V31, P228
   Gallese V, 2005, COGN NEUROPSYCHOL, V22, P455, DOI 10.1080/02643290442000310
   Gao D., 2022, Eng. Intell. Syst, V30, P49
   Gnisci A., 2014, Smart Innovation, V26, P305, DOI [10.1007/978-3-319-04129-2_30, DOI 10.1007/978-3-319-04129-2_30]
   Gunnell KE, 2016, PREV MED, V88, P147, DOI 10.1016/j.ypmed.2016.04.002
   Hall JA, 2005, PSYCHOL BULL, V131, P898, DOI 10.1037/0033-2909.131.6.898
   Hanks E., 2019, TESL Report, V52, P72
   Heuett B.L., 2011, International Journal of Humanities and Social Sciences, V1, P1, DOI DOI 10.3390/JPM10010014
   Hostetter AB, 2008, PSYCHON B REV, V15, P495, DOI 10.3758/PBR.15.3.495
   Hostetter AB, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P589
   Hostetter AB, 2019, PSYCHON B REV, V26, P721, DOI 10.3758/s13423-018-1548-0
   Jackob N, 2011, COMMUNICATIONS-GER, V36, P245, DOI 10.1515/COMM.2011.012
   Jusslin S, 2022, EDUC RES REV-NETH, V37, DOI 10.1016/j.edurev.2022.100480
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Kalantzis M., 2004, E-Learning and digital media, V1, P38
   Kelly S.D., 2004, Gesture, V4, P25, DOI [10.1075/gest.4.1.03kel, DOI 10.1075/GEST.4.1.03KEL]
   Kendon Adam, 2004, Gesture: Visible Action as utterance, DOI DOI 10.1017/CBO9780511807572
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kita Sotaro., 2000, Language and Gesture, P162, DOI DOI 10.1017/CBO9780511620850.011
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Korczak DJ, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-2266
   Kosmas P, 2020, INNOV LANG LEARN TEA, V14, P317, DOI 10.1080/17501229.2019.1607355
   KOUGL KM, 1980, COMMUN EDUC, V29, P234, DOI 10.1080/03634528009378418
   Krauss RM, 1996, ADV EXP SOC PSYCHOL, V28, P389, DOI 10.1016/S0065-2601(08)60241-5
   Kryston K., 2021, J. Commun. Pedagogy, V4, P131, DOI [10.31446/jcp.2021.1.13, DOI 10.31446/JCP.2021.1.13]
   Latu I.M., 2017, Comprehensive Results in Social Psychology, V2, P68, DOI DOI 10.1080/23743603.2017.1327178
   LeFebvre L. E., 2021, Imagination, Cognition and Personality, V40, P189, DOI [https://doi.org/10.1177/0276236620938310, DOI 10.1177/0276236620938310]
   Legault J, 2019, LANGUAGES-BASEL, V4, DOI 10.3390/languages4010013
   Lindner P, 2019, J ANXIETY DISORD, V61, P45, DOI 10.1016/j.janxdis.2018.07.003
   Lister H. A., 2016, The effect of virtual reality exposure on fear of public speaking using cloud-based software
   Lister Heather A., 2010, Journal of Cyber Therapy and Rehabilitation, V3, P375
   Liu X., 2014, P SPEECH PROS DUBL, P974
   Lovgren T., 2005, P DISFLUENCY SPONTAN, P123
   Manusov V., 2006, The Sage handbook of nonverbal communication, DOI DOI 10.4135/9781412976152
   Maricchiolo F, 2009, LANG COGNITIVE PROC, V24, P239, DOI 10.1080/01690960802159929
   Mathias B, 2023, TRENDS COGN SCI, V27, P81, DOI 10.1016/j.tics.2022.10.007
   McDonald D.G., 1991, PSYCHOL EFFECTS AERO
   McMahon EM, 2017, EUR CHILD ADOLES PSY, V26, P111, DOI 10.1007/s00787-016-0875-9
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   McNeill D., 2005, GESTURE THOUGHT, DOI DOI 10.7208/CHICAGO/9780226514642.001.0001
   MEHRABIA.A, 1969, J PERS SOC PSYCHOL, V13, P37, DOI 10.1037/h0027993
   Michalsky J., 2019, AUC PHILOLOGICA, V2019, P27, DOI [10.14712/24646830.2019.17, DOI 10.14712/24646830.2019.17]
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Morreale S.P., 2000, Journal of the Association for Communication Administration, V29, P1, DOI DOI 10.1080/03634520701861713
   Niebuhr Oliver, 2020, Speech and Computer. 22nd International Conference, SPECOM 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12335), P357, DOI 10.1007/978-3-030-60276-5_35
   Niebuhr O., 2019, Interfaces between digital technologies and entrepreneurship, P123
   Niebuhr O., 2018, Virtual reality simulations as a new tool for practicing presentations and refining public-speaking skills
   North M. M., 1998, International Journal of Virtual Reality, V3, P2
   Notaro A., 2021, Proc. IST Int'l. Symp. Electron. Imaging Image Qual. Syst. Perform. XVIII, V2021, P294, DOI [10.2352/ISSN.2470-1173.2021.9.IQSP-294, DOI 10.2352/ISSN.2470-1173.2021.9.IQSP-294]
   Pallavicini F, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/15635
   Pearson JC, 2006, COMMUN Q, V54, P351, DOI 10.1080/01463370600878321
   Peeters D, 2019, PSYCHON B REV, V26, P894, DOI 10.3758/s13423-019-01571-3
   Peters J, 2017, INTERSPEECH, P659, DOI 10.21437/Interspeech.2017-194
   Pine KJ, 2004, DEV PSYCHOL, V40, P1059, DOI 10.1037/0012-1649.40.6.1059
   Ranehill E, 2015, PSYCHOL SCI, V26, P653, DOI 10.1177/0956797614553946
   Rasipuram S, 2016, ANNU IEEE IND CONF
   RAY GB, 1986, COMMUN MONOGR, V53, P266, DOI 10.1080/03637758609376141
   Remacle A, 2021, VIRTUAL REAL-LONDON, V25, P935, DOI 10.1007/s10055-020-00491-1
   Rocklage MD, 2018, PSYCHOL SCI, V29, P749, DOI 10.1177/0956797617744797
   Rodero E, 2022, FRONT COMMUN, V7, DOI 10.3389/fcomm.2022.869084
   Rodero E, 2022, COMUNICAR, V30, DOI 10.3916/C72-2022-07
   Rodero E, 2022, J LANG SOC PSYCHOL, V41, P659, DOI 10.1177/0261927X221078317
   Rohrer Patrick Louis, 2021, OSF, DOI 10.17605/OSF.IO/ANKDX
   Rosenberg A, 2009, SPEECH COMMUN, V51, P640, DOI 10.1016/j.specom.2008.11.001
   Sakib M. N., 2019, P 19 INT C CONSTR AP, P171
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Scheidel T., 1967, Persuasive Speaking
   Schneider J, 2017, J COMPUT ASSIST LEAR, V33, P164, DOI 10.1111/jcal.12175
   Selck K., 2022, Book of abstracts of the 13th nordic prosody conference, P44
   Shapiro L, 2014, ROUTLEDGE HBK PHILOS, P1
   Siegert I, 2021, FRONT COMMUN, V5, DOI 10.3389/fcomm.2020.611555
   Signorello R, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P435, DOI 10.1109/SocialCom-PASSAT.2012.68
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Smith CD, 2005, COMMUN REP, V18, P31, DOI 10.1080/08934210500084206
   Spring R, 2019, FOREIGN LANG ANN, V52, P87, DOI 10.1111/flan.12381
   Takac M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216288
   Tanner BA, 2012, APPL PSYCHOPHYS BIOF, V37, P31, DOI 10.1007/s10484-011-9174-x
   Thomas LE, 2009, PSYCHON B REV, V16, P719, DOI 10.3758/PBR.16.4.719
   Thrasher T, 2022, CALICO J, V39, P219, DOI 10.1558/cj.42198
   Tse A. Y., 2012, Int. J. Asian Soc. Sci, V2, P2061
   Vallade JI, 2021, COMMUN EDUC, V70, P127, DOI 10.1080/03634523.2020.1791351
   Valls-Rates I., 2023, Using virtual reality to train public speaking skills in a secondary school setting
   Valls-Rates I, 2022, FRONT COMMUN, V7, DOI 10.3389/fcomm.2022.910952
   Van Ginkel S, 2020, J COMPUT ASSIST LEAR, V36, P412, DOI 10.1111/jcal.12424
   van Ginkel S, 2019, COMPUT EDUC, V134, P78, DOI 10.1016/j.compedu.2019.02.006
   Wagner U, 2004, NATURE, V427, P352, DOI 10.1038/nature02223
   Wallach HS, 2011, ISR J PSYCHIATR REL, V48, P91
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Wang F, 2014, INT J BEHAV MED, V21, P605, DOI 10.1007/s12529-013-9351-9
   Weber Max., 1968, On Charisma and Institution Building
   Weninger F, 2012, IEEE T AFFECT COMPUT, V3, P496, DOI 10.1109/T-AFFC.2012.15
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Wolpe J., 1969, PRACTICE BEHAV THERA
   Xu Y., 2013, P TOOLS RES AN SPEEC, P7
   Yokoyama H, 2012, PSYCHOL REP, V110, P663, DOI 10.2466/07.11.21.28.PR0.110.2.663-676
   Yuen EK, 2019, J CONTEXT BEHAV SCI, V12, P47, DOI 10.1016/j.jcbs.2019.01.006
   Zacarin Marcela Roberta Jacyntho, 2019, Trends Psychol., V27, P491, DOI 10.9788/tp2019.2-14
   Zellin M, 2014, PSYCHON B REV, V21, P1073, DOI 10.3758/s13423-013-0568-z
NR 141
TC 1
Z9 1
U1 4
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 3
PY 2023
VL 4
AR 1074062
DI 10.3389/frvir.2023.1074062
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA U4EV3
UT WOS:001084353800001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Johnson-Glenberg, MC
   Yu, CSP
   Liu, F
   Amador, C
   Bao, YM
   Yu, SF
   LiKamWa, R
AF Johnson-Glenberg, Mina C.
   Yu, Christine S. P.
   Liu, Frank
   Amador, Charles
   Bao, Yueming
   Yu, Shufan
   LiKamWa, Robert
TI Embodied mixed reality with passive haptics in STEM education:
   randomized control study with chemistry titration
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE mixed reality (MR); chemistry; passive haptics; embodied learning; stem
   education; 3D-printable; XR
ID STUDENTS; GESTURE; OBJECTS
AB Researchers, educators, and multimedia designers need to better understand how mixing physical tangible objects with virtual experiences affects learning and science identity. In this novel study, a 3D-printed tangible that is an accurate facsimile of the sort of expensive glassware that chemists use in real laboratories is tethered to a laptop with a digitized lesson. Interactive educational content is increasingly being placed online, it is important to understand the educational boundary conditions associated with passive haptics and 3D-printed manipulables. Cost-effective printed objects would be particularly welcome in rural and low Socio-Economic (SES) classrooms. A Mixed Reality (MR) experience was created that used a physical 3D-printed haptic burette to control a computer-based chemistry titration experiment. This randomized control trial study with 136 college students had two conditions: 1) low-embodied control (using keyboard arrows), and 2) high-embodied experimental (physically turning a valve/stopcock on the 3D-printed burette). Although both groups displayed similar significant gains on the declarative knowledge test, deeper analyses revealed nuanced Aptitude by Treatment Interactions (ATIs). These interactions favored the high-embodied experimental group that used the MR device for both titration-specific posttest knowledge questions and for science efficacy and science identity. Those students with higher prior science knowledge displayed higher titration knowledge scores after using the experimental 3D-printed haptic device. A multi-modal linguistic and gesture analysis revealed that during recall the experimental participants used the stopcock-turning gesture significantly more often, and their recalls created a significantly different Epistemic Network Analysis (ENA). ENA is a type of 2D projection of the recall data, stronger connections were seen in the high embodied group mainly centering on the key hand-turning gesture. Instructors and designers should consider the multi-modal and multi-dimensional nature of the user interface, and how the addition of another sensory-based learning signal (haptics) might differentially affect lower prior knowledge students. One hypothesis is that haptically manipulating novel devices during learning may create more cognitive load. For low prior knowledge students, it may be advantageous for them to begin learning content on a more ubiquitous interface (e.g., keyboard) before moving them to more novel, multi-modal MR devices/interfaces.
C1 [Johnson-Glenberg, Mina C.; Yu, Christine S. P.] Arizona State Univ, Dept Psychol, Tempe, AZ 85281 USA.
   [Liu, Frank; Amador, Charles; Bao, Yueming; LiKamWa, Robert] Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ USA.
   [Yu, Shufan] Cent China Normal Univ, Fac Artificial Intelligence Educ, Wuhan, Peoples R China.
C3 Arizona State University; Arizona State University-Tempe; Arizona State
   University; Arizona State University-Tempe; Central China Normal
   University
RP Johnson-Glenberg, MC (corresponding author), Arizona State Univ, Dept Psychol, Tempe, AZ 85281 USA.
EM mina.johnson@asu.edu
OI LiKamWa, Robert/0000-0002-6409-6131
FU National Science Foundation [1917912]
FX Funding Research supported by National Science Foundation grant number
   1917912 to the first and last authors.
CR Aldosari S. S., 2015, 2015 5 INT C E LEARN
   [Anonymous], 1974, The Representation of Meaning in Memory
   [Anonymous], 2009, INT J LEARNING MEDIA, DOI DOI 10.1162/IJLM.2009.0013
   Argüello JM, 2020, J CHEM EDUC, V97, P2327, DOI 10.1021/acs.jchemed.0c00323
   Barmpoutis Angelos, 2020, Virtual, Augmented and Mixed Reality. Design and Interaction. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12190), P275, DOI 10.1007/978-3-030-49695-1_18
   Barmpoutis A., 2020, P 2020 HCI INT C C
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Beege M, 2020, COMPUT EDUC, V156, DOI 10.1016/j.compedu.2020.103955
   Born F, 2020, IEEE CONF COMPU INTE, P221, DOI 10.1109/CoG47356.2020.9231867
   Bouzbib E, 2021, Arxiv, DOI arXiv:2101.11278
   Bozgeyikli E., 2021, 2021 IEEE VIRT REAL
   Broaders SC, 2007, J EXP PSYCHOL GEN, V136, P539, DOI 10.1037/0096-3445.136.4.539
   Brucker B, 2021, COMPUT HUM BEHAV, V119, DOI 10.1016/j.chb.2021.106708
   Chan P, 2021, COMPUT EDUC OPEN, V2, DOI 10.1016/j.caeo.2021.100053
   Chang HY, 2023, J SCI EDUC TECHNOL, V32, P267, DOI 10.1007/s10956-022-10026-9
   Chin DB, 2010, ETR&D-EDUC TECH RES, V58, P649, DOI 10.1007/s11423-010-9154-5
   Clark R. C., 2016, E LEARNING SCI INSTR, DOI [10.1002/9781119239086, DOI 10.1002/9781119239086]
   Cook SW, 2008, COGNITION, V106, P1047, DOI 10.1016/j.cognition.2007.04.010
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Drigas A., 2016, INT J ENG SCI, V4, P25
   Dunleavy M, 2014, TECHTRENDS, V58, P28, DOI 10.1007/s11528-013-0717-2
   Dunnagan CL, 2020, J CHEM EDUC, V97, P258, DOI 10.1021/acs.jchemed.9b00705
   Flood VJ, 2015, J CHEM EDUC, V92, P11, DOI 10.1021/ed400477b
   Fuhrman O, 2021, J COMPUT ASSIST LEAR, V37, P672, DOI 10.1111/jcal.12515
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Glenberg A.M., 2008, Handbook of cognitive science: An embodied approach, P355, DOI DOI 10.1016/B978-0-08-046616-3.00018-9
   Glenberg AM, 2010, WIRES COGN SCI, V1, P586, DOI 10.1002/wcs.55
   Goldin-Meadow S, 2001, PSYCHOL SCI, V12, P516, DOI 10.1111/1467-9280.00395
   Goldin-Meadow S, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0295
   Goldin-Meadow S, 2011, WIRES COGN SCI, V2, P595, DOI 10.1002/wcs.132
   Han DT, 2018, IEEE T VIS COMPUT GR, V24, P1467, DOI 10.1109/TVCG.2018.2794659
   Hostetter AB, 2019, PSYCHON B REV, V26, P721, DOI 10.3758/s13423-018-1548-0
   Huwer J., 2018, World J. Chem. Educ, V6, P124, DOI [10.12691/wjce-6-3-4, DOI 10.12691/WJCE-6-3-4]
   Insko B.E., 2001, Passive Haptics Significantly Enhances Virtual Environ- ments
   Jimenez Z. A., 2019, TECHNOLOGY INTEGRATI, V1318, P31, DOI DOI 10.1021/BK-2019-1318.CH003
   Johnson-Glenberg MC, 2019, SMART COMPUT INTELL, P83, DOI 10.1007/978-981-13-8265-9_5
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Johnson-Glenberg MC, 2014, J EDUC PSYCHOL, V106, P86, DOI 10.1037/a0034008
   Kong CI, 2022, J CHEM EDUC, V99, P1982, DOI 10.1021/acs.jchemed.2c00096
   Kontra C, 2015, PSYCHOL SCI, V26, P737, DOI 10.1177/0956797615569355
   Lages WS, 2019, PROCEEDINGS OF IUI 2019, P356, DOI 10.1145/3301275.3302278
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Li Y, 2022, IEEE T VIS COMPUT GR, V28, P3896, DOI 10.1109/TVCG.2022.3203094
   Lindgren R, 2013, EDUC RESEARCHER, V42, P445, DOI 10.3102/0013189X13511661
   Lowry PB, 2013, J ASSOC INF SYST, V14, P617
   Macedonia M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02098
   Martinez MO, 2016, IEEE HAPTICS SYM, P126, DOI 10.1109/HAPTICS.2016.7463166
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P1, DOI 10.1017/CBO9780511811678
   McNeil NM, 2009, LEARN INSTR, V19, P171, DOI 10.1016/j.learninstruc.2008.03.005
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   McNeill D., 2008, GESTURE THOUGHT
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Naese JA, 2019, J CHEM EDUC, V96, P593, DOI 10.1021/acs.jchemed.8b00794
   Nathan MJ, 2017, COGN RES, V2, DOI 10.1186/s41235-016-0040-5
   Radu I., 2023, COMPUT ED X REAL, V2, P100008, DOI [10.1016/j.cexr.2023.100008, DOI 10.1016/J.CEXR.2023.100008]
   Radu I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300774
   Robison MK, 2020, ATTEN PERCEPT PSYCHO, V82, P3273, DOI 10.3758/s13414-020-02077-0
   Schaufeli WB, 2006, EDUC PSYCHOL MEAS, V66, P701, DOI 10.1177/0013164405282471
   Schwartz DL, 2004, COGNITION INSTRUCT, V22, P129, DOI 10.1207/s1532690xci2202_1
   Segal A, 2014, J APPL RES MEM COGN, V3, P124, DOI 10.1016/j.jarmac.2014.06.004
   Shaffer D. W., 2016, Journal of Learning Analytics, V3, P9
   Shaffer DW., 2017, Handbook of learning analytics, P175
   Sheppard K., 2006, Chemistry Education Research and Practice, V7, P32, DOI DOI 10.1039/B5RP90014J
   Stets JE, 2017, SOC SCI RES, V64, P1, DOI 10.1016/j.ssresearch.2016.10.016
   Tee NYK, 2018, J CHEM EDUC, V95, P393, DOI 10.1021/acs.jchemed.7b00618
   Ulrich M, 2021, EXTENDED ABSTRACTS OF 23RD INTERNATIONAL CONFERENCE ON MOBILE HUMAN-COMPUTER INTERACTION (MOBILEHCI 2021): MOBILE APART, MOBILE TOGETHER, DOI 10.1145/3447527.3474874
   Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1
   Walkington C., 2023, Multimodal analysis of interaction data from embodied education technologies"
   Wasserman S., 1994, Social network analysis: Methods and applications'
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Wolski R, 2019, BRIT J EDUC TECHNOL, V50, P218, DOI 10.1111/bjet.12563
   Wu LJ, 2020, LEARN INDIVID DIFFER, V82, DOI 10.1016/j.lindif.2020.101913
   Yang ZZ, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P23, DOI 10.1145/3013971.3013995
   Zacharia ZC, 2015, EDUC RES REV-NETH, V16, P116, DOI 10.1016/j.edurev.2015.10.001
   Zhang S, 2021, INT J COMP-SUPP COLL, V16, P37, DOI 10.1007/s11412-021-09339-5
   Zimmer, 1985, GERMAN J PSYCHOL, V9, P239
   Zimmer H.D., 2001, Memory for action: A distinct form of episodic memory?
NR 77
TC 1
Z9 2
U1 4
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 14
PY 2023
VL 4
AR 1047833
DI 10.3389/frvir.2023.1047833
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA N8KE8
UT WOS:001039430900001
OA gold
DA 2024-07-18
ER

PT J
AU Moore, J
   Scheirich, H
   Jadhav, S
   Enquobahrie, A
   Paniagua, B
   Wilson, A
   Bray, A
   Sankaranarayanan, G
   Clipp, RB
AF Moore, Jacob
   Scheirich, Harald
   Jadhav, Shreeraj
   Enquobahrie, Andinet
   Paniagua, Beatriz
   Wilson, Andrew
   Bray, Aaron
   Sankaranarayanan, Ganesh
   Clipp, Rachel B. B.
TI The interactive medical simulation toolkit (iMSTK): an open source
   platform for surgical simulation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual simulation; open source; surgical simulation; soft tissue
   dynamics; position-based dynamics; continuous collision detection;
   medical simulation
ID LAPAROSCOPIC CHOLECYSTECTOMY; REALITY; CARE; PERFORMANCE; SURGERY; SKILL
AB Introduction: Human error is one of the leading causes of medical error. It is estimated that human error leads to between 250,000 and 440,000 deaths each year. Medical simulation has been shown to improve the skills and confidence of clinicians and reduce medical errors. Surgical simulation is critical for training surgeons in complicated procedures and can be particularly effective in skill retention.Methods: The interactive Medical Simulation Toolkit (iMSTK) is an open source platform with position-based dynamics, continuous collision detection, smooth particle hydrodynamics, integrated haptics, and compatibility with Unity and Unreal, among others. iMSTK provides a wide range of real-time simulation capabilities with a flexible open-source license (Apache 2.0) that encourages adoption across the research and commercial simulation communities. iMSTK uses extended position-based dynamics and an established collision and constraint implementations to model biological tissues and their interactions with medical tools and other tissues.Results: The platform demonstrates performance, that is, compatible with real-time simulation that incorporates both visualization and haptics. iMSTK has been used in a variety of virtual simulations, including for laparoscopic hiatal hernia surgery, laparoscopic cholecystectomy, osteotomy procedures, and kidney biopsy procedures.Discussion: iMSTK currently supports building simulations for a wide range of surgical scenarios. Future work includes expanding Unity support to make it easier to use and improving the speed of the computation to allow for larger scenes and finer meshes for larger surgical procedures.
C1 [Moore, Jacob; Scheirich, Harald; Jadhav, Shreeraj; Enquobahrie, Andinet; Paniagua, Beatriz; Wilson, Andrew; Bray, Aaron; Clipp, Rachel B. B.] Kitware Inc, Med Comp Grp, Carrboro, NC 27510 USA.
   [Sankaranarayanan, Ganesh] Univ Texas Southwestern Med Ctr, Dept Surg, Dept Biomed Engn, Dallas, TX USA.
C3 Kitware, Inc.; University of Texas System; University of Texas
   Southwestern Medical Center Dallas
RP Clipp, RB (corresponding author), Kitware Inc, Med Comp Grp, Carrboro, NC 27510 USA.
EM Rachel.clipp@kitware.com
CR 3dsystems, 2022, OPENHAPTICS DEV SOFT
   Alexis Girault, 2019, PULSE IS NOW AVAILAB
   Arnold J, 2016, SEMIN PERINATOL, V40, P466, DOI 10.1053/j.semperi.2016.08.007
   Arnold Jennifer L., 2017, J RADIOLOGY NURS, V36, P1, DOI [10.1016/J.JRADNU.2016.12.001, DOI 10.1016/J.JRADNU.2016.12.001]
   Bansal G, 2022, IEEE ACCESS, V10, P119914, DOI 10.1109/ACCESS.2022.3219845
   Bauman E. B., 2013, THESIS LLC
   Bousseau A., 2017, SURVEY POSITION BASE
   Bray A., 2019, SN COMPR CLIN MED, V1, P362, DOI DOI 10.1007/S42399-019-00053-W
   Brown R, 2016, IEEE INT CONF SERIOU
   Caehealthcare, 2017, ABOUT US
   Clipp Rachel B., 2019, MIL HLTH RES S
   COLGATE JE, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P140, DOI 10.1109/IROS.1995.525875
   Committee on Pediatric Emergency Medicine, 2007, PEDIATRICS, V120
   Couperus K, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8062
   Educationxr, 2022, EDUCATIONXR
   Enquobahrie A, 2019, HEALTHC TECHNOL LETT, V6, P210, DOI 10.1049/htl.2019.0081
   Ericson C., 2005, Real-time collision detection
   Falcone RA, 2008, J PEDIATR SURG, V43, P1065, DOI 10.1016/j.jpedsurg.2008.02.033
   Feiger B., 2020, APS DIV FLUID DYN, V65
   Foronda CL, 2020, SIMUL HEALTHC, V15, P46, DOI 10.1097/SIH.0000000000000411
   Fu CP, 2017, MED TEACH, V39, P851, DOI 10.1080/0142159X.2017.1320540
   Google, 2022, GOOGLETEST US GUID G
   Gruen RL, 2006, ANN SURG, V244, P371, DOI 10.1097/01.sla.0000234655.83517.56
   Hcup-Us, 2022, HCUP US NIS OV
   He SR, 2022, COMPUT METH PROG BIO, V219, DOI 10.1016/j.cmpb.2022.106749
   Hoopes S, 2020, OBSTET GYNECOL, V136, P56, DOI 10.1097/AOG.0000000000003931
   Hugh TB, 2002, SURGERY, V132, P826, DOI 10.1067/msy.2002.127681
   Hyun JJ, 2011, GUT LIVER, V5, P267, DOI 10.5009/gnl.2011.5.3.267
   Imstk, 2022, IMSTK PHYS UN ASS ST
   Issenberg SB, 2005, MED TEACH, V27, P10, DOI 10.1080/01421590500046924
   James JT, 2013, J PATIENT SAF, V9, P122, DOI 10.1097/PTS.0b013e3182948a69
   Jan Bender, 2014, POSITION BASED SIMUL
   Kamarianakis M., 2022, arXiv
   Kanumuri P., 2008, JSLS, V12
   Katic D, 2013, COMPUT MED IMAG GRAP, V37, P174, DOI 10.1016/j.compmedimag.2013.03.003
   Kitware, 2022, LUM US KITW PULS PHY
   Kitware, 2022, KITW SUPP INCITEVR T
   Kitware, 2022, LAT INT MED SIM TOOL
   Laerdal, 2017, SIMMAN PROD PRIC
   Laerdal, 2017, WELC LAERD MED HELP
   Laskin DM, 2016, J ORAL MAX SURG MED, V28, P101, DOI 10.1016/j.ajoms.2015.11.001
   Macklin M, 2016, P 9 INT C MOT GAM, P49, DOI [10.1145/2994258.2994272, DOI 10.1145/2994258.2994272]
   Madan AK, 2007, SURG ENDOSC, V21, P209, DOI 10.1007/s00464-006-0149-6
   Makary MA, 2016, BMJ-BRIT MED J, V353, DOI 10.1136/bmj.i2139
   Mannella P, 2019, BMC SURG, V19, DOI 10.1186/s12893-019-0610-9
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller M, 2020, COMPUT GRAPH FORUM, V39, P101, DOI 10.1111/cgf.14105
   Neo EL, 2011, SURG ENDOSC, V25, P1775, DOI 10.1007/s00464-010-1461-8
   Niddk, 2022, KIDN DIS STAT US NID
   Nishisaki Akira, 2007, Anesthesiol Clin, V25, P225, DOI 10.1016/j.anclin.2007.03.009
   Nishisaki A, 2011, PEDIATR CRIT CARE ME, V12, P406, DOI 10.1097/PCC.0b013e3181f52b2f
   Nvidia, 2022, NVIDIA PHYSX SDK 4 1
   Obi, 2022, OB UN PART PHYS UN 3
   openstreetmap, 2022, Openstreetmap
   Parham G, 2019, ECANCERMEDICALSCIENC, V13, DOI 10.3332/ecancer.2019.910
   Patel HRH, 2012, EXPERT REV ANTICANC, V12, P417, DOI [10.1586/era.12.23, 10.1586/ERA.12.23]
   Plustoolkit, 2022, PLUS TOOLKIT
   PUNJABI AP, 1990, J ORAL MAXIL SURG, V48, P612, DOI 10.1016/S0278-2391(10)80476-8
   Qi D, 2017, J BIOMED INFORM, V75, P48, DOI 10.1016/j.jbi.2017.09.010
   Sakpal SV, 2010, JSLS-J SOC LAPAROEND, V14, P476, DOI [10.4293/108680810X12924466007926, 10.4293/108680810X12924466008240]
   Schijven M, 2003, SURG ENDOSC, V17, P1943, DOI 10.1007/s00464-003-9052-6
   Schroeder W., 2006, The visualization toolkit, V4th
   Shamiyeh A, 2004, LANGENBECK ARCH SURG, V389, P164, DOI 10.1007/s00423-004-0470-2
   Sims, 2015, SOC SIMUL HEALTHC SE
   Sims E., 2016, P INT IND TRAIN SIM
   Sims EM, 2007, COMPUT EDUC, V49, P75, DOI 10.1016/j.compedu.2005.06.006
   Slicer, 2021, 3D SLICER
   Sofa, 2022, ABOUT US
   Stefanidis D, 2005, SURGERY, V138, P165, DOI 10.1016/j.surg.2005.06.002
   Stefanidis D, 2008, SURG INNOV, V15, P69, DOI 10.1177/1553350608316683
   Sureka Binit, 2017, Indian J Radiol Imaging, V27, P470, DOI 10.4103/ijri.IJRI_489_16
   Syndaver, 2017, ABOUT US
   Taylor Glenn., 2018, Augmented Cognition: Users and Contexts, V10916, P227, DOI DOI 10.1007/978-3-319-91467-1_19
   Unity, 2022, Unity Real-Time Development Platform
   Unrealengine, 2022, MOST POW REAL TIM 3D
   Vrpn, 2022, VRPN VIRT REAL PER N
   Willie C, 2016, MED EDUC, V50, P1161, DOI 10.1111/medu.13179
   Yang D., 2022, CLIN EHEALTH, V5, P39, DOI DOI 10.1016/J.CEH.2022.04.002
   Yang D, 2022, Clinical eHealth, V5, P1, DOI [10.1016/j.ceh.2022.02.001, DOI 10.1016/J.CEH.2022.02.001]
   Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014
   Zendejas B, 2011, ANN SURG, V254, P502, DOI 10.1097/SLA.0b013e31822c6994
   Zikas P, 2023, IEEE COMPUT GRAPH, V43, P43, DOI 10.1109/MCG.2023.3242686
NR 82
TC 2
Z9 2
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 27
PY 2023
VL 4
AR 1130156
DI 10.3389/frvir.2023.1130156
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XC0
UT WOS:001023300600001
OA gold
DA 2024-07-18
ER

PT J
AU Vincent, A
   Frewen, P
AF Vincent, Andrew
   Frewen, Paul
TI Being where, with whom, and when it happens: spatial, interpersonal, and
   temporal presence while viewing live streaming of collegiate sports in
   virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; sports; presence; spatial presence; temporal presence;
   social presence; 360-degree video
ID TECHNOLOGY
AB Introduction: Although virtual reality (VR) is most popularly known for its applications to gaming, other entertainment applications are increasingly being explored including in the sports media industry, but little research has so far examined the experiences induced by VR viewing of a live sporting event.
   Materials and methods: Participants (n = 93) were university students who were approached in the context of a field study from a nearby community eatery area on the university campus to watch brief segments of a 360 degrees live stream of the home games of their university volleyball and basketball teams both while wearing and not wearing an inexpensive smart-phone based head-mounted display (HMD). Immediately afterward, participants then reported on their relative experience of spatial, interpersonal, and temporal presence, as well as their satisfaction-preference with each of the two viewing modalities, in response to brief face-valid screening questions.
   Results: The majority of participants experienced greater presence while wearing the VR headset, and approximately one in every two reported preferring to watch the games in VR. Participants' experience of spatial presence independently correlated with preferring to watch the games in VR.
   Discussion: Media vendors should offer VR viewing of sports including via inexpensive, smart-phone mediated VR as an additional, cost-effective alternative means of heightening fans' experience of virtual presence at the games when fans are unable to go to the games in person.
C1 [Vincent, Andrew; Frewen, Paul] Western Univ, Dept Psychol, London, ON, Canada.
   [Frewen, Paul] Western Univ, Dept Psychiat, London, ON, Canada.
C3 Western University (University of Western Ontario); Western University
   (University of Western Ontario)
RP Frewen, P (corresponding author), Western Univ, Dept Psychol, London, ON, Canada.; Frewen, P (corresponding author), Western Univ, Dept Psychiat, London, ON, Canada.
EM pfrewen@uwo.ca
CR Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Felton WM, 2022, INT J HUM-COMPUT INT, V38, P1, DOI 10.1080/10447318.2021.1921368
   Frewen P., 2022, SCHOLARSHIP TEACHING, DOI [10.1037/stl0000341, DOI 10.1037/STL0000341]
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   Hartmann T, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694048
   Jung S, 2021, PHYS MEDICA, V92, P1, DOI 10.1016/j.ejmp.2021.10.016
   Kim D, 2019, COMPUT HUM BEHAV, V93, P346, DOI 10.1016/j.chb.2018.12.040
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   National Basketball Association [NBA], 2023, ABOUT US
   National Hockey League [NHL], 2019, NHL NEXTVR PARTN UN
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Vincent A., 2023, 360 LIVE VR W MUSTAN
   Wilson Ragan, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P1978, DOI 10.1177/1071181319631424
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 16
TC 0
Z9 0
U1 2
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 14
PY 2023
VL 4
AR 1167051
DI 10.3389/frvir.2023.1167051
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XQ7
UT WOS:001023315300001
OA gold
DA 2024-07-18
ER

PT J
AU Delcombel, N
   Duval, T
   Pahl, MO
AF Delcombel, Nicolas
   Duval, Thierry
   Pahl, Marc-Oliver
TI Cybercopters Swarm: Immersive analytics for alerts classification based
   on periodic data
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive analytics; cybersecurity; periodic signals; virtual reality;
   alarm classification
ID INFORMATION VISUALIZATION
AB This paper assesses the usefulness of an interactive and navigable 3D environment to help decision-making in cybersecurity. Malware programs frequently emit periodic signals in network logs; however, normal periodical network activities, such as software updates and data collection activities, mask them. Thus, if automatic systems use periodicity to successfully detect malware, they also detect ordinary activities as suspicious ones and raise false positives. Hence, there is a need to provide tools to sort the alerts raised by such software. Data visualizations can make it easier to categorize these alerts, as proven by previous research. However, traditional visualization tools can struggle to display a large amount of data that needs to be treated in cybersecurity in a clear way. In response, this paper explores the use of Immersive Analytics to interact with complex dataset representations and collect cues for alert classification. We created a prototype that uses a helical representation to underline periodicity in the distribution of one variable of a dataset. We tested this prototype in an alert triage scenario and compared it with a state-of-the-art 2D visualization with regard to the visualization efficiency, usability, workload, and flow induced.
C1 [Delcombel, Nicolas; Duval, Thierry] IMT Atlantique, Lab STICC, UMR CNRS 6285, Brest, France.
   [Pahl, Marc-Oliver] IMT Atlantique, Inst Rech Informat & Syst Aleatoires IRISA, UMR CNRS 6074, Cesson Sevigne, France.
C3 Universite de Bretagne Occidentale; IMT - Institut Mines-Telecom; IMT
   Atlantique; IMT - Institut Mines-Telecom; IMT Atlantique
RP Delcombel, N (corresponding author), IMT Atlantique, Lab STICC, UMR CNRS 6285, Brest, France.
EM nicolas.delcombel@imt-atlantique.fr
OI Pahl, Marc-Oliver/0000-0001-5241-3809
FU industrial chair Cybersecurity for Critical Networked Infrastructures;
   FEDER development fund of the Brittany region; French government;
   National Research Agency under the Investments for the Future program
   (PIA) [ANR-21-ESRE-0030]
FX This work was supported by the industrial chair Cybersecurity for
   Critical Networked Infrastructures (https://CyberCNI.fr) with support of
   the FEDER development fund of the Brittany region. This work was
   supported by French government funding managed by the National Research
   Agency under the Investments for the Future program (PIA) grant
   ANR-21-ESRE-0030 (CONTINUUM).
CR Anh Huynh N., 2016, IEEE SYM VIS CYB SEC, P1, DOI 10.1109/VIZSEC.2016.7739581
   [Anonymous], 2015, 2015 BIG DATA VISUAL, DOI DOI 10.1109/BDVA.2015.7314302
   Anton SDD, 2019, THIRD CENTRAL EUROPEAN CYBERSECURITY CONFERENCE (CECC 2019), DOI 10.1145/3360664.3360669
   Bach B, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P529, DOI 10.1145/2992154.2996365
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cantu A, 2018, IEEE PAC VIS SYMP, P175, DOI 10.1109/PacificVis.2018.00030
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/ICSENS.2015.7370446, 10.1109/GLOCOM.2015.7417476]
   Cleveland W. S., 2007, J AM STAT ASSOC, V17, P1
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   Delcombel N., 2021, CYBERCOPTER 3D HELIC, V1-5
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Foresti S., 2006, IEEE COMPUT GRAPH, P1275
   Gautier J., 2017, 19 AGILE INT C GEOGR
   Gove R., 2018, P IEEE S VIS CYB SEC, P1, DOI 10.1109/VIZSEC.2018.8709177
   HART S G, 1988, P139
   Hoppe Adrian H, 2020, HCI INT 2020 POST, P30, DOI DOI 10.1007/978-3-030-50729-9_4
   Inoue J, 2017, INT CONF DAT MIN WOR, P1058, DOI 10.1109/ICDMW.2017.149
   Jackson S., 2010, FLOW MANUAL MANUAL F
   Joo D, 2003, EXPERT SYST APPL, V25, P69, DOI 10.1016/S0957-4174(03)00007-1
   Kim G, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102822
   Koffka Kurt, 2013, PRINCIPLES GESTALT P
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Legg P.A., 2015, IEEE Symposium on Visualization for Cyber Security, P1, DOI DOI 10.1109/VIZSEC.2015.7312772
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.00-23, 10.1109/VR46266.2020.1581122519414]
   Lohfink AP, 2020, IEEE T VIS COMPUT GR, V26, P1638, DOI 10.1109/TVCG.2020.2969007
   Marchetti M, 2016, INT CONF CYBER CONFL, P243, DOI 10.1109/CYCON.2016.7529438
   Yeh CCM, 2016, IEEE DATA MINING, P1317, DOI [10.1109/ICDM.2016.89, 10.1109/ICDM.2016.0179]
   Huynh NA, 2016, 2016 11TH INTERNATIONAL CONFERENCE ON MALICIOUS AND UNWANTED SOFTWARE (MALWARE), P85, DOI 10.1109/MALWARE.2016.7888733
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Prabaswari AD., 2019, IOP Conf Ser Mater Sci Eng, V528, P012018, DOI DOI 10.1088/1757-899X/528/1/012018
   Prouzeau A., 2017, P 2019 ACM INT C INT, P189, DOI [10.1145/1235, DOI 10.1145/1235]
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Scott C., 2003, Information Visualization, V2, P82, DOI 10.1057/palgrave.ivs.9500044
   Tominski C, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P175, DOI 10.1109/IV.2005.3
   Tominski Christian, 2008, P ANN SIGRAD C SPEC, P53
   Van Benschoten Andrew., 2020, Journal of Open Source Software, V5, P2179, DOI DOI 10.21105/JOSS.02179
   Wagner JA, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13430
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Ware C, 2008, MORG KAUF SER INTER, P1
   Weber M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P7, DOI 10.1109/infvis.2001.963273
   Webga K, 2015, IEEE SYM VIS CYB SEC
NR 44
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 13
PY 2023
VL 4
AR 1156656
DI 10.3389/frvir.2023.1156656
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WT7
UT WOS:001023292300001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Tu, XY
   Autiosalo, J
   Ala-Laurinaho, R
   Yang, C
   Salminen, P
   Tammi, K
AF Tu, Xinyi
   Autiosalo, Juuso
   Ala-Laurinaho, Riku
   Yang, Chao
   Salminen, Pauli
   Tammi, Kari
TI TwinXR: Method for using digital twin descriptions in industrial
   eXtended reality applications
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE eXtended reality; digital twins; metaverse; ontology; metadata; cyber
   manufacturing; human-machine interaction
AB Digital twins (DTs) and eXtended Reality (XR) are two core technological enablers for engineering in the Metaverse that can accelerate the human-centric Industry 5.0 transformation. The digital twin technology provides a digital representation of a physical asset with data linkages for inspection, monitoring, and prediction of complex processes or systems, while eXtended reality offers real-and-virtual combined environments for human users to interact with machines. However, the synergies between digital twins and eXtended reality remain understudied. This work addresses this research gap by introducing a novel method "TwinXR" that leverages ontology-based descriptions of Digital twins, i.e., digital twin documents, in industrial eXtended reality applications. To ease the use of the TwinXR method, we publish a Unity package that allows data flow and conversion between eXtended reality applications and digital twin documents on the server. Finally, the work applies the TwinXR method in two industrial eXtended reality applications involving overhead cranes and a robot arm to demonstrate the use and indicate the validity of the method. We conclude that the TwinXR method is a promising way to advance the synergies between digital twins and eXtended reality: For eXtended reality, TwinXR enables efficient and scalable eXtended reality development; For digital twins, TwinXR unlocks and demonstrates the potential of digital twins for data interchange and system interoperation. Future work includes introducing more detailed principles of Semantic Web and Knowledge Graph, as well as developing factory-level TwinXR-compatible applications.
C1 [Tu, Xinyi; Autiosalo, Juuso; Ala-Laurinaho, Riku; Yang, Chao; Salminen, Pauli; Tammi, Kari] Aalto Univ, Sch Engn, Mechatron Grp, Mech Engn, Espoo, Finland.
C3 Aalto University
RP Tu, XY (corresponding author), Aalto Univ, Sch Engn, Mechatron Grp, Mech Engn, Espoo, Finland.
EM xinyi.tu@aalto.fi
RI Tammi, Kari/J-8999-2015
OI Tammi, Kari/0000-0001-9376-2386; Tu, Xinyi/0000-0001-8914-6986; yang,
   chao/0000-0002-6220-0660
FU Business Finland; ITEA 3 Call 5 MACHINAIDE
FX This research was funded by the Business Finland under Grant
   3508/31/2019 and ITEA 3 Call 5 MACHINAIDE.
CR Ala-Laurinaho R, 2020, IEEE ACCESS, V8, P228675, DOI 10.1109/ACCESS.2020.3045856
   [Anonymous], 2017, P 50 HAWAII INT C SY, DOI DOI 10.24251/HICSS.2017.716
   Antoniou Grigoris, 2004, A Semantic Web Primer
   Autiosalo J, 2021, IEEE ACCESS, V9, P140779, DOI 10.1109/ACCESS.2021.3119487
   Autiosalo J, 2020, IEEE ACCESS, V8, P1193, DOI 10.1109/ACCESS.2019.2950507
   Begout P, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.918685
   Breque M., 2021, Industry 5.0: Towards a sustainable, humancentric and resilient European industry, DOI DOI 10.2777/308407KI-BD-20-021-EN-N
   Brewster C, 2004, IEEE INTELL SYST, V19, P72, DOI 10.1109/MIS.2004.1265889
   Chuah S.H.-W., 2018, WHY WHO WILL ADOPT E, DOI DOI 10.2139/SSRN.3300469
   Ehrlinger Lisa, 2016, Towards a Definition of Knowledge Graphs
   Flotynski J., 2020, KNOWLEDGE BASED EXPL
   Flotynski J, 2022, VIRTUAL REAL-LONDON, V26, P939, DOI 10.1007/s10055-021-00601-7
   Gobel M., 2022, SIMPLEJSON
   Górski F, 2019, LECT N MECH ENG, P104, DOI 10.1007/978-3-030-18715-6_9
   GS1, 2021, GS1 WEB VOC
   Heymann S, 2018, IEEE INT C EMERG, P187, DOI 10.1109/ETFA.2018.8502645
   Jacoby M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186519
   Kaebisch T., 2020, Web of Things (WoT) Thing Description
   Kellogg G., 2022, YAML LD
   Lee L.-H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2110.05352
   Liu MN, 2021, J MANUF SYST, V58, P346, DOI 10.1016/j.jmsy.2020.06.017
   Longo F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124182
   Ma X, 2019, PROC CIRP, V83, P789, DOI 10.1016/j.procir.2019.04.330
   Mattila J, 2022, MACHINES, V10, DOI 10.3390/machines10040225
   Microsoft, 2020, DIG TWIN DEF LANG
   Plattform Industrie 4.0, 2020, DET ASS ADM SHELL
   Podder A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.781170
   SAREF, 2021, US
   Schema.org, 2022, About us
   Siegel J, 2019, IEEE SECUR PRIV, V17, P40, DOI 10.1109/MSEC.2018.2884860
   Sparkes M, 2021, NEW SCI, V245, P18
   Sporny M., 2020, JSON LD 1 1
   Tu X., 2022, TWINXR TWINBASE IND
   Tu X., 2022, TWINXR HOLOCRANE UNI
   Tu X, TWINXR UNITY PACKAGE
   Tu XY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11209480
   Usländer T, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146585
   Vogel-Heuser B, 2016, IEEE T AUTOM SCI ENG, V13, P411, DOI 10.1109/TASE.2016.2523639
   Weistroffer V, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.781830
   Yang C, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12126030
   Zhu ZX, 2019, PROC CIRP, V81, P898, DOI 10.1016/j.procir.2019.03.223
   Zillner S, 2016, IFAC PAPERSONLINE, V49, P220, DOI 10.1016/j.ifacol.2016.10.124
   Zuehlke D, 2010, ANNU REV CONTROL, V34, P129, DOI 10.1016/j.arcontrol.2010.02.008
NR 43
TC 6
Z9 6
U1 8
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 13
PY 2023
VL 4
AR 1019080
DI 10.3389/frvir.2023.1019080
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YM7
UT WOS:001023337500001
OA gold
DA 2024-07-18
ER

PT J
AU Wolf, E
   Döllinger, N
   Mal, D
   Wenninger, S
   Bartl, A
   Botsch, M
   Latoschik, ME
   Wienrich, C
AF Wolf, Erik
   Doellinger, Nina
   Mal, David
   Wenninger, Stephan
   Bartl, Andrea
   Botsch, Mario
   Latoschik, Marc Erich
   Wienrich, Carolin
TI Does distance matter? Embodiment and perception of personalized avatars
   in relation to the self-observation distance in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual human; virtual body ownership; agency; body image distortion;
   body weight perception; body weight modification; affective appraisal;
   distance compression
ID PERCEIVED DISTANCE; MIRROR EXPOSURE; BODY SHAPES; SIZE; QUESTIONNAIRE;
   OWNERSHIP; JUDGMENTS
AB Virtual reality applications employing avatar embodiment typically use virtual mirrors to allow users to perceive their digital selves not only from a first-person but also from a holistic third-person perspective. However, due to distance-related biases such as the distance compression effect or a reduced relative rendering resolution, the self-observation distance (SOD) between the user and the virtual mirror might influence how users perceive their embodied avatar. Our article systematically investigates the effects of a short (1 m), middle (2.5 m), and far (4 m) SOD between users and mirror on the perception of their personalized and self-embodied avatars. The avatars were photorealistic reconstructed using state-of-the-art photogrammetric methods. Thirty participants repeatedly faced their real-time animated self-embodied avatars in each of the three SOD conditions, where they were repeatedly altered in their body weight, and participants rated the 1) sense of embodiment, 2) body weight perception, and 3) affective appraisal towards their avatar. We found that the different SODs are unlikely to influence any of our measures except for the perceived body weight estimation difficulty. Here, the participants perceived the difficulty significantly higher for the farthest SOD. We further found that the participants' self-esteem significantly impacted their ability to modify their avatar's body weight to their current body weight and that it positively correlated with the perceived attractiveness of the avatar. Additionally, the participants' concerns about their body shape affected how eerie they perceived their avatars. The participants' self-esteem and concerns about their body shape influenced the perceived body weight estimation difficulty. We conclude that the virtual mirror in embodiment scenarios can be freely placed and varied at a distance of one to four meters from the user without expecting major effects on the perception of the avatar.
C1 [Wolf, Erik; Mal, David; Bartl, Andrea; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
   [Doellinger, Nina; Mal, David; Wienrich, Carolin] Univ Wurzburg, Psychol Intelligent Interact Syst Grp, Wurzburg, Germany.
   [Wenninger, Stephan; Botsch, Mario] TU Dortmund Univ, Comp Graph Grp, Dortmund, Germany.
C3 University of Wurzburg; University of Wurzburg; Dortmund University of
   Technology
RP Wolf, E (corresponding author), Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
EM erik.wolf@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600; Dollinger,
   Nina/0000-0002-0609-8841; Wenninger, Stephan/0009-0008-2404-7117
FU German Federal Ministry of Education and Research in the project ViTraS
   [16SV8219, 16SV8225]; University of Wurzburg
FX This research has been funded by the German Federal Ministry of
   Education and Research in the project ViTraS (project numbers 16SV8219
   and 16SV8225). It was further supported by the Open Access Publication
   Fund of the University of Wurzburg.
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Agisoft, 2021, MET PRO
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Angelov V, 2020, 2ND INTERNATIONAL CONGRESS ON HUMAN-COMPUTER INTERACTION, OPTIMIZATION AND ROBOTIC APPLICATIONS (HORA 2020), P520, DOI 10.1109/hora49412.2020.9152604
   [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   [Anonymous], 2022, SPSS Statistics
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Arnold A. G., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P1003
   Aymerich-Franch L., 2020, TECHNOLOGY HLTH, P49, DOI [10.1016/B978-0-12-816958-2.00003-4, DOI 10.1016/B978-0-12-816958-2.00003-4]
   Bailenson Jeremy N, 2004, Berkshire Encyclopedia of Human-Computer Interaction, P64, DOI DOI 10.1108/095041206106853731
   Bartl A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694617
   Bartolini A, 2022, IEEE INT SOC CONF, P1, DOI 10.1109/SOCC56010.2022.9908096
   Bauer A, 2017, J ABNORM CHILD PSYCH, V45, P1647, DOI 10.1007/s10802-017-0263-z
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Brenner E, 1999, VISION RES, V39, P975, DOI 10.1016/S0042-6989(98)00162-X
   Buck LE, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3196885
   Chaminade T, 2007, SOC COGN AFFECT NEUR, V2, P206, DOI 10.1093/scan/nsm017
   Cohen J., 1988, STAT POWER ANAL BEHA
   COOPER PJ, 1987, INT J EAT DISORDER, V6, P485, DOI 10.1002/1098-108X(198707)6:4<485::AID-EAT2260060405>3.0.CO;2-O
   Cornelissen PL, 2018, BODY IMAGE, V24, P116, DOI 10.1016/j.bodyim.2017.12.007
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Delinsky SS, 2006, INT J EAT DISORDER, V39, P108, DOI 10.1002/eat.20207
   Döllinger N, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.935449
   Dollinger N., 2023, ARE EMBODIED A UNPUB
   Dollinger N., 2019, Mensch und Computer 2019-Workshopband, DOI [DOI 10.18420/MUC2019-WS-633, 10.18420/muc2019-ws-633]
   Eilers K., 1986, Zeitschrift fur Arbeitswissenschaft, P214
   Epstein RA, 2017, NAT NEUROSCI, V20, P1504, DOI 10.1038/nn.4656
   EVANS C, 1993, INT J EAT DISORDER, V13, P315, DOI 10.1002/1098-108X(199304)13:3<315::AID-EAT2260130310>3.0.CO;2-3
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Ferring D, 1996, DIAGNOSTICA, V42, P284
   Fiedler M. L., 2023, APPEARING BEHA UNPUB
   GILINSKY AS, 1951, PSYCHOL REV, V58, P460, DOI 10.1037/h0061505
   Gonzalez-Franco M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P941, DOI [10.1109/VR.2019.8798348, 10.1109/vr.2019.8798348]
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Griffen TC, 2018, CLIN PSYCHOL REV, V65, P163, DOI 10.1016/j.cpr.2018.08.006
   He Ding, 2000, INT IMMERSIVE PROJEC, P1, DOI 10.1080/09638280400009071
   Hepperle D, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2020), P41, DOI 10.1109/CW49994.2020.00014
   Hepperle D, 2022, VISUAL COMPUT, V38, P1227, DOI 10.1007/s00371-021-02151-0
   Higashiyama A, 2004, PERCEPT PSYCHOPHYS, V66, P679, DOI 10.3758/BF03194911
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Inoue Y, 2021, J ROBOT MECHATRON, V33, P1004, DOI 10.20965/jrm.2021.p1004
   Irvine KR, 2019, NEUROPSYCHOLOGIA, V122, P38, DOI 10.1016/j.neuropsychologia.2018.11.015
   Kamaria K, 2016, J TEKNOL, V78, P37
   Kelly JW, 2023, IEEE T VIS COMPUT GR, V29, P4978, DOI 10.1109/TVCG.2022.3196606
   Kelly JW, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3165285
   Kelly Jonathan W., 2022, Frontiers in Virtual Reality, V3, P27
   KENEALY P, 1991, J COMMUNITY APPL SOC, V1, P45, DOI 10.1002/casp.2450010108
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Korwisi K., 2021, 2021 CHI C HUMAN FAC, P1
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Leyrer M., 2011, P ACM SIGGRAPH S APP, DOI 10.1145/2077451.2077464
   LimeSurvey GmbH, 2020, LIM 4
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Lugrin J.-L., 2015, ICAT EGVE 2015 INT C, P1, DOI DOI 10.2312/EGVE.20151303
   Mal D., 2023, IMPACT AVATAR UNPUB
   Matamala-Gomez M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010139
   Mölbert SC, 2018, PSYCHOL MED, V48, P642, DOI 10.1017/S0033291717002008
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Muller M., 2016, Proceedings of the 9th International Conference on Motion in Games, MIG'16, P55, DOI [DOI 10.1145/2994258.2994269, 10.1145/2994258.2994269]
   Neyret S, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00031
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   O'Dea J., 2012, Encyclopedia of body image and human appearance, V12, P141, DOI 10.1016/B978-0-12-384925-0.00021-3
   Patzer G L, 1995, J Esthet Dent, V7, P274, DOI 10.1111/j.1708-8240.1995.tb00591.x
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Philbeck JW, 1997, J EXP PSYCHOL HUMAN, V23, P72, DOI 10.1037/0096-1523.23.1.72
   Piryankova IV, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641568
   Pook M, 2002, VERHALTENSTHERAPIE, V12, P116, DOI 10.1159/000064375
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Robinette K.M., 2002, Civilian American and European surface anthropometry resource (CAESAR), V1, DOI DOI 10.21236/ADA406704
   Romano D, 2014, BEHAV BRAIN RES, V261, P275, DOI 10.1016/j.bbr.2013.12.049
   Rosenberg M., 1965, SOC ADOLESCENT SELF, DOI DOI /10.1515/9781400876136
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Roth M, 2008, EUR J PSYCHOL ASSESS, V24, P190, DOI 10.1027/1015-5759.24.3.190
   Sedgwick H.A., 1986, Handbook of Perception and Human Performance, p21
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Spitzley KA, 2019, J BIOMECH, V87, P172, DOI 10.1016/j.jbiomech.2019.02.015
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Stefanucci JK, 2009, PERCEPTION, V38, P1782, DOI 10.1068/p6437
   Thaler A., 2018, FRONT ICT, V5, P18, DOI [DOI 10.3389/FICT.2018.00018, 10.3389/fict.2018, DOI 10.3389/FICT.2018]
   Thaler A., 2019, MPI SERIES BIOL CYBE
   Thaler A, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343134
   Thaler A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192152
   Tsakiris M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0004040
   Turbyne C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.657638
   Tuschen-Caffier B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145886
   Unity Technologies, 2019, UNIT
   Valve Corporation, 2020, STEAMVR
   Valve Corporation, 2020, IND
   Vox JP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093145
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Wienrich C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P690, DOI [10.1109/VR.2019.8798070, 10.1109/vr.2019.8798070]
   Willemsen P, 2002, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2002.996536
   Wolf E, 2022, INT SYM MIX AUGMENT, P489, DOI 10.1109/ISMAR55827.2022.00065
   Wolf E, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P350, DOI 10.1109/VR51125.2022.00054
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Wolf E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR50410.2021.00027
   World Health Organization, 2019, International statistical classification of diseases and related health problems, V11th
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zijlstra F.R.H., 1993, Efficiency in Work Behavior
NR 113
TC 3
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 21
PY 2022
VL 3
AR 1031093
DI 10.3389/frvir.2022.1031093
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UX5
UT WOS:001023243800001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Pladere, T
   Svarverud, E
   Krumina, G
   Gilson, SJ
   Baraas, RC
AF Pladere, Tatjana
   Svarverud, Ellen
   Krumina, Gunta
   Gilson, Stuart J.
   Baraas, Rigmor C.
TI Inclusivity in stereoscopic XR: Human vision first
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE XR; stereoscopic images; stereo vision; vision problems; inclusivity;
   HMD
ID AUGMENTED REALITY; PREVALENCE; AMBLYOPIA
AB Full accessibility to eXtended Reality Head-Mounted Displays (XR HMDs) includes a requirement for well-functioning eyes and visual system. Eye and vision problems-that affect visual skills and abilities to various degrees-are common and may prevent an individual from comfortably wearing and using XR HMDs. Yet, vision problems have gained little attention in the XR community, making it difficult to assess the degree of accessibility and how to increase inclusivity. This perspective article aims to highlight the need for understanding, assessing, and correcting common eye and vision problems to increase inclusivity-to help broaden a responsible uptake of XR HMDs. There is a need to apply an interdisciplinary, human-centered approach in research. Guidelines are given for conducting reproducible research to contribute to the development of more inclusive XR technologies, through consideration of the individual variations in human visual skills and abilities.
C1 [Pladere, Tatjana; Krumina, Gunta] Univ Latvia, Fac Phys Math & Optometry, Dept Optometry & Vis Sci, Riga, Latvia.
   [Svarverud, Ellen; Gilson, Stuart J.; Baraas, Rigmor C.] Univ South Eastern Norway, Fac Hlth & Social Sci, Natl Ctr Opt Vis & Eye Care, Kongsberg, Norway.
C3 University of Latvia; University College of Southeast Norway
RP Pladere, T (corresponding author), Univ Latvia, Fac Phys Math & Optometry, Dept Optometry & Vis Sci, Riga, Latvia.
EM tatjana.pladere@lu.lv
RI Krumina, Gunta/AAC-2427-2021; Krumina, Gunta/KUF-3990-2024
OI Krumina, Gunta/0000-0002-5726-3819; Krumina, Gunta/0000-0002-5726-3819;
   Pladere, Tatjana/0000-0002-7120-9755
FU University of South-Eastern Norway; Research Council of Norway (regional
   funds projects) [828390, FORREGION-VT 328526]; Latvian Council of
   Science [lzp-2021/1-0399]
FX The work was funded by the University of South-Eastern Norway, the
   Research Council of Norway (regional funds projects 828390 and
   FORREGION-VT 328526), and the Latvian Council of Science project No.
   lzp-2021/1-0399.
CR Arechiga N., 2017, U.S. Patent, Patent No. 201710
   Arnegard S, 2022, ACTA OPHTHALMOL, V100, P805, DOI 10.1111/aos.15103
   Atiya A, 2020, J OPTOM, V13, P185, DOI 10.1016/j.optom.2020.01.003
   Banstola Sanjog, 2022, Br Ir Orthopt J, V18, P57, DOI 10.22599/bioj.257
   Baraas RC, 2008, VISUAL NEUROSCI, V25, P501, DOI 10.1017/S0952523808080632
   Baraas RC, 2010, INVEST OPHTH VIS SCI, V51, P2286, DOI 10.1167/iovs.09-4576
   Birch J, 2012, J OPT SOC AM A, V29, P313, DOI 10.1364/JOSAA.29.000313
   Cakmakci Ozan, 2019, SID Symposium Digest of Technical Papers, V50, P438, DOI 10.1002/sdtp.12950
   Cholewiak SA, 2020, OPT EXPRESS, V28, P38008, DOI 10.1364/OE.408404
   Chopin A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42149-2
   Chua SYL, 2020, UPDATES ON MYOPIA: A CLINICAL PERSPECTIVE, P53, DOI 10.1007/978-981-13-8491-2_3
   Çöltekin A, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P533
   Dahal M., 2021, Med Surg Ophthal Res, V000559, DOI [10.31031/MSOR.2021.03.000559, DOI 10.31031/MSOR.2021.03.000559]
   Díaz-Barrancas F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195658
   Eisenberg E., 2022, REPLICATING HUMAN VI
   Erkelens Ian, 2020, SID Symposium Digest of Technical Papers, P265, DOI 10.1002/sdtp.13855
   Flaxman SR, 2017, LANCET GLOB HEALTH, V5, pE1221, DOI 10.1016/S2214-109X(17)30393-5
   Foreman J, 2017, OPHTHALMOLOGY, V124, P1743, DOI 10.1016/j.ophtha.2017.06.001
   Franco S, 2022, J OPTOM, V15, P271, DOI 10.1016/j.optom.2021.10.002
   Franks M. A., 2017, UC DAVIS LAW REV, P17
   Frick KD, 2015, OPHTHALMOLOGY, V122, P1706, DOI 10.1016/j.ophtha.2015.04.014
   Gopalakrishnan S, 2020, INDIAN J OPHTHALMOL, V68, P1136, DOI 10.4103/ijo.IJO_1524_19
   Gurumurthy S., 2019, MADRIDGE J BIOINFORM, V1, P31, DOI [10.18689/mjbsb-1000106, DOI 10.18689/MJBSB-1000106]
   Hashemi H, 2018, J CURR OPHTHALMOL, V30, P3, DOI 10.1016/j.joco.2017.08.009
   Hess RF, 2015, I-PERCEPTION, V6, DOI 10.1177/2041669515593028
   Hibbard PB, 2020, INT CONF 3D IMAG, DOI 10.1109/IC3D51119.2020.9376369
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Iqbal SA, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002333
   Jabbireddy S., 2022, PREPRINT, V23, DOI [10.48550/arXiv.2205.04529, DOI 10.48550/ARXIV.2205.04529]
   Kim D, 2021, BIOMED OPT EXPRESS, V12, P5179, DOI 10.1364/BOE.433919
   Levi DM, 2015, VISION RES, V114, P17, DOI 10.1016/j.visres.2015.01.002
   Mavi S, 2022, ASIA-PAC J OPHTHALMO, V11, P36, DOI 10.1097/APO.0000000000000492
   Munafò MR, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-016-0021
   Peillard E, 2020, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR50242.2020.00028
   Pladere T, 2021, J VISION, V21, DOI 10.1167/jov.21.8.17
   Ponce Gallegos J.C., 2020, LNCS, V12426, P306, DOI [10.1007/978-3, DOI 10.1007/978-3]
   Rousset T, 2018, DISPLAYS, V52, P8, DOI 10.1016/j.displa.2018.02.004
   Schieber Hannah, 2022, 2022 IEEE C VIRT REA, P726
   Sharpe L.T., 1999, COLOR VISION GENES P, P3
   SIMONS K, 1974, AM J OPHTHALMOL, V78, P707, DOI 10.1016/S0002-9394(14)76310-X
   Souchet AD, 2023, VIRTUAL REAL-LONDON, V27, P19, DOI 10.1007/s10055-022-00672-0
   Svarverud E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033782
   Svarverud E, 2010, J VISION, V10, DOI 10.1167/10.1.5
   Wu JY, 2020, OPT EXPRESS, V28, P6225, DOI 10.1364/OE.380945
   Xia XX, 2019, IEEE T VIS COMPUT GR, V25, P3114, DOI 10.1109/TVCG.2019.2932238
   Xiong JH, 2021, LIGHT-SCI APPL, V10, DOI 10.1038/s41377-021-00658-8
   Ye HH, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-021325
   Yoon HJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94680-w
   Zabels R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153147
   Zhan T, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101397
   Zhu RD, 2016, OPT EXPRESS, V24, P5431, DOI 10.1364/OE.24.005431
NR 51
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 23
PY 2022
VL 3
AR 1006021
DI 10.3389/frvir.2022.1006021
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XB3
UT WOS:001023299900001
OA gold
DA 2024-07-18
ER

PT J
AU Carius, L
   Eichhorn, C
   Rudolph, L
   Plecher, DA
   Klinker, G
AF Carius, Lars
   Eichhorn, Christian
   Rudolph, Linda
   Plecher, David A.
   Klinker, Gudrun
TI Cloud-based cross-platform collaborative augmented reality in flutter
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; collaboration; cross-platform; cloud; flutter
AB Augmented Reality (AR) as a technology in the business area is utilized in new frontiers such as collaborative real-time experiences and cloud-based solutions. However, there is still a strong tendency towards game engines, which hinders widespread adoption for businesses. We present a collaborative AR framework (Flutter plugin) aimed at lowering the entry barriers and operating expenses of AR applications. A cross-platform and cloud-based solution combined with a web-based content management system (cloud) is a powerful tool for non-technical staff to take over operational tasks such as providing 3D models or moderating community annotations. To achieve cross-platform support, the AR Flutter plugin builds upon ARCore (Android) and ARKit (iOS) and unifies the two frameworks using an abstraction layer written in Dart. In this extensive description we present an in-depth summary of the concepts to realize the framework and prove its performance being on the same level as the native AR frameworks. This includes application-level metrics like CPU and RAM consumption and tracking-level qualities such as keyframes per second used by the underlying SLAM algorithm, detected feature points, and area of tracked planes. Our contribution closes a gap in today's technological landscape by providing an AR framework with the familiar development process of cross-platform apps. Building upon on a content management system (cloud) and AR can be a game changer to achieve business objectives, while being not restrained to stand-alone single-purpose apps. This will trigger a potential paradigm shift for previously complex-to-realize applications relying on AR, e.g., in production and planning. The AR Flutter plugin is fully open-source, the code can be found at: https://github.com/ CariusLars/ar_flutter_plugin.
C1 [Carius, Lars; Eichhorn, Christian; Rudolph, Linda; Plecher, David A.; Klinker, Gudrun] Tech Univ Munich, FAR Augmented Real Res Grp, Munich, Germany.
C3 Technical University of Munich
RP Eichhorn, C (corresponding author), Tech Univ Munich, FAR Augmented Real Res Grp, Munich, Germany.
EM christian.eichhorn@tum.de
RI Klinker, Gudrun/JVP-3665-2024
OI Klinker, Gudrun/0000-0003-0971-5726
CR Baek F, 2019, AUTOMAT CONSTR, V99, P18, DOI 10.1016/j.autcon.2018.11.034
   Bonasio A., 2019, REPORT XR IND INSIGH
   Bostanci Erkan, 2013, International Journal of Computer Theory and Engineering, V5, P93, DOI 10.7763/IJCTE.2013.V5.654
   Carius L, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P673, DOI 10.1109/VRW55335.2022.00192
   Coninck B. D., 2019, FLUTTER VERSUS OTH 2
   Egodagamage R, 2018, COMPUT GRAPH-UK, V71, P113, DOI 10.1016/j.cag.2018.01.002
   Eichhorn C, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P24, DOI 10.1109/ISMAR-Adjunct51615.2020.00022
   Francesco G. M. D., 2022, ARCORE FLUTTER PLUGI
   Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   Horst R., 2021, INFORM 2020
   Huo K, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P19, DOI 10.1145/3242587.3242595
   InVerita, 2020, FLUTT VS REACT NAT N
   Kaufmann H., 2003, Collaborative augmented reality in education, P2
   Keshavarzi M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P353, DOI [10.1109/VR46266.2020.1581131119600, 10.1109/VR46266.2020.00-49]
   Kumar T., 2021, COMPUTATIONAL INTELL, P141
   Lee J., 2011, INT J DIGITAL MANAG
   Leuschenko O., 2021, ARKIT FLUTTER PLUGIN
   Lock O, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365734
   MacWilliams A., 2003, DESIGN PATTERNS AUGM
   Marchesi G, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10110772
   Miedema NA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1819, DOI [10.1109/VR.2019.8798275, 10.1109/vr.2019.8798275]
   Mourtzis Dimitris, 2020, Procedia Manufacturing, V45, P546, DOI 10.1016/j.promfg.2020.04.076
   Ohlenburg J., 2004, P ACM S VIRTUAL REAL, P166, DOI DOI 10.1145/1077534.1077568
   Oriti D, 2023, VIRTUAL REAL-LONDON, V27, P3259, DOI 10.1007/s10055-021-00585-4
   Pereira N, 2021, INT SYM MIX AUGMENT, P479, DOI 10.1109/ISMAR52148.2021.00065
   Piumsomboon T, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P218, DOI 10.1109/ISMAR-Adjunct.2017.72
   Plecher D. A., 2020, GI VR AR WORKSH
   Plecher David, 2022, ROAR ROLE AUGMENTED
   Plecher DA, 2019, LECT NOTES COMPUT SC, V11899, P550, DOI 10.1007/978-3-030-34350-7_53
   Ren JK, 2019, IEEE NETWORK, V33, P162, DOI 10.1109/MNET.2018.1800132
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Skuza B., 2019, FLUTTER VS REACT NAT
   Statista Inc, 2021, CROSS PLATF MOB FRAM
   Weber S, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.765959
   Zhang WX, 2018, HOTMOBILE'18: PROCEEDINGS OF THE 19TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, P25, DOI 10.1145/3177102.3177107
   Zillner J, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P38, DOI 10.1109/ISMAR-Adjunct.2018.00028
NR 36
TC 0
Z9 0
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 21
PY 2022
VL 3
AR 1021932
DI 10.3389/frvir.2022.1021932
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XD8
UT WOS:001023302400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Miyakami, M
   Takahashi, A
   Kajimoto, H
AF Miyakami, Masahiro
   Takahashi, Akifumi
   Kajimoto, Hiroyuki
TI Head rotation and illusory force sensation by lateral skin stretch on
   the face
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE illusory force sensation; lateral skin stretch; head rotation; haptics;
   virtual reality
ID HANGER REFLEX; DEVICE
AB Various methods for inducing an illusory force sensation to present a sense of force to users in energy-saving and space-saving systems have been proposed. One of them is the illusion of force sensation induced by cutaneous sensory stimulation. In this study, we hypothesized and empirically verified that lateral skin stretch alone on the face can induce an illusory force sensation in the direction of the stretch. We focused on the anterior temporal and cheekbone regions, in which the cushion part of the head-mounted display contacts the skin, and applied skin stretches of different intensities to these regions, envisioning a force presentation device built into the head-mounted display. Head rotations of approximately 40 and 50 degrees were generated by skin stretches in the anterior temporal and cheekbone regions, respectively, confirming the illusory force sensation in the direction of rotation. We confirmed a positive correlation between the head-turning angle and the amount of skin deformation. The intensity of the illusory force sensation can be controlled by changing the amount of lateral skin deformation; this may be applied to the development of a new force presentation head-mounted device.
C1 [Miyakami, Masahiro; Takahashi, Akifumi; Kajimoto, Hiroyuki] Univ Electrocommun, Dept Informat, Chofu, Japan.
C3 University of Electro-Communications - Japan
RP Miyakami, M (corresponding author), Univ Electrocommun, Dept Informat, Chofu, Japan.
EM miyakami@kaji-lab.jp
FU JSPS KAKENHI [JP20K20627]; JST SPRING [302, JPMJSP2131]; Grants-in-Aid
   for Scientific Research [20K20627] Funding Source: KAKEN
FX This research was supported by JSPS KAKENHI (Grant Number JP20K20627)
   and JST SPRING (Grant302 Number JPMJSP2131).
CR Amemiya T, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P619
   Amemiya T, 2014, LECT NOTES COMPUT SC, V8619, P88, DOI 10.1007/978-3-662-44196-1_12
   Aoyama K., 2017, ACM SIGGRAPH 2017 EM, DOI [10.1145/3084822.3084840, DOI 10.1145/3084822.3084840]
   Asahi T, 2020, NEUROL MED-CHIR, V60, P525, DOI 10.2176/nmc.ra.2020-0156
   Asahi T, 2018, NEUROL MED-CHIR, V58, P206, DOI 10.2176/nmc.oa.2017-0111
   Clark JP, 2018, LECT NOTES COMPUT SC, V10894, P125, DOI 10.1007/978-3-319-93399-3_12
   Colella N, 2019, IEEE ROBOT AUTOM LET, V4, P1572, DOI 10.1109/LRA.2019.2896484
   Costes A, 2021, Arxiv, DOI arXiv:2108.10196
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P227, DOI 10.1145/2984511.2984535
   Hamdan NA, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300718
   Hoppe Matthias, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3461734
   Kon Yuki, 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P765, DOI 10.1109/VR.2018.8446524
   Kon Y., 2017, In proceedings of the ACM SIGGRAPH 2017 emerging Technologies, P1, DOI [10.1145/3084822.3084842, DOI 10.1145/3084822.3084842]
   Kuang LS, 2022, IEEE HAPTICS SYM, DOI 10.1109/HAPTICS52432.2022.9765619
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Liu SH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392482
   Minamizawa K, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P133
   Miyakami M., 2018, INT C HUM HAPT SENS, P36
   Preechayasomboon P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376512
   Sato Michi, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P534, DOI 10.1109/ROMAN.2009.5326327
   Sato M., 2014, SIG TELEXISTENCE 5 W
   Sra M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300905
   Tanabe T, 2018, IEEE T HAPTICS, V11, P220, DOI 10.1109/TOH.2017.2743717
   Tanaka Yudai, 2022, CHI C HUM FACT COMP, P1
   Teo T, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3407288
   Utz KS, 2011, BRAIN INJURY, V25, P1058, DOI 10.3109/02699052.2011.607789
   Wang C, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P439, DOI 10.1145/3332165.3347898
NR 27
TC 4
Z9 4
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 9
PY 2022
VL 3
AR 930848
DI 10.3389/frvir.2022.930848
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WC5
UT WOS:001023275000001
OA gold
DA 2024-07-18
ER

PT J
AU Chaby, L
   Benamara, A
   Pino, M
   Prigent, E
   Ravenet, B
   Martin, JC
   Vanderstichel, H
   Becerril-Ortega, R
   Rigaud, AS
   Chetouani, M
AF Chaby, Laurence
   Benamara, Amine
   Pino, Maribel
   Prigent, Elise
   Ravenet, Brian
   Martin, Jean-Claude
   Vanderstichel, Helene
   Becerril-Ortega, Raquel
   Rigaud, Anne-Sophie
   Chetouani, Mohamed
TI Embodied Virtual Patients as a Simulation-Based Framework for Training
   Clinician-Patient Communication Skills: An Overview of Their Use in
   Psychiatric and Geriatric Care
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual and e-learning; virtual patient; geriatrics and gerontology;
   psychiatry; clinician-patient communication; relationship; non-verbal
   communication (NVC); embodied conversational agent (ECA); human-agent
   interaction (HAI)
ID NONVERBAL-COMMUNICATION; HEALTH-CARE; MEDICAL-STUDENTS; THERAPIST
   EMPATHY; DIFFICULT NEWS; EDUCATION; METAANALYSIS; ASSOCIATION;
   SYNCHRONY; DEMENTIA
AB Clinician-patient communication is essential to successful care and treatment. However, health training programs do not provide sufficient clinical exposure to practice communication skills that are pivotal when interacting with patients exhibiting mental health or age-related disorders. Recently, virtual reality has been used to develop simulation and training tools, in particular through embodied virtual patients (VP) offering the opportunity to engage in face-to-face human-like interactions. In this article, we overview recent developments in the literature on the use of VP-simulation tools for training communicative skills in psychiatry and geriatrics, fields in which patients have challenging social communication difficulties. We begin by highlighting the importance of verbal and non-verbal communication, arguing that clinical interactions are an interpersonal process where the patient's and the clinician's behavior mutually shape each other and are central to the therapeutic alliance. We also highlight the different simulation tools available to train healthcare professionals to interact with patients. Then, after clarifying what communication with a VP is about, we propose an overview of the most significant VP applications to highlight: 1) in what context and for what purpose VP simulation tools are used in psychiatry (e.g. depression, suicide risk, PTSD) and geriatrics (e.g., care needs, dementia), 2) how VP are conceptualized, 3) how trainee behaviors are assessed. We complete this overview with the presentation of VirtuAlz, our tool designed to train health care professionals in the social skills required to interact with patients with dementia. Finally, we propose recommendations, best practices and uses for the design, conduct and evaluation of VP training sessions.
C1 [Chaby, Laurence] Univ Paris Cite, UFR Psychol, Boulogne Billancourt, France.
   [Chaby, Laurence; Chetouani, Mohamed] Sorbonne Univ, CNRS, ISIR, Inst Syst Intelligents & Robot, Paris, France.
   [Benamara, Amine; Prigent, Elise; Ravenet, Brian; Martin, Jean-Claude] Univ Paris Saclay, CNRS, Lab Interdisciplinaire Sci Numer, Orsay, France.
   [Pino, Maribel; Rigaud, Anne-Sophie] Univ Paris Cite, Malad Alzheimer, Paris, France.
   [Pino, Maribel; Rigaud, Anne-Sophie] Hop Broca, AP HP, Ctr Memoire Ressources & Rech Ile France Broca, Serv Griatr 1&2, Paris, France.
   [Vanderstichel, Helene; Becerril-Ortega, Raquel] Univ Lille, Ctr Interuniv Recherche Educ Lille, ULR 4354, CIREL, Lille, France.
C3 Universite Paris Cite; Centre National de la Recherche Scientifique
   (CNRS); Sorbonne Universite; Centre National de la Recherche
   Scientifique (CNRS); Universite Paris Cite; Universite Paris Saclay;
   Universite Paris Cite; Assistance Publique Hopitaux Paris (APHP);
   Universite Paris Cite; Hopital Universitaire Broca - APHP; Universite de
   Lille
RP Chaby, L (corresponding author), Univ Paris Cite, UFR Psychol, Boulogne Billancourt, France.; Chaby, L (corresponding author), Sorbonne Univ, CNRS, ISIR, Inst Syst Intelligents & Robot, Paris, France.
EM laurence.chaby@u-paris.fr
RI Chaby, Laurence/B-7830-2013
OI Chaby, Laurence/0000-0002-2241-412X; Ravenet, Brian/0000-0001-6824-4800;
   Vanderstichel, Helene/0009-0007-5420-0293
FU French National Agency (ANR) [ANR-17-CE19-0028]; Agence Nationale de la
   Recherche (ANR) [ANR-17-CE19-0028] Funding Source: Agence Nationale de
   la Recherche (ANR)
FX Funding This work has been supported by the French National Agency (ANR)
   (VirtuAlz, project ANR-17-CE19-0028)
CR Adefila A, 2016, J MENT HEALTH TRAIN, V11, P91, DOI 10.1108/JMHTEP-10-2015-0048
   Aebersold M., 2012, CLIN SIMUL NURS, V8, pe469, DOI DOI 10.1016/J.ECNS.2011.05.002
   Aigrain J, 2018, IEEE T AFFECT COMPUT, V9, P491, DOI 10.1109/TAFFC.2016.2631594
   Albright Glenn, 2016, Mhealth, V2, P44, DOI 10.21037/mhealth.2016.11.02
   Ali R, 2021, AM J GERIAT PSYCHIAT, V29, P804, DOI 10.1016/j.jagp.2020.11.004
   Alinier G, 2014, NURS CRIT CARE, V19, P42, DOI 10.1111/nicc.12030
   Alsawy S, 2020, J PSYCHIATR MENT HLT, V27, P151, DOI 10.1111/jpm.12559
   Ambady N, 2002, PSYCHOL AGING, V17, P443, DOI 10.1037//0882-7974.17.3.443
   [Anonymous], 2000, Am J Psychiatry, V157, P1
   [Anonymous], 2017, C COMP AN SOC AG CAS
   [Anonymous], 2012, 25 INT FLORIDA ARTIF
   Anzalone SM, 2019, PATTERN RECOGN LETT, V118, P42, DOI 10.1016/j.patrec.2018.03.007
   Arts E., 2009, SIMS VERS 3 PC GAM
   Avril M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01437
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Bar-Kalifa E, 2019, J COUNS PSYCHOL, V66, P508, DOI 10.1037/cou0000358
   Baumann-Birkbeck L, 2017, CURR PHARM TEACH LEA, V9, P934, DOI 10.1016/j.cptl.2017.05.012
   Baumgart M, 2015, ALZHEIMERS DEMENT, V11, P718, DOI 10.1016/j.jalz.2015.05.016
   Bearman M, 2015, SIMUL HEALTHC, V10, P308, DOI 10.1097/SIH.0000000000000113
   Beaulieu Marie-Dominique, 2011, Healthc Policy, V7, P108
   Becerril-Ortega Raquel, 2022, Professional and Practice-based Learning, V30, P101, DOI [10.1007/978-3-030-89567, DOI 10.1007/978-3-030-89567]
   Beck Rainer S, 2002, J Am Board Fam Pract, V15, P25
   Behr KM, 2005, PRESENCE-TELEOP VIRT, V14, P668, DOI 10.1162/105474605775196535
   Benamara A., 2022, P 21 INT C AUT AG MU, P1
   Benamara A., 2020, WORKSHOP AFFECTS COM
   Beville P K, 2002, Am J Alzheimers Dis Other Demen, V17, P183, DOI 10.1177/153331750201700301
   Brender Erin, 2005, JAMA, V294, P1172, DOI 10.1001/jama.294.9.1172
   Brown EL, 2020, RES GERONTOL NURS, V13, P158, DOI 10.3928/19404921-20191028-01
   Brown JB, 1999, ANN INTERN MED, V131, P822, DOI 10.7326/0003-4819-131-11-199912070-00004
   Burns Johnatan, 2006, Psychiatr Danub, V18, P225
   Callejas Z, 2014, INT J HUM-COMPUT ST, V72, P567, DOI 10.1016/j.ijhcs.2014.02.002
   Campbell D, 2021, NURS EDUC TODAY, V98, DOI 10.1016/j.nedt.2021.104764
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carrard V, 2020, PATIENT EDUC COUNS, V103, P1435, DOI 10.1016/j.pec.2020.01.019
   Cassell J., 2000, Embodied Conversational Agents
   Castelli L, 2020, CAN J PSYCHIAT, V65, P731, DOI 10.1177/0706743720938598
   Catty J, 2004, PSYCHOL PSYCHOTHER-T, V77, P255, DOI 10.1348/147608304323112528
   Chaby L, 2009, PSYCHOL NEUROPSYCHIA, V7, P31, DOI 10.1684/pnv.2008.0154
   Chang BP, 2018, AM J EMERG MED, V36, P156, DOI 10.1016/j.ajem.2017.07.031
   Cleary M, 2009, HARVARD REV PSYCHIAT, V17, P315, DOI 10.3109/10673220903271780
   Collins LG, 2011, PATIENT EDUC COUNS, V83, P158, DOI 10.1016/j.pec.2010.05.012
   Combs C Donald, 2019, AMA J Ethics, V21, pE153, DOI 10.1001/amajethics.2019.153
   Conigliaro R. L., 2007, JAMA-J AM MED ASSOC, V297, P748, DOI [10.1001/jama.297.7.750, DOI 10.1001/JAMA.297.7.750]
   Consorti F, 2012, COMPUT EDUC, V59, P1001, DOI 10.1016/j.compedu.2012.04.017
   Cook DA, 2010, ACAD MED, V85, P1589, DOI 10.1097/ACM.0b013e3181edfe13
   Cook DA, 2009, MED EDUC, V43, P303, DOI 10.1111/j.1365-2923.2008.03286.x
   Cordar A, 2014, LECT NOTES ARTIF INT, V8637, P144, DOI 10.1007/978-3-319-09767-1_17
   Cruz M, 2011, PSYCHIAT SERV, V62, P1361, DOI 10.1176/ps.62.11.pss6211_1361
   Curran VR, 2007, MED EDUC, V41, P892, DOI 10.1111/j.1365-2923.2007.02823.x
   D'Agostino TA, 2011, PATIENT EDUC COUNS, V85, P33, DOI 10.1016/j.pec.2010.07.043
   Del Piccolo L, 2012, EPIDEMIOL PSYCH SCI, V21, P145, DOI 10.1017/S2045796012000091
   Deladisma AM, 2007, AM J SURG, V193, P756, DOI 10.1016/j.amjsurg.2007.01.021
   Delaherche E., 2013, NEURAL NETS SURROUND, P345, DOI [10.1007/978-3-642-35467-0_34, DOI 10.1007/978-3-642-35467-0_34]
   Delaherche E, 2012, IEEE T AFFECT COMPUT, V3, P349, DOI 10.1109/T-AFFC.2012.12
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Douglas KM, 2010, BRIT J PSYCHIAT, V197, P156, DOI 10.1192/bjp.bp.110.078113
   Dupuy L, 2020, J AFFECT DISORDERS, V263, P1, DOI 10.1016/j.jad.2019.11.117
   Dwamena F, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003267.pub2
   Ellgring H, 1996, J NONVERBAL BEHAV, V20, P83, DOI 10.1007/BF02253071
   Ellingsen DM, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abc1304
   Elzubeir MA, 2010, EDUC HEALTH, V23, P355
   Fallowfield L, 2004, LANCET, V363, P312, DOI 10.1016/S0140-6736(03)15392-5
   Forbes R., 2009, ENHANCING SIMULATION
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Fraser N. M., 1991, Computer Speech and Language, V5, P81, DOI 10.1016/0885-2308(91)90019-M
   FRIEDMAN RB, 1977, JAMA-J AM MED ASSOC, V238, P1927
   Gaba DM, 2004, QUAL SAF HEALTH CARE, V13, pI2, DOI 10.1136/qshc.2004.009878
   Georgescu AL, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00807
   Giannitelli M, 2015, SCHIZOPHR RES, V168, P252, DOI 10.1016/j.schres.2015.07.039
   Gill TM, 1996, J GERONTOL A-BIOL, V51, pM283, DOI 10.1093/gerona/51A.6.M283
   Goldstein P, 2020, J PAIN, V21, P1160, DOI 10.1016/j.jpain.2020.03.001
   Gorawara-Bhat R, 2007, PATIENT EDUC COUNS, V66, P223, DOI 10.1016/j.pec.2006.12.005
   Gorawara-Bhat R, 2013, PATIENT EDUC COUNS, V92, P375, DOI 10.1016/j.pec.2013.03.002
   Gorawara-Bhat R, 2011, PATIENT EDUC COUNS, V82, P442, DOI 10.1016/j.pec.2010.12.002
   Granry JC, 2012, GUIDE BONNES PRATIQU
   Gratch J., 2013, P ANN M COGNITIVE SC, V35, P42
   Grinbaum A, 2017, IEEE ROBOT AUTOM MAG, V24, P139, DOI 10.1109/MRA.2016.2611586
   Grossard C, 2020, MOL AUTISM, V11, DOI 10.1186/s13229-020-0312-2
   Ha JF, 2010, OCHSNER J, V10, P38
   HALL JA, 1981, J HEALTH SOC BEHAV, V22, P18, DOI 10.2307/2136365
   Hall JA, 2019, ANNU REV PSYCHOL, V70, P271, DOI 10.1146/annurev-psych-010418-103145
   Hardman D., 2019, EUR J PERS CENT HEAL, V7, P351, DOI DOI 10.5750/EJPCH.V7I2.1689
   HARRIGAN JA, 1985, SOC SCI MED, V20, P1161, DOI 10.1016/0277-9536(85)90193-5
   Hart Y, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01130
   Hartley S, 2020, INT J NURS STUD, V102, DOI 10.1016/j.ijnurstu.2019.103490
   Hashimoto K, 2010, J POPUL ECON, V23, P571, DOI 10.1007/s00148-008-0216-5
   Hawley K, 2015, J EVAL CLIN PRACT, V21, P798, DOI 10.1111/jep.12374
   Henry SG, 2012, PATIENT EDUC COUNS, V86, P297, DOI 10.1016/j.pec.2011.07.006
   Hinshaw SP, 2008, ANNU REV CLIN PSYCHO, V4, P367, DOI 10.1146/annurev.clinpsy.4.022007.141245
   Hojat M, 2011, ACAD MED, V86, P359, DOI 10.1097/ACM.0b013e3182086fe1
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   Howe LC, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00475
   Howick J, 2018, J ROY SOC MED, V111, P240, DOI 10.1177/0141076818769477
   Imel ZE, 2014, J COUNS PSYCHOL, V61, P146, DOI 10.1037/a0034943
   Irwin P, 2015, J NURS EDUC, V54, P572, DOI 10.3928/01484834-20150916-05
   Ishikawa H, 2006, MED EDUC, V40, P1180, DOI 10.1111/j.1365-2929.2006.02628.x
   Isik AT, 2019, INT J GERIATR PSYCH, V34, P1326, DOI 10.1002/gps.4965
   Jagtap R, 2021, HDB RES ENG BUSINESS, P401, DOI DOI 10.4018/978-1-7998-3053-5.CH020
   Jones H., 2013, IDGEI INTELLIGENT DI
   Kee JWY., 2018, Health Prof Educ, V4, P97, DOI [10.1016/j.hpe.2017.03.006, DOI 10.1016/J.HPE.2017.03.006]
   Keiser MM, 2017, CLIN SIMUL NURS, V13, P321, DOI 10.1016/j.ecns.2017.05.008
   Keltner NL, 2011, J PSYCHOSOC NURS MEN, V49, P35, DOI 10.3928/02793695-20110329-02
   Kenny PG, 2009, ANN REV CYBERTHERAPY, V7, P122
   Kenny PG, 2009, LECT NOTES ARTIF INT, V5773, P511, DOI 10.1007/978-3-642-04380-2_67
   Ker Jean., 2010, UNDERSTANDING MED ED, P164, DOI [https://doi.org/10.1002/9781444320282.ch12, DOI 10.1002/9781444320282.CH12]
   Khullar D, 2019, JAMA-J AM MED ASSOC, V322, P507, DOI 10.1001/jama.2019.4892
   Kim EJ, 1999, INT J NURS STUD, V36, P235, DOI 10.1016/S0020-7489(99)00019-X
   Kodama K., 2018, Psychology, V9, P1858, DOI [DOI 10.4236/PSYCH.2018.9765108, 10.4236/psych.2018.97108, DOI 10.4236/PSYCH.2018.97108]
   Lapkin S., 2010, CLIN SIMUL NURS, V6, pe207, DOI DOI 10.1016/J.ECNS.2010.05.005
   Lavelle M, 2015, ACTA PSYCHIAT SCAND, V131, P197, DOI 10.1111/acps.12319
   Lee J, 2020, MED EDUC, V54, P786, DOI 10.1111/medu.14152
   Lenherr G, 2012, SWISS MED WKLY, V142, DOI 10.4414/smw.2012.13563
   Liaw SY, 2020, CLIN SIMUL NURS, V45, P42, DOI 10.1016/j.ecns.2020.03.013
   Liaw SY, 2019, NURS EDUC TODAY, V81, P64, DOI 10.1016/j.nedt.2019.06.012
   Lorie A, 2017, PATIENT EDUC COUNS, V100, P411, DOI 10.1016/j.pec.2016.09.018
   Loveys K, 2020, INT J SOC ROBOT, V12, P1293, DOI 10.1007/s12369-020-00680-7
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Machiels M, 2017, INT J NURS STUD, V66, P37, DOI 10.1016/j.ijnurstu.2016.11.017
   Madhu D, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P243, DOI 10.1109/ICICCT.2017.7975195
   Magai C, 2002, INT PSYCHOGERIATR, V14, P25, DOI 10.1017/S1041610202008256
   Mantovani F, 2003, CYBERPSYCHOL BEHAV, V6, P389, DOI 10.1089/109493103322278772
   Marci CD, 2007, J NERV MENT DIS, V195, P103, DOI 10.1097/01.nmd.0000253731.71025.fc
   Mast M. S., 2017, VERTICAL DIMENSION S
   Mast M.S., 2013, The oxford handbook of health communication, behavior change and treatment adherence, P38
   Maurage P, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00394
   McCabe R, 2013, PATIENT EDUC COUNS, V93, P73, DOI 10.1016/j.pec.2013.05.015
   McGilton KS, 2009, WORLDV EVID-BASED NU, V6, P149, DOI 10.1111/j.1741-6787.2009.00155.x
   McNaughton N, 2008, CAN J PSYCHIAT, V53, P85, DOI 10.1177/070674370805300203
   Mirheidari B, 2019, COMPUT SPEECH LANG, V53, P65, DOI 10.1016/j.csl.2018.07.006
   Munshi F, 2015, J TAIBAH UNIV MED SC, V10, P12, DOI 10.1016/j.jtumed.2015.01.008
   Nasir J, 2022, INT J SOC ROBOT, V14, P55, DOI 10.1007/s12369-021-00766-w
   O'Brien Kimberly H McManama, 2019, Mhealth, V5, P31, DOI 10.21037/mhealth.2019.08.03
   O'Connor K, 2018, EUR PSYCHIAT, V53, P74, DOI 10.1016/j.eurpsy.2018.06.003
   O'Rourke SR, 2020, TEACH LEARN MED, V32, P139, DOI 10.1080/10401334.2019.1652180
   Ochs M, 2019, J MULTIMODAL USER IN, V13, P41, DOI 10.1007/s12193-018-0289-8
   Ochs M, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P161, DOI 10.1145/3284432.3284452
   Okuda Y, 2009, MT SINAI J MED, V76, P330, DOI 10.1002/msj.20127
   Orange JB, 2001, LEA COMMUN SER, P225
   Orton E, 2007, GERONTOL GERIATR EDU, V28, P73, DOI 10.1300/J021v28n03_06
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pantziaras I., 2014, J CONT MED EDU, V2, P109, DOI [10.5455/jcme.20140627042240, DOI 10.5455/JCME.20140627042240]
   Pantziaras Ioannis, 2015, J Med Internet Res, V17, pe46, DOI 10.2196/jmir.3497
   Parsons K., 2008, ANN REV CYBERTHERAPY, V6
   Parsons TD, 2021, J CLIN MED, V10, DOI 10.3390/jcm10030378
   Pavic K, 2021, Q J EXP PSYCHOL, V74, P1128, DOI 10.1177/1747021820982165
   Peddle M, 2016, CLIN SIMUL NURS, V12, P400, DOI 10.1016/j.ecns.2016.04.004
   Pelachaud C., 2021, The handbook on socially interactive agents, P259, DOI [10.1145/3477322.3477331, DOI 10.1145/3477322.3477331]
   Philip P, 2020, J MED INTERNET RES, V22, DOI 10.2196/24268
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Piette JD, 2005, ARCH INTERN MED, V165, P1749, DOI 10.1001/archinte.165.15.1749
   Piot MA, 2020, MED EDUC, V54, P696, DOI 10.1111/medu.14166
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Priebe S, 2011, EUR PSYCHIAT, V26, P403, DOI 10.1016/j.eurpsy.2010.07.010
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Quail M, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0577-5
   Ramseyer F, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00979
   Ramseyer F, 2011, J CONSULT CLIN PSYCH, V79, P284, DOI 10.1037/a0023419
   Richardson CL, 2020, BMJ SIMUL TECHNOL EN, V6, P332, DOI 10.1136/bmjstel-2019-000514
   Riek LD, 2012, J HUM-ROBOT INTERACT, V1, P119, DOI 10.5898/JHRI.1.1.Riek
   Riva G, 2020, J CLIN MED, V9, DOI 10.3390/jcm9113434
   Rivière E, 2018, MED TEACH, V40, P743, DOI 10.1080/0142159X.2017.1391375
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Rizzo A, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1414560
   Robinson Kate E., 2020, Interactive Learning Environments, V28, P795, DOI 10.1080/10494820.2018.1552869
   Rössler W, 2012, EUR ARCH PSY CLIN N, V262, pS65, DOI 10.1007/s00406-012-0353-4
   Roter DL, 2006, J GEN INTERN MED, V21, pS28, DOI 10.1111/j.1525-1497.2006.00306.x
   Ruben MA, 2018, ANN BEHAV MED, V52, P662, DOI 10.1093/abm/kax036
   Ruberton PM, 2016, PATIENT EDUC COUNS, V99, P1138, DOI 10.1016/j.pec.2016.01.012
   Ruiz JG, 2008, J AM GERIATR SOC, V56, P130, DOI 10.1111/j.1532-5415.2007.01480.x
   Salari Nader, 2020, Global Health, V16, P57, DOI 10.1186/s12992-020-00589-w
   Schneider B, 2004, QUAL HEALTH RES, V14, P562, DOI 10.1177/1049732303262423
   Shah H, 2012, ACAD PSYCHIATR, V36, P146, DOI 10.1176/appi.ap.10030049
   Shattell MM, 2007, INT J MENT HEALTH NU, V16, P274, DOI 10.1111/j.1447-0349.2007.00477.x
   Slater P, 2019, INT J OLDER PEOPLE N, V14, DOI 10.1111/opn.12243
   Staccini P., 2021, DIGITAL INNOVATIONS, P17, DOI [10.1016/b978-0-12-813144-2.00002-7, DOI 10.1016/B978-0-12-813144-2.00002-7]
   Staccini PM, 2019, CLINICAL SIMULATION: EDUCATION, OPERATIONS AND ENGINEERING, 2ND EDITION, P41, DOI 10.1016/B978-0-12-815657-5.00004-8
   Steel Z, 2014, INT J EPIDEMIOL, V43, P476, DOI 10.1093/ije/dyu038
   Stepanikova I, 2012, J GEN INTERN MED, V27, P576, DOI 10.1007/s11606-011-1934-z
   Strasser F, 2005, J PAIN SYMPTOM MANAG, V29, P489, DOI 10.1016/j.jpainsymman.2004.08.011
   Stratou G, 2015, INT CONF AFFECT, P787, DOI 10.1109/ACII.2015.7344661
   Stuckless P., 2014, Virtual, augmented reality and serious games for healthcare, V1, P145, DOI [10.1007/978-3-642-54816-1_8, DOI 10.1007/978-3-642-54816-1_8]
   Su WS, 2023, INTERACT LEARN ENVIR, V31, P2324, DOI 10.1080/10494820.2021.1879873
   Szilas N, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P91, DOI 10.1145/3308532.33294571
   Talbot T. B., 2019, EXPLORING COGNITIVE, P62, DOI [10.4018/978-1-5225-7461-3.ch003, DOI 10.4018/978-1-5225-7461-3.CH003]
   Tan TY, 2020, IEEE INT C BIOINF BI, P993, DOI 10.1109/BIBE50027.2020.00168
   Tan ZS, 2010, GERONTOL GERIATR EDU, V31, P163, DOI 10.1080/02701961003795813
   Tanaka H, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2752152
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Templier L, 2015, GERIATR PSYCHOL NEUR, V13, P106, DOI 10.1684/pnv.2015.0524
   Tomicic A, 2017, REV LAT AM PSICOL, V49, P48, DOI 10.1016/j.rlp.2016.09.004
   Torres MI, 2018, 4 INT C ADV SPEECH L, P172, DOI [10.26342/2018-61-24, DOI 10.26342/2018-61-24]
   van Manen AS, 2021, INT J NURS STUD, V113, DOI 10.1016/j.ijnurstu.2020.103776
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Wang I, 2021, INT J HUM-COMPUT INT, V37, P1648, DOI 10.1080/10447318.2021.1898851
   Wang R, 2016, SIMUL HEALTHC, V11, P41, DOI 10.1097/SIH.0000000000000118
   Williams S, 1998, FAM PRACT, V15, P480, DOI 10.1093/fampra/15.5.480
   Wolf L, 2011, NURS EDUC, V36, P128, DOI 10.1097/NNE.0b013e318216120b
   Wullenkord R., 2020, Current Robotics Reports, V1, P85, DOI [10.1007/s43154-020-00010-9, DOI 10.1007/S43154-020-00010-9, https://doi.org/10.1007/s43154-020-00010-9]
   Xavier J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01954
   Zagdoun J., 2021, SOCIALLY INFORM AI H, DOI [10.1145/3461615.3485442, DOI 10.1145/3461615.3485442]
   Zoellner LA, 2014, DEPRESS ANXIETY, V31, P97, DOI 10.1002/da.22133
   Zolnierek KBH, 2009, MED CARE, V47, P826, DOI 10.1097/MLR.0b013e31819a5acc
NR 202
TC 4
Z9 4
U1 2
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 29
PY 2022
VL 3
AR 827312
DI 10.3389/frvir.2022.827312
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZO5
UT WOS:001019267100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Horst, R
   Naraghi-Taghi-Off, R
   Rau, L
   Doerner, R
AF Horst, Robin
   Naraghi-Taghi-Off, Ramtin
   Rau, Linda
   Doerner, Ralf
TI Authoring With Virtual Reality Nuggets-Lessons Learned
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; authoring; virtual reality nuggets; design patterns;
   e-learning; system design
ID CREATION; TOOL; MANAGEMENT; DESIGN
AB Virtual Reality (VR) systems and VR content are complex, and their creation can mainly be conducted by experts in VR and related areas. That makes the use of VR challenging for experts from other domains, such as educators. In this paper, we build up on existing work and investigate the VR nugget concept-small self-contained VR systems that are built from educational design patterns. Particularly, we extend this concept and introduce structured authoring processes based on VR nuggets that show how standalone, combinable, and reusable VR software can serve as a meta-level guide for various VR applications and involve educators as domain experts. We conduct a user study with VR Forge, a VR-nugget-based authoring software tool, to draw conclusions on how pattern-based VR authoring tools should be designed to support domain experts. We compare our results with those of a related study of the VR nugget tool IN Tiles. Based on the comparative results of usability and hedonic quality measures, both anecdotal evidence and statistically significant results support the concept's potential for VR authoring conducted by practitioners who are not experts in VR. We derive the recommendation that the design of a VR-nugget-based authoring environment will benefit from using both immersive and desktop user interface (UI) technologies and that the authoring workflow will need authors to frequently alternate between the technologies. We state findings and lessons learned from the development and the studies. We contribute insights in developing reusable and use-case-specific VR content and tools and propose authoring processes that focus on the tasks and goals of domain experts as the primary authoring role within educational VR development. Finally, the relevance of VR-nugget-based authoring is supported by anecdotal evidence gathered from over 3 years of investigating and applying it within three educational institutions and a company providing education services.
C1 [Horst, Robin; Naraghi-Taghi-Off, Ramtin; Rau, Linda; Doerner, Ralf] RheinMain Univ Appl Sci, Dept Design Comp Sci Media, Visualizat Lab, Wiesbaden, Germany.
RP Horst, R (corresponding author), RheinMain Univ Appl Sci, Dept Design Comp Sci Media, Visualizat Lab, Wiesbaden, Germany.
EM robin.horst@hs-rm.de
OI Rau, Linda/0000-0001-7165-0041
CR Abawi DF, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P444, DOI 10.1109/CGI.2004.1309246
   Abdelaziz Marwa A., 2014, International Journal of e-Education, e-Business, e-Management and e-Learning, V4, P320, DOI 10.7763/ijeeee.2014.V4.347
   Adao T, 2018, PROCEDIA COMPUT SCI, V138, P441, DOI 10.1016/j.procs.2018.10.062
   Alexander C., 1977, PATTERN LANGUAGE TOW
   [Anonymous], 2005, J INTERACTIVE MEDIA, DOI DOI 10.5334/2005-2
   [Anonymous], 2003, J DIGITAL INF
   [Anonymous], 2000, INSTRUCTIONAL USE LE
   [Anonymous], 2008, SOFTWARE ENG ARCHITE
   [Anonymous], 2000, LEARN LIMITS
   Armstrong SJ, 2008, ACAD MANAG LEARN EDU, V7, P571, DOI 10.5465/AMLE.2008.35882197
   Arrighi PA, 2019, J INTELL MANUF, V30, P743, DOI 10.1007/s10845-016-1276-0
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Autodesk Inc, 2021, 3DS MAX BATCH PROOPT
   Bailey C, 2006, EDUC TECHNOL SOC, V9, P113
   Bannan-Ritland B., 2002, The instructional use of learning objects, P61
   Bergin J., 2012, Pedagogical patterns: Advice for educators
   Billinghurst M., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P155, DOI 10.1145/261135.261163
   Coburn JQ, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4036921
   Coelho H, 2019, MULTIMED TOOLS APPL, V78, P19473, DOI 10.1007/s11042-019-7309-x
   Conole G, 2005, J INTERACT MEDIA EDU
   Conway M., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P486, DOI 10.1145/332040.332481
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Dias JB, 2010, LECT NOTES COMPUT SC, V6157, P167, DOI 10.1007/978-3-642-13789-1_16
   Doerner R, 2015, LECT NOTES COMPUT SC, V8844, P187, DOI 10.1007/978-3-319-17043-5_11
   Dörner R, 2014, WORK SOFTW ENG, P1, DOI 10.1109/SEARIS.2014.7152795
   Dorner R., 2021, EUROGRAPHICS 2021 ED, DOI [10.2312/eged.20211002, DOI 10.2312/EGED.20211002]
   Dunk A., 2013, THESIS U READING REA
   Dunk A, 2010, PROCEDIA COMPUT SCI, V1, P2603, DOI 10.1016/j.procs.2010.04.294
   Eckstein J., 2000, P EUROPLOP
   Epic Games Inc, 2021, UNR ENG DESCR
   Fayad ME, 1997, COMMUN ACM, V40, P32, DOI 10.1145/262793.262798
   Fincher S., 1999, Journal of Computers in Mathematics and Science Teaching, V18, P331
   Fransson G, 2020, EDUC INF TECHNOL, V25, P3383, DOI 10.1007/s10639-020-10119-1
   Gandy M, 2004, ACM CHI Lett, V6, P197
   Gasques D, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312847
   Geijtenbeek Thomas, 2011, P 10 INT C VIRT REAL, DOI [DOI 10.1145/2087756.2087785, 10.1145/2087756.2087785]
   Gerken K, 2013, LECT NOTES COMPUT SC, V8119, P744
   Goodyear P., 2005, Australasian Journal of Educational Technology, V21, P82
   Green M., 1991, COMPUT GRAPHICS-US, V25, P229, DOI DOI 10.1145/126640.126677
   Grimm P., 2002, First IEEE International Augmented Reality Toolkit Workshop. Proceedings (Cat. No.02EX632), DOI 10.1109/ART.2002.1107008
   Hassenzahl M., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P201, DOI 10.1145/332040.332432
   Hassenzahl M., 2003, Mensch & Computer 2003: Interaktion in Bewegung, P187, DOI [DOI 10.1007/978-3-322-80058, DOI 10.1007/978-3-322-80058-9_19]
   Hassenzahl M., 2018, FUNOLOGY, P301, DOI [10.1007/978-3-319-68213-6_19, DOI 10.1007/978-3-319-68213-6_19]
   Horst R., 2019, 2019 IEEE INT C ENG, P1, DOI [10.1109/TALE48000.2019.9225867, DOI 10.1109/TALE48000.2019.9225867]
   Horst R., 2021, THESIS RHEINMAIN U A
   Horst R., 2021, P 13 WORKSHOP VIRTUA
   Horst R., 2019, P 16 WORKSHOP VIRTUA, P137, DOI [10.2370/9783844068870, DOI 10.2370/9783844068870]
   Horst R, 2021, MULTIMED TOOLS APPL, DOI 10.1007/s11042-021-11317-w
   Horst R, 2020, J UNIVERS COMPUT SCI, V26, P947
   Horst R, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364261
   Hovhannisyan G, 2019, LECT NOTES ARTIF INT, V11580, P225, DOI 10.1007/978-3-030-22419-6_17
   Hug T., 2005, P MEDIA TRANSITION
   Jacobson J, 2005, COMPUTER, V38, P79, DOI 10.1109/MC.2005.126
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Johnson RE, 1997, COMMUN ACM, V40, P39, DOI 10.1145/262793.262799
   Jong MSY, 2020, BRIT J EDUC TECHNOL, V51, P2063, DOI 10.1111/bjet.12947
   Kemanji K. V., 2020, COMPANION P 12 ACM S, DOI [10.1145/3393672.3398645, DOI 10.1145/3393672.3398645]
   Koper R., 2005, Learning Design: A Handbook on Modelling and Delivering Networked Education and Training, DOI DOI 10.1007/B138966
   Krauss V, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445335
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   Lee GA, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P172, DOI 10.1109/ISMAR.2004.34
   Lewis C., 1982, USING THINKING ALOUD
   Lorenz A., 2010, 8 WORKSH E LEARN, P79
   Lugrin J., 2012, Proceedings of the 18th ACM Symposium on Virtual Reality Software and Technology, VRST '12, P137, DOI [DOI 10.1145/2407336.2407363, 10.1145/2407336.2407363]
   MakerBot Industries LLC, 2021, THING DIG DES PHYS O
   Maloney J, 2004, SECOND INTERNATIONAL CONFERENCE ON CREATING, CONNECTING AND COLLABORATING THROUGH COMPUTING, PROCEEDINGS, P104
   Marcos D., 2021, A FRAME DESCRIPTION
   Mateevitsi V., 2008, P 3 INT C DIGITAL IN, P451, DOI [10.1145/1413634.1413714, DOI 10.1145/1413634.1413714]
   Microsoft, 2021, BOX WHISK PLOT DOC
   Nebeling M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376637
   Nebeling M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P333, DOI 10.1109/ISMAR-Adjunct.2018.00098
   Nersesian E, 2019, INTEGR STEM EDU CONF, P83, DOI [10.1109/ISECon.2019.8882070, 10.1109/isecon.2019.8882070]
   Park NS, 2018, I C INF COMM TECH CO, P1497, DOI 10.1109/ICTC.2018.8539366
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Patterson T, 2019, TECHTRENDS, V63, P463, DOI 10.1007/s11528-019-00401-6
   PAUSCH R, 1995, IEEE COMPUT GRAPH, V15, P8, DOI 10.1109/38.376600
   Roth A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH 2011), P101, DOI 10.1109/ISMAR-AMH.2011.6093664
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Souza M., 2014, Creative Education, V5, P672, DOI [10.4236/ce.2014.59079, DOI 10.4236/CE.2014.59079]
   Steinicke F, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P203, DOI 10.1109/VR.2009.4811024
   Takala T.M., 2014, Proceedings of the 2Nd ACM Symposium on Spatial User Interaction, P94, DOI DOI 10.1145/2659766.2659774
   TurboSquid, 2021, TURB 3D MOD SOURC
   Unity Technologies, 2021, UN GAM ENG DESCR
   Unity Technologies, 2021, UN ASS STOR
   User Interface Design GmbH, 2021, ATTR QUEST
   W3C, 2021, WEBXR DESCR
   Wang Y, 2017, ADV EDUC RES, V96, P37
   Wingrave CA, 2010, PRESENCE-TELEOP VIRT, V19, P179, DOI 10.1162/pres.19.2.179
NR 88
TC 1
Z9 1
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 25
PY 2022
VL 3
AR 840729
DI 10.3389/frvir.2022.840729
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZT6
UT WOS:001019272300001
OA gold
DA 2024-07-18
ER

PT J
AU Rahimian, P
   Plumert, JM
   Kearney, JK
AF Rahimian, Pooya
   Plumert, Jodie M.
   Kearney, Joseph K.
TI The Effect of Visuomotor Latency on Steering Behavior in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive virtual environments; visuomotor latency; steering behavior;
   head-mounted displays; perceptual-motor adaptation
ID DELAYED VISUAL FEEDBACK; PRISM ADAPTATION; MOTOR
AB Visual feedback latency in virtual reality systems is inherent due to the computing time it takes to simulate the effects of user actions. Depending upon the nature of interaction and amount of latency, the impact of this latency could range from a minor degradation to a major disruption of performance. The goal of this study was to examine how visuomotor latency impacts users' performance in a continuous steering task and how users adapt to this latency with experience. The task involved steering a bike along an illuminated path in a dark environment viewed in an HTC Vive head-mounted virtual reality display. We examined how users adapt to visuomotor latency in two different conditions: 1) when the user controlled the steering while the bike moved forward at a constant speed, and 2) when the user controlled the steering and the speed of the bike through pedaling and braking. We found that users in both conditions started with a large steering error at the beginning of exposure to visuomotor latency but then quickly adapted to the delay. We also found that when users could control their speed, they adjusted their speed based on the complexity of the path (i.e., proximity to turns) and they gradually increased their speed as they adapted to latency and gained better control over their movement. The current work supports the idea that users can adapt to visual feedback delay in virtual reality regardless of whether they control the pace of movement. The results inform the design of virtual reality simulators and teleoperation systems and give insight into perceptual-motor adaptation in the presence of latency.
C1 [Rahimian, Pooya; Kearney, Joseph K.] Univ Iowa, Dept Comp Sci, Iowa, IA 52242 USA.
   [Plumert, Jodie M.] Univ Iowa, Dept Psychol & Brain Sci, Iowa, IA USA.
C3 University of Iowa; University of Iowa
RP Kearney, JK (corresponding author), Univ Iowa, Dept Comp Sci, Iowa, IA 52242 USA.
EM joe-kearney@uiowa.edu
FU National Science Foundation [CNS-1305131]; Safety Research Using
   Simulation University Transportation Center (SAFER-SIM); U. S.
   Department of Transportation's University Transportation Centers Program
   [69A3551747121]
FX This work was supported in part by National Science Foundation award
   CNS-1305131 and by the Safety Research Using Simulation University
   Transportation Center (SAFER-SIM). SAFER-SIM is funded by a grant from
   the U. S. Department of Transportation's University Transportation
   Centers Program (69A3551747121). However, the U. S. Government assumes
   no liability for the contents thereof.
CR BEDFORD F, 1993, PSYCHOL LEARN MOTIV, V30, P1, DOI 10.1016/S0079-7421(08)60293-5
   Cunningham DW, 2001, J VISION, V1, P88, DOI 10.1167/1.2.3
   Cunningham DW, 2001, PSYCHOL SCI, V12, P532, DOI 10.1111/1467-9280.00398
   Davis J, 2010, IEEE T ROBOT, V26, P590, DOI 10.1109/TRO.2010.2046695
   HARRIS CS, 1963, SCIENCE, V140, P812, DOI 10.1126/science.140.3568.812
   HELD R, 1966, J EXP PSYCHOL, V72, P887, DOI 10.1037/h0023868
   Helmholtz H., 1896, ALLGEMEINE ENCYKLOP, V9, P1
   Kennedy JS, 2009, Q J EXP PSYCHOL, V62, P453, DOI 10.1080/17470210801985235
   Miall RC, 2006, EXP BRAIN RES, V172, P77, DOI 10.1007/s00221-005-0306-5
   Petitet P, 2018, NEUROPSYCHOLOGIA, V115, P188, DOI 10.1016/j.neuropsychologia.2017.12.021
   Redding GA, 2006, NEUROPSYCHOLOGIA, V44, P1, DOI 10.1016/j.neuropsychologia.2005.04.009
   Redding GM, 2005, NEUROSCI BIOBEHAV R, V29, P431, DOI 10.1016/j.neubiorev.2004.12.004
   Redding GM, 2006, J EXP PSYCHOL HUMAN, V32, P1006, DOI 10.1037/0096-1523.32.4.1006
   Rohde M, 2014, J VISION, V14, DOI 10.1167/14.3.4
   Sarpeshkar V, 2011, SPORT BIOMECH, V10, P306, DOI 10.1080/14763141.2011.629207
   SHERIDAN TB, 1963, IEEE T HUM FACT ENG, VHFE4, P25, DOI 10.1109/THFE.1963.231283
   SMITH K U, 1963, Percept Mot Skills, V16, P781
   Smith K.U., 1962, PERCEPTION MOTION AN
   SMITH WM, 1960, SCIENCE, V132, P1013, DOI 10.1126/science.132.3433.1013
   Tzafestas SG., 2013, INTRO MOBILE ROBOT C
   Welch R.B., 1978, PERCEPTUAL MODIFICAT
   Wilde G J, 1998, Inj Prev, V4, P89
NR 22
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 21
PY 2021
VL 2
AR 727858
DI 10.3389/frvir.2021.727858
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TS1
UT WOS:001021840400001
OA gold
DA 2024-07-18
ER

PT J
AU Pfaller, M
   Kroczek, LOH
   Lange, B
   Fulöp, R
   Müller, M
   Mühlberger, A
AF Pfaller, Michael
   Kroczek, Leon O. H.
   Lange, Bastian
   Fueloep, Raymund
   Mueller, Mathias
   Muehlberger, Andreas
TI Social Presence as a Moderator of the Effect of Agent Behavior on
   Emotional Experience in Social Interactions in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; social anxiety; social presence; virtual agents;
   realism
ID IN-VIVO EXPOSURE; ANXIETY DISORDER; METAANALYSIS; EFFICACY; THERAPY
AB Background: Exposure therapy involves exposure to feared stimuli and is considered to be the gold-standard treatment for anxiety disorders. While its application in Virtual Reality (VR) has been very successful for phobic disorders, the effects of exposure to virtual social stimuli in Social Anxiety Disorder are heterogeneous. This difference has been linked to demands on realism and presence, particularly social presence, as a pre-requisite in evoking emotional experiences in virtual social interactions. So far, however, the influence of social presence on emotional experience in social interactions with virtual agents remains unknown.Objective: We investigated the relationship between realism and social presence and the moderating effect of social presence on the relationship between agent behavior and experienced emotions in virtual social interaction.Methods: Healthy participants (N = 51) faced virtual agents showing supportive and dismissive behaviors in two virtual environments (short interactions and oral presentations). At first, participants performed five blocks of short one-on-one interactions with virtual agents (two male and two female agents per block). Secondly, participants gave five presentations in front of an audience of 16 agents. In each scenario, agent behavior was a within subjects factor, resulting in one block of neutral, two blocks of negative, and two blocks of positive agent behavior. Ratings of agent behavior (valence and realism), experience (valence and arousal), and presence (physical and social) were collected after every block. Moderator effects were investigated using mixed linear models with random intercepts. Correlations were analyzed via repeated measures correlations.Results: Ratings of valence of agent behaviors showed reliable relationships with experienced valence and less reliable relationships with experienced arousal. These relationships were moderated by social presence in the presentation scenario. Results for the interaction scenario were weaker but potentially promising for experimental studies. Variations in social presence and realism over time were correlated but social presence proved a more reliable moderator.Conclusion: Our findings emphasize the role of social presence for emotional experience in response to specific agent behaviors in virtual social interactions. While these findings should be replicated with experimental designs and in clinical samples, variability in social presence might account for heterogeneity in efficacy of virtual exposure to treat social anxiety disorder.
C1 [Pfaller, Michael; Kroczek, Leon O. H.; Muehlberger, Andreas] Univ Regensburg, Dept Psychol Clin Psychol & Psychotherapy, Regensburg, Germany.
   [Lange, Bastian; Mueller, Mathias] VTplus GmbH, Dept Res & Dev, Wurzburg, Germany.
   [Fueloep, Raymund] Univ Regensburg, Inst Informat & Media Language & Culture, Informat Sci, Regensburg, Germany.
C3 University of Regensburg; University of Regensburg
RP Mühlberger, A (corresponding author), Univ Regensburg, Dept Psychol Clin Psychol & Psychotherapy, Regensburg, Germany.
EM andreas.muehlberger@ur.de
RI Kroczek, Leon O.H./GQZ-0720-2022
CR Allan Steven, 1997, British Journal of Clinical Psychology, V36, P467
   AYRES J, 1990, COMMUN EDUC, V39, P283, DOI 10.1080/03634529009378810
   Bakdash JZ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00456
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chesham RK, 2018, BEHAV CHANGE, V35, P152, DOI 10.1017/bec.2018.15
   Delacre M, 2017, INT REV SOC PSYCHOL, V30, P92, DOI 10.5334/irsp.82
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Felnhofer A, 2019, CYBERPSYCH BEH SOC N, V22, P46, DOI 10.1089/cyber.2018.0221
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Felnhofer A, 2014, CYBERPSYCH BEH SOC N, V17, P310, DOI 10.1089/cyber.2013.0472
   Hsu CF, 2009, COMMUN RES REP, V26, P237
   IBM Corp, 2016, IBM SPSS Statistics for Windows, Version 22.0
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Kampmann IL, 2016, BEHAV RES THER, V77, P147, DOI 10.1016/j.brat.2015.12.016
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kroczek LOH, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00561
   LEARY MR, 1983, PERS SOC PSYCHOL B, V9, P371, DOI 10.1177/0146167283093007
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Lombard M., 2015, Immersed in media, P13, DOI [DOI 10.1007/978-3-319-10190-3, https://doi.org/10.1007/978-3-319-10190-32, DOI 10.1007/978-3-319-10190-32, 10.1007/978-3-319-10190-3_2, DOI 10.1007/978-3-319-10190-3_2]
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Neudeck P., 2012, Exposure Therapy: Rethinking the Model - Refining the Method, P23, DOI DOI 10.1007/978-1-4614-3342-2_3
   Paul G.L., 1966, INSIGHT VS DESENSITI
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Povey D., 2011, P IEEE ASRU
   Rothbaum B O, 1997, J Psychother Pract Res, V6, P219
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stangier U., 2002, Social phobia inventory (SPIN)- Deutsche Fassung
   Steinman S. A., 2015, ENCY MENTAL HLTH, P186, DOI [10.1016/B978-0-12-397045-9.00266-4, DOI 10.1016/B978-0-12-397045-9.00266-4]
   Strojny PM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01252
   Volkmann T., 2018, GERMAN TRANSLATION M, DOI [10.18420/muc2018-mci-0428, DOI 10.18420/MUC2018-MCI-0428]
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [10.1007/978-3-319-24277-4, DOI 10.1007/978-3-319-24277-4]
   Xie Y., 2015, Dynamic Documents with R and knitr, V2nd, DOI DOI 10.1201/9781315382487
NR 37
TC 3
Z9 3
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 8
PY 2021
VL 2
AR 741138
DI 10.3389/frvir.2021.741138
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZG6
UT WOS:001019259200001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Prithul, A
   Adhanom, IB
   Folmer, E
AF Prithul, Aniruddha
   Adhanom, Isayas Berhe
   Folmer, Eelke
TI Teleportation in Virtual Reality; A Mini-Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual realty; virtual locomotion; teleportation; VR sickness;
   navigation
ID ENVIRONMENTS; TRAVEL; SCALE
AB Teleportation is a widely implemented virtual locomotion technique that allows users to navigate beyond the confines of available tracking space with a low possibility of inducing virtual reality (VR) sickness. This paper provides a comprehensive overview of prior research on teleportation. We report results from user studies that have evaluated teleportation in comparison to other locomotion methods and survey improved versions of teleportation. We identify a number of areas for future research.
C1 [Prithul, Aniruddha; Adhanom, Isayas Berhe; Folmer, Eelke] Univ Nevada, Dept Comp Sci & Engn, Reno, NV 89557 USA.
C3 Nevada System of Higher Education (NSHE); University of Nevada Reno
RP Folmer, E (corresponding author), Univ Nevada, Dept Comp Sci & Engn, Reno, NV 89557 USA.
EM eelke@unr.edu
OI Adhanom, Isayas/0000-0003-4798-7415
FU NIH [P20 GM103650]; NSF [1911041]
FX Funding This research was supported by NIH under Grant No. P20 GM103650
   and by NSF under Grant No. 1911041.
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   [Anonymous], 1995, VIRTUAL ENV INTERACT
   [Anonymous], 2018, 2018 10 INT C QUALIT, DOI DOI 10.1109/QOMEX.2018.8463433
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Bhandari J., 2018, P 44 GRAPHICS INTERF, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018.223, DOI 10.20380/GI2018.223]
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bolte B, 2011, P VIRT REAL INT C VR
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Cherep LA, 2020, J EXP PSYCHOL-APPL, V26, P480, DOI 10.1037/xap0000263
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cmentowski S, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P287, DOI 10.1145/3311350.3347183
   Coomer N., 2018, P SAP 2018 ACM S APP, DOI [10.1145/3225153.3225175, DOI 10.1145/3225153.3225175]
   Drogemuller A, 2020, J COMPUT LANG, V56, DOI 10.1016/j.cola.2019.100937
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   Funk M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300377
   Griffin NN, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364243
   Griffin NN, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P211, DOI 10.1145/3242671.3242707
   Kelly JW, 2020, IEEE T VIS COMPUT GR, V26, P1841, DOI 10.1109/TVCG.2020.2973051
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lindal PallJ., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games), P1, DOI DOI 10.1109/VS-GAMES.2018.8493414
   Linn Andreas., 2017, Gaze Teleportation in Virtual Reality
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Loup G, 2019, INT J HUM-COMPUT INT, V35, P1270, DOI 10.1080/10447318.2018.1519164
   Paris R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343131
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Sumner B., 2017, REC ROOM DISCUSSION
   von Willich J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376626
   Weissker T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI [10.1109/VR.2019.8797807, 10.1109/vr.2019.8797807]
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   WOHLIN Claes, 2014, P 18 INT C EVALUATIO, DOI [10.1145/2601248.2601268.10, 10.1145/2601248.2601268]
NR 34
TC 23
Z9 25
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 18
PY 2021
VL 2
AR 730792
DI 10.3389/frvir.2021.730792
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YR8
UT WOS:001019244200001
OA gold
DA 2024-07-18
ER

PT J
AU Yoshimura, A
   Borst, CW
AF Yoshimura, Andrew
   Borst, Christoph W.
TI A Study of Class Meetings in VR: Student Experiences of Attending
   Lectures and of Giving a Project Presentation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; educational VR; teleconferencing; distance learning;
   remote instruction; Mozilla Hubs; COVID-19; SARS-CoV-2
ID VIRTUAL-REALITY
AB We study student experiences of social VR for remote instruction, with students attending class from home. The study evaluates student experiences when: (1) viewing remote lectures with VR headsets, (2) viewing with desktop displays, (3) presenting with VR headsets, and (4) reflecting on several weeks of VR-based class attendance. Students rated factors such as presence, social presence, simulator sickness, communication methods, avatar and application features, and tradeoffs with other remote approaches. Headset-based viewing and presenting produced higher presence than desktop viewing, but had less-clear impact on overall experience and on most social presence measures. We observed higher attentional allocation scores for headset-based presenting than for both viewing methods. For headset VR, there were strong negative correlations between simulator sickness (primarily reported as general discomfort) and ratings of co-presence, overall experience, and some other factors. This suggests that comfortable users experienced substantial benefits of headset viewing and presenting, but others did not. Based on the type of virtual environment, student ratings, and comments, reported discomfort appears related to physical ergonomic factors or technical problems. Desktop VR appears to be a good alternative for uncomfortable students, and students report that they prefer a mix of headset and desktop viewing. We additionally provide insight from students and a teacher about possible improvements for VR class technology, and we summarize student opinions comparing viewing and presenting in VR to other remote class technologies.
C1 [Yoshimura, Andrew; Borst, Christoph W.] Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
C3 University of Louisiana Lafayette
RP Yoshimura, A (corresponding author), Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
EM andrewyosh@yahoo.com
FU National Science Foundation [1815976]; Louisiana Board of Regents
   Support Fund [LEQSF (2019-20)-ENH-DE-22]
FX Funding. This material was based on work supported by the National
   Science Foundation under Grant No. 1815976 and by the Louisiana Board of
   Regents Support Fund contract LEQSF (2019-20)-ENH-DE-22.
CR Abulrub A. G., 2011, 2011 IEEE Global Engineering Education Conference (EDUCON), P751, DOI 10.1109/EDUCON.2011.5773223
   Ahn SJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.648575
   [Anonymous], 2013, ELECT DREAMS
   Borst CW, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P467, DOI 10.1109/VR.2018.8448286
   Brooke J., 1996, USABILITY EVALUATION, P6
   Campbell Abraham G., 2020, Advances in Information and Communication. Proceedings of the 2019 Future of Information and Communication Conference (FICC). Lecture Notes in Networks and Systems (LNNS 69), P463, DOI 10.1007/978-3-030-12388-8_33
   Chen YT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P172, DOI [10.1109/VR.2019.8798338, 10.1109/vr.2019.8798338]
   Erickson T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P503
   Freeman M, 1998, BRIT J EDUC TECHNOL, V29, P197, DOI 10.1111/1467-8535.00064
   Grant MM, 2007, J INTERACT ONLINE LE, V6, P211
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Harms C., 2004, 7 ANN INT WORKSH PRE
   Jennings M., 2001, International Journal of Educational Telecommunications, V7, P91
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Le DA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P485, DOI [10.1109/VRW50115.2020.0-175, 10.1109/VRW50115.2020.00101]
   Lindeman RW, 2009, IEEE COMPUT GRAPH, V29, P80, DOI 10.1109/MCG.2009.28
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Murcia-Lopez M., 2016, Frontiers in ICT, V3, DOI [DOI 10.3389/FICT.2016.00024, 10.3389/fict.2016.00024]
   Oberdörfer S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300405
   Parmar D, 2016, VIRTUAL REAL-LONDON, V20, P141, DOI 10.1007/s10055-016-0287-7
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Psotka J, 2013, EDUC TECHNOL SOC, V16, P69
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Ryu J, 2021, LECT NOTES COMPUT SC, V12615, P218, DOI 10.1007/978-3-030-68449-5_22
   Schultz A. R., 2019, UPDATED COMP CHART 1
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Srivastava P, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00050
   Steinicke Frank, 2020, SUI '20: Symposium on Spatial User Interaction, DOI 10.1145/3385959.3422699
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yoshimura A, 2020, P ACM S VIRT REAL SO, V26, P1, DOI [10.1145/3385956.3422124, DOI 10.1145/3385956.3422124]
   Yoshimura A., 2020, INT C ART REAL TEL E
NR 36
TC 8
Z9 8
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 31
PY 2021
VL 2
AR 648619
DI 10.3389/frvir.2021.648619
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0GG3
UT WOS:001020118200001
OA gold
DA 2024-07-18
ER

PT J
AU Suárez, G
   Jung, SC
   Lindeman, RW
AF Suarez, Gonzalo
   Jung, Sungchul
   Lindeman, Robert W.
TI Evaluating Virtual Human Role-Players for the Practice and Development
   of Leadership Skills
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual humans; role-playing; virtual reality; mixed reality; leadership
   training
ID HEART-RATE-VARIABILITY; STRESS; REALITY; BODY; METAANALYSIS; STATE
AB This article reports on a study to evaluate the effectiveness of virtual human (VH) role-players as leadership training tools within two computer-generated environments, virtual reality (VR) and mixed reality (MR), compared to a traditional training method, real human (RH) role-players in a real-world (RW) environment. We developed an experimental training platform to assess the three conditions: RH role-players in RW (RH-RW), VH role-players in VR (VH-VR), and VH role-players in MR (VH-MR), during two practice-type opportunities, namely pre-session and post-session. We conducted a user study where 30 participants played the role of leaders in interacting with either RHs or VHs before and after receiving a leadership training session. We then investigated (1) if VH role-players were as effective as RH role-players during pre- and post-sessions, and (2) the impact that the human-type (RH, VH) in conjunction with the environment-type (RW, VR, MR) had on the outcomes. We also collected user reactions and learning data from the overall training experience. The results showed a regular increase in performance from pre- to post-sessions in all three conditions. However, we did not find a significant difference between VHs and RHs. Interestingly, the VH-MR condition had a more significant influence on performance and task engagement compared to the VH-VR and RH-RW conditions. Based on our findings, we conclude that VH role-players can be as effective as RH role-players to support the practice of leadership skills, where VH-MR could be the best method due to its effectiveness.
C1 [Suarez, Gonzalo; Jung, Sungchul; Lindeman, Robert W.] Univ Canterbury, Coll Engn, Human Interface Technol Lab NZ, Christchurch, New Zealand.
C3 University of Canterbury
RP Suárez, G (corresponding author), Univ Canterbury, Coll Engn, Human Interface Technol Lab NZ, Christchurch, New Zealand.
EM gonzalo.suarez.v@gmail.com
OI Jung, Sungchul/0000-0003-3633-7767
CR ALBERTSON LA, 1980, COMMUN RES, V7, P387, DOI 10.1177/009365028000700307
   [Anonymous], 2012, INT IND TRAIN SIM ED
   Badler N, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P28, DOI 10.1109/NAMW.1997.609848
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Batrinca Ligia, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P116, DOI 10.1007/978-3-642-40415-3_10
   Blanchard K.H., 1993, Journal of Leadership Organizational Studies, V1, P21, DOI DOI 10.1177/107179199300100104
   Blanchard K. H., 2015, LEADERSHIP ONE MINUT
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bosman Kim, 2019, INTELLIGENT TECHNOLO, P75
   Campbell Julia C, 2011, PAPER, V11358
   Conrad D., 2011, American Communication Journal, V13, P4
   Core M, 2006, SIMUL-T SOC MOD SIM, V82, P685, DOI 10.1177/0037549706075542
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Gratch J, 2016, LECT NOTES ARTIF INT, V10011, P283, DOI 10.1007/978-3-319-47665-0_25
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Guetterman TC, 2017, ADV MED EDUC PRACT, V8, P505, DOI 10.2147/AMEP.S138380
   Hartholt Arno, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P368, DOI 10.1007/978-3-642-40415-3_33
   Hartholt A, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P238, DOI 10.1145/ivade780
   Helton W.S., 2004, Proc. Hum. Factors Ergon. Soc. Annu. Meet., V48, P1238, DOI DOI 10.1177/154193120404801107
   Hunt J. W., 2003, Journal of Management Development, V22, P729, DOI 10.1108/02621710310487882
   Johnsen K, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1049
   Jung S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P463, DOI [10.1109/VR46266.2020.1580947852943, 10.1109/VR46266.2020.00-37]
   Jung S, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P60, DOI 10.1145/3267782.3267920
   Jung S, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P3, DOI 10.1145/3131277.3132186
   Jung S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P267, DOI 10.1109/VR.2018.8447562
   Jung Sungchul., 2016, P 26 INT C ART REAL, P107, DOI DOI 10.2312/EGVE.20161442
   Kaiser R.B., 2013, Consulting Psychology Journal: Practice and Research, V65, P294, DOI DOI 10.1037/A0035460
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kim HG, 2018, PSYCHIAT INVEST, V15, P235, DOI 10.30773/pi.2017.08.17
   Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039
   Kirkpatrick D. L., 1996, ASTD TRAINING DEV HD, P59
   Kirkpatrick D.L., 1994, EVALUATING TRAINING
   Kirkpatrick J., 2009, NEW WORLD LEVEL 2 IM
   Kirkpatrick J., 2008, NEW WORLD LEVEL 1 RE
   Kirkpatrick J. D., 2016, Kirkpatricks Four Levels of Training Evaluation
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P997, DOI 10.1007/s00371-005-0363-6
   Mast MS, 2018, HUM RESOUR DEV Q, V29, P125, DOI 10.1002/hrdq.21307
   Matthews G., 1999, PERSONALITY PSYCHOL, V7, P335, DOI DOI 10.1177/154193120404801107
   MATTHEWS G, 2005, 12 M INT SOC STUD IN
   Matthews G, 2016, HUM FACTORS, V58, P801, DOI 10.1177/0018720816653688
   Matthews G, 2012, PERS INDIV DIFFER, V53, P574, DOI 10.1016/j.paid.2012.04.034
   Matthews G, 2002, EMOTION, V2, P315, DOI 10.1037//1528-3542.2.4.315
   McCauley C.D., 2004, CTR CREATIVE LEADERS, V2nd
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nazari G, 2018, BMC SPORTS SCI MED R, V10, DOI 10.1186/s13102-018-0094-4
   Neubauer C.E., 2012, Proceedings of Human Factors and Ergonomics Society, V56, DOI DOI 10.1177/1071181312561415
   Piaget J., 1952, The origins of intelligence in children, DOI DOI 10.1037/11494-000
   Rosenthal-von der Putten A. M., 2009, 12 ANN INT WORKSH PR
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Sogunro O.A., 2004, The Journal of Management Development, V23, P355, DOI 10.1108/02621710410529802
   Storey Cox., 2015, American Research Institute for Policy Development, V4, P41, DOI [10.15640/jehd.v4n2a5, DOI 10.15640/JEHD.V4N2A5]
   Thayer JF, 2012, NEUROSCI BIOBEHAV R, V36, P747, DOI 10.1016/j.neubiorev.2011.11.009
   Van Ments M., 1989, The effective use of role-play, Vrev.
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang MJ, 2011, ADV INTEL SOFT COMPU, V92, P59
   Watkins R, 1998, ETR&D-EDUC TECH RES, V46, P90, DOI 10.1007/BF02299676
   Weaver SJ, 2010, J CONTIN EDUC HEALTH, V30, P208, DOI 10.1002/chp.20085
   Weber CS, 2010, EUR J APPL PHYSIOL, V109, P201, DOI 10.1007/s00421-009-1341-x
   Wexley K.N., 2002, DEV TRAINING HUMAN R
   Zigarmi D., 1997, GETTING KNOW LBAII R
   Zigarmi D, 2017, EUR J TRAIN DEV, V41, P241, DOI 10.1108/EJTD-05-2016-0035
   ZIMMERMAN BJ, 1989, J EDUC PSYCHOL, V81, P329, DOI 10.1037/0022-0663.81.3.329
NR 66
TC 5
Z9 6
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 12
PY 2021
VL 2
AR 658561
DI 10.3389/frvir.2021.658561
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XR1
UT WOS:001023315700001
OA gold
DA 2024-07-18
ER

PT J
AU Richard, G
   Pietrzak, T
   Argelaguet, F
   Lécuyer, A
   Casiez, G
AF Richard, Gregoire
   Pietrzak, Thomas
   Argelaguet, Ferran
   Lecuyer, Anatole
   Casiez, Gery
TI Studying the Role of Haptic Feedback on Virtual Embodiment in a Drawing
   Task
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; haptic feedback; embodiment; vibrotactile feedback;
   kinesthesia; force-feedback
ID BODY OWNERSHIP; HAND ILLUSION; SELF; AGENCY; TOUCH; SENSE; FEEL
AB The role of haptic feedback on virtual embodiment is investigated in this paper in a context of active and fine manipulation. In particular, we explore which haptic cue, with varying ecological validity, has more influence on virtual embodiment. We conducted a within-subject experiment with 24 participants and compared self-reported embodiment over a humanoid avatar during a coloring task under three conditions: force feedback, vibrotactile feedback, and no haptic feedback. In the experiment, force feedback was more ecological as it matched reality more closely, while vibrotactile feedback was more symbolic. Taken together, our results show significant superiority of force feedback over no haptic feedback regarding embodiment, and significant superiority of force feedback over the other two conditions regarding subjective performance. Those results suggest that a more ecological feedback is better suited to elicit embodiment during fine manipulation tasks.
C1 [Richard, Gregoire; Pietrzak, Thomas; Casiez, Gery] Univ Lille, Inria, CNRS, Cent Lille,CRIStAL,UMR 9189, Lille, France.
   [Argelaguet, Ferran; Lecuyer, Anatole] Inria Rennes Bretagne Atlantique, Rennes, France.
   [Casiez, Gery] Inst Univ France, Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   de Lille; Centrale Lille; Universite de Rennes; Institut Universitaire
   de France
RP Richard, G (corresponding author), Univ Lille, Inria, CNRS, Cent Lille,CRIStAL,UMR 9189, Lille, France.
EM gregoire.richard@inria.fr
RI Pietrzak, Thomas/AAW-1170-2021
OI Pietrzak, Thomas/0000-0002-2013-7253
FU Inria Challenge Avatar
FX & nbsp;This work was partially supported by the Inria Challenge Avatar.
CR Alimardani M, 2016, SCI REP-UK, V6, DOI 10.1038/srep33514
   [Anonymous], 1994, P ASME WINT ANN M S
   Bayne T, 2007, SYNTHESE, V159, P475, DOI 10.1007/s11229-007-9239-9
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Bergstrom J., 2019, P 2019 CHI C HUM FAC, P568, DOI [10.1145/3290605.3300798, DOI 10.1145/3290605.3300798]
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Burin D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209899
   Burns E., 2006, P ACM S VIRT REAL SO, P3, DOI [DOI 10.1145/1180495.1180499, 10.1145/1180495.1180499]
   Cardinali L, 2009, CURR BIOL, V19, pR478, DOI 10.1016/j.cub.2009.05.009
   Casiez G, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P29, DOI 10.1145/3126594.3126606
   Cheng L.-T., 1997, P 4 ACM INT C MULT, P243, DOI [10.1145/244130.244220, DOI 10.1145/244130.244220]
   Choi W, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/8163098
   Culbertson H, 2018, ANNU REV CONTR ROBOT, V1, P385, DOI 10.1146/annurev-control-060117-105043
   de Vignemont F, 2015, NEUROPSYCHOLOGIA, V70, P327, DOI 10.1016/j.neuropsychologia.2014.11.018
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Franck N, 2001, AM J PSYCHIAT, V158, P454, DOI 10.1176/appi.ajp.158.3.454
   Fröhner J, 2019, IEEE T HAPTICS, V12, P339, DOI 10.1109/TOH.2018.2889497
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   Giummarra MJ, 2008, NEUROSCI BIOBEHAV R, V32, P143, DOI 10.1016/j.neubiorev.2007.07.001
   GOFF GD, 1967, J EXP PSYCHOL, V74, P294, DOI 10.1037/h0024561
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Gupta A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3683, DOI 10.1145/2858036.2858161
   Israr A, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641570
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Lemole GM, 2007, NEUROSURGERY, V61, P142, DOI 10.1227/01.neu.0000279734.22931.21
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   Lopez C, 2008, NEUROPHYSIOL CLIN, V38, P149, DOI 10.1016/j.neucli.2007.12.006
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   Mitra P, 2004, 2004 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P1054
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Oakley I., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P415, DOI 10.1145/332040.332467
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Perry J.S., 2018, IBM developerWorks, P1
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Raz L, 2008, LECT NOTES COMPUT SC, V5024, P367, DOI 10.1007/978-3-540-69057-3_47
   Rincon-Gonzalez L, 2011, IEEE T NEUR SYS REH, V19, P490, DOI 10.1109/TNSRE.2011.2166808
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Shimada S, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006185
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P2740, DOI 10.1016/j.neuropsychologia.2010.05.021
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
NR 56
TC 15
Z9 17
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 18
PY 2021
VL 1
AR 573167
DI 10.3389/frvir.2020.573167
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XT5
UT WOS:001023318200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Harada, Y
   Wada, M
AF Harada, Yuki
   Wada, Makoto
TI Autism-related traits are related to effectiveness of immersive visual
   guidance on spatial cognitive ability: a pilot study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE autistic trait; systemizing cognition; empathizing cognition; spatial
   cognition; immersive visual guidance; visual search; spatial
   localization
ID HIGH-FUNCTIONING AUTISM; ASPERGER-SYNDROME; QUOTIENT; ADULTS
AB A head-mounted display could potentially restrict users' visual fields and thereby impair their spatial cognitive ability. Spatial cognition can be assisted with immersive visual guidance. However, whether this technique is useful for individuals with autism-spectrum disorder (ASD) remains unclear. Given the recent virtual reality (VR) contents targeting individuals with ASD, the relationship between ASD-related traits and the effectiveness of immersive visual guidance should be clarified. This pilot study evaluated how ASD-related traits (autistic traits and empathizing-systemizing cognitive styles) among typically developing individuals are related to the effectiveness of visual guidance. Participants performed visual search and spatial localization tasks while using immersive visual guidance. In the visual search task, participants searched immersive VR environments for a target object and pushed a button according to the target color as quickly as possible. In the localization task, they viewed immersive visual guidance for a short duration and localized the guided direction via a controller. Results showed that visual search times were hastened with systemizing cognition. However, ASD-related traits were not significantly related to localization accuracy. These findings suggest that immersive visual guidance is generally useful for individuals with higher ASD-related traits.
C1 [Harada, Yuki] Kyoto Univ Adv Sci, Fac Humanities, Kyoto, Japan.
   [Harada, Yuki; Wada, Makoto] Natl Rehabil Ctr Persons Disabil, Res Inst, Dept Rehabil Brain Funct, Dev Disorders Sect, Tokorozawa, Japan.
RP Harada, Y (corresponding author), Kyoto Univ Adv Sci, Fac Humanities, Kyoto, Japan.; Harada, Y (corresponding author), Natl Rehabil Ctr Persons Disabil, Res Inst, Dept Rehabil Brain Funct, Dev Disorders Sect, Tokorozawa, Japan.
EM haradayuuki00@gmail.com
FU Japan Society for the Promotion of Science KAKENHI [20K19855, 21H05053,
   23K12937]
FX The author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. This work was partially
   supported by the Japan Society for the Promotion of Science KAKENHI
   (grant numbers 20K19855, 21H05053, and 23K12937) for the equipment,
   payment to participants, and publication fees.
CR American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Baron-Cohen S, 2003, PHILOS T ROY SOC B, V358, P361, DOI 10.1098/rstb.2002.1206
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Conson M, 2020, COGN PROCESS, V21, P127, DOI 10.1007/s10339-019-00941-y
   Cook CM, 2010, PERS INDIV DIFFER, V49, P712, DOI 10.1016/j.paid.2010.06.010
   Franconeri SL, 2003, PERCEPT PSYCHOPHYS, V65, P999, DOI 10.3758/BF03194829
   FRITH U, 1994, COGNITION, V50, P115, DOI 10.1016/0010-0277(94)90024-8
   Gruenefeld U., 2017, OutOfView
   Gruenefeld U., 2018, P 7 ACM INT S PERVAS, P1
   Gruenefeld U., 2018, P 20 INT C HUMAN COM, P1
   Gruenefeld U, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P742, DOI [10.1109/vr.2019.8797725, 10.1109/VR.2019.8797725]
   Harada Y, 2022, VIRTUAL REAL-LONDON, V26, P759, DOI 10.1007/s10055-021-00574-7
   Harmsen IE, 2019, J AUTISM DEV DISORD, V49, P3939, DOI 10.1007/s10803-019-04087-w
   Haswell CC, 2009, NAT NEUROSCI, V12, P970, DOI 10.1038/nn.2356
   HENDERSON JM, 1993, PERCEPT PSYCHOPHYS, V53, P221, DOI 10.3758/BF03211732
   Ip HHS, 2018, COMPUT EDUC, V117, P1, DOI 10.1016/j.compedu.2017.09.010
   Kaldy Z, 2016, J AUTISM DEV DISORD, V46, P1513, DOI 10.1007/s10803-013-1957-x
   Keehn B, 2013, NEUROSCI BIOBEHAV R, V37, P164, DOI 10.1016/j.neubiorev.2012.11.014
   Kumazaki H, 2022, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.704564
   Li C, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12112497
   Lorenzo G, 2013, COMPUT EDUC, V62, P88, DOI 10.1016/j.compedu.2012.10.028
   McCleery JP, 2020, AUTISM RES, V13, P1418, DOI 10.1002/aur.2352
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Muth A, 2014, J AUTISM DEV DISORD, V44, P3245, DOI 10.1007/s10803-014-2188-5
   O'Riordan MA, 2004, AUTISM, V8, P229, DOI 10.1177/1362361304045219
   Visser E, 2013, J PSYCHIATR NEUROSCI, V38, P398, DOI 10.1503/jpn.120177
   Wada M, 2014, SCI REP-UK, V4, DOI 10.1038/srep05985
   Wakabayashi Akio, 2004, Shinrigaku Kenkyu, V75, P78
   Wakabayashi Akio, 2006, Shinrigaku Kenkyu, V77, P271
   Zwiers MP, 2004, J NEUROSCI, V24, P4145, DOI 10.1523/JNEUROSCI.0199-04.2004
NR 32
TC 0
Z9 0
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 30
PY 2023
VL 4
AR 1291516
DI 10.3389/frvir.2023.1291516
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CD1V2
UT WOS:001123229700001
OA gold
DA 2024-07-18
ER

PT J
AU Kirollos, R
   Herdman, CM
AF Kirollos, Ramy
   Herdman, Chris M.
TI Visual-vestibular sensory integration during congruent and incongruent
   self-rotation percepts using caloric vestibular stimulation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; visual-vestibular sensory integration; caloric
   vestibular stimulation; vection; optokinetic drum
ID MULTISENSORY CUE INTEGRATION; PERIPHERAL-VISION; CIRCULAR VECTION;
   MOTION; RESPONSES; ORIENTATION; ADAPTATION; SENSATIONS; LATENCY; SMOOTH
AB Introduction: The present study sets out to determine which sensory system mostly influences self-motion perception when visual and vestibular cues are in conflict. We paired caloric vestibular stimulation that signaled motion in either the clockwise or counter-clockwise direction with a visual display that indicated self-rotation in either the same or opposite directions.Methods: In Experiment 1 (E1), caloric vestibular stimulation was used to produce vestibular circular vection. In Experiment 2 (E2), a virtual optokinetic drum was used to produce visual circular vection in a VR headset. Vection speed, direction, and duration were recorded using a potentiometer knob the participant controlled in E1 and E2. In Experiment 3 (E3), visual and vestibular stimuli were matched to be at approximately equal speeds across visual and vestibular modalities for each participant setting up Experiment 4 (E4). In E4, participants observed a moving visual pattern in a virtual reality (VR) headset while receiving caloric vestibular stimulation. Participants rotated the potentiometer knob while attending to visual-vestibular stimuli presentations to indicate their perceived circular vection. E4 had two conditions: 1) A congruent condition where calorics and visual display indicated circular vection in the same direction; 2) an incongruent condition where calorics and visual display indicated circular vection in opposite directions.Results and discussion: There were equal reports of knob rotation in the direction consistent with the visual and vestibular self-rotation direction in the incongruent condition of E4 across trials. There were no significant differences in knob rotation speed and duration in both conditions. These results demonstrate that the brain appears to weigh visual and vestibular cues equally during a visual-vestibular conflict of approximately equal speeds. These results are most consistent with the optimal cue integration hypothesis.
C1 [Kirollos, Ramy] Toronto Res Ctr, Def Res & Dev Canada, Toronto, ON, Canada.
   [Kirollos, Ramy; Herdman, Chris M.] Carleton Univ, Visualizat & Simulat Ctr, Ottawa, ON, Canada.
C3 Defence Research & Development Canada; Carleton University
RP Kirollos, R (corresponding author), Toronto Res Ctr, Def Res & Dev Canada, Toronto, ON, Canada.; Kirollos, R (corresponding author), Carleton Univ, Visualizat & Simulat Ctr, Ottawa, ON, Canada.
EM ramy.kirollos@drdc-rddc.gc.ca
CR Allison RS, 2012, EXP BRAIN RES, V223, P479, DOI 10.1007/s00221-012-3275-5
   Aoyama K, 2015, SCI REP-UK, V5, DOI 10.1038/srep10168
   Baloh R. W., 2003, Encyclopedia of the neurological sciences, P661
   Barany R., 1906, Oscar Coblentz
   Benjamin N., 2008, XBOX 360 controller
   Bense S, 2001, J NEUROPHYSIOL, V85, P886, DOI 10.1152/jn.2001.85.2.886
   BERTHOZ A, 1975, EXP BRAIN RES, V23, P471
   Berti S, 2019, DISPLAYS, V58, P56, DOI 10.1016/j.displa.2018.10.002
   Bordoni B., 2021, StatPearls
   Bos JE, 2019, DISPLAYS, V58, P66, DOI 10.1016/j.displa.2019.01.001
   Brandt T, 1998, BRAIN, V121, P1749, DOI 10.1093/brain/121.9.1749
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   Butler JS, 2010, J VISION, V10, DOI 10.1167/10.11.23
   Campos J, 2018, HEARING RES, V369, P42, DOI 10.1016/j.heares.2018.03.025
   Clarke J. J., 1990, Data fusion for sensory information processing, P978
   COATS AC, 1976, ARCH OTOLARYNGOL, V102, P343
   Cress JD, 1997, IEEE COMPUT GRAPH, V17, P46, DOI 10.1109/38.626969
   de Winkel KN, 2013, EXP BRAIN RES, V231, P209, DOI 10.1007/s00221-013-3683-1
   de Winkel KN, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127104
   de Winkel KN, 2010, J VISION, V10, DOI 10.1167/10.12.1
   Dichgans Johannes, 1978, Perception, P755, DOI [DOI 10.1007/978-3-642-46354-9253F, DOI 10.1007/978-3-642-46354-9_25, DOI 10.1007/978-3-642-46354-925]
   Dilda V, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112131
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Fetsch CR, 2012, NAT NEUROSCI, V15, P146, DOI 10.1038/nn.2983
   Fetsch CR, 2010, EUR J NEUROSCI, V31, P1721, DOI 10.1111/j.1460-9568.2010.07207.x
   Fetsch CR, 2009, J NEUROSCI, V29, P15601, DOI 10.1523/JNEUROSCI.2574-09.2009
   Fischer M. H, 1924, KLIN WOCHENSCHR, V3, P1406, DOI [10.1007/BF01852444, DOI 10.1007/BF01852444]
   Fitzpatrick RC, 2004, J APPL PHYSIOL, V96, P2301, DOI 10.1152/japplphysiol.00008.2004
   Fitzpatrick RC, 2002, NEUROREPORT, V13, P2379, DOI 10.1097/00001756-200212200-00001
   Fitzpatrick RC, 2015, J PHYSIOL-LONDON, V593, P2389, DOI 10.1113/JP270334
   Frank SM, 2018, J NEUROPHYSIOL, V120, P1438, DOI 10.1152/jn.00907.2017
   Frank SM, 2016, J NEUROPHYSIOL, V116, P263, DOI 10.1152/jn.00009.2016
   Frank SM, 2014, J NEUROPHYSIOL, V112, P2481, DOI 10.1152/jn.00078.2014
   Frank SM, 2014, J NEUROSCI METH, V235, P208, DOI 10.1016/j.jneumeth.2014.07.008
   Gallagher M, 2020, MULTISENS RES, V33, P625, DOI 10.1163/22134808-20201487
   Gescheider GA., 1997, PSYCHOPHYSICS FUNDAM
   GIBSON JAMES J., 1966
   GOLDBERG JM, 1987, J NEUROPHYSIOL, V58, P700, DOI 10.1152/jn.1987.58.4.700
   Gonçalves Denise Utsch, 2008, Rev. Bras. Otorrinolaringol., V74, P440, DOI 10.1590/S0034-72992008000300020
   Gu Y, 2008, NAT NEUROSCI, V11, P1201, DOI 10.1038/nn.2191
   Harris LR, 2000, EXP BRAIN RES, V135, P12, DOI 10.1007/s002210000504
   Hogyes A., 1913, Uber den Nervenmechanismus der assoziierten Augenbewegungen: von Andreas Hogyes. Ubers. von Martin Sugar
   Howard I.P., 1982, HUMAN VISUAL ORIENTA
   HOWARD IP, 1994, PERCEPTION, V23, P753, DOI 10.1068/p230753
   Jacobson G P., 1993, Handbook of Balance Function Testing, P156
   Jarmasz J, 2009, CAN J EXP PSYCHOL, V63, P124, DOI 10.1037/a0014164
   JONES AM, 1985, PSYCHIAT RES, V14, P291, DOI 10.1016/0165-1781(85)90097-6
   Jürgens R, 2016, EXP BRAIN RES, V234, P67, DOI 10.1007/s00221-015-4433-3
   Jürgens R, 2011, EXP BRAIN RES, V215, P327, DOI 10.1007/s00221-011-2900-z
   KARNATH HO, 1994, BRAIN, V117, P1001, DOI 10.1093/brain/117.5.1001
   Kassemi M, 2004, ANN NY ACAD SCI, V1027, P360, DOI 10.1196/annals.1324.030
   Kassemi M, 2005, COMPUT STRUCT, V83, P181, DOI 10.1016/j.compstruc.2004.08.001
   Keshavarz B, 2014, EXP BRAIN RES, V232, P827, DOI 10.1007/s00221-013-3793-9
   Kirollos R, 2023, I-PERCEPTION, V14, DOI 10.1177/20416695231168093
   Kirollos R, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102049
   Kirollos R, 2017, MULTISENS RES, V30, P739, DOI 10.1163/22134808-00002593
   Klaus MP, 2020, J COGNITIVE NEUROSCI, V32, P484, DOI 10.1162/jocn_a_01496
   Lee D. N., 1975, Journal of Human Movement Studies, V1, P87, DOI DOI 10.3758/BF03199297
   LEVY DL, 1983, SCHIZOPHRENIA BULL, V9, P383, DOI 10.1093/schbul/9.3.383
   LISHMAN JR, 1973, PERCEPTION, V2, P287, DOI 10.1068/p020287
   Mach E., 1875, GRUNDLINIEN LEHRE BE
   Meiry J., 1967, Report
   MELCHER GA, 1981, PERCEPT PSYCHOPHYS, V30, P552, DOI 10.3758/BF03202009
   Moon Sy, 2006, J Clin Neurol, V2, P12, DOI 10.3988/jcn.2006.2.1.12
   Moore ST, 2011, AVIAT SPACE ENVIR MD, V82, P535, DOI 10.3357/ASEM.2942.2011
   Nishiike S, 2002, NEUROREPORT, V13, P1805, DOI 10.1097/00001756-200210070-00023
   Owens DA, 2018, CONSCIOUS COGN, V64, P61, DOI 10.1016/j.concog.2018.07.006
   Palmisano S, 1998, PERCEPTION, V27, P1067, DOI 10.1068/p271067
   Palmisano S, 2000, PERCEPTION, V29, P57, DOI 10.1068/p2990
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Purves D, 2001, NAT NEUROSCI, V4, P777, DOI 10.1038/90470
   Rabbitt RD, 2019, J NEUROPHYSIOL, V121, P732, DOI 10.1152/jn.00708.2018
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Reymond G, 2002, BIOL CYBERN, V87, P301, DOI 10.1007/s00422-002-0357-7
   Riecke B. E., 2008, Proceedings of the 5th symposium on applied perception in graphics and visualization
   Riecke B. E., 2013, Human walking in virtual environments, P27, DOI 10.1007/978-1-4419-8432-6_2
   Rohde M, 2016, MULTISENS RES, V29, P279, DOI 10.1163/22134808-00002510
   Santos CF, 2017, ACTA BIOENG BIOMECH, V19, P3, DOI 10.5277/ABB-00498-2015-03
   Sluga M., 2021, Slovenian Med. J.-Neurobiol, V90, P54, DOI [10.6016/zdravvestn.2985, DOI 10.6016/ZDRAVVESTN.2985]
   St George RJ, 2011, J PHYSIOL-LONDON, V589, P843, DOI 10.1113/jphysiol.2010.197053
   Telban R., 2001, Psychol. Rev, V2, P273, DOI [10.2514/6.2001-4249, DOI 10.2514/6.2001-4249]
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weech S, 2017, MULTISENS RES, V30, P65, DOI 10.1163/22134808-00002545
   Wu X, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87730-w
NR 85
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 26
PY 2023
VL 4
AR 1253155
DI 10.3389/frvir.2023.1253155
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA X8JJ4
UT WOS:001100842600001
OA gold
DA 2024-07-18
ER

PT J
AU Luna-Rodríguez, GL
   Peláez-Hernández, V
   Orea-Tejeda, A
   Ledesma-Ruiz, CD
   Casarin-López, F
   Rosas-Trujillo, A
   Dominguez-Trejo, B
   Tepepa-Flores, L
AF Luna-Rodriguez, Guadalupe Lizzbett
   Pelaez-Hernandez, Viridiana
   Orea-Tejeda, Arturo
   Ledesma-Ruiz, Celia Deyanira
   Casarin-Lopez, Fernando
   Rosas-Trujillo, Adrian
   Dominguez-Trejo, Benjamin
   Tepepa-Flores, Li Erandi
TI Prevalence of post-traumatic stress disorder, emotional impairments, and
   fear in COVID-19 surviving patients
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE post-traumatic stress disorder (PTSD); anxiety; depression; fear; SARS-
   CoV-2
ID PSYCHOLOGICAL DISTRESS; DEPRESSION; MORBIDITIES; VALIDITY; PHQ-9
AB Introduction: Among the different psychological sequelae of post-COVID syndrome are symptoms related to emotional impairment, mostly depression, anxiety, and post-traumatic stress disorder (PTSD).
   Objective: To describe and compare the prevalence and severity of PTSD, anxiety, depression, and fear of COVID-19 in survivors 3 months after discharge from the hospital.
   Methods: A cross-sectional descriptive study was conducted, a total of 227 survivors of COVID-19 participated; they were assessed 3 months after being discharged from the hospital. A psychological evaluation focused on anxiety, depression, PTSD, and fear was conducted. Statistical analysis through the t-test for independent samples was performed.
   Results: Of the patients, 64.5% were men, 60.9% required invasive mechanical ventilation (IMV) during hospitalization, and the average age was about 48.23 +/- 14.33 years. Also, 40% showed symptoms associated with PTSD, 38.4% exhibited anxiety, 36.6% depression, and 36.12% exhibited fear of COVID-19. There were statistically significant differences between men and women, in PTSD (t = -3.414, df = 224, p = 0.001, (X) over bar (m) = 5.10, (X) over bar (w) = 6.32), depression (t = -4.680, df = 225, p = 0.000, (X) over bar (m) = 3.64, (X) over bar (w) = 7.18), anxiety (t = -3.427, df = 152.53, p = 0.001, (X) over bar (m) = 3.78, (X) over bar (w) = 6.20), and fear of COVID-19 (t = -3.400, df = 224, p = 0.001, (X) over bar (m) = 11.88, (X) over bar (w) = 15.19). Furthermore, there were also statistically significant differences between the type of treatment during hospitalization (IMV vs. without IMV), in PTSD (t = 2.482, df = 223, p = 0.014, (X) over bar (IMV) = 5.21, (X) over bar (WIMV) = 6.08) and anxiety (t = -2.006, df = 223, p = 0.046, (X) over bar (IMV) = 4.05, (X) over bar (WIMV) = 5.44).
   Conclusion: Survivors of COVID-19 experience a high prevalence of PTSD, anxiety, depression, and fear, even 3 months after discharge from the hospital. Females and patients who did not require IMV during hospitalization are the most affected population, presenting more severe symptoms of these psychological alterations. More research is required to know and observe the long-term evolution of these psychological alterations in this population.
C1 [Luna-Rodriguez, Guadalupe Lizzbett; Pelaez-Hernandez, Viridiana; Orea-Tejeda, Arturo; Ledesma-Ruiz, Celia Deyanira; Casarin-Lopez, Fernando; Rosas-Trujillo, Adrian] Inst Nacl Enfermedades Respiratorias Ismael Cosio, Cardiol Serv, Mexico City, Mexico.
   [Dominguez-Trejo, Benjamin; Tepepa-Flores, Li Erandi] Univ Nacl Autonoma Mexico, Fac Psychol, Mexico City, Mexico.
C3 Universidad Nacional Autonoma de Mexico
RP Peláez-Hernández, V (corresponding author), Inst Nacl Enfermedades Respiratorias Ismael Cosio, Cardiol Serv, Mexico City, Mexico.
EM vpelaezh@gmail.com
FU Secretary of Health of the Mexican government
FX This work was supported by economic funds granted by the Secretary of
   Health of the Mexican government.
CR Abdelghani M, 2021, MIDDLE EAST CURR PSY, V28, DOI 10.1186/s43045-021-00102-y
   Ahorsu DK, 2022, INT J MENT HEALTH AD, V20, P1537, DOI 10.1007/s11469-020-00270-8
   Arrieta J, 2017, J CLIN PSYCHOL, V73, P1076, DOI 10.1002/jclp.22390
   Bender del Busto J. E., 2022, REV ELECT NICA MEDIM, V29, P1
   Boix V, 2022, MED CLIN-BARCELONA, V158, P178, DOI 10.1016/j.medcli.2021.10.002
   Brady KT, 2000, J CLIN PSYCHIAT, V61, P22
   Brooks SK, 2020, LANCET, V395, P912, DOI 10.1016/S0140-6736(20)30460-8
   Cai X, 2020, AM J GERIAT PSYCHIAT, V28, P1030, DOI 10.1016/j.jagp.2020.07.003
   Campo-Arias Adalberto, 2020, Rev. Fac. Nac. Salud Pública, V38, pe339851, DOI 10.17533/udea.rfnsp.e339851
   Carvajal César, 2002, Rev. chil. neuro-psiquiatr., V40, P20
   Chen YR, 2021, BMC PSYCHIATRY, V21, DOI 10.1186/s12888-021-03076-7
   Cheng SKW, 2004, PSYCHOL MED, V34, P1187, DOI 10.1017/S0033291704002272
   Ciotti Marco, 2020, Crit Rev Clin Lab Sci, V57, P365, DOI 10.1080/10408363.2020.1783198
   Carvalho PMD, 2020, PSYCHIAT RES, V286, DOI 10.1016/j.psychres.2020.112902
   Du L, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000022235
   Gambin M, 2021, COMPR PSYCHIAT, V105, DOI 10.1016/j.comppsych.2020.152222
   García-Reyna B, 2022, INT J MENT HEALTH AD, V20, P895, DOI 10.1007/s11469-020-00413-x
   Ginzburg K, 2010, J AFFECT DISORDERS, V123, P249, DOI 10.1016/j.jad.2009.08.006
   Gutierrez-Velilla E., 2022, ASSESSMENT ANXIETY M
   Halpin SJ, 2021, J MED VIROL, V93, P1013, DOI 10.1002/jmv.26368
   Huang CL, 2021, LANCET, V397, P220, DOI [10.1016/S0140-6736(20)32656-8, 10.1016/S0140-6736(23)00810-3]
   Huilca Sergo K., 2021, FACTORES ASOCIADOS S
   Janiri D, 2021, JAMA PSYCHIAT, V78, P567, DOI 10.1001/jamapsychiatry.2021.0109
   Carod-Artal FJ, 2018, CLIN AUTON RES, V28, P67, DOI 10.1007/s10286-017-0452-4
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Lam MHB, 2009, ARCH INTERN MED, V169, P2142, DOI 10.1001/archinternmed.2009.384
   Lee SH, 2019, PSYCHIAT INVEST, V16, P59
   Liu D, 2020, PSYCHIAT RES, V292, DOI 10.1016/j.psychres.2020.113297
   Mak IWC, 2010, GEN HOSP PSYCHIAT, V32, P590, DOI 10.1016/j.genhosppsych.2010.07.007
   Mak IWC, 2009, GEN HOSP PSYCHIAT, V31, P318, DOI 10.1016/j.genhosppsych.2009.03.001
   Mazza MG, 2020, BRAIN BEHAV IMMUN, V89, P594, DOI 10.1016/j.bbi.2020.07.037
   Meltzer-Brody S, 1999, PSYCHIAT RES, V88, P63, DOI 10.1016/S0165-1781(99)00070-0
   Miller AH, 2016, NAT REV IMMUNOL, V16, P22, DOI 10.1038/nri.2015.5
   Moldofsky H, 2011, BMC NEUROL, V11, DOI 10.1186/1471-2377-11-37
   Moreno-Pérez O, 2021, J INFECTION, V82, P378, DOI 10.1016/j.jinf.2021.01.004
   Najjar S, 2013, J NEUROINFLAMM, V10, DOI 10.1186/1742-2094-10-43
   Nalbandian A, 2021, NAT MED, V27, P601, DOI 10.1038/s41591-021-01283-z
   Nie XD, 2021, INT J PSYCHIAT CLIN, V25, P109, DOI 10.1080/13651501.2020.1791345
   Ochnik D, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19127207
   Peghin M, 2021, CLIN MICROBIOL INFEC, V27, P1507, DOI 10.1016/j.cmi.2021.05.033
   Poyraz BÇ, 2021, PSYCHIAT RES, V295, DOI 10.1016/j.psychres.2020.113604
   Reynolds K, 2016, AM J GERIAT PSYCHIAT, V24, P81, DOI 10.1016/j.jagp.2015.11.001
   Rogers JP, 2020, LANCET PSYCHIAT, V7, P611, DOI 10.1016/S2215-0366(20)30203-0
   Schein J, 2021, CURR MED RES OPIN, V37, P2151, DOI 10.1080/03007995.2021.1978417
   Solomou I, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17144924
   Spitzer RL, 2006, ARCH INTERN MED, V166, P1092, DOI 10.1001/archinte.166.10.1092
   Sun LN, 2021, J AFFECT DISORDERS, V283, P123, DOI 10.1016/j.jad.2021.01.050
   Tang LR, 2022, BMC PSYCHIATRY, V22, DOI 10.1186/s12888-022-03790-w
   Taquet M, 2021, LANCET PSYCHIAT, V8, P416, DOI 10.1016/S2215-0366(21)00084-5
   Velavan TP, 2020, TROP MED INT HEALTH, V25, P278, DOI 10.1111/tmi.13383
   Xiong QT, 2021, CLIN MICROBIOL INFEC, V27, P89, DOI 10.1016/j.cmi.2020.09.023
NR 51
TC 1
Z9 1
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 20
PY 2022
VL 3
AR 927058
DI 10.3389/frvir.2022.927058
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WD2
UT WOS:001023275700001
OA gold
DA 2024-07-18
ER

PT J
AU Sepich, NC
   Jasper, A
   Fieffer, S
   Gilbert, SB
   Dorneich, MC
   Kelly, JW
AF Sepich, Nathan C.
   Jasper, Angelica
   Fieffer, Stephen
   Gilbert, Stephen B.
   Dorneich, Michael C.
   Kelly, Jonathan W.
TI The impact of task workload on cybersickness
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; cybersickness; task; workload; attention; presence;
   performance
ID VIRTUAL ENVIRONMENTS; SICKNESS; MOTION; DISTRACTION; PERFORMANCE;
   EXPERIENCE; IMMERSION; FREQUENCY; ATTENTION; EXPOSURE
AB This study explored the impact of task workload on virtual reality (VR) cybersickness. Cybersickness is a negative side effect of using VR to which many users are susceptible. Previous research on the impact on task workload on cybersickness has yielded no consistent relationships, but given that task workload requires attentional resources, it is worth further investigation of how a demand on attention might increase or decrease cybersickness. In this study, mental workload of participants (N = 151) was modified in three different task groups within the same virtual environment (VE). The Cybersickness Corn Maze VR testbed contained cybersickness-inducing stimuli and tasks with varying workload. The 0-Back group used a controller to select an object as a visual attention task. The 2-Back group performed the 2-Back memory detection task, using a controller to collect objects that matched the object presented two objects ago. The No-Task group passively moved through the environment and was not given a controller. Workload, cybersickness, dropout rate, presence, and task accuracy were compared across groups. Workload was found to be statistically significantly different in each group: highest in the 2-Back group, medium in the 0-Back group, and lowest in the No-Task group, validating the task design. Cybersickness in the 2-Back group was significantly higher than in the No-Task (140% higher) and 0-Back (54% higher) groups measured by the change in simulator sickness questionnaire (SSQ) total severity (Post SSQ - Pre SSQ). The rate of participants' dropout due to cybersickness was significantly higher in 2-back (33%) as compared with 0-Back (10%), but 0-Back and No-Task dropout rates were not significantly different. These results indicate that 1) task workload affects cybersickness and 2) its effect could be based on a threshold of workload. Presence increased with the addition of a task but plateaued between the 0-Back and 2-Back groups, suggesting that presence can be affected by task workload but only to a certain extent. Task accuracy was shown to negatively correlate with cybersickness within the task groups. A relationship between workload and cybersickness was found and warrants further research into these concepts. This work highlights the need for task workload and attention to be studied as components of the mechanisms underlying cybersickness.
C1 [Sepich, Nathan C.; Jasper, Angelica; Gilbert, Stephen B.; Dorneich, Michael C.; Kelly, Jonathan W.] Iowa State Univ, Virtual Real Applicat Ctr, Ames, IA 50011 USA.
   [Sepich, Nathan C.; Fieffer, Stephen; Gilbert, Stephen B.; Dorneich, Michael C.] Iowa State Univ, Ind & Mfg Syst Engn Dept, Ames, IA 50011 USA.
   [Kelly, Jonathan W.] Iowa State Univ, Psychol Dept, Ames, IA USA.
C3 Iowa State University; Iowa State University; Iowa State University
RP Gilbert, SB (corresponding author), Iowa State Univ, Virtual Real Applicat Ctr, Ames, IA 50011 USA.; Gilbert, SB (corresponding author), Iowa State Univ, Ind & Mfg Syst Engn Dept, Ames, IA 50011 USA.
EM gilbert@iastate.edu
RI Gilbert, Stephen/F-3138-2018; Kelly, Jonathan/A-4793-2013
OI Gilbert, Stephen/0000-0002-5332-029X; Kelly,
   Jonathan/0000-0002-4317-273X
FU Iowa State University Virtual Reality Applications Center
FX This research was supported by faculty authors and the Iowa State
   University Virtual Reality Applications Center.
CR [Anonymous], 2003, PRESENCE CONNECT
   [Anonymous], 2017, STAT TUTORIALS SOFTW
   Barrett J., 2004, Side effects of virtual environments: A review of the literature
   Beilock SL, 2002, J EXP PSYCHOL-APPL, V8, P6, DOI 10.1037/1076-898X.8.1.6
   Beilock SL, 2001, J EXP PSYCHOL GEN, V130, P701, DOI 10.1037/0096-3445.130.4.701
   Bos JE, 2015, J VESTIBUL RES-EQUIL, V25, P23, DOI 10.3233/VES-150541
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen Y.C., 2011, BIO Web of Conferences, V1, P00016, DOI DOI 10.1051/BIOCONF/20110100016
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cohen R.A., 2011, Encyclopedia of Clinical Neuropsychology, P2737, DOI DOI 10.1007/978-0-387-79948-31340
   Coleridge SamuelTaylor., 1952, Biographia Literaria
   Csikszentmihalyi M., 1993, NEBRASKA S MOTIVATIO, V40, P57
   Curtis M.K., 2015, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V59, P1839
   Davis Simon, 2014, P 2014 C INT ENT, P1
   Denisova A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P145, DOI 10.1145/2702123.2702256
   Dilanchian AT, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.736793
   Dinet J., 2018, P VIRT REAL INT C LA, P1
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Gilbert SB, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P161, DOI 10.1109/VRW52623.2021.00037
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   HART S G, 1988, P139
   Hartmann T., 2015, SPATIAL PRESENCE THE
   Hartmann T., 2021, PSYARXIV, DOI [10.31234/osf.io/a2ykd, DOI 10.31234/OSF.IO/A2YKD]
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI [10.3389/frvir.2020.00002, DOI 10.3389/FRVIR.2020.00002]
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Jasper A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582108
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   JungHa Park, 2020, The International Journal of Advanced Culture Technology, V8, P89
   Kahneman D., 2017, Thinking, fast and slow
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B., 2014, HDB VIRTUAL ENV, P551
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim YY, 2008, PRESENCE-TELEOP VIRT, V17, P1, DOI 10.1162/pres.17.1.1
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   Lampton DR., 1994, Presence: Teleoperators and Virtual Environments, V3, P145
   Melo M., 2021, 2021 International Conference on Graphics and Interaction (ICGI), P1, DOI [DOI 10.1109/ICGI54032.2021.9655281, 10.1109/ICGI54032.2021.9655281]
   Meusel C., 2014, Exploring mental effort and nausea via electrodermal activity within scenario-based tasks
   Milleville-Pennel I, 2015, ACCIDENT ANAL PREV, V74, P192, DOI 10.1016/j.aap.2014.10.021
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Monteiro D, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1830
   MORONEY WF, 1992, PROC NAECON IEEE NAT, P734, DOI 10.1109/NAECON.1992.220513
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   Norman G, 2013, ADV HEALTH SCI EDUC, V18, P163, DOI 10.1007/s10459-013-9451-y
   OHANLON JF, 1974, AEROSPACE MED, V45, P366
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309
   REDD WH, 1987, J CONSULT CLIN PSYCH, V55, P391, DOI 10.1037/0022-006X.55.3.391
   Roscoe A.H., 1990, SUBJECTIVE RATING SC
   SCHAPER E, 1978, BRIT J AESTHET, V18, P31, DOI 10.1093/bjaesthetics/18.1.31
   Servotte JC, 2020, CLIN SIMUL NURS, V38, P35, DOI 10.1016/j.ecns.2019.09.006
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   So R. H. Y., 1998, 1 WORLD C ERG GLOB Q
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P447, DOI 10.1162/105474698565848
   Tattersall AJ, 1996, ERGONOMICS, V39, P740, DOI 10.1080/00140139608964495
   TREISMAN AM, 1964, BRIT MED BULL, V20, P12, DOI 10.1093/oxfordjournals.bmb.a070274
   Turner P, 2016, AI SOC, V31, P147, DOI 10.1007/s00146-014-0579-y
   TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9
   Varmaghani S, 2022, VIRTUAL REAL-LONDON, V26, P659, DOI 10.1007/s10055-021-00535-0
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Wang JL, 2023, IEEE T GAMES, V15, P252, DOI 10.1109/TG.2022.3178539
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wei Y, 2018, ERGONOMICS, V61, P933, DOI 10.1080/00140139.2018.1427805
   Wickens C.D., 2021, Engineering psychology and human performance
   Wienrich C., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications, P1, DOI [DOI 10.1109/VS-GAMES.2018.8493408, DOI 10.1109/VS-GAMES.2018, 10.1109/VS-Games.2018.8493408]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhou C, 2019, IEEE INT CONF MOB, P72, DOI 10.1109/MASSW.2019.00021
NR 75
TC 14
Z9 15
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 19
PY 2022
VL 3
AR 943409
DI 10.3389/frvir.2022.943409
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VB6
UT WOS:001023247900001
OA gold
DA 2024-07-18
ER

PT J
AU Bartlett, J
   Fisher, E
   Liikkanen, S
   Turunen, J
   Skog, M
   Eccleston, C
AF Bartlett, J.
   Fisher, E.
   Liikkanen, S.
   Turunen, J.
   Skog, M.
   Eccleston, C.
TI The Design and Development of an Embodied Semi-Autonomous Mentoring
   Intelligence (SAMI) for Use in Virtual Reality Interventions,
   Operationalized for the Self-Management of Chronic Pain
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE pain; autonomous agent; mentor; rehabilitation; virtual reality
ID PATIENT WORKING ALLIANCE; UNCANNY VALLEY; COMMUNICATION; PERCEPTION;
   BEHAVIOR
AB Introduction: Avatars are becoming more common in virtual reality, used as a guide, teacher, companion, or mentor through immersive experiences. Special attention needs to be paid to their design to ensure credibility and working alliance, to allow for the optimal delivery of behavior change content.Methods: We present a new embodied Semi-Autonomous Mentoring Intelligence (SAMI) avatar used in an immersive virtual reality intervention for the self-management of chronic pain. We discuss the research findings that were taken into consideration and guided the design and development of SAMI, such methods to promote working alliance with non-human agents, optimal characteristics of non-human agents, and features of effective "automation".Conclusion: We provide a table of considerations and recommendations for researchers involved in designing future virtual reality characters. We provide suggestions on how future research could advance SAMI further for use in pain management and related interventions.
C1 [Bartlett, J.; Fisher, E.; Eccleston, C.] Univ Bath, Ctr Pain Res, Bath, England.
   [Liikkanen, S.; Skog, M.] Orion Corp, Res & Dev, Espoo, Finland.
   [Turunen, J.] Healthware Int Nord, Helsinki, Finland.
   [Eccleston, C.] Univ Ghent, Dept Clin Expt & Hlth Psychol, Ghent, Belgium.
C3 University of Bath; Orion Corporation; Ghent University
RP Eccleston, C (corresponding author), Univ Bath, Ctr Pain Res, Bath, England.; Eccleston, C (corresponding author), Univ Ghent, Dept Clin Expt & Hlth Psychol, Ghent, Belgium.
EM c.eccleston@bath.ac.uk
OI Fisher, Emma/0000-0001-8980-3181; Eccleston,
   Christopher/0000-0003-0698-1543
FU Orion Corporation; Business Finland; Finnish government
FX This project was funded by Orion Corporation and has also received
   support from Business Finland, the Finnish government organization for
   innovation funding and trade, travel, and investment promotion.
CR Abd-Alrazaq AA, 2020, J MED INTERNET RES, V22, DOI 10.2196/16021
   Alderson-Day B, 2018, LANCET PSYCHIAT, V5, P2, DOI 10.1016/S2215-0366(17)30471-6
   Bhati KS, 2014, PSYCHOL REP, V115, P565, DOI 10.2466/21.02.PR0.115c23z1
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bordin E. S., 1979, Psychotherapy: Theory, Research Practice, V16, P252, DOI [10.1037/h0085885, DOI 10.1037/H0085885, https://doi.org/10.1037/h0085885]
   Breivik H., 2018, European Pain Management.
   Busse JW, 2018, JAMA-J AM MED ASSOC, V320, P2448, DOI 10.1001/jama.2018.18472
   Carville S, 2021, BMJ-BRIT MED J, V373, DOI 10.1136/bmj.n895
   Chen S, 2022, J ORTHOP TRANSL, V32, P49, DOI 10.1016/j.jot.2021.07.005
   Costa S, 2018, INT J HUM ROBOT, V15, DOI 10.1142/S0219843618500068
   DUFFY SA, 1992, LANG SPEECH, V35, P351, DOI 10.1177/002383099203500401
   Eccleston C., 2018, USING ADV TECHNOLOGI, V3rd Edition, P289
   Eccleston C, 2022, PAIN, V163, P1700, DOI 10.1097/j.pain.0000000000002617
   Eccleston C, 2009, COCHRANE DB SYST REV, DOI [10.1002/14651858.CD007407.pub2, 10.1002/14651858.CD007407.pub3]
   Ewbank MP, 2020, JAMA PSYCHIAT, V77, P35, DOI 10.1001/jamapsychiatry.2019.2664
   Fayaz A, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2015-010364
   Fisher E, 2022, PAIN, V163, pE1, DOI 10.1097/j.pain.0000000000002297
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Freud Sigmund., 2003, The Uncanny
   Fuertes JN, 2017, PATIENT EDUC COUNS, V100, P610, DOI 10.1016/j.pec.2016.10.018
   Goldberg DS, 2011, BMC PUBLIC HEALTH, V11, DOI 10.1186/1471-2458-11-770
   Haight Joel M., 2007, International Journal of Risk Assessment & Management, V7, P708, DOI 10.1504/IJRAM.2007.014095
   Heim E, 2018, INTERNET INTERV, V11, P41, DOI 10.1016/j.invent.2018.01.005
   Hoffman HG, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89526-4
   Horvath AO, 2011, PSYCHOTHERAPY, V48, P9, DOI 10.1037/a0022186
   HORVATH AO, 1989, J COUNS PSYCHOL, V36, P223, DOI 10.1037/0022-0167.36.2.223
   Keefe FJ, 2012, PAIN, V153, P2163, DOI 10.1016/j.pain.2012.05.030
   Khirasaria Raj, 2020, Perspect Clin Res, V11, P54, DOI 10.4103/picr.PICR_89_19
   Kinney M, 2020, PHYSIOTHER THEOR PR, V36, P886, DOI 10.1080/09593985.2018.1516015
   Kretzschmar K, 2019, BIOMED INFORM INSIGH, V11, DOI 10.1177/1178222619829083
   Lakke S.E., 2016, Journal of Compassionate Health Care, V3, P1, DOI DOI 10.1186/S40639-016-0018-7
   Liddon L, 2018, BRIT J CLIN PSYCHOL, V57, P42, DOI 10.1111/bjc.12147
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Miragall M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01531
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Palanica Adam, 2020, Digit Biomark, V4, P21, DOI 10.1159/000506861
   Pikus C.F., 1996, J COLL STUD PSYCH, V10, P35, DOI [DOI 10.1300/J035V10N04_05, 10.1300/J035v10n04_05]
   Pinto RZ, 2012, J PHYSIOTHER, V58, P77, DOI 10.1016/S1836-9553(12)70087-5
   Rejula V., 2021, FRONT PUBLIC HEALTH, V9, P779328, DOI [10.3389/fpubh.2021.779328, DOI 10.3389/FPUBH.2021.779328]
   Retto J, 2017, ResearchGate
   Schwind V., 2018, Interactions, V25, P45, DOI [https://doi.org/10.1145/3236673, DOI 10.1145/3236673]
   Seidler ZE, 2022, COUNS PSYCHOL Q, V35, P173, DOI 10.1080/09515070.2021.1940866
   Takashima K., 2008, Proceedings of Graphics Interface 2008, P169, DOI DOI 10.1145/1375714.1375744
   Tickle-Degnen L., 2003, NONVERBAL BEHAV CLIN, P75
   Tinwell A, 2013, COMPUT HUM BEHAV, V29, P1617, DOI 10.1016/j.chb.2013.01.008
   Tinwell A, 2010, J GAMING VIRTUAL WOR, V2, P3, DOI 10.1386/jgvw.2.1.3_1
   Tinwell A, 2011, COMPUT HUM BEHAV, V27, P741, DOI 10.1016/j.chb.2010.10.018
   Trost Z, 2021, PAIN, V162, P325, DOI 10.1097/j.pain.0000000000002060
   Tryon GS, 2018, PSYCHOTHERAPY, V55, P372, DOI 10.1037/pst0000170
   Varrassi G, 2010, CURR MED RES OPIN, V26, P1231, DOI 10.1185/03007991003689175
   Wallace Richard S., 2009, Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer, P181, DOI [10.1007/978-1-4020-6710-5_13, DOI 10.1007/978-1-4020-6710-5_13]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Willis M, 2019, JMIR RES PROTOC, V8, DOI 10.2196/11232
NR 53
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 7
PY 2022
VL 3
AR 882980
DI 10.3389/frvir.2022.882980
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PQ0
UT WOS:001021733500001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Takahashi, N
   Amemiya, T
   Narumi, T
   Kuzuoka, H
   Hirose, M
   Aoyama, K
AF Takahashi, Nozomi
   Amemiya, Tomohiro
   Narumi, Takuji
   Kuzuoka, Hideaki
   Hirose, Michitaka
   Aoyama, Kazuma
TI Sensation of Anteroposterior and Lateral Body Tilt Induced by Electrical
   Stimulation of Ankle Tendons
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE new haptic and tactile interaction; tendon electrical stimulation;
   proprioceptive sensation; golgi tendon organ; illusory movement
ID VIBRATION; BALANCE
AB While virtual reality technology enables users to walk on surfaces of various shapes in virtual environments, these experiences are often on a flat floor, and any discordance between visual and somatosensory information hampers the immersive experience. To resolve this issue, we have focused on the ankle joint angle as an essential cue in detecting the surface shape of the ground. To modulate the sensation of the ankle joint angle, we propose novel percutaneous electrical stimulation methods that stimulate four targeted ankle tendons: the tibialis anterior muscle tendon, the Achilles tendon, the peroneus longus muscle tendon, and the flexor digitorum longus tendon. Since electrically stimulating the elbow tendon is known to evoke reflexive hand movement, electrically stimulating the ankle tendon is expected to evoke a body tilt due to illusory changes in the ankle joint angle. In this study, we designed electrode configurations to stimulate the above four ankle tendons using a finite element analysis and investigated the effect of electrically stimulating the ankle tendons on the subjective sensation of body tilt and actual body sway through psychophysical experiments. The results revealed that applying this stimulation with our novel electrode configurations can induce a subjective sensation of body tilt and actual body sway in a direction opposite to the stimulated part.
C1 [Takahashi, Nozomi; Amemiya, Tomohiro; Narumi, Takuji; Kuzuoka, Hideaki] Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, Tokyo, Japan.
   [Amemiya, Tomohiro; Kuzuoka, Hideaki; Aoyama, Kazuma] Univ Tokyo, Virtual Real Educ Res Ctr, Tokyo, Japan.
   [Hirose, Michitaka; Aoyama, Kazuma] Univ Tokyo, Res Ctr Adv Sci & Technol, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo; University of Tokyo
RP Takahashi, N (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, Tokyo, Japan.; Aoyama, K (corresponding author), Univ Tokyo, Virtual Real Educ Res Ctr, Tokyo, Japan.; Aoyama, K (corresponding author), Univ Tokyo, Res Ctr Adv Sci & Technol, Tokyo, Japan.
EM nozomi@cyber.t.u-tokyo.ac.jp; aoyama@vr.u-tokyo.ac.jp
RI Narumi, Takuji/K-3925-2014
OI Narumi, Takuji/0000-0002-9010-1491; Amemiya,
   Tomohiro/0000-0002-7079-9167; Kuzuoka, Hideaki/0000-0003-1252-7814
FU JST, PRESTO [JPMJPR19J1]; JSPS KAKENHI [JP21H04883]; Grants-in-Aid for
   Scientific Research [20K21801, 21H04883, 22H03628] Funding Source: KAKEN
FX Funding This study was supported by the JST, PRESTO (JPMJPR19J1), and
   JSPS KAKENHI (JP21H04883).
CR Aoyama K., 2017, ACM SIGGRAPH 2017 EM, DOI [10.1145/3084822.3084840, DOI 10.1145/3084822.3084840]
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bruder G., 2014, P 20 ACM S VIRT REAL, P177, DOI [DOI 10.1145/2671015.2671026, 10.1145/2671015.2671026, 10.1145/2671015.2671026=0pt]
   Flansbjer UB, 2012, PM&R, V4, P165, DOI 10.1016/j.pmrj.2011.11.004
   GOODWIN GM, 1972, SCIENCE, V175, P1382, DOI 10.1126/science.175.4028.1382
   Hagimori D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P952, DOI 10.1109/VR.2019.8797832
   Hothorn LA, 2016, COMMUN STAT-THEOR M, V45, P3332, DOI 10.1080/03610926.2014.902225
   Je H., 2021, P 2021 CHI C HUM FAC, P1
   Kajimoto H, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P555, DOI 10.1109/WHC.2013.6548468
   Laakso I, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/4/046009
   MOORE JC, 1984, AM J OCCUP THER, V38, P227, DOI 10.5014/ajot.38.4.227
   ROGERS JH, 1980, J LARYNGOL OTOL, V94, P1401, DOI 10.1017/S002221510009023X
   Saltzman C., 1997, FOOT ANKLE INT, V18, P310
   Sasagawa S, 2009, EXP BRAIN RES, V196, P537, DOI 10.1007/s00221-009-1876-4
   Schmidt D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2157, DOI 10.1145/2702123.2702253
   Seki H, 2011, JPN J PHYS FIT SPORT, V60, P229, DOI 10.7600/jspfsm.60.229
   Shigaki L, 2013, REV BRAS MED ESPORTE, V19, P104, DOI 10.1590/S1517-86922013000200006
   SOAMES RW, 1982, EUR J APPL PHYSIOL O, V49, P169, DOI 10.1007/BF02334065
   STEEL RGD, 1959, BIOMETRICS, V15, P560, DOI 10.2307/2527654
   Takahashi A, 2018, LECT NOTES ELECTR EN, V432, P233, DOI 10.1007/978-981-10-4157-0_40
   Takahashi N., 2021, INT C HUM COMP INT J, P357, DOI [10.1007/978-3-030-78321-1_27, DOI 10.1007/978-3-030-78321-1_27]
   Tamaki Emi, 2016, P ADJUNCT P 29 ANN A, P163
   Tanaka Satoshi, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P316, DOI 10.1007/978-3-030-58147-3_35
NR 23
TC 3
Z9 3
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 5
PY 2022
VL 3
AR 800884
DI 10.3389/frvir.2022.800884
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AT7
UT WOS:001019298500001
OA gold
DA 2024-07-18
ER

PT J
AU Stokes, JD
   Rizzo, A
   Geng, JJ
   Schweitzer, JB
AF Stokes, Jared D.
   Rizzo, Albert
   Geng, Joy J.
   Schweitzer, Julie B.
TI Measuring Attentional Distraction in Children With ADHD Using Virtual
   Reality Technology With Eye-Tracking
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE ADHD (attention deficit and hyperactivity disorder); virtual reality;
   eye tracking; attention; distraction
ID DEFICIT/HYPERACTIVITY DISORDER; EXECUTIVE FUNCTION; ADOLESCENTS;
   PERFORMANCE; VALIDITY; IMPACT; CLASSROOM; DEFICITS; OUTCOMES; TASK
AB Objective: Distractions inordinately impair attention in children with Attention-Deficit Hyperactivity Disorder (ADHD) but examining this behavior under real-life conditions poses a challenge for researchers and clinicians. Virtual reality (VR) technologies may mitigate the limitations of traditional laboratory methods by providing a more ecologically relevant experience. The use of eye-tracking measures to assess attentional functioning in a VR context in ADHD is novel. In this proof of principle project, we evaluate the temporal dynamics of distraction via eye-tracking measures in a VR classroom setting with 20 children diagnosed with ADHD between 8 and 12 years of age.
   Method: We recorded continuous eye movements while participants performed math, Stroop, and continuous performance test (CPT) tasks with a series of "real-world" classroom distractors presented. We analyzed the impact of the distractors on rates of on-task performance and on-task, eye-gaze (i.e., looking at a classroom whiteboard) versus off-task eye-gaze (i.e., looking away from the whiteboard).
   Results: We found that while children did not always look at distractors themselves for long periods of time, the presence of a distractor disrupted on-task gaze at task-relevant whiteboard stimuli and lowered rates of task performance. This suggests that children with attention deficits may have a hard time returning to tasks once those tasks are interrupted, even if the distractor itself does not hold attention. Eye-tracking measures within the VR context can reveal rich information about attentional disruption.
   Conclusions: Leveraging virtual reality technology in combination with eye-tracking measures is well-suited to advance the understanding of mechanisms underlying attentional impairment in naturalistic settings. Assessment within these immersive and well-controlled simulated environments provides new options for increasing our understanding of distractibility and its potential impact on the development of interventions for children with ADHD.
C1 [Stokes, Jared D.; Schweitzer, Julie B.] Univ Calif Davis, MIND Inst, Sacramento, CA 95819 USA.
   [Stokes, Jared D.; Schweitzer, Julie B.] Univ Calif Davis, Dept Psychiat & Behav Sci, Sacramento, CA 95819 USA.
   [Stokes, Jared D.; Geng, Joy J.] Univ Calif Davis, Ctr Mind & Brain, Davis, CA USA.
   [Rizzo, Albert] Univ Southern Calif, Inst Creat Studies, Los Angeles, CA USA.
   [Geng, Joy J.] Univ Calif Davis, Dept Psychol, Davis, CA USA.
C3 University of California System; University of California Davis;
   University of California System; University of California Davis;
   University of California System; University of California Davis;
   University of Southern California; University of California System;
   University of California Davis
RP Schweitzer, JB (corresponding author), Univ Calif Davis, MIND Inst, Sacramento, CA 95819 USA.; Schweitzer, JB (corresponding author), Univ Calif Davis, Dept Psychiat & Behav Sci, Sacramento, CA 95819 USA.
EM jschweitzer@ucdavis.edu
FU National Institute of Mental Health [R33MH110043] Funding Source: NIH
   RePORTER
CR Adams R, 2009, CHILD NEUROPSYCHOL, V15, P120, DOI 10.1080/09297040802169077
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Barkley R.A., 2019, ADHD REPORT, V27, P1, DOI DOI 10.1521/ADHD.2019.27.2.1
   BARKLEY RA, 1992, J ABNORM CHILD PSYCH, V20, P163, DOI 10.1007/BF00916547
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Berger I, 2014, J NEUROSCI METH, V222, P62, DOI 10.1016/j.jneumeth.2013.10.012
   Biederman J, 2004, J CONSULT CLIN PSYCH, V72, P757, DOI 10.1037/0022-006X.72.5.757
   Bioulac S, 2020, J ATTEN DISORD, V24, P326, DOI 10.1177/1087054718759751
   Bioulac S, 2012, EUR J PAEDIATR NEURO, V16, P514, DOI 10.1016/j.ejpn.2012.01.006
   Born S, 2011, EXP BRAIN RES, V208, P621, DOI 10.1007/s00221-010-2510-1
   Buzy WM, 2009, CHILD NEUROPSYCHOL, V15, P441, DOI 10.1080/09297040802646991
   Chang Z, 2014, JAMA PSYCHIAT, V71, P319, DOI 10.1001/jamapsychiatry.2013.4174
   Conners C.K., 2008, CONNERS, V3rd, DOI DOI 10.1007/978-0-387-79948-3
   Cortese S, 2018, LANCET PSYCHIAT, V5, P727, DOI 10.1016/S2215-0366(18)30269-4
   de Haas B, 2019, P NATL ACAD SCI USA, V116, P11687, DOI 10.1073/pnas.1820553116
   Díaz-Orueta U, 2014, CHILD NEUROPSYCHOL, V20, P328, DOI 10.1080/09297049.2013.792332
   Doshi JA, 2012, J AM ACAD CHILD PSY, V51, P990, DOI 10.1016/j.jaac.2012.07.008
   DuPaul G. J., 2016, ADHD RATING SCALE 5
   Eaves LC, 2006, J DEV BEHAV PEDIATR, V27, pS95, DOI 10.1097/00004703-200604002-00007
   Efron D, 2014, PEDIATRICS, V134, pE992, DOI 10.1542/peds.2014-1027
   Faraone Stephen V, 2007, J Atten Disord, V11, P74, DOI 10.1177/1087054706292196
   Forster S, 2008, J EXP PSYCHOL-APPL, V14, P73, DOI 10.1037/1076-898X.14.1.73
   Forster S, 2016, PSYCHOL SCI, V27, P203, DOI 10.1177/0956797615617761
   Fried M, 2014, VISION RES, V101, P62, DOI 10.1016/j.visres.2014.05.004
   Friedman-Hill SR, 2010, COGNITION, V115, P93, DOI 10.1016/j.cognition.2009.11.013
   Fukuda K, 2011, PSYCHOL SCI, V22, P361, DOI 10.1177/0956797611398493
   Geng JJ, 2010, J VISION, V10, DOI 10.1167/10.6.5
   Huang-Pollock CL, 2012, J ABNORM PSYCHOL, V121, P360, DOI 10.1037/a0027205
   Insel TR, 2015, SCIENCE, V348, P499, DOI 10.1126/science.aab2358
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Lalonde G, 2013, J NEUROSCI METH, V219, P76, DOI 10.1016/j.jneumeth.2013.07.005
   Lev A, 2022, J ATTEN DISORD, V26, P245, DOI 10.1177/1087054720972786
   Levantini V, 2020, PSYCHIAT RES, V290, DOI 10.1016/j.psychres.2020.113135
   Loe IM, 2007, J PEDIATR PSYCHOL, V32, P643, DOI 10.1093/jpepsy/jsl054
   Mangalmurti A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56936-4
   March J.S., 1997, MULTIDIMENSIONAL ANX
   Moore T, 2001, P NATL ACAD SCI USA, V98, P1273, DOI 10.1073/pnas.021549498
   Parsons TD, 2007, CHILD NEUROPSYCHOL, V13, P363, DOI 10.1080/13825580600943473
   Parsons TD, 2019, NEUROPSYCHOL REV, V29, P338, DOI 10.1007/s11065-019-09407-6
   Paul HA, 2016, CHILD FAM BEHAV THER, V38, P331, DOI 10.1080/07317107.2016.1238694
   Pliszka S, 2007, J AM ACAD CHILD PSY, V46, P894, DOI 10.1097/chi.0b013e318054e724
   Pollak Y, 2009, J DEV BEHAV PEDIATR, V30, P2, DOI 10.1097/DBP.0b013e3181969b22
   Posner K, 2011, AM J PSYCHIAT, V168, P1266, DOI 10.1176/appi.ajp.2011.10111704
   Rizzo AA, 2006, CNS SPECTRUMS, V11, P35, DOI 10.1017/S1092852900024196
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Romero-Ayuso D, 2021, CHILDREN-BASEL, V8, DOI 10.3390/children8020070
   Rosenberg-Lee M, 2011, NEUROIMAGE, V57, P796, DOI 10.1016/j.neuroimage.2011.05.013
   Scheres A, 2004, ARCH CLIN NEUROPSYCH, V19, P569, DOI 10.1016/j.acn.2003.08.005
   Sheehan DV, 2010, J CLIN PSYCHIAT, V71, P313, DOI 10.4088/JCP.09m05305whi
   Slobodin O, 2018, J ATTEN DISORD, V22, P1333, DOI 10.1177/1087054715575066
   Sonuga-Barke E, 2014, CHILD ADOL PSYCH CL, V23, P807, DOI 10.1016/j.chc.2014.05.009
   Vakil E, 2019, J ATTEN DISORD, V23, P1160, DOI 10.1177/1087054716642904
   Vallat R, 2018, J. Open Source Softw, V3, P1026, DOI [10.21105/joss.01026, DOI 10.21105/JOSS.01026]
   Visser SN, 2013, PREV CHRONIC DIS, V10, DOI 10.5888/pcd9.120073
   Wechsler D., 2011, Wechsler Abbreviated Scale of Intelligence Second Edition (WASI-II)
   Wechsler D., 2009, WECHSLER INDIVIDUAL
   Wigal Sharon B, 2006, J Atten Disord, V10, P92, DOI 10.1177/1087054705286049
   Willcutt EG, 2012, J ABNORM PSYCHOL, V121, P991, DOI 10.1037/a0027347
NR 60
TC 12
Z9 12
U1 6
U2 22
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 8
PY 2022
VL 3
AR 855895
DI 10.3389/frvir.2022.855895
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8UE0
UT WOS:001019124700001
PM 35601272
OA Green Accepted, gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Woods, AT
   Whittaker, L
   Verhulst, I
   Bennett, J
   Dalton, P
AF Woods, Andy T.
   Whittaker, Laryssa
   Verhulst, Isabelle
   Bennett, James
   Dalton, Polly
TI The Impact of an Audience on the Appeal of Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; anxiety; audience; Willlingness to try; extroversion;
   peers
ID SOCIAL FACILITATION; STAGE FRIGHT; GROUP-SIZE; NUMBER
AB Virtual reality in a public place is enticing for some yet daunting for others. Social Impact theory proposes that performing in front of larger (vs. smaller) audiences is typically seen as more anxiety provoking and less desirable. Having peers perform with you can offset this, however. Our goal was to test whether Social Impact theory extends to the context of trying virtual reality in a busy public setting, and whether any such effects are influenced by extroversion and trait anxiety. In Experiment 1, we ran an online study with 100 participants and found that images of people trying virtual reality in front of others were indeed rated as more anxiety provoking than images with no audiences. Images with (vs. without) audiences were also rated as scenarios in which people would be less willing to try virtual reality. There was no impact of extroversion levels on people's reported Willingness to Try; however extroverted individuals were less affected by audience size compared to introverts in terms of how anxiety-provoking they considered the scenario. Experiment 1 also found that the presence of a monitor showing one's virtual reality "performance" made Extroverts keener to try the experience, yet Introverts less keen. Experiment 2 tested whether the main findings of the first study extended to a real-world scenario. 69 participants observed 0-3 individuals trying a virtual-reality experience in the foyer of a busy library and were then questioned on expected anxiety levels and Willingness to Try. Whilst anxiety levels were again influenced by the audience size (number of people in the foyer at the start of each test), there was no impact of audience size on Willingness to Try virtual reality. Note that relative inattention of the audience on those trying VR in Experiment 2 (compared to Experiment 1), as well as a small sample size, may have made it hard to detect effects here. Extroverts were again less anxious about trying VR in-front of others compared to introverts. These findings offer some ways to make public space virtual reality experiences more accessible, whilst suggesting future steps to properly assess some exploratory findings presented here.
C1 [Woods, Andy T.; Whittaker, Laryssa; Verhulst, Isabelle; Bennett, James; Dalton, Polly] Univ London, StoryFutures, Royal Holloway, London, England.
   [Woods, Andy T.; Verhulst, Isabelle; Dalton, Polly] Univ London, Dept Psychol, Royal Holloway, London, England.
   [Whittaker, Laryssa; Bennett, James] Univ London, Dept Media Arts, Royal Holloway, London, England.
C3 University of London; Royal Holloway University London; University of
   London; Royal Holloway University London; University of London; Royal
   Holloway University London
RP Woods, AT (corresponding author), Univ London, StoryFutures, Royal Holloway, London, England.; Woods, AT (corresponding author), Univ London, Dept Psychol, Royal Holloway, London, England.
EM Andy.Woods@rhul.ac.uk
RI Whittaker, Laryssa/JDW-9824-2023
OI Verhulst, Isabelle/0000-0003-4603-0435
CR Allen C., 2020, CULTURAL IND CAN INC
   [Anonymous], 1990, Handbook of personality: Theory and research
   BEATTY MJ, 1983, PERCEPT MOTOR SKILL, V56, P792, DOI 10.2466/pms.1983.56.3.792
   Bennett J., 2021, STORY IMMERSIVE USER
   BOND CF, 1983, PSYCHOL BULL, V94, P265, DOI 10.1037/0033-2909.94.2.265
   Bond R, 2005, GROUP PROCESS INTERG, V8, P331, DOI 10.1177/1368430205056464
   Brase GL, 2004, J APPL SOC PSYCHOL, V34, P2469, DOI 10.1111/j.1559-1816.2004.tb01987.x
   ComRes, 2017, WIGG VIRT REAL ETH P
   Crowne D., 1964, The approval motive: Studies in evaluative dependence
   Dashiell JF, 1930, J ABNORM SOC PSYCH, V25, P190, DOI 10.1037/h0075144
   DIENER E, 1980, J PERS SOC PSYCHOL, V39, P449
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fiennes T., 2017, PUTTING AUDIENCES HE
   Fink C., 2018, ARE PEOPLE MAKING MO
   Fischer P, 2011, PSYCHOL BULL, V137, P517, DOI 10.1037/a0023304
   Geronikolakis E., 2018, USING VR AR TECHNOLO
   Gibson S, 2019, BRIT J SOC PSYCHOL, V58, P241, DOI 10.1111/bjso.12272
   Hayes A. F., 2013, Introduction to mediation, moderation, and conditional process analysis: a regression -based approach
   JACKSON JM, 1981, J PERS SOC PSYCHOL, V40, P73, DOI 10.1037/0022-3514.40.1.73
   Keltner D, 1997, PSYCHOL BULL, V122, P250, DOI 10.1037/0033-2909.122.3.250
   LATANE B, 1979, J PERS SOC PSYCHOL, V37, P822, DOI 10.1037//0022-3514.37.6.822
   LATANE B, 1981, AM PSYCHOL, V36, P343, DOI 10.1037/0003-066X.36.4.343
   Lightstone K., 2011, INT J BUSINESS SOCIA, V15, P15
   Lovibond SH., 1995, Manual for the depression anxiety and stress scales (DASS21), V2nd ed, P1
   Mai C., 2018, P 7 ACM INT S PERV D, P1
   McRoberts J, 2018, STUD DOC FILM, V12, P101, DOI 10.1080/17503280.2017.1344924
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Mirams L, 2013, CONSCIOUS COGN, V22, P348, DOI 10.1016/j.concog.2012.07.009
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Rowland DL, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01615
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Steinmetz J, 2017, SOC COGNITION, V35, P585, DOI 10.1521/soco.2017.35.5.585
   STEPTOE A, 1995, BRIT J PSYCHOL, V86, P27, DOI 10.1111/j.2044-8295.1995.tb02544.x
   TANFORD S, 1984, PSYCHOL BULL, V95, P189, DOI 10.1037/0033-2909.95.2.189
   Van Doorn G, 2017, FOOD QUAL PREFER, V56, P201, DOI 10.1016/j.foodqual.2016.10.013
   Verhulst I, 2021, COMPUT HUM BEHAV, V125, DOI 10.1016/j.chb.2021.106951
   Wilcox R, 2012, INTRODUCTION TO ROBUST ESTIMATION AND HYPOTHESIS TESTING, 3RD EDITION, P1, DOI 10.1016/B978-0-12-386983-8.00001-9
   Wilcox RandR., 2020, MODERN STAT SOCIAL B
   Woods AT, 2015, PEERJ, V3, DOI 10.7717/peerj.1058
   ZAJONC RB, 1965, SCIENCE, V149, P269, DOI 10.1126/science.149.3681.269
NR 41
TC 1
Z9 1
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 8
PY 2022
VL 2
AR 807910
DI 10.3389/frvir.2021.807910
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AY6
UT WOS:001019303500001
OA gold
DA 2024-07-18
ER

PT J
AU Björling, EA
   Kim, A
   Oleson, K
   Alves-Oliveira, P
AF Bjorling, Elin A.
   Kim, Ada
   Oleson, Katelynn
   Alves-Oliveira, Patricia
TI <i>I Am the Robot</i>: Teen Collaboration in an Asymmetric, Virtual
   Reality Game
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; participatory design; adolescents; asymmetric VR;
   collaboration
ID ROLE-PLAY; ADOLESCENTS; ATTITUDE; BRAIN
AB Virtual reality (VR) offers potential as a collaborative tool for both technology design and human-robot interaction. We utilized a participatory, human-centered design (HCD) methodology to develop a collaborative, asymmetric VR game to explore teens' perceptions of, and interactions with, social robots. Our paper illustrates three stages of our design process; ideation, prototyping, and usability testing with users. Through these stages we identified important design requirements for our mid-fidelity environment. We then describe findings from our pilot test of the mid-fidelity VR game with teens. Due to the unique asymmetric virtual reality design, we observed successful collaborations, and interesting collaboration styles across teens. This study highlights the potential for asymmetric VR as a collaborative design tool as well as an appropriate medium for successful teen-to-teen collaboration.
C1 [Bjorling, Elin A.; Oleson, Katelynn] Univ Washington, Human Ctr Design & Engn, Seattle, WA 98195 USA.
   [Kim, Ada] BankSalad, Informat & Technol Serv, Seoul, South Korea.
   [Alves-Oliveira, Patricia] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA USA.
C3 University of Washington; University of Washington Seattle; University
   of Washington; University of Washington Seattle
RP Björling, EA; Oleson, K (corresponding author), Univ Washington, Human Ctr Design & Engn, Seattle, WA 98195 USA.
EM bjorling@uw.edu; kjoleson@uw.edu
RI Alves-Oliveira, Patrícia/H-4655-2018
OI Alves-Oliveira, Patrícia/0000-0002-0133-2432
CR Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   Arrighi P.-A., 2016, J INTELL MANUFACTURI, P1, DOI [DOI 10.1007/S10845-016-1276-0, 10.1007/s10845-016-1276-0]
   Ashktorab Z, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3895, DOI 10.1145/2858036.2858548
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Bailey JO, 2016, PRESENCE-TELEOP VIRT, V25, P222, DOI 10.1162/PRES_a_00263
   Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7
   Barsalou LW, 2003, PSYCHOL LEARN MOTIV, V43, P43, DOI 10.1016/S0079-7421(03)01011-9
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Björling E, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010008
   Björling EA, 2018, ACMIEEE INT CONF HUM, P69, DOI 10.1145/3173386.3177068
   Blakemore SJ, 2012, NEUROIMAGE, V61, P397, DOI 10.1016/j.neuroimage.2011.11.080
   Blakemore SJ, 2006, J CHILD PSYCHOL PSYC, V47, P296, DOI 10.1111/j.1469-7610.2006.01611.x
   Blascovich J., 2005, Immersive Virtual Environments and Education Simulations"
   Bonsignore E., 2014, CHI 2014 WORKSH UND
   Bowen Simon, 2013, Int J Child Comput Interact, V1, P71
   Clergeaud D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139165
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Depping AE, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P449, DOI 10.1145/3116595.3116639
   Fitton D., 2014, Proceedings of the 28th International BCS Human Computer Interaction Conference on HCI 2014-Sand, Sea and Sky-Holiday HCI, P201, DOI DOI 10.14236/EWIC/HCI2014.23
   Fitton D, 2016, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-3-319-33450-9_1
   Games S. C., 2015, KEEP TALKING NOBODY
   Greenwald S. W., 2017, MULT US FRAM COLL CO
   Guest G., 2011, sage publications
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Harris J, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION EXTENDED ABSTRACTS (CHI PLAY 2018), P193, DOI 10.1145/3270316.3273039
   Hrpka A., 2016, THESIS
   Imran N, 2020, PAK J MED SCI, V36, pS67, DOI 10.12669/pjms.36.COVID19-S4.2759
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI 10.1145/2792790
   Kensing F., 1998, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V7, P167, DOI 10.1023/A:1008689307411
   Kim AS, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P470, DOI 10.1145/3311927.3325314
   Lacoche J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139142
   Little Linda, 2016, PERSPECTIVES HCI RES
   Lo JC, 2017, THEOR RES SOC EDUC, V45, P189, DOI 10.1080/00933104.2016.1220877
   MEHRABIAN A, 1968, J PERS SOC PSYCHOL, V10, P26, DOI 10.1037/h0026384
   Parsons Sarah, 2015, International Journal of Child-Computer Interaction, V6, P28, DOI 10.1016/j.ijcci.2015.12.002
   Ratto AB, 2011, J AUTISM DEV DISORD, V41, P1277, DOI 10.1007/s10803-010-1147-z
   Read J.C., 2013, CHI'13 Extended Abstracts on Human Factors in Computing Systems, P3243, DOI DOI 10.1145/2468356.2479657
   Rose EJ, 2017, SIGDOC'17: PROCEEDINGS OF THE 35TH ACM INTERNATIONAL CONFERENCE ON THE DESIGN OF COMMUNICATION, DOI 10.1145/3121113.3121212
   Rose Emma J., 2018, P 36 ACM INT C DES C, P1
   Safaric R, 2003, P IEEE, V91, P422, DOI 10.1109/JPROC.2003.809205
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Sustar H., 2013, USING POPULAR CULTUR
   Thomas NL, 2015, J KRISHNA INST MED S, V4, P114
NR 47
TC 1
Z9 1
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 13
PY 2022
VL 2
AR 746521
DI 10.3389/frvir.2021.746521
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9BE6
UT WOS:001019309500001
OA gold
DA 2024-07-18
ER

PT J
AU Orlosky, J
   Sra, M
   Bektas, K
   Peng, HS
   Kim, J
   Kos'myna, N
   Höllerer, T
   Steed, A
   Kiyokawa, K
   Aksit, K
AF Orlosky, Jason
   Sra, Misha
   Bektas, Kenan
   Peng, Huaishu
   Kim, Jeeeun
   Kos'myna, Nataliya
   Hollerer, Tobias
   Steed, Anthony
   Kiyokawa, Kiyoshi
   Aksit, Kaan
TI Telelife: The Future of Remote Living
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; augmented reality; telelife; telepresence; human
   computer interaction
ID AUGMENTED REALITY; DISPLAY; SYSTEM; TECHNOLOGIES; CHALLENGES; GLASSES
AB In recent years, everyday activities such as work and socialization have steadily shifted to more remote and virtual settings. With the COVID-19 pandemic, the switch from physical to virtual has been accelerated, which has substantially affected almost all aspects of our lives, including business, education, commerce, healthcare, and personal life. This rapid and large-scale switch from in-person to remote interactions has exacerbated the fact that our current technologies lack functionality and are limited in their ability to recreate interpersonal interactions. To help address these limitations in the future, we introduce "Telelife," a vision for the near and far future that depicts the potential means to improve remote living and better align it with how we interact, live and work in the physical world. Telelife encompasses novel synergies of technologies and concepts such as digital twins, virtual/physical rapid prototyping, and attention and context-aware user interfaces with innovative hardware that can support ultrarealistic graphics and haptic feedback, user state detection, and more. These ideas will guide the transformation of our daily lives and routines soon, targeting the year 2035. In addition, we identify opportunities across high-impact applications in domains related to this vision of Telelife. Along with a recent survey of relevant fields such as human-computer interaction, pervasive computing, and virtual reality, we provide a meta-synthesis in this paper that will guide future research on remote living.
C1 [Orlosky, Jason] Osaka Univ, Cybermedia Ctr, Osaka, Japan.
   [Orlosky, Jason] Augusta Univ, Sch Comp & Cyber Sci, Augusta, GA 30912 USA.
   [Sra, Misha; Hollerer, Tobias] Univ Calif Santa Barbara, Comp Sci Dept, Santa Barbara, CA USA.
   [Bektas, Kenan] Univ St Gallen, Inst Comp Sci, St Gallen, Switzerland.
   [Peng, Huaishu] Univ Maryland, Comp Sci Dept, College Pk, MD USA.
   [Kim, Jeeeun] Texas A&M Univ, Comp Sci Dept, College Stn, TX USA.
   [Kos'myna, Nataliya] MIT, Comp Sci Dept, Cambridge, MA USA.
   [Steed, Anthony; Aksit, Kaan] UCL, Comp Sci Dept, London, England.
   [Kiyokawa, Kiyoshi] Nara Inst Sci & Technol, Div Informat Sci, Nara, Japan.
C3 Osaka University; University System of Georgia; Augusta University;
   University of California System; University of California Santa Barbara;
   University of St Gallen; University System of Maryland; University of
   Maryland College Park; Texas A&M University System; Texas A&M University
   College Station; Massachusetts Institute of Technology (MIT); University
   of London; University College London; Nara Institute of Science &
   Technology
RP Orlosky, J (corresponding author), Osaka Univ, Cybermedia Ctr, Osaka, Japan.; Orlosky, J (corresponding author), Augusta Univ, Sch Comp & Cyber Sci, Augusta, GA 30912 USA.
EM jorlosky@augusta.edu
RI Bektas, Kenan/AEO-2264-2022
OI Bektas, Kenan/0000-0003-2937-0542; Steed, Anthony/0000-0001-9034-3020;
   AKSIT, KAAN/0000-0002-5934-5500; Orlosky, Jason/0000-0002-0538-6630
CR Abowd GD, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P31
   Afergan D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3797, DOI 10.1145/2556288.2557230
   Aksit K, 2020, OPT EXPRESS, V28, P2107, DOI 10.1364/OE.380858
   Amores J, 2018, INT CONF WEARAB IMPL, P98, DOI 10.1109/BSN.2018.8329668
   Angelopoulos AN, 2022, Arxiv, DOI arXiv:2004.03577
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bailenson J, 2018, JAMA PEDIATR, V172, P905, DOI 10.1001/jamapediatrics.2018.1909
   Bektas K., 2019, P 11 ACM S EYE TRACK, P1, DOI 10.1145/3314111.3321488
   Bektas K., 2015, TESTBED COMBINING VI
   Bektas K., 2020, ACM S EYE TRACKING R, P1
   Bhattacharya B, 2019, COMPUT IND, V105, P61, DOI 10.1016/j.compind.2018.04.021
   Billinghurst M., 2002, NEW HORIZONS LEARNIN, V12, P1, DOI DOI 10.1016/J.SBSPRO.2012.06.654
   Boucsein W, 2007, LECT NOTES ARTIF INT, V4562, P639
   Brush AJB, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2115
   Bulling A, 2016, COMPUTER, V49, P94, DOI 10.1109/MC.2016.32
   Byrne EA, 1996, BIOL PSYCHOL, V42, P249, DOI 10.1016/0301-0511(95)05161-9
   Chakravarthula P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356539
   Chakravarthula P, 2018, IEEE T VIS COMPUT GR, V24, P2906, DOI 10.1109/TVCG.2018.2868532
   Chen J, 2019, OPT EXPRESS, V27, P38204, DOI 10.1364/OE.381200
   Chernikova O, 2020, REV EDUC RES, V90, P499, DOI 10.3102/0034654320933544
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   Choi S, 2020, ARXIV
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Dahmen Jessamyn, 2017, J Reliab Intell Environ, V3, P83, DOI 10.1007/s40860-017-0035-0
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   De Guzman JA, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3359626
   Dey A. K., 2000, CHI 2000 WORKSH WHAT
   Dogan Mustafa Doga, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P24, DOI 10.1145/3472749.3474733
   Dogan MD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376202
   Dourish P., 1996, Computer Supported Cooperative Work (CSCW), V5, P33, DOI 10.1007/BF00141935
   Duchowski A., 2019, IEEE T VISUALIZATION
   Dun X, 2020, OPTICA, V7, P913, DOI 10.1364/OPTICA.394413
   Fares R., 2013, CAN WE BEAT MOUSE MA, P1387
   Fu RR, 2016, EXPERT SYST APPL, V63, P397, DOI 10.1016/j.eswa.2016.06.042
   Fuchsberger V., 2019, INTERACTIONS, V26, P26, DOI [https://doi.org/10.1145/3328481, DOI 10.1145/3328481]
   Fuller A, 2020, IEEE ACCESS, V8, P108952, DOI 10.1109/ACCESS.2020.2998358
   García K, 2018, INFORM SYST FRONT, V20, P1075, DOI 10.1007/s10796-016-9708-0
   Gardony AL, 2020, PROC SPIE, V11310, DOI 10.1117/12.2542699
   Gebhardt C, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P197, DOI 10.1145/3332165.3347933
   Gee J. P., 2003, COMPUTERS ENTERTAINM, V1, P20, DOI [https://doi.org/10.1145/950566.950595, DOI 10.1145/950566.950595]
   Glaessgen E.H., 2012, 53 AIAA ASME ASCE AH, DOI DOI 10.2514/6.2012-1818
   Grasset Raphael, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P231, DOI 10.1109/ISMAR.2006.297819
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Happa Jassim., 2019, Frontiers in ICT, V6, P5, DOI DOI 10.3389/FICT.2019.00005
   Hartmann D, 2020, Arxiv, DOI arXiv:2001.09747
   Hassib M, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P305, DOI 10.1145/3152832.3152865
   Hassib M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5114, DOI 10.1145/3025453.3025669
   Heimo OI, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON ETHICS IN SCIENCE, TECHNOLOGY AND ENGINEERING
   Held R. M., 1992, Presence: Teleoperators and Virtual Environments, V1, P109, DOI [https://doi.org/10.1162/pres.1992.1.1.109, 10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Hernandez J, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P307, DOI 10.1145/2632048.2636065
   Herz M, 2019, TECHNOL FORECAST SOC, V138, P228, DOI 10.1016/j.techfore.2018.09.008
   Howcroft J, 2012, ARCH PHYS MED REHAB, V93, P1448, DOI 10.1016/j.apmr.2012.02.033
   Hutt S, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P94, DOI 10.1145/3079628.3079669
   Huws U., 1990, Telework: Towards the elusive office
   Itoh Y, 2021, IEEE T VIS COMPUT GR, V27, P2659, DOI 10.1109/TVCG.2021.3067764
   Jain Dhruv., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P1563, DOI [10.1145/2851581.2892503, DOI 10.1145/2851581.2892503]
   Kaviyaraj R., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P47, DOI 10.1109/ICAIS50930.2021.9395838
   Kelly BE, 2019, SCIENCE, V363, P1075, DOI 10.1126/science.aau7114
   Kim J, 2018, ROU FOC BUS MANAG, P1, DOI [10.4324/9781351113717, 10.1109/NVMSA.2018.00008]
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Kiyokawa K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P133, DOI 10.1109/ISMAR.2003.1240696
   Knierim P, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3340142
   Kosmyna N, 2019, INT CONF WEARAB IMPL, DOI 10.1109/bsn.2019.8771080
   Kosmyna N, 2019, AUTOMOTIVEUI'19: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P355, DOI 10.1145/3342197.3344516
   Kosmyna N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235200
   Kosmyna N, 2015, LECT NOTES COMPUT SC, V9296, P506, DOI 10.1007/978-3-319-22701-6_37
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   KRANZBERG M, 1986, TECHNOL CULT, V27, P544, DOI 10.2307/3105385
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kuo G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392414
   Kwak H, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3739, DOI 10.1145/2702123.2702529
   Langlotz T., 2018, P 2018 CHI C HUM FAC, P112
   Leroy S, 2009, ORGAN BEHAV HUM DEC, V109, P168, DOI 10.1016/j.obhdp.2009.04.002
   Li R., 2020, ARXIV
   Li TX, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS'17), DOI 10.1145/3131672.3131682
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Liu C, 2020, COMPUT GRAPH-UK, V89, P1, DOI 10.1016/j.cag.2020.04.005
   Liu Z, 2018, AIP CONF PROC, V1949, DOI 10.1063/1.5031520
   Lu C, 2020, INT SYM MIX AUGMENT, P320, DOI 10.1109/ISMAR50242.2020.00058
   Mack Kelly., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1
   Mahar K., 2018, P 2018 CHI C HUM FAC, P1586
   Mahar K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174160
   Marwecki S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P777, DOI 10.1145/3332165.3347919
   Matsukura H, 2013, IEEE T VIS COMPUT GR, V19, P606, DOI 10.1109/TVCG.2013.40
   Mayer S, 2018, INTERNET TECHNOL LET, V1, DOI 10.1002/itl2.50
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Miller MR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74486-y
   Miyatake H, 2020, CLIN CASE REP, V8, P950, DOI [10.1002/ccr3.2633, 10.1145/3334480.3382984]
   MONTGOMERY LD, 1995, BIOL PSYCHOL, V40, P143, DOI 10.1016/0301-0511(95)05117-1
   Mott ME, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI [10.1145/3396956.3396969, 10.1145/3373625.3416998]
   Mueller FlorianFloyd., 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, CHI'20, P1, DOI DOI 10.1145/3313831.3376242
   Mueller S, 2015, 2015 JOINT IEEE INTERNATIONAL SYMPOSIUM ON THE APPLICATIONS OF FERROELECTRIC, INTERNATIONAL SYMPOSIUM ON INTEGRATED FUNCTIONALITIES AND PIEZOELECTRIC FORCE MICROSCOPY WORKSHOP (ISAF/ISIF/PFM), P233, DOI 10.1109/ISAF.2015.7172714
   Nakano K, 2019, INT SYM MIX AUGMENT, P212, DOI 10.1109/ISMAR.2019.000-1
   Narumi Takuji, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P260, DOI 10.1007/978-3-642-22021-0_29
   Narumi T, 2011, P IEEE VIRT REAL ANN, P127, DOI 10.1109/VR.2011.5759450
   Norouzi* N., 2019, S SPATIAL USER INTER, P1, DOI DOI 10.1007/978-3-030-04110-61
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pellas N, 2020, EDUC INF TECHNOL, V25, P2481, DOI 10.1007/s10639-019-10076-4
   Peng H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174153
   Peng HS, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P887, DOI 10.1145/2858036.2858106
   Peng YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417802
   Peng YF, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356526
   Piovarci M, 2017, PROCEEDINGS SCF 2017: ACM SYMPOSIUM ON COMPUTATIONAL FABRICATION, DOI 10.1145/3083157.3083162
   Popescu VG, 2000, IEEE T INF TECHNOL B, V4, P45, DOI 10.1109/4233.826858
   Raca M., 2015, Proceedings of the 8th International Conference on Educational Data Mining (EDM 2015), P320
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1731, DOI 10.1145/3025453.3025723
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Rauschnabel Philipp A., 2016, International Journal of Technology Marketing, V11, P123
   Rauschnabel PA, 2015, COMPUT HUM BEHAV, V49, P635, DOI 10.1016/j.chb.2015.03.003
   Ricci A, 2015, IEEE PERVAS COMPUT, V14, P60, DOI 10.1109/MPRV.2015.44
   Rizzo A, 2010, ANN NY ACAD SCI, V1208, P114, DOI 10.1111/j.1749-6632.2010.05755.x
   Roy AK, 2020, IEEE T AFFECT COMPUT, V11, P63, DOI 10.1109/TAFFC.2017.2768026
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Sato W, 2008, INT J PSYCHOPHYSIOL, V70, P70, DOI 10.1016/j.ijpsycho.2008.06.001
   Schäfer A, 2021, Arxiv, DOI arXiv:2102.05998
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Shneiderman Ben, 2020, AIS Trans. Hum.-Comput. Interact., V12, P109, DOI [10.17705/1thci.00131, DOI 10.17705/1THCI.00131]
   SOHLBERG MM, 1987, J CLIN EXP NEUROPSYC, V9, P117, DOI 10.1080/01688638708405352
   Sra M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P59, DOI 10.1145/3196709.3196792
   Steed A, 2010, NETWORKED GRAPHICS: BUILDING NETWORKED GAMES AND VIRTUAL ENVIRONMENTS, P1
   Steed A., 2020, Interactions, V27, P62, DOI DOI 10.1145/3406098
   Stengel M, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P15, DOI 10.1145/2733373.2806265
   Stengel M, 2016, IEEE SIGNAL PROC MAG, V33, P139, DOI 10.1109/MSP.2016.2580913
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Sutherland IE., 1965, P IFIP C
   Sweller J., 2011, Measuring cognitive load. Cognitive load theory, P71, DOI [10.1007/978-1-4419-8126-4_6, DOI 10.1007/978-1-4419-8126-4_6, 10.1007/978-1-4419-8126-46, DOI 10.1007/978-1-4419-8126-46]
   Tao F, 2019, IEEE T IND INFORM, V15, P2405, DOI 10.1109/TII.2018.2873186
   Templier T, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5812, DOI 10.1145/2858036.2858578
   Topal C, 2014, IEEE T CYBERNETICS, V44, P228, DOI 10.1109/TCYB.2013.2252792
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   van Dokkum LEH, 2015, ANN PHYS REHABIL MED, V58, P3, DOI 10.1016/j.rehab.2014.09.016
   Wang G. G., 2002, Transactions of the ASME. Journal of Computing and Information Science in Engineering, V2, P232, DOI 10.1115/1.1526508
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Whitmire E, 2016, IEEE INT SYM WRBL CO, P184, DOI 10.1145/2971763.2971771
   Yarramreddy A, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P186, DOI 10.1109/SPW.2018.00034
   Zander TO, 2010, HUM-COMPUT INT-SPRIN, P181, DOI 10.1007/978-1-84996-272-8_11
   Zotter F., 2019, Ambisonics, DOI DOI 10.1007/978-3-030-17207-7
NR 138
TC 8
Z9 8
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 29
PY 2021
VL 2
AR 763340
DI 10.3389/frvir.2021.763340
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AV9
UT WOS:001019300700001
OA Green Submitted, Green Published, gold
DA 2024-07-18
ER

PT J
AU Mine, D
   Kimoto, S
   Yokosawa, K
AF Mine, Daisuke
   Kimoto, Sakurako
   Yokosawa, Kazuhiko
TI Obstacles Affect Perceptions of Egocentric Distances in Virtual
   Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE action-specific effects; distance perception; spatial perception;
   vision; touch
ID ENERGY-EXPENDITURE AFFECT; TOOL USE; SPATIAL REPRESENTATIONS; REPLICATE
   EXPERIMENT-1; SPACE; STEFANUCCI; PROFFITT; FAILURE; PEOPLE; BANTON
AB Distance perception in humans can be affected by oculomotor and optical cues and a person's action capability in a given environment, known as action-specific effects. For example, a previous study has demonstrated that egocentric distance estimation to a target is affected by the width of a transparent barrier placed in the intermediate space between a participant and a target. However, the characteristics of a barrier's width that affect distance perception remain unknown. Therefore, we investigated whether visual and tactile inputs and actions related to a barrier affect distance estimation to a target behind the barrier. The results confirmed previous studies by demonstrating that visual and tactile presentations of the barrier's width affected distance estimation to the target. However, this effect of the barrier's width was not observed when the barrier was touchable but invisible nor when the barrier was visible but penetrable. These findings indicate the complexity of action-specific effects and the difficulty of identifying necessary information for inducing these effects.
C1 [Mine, Daisuke] Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Tokyo, Japan.
   [Kimoto, Sakurako; Yokosawa, Kazuhiko] Univ Tokyo, Dept Psychol, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo
RP Mine, D (corresponding author), Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Tokyo, Japan.
EM mine@cyber.t.u-tokyo.ac.jp
FU Japan Society for the Promotion of Science [19H01490]
FX Funding This work was supported by the Japan Society for the Promotion
   of Science (Grant numbers: 19H01490) to KY. The funders had no role in
   study design, data collection, and analysis, the decision to publish, or
   manuscript preparation.
CR Afonso A, 2010, MEM COGNITION, V38, P591, DOI 10.3758/MC.38.5.591
   Bhalla M, 1999, J EXP PSYCHOL HUMAN, V25, P1076, DOI 10.1037/0096-1523.25.4.1076
   Cohen RG, 2010, EXP BRAIN RES, V201, P587, DOI 10.1007/s00221-009-2042-8
   Costello MC, 2015, PSYCHOL AGING, V30, P656, DOI 10.1037/pag0000029
   Creem-Regehr SH, 2010, WIRES COGN SCI, V1, P800, DOI 10.1002/wcs.82
   Durgin FH, 2009, PSYCHON B REV, V16, P964, DOI 10.3758/PBR.16.5.964
   Firestone C, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X15000965
   Hess RF, 2015, I-PERCEPTION, V6, DOI 10.1177/2041669515593028
   Holmes NP, 2004, NEUROSCI LETT, V372, P62, DOI 10.1016/j.neulet.2004.09.024
   Hutchison JJ, 2006, SPAN J PSYCHOL, V9, P332, DOI 10.1017/S1138741600006235
   Iriki A, 1996, NEUROREPORT, V7, P2325
   Kirsch W, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034880
   Lahav O, 2008, INT J HUM-COMPUT ST, V66, P23, DOI 10.1016/j.ijhcs.2007.08.001
   Laitin EL, 2019, ATTEN PERCEPT PSYCHO, V81, P778, DOI 10.3758/s13414-018-01652-w
   Lessard DA, 2009, PERCEPTION, V38, P1863, DOI 10.1068/p6509
   Linkenauger SA, 2015, NEUROPSYCHOLOGIA, V70, P393, DOI 10.1016/j.neuropsychologia.2014.10.034
   Longo MR, 2006, NEUROPSYCHOLOGIA, V44, P977, DOI 10.1016/j.neuropsychologia.2005.09.003
   Lourenco SF, 2009, COGNITION, V112, P451, DOI 10.1016/j.cognition.2009.05.011
   Mine D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232290
   Molto L, 2020, PSYCHOL SCI, V31, P488, DOI 10.1177/0956797619900336
   Morash V, 2012, SPAT COGN COMPUT, V12, P83, DOI 10.1080/13875868.2011.599901
   Morgado N, 2013, PSYCHON B REV, V20, P462, DOI 10.3758/s13423-012-0358-z
   Ogawa N., 2017, P 8 AUGM HUM INT C, DOI [DOI 10.1145/3041164.3041204, 10.1145/3041164.3041204]
   Osiurak F, 2012, EXP BRAIN RES, V218, P331, DOI 10.1007/s00221-012-3036-5
   Philbeck JW, 2015, PSYCHOL BULL, V141, P1120, DOI 10.1037/a0039738
   Proffitt DR, 2006, SPAN J PSYCHOL, V9, P340, DOI 10.1017/S1138741600006247
   Proffitt DR, 2013, ACTION SCIENCE: FOUNDATIONS OF AN EMERGING DISCIPLINE, P171
   Proffitt DR, 2003, PSYCHOL SCI, V14, P106, DOI 10.1111/1467-9280.t01-1-01427
   Quarona D, 2020, EXP BRAIN RES, V238, P2857, DOI 10.1007/s00221-020-05948-y
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Stefanucci JK, 2005, PERCEPT PSYCHOPHYS, V67, P1052, DOI 10.3758/BF03193631
   Tosi G, 2020, EXP BRAIN RES, V238, P2125, DOI 10.1007/s00221-020-05874-z
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Witt JK, 2011, PERCEPTION, V40, P530, DOI 10.1068/p6910
   Witt JK, 2011, J EXP PSYCHOL HUMAN, V37, P1148, DOI 10.1037/a0021933
   Witt JK, 2008, J EXP PSYCHOL HUMAN, V34, P1479, DOI 10.1037/a0010781
   Witt JK, 2005, J EXP PSYCHOL HUMAN, V31, P880, DOI 10.1037/0096-1523.31.5.880
   Witt JK, 2004, PERCEPTION, V33, P577, DOI 10.1068/p5090
   Woods AJ, 2009, J EXP PSYCHOL HUMAN, V35, P1104, DOI 10.1037/a0013622
NR 39
TC 1
Z9 1
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 16
PY 2021
VL 2
AR 726114
DI 10.3389/frvir.2021.726114
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AN7
UT WOS:001019292500001
OA gold
DA 2024-07-18
ER

PT J
AU Dilanchian, AT
   Andringa, R
   Boot, WR
AF Dilanchian, Andrew T.
   Andringa, Ronald
   Boot, Walter R.
TI A Pilot Study Exploring Age Differences in Presence, Workload, and
   Cybersickness in the Experience of Immersive Virtual Reality
   Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; technology adoption; usability; aging; human factors
ID SIMULATOR SICKNESS; OLDER-ADULTS; DRIVING SIMULATOR; PROFICIENCY;
   ENGAGEMENT
AB Research is often focused on understanding barriers to the use and adoption of technology to support older adults' (65+) instrumental activities of daily living (IADLs), such as communication, banking, and transportation. Less attention is paid to technology to support enhanced activities of daily living (EADLs), activities that enrich our daily lives, even though they have the potential to improve wellbeing, promote physical and emotional health, and reduce stress. Here, we explored how older adults interacted with commercial virtual reality (VR) to investigate the feasibility of using VR as an EADL support system. Older adults navigated different VR environments, including environments that were meditation, exploration, and game-oriented. Of particular interest was whether older adults (N = 20) psychologically experienced differing degrees of presence within virtual environments compared to younger adults (N = 20), and potential barriers to use as assessed by measures of workload and system usability. Given previously observed agerelated differences in cybersickness, this was also assessed as a potential barrier. Compared to younger adults, older adults expressed a greater sense of presence in virtual environments, with nonsignificant differences in perceived workload and usability according to most measures. Contrary to expectations, older adults reported significantly less cybersickness compared to younger adults. Results suggest that VR is a promising means to support older adults' EADLs.
C1 [Dilanchian, Andrew T.; Andringa, Ronald; Boot, Walter R.] Florida State Univ, Dept Psychol, Tallahassee, FL 32306 USA.
C3 State University System of Florida; Florida State University
RP Boot, WR (corresponding author), Florida State Univ, Dept Psychol, Tallahassee, FL 32306 USA.
EM boot@psy.fsu.edu
FU National Institute on Aging [NIAP01AG017211]
FX We gratefully acknowledge financial support from the National Institute
   on Aging, through Project CREATE IV-Center for Research and Education on
   Aging and Technology Enhancement (www.create-center.org,NIAP01AG017211).
CR Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Boot WR, 2015, GERONTOLOGIST, V55, P404, DOI 10.1093/geront/gnt117
   Bouchard S., 2014, J CYBERTHERAPY REHAB, V2, P127
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Brown A., 2017, YOUNGER MEN PLAY VID
   Charness N, 2009, CURR DIR PSYCHOL SCI, V18, P253, DOI 10.1111/j.1467-8721.2009.01647.x
   Classen S, 2011, AM J OCCUP THER, V65, P179, DOI 10.5014/ajot.2011.000802
   Cohen J., 1988, STAT POWER ANAL BEHA
   Czaja Sara J., 2019, Designing for older adults: Principles and creative human factors approaches, VThird, DOI DOI 10.1201/B22189
   De Schutter B, 2015, NEW MEDIA SOC, V17, P1170, DOI 10.1177/1461444814522945
   Diersch N, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.187252
   Harrington Christina N., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P32, DOI 10.1177/1541931213601503
   HART S G, 1988, P139
   Horgas A, 2004, TECHNOLOGY FOR ADAPTIVE AGING, P230
   Hughes TF, 2010, AM J ALZHEIMERS DIS, V25, P432, DOI 10.1177/1533317510368399
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Kawano N, 2012, AGING CLIN EXP RES, V24, P285, DOI 10.1007/BF03325260
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2018, TRANSPORT RES F-TRAF, V54, P47, DOI 10.1016/j.trf.2018.01.007
   Kim HY, 2021, SCI REP-UK, V11, DOI [10.1038/s41598-020-80289-y, 10.1038/s41598-021-02201-6]
   Kuykendall L, 2015, PSYCHOL BULL, V141, P364, DOI 10.1037/a0038508
   Lee LN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173556
   Matas NA, 2015, J SAFETY RES, V55, P159, DOI 10.1016/j.jsr.2015.08.004
   Menec VH, 2003, J GERONTOL B-PSYCHOL, V58, pS74, DOI 10.1093/geronb/58.2.S74
   Narciso D, 2019, UNIVERSAL ACCESS INF, V18, P77, DOI 10.1007/s10209-017-0581-5
   Park G.R., 2006, Proceedings of the Human Factors and Ergonomics Society 50 Annual Meeting, P2702, DOI DOI 10.1177/154193120605002607
   Ramprasad C, 2019, CLIN GERONTOLOGIST, V42, P17, DOI 10.1080/07317115.2017.1322162
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Roberts AR, 2019, CLIN GERONTOLOGIST, V42, P27, DOI 10.1080/07317115.2018.1442380
   Rogers WA, 1998, HUM FACTORS, V40, P111, DOI 10.1518/001872098779480613
   Roque NA, 2018, J APPL GERONTOL, V37, P131, DOI 10.1177/0733464816642582
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Seifert A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.639718
   Walter R., 2020, Gerontechnology, V19, P138, DOI [10.4017/gt.2020.19.2.006.00, DOI 10.4017/GT.2020.19.2.006.00]
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Winter C, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00848-w
   Yen HY, 2021, J AM MED DIR ASSOC, V22, P995, DOI 10.1016/j.jamda.2021.03.009
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
NR 42
TC 20
Z9 22
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 7
PY 2021
VL 2
AR 736793
DI 10.3389/frvir.2021.736793
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZQ8
UT WOS:001019269500001
OA gold
DA 2024-07-18
ER

PT J
AU Bartl, A
   Wenninger, S
   Wolf, E
   Botsch, M
   Latoschik, ME
AF Bartl, Andrea
   Wenninger, Stephan
   Wolf, Erik
   Botsch, Mario
   Latoschik, Marc Erich
TI Affordable But Not Cheap: A Case Study of the Effects of Two
   3D-Reconstruction Methods of Virtual Humans
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual humans; 3D-reconstruction methods; avatars; agents; user study
ID EMBODIMENT; AVATAR; ENVIRONMENTS; APPEARANCE; OWNERSHIP; BEHAVIOR
AB Realistic and lifelike 3D-reconstruction of virtual humans has various exciting and important use cases. Our and others' appearances have notable effects on ourselves and our interaction partners in virtual environments, e.g., on acceptance, preference, trust, believability, behavior (the Proteus effect), and more. Today, multiple approaches for the 3D-reconstruction of virtual humans exist. They significantly vary in terms of the degree of achievable realism, the technical complexities, and finally, the overall reconstruction costs involved. This article compares two 3D-reconstruction approaches with very different hardware requirements. The high-cost solution uses a typical complex and elaborated camera rig consisting of 94 digital single-lens reflex (DSLR) cameras. The recently developed low-cost solution uses a smartphone camera to create videos that capture multiple views of a person. Both methods use photogrammetric reconstruction and template fitting with the same template model and differ in their adaptation to the method-specific input material. Each method generates high-quality virtual humans ready to be processed, animated, and rendered by standard XR simulation and game engines such as Unreal or Unity. We compare the results of the two 3D-reconstruction methods in an immersive virtual environment against each other in a user study. Our results indicate that the virtual humans from the low-cost approach are perceived similarly to those from the high-cost approach regarding the perceived similarity to the original, human-likeness, beauty, and uncanniness, despite significant differences in the objectively measured quality. The perceived feeling of change of the own body was higher for the low-cost virtual humans. Quality differences were perceived more strongly for one's own body than for other virtual humans.
C1 [Bartl, Andrea; Wolf, Erik; Latoschik, Marc Erich] Univ Wurzburg, HCI Grp, Wurzburg, Germany.
   [Wenninger, Stephan; Botsch, Mario] TU Dortmund Univ, Comp Grp Grp, Dortmund, Germany.
C3 University of Wurzburg; Dortmund University of Technology
RP Bartl, A (corresponding author), Univ Wurzburg, HCI Grp, Wurzburg, Germany.
EM andrea.bartl@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600; Wenninger,
   Stephan/0009-0008-2404-7117
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Agisoft, 2020, MET PRO
   Alexandrovsky D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376260
   Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Alldieck T, 2018, INT CONF 3D VISION, P98, DOI 10.1109/3DV.2018.00022
   Autodesk, 2014, CHAR GEN
   Aymerich-Franch L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00944
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bouaziz S., 2014, EUROGRAPHICS TUTORIA, V1-17
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Brenton H., 2005, P 19 BRIT HCI GROUP
   Chin-Chang Ho, 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P169
   Cohen J., 1988, STAT POWER ANAL BEHA
   de Rooij A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P232, DOI 10.1145/3059454.3078856
   Dollinger N., 2019, MENSCH COMP 2019 WOR, P606
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Epic Games, 2021, MET CREAT
   Feng A, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1769
   Fox J, 2013, COMPUT HUM BEHAV, V29, P930, DOI 10.1016/j.chb.2012.12.027
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Guo K., 2019, ACM T GRAPHIC, V38, P1, DOI DOI 10.1145/3355089.3356571
   He D., 2000, INT IMMERSIVE PROJEC
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   Hudson Irwin, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P14, DOI 10.1007/978-3-319-39907-2_2
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jo Dongsik, 2017, Proceedings_of_the_30th_Conference_on_Computer_Animation_and_Social_Agents, P27
   Kätsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kocur Martin, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P193, DOI 10.1145/3410404.3414261
   Latoschik M. E., 2021, ARXIV
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2015.7223377
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P227, DOI 10.1109/VR.2015.7223378
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P997, DOI 10.1007/s00371-005-0363-6
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nelson Michael G., 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P617, DOI 10.1007/978-3-030-64556-4_48
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Peña J, 2016, J COMPUT-MEDIAT COMM, V21, P195, DOI 10.1111/jcc4.12151
   Praetorius AS., 2020, International Conference on the Foundations of Digital Games, P1
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Rootmotion, 2020, FINALIK
   Roth D., 2017, C HUM FACTORS COMPUT, VPart F1276, P2875, DOI DOI 10.1145/3027063.3053272
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Salomoni Paola, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P387, DOI 10.1109/CCNC.2016.7444811
   Seymour M, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P547
   Seymour M, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P1748
   Shafer D. M., 2017, MEDIA PSYCHOL REV, V11, P1
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steed Anthony, 2015, Collaboration in Immersive and Non-immersive Virtual Environments, P263, DOI [DOI 10.1007/978-3-319-10190-3{_}11, 10.1007/978-3-319-10190-3_11, DOI 10.1007/978-3-319-10190-3_11]
   Thaler A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192152
   Tinwell A., 2009, P 13 INT MINDTREK C, P66, DOI [DOI 10.1145/1621841.1621855, https://doi.org/10.1145/1621841.1621855]
   Unity Technologies, 2019, Unity
   Valve, 2020, STEAMVR
   Valve Corporation, 2020, IND
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Wang SS, 2015, REV GEN PSYCHOL, V19, P393, DOI 10.1037/gpr0000056
   Weng CY, 2019, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR.2019.00606
   Wenninger S., 2020, 26 ACM S VIRTUAL REA, P1, DOI [DOI 10.1145/3385956.3418940, 10.1145/3385956.3418940]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Wolf E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR50410.2021.00027
   Yee N., 2006, P PRESENCE 2006 9 AN
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 84
TC 11
Z9 11
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 24
PY 2021
VL 2
AR 694617
DI 10.3389/frvir.2021.694617
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AV5
UT WOS:001019300300001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Adhikari, A
   Hashemian, AM
   Nguyen-Vo, T
   Kruijff, E
   von der Heyde, M
   Riecke, BE
AF Adhikari, Ashu
   Hashemian, Abraham M.
   Nguyen-Vo, Thinh
   Kruijff, Ernst
   von der Heyde, Markus
   Riecke, Bernhard E.
TI Lean to Fly: Leaning-Based Embodied Flying can Improve Performance and
   User Experience in 3D Navigation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE locomotion interface; spatial orientation; navigational search; 3D
   navigation; leaning-based interfaces; virtual reality; spatial updating
ID PATH-INTEGRATION; VIRTUAL-REALITY; SICKNESS; MOVEMENT; KNOWLEDGE;
   SIMULATOR; SENSES
AB When users in virtual reality cannot physically walk and self-motions are instead only visually simulated, spatial updating is often impaired. In this paper, we report on a study that investigated if HeadJoystick, an embodied leaning-based flying interface, could improve performance in a 3D navigational search task that relies on maintaining situational awareness and spatial updating in VR. We compared it to Gamepad, a standard flying interface. For both interfaces, participants were seated on a swivel chair and controlled simulated rotations by physically rotating. They either leaned (forward/backward, right/left, up/down) or used the Gamepad thumbsticks for simulated translation. In a gamified 3D navigational search task, participants had to find eight balls within 5 min. Those balls were hidden amongst 16 randomly positioned boxes in a dark environment devoid of any landmarks. Compared to the Gamepad, participants collected more balls using the HeadJoystick. It also minimized the distance travelled, motion sickness, and mental task demand. Moreover, the HeadJoystick was rated better in terms of ease of use, controllability, learnability, overall usability, and self-motion perception. However, participants rated HeadJoystick could be more physically fatiguing after a long use. Overall, participants felt more engaged with HeadJoystick, enjoyed it more, and preferred it. Together, this provides evidence that leaning-based interfaces like HeadJoystick can provide an affordable and effective alternative for flying in VR and potentially telepresence drones.
C1 [Adhikari, Ashu; Hashemian, Abraham M.; Nguyen-Vo, Thinh; Kruijff, Ernst; von der Heyde, Markus; Riecke, Bernhard E.] Sch Interact Arts & Technol, iSpace Lab, Burnaby, BC, Canada.
   [Nguyen-Vo, Thinh] Microsoft Corp, Seattle, WA USA.
   [Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, Bonn, Germany.
   [von der Heyde, Markus] VdH IT, Weima, Germany.
C3 Microsoft; Hochschule Bonn Rhein Sieg
RP Riecke, BE (corresponding author), Sch Interact Arts & Technol, iSpace Lab, Burnaby, BC, Canada.
EM ber1@sfu.ca
RI von der Heyde, Markus/HJA-0319-2022; Riecke, Bernhard E./C-6399-2011
OI von der Heyde, Markus/0000-0002-6026-082X; 
FU Natural Sciences and Engineering Research Council (NSERC) [R611547]
FX Funding This research was supported by Natural Sciences and Engineering
   Research Council (NSERC) (grant: #R611547).
CR Adhikari A, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P370, DOI 10.1109/VRW52623.2021.00074
   Aykent B, 2014, P I MECH ENG D-J AUT, V228, P818, DOI 10.1177/0954407013516101
   Badcock D. R., 2014, HDB VIRTUAL ENV, V2nd, P39, DOI DOI 10.1201/B17360-6
   Balk S., 2013, SIMULATOR SICKNESS Q, DOI DOI 10.17077/DRIVINGASSESSMENT.1498
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   CHEUNG BSK, 1991, AVIAT SPACE ENVIR MD, V62, P527
   Cirio G., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P155, DOI [DOI 10.1145/1643928.1643965, 10.1145/1643928.1643965]
   Farrell MJ, 1998, J EXP PSYCHOL LEARN, V24, P227, DOI 10.1037/0278-7393.24.1.227
   Fiore LorenPuchalla., 2013, Proceedings of the Joint Virtual Reality Conference of ICAT-EGVE-EuroVR, P83, DOI DOI 10.2312/EGVE.JVRC13.083-090
   Groen EL, 2004, J VESTIBUL RES-EQUIL, V14, P375
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231, DOI DOI 10.1145/2670473.2670512
   HART S G, 1988, P139
   Hashemian A., 2020, HEADJOYSTICK IMPROVI
   Hashemian A. M., 2017, Swivel-chair: Evaluating seated full-rotational interfaces for virtual reality navigation
   Hashemian A. M., 2015, P 3 ACM S SPAT US IN, P123, DOI DOI 10.1145/2788940.2788956
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Higuchi Keita., 2013, Proc. CHI'13 extended abstracts, P2029
   Kearns MJ, 2002, PERCEPTION, V31, P349, DOI 10.1068/p3311
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Kruijff E., 2015, P 3 ACM S SPAT US IN, P103, DOI 10.1145/2788940.2788943
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Krupke D, 2016, P IEEE VIRT REAL ANN, P329
   LaViola J. J., 2001, SI3D, V1, P9, DOI [10.1145/364338.364339, DOI 10.1145/364338.364339]
   Lawson B. D., 2014, HDB VIRTUAL ENV, P536, DOI [10.1201/b17360-33, DOI 10.1201/B17360-33]
   Lawson BD, 2015, HUM FACTORS ERGON, P163
   Lessells S, 2005, PRESENCE-TELEOP VIRT, V14, P580, DOI 10.1162/105474605774918778
   Loomis J.M., 2008, EMBODIMENT EGO SPACE, P1, DOI DOI 10.4324/9780203809891
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   Marsh WE, 2013, PRESENCE-VIRTUAL AUG, V22, P216, DOI 10.1162/PRES_a_00152
   McMahan R. P., 2011, Exploring the effects of higher-fidelity display and interaction for virtual reality games
   McNamara T.P., 2008, Learning and memory: A comprehensive reference: Vol. 2. Cognitive psychology of memory, V2, P157, DOI [DOI 10.1016/B978-012370509-9.00176-5, 10.1016/B978-012370509-9.00176-5]
   Miehlbradt J, 2018, P NATL ACAD SCI USA, V115, P7913, DOI 10.1073/pnas.1718648115
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Nguyen-Vo T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P415, DOI 10.1109/VR.2018.8446383
   Perusquia-Hernandez M., 2017, P 8 AUGM HUM INT C, V4, DOI [10.1145/3041164.3041173, DOI 10.1145/3041164.3041173]
   Pittman C., 2014, P 19 INT C INT US IN, P323
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Rheiner M., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P3, DOI DOI 10.1145/2614066.2614101
   Riecke B. E., 2003, FAR CAN WE GET JUST, VVol. 8
   Riecke B. E., 2012, P ACM S APPL PERCEPT, P17
   Riecke B.E., 2006, P ACM S VIRTUAL REAL, P104, DOI DOI 10.1145/1180495.1180517
   Riecke BE, 2008, PRESENCE-TELEOP VIRT, V17, P143, DOI 10.1162/pres.17.2.143
   Riecke BE, 2007, PSYCHOL RES-PSYCH FO, V71, P298, DOI 10.1007/s00426-006-0085-z
   Riecke BE, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P295, DOI [10.1109/VRW50115.2020.0-210, 10.1109/VRW50115.2020.00066]
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01174
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Rognon C, 2018, IEEE ROBOT AUTOM LET, V3, P2362, DOI 10.1109/LRA.2018.2810955
   Ruddle R.A., 2013, HUMAN WALKING VIRTUA, P99, DOI [10.1007/978-1-4419-8432-6_5, DOI 10.1007/978-1-4419-8432-6_5]
   Ruddle RA, 2005, P IEEE VIRT REAL ANN, P115
   Ruddle RA, 2001, PRESENCE-TELEOP VIRT, V10, P511, DOI 10.1162/105474601753132687
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2011, MEM COGNITION, V39, P686, DOI 10.3758/s13421-010-0054-z
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Schulte B., 2016, P GI WORKSHOP VRAR, P109
   Shelton AL, 1997, PSYCHON B REV, V4, P102, DOI 10.3758/BF03210780
   Shumin Zhai, 1998, Computer Graphics, V32, P50, DOI 10.1145/307710.307728
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Steinicke F, 2013, Human walking in virtual environments
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Sun HJ, 2004, EXP BRAIN RES, V154, P246, DOI 10.1007/s00221-003-1652-9
   Waller D, 2004, PSYCHON B REV, V11, P157, DOI 10.3758/BF03206476
   Wang RF, 2016, PSYCHON B REV, V23, P692, DOI 10.3758/s13423-015-0952-y
   Wang RF, 2002, TRENDS COGN SCI, V6, P376, DOI 10.1016/S1364-6613(02)01961-7
   Wang RXF, 2004, PERCEPT PSYCHOPHYS, V66, P68, DOI 10.3758/BF03194862
   Xia XY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1241, DOI [10.1109/VR.2019.8797791, 10.1109/vr.2019.8797791]
   Zhang H, 2011, COGNITION, V119, P419, DOI 10.1016/j.cognition.2011.02.006
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P297, DOI [10.1109/VRW50115.2020.0-209, 10.1109/VRW50115.2020.00067]
NR 77
TC 2
Z9 2
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 23
PY 2021
VL 2
AR 730334
DI 10.3389/frvir.2021.730334
PG 22
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZE9
UT WOS:001019257500001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Lerner, F
   Tahar, G
   Bar, A
   Koren, O
   Flash, T
AF Lerner, France
   Tahar, Guillaume
   Bar, Alon
   Koren, Ori
   Flash, Tamar
TI VR Setup to Assess Peripersonal Space Audio-Tactile 3D Boundaries
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE peripersonal space; virtual reality; 3D boundary; audio-tactile
   representation; body schemas; reaction time
ID DYNAMIC SIZE-CHANGE; BODY SCHEMA; MULTISENSORY REPRESENTATION;
   INTERPERSONAL SPACE; EXTRAPERSONAL SPACE; CROSSMODAL LINKS; TOOL-USE;
   HAND; PERCEPTION; CORTEX
AB Many distinct spaces surround our bodies. Most schematically, the key division is between peripersonal space (PPS), the close space surrounding our body, and an extrapersonal space, which is the space out of one's reach. The PPS is considered as an action space, which allows us to interact with our environment by touching and grasping. In the current scientific literature, PPS' visual representations are appearing as mere bubbles of even dimensions wrapped around the body. Although more recent investigations of PPS' upper body (trunk, head, and hands) and lower body (legs and foot) have provided new representations, no investigation has been made yet concerning the estimation of PPS's overall representation in 3D. Previous findings have demonstrated how the relationship between tactile processing and the location of sound sources in space is modified along a spatial continuum. These findings suggest that similar methods can be used to localize the boundaries of the subjective individual representation of PPS. Hence, we designed a behavioral paradigm in virtual reality based on audio-tactile interactions, which has enabled us to infer a detailed individual 3D audio-tactile representation of PPS. Considering that inadequate body-related multisensory integration processes can produce incoherent spatio-temporal perception, the development of a virtual reality setup and a method to estimate the representation of the subjective PPS volumetric boundaries will be a valuable addition for the comprehension of the mismatches occurring between body physical boundaries and body schema representations in 3D.
C1 [Lerner, France; Tahar, Guillaume; Koren, Ori; Flash, Tamar] Weizmann Inst Sci, Dept Comp Sci & Appl Math, Rehovot, Israel.
   [Bar, Alon] Weizmann Inst Sci, Dept Mol Cell Biol, Rehovot, Israel.
C3 Weizmann Institute of Science; Weizmann Institute of Science
RP Lerner, F (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, Rehovot, Israel.
EM France.Lerner@weizmann.ac.il
FU Feinberg Institute of the Weizmann Institute of Science, Rehovot,
   Israel; Braginsky Center of Art and Science of WIS; Israel Science
   Foundation [1167/17]; European Research Council (ERC) under the European
   Union [802107]
FX All the authors are supported by the Feinberg Institute of the Weizmann
   Institute of Science, Rehovot, Israel. The first author has additional
   funding from the Braginsky Center of Art and Science of WIS. The second
   author is supported by the Israel Science Foundation (grant No 1167/17)
   and the European Research Council (ERC) under the European Union Horizon
   2020 research innovation program (grant agreement No. 802107).
CR Amemiya T, 2019, PSYCHOL SCI, V30, P1522, DOI 10.1177/0956797619869337
   [Anonymous], 2016, NEUROPSYCHOLOGY SPAC
   Ardizzi M, 2018, COGNITION, V177, P79, DOI 10.1016/j.cognition.2018.04.001
   Bassolino M, 2010, NEUROPSYCHOLOGIA, V48, P803, DOI 10.1016/j.neuropsychologia.2009.11.009
   Berger M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39520-8
   Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237
   Binkofski F, 2003, EXP BRAIN RES, V153, P210, DOI 10.1007/s00221-003-1594-2
   Bonifazi S, 2007, J NEUROPSYCHOL, V1, P101, DOI 10.1348/174866407X180846
   Bonnier P, 2009, EPILEPSY BEHAV, V16, P401, DOI 10.1016/j.yebeh.2009.09.020
   Brain WR, 1941, BRAIN, V64, P244, DOI 10.1093/brain/64.4.244
   Bremmer F, 2001, NEURON, V29, P287, DOI 10.1016/S0896-6273(01)00198-2
   Brozzoli C, 2010, NEUROPSYCHOLOGIA, V48, P796, DOI 10.1016/j.neuropsychologia.2009.10.009
   Brozzoli C., 2012, NEURAL BASES MULTISE
   Bufacchi RJ, 2016, J NEUROPHYSIOL, V115, P218, DOI 10.1152/jn.00691.2015
   Bufacchi RJ, 2018, TRENDS COGN SCI, V22, P1076, DOI 10.1016/j.tics.2018.09.004
   Bufacchi RJ, 2016, CURR BIOL, V26, pR1133, DOI 10.1016/j.cub.2016.09.025
   Canzoneri E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044306
   Cartaud A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00657
   Cléry J, 2015, NEUROPSYCHOLOGIA, V70, P313, DOI 10.1016/j.neuropsychologia.2014.10.022
   Cuevas-Rodríguez M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211899
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   D'Angelo M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32238-z
   De Vignemont F., 2015, NEUROPSYCHOLOGIA, V70, P327, DOI [10.1016/j.tics.2003.12.008, DOI 10.1016/J.TICS.2003.12.008]
   de Vignemont F., 2018, Mind the body: An exploration of the bodily selfawareness
   de Vignemont F, 2010, NEUROPSYCHOLOGIA, V48, P669, DOI 10.1016/j.neuropsychologia.2009.09.022
   Delevoye-Turrell Y, 2011, SOC PSYCHOL-GERMANY, V42, P193, DOI 10.1027/1864-9335/a000063
   Dell C., 1977, SPACE HARMONY BASIC
   di Pellegrino G, 2015, NEUROPSYCHOLOGIA, V66, P126, DOI 10.1016/j.neuropsychologia.2014.11.011
   Dijkerman HC, 2017, NEUROPSYCHOLOGY OF SPACE: SPATIAL FUNCTIONS OF THE HUMAN BRAIN, P77, DOI 10.1016/B978-0-12-801638-1.00003-3
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Farnè A, 2000, NEUROREPORT, V11, P1645, DOI 10.1097/00001756-200006050-00010
   Farnè A, 2007, CORTEX, V43, P436, DOI 10.1016/S0010-9452(08)70468-4
   Ferri F, 2015, NEUROPSYCHOLOGIA, V70, P468, DOI 10.1016/j.neuropsychologia.2015.03.001
   Fini C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114719
   Fogassi L, 1996, J NEUROPHYSIOL, V76, P141, DOI 10.1152/jn.1996.76.1.141
   GALLAGHER S, 1986, J MIND BEHAV, V7, P541
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   Galli G, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00639
   Gamberini L, 2008, NEUROPSYCHOLOGIA, V46, P1298, DOI 10.1016/j.neuropsychologia.2007.12.016
   Graziano M., 2017, The Spaces Between Us: A Story of Neuroscience, Evolution, and Human Nature
   GRAZIANO MSA, 1993, EXP BRAIN RES, V97, P96
   GRAZIANO MSA, 1994, SCIENCE, V266, P1054, DOI 10.1126/science.7973661
   Grusser O.J., 1983, SPATIALLY ORIENTED B, P327, DOI [DOI 10.1007/978-1-4612-5488-1_18, 10.1007/978-1-4612-5488-1_18]
   HALLIGAN PW, 1991, NATURE, V350, P498, DOI 10.1038/350498a0
   Head H, 1911, BRAIN, V34, P102, DOI 10.1093/brain/34.2-3.102
   Hobeika L, 2018, EXP BRAIN RES, V236, P609, DOI 10.1007/s00221-017-5158-2
   Holmes Nicholas P, 2004, Cogn Process, V5, P94, DOI 10.1007/s10339-004-0013-3
   Holmes NP, 2020, EXP BRAIN RES, V238, P995, DOI 10.1007/s00221-020-05771-5
   Hunley SB, 2018, WIRES COGN SCI, V9, DOI 10.1002/wcs.1472
   Iachini T, 2016, J ENVIRON PSYCHOL, V45, P154, DOI 10.1016/j.jenvp.2016.01.004
   Iachini T, 2015, ACTA PSYCHOL, V161, P131, DOI 10.1016/j.actpsy.2015.09.003
   Iachini T, 2015, COGN PROCESS, V16, pS255, DOI 10.1007/s10339-015-0717-6
   Kandula M, 2017, EXP BRAIN RES, V235, P2511, DOI 10.1007/s00221-017-4965-9
   Keysers C, 2004, NEURON, V42, P335, DOI 10.1016/S0896-6273(04)00156-4
   Làdavas E, 2002, TRENDS COGN SCI, V6, P17, DOI 10.1016/S1364-6613(00)01814-3
   Làdavas E, 2008, COGN NEUROPSYCHOL, V25, P1099, DOI 10.1080/02643290802359113
   Lee J., 2016, Proceedings of the 29th Annual Symposium on User Interface Software and Technology, UIST'16 Adjunct, (New York, NY, USA), P207
   Lloyd DM, 2003, PERCEPT PSYCHOPHYS, V65, P901, DOI 10.3758/BF03194823
   Lloyd DM, 2003, NAT NEUROSCI, V6, P17, DOI 10.1038/nn991
   Lloyd DM, 2007, BRAIN COGNITION, V64, P104, DOI 10.1016/j.bandc.2006.09.013
   Longo MR, 2007, EXP BRAIN RES, V177, P285, DOI 10.1007/s00221-007-0855-x
   Longo MR, 2006, NEUROPSYCHOLOGIA, V44, P977, DOI 10.1016/j.neuropsychologia.2005.09.003
   Lourenco SF, 2011, COGNITION, V119, P448, DOI 10.1016/j.cognition.2011.02.009
   Makin TR, 2008, BEHAV BRAIN RES, V191, P1, DOI 10.1016/j.bbr.2008.02.041
   Makin TR, 2007, J NEUROSCI, V27, P731, DOI 10.1523/JNEUROSCI.3653-06.2007
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   Maravita A, 2003, CURR BIOL, V13, pR531, DOI 10.1016/S0960-9822(03)00449-4
   Mine D, 2021, EXP BRAIN RES, V239, P237, DOI 10.1007/s00221-020-05971-z
   Nandrino JL, 2017, EUR EAT DISORD REV, V25, P179, DOI 10.1002/erv.2506
   Noel JP, 2020, CEREB CORTEX, V30, P5088, DOI 10.1093/cercor/bhaa103
   Noel JP, 2018, J NEUROPHYSIOL, V119, P2307, DOI 10.1152/jn.00652.2017
   Noel JP, 2017, SCHIZOPHR RES, V179, P8, DOI 10.1016/j.schres.2016.09.021
   Noel JP, 2015, COGNITION, V144, P49, DOI 10.1016/j.cognition.2015.07.012
   Noel JP, 2015, NEUROPSYCHOLOGIA, V70, P375, DOI 10.1016/j.neuropsychologia.2014.08.030
   Pavani F, 2004, NAT NEUROSCI, V7, P14, DOI 10.1038/nn1167
   Pellencin E, 2018, CORTEX, V104, P163, DOI 10.1016/j.cortex.2017.08.033
   Pfeiffer C, 2018, EUR J NEUROSCI, V47, P800, DOI 10.1111/ejn.13872
   PREVIC FH, 1990, BEHAV BRAIN SCI, V13, P519, DOI 10.1017/S0140525X00080018
   Previc FH, 1998, PSYCHOL BULL, V124, P123, DOI 10.1037/0033-2909.124.2.123
   Rizzolatti G, 1997, SCIENCE, V277, P190, DOI 10.1126/science.277.5323.190
   RIZZOLATTI G, 1981, BEHAV BRAIN RES, V2, P147, DOI 10.1016/0166-4328(81)90053-X
   Ruggiero G, 2017, PSYCHOL RES-PSYCH FO, V81, P1232, DOI 10.1007/s00426-016-0806-x
   Sambo CF, 2012, J NEUROSCI, V32, P12921, DOI 10.1523/JNEUROSCI.0607-12.2012
   Sambo CF, 2013, J NEUROSCI, V33, P14225, DOI 10.1523/JNEUROSCI.0706-13.2013
   Serino A., 2018, Frontiers in ICT, V4, P31, DOI [10.3389/fict.2017.00031, DOI 10.3389/FICT.2017.00031]
   Serino A, 2016, TRENDS COGN SCI, V20, P169, DOI 10.1016/j.tics.2016.01.005
   Serino A, 2015, SCI REP-UK, V5, DOI 10.1038/srep18603
   Serino A, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00004
   Serino A, 2011, J COGNITIVE NEUROSCI, V23, P2956, DOI 10.1162/jocn_a_00006
   Spence C, 2000, J EXP PSYCHOL HUMAN, V26, P1298, DOI 10.1037//0096-1523.26.4.1298
   Spence C, 2008, HAPTIC RENDERING FDN, P21, DOI [10.1201/b10636-4, DOI 10.1201/B10636-4]
   Stone KD, 2018, EXP BRAIN RES, V236, P161, DOI 10.1007/s00221-017-5115-0
   Taffou M, 2014, FRONT PSYCHIATRY, V5, DOI 10.3389/fpsyt.2014.00122
   Teneggi C, 2013, CURR BIOL, V23, P406, DOI 10.1016/j.cub.2013.01.043
   Von Laban R., 1966, LANGUAGE MOVEMENT GU
   Yairi Satoshi, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1122, DOI 10.1109/IIH-MSP.2009.267
   Yu XQ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00981
NR 97
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 13
PY 2021
VL 2
AR 644214
DI 10.3389/frvir.2021.644214
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2UC3
UT WOS:001021850600001
OA gold
DA 2024-07-18
ER

PT J
AU Madshaven, JM
   Markseth, TF
   Jomås, DB
   Isabwe, GMN
   Ottestad, M
   Reichert, F
   Sanfilippo, F
AF Madshaven, Julie Madelen
   Markseth, Tonje Fjeldstad
   Jomas, David Bye
   Isabwe, Ghislain Maurice Norbert
   Ottestad, Morten
   Reichert, Frank
   Sanfilippo, Filippo
TI Investigating the User Experience of Virtual Reality Rehabilitation
   Solution for Biomechatronics Laboratory and Home Environment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; biomechatronics lab; physical rehabilitation; user
   experience; home system
ID FEASIBILITY; PROGRAM; GAIT; PERFORMANCE
AB Virtual reality (VR) technology is a promising tool in physical rehabilitation. Research indicates that VR-supported rehabilitation is beneficial for task-specific training, multi-sensory feedback, diversified rehabilitation tasks, and patient motivation. Our first goal was to create a biomechatronics laboratory with a VR setup for increasing immersion and a motion platform to provide realistic feedback to patients. The second goal was to investigate possibilities to replicate features of the biomechatronics laboratory in a home-based training system using commercially available components. The laboratory comprises of a motion platform with 6-degrees-of-freedom (Rexroth eMotion), fitted with a load cell integrated treadmill, and an Oculus Quest virtual reality headset. The load cells provide input for data collection, as well as VR motion control. The home-based rehabilitation system consists of a Nintendo Wii Balance Board and an Oculus Rift virtual reality headset. User studies in the laboratory and home environment used direct observation techniques and self-reported attitudinal research methods to assess the solution's usability and user experience. The findings indicate that the proposed VR solution is feasible. Participants using the home-based system experienced more cybersickness and imbalance compared to those using the biomechatronics laboratory solution. Future studies will look at a setup that is safe for first patient studies, and exercises to improve diagnosis of patients and progress during rehabilitation.
C1 [Madshaven, Julie Madelen; Markseth, Tonje Fjeldstad; Isabwe, Ghislain Maurice Norbert; Reichert, Frank] Univ Agder, Fac Engn & Sci, Dept Informat & Commun Technol, Grimstad, Norway.
   [Jomas, David Bye; Ottestad, Morten; Sanfilippo, Filippo] Univ Agder, Fac Engn & Sci, Dept Engn Sci, Grimstad, Norway.
C3 University of Agder; University of Agder
RP Madshaven, JM (corresponding author), Univ Agder, Fac Engn & Sci, Dept Informat & Commun Technol, Grimstad, Norway.
EM julie.madshaven@uia.no
FU Top Research Centre Mechatronics, University of Agder (UiA), Grimstad,
   Norway
FX This work is supported by the Top Research Centre Mechatronics,
   University of Agder (UiA), Jon Lilletuns vei 9, 4879, Grimstad, Norway.
CR Benzeroual K, 2013, INT CONF 3D IMAG
   Bonnechere Bruno, 2015, JMIR Rehabil Assist Technol, V2, pe8, DOI 10.2196/rehab.3832
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Bortone I, 2018, IEEE T NEUR SYS REH, V26, P1469, DOI 10.1109/TNSRE.2018.2846814
   Brütsch K, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-15
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Clark RA, 2010, GAIT POSTURE, V31, P307, DOI 10.1016/j.gaitpost.2009.11.012
   Darekar A, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0035-3
   Dasgupta B, 2000, MECH MACH THEORY, V35, P15, DOI 10.1016/S0094-114X(99)00006-3
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dobkin BH, 2013, CURR OPIN NEUROL, V26, P602, DOI 10.1097/WCO.0000000000000026
   Gil-Gómez JA, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-30
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Jomas D., 2020, COMPUTER BASED ENV L
   Kalron A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0124-y
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kern F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P500, DOI [10.1109/VR.2019.8797828, 10.1109/vr.2019.8797828]
   Keshavarz B, 2015, EXP BRAIN RES, V233, P1353, DOI 10.1007/s00221-015-4209-9
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Keshner EA, 2017, J VESTIBUL RES-EQUIL, V27, P1, DOI 10.3233/VES-170610
   Kizony R, 2010, PHYS THER, V90, P252, DOI 10.2522/ptj.20090061
   Kleim JA, 2008, J SPEECH LANG HEAR R, V51, pS225, DOI 10.1044/1092-4388(2008/018)
   Koenig S. T., 2019, HDB REHABILITATION P, V3rd edn, P521521
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lawo M., 2018, ADV STUDIES MOBILE R
   Lazar J., 2017, RES METHODS HUMAN CO, DOI DOI 10.1016/B978-0-12-805390-4.00014-5
   Liao WC, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000013207
   Liu GY, 2019, CHINESE J AERONAUT, V32, P723, DOI 10.1016/j.cja.2018.07.009
   Lubetzky AV, 2022, DISABIL REHABIL-ASSI, V17, P74, DOI 10.1080/17483107.2020.1765419
   Madshaven J. M., 2020, THESIS U AGDER GRIMS
   Mansfield A, 2015, REHABIL PROCESS OUTC, V4, P7, DOI 10.4137/RPO.S20363
   Pareek S, 2018, 2018 INTERNATIONAL SYMPOSIUM ON MEDICAL ROBOTICS (ISMR)
   Plouzeau J., 2015, P INT C ARTIFICIAL R, P1
   Porras DC, 2019, THER ADV CHRONIC DIS, V10, DOI 10.1177/2040622319868379
   Porras DC, 2018, NEUROLOGY, V90, P1017, DOI 10.1212/WNL.0000000000005603
   Proffitt R, 2015, INT J TELEREHABILITA, V7, P23, DOI 10.5195/ijt.2015.6177
   Salisbury K., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P123, DOI 10.1145/199404.199426
   Sanfilippo F, 2015, IEEE IND ELEC, P168, DOI 10.1109/IECON.2015.7392094
   Sanfilippo F, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2020), P213, DOI 10.1109/ICICT50521.2020.00040
   Sanfilippo F, 2018, INT J ONLINE ENG, V14, P52, DOI 10.3991/ijoe.v14i08.8571
   Schiza E, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00100
   Seo NJ, 2016, J REHABIL RES DEV, V53, P321, DOI 10.1682/JRRD.2015.03.0045
   Sessoms PH, 2015, MIL MED, V180, P143, DOI 10.7205/MILMED-D-14-00385
   Shema SR, 2014, PHYS THER, V94, P1319, DOI 10.2522/ptj.20130305
   Stozek J, 2016, AGING CLIN EXP RES, V28, P1169, DOI 10.1007/s40520-015-0506-1
   Tokuyama Y, 2019, PROC SPIE, V11049, DOI 10.1117/12.2521513
   Tuthill JC, 2018, CURR BIOL, V28, pR194, DOI 10.1016/j.cub.2018.01.064
   Weiss Patrice L Tamar, 2003, Occup Ther Int, V10, P39, DOI 10.1002/oti.176
   Wienrich C., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications, P1, DOI [DOI 10.1109/VS-GAMES.2018.8493408, DOI 10.1109/VS-GAMES.2018, 10.1109/VS-Games.2018.8493408]
   Yeh SC, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/9840273
NR 52
TC 3
Z9 3
U1 6
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 13
PY 2021
VL 2
AR 645042
DI 10.3389/frvir.2021.645042
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TX8
UT WOS:001021846100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Panteleris, P
   Michel, D
   Argyros, A
AF Panteleris, Paschalis
   Michel, Damien
   Argyros, Antonis
TI Toward Augmented Reality in Museums: Evaluation of Design Choices for 3D
   Object Pose Estimation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE 3D object pose estimation; monocular RGB; templates; CNN; hybrid; method
   evaluation
ID EFFICIENT
AB The solutions to many computer vision problems, including that of 6D object pose estimation, are dominated nowadays by the explosion of the learning-based paradigm. In this paper, we investigate 6D object pose estimation in a practical, real-word setting in which a mobile device (smartphone/tablet) needs to be localized in front of a museum exhibit, in support of an augmented-reality application scenario. In view of the constraints and the priorities set by this particular setting, we consider an appropriately tailored classical as well as a learning-based method. Moreover, we develop a hybrid method that consists of both classical and learning based components. All three methods are evaluated quantitatively on a standard, benchmark dataset, but also on a new dataset that is specific to the museum guidance scenario of interest.
C1 [Panteleris, Paschalis; Michel, Damien; Argyros, Antonis] FORTH, Inst Comp Sci, Iraklion, Greece.
   [Argyros, Antonis] Univ Crete, Comp Sci Dept, Iraklion, Greece.
C3 Foundation for Research & Technology - Hellas (FORTH); University of
   Crete
RP Panteleris, P (corresponding author), FORTH, Inst Comp Sci, Iraklion, Greece.
EM padeler@ics.forth.gr
RI Argyros, Antonis/GPK-4775-2022
OI Argyros, Antonis/0000-0001-8230-3192
FU EU; Greek national funds through the Operational Program
   Competitiveness, Entrepreneurship and Innovation, under the call
   RESEARCH - CREATE - INNOVATE [T1E?K - 00502]; project Co4Robots
   [H2020-ICT-2016-1-731869]
FX This work was partially supported by the EU and Greek national funds
   through the Operational Program Competitiveness, Entrepreneurship and
   Innovation, under the call RESEARCH - CREATE - INNOVATE (project
   MuseLearn T1E?K - 00502) and by the H2020-ICT-2016-1-731869 project
   Co4Robots.
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366
   Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hodan T, 2018, LECT NOTES COMPUT SC, V11214, P19, DOI 10.1007/978-3-030-01249-6_2
   Hodan T, 2016, LECT NOTES COMPUT SC, V9915, P606, DOI 10.1007/978-3-319-49409-8_52
   Hu YL, 2019, PROC CVPR IEEE, P3380, DOI 10.1109/CVPR.2019.00350
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Konishi Y, 2016, LECT NOTES COMPUT SC, V9905, P398, DOI 10.1007/978-3-319-46448-0_24
   Li ZG, 2019, IEEE I CONF COMP VIS, P7677, DOI 10.1109/ICCV.2019.00777
   Lourakis Manolis, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P83, DOI 10.1007/978-3-642-39402-7_9
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Muoz E, 2016, IEEE INT CONF ROBOT, P5623, DOI 10.1109/ICRA.2016.7487781
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Park K, 2019, IEEE I CONF COMP VIS, P7667, DOI 10.1109/ICCV.2019.00776
   Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Pitteri G., 2019, ICCV WORKSH, DOI [10.1109/ICCVW.2019.00342, DOI 10.1109/ICCVW.2019.00342]
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sahin C, 2020, IMAGE VISION COMPUT, V96, DOI 10.1016/j.imavis.2020.103898
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tjaden H, 2017, IEEE I CONF COMP VIS, P124, DOI 10.1109/ICCV.2017.23
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Zakharov Sergey., 2019, DPOD: Dense 6D pose object detector in RGB images
NR 30
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 25
PY 2021
VL 2
AR 649784
DI 10.3389/frvir.2021.649784
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UY4
UT WOS:001023244700001
OA gold
DA 2024-07-18
ER

PT J
AU Weech, S
   Calderon, CM
   Barnett-Cowan, M
AF Weech, Seamas
   Calderon, Claudia Martin
   Barnett-Cowan, Michael
TI Sensory Down-Weighting in Visual-Postural Coupling Is Linked With Lower
   Cybersickness
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE sensory re-weighting; vection; self-motion perception; motion sickness;
   virtual reality
ID COMPUTERIZED DYNAMIC POSTUROGRAPHY; GALVANIC VESTIBULAR STIMULATION;
   MOTION SICKNESS; POSTERIOR PARIETAL; MOTOR; INTEGRATION; ADAPTATION;
   CEREBELLUM; SWAY; HABITUATION
AB Sensory dynamics can be re-shaped by environmental interaction, allowing adaptation to altered or unfamiliar conditions that would otherwise provoke challenges for the central nervous system. One such condition occurs in virtual reality, where sensory conflict is thought to induce cybersickness. Although the sensory re-weighting process is likely to underlie adaptation to cybersickness, evidence of a link between sensory re-weighting dynamics and cybersickness is rare. Here, we characterize the relationship between sensory re-weighting in a balance control task and cybersickness. Participants were exposed to visual oscillation while standing in tandem stance. The sway path length of the center of pressure (COP) was measured and averaged for each level of visual oscillation, and a ratio was computed between high and low oscillation magnitudes to reflect the relative contributions of multiple sensory sources of information concerning balance control. Results showed a significant relationship between the magnitude dependency of sway and common sub-scales of cybersickness: disorientation [r((21)) = 0.45, p = 0.028] and oculomotor discomfort [r((21)) = 0.45, p = 0.033]. We conclude that participants who reported less cybersickness were better-able to down-weight visual information at high magnitude oscillations, thus demonstrating a lower dependency between sway and visual magnitude. The results confirm the utility of balance control as an indicator of cybersickness, and support the role of multisensory re-weighting in determining an individual's tolerance to VR applications.
C1 [Weech, Seamas; Calderon, Claudia Martin; Barnett-Cowan, Michael] Univ Waterloo, Dept Kinesiol, Waterloo, ON, Canada.
C3 University of Waterloo
RP Weech, S (corresponding author), Univ Waterloo, Dept Kinesiol, Waterloo, ON, Canada.
EM seamas.weech@mail.mcgill.ca
OI Martin Calderon, Claudia/0000-0003-0930-2913; Weech,
   Seamas/0000-0003-2333-3505
FU Oculus Research; Ontario Research Fund; Canadian Foundation for
   Innovation's John R. Evans Leaders Fund; Natural Sciences and
   Engineering Research Council of Canada
FX This research was supported by grants to MB-C from Oculus Research, the
   Ontario Research Fund, Canadian Foundation for Innovation's John R.
   Evans Leaders Fund, and the Natural Sciences and Engineering Research
   Council of Canada. The sponsors had no influence in the design or
   execution of the current research.
CR Alberts BBGT, 2018, J NEUROPHYSIOL, V119, P1209, DOI 10.1152/jn.00082.2017
   Allison LK, 2006, EXP BRAIN RES, V175, P342, DOI 10.1007/s00221-006-0559-7
   Andersen Richard A, 2003, Adv Neurol, V93, P159
   Angelaki DE, 2008, ANNU REV NEUROSCI, V31, P125, DOI 10.1146/annurev.neuro.31.060407.125555
   [Anonymous], 1975, Motion sickness
   Balk S., 2013, SIMULATOR SICKNESS Q, DOI DOI 10.17077/DRIVINGASSESSMENT.1498
   Balter SGT, 2004, ACTA OTO-LARYNGOL, V124, P690, DOI 10.1080/00016480410017242
   Black FO, 1998, OTOLARYNG HEAD NECK, V118, pS45, DOI 10.1016/S0194-5998(98)70009-9
   BLACK FO, 1995, ACTA OTO-LARYNGOL, P450, DOI 10.3109/00016489509125296
   Block HJ, 2012, NEUROPSYCHOLOGIA, V50, P1766, DOI 10.1016/j.neuropsychologia.2012.03.034
   Bloomberg JJ, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00129
   Brady RA, 2012, EXP BRAIN RES, V220, P1, DOI 10.1007/s00221-012-3109-5
   Bremmer F, 2001, NEURON, V29, P287, DOI 10.1016/S0896-6273(01)00198-2
   BRONSTEIN AM, 1990, BRAIN, V113, P767, DOI 10.1093/brain/113.3.767
   Brooks JX, 2013, CURR BIOL, V23, P947, DOI 10.1016/j.cub.2013.04.029
   Butler JS, 2010, J VISION, V10, DOI 10.1167/10.11.23
   Cao Y, 2002, NEUROLOGY, V59, P72, DOI 10.1212/WNL.59.1.72
   Carver S, 2006, BIOL CYBERN, V95, P123, DOI 10.1007/s00422-006-0069-5
   Clower DM, 1996, NATURE, V383, P618, DOI 10.1038/383618a0
   Cohen J., 1992, Current Directions in Psychological Science, V1, P98, DOI [DOI 10.1111/1467-8721.EP10768783, 10.1111/1467-8721.ep10768783]
   Cullen KE, 2012, TRENDS NEUROSCI, V35, P185, DOI 10.1016/j.tins.2011.12.001
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dilda V, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112131
   Earhart GM, 2002, EXP BRAIN RES, V146, P538, DOI 10.1007/s00221-002-1238-y
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Harris CM, 1998, NATURE, V394, P780, DOI 10.1038/29528
   Horak F., 1996, MD AM PHYSL SOC, P255, DOI DOI 10.1002/CPHY.CP120107
   Jeka JJ, 2008, EXP BRAIN RES, V191, P453, DOI 10.1007/s00221-008-1539-x
   Jeka JJ, 2010, J MOTOR BEHAV, V42, P197, DOI 10.1080/00222895.2010.481693
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kiemel T, 2006, J NEUROPHYSIOL, V95, P1410, DOI 10.1152/jn.01144.2004
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2011, IEEE ENG MED BIO, P2825, DOI 10.1109/IEMBS.2011.6090781
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kitazaki M, 2010, PRESENCE-TELEOP VIRT, V19, P544, DOI 10.1162/pres_a_00017
   Lackner JR, 2005, ANNU REV PSYCHOL, V56, P115, DOI 10.1146/annurev.psych.55.090902.142023
   Medendorp WP, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00377
   MONEY KE, 1970, PHYSIOL REV, V50, P1, DOI 10.1152/physrev.1970.50.1.1
   NASHNER L, 1978, BRAIN RES, V150, P403, DOI 10.1016/0006-8993(78)90291-3
   Oie K., 2005, GAIT POSTURE, V21, pS29
   Oie KS, 2002, COGNITIVE BRAIN RES, V14, P164, DOI 10.1016/S0926-6410(02)00071-X
   Oman CM, 2014, EXP BRAIN RES, V232, P2483, DOI 10.1007/s00221-014-3973-2
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Peterka RJ, 2002, J NEUROPHYSIOL, V88, P1097, DOI 10.1152/jn.2002.88.3.1097
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Sadeghi SG, 2012, J NEUROSCI, V32, P14685, DOI 10.1523/JNEUROSCI.2493-12.2012
   Shahal B, 1999, LARYNGOSCOPE, V109, P1996, DOI 10.1097/00005537-199912000-00019
   Suzuki T, 2012, AM J PHYSIOL-REG I, V302, pR965, DOI 10.1152/ajpregu.00680.2011
   Tal D, 2010, NEUROSCI LETT, V479, P134, DOI 10.1016/j.neulet.2010.05.044
   THACH WT, 1992, ANNU REV NEUROSCI, V15, P403, DOI 10.1146/annurev.ne.15.030192.002155
   Walter HJ, 2019, HUM MOVEMENT SCI, V64, P389, DOI 10.1016/j.humov.2019.03.006
   Webb NA, 2002, AVIAT SPACE ENVIR MD, V73, P351
   Weech S, 2020, DISPLAYS, V64, DOI 10.1016/j.displa.2020.101961
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Weech S, 2017, MULTISENS RES, V30, P65, DOI 10.1163/22134808-00002545
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2
   Yates BJ, 2014, EXP BRAIN RES, V232, P2455, DOI 10.1007/s00221-014-3937-6
NR 64
TC 9
Z9 9
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 2
PY 2020
VL 1
AR 10
DI 10.3389/frvir.2020.00010
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L7BQ6
UT WOS:001024779300001
OA gold
DA 2024-07-18
ER

PT J
AU Pedersen, K
   Musaeus, P
AF Pedersen, Kamilla
   Musaeus, Peter
TI A phenomenological approach to virtual reality in psychiatry education
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; phenomenology; psychiatry education; psychosis;
   psychopathology
ID MEDICAL-EDUCATION; PSYCHOPATHOLOGY; SKILLS; ATTITUDES; BEHAVIOR; WARDS
AB Virtual Reality has emerged as a valuable tool in medical education, primarily for teaching basic sciences and procedural skills. However, its potential in clinical psychiatry, particularly in comprehending the subjective experiences of individuals with mental illness, remains largely untapped. This paper aims to address this gap by proposing a phenomenological-driven approach to the design of virtual reality in psychiatry education. Insights into psychopathology, which involves the systematic study of abnormal experiences as well as self-awareness on behalf of the clinician, demands training. The clinician must develop sensitivity, observational skills, and an understanding of patients' subjective experiences. While integrating the subjective perspective and promoting emotional self-awareness in psychiatry education have been recommended, further research is necessary to effectively harness virtual reality for this purpose. Drawing from the convergence of virtual reality, phenomenological approaches to grasping subjectivity and psychopathology, this paper aims to advance teachings in psychopathology. It underscores the importance of integrating biomedical knowledge with the lived experiences of psychiatric patients to offer learners a comprehensive understanding of clinical psychiatry. This approach is deeply rooted in the theories of three influential figures: Karl Jaspers, a German psychiatrist and philosopher, who emphasized the role of phenomenology in clinical psychiatry; Ludwig Binswanger, a Swiss psychiatrist and psychotherapist, known for his work on existential analysis; and Medard Boss, a Swiss psychiatrist and psychoanalyst, who introduced Daseinsanalysis, focusing on the individual's existence in the world. To facilitate learning in acute psychiatry, a virtual reality scenario was developed. This scenario offers two perspectives: one from the patient's viewpoint, simulating a severe psychotic incident, and the other from the perspective of junior doctors, exposing them to the challenges of communication, decision-making, and stress in a clinical setting. This paper argues that these phenomenological approaches are valuable in helping inform the didactical considerations in the design of the virtual reality scenario, enhancing the learning experience in psychiatry education. It highlights the potential of virtual reality to deepen understanding in the teaching of clinical psychiatry and provides practical insights into its application in an educational context.
C1 [Pedersen, Kamilla; Musaeus, Peter] Aarhus Univ, Ctr Educ Dev, Aarhus, Denmark.
   [Pedersen, Kamilla] Aarhus Univ Hosp Psychiat, Psychosis Res Unit, Aarhus, Denmark.
C3 Aarhus University
RP Pedersen, K (corresponding author), Aarhus Univ, Ctr Educ Dev, Aarhus, Denmark.; Pedersen, K (corresponding author), Aarhus Univ Hosp Psychiat, Psychosis Res Unit, Aarhus, Denmark.
EM Kamilla@au.dk
OI Musaeus, Peter/0000-0001-6062-055X
FU The authors declare that no financial support was received for the
   research, authorship, and/or publication of this article.
FX The authors declare that no financial support was received for the
   research, authorship, and/or publication of this article.
CR Abelman DD, 2017, HARM REDUCT J, V14, DOI 10.1186/s12954-017-0194-6
   Anderson L. W., 2001, A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives
   Andreassen P, 2020, MED EDUC, V54, P296, DOI 10.1111/medu.14045
   [Anonymous], 2013, One century of Karl Jaspers' general psychopathology
   [Anonymous], 2008, Annu. Rev. CyberTherapy Telemedicine, DOI DOI 10.1007/978-3-540-85483-8_40
   Arseneault L, 2021, WORLD PSYCHIATRY, V20, P73, DOI 10.1002/wps.20817
   Ballon Bruce, 2007, Am J Psychother, V61, P211
   Baniasadi Tayebeh, 2020, Oman Med J, V35, pe125, DOI 10.5001/omj.2020.43
   Baron D., 2009, Psychiatry and behavioral science-an introduction and study guide for medical students, P191
   Bateman J, 2013, MED EDUC, V47, P595, DOI 10.1111/medu.12151
   Belitsky C., 1995, Jefferson J. Psychiatry, V12, P37, DOI [10.29046/jjp.012.2.004, DOI 10.29046/JJP.012.2.004]
   Binswanger L., 1958, EXISTENCE, P191, DOI [DOI 10.1037/11321-007, DOI 10.1037/11321]
   Boler M., 1999, Feeling power: Emotions and education
   Bordwell D, 2006, WAY HOLLYWOOD TELLS IT: STORY AND STYLE IN MODERN MOVIES, P1
   BOSS M, 1990, Daseinsanalyse, V7, P167
   Boss M., 1977, Sound. Interdiscip. J, V60, P235
   Bowers L., 2005, J MENT HEALTH, V14, P625, DOI [DOI 10.1080/09638230500389105, 10.1080/09638230500389105]
   Bowers L, 2015, INT J NURS STUD, V52, P1412, DOI 10.1016/j.ijnurstu.2015.05.001
   Bucher J, 2018, STORYTELLING FOR VIRTUAL REALITY: METHODS AND PRINCIPLES FOR CRAFTING IMMERSIVE NARRATIVES, P1
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Cheung JJH, 2018, ADV HEALTH SCI EDUC, V23, P61, DOI 10.1007/s10459-017-9774-1
   Cocks G, 2022, CENT EUR HIST, V55, P528, DOI 10.1017/S0008938921001448
   Courteille O., 2008, Computer Simulations of the Clinical Encounter- Perceptions and Emotional Aspects
   Craig J. R., 2005, The cinema of John carpenter: The technique of terror
   Davis K.W., 2009, J SCHOLARSHIP TEACHI, V9, P70
   de Leon J, 2014, J NERV MENT DIS, V202, P79, DOI 10.1097/NMD.0000000000000092
   DeSantis AD, 2010, SUBST USE MISUSE, V45, P31, DOI 10.3109/10826080902858334
   Dickson S., 2017, The oneiric film: Refocusing the film-dream analogy from an existential phenomenological perspective
   Edelbring S, 2011, ADV HEALTH SCI EDUC, V16, P331, DOI 10.1007/s10459-010-9265-0
   Engel KG, 2022, MED TEACH, V44, P1221, DOI 10.1080/0142159X.2022.2072280
   Formosa NJ, 2018, AUST J PSYCHOL, V70, P57, DOI 10.1111/ajpy.12167
   Foster C, 2007, J ADV NURS, V58, P140, DOI 10.1111/j.1365-2648.2007.04169.x
   Fuchs T, 2009, CURR OPIN PSYCHIATR, V22, P570, DOI 10.1097/YCO.0b013e3283318e5c
   Gask L., 2011, Teaching psychiatry: Putting theory into practice
   Gerup J, 2020, INT J MED EDUC, V11, DOI 10.5116/ijme.5e01.eb1a
   Goldberg JL, 2008, ACAD MED, V83, P715, DOI 10.1097/ACM.0b013e31817eba30
   Graafland M, 2012, BRIT J SURG, V99, P1322, DOI 10.1002/bjs.8819
   Haj-Bolouri A, 2023, COMMUN ASSOC INF SYS, V52, P782, DOI 10.17705/1CAIS.05238
   Halliwell Stephen., 1987, The Poetics of Aristotle: Translation and Commentary
   Hammersley M, 2018, ETHNOGR EDUC, V13, P1, DOI 10.1080/17457823.2017.1298458
   Ho JCF, 2022, BEHAV INFORM TECHNOL, V41, P1185, DOI 10.1080/0144929X.2020.1864018
   Irarrázaval L, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1000059
   JASPERS K, 1968, BRIT J PSYCHIAT, V114, P1313, DOI 10.1192/bjp.114.516.1313
   Jaspers Karl., 1997, General Psychopathology
   Jensen RAA, 2024, ADV HEALTH SCI EDUC, V29, P329, DOI 10.1007/s10459-023-10247-6
   Johansen JD, 2010, INTEGR PSYCHOL BEHAV, V44, P185, DOI 10.1007/s12124-009-9112-0
   Kallivayalil Roy Abraham, 2012, Indian J Psychiatry, V54, P208, DOI 10.4103/0019-5545.102336
   Kampa A., 2016, Entertainment computing and serious games, V1st edn, DOI [10.1007/978-3-319-46152-6, DOI 10.1007/978-3-319-46152-6]
   Kegel LC, 2020, SOC COGN AFFECT NEUR, V15, P347, DOI 10.1093/scan/nsaa039
   Kiesewetter J, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-1987-y
   Kurtz S, 2003, ACAD MED, V78, P802, DOI 10.1097/00001888-200308000-00011
   Lam JT, 2019, CURR PHARM TEACH LEA, V11, P51, DOI 10.1016/j.cptl.2018.09.012
   Laverty SM, 2003, International Journal of Qualitative Methods, V2, P21, DOI DOI 10.1177/160940690300200303
   Leinster S, 2009, MED TEACH, V31, P79, DOI 10.1080/01421590902744936
   Lewis A., 2013, The state of psychiatry (psychology revivals): Essays and addresses
   Libera C. D., 2021, Using 360  immersive videos to assess paranoia in a non-clinical population clinical population, DOI [10.1080/13546805.2021.1956885, DOI 10.1080/13546805.2021.1956885]
   Lindseth A, 2004, SCAND J CARING SCI, V18, P145, DOI 10.1111/j.1471-6712.2004.00258.x
   Makhkamova A., 2019, Augmented reality and virtual reality Changing realities in a dynamic world
   Meyer JHF, 2005, HIGH EDUC, V49, P373, DOI 10.1007/s10734-004-6779-5
   Miron R., 2012, Karl Jaspers: From selfhood to being, DOI [10.1163/9789401208062, DOI 10.1163/9789401208062]
   Moore WA, 2012, INNOV EDUC TEACH INT, V49, P401, DOI 10.1080/14703297.2012.728876
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Needleman J., 1963, BEING IN THE WORLD
   Nicholls D, 2011, J CLIN NURS, V20, P530, DOI 10.1111/j.1365-2702.2010.03504.x
   Nordgaard J, 2013, ACTA PSYCHIAT SCAND, V127, P434, DOI 10.1111/acps.12092
   Nordgaard J, 2013, EUR ARCH PSY CLIN N, V263, P353, DOI 10.1007/s00406-012-0366-z
   Nordt C, 2006, SCHIZOPHRENIA BULL, V32, P709, DOI 10.1093/schbul/sbj065
   Parnas J, 2013, SCHIZOPHRENIA BULL, V39, P270, DOI 10.1093/schbul/sbs153
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pedersen K., 2021, MedEdPublish, V10, P1, DOI [10.15694/mep.2021.000095.1, DOI 10.15694/MEP.2021.000095.1]
   Pedersen K., 2021, Humanist. Psychiatry, V9, P2325
   Pirker J, 2021, IEEE COMPUT GRAPH, V41, P76, DOI 10.1109/MCG.2021.3067999
   Pomata G, 2014, LIT MED, V32, P1
   Priebe S, 2011, EUR PSYCHIAT, V26, P403, DOI 10.1016/j.eurpsy.2010.07.010
   Priyadharshini E, 2012, CAMB J EDUC, V42, P547, DOI 10.1080/0305764X.2012.733344
   Qureshi A, 2017, ACAD PSYCHIATR, V41, P533, DOI 10.1007/s40596-016-0657-1
   Ramirez EJ, 2021, ETHICS INF TECHNOL, V23, P527, DOI 10.1007/s10676-021-09594-y
   Rapuano M, 2023, J CLIN MED, V12, DOI 10.3390/jcm12041339
   Regenbrecht H., 2023, Designing for presence: Embodied interaction in computer-mediated realities, DOI [10.31234/osf.io/cyw23, DOI 10.31234/OSF.IO/CYW23]
   Sanati A, 2020, BJPSYCH ADV, V26, P296, DOI 10.1192/bja.2020.37
   Scholl I, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107828
   Seinfeld S, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1089006
   Shibuya K., 2020, Digital transformation of identity in the age of artificial intelligence, DOI [10.1007/978-981-15-2248-2, DOI 10.1007/978-981-15-2248-2]
   Siricharoen W. V., 2019, The effect of virtual reality as a form of escapism
   Slater M, 2009, ANU PSICOL, V40, P193
   Sora-Domenjó C, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.814565
   Stanghellini G., 2017, Lost in Dialogue: Anthropology, Psychopathology, and Care
   TAYLOR FK, 1967, BRIT J PSYCHIAT, V113, P765, DOI 10.1192/bjp.113.500.765
   Tazakori Z., 2008, Annals of General Psychiatry, V7, pS309, DOI DOI 10.1186/1744-859X-7-S1-S309
   Tufford L, 2012, QUAL SOC WORK, V11, P80, DOI 10.1177/1473325010368316
   Turner V., 1966, The ritual process, the ritual process: Structure and antistructure
   Urresti-Gundlach M, 2017, BMC MED EDUC, V17, DOI 10.1186/s12909-017-1013-1
   Varisco D., 2007, CyberOrient, V2, P26, DOI [10.1002/j.cyo2.20100201.0002, DOI 10.1002/J.CYO2.20100201.0002]
   Ventura S, 2020, CYBERPSYCH BEH SOC N, V23, P667, DOI 10.1089/cyber.2019.0681
   Vernallis Carol., 2007, Medium Cool: Music Videos from Soundies to Cell Phones, P111
   Vindenes J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.656423
   Wijma EM, 2018, AGING MENT HEALTH, V22, P1115, DOI 10.1080/13607863.2017.1348470
   Wing J. K., 2016, Diagnosis Clin. Meas. Psychiatry, P36, DOI [10.1017/cbo9780511666445.005, DOI 10.1017/CBO9780511666445.005]
   Woolley NN, 2007, NURS EDUC TODAY, V27, P73, DOI 10.1016/j.nedt.2006.02.010
   Yakeley J, 2014, PSYCHIATR BULL, V38, P97, DOI 10.1192/pb.bp.113.045260
   Zippel N, 2016, RIV INT FILOS PSICOL, V7, P180, DOI 10.4453/rifp.2016.0019
NR 101
TC 1
Z9 1
U1 7
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 19
PY 2023
VL 4
AR 1259263
DI 10.3389/frvir.2023.1259263
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA W5YE9
UT WOS:001092372800001
OA gold
DA 2024-07-18
ER

PT J
AU Johnson, M
   Tate, AM
   Tate, K
   Laane, SA
   Chang, ZS
   Chapman, SB
AF Johnson, Maria
   Tate, Aaron M.
   Tate, Kathleen
   Laane, Sarah A.
   Chang, Zhengsi
   Chapman, Sandra Bond
TI Charisma™ virtual social training: A digital health platform and
   protocol
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; social cognition; pediatric; digital health; immersion
ID YOUNG-ADULTS; REALITY; AUTISM; REHABILITATION; INTERVENTION; IMMERSION;
   CHILDREN
AB Low immersion virtual reality (LIVR) is a computer-generated, three-dimensional virtual environment that allows for authentic social interactions through a personal avatar, or digital representation of oneself. Lab-based delivery of LIVR social skills intervention has been shown to support social learning through controlled, targeted practice. Recent remote technological advancements allow LIVR-based social skills training to potentially overcome accessibility barriers by delivering to youth in their home. This study investigated the impact of 10-h of Charisma (TM) Virtual Social Training (CHARISMA-VST), a LIVR-based intervention, on social skill changes in children and adolescents who struggle socially via either in-person or remote training protocols. Specifically, the aims examined both the impact of training location (in-person vs remote access) and diagnosis (parent report of autism spectrum disorder (ASD) diagnosis versus parent report of other non-ASD diagnosis) on objective measures of social skill change following CHARISMA-VST. Researchers delivered the CHARISMA-VST via Charisma 1.0, a customized virtual gaming environment. Sixty-seven participants (49 males, 18 females) between the ages of 9-17, with parent reported social challenges, completed 10, 1-h CHARISMA-VST sessions during which nine social cognitive strategies were taught and then practiced within a LIVR environment with interspersed social coaching. Four social cognitive domains were measured pre-post training: emotion recognition, social inferencing, social attribution, and social self-schemata. Results revealed improvements in emotion recognition, social inferencing, social attribution, and social self-schemata with medium to large effect sizes following the CHARISMA-VST. There was no moderating effect of training location on emotion recognition, social inferencing, and social self-schemata, suggesting comparable gains whether participants accessed the technology in their own homes or from a school or specialty center. There was no moderating effect of ASD versus non-ASD diagnosis on performance measures, suggesting CHARISMA-VST may be effective in improving social skills in individuals beyond its initially designed use focused on individuals with ASD. These encouraging findings from this pilot intervention study provide some of the first evidence of potential new virtual technology tools, as exemplified by CHARISMA-VST, to improve one of the most important aspects of human behavior-social skills and human connectedness in youth with a range of social competency challenges.
C1 [Johnson, Maria; Tate, Aaron M.; Tate, Kathleen; Laane, Sarah A.; Chang, Zhengsi; Chapman, Sandra Bond] Univ Texas Dallas, Ctr BrainHealth, Sch Behav & Brain Sci, Dallas, TX 75080 USA.
C3 University of Texas System; University of Texas Dallas
RP Johnson, M (corresponding author), Univ Texas Dallas, Ctr BrainHealth, Sch Behav & Brain Sci, Dallas, TX 75080 USA.
EM Maria.johnson@utdallas.edu
CR Abell F, 2000, COGNITIVE DEV, V15, P1, DOI 10.1016/S0885-2014(00)00014-9
   [Anonymous], 2022, RStudio
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Batastini AB, 2021, CLIN PSYCHOL REV, V83, DOI 10.1016/j.cpr.2020.101944
   Blakemore SJ, 2019, LANCET, V393, P2030, DOI 10.1016/S0140-6736(19)31013-X
   Bowers L., 2008, Social Language Development Test Elementary
   Bowers L., 2010, SOCIAL LANGUAGE DEV
   Brooks BL, 2010, CHILD NEUROPSYCHOL, V16, P80, DOI 10.1080/09297040903146966
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Castelli F, 2000, NEUROIMAGE, V12, P314, DOI 10.1006/nimg.2000.0612
   Cervone D., 2021, HDB PERSONALITY DYNA, P601, DOI DOI 10.1016/B978-0-12-813995-0.00022-4
   Cohen J., 1988, STAT POWER ANAL BEHA
   Dechsling A, 2021, RES DEV DISABIL, V111, DOI 10.1016/j.ridd.2021.103885
   Didehbani N, 2016, COMPUT HUM BEHAV, V62, P703, DOI 10.1016/j.chb.2016.04.033
   Farashi S, 2024, INT J DEV DISABIL, V70, P110, DOI 10.1080/20473869.2022.2063656
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Greenleaf W J, 1994, Artif Intell Med, V6, P289, DOI 10.1016/0933-3657(94)90034-5
   Grinberg AM, 2018, J PALLIAT MED, V21, P103, DOI 10.1089/jpm.2017.0312
   Grinberg AM, 2014, COMPUT HUM BEHAV, V36, P479, DOI 10.1016/j.chb.2014.04.008
   Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950
   Ip HHS, 2018, COMPUT EDUC, V117, P1, DOI 10.1016/j.compedu.2017.09.010
   Jacobson D, 2017, DECIS SCI-J INNOV ED, V15, P42, DOI 10.1111/dsji.12116
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Johnson MT, 2021, FRONT EDUC, V6, DOI 10.3389/feduc.2021.678640
   Kaimara P, 2022, VIRTUAL REAL-LONDON, V26, P697, DOI 10.1007/s10055-021-00563-w
   Kandalaft MR, 2013, J AUTISM DEV DISORD, V43, P34, DOI 10.1007/s10803-012-1544-6
   Kaplan-Rakowski R., 2019, P INN LANG LEARN INT
   Karami B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.665326
   Korkman M., 2007, NEPSY-II: Clinical and interpretive manual
   Kriz W. C., 2003, Simulation & Gaming, V34, P495, DOI 10.1177/1046878103258201
   Malihi M, 2020, AUTISM, V24, P1924, DOI 10.1177/1362361320934214
   MARKUS H, 1977, J PERS SOC PSYCHOL, V35, P63, DOI 10.1037/0022-3514.35.2.63
   Mesa-Gresa P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082486
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   Nijman SA, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2250-0
   Pandey V., 2021, Open Journal of Occupational Therapy (OJOT), V9, P1, DOI DOI 10.15453/2168-6408.1808
   Parsons S, 2016, EDUC RES REV-NETH, V19, P138, DOI 10.1016/j.edurev.2016.08.001
   Pinheiro J, 2021, NLME LINEAR NONLINEA
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rus-Calafell M, 2018, PSYCHOL MED, V48, P362, DOI 10.1017/S0033291717001945
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Standen P.J., 2006, VIRTUAL REAL-LONDON, V10, P241, DOI 10.1007/s10055-006-0042-6
   Tan BL, 2018, ASIAN J PSYCHIATR, V35, P115, DOI 10.1016/j.ajp.2016.06.013
   Wickham H., 2019, J OPEN SOURCE SOFTW, V4, P1686, DOI [10.21105/joss.01686, DOI 10.21105/JOSS.01686]
   Yang YJD, 2017, BEHAV RES THER, V93, P55, DOI 10.1016/j.brat.2017.03.014
   Zhang MY, 2022, BEHAV SCI-BASEL, V12, DOI 10.3390/bs12050138
NR 47
TC 0
Z9 0
U1 3
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 14
PY 2022
VL 3
AR 1004162
DI 10.3389/frvir.2022.1004162
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XG4
UT WOS:001023305000001
OA gold
DA 2024-07-18
ER

PT J
AU Porter, JP
   Robb, A
AF Porter III, John
   Robb, Andrew
TI Lingering effects associated with the consumer use of virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; reddit; lingering effects; long-term use; games;
   qualitative; over time
ID EXPOSURE THERAPY
AB Since the release of the Oculus Rift CV1 in 2016, millions of VR headsets have made their way into consumers' homes. Since then, users have created large quantities of data about their experiences in VR through posts made to online discussion forums. We examine this data to gain insights on what sorts of "lingering effects" users report having experienced after VR, and on the progression of these effects over time. We found three major categories of lingering effects (besides simulator sickness) during our qualitative analysis: perceptual effects, behavioral effects, and changes in dreams. The perceptual and behavioral categories were further divided into sub-themes: disruption of body ownership and proprioception, loss of a sense of depth in the real world, visual aftereffects, the need to verify the reality of the real world through touch, hesitation when moving in the real world, and attempts to apply VR interaction metaphors to real life interactions. Users were nearly unanimous that these lingering effects only occurred after spending at least 1 h in VR, and that these effects completely disappeared several weeks after they first appeared (assuming the user continued to spend time in VR). There was less agreement about how long these effects lasted after exiting a specific VR session. The results of our analysis suggest that users feel that there are no long-term side effects to the use of VR. We pair this analysis with an analysis of interviews conducted with 20 novice users who were loaned Oculus Quest HMDs to use for 4 weeks. Semi-structured interviews with participants further substantiated the findings of our analysis of online discussions.
C1 [Porter III, John; Robb, Andrew] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
C3 Clemson University
RP Porter, JP (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM jjporte@clemson.edu
OI Robb, Andrew/0000-0002-0398-5576
FU NSF [1717937]
FX This work was supported in part by NSF Grant #1717937.
CR Altenhoff BlissM., 2012, P ACM S APPL PERCEPT, V1, P71, DOI DOI 10.1145/2338676.2338691
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Buntain C, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P615, DOI 10.1145/2567948.2579231
   Champney RK, 2007, HUM FACTORS, V49, P491, DOI 10.1518/001872007X200120
   Crochet P, 2011, ANN SURG, V253, P1216, DOI 10.1097/SLA.0b013e3182197016
   de Gortari Angelica B. Ortiz, 2011, International Journal of Cyber Behavior, Psychology and Learning, V1, P15, DOI 10.4018/ijcbpl.2011070102
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Gackenbach J, 2010, COMPUT SCI TECH APPL, P127
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hoffman HG, 2001, CYBERPSYCHOL BEHAV, V4, P565, DOI 10.1089/109493101753235151
   Kolasinski E. M., 1995, 1027 ARM RES I BEH S
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lin JHT, 2017, COMPUT HUM BEHAV, V72, P350, DOI 10.1016/j.chb.2017.02.057
   McLay RN, 2010, CYBERPSYCH BEH SOC N, V13, P37, DOI 10.1089/cyber.2009.0346
   Meehan M., 2001, Physiological Reaction as an Objective Measure of Presence in Virtual Environments
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Ployhart RE, 2010, J MANAGE, V36, P94, DOI 10.1177/0149206309352110
   Poels K, 2015, NEW MEDIA SOC, V17, P1137, DOI 10.1177/1461444814521596
   Porter J, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P405, DOI 10.1145/3242671.3242677
   Segovia KY, 2009, MEDIA PSYCHOL, V12, P371, DOI 10.1080/15213260903287267
   Singer P, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P517, DOI 10.1145/2567948.2576943
   Steed A, 2021, IEEE T VIS COMPUT GR, V27, P4171, DOI 10.1109/TVCG.2021.3106431
   Steinicke F., 2014, P 2 ACM S SPAT US IN, P66
   Taris TW, 2003, SCAND J WORK ENV HEA, V29, P1, DOI 10.5271/sjweh.697
   THOMSON R, 2003, INT J SOCIAL RES MET, V0006
   Van den Bulck J., 2004, DREAMING, V14, P43, DOI [DOI 10.1037/1053-0797.14.1.43, 10.1037/1053-0797.14.1.43]
NR 28
TC 0
Z9 0
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 29
PY 2022
VL 3
AR 880634
DI 10.3389/frvir.2022.880634
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VP0
UT WOS:001023261300001
OA gold
DA 2024-07-18
ER

PT J
AU Juliano, JM
   Phanord, CS
   Liew, SL
AF Juliano, Julia M.
   Phanord, Coralie S.
   Liew, Sook-Lei
TI Visual processing of actions directed towards three-dimensional objects
   in immersive virtual reality may involve holistic processing of object
   shape
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive virtual reality; head-mounted display; virtual 3D grasping;
   vision-for-action; garner interference
ID DEPTH-PERCEPTION; DORSAL; INFORMATION; ATTENTION; STREAMS; VISION
AB Immersive virtual reality using a head-mounted display (HMD-VR) is increasing in use for motor learning and motor skill training. However, it remains unclear how visual information for action is processed in an HMD-VR environment. In the real world, actions towards three-dimensional (3D) objects are processed analytically and are immune to perceptual effects, such as processing object dimensions irrelevant to performing the action (i.e., holistic processing). However, actions towards two-dimensional (2D) objects are processed holistically and are susceptible to perceptual effects. In HMD-VR, distances are often underestimated, and the environment can appear flatter compared to the real world. Thus, actions towards virtual 3D objects in HMD-VR may be processed more like 2D objects and involve holistic processing, which is susceptible to perceptual effects. In an initial study, we used a Garner interference task to examine whether vision-for-action in HMD-VR is processed holistically and hypothesized that vision-for-action towards virtual 3D objects in HMD-VR would result in a Garner interference effect, suggesting holistic processing. We found Garner interference effects for reaction times to reach maximum grip aperture and to complete movement. These results show that visual processing of actions towards virtual 3D objects in HMD-VR may involve holistic processing of object shape. These findings demonstrate that visual information for action in HMD-VR is processed differently compared to real 3D objects and is susceptible to perceptual effects, which could affect motor skill training in HMD-VR.
C1 [Juliano, Julia M.; Liew, Sook-Lei] Univ Southern Calif, Neurosci Grad Program, Los Angeles, CA 90007 USA.
   [Juliano, Julia M.; Phanord, Coralie S.; Liew, Sook-Lei] Univ Southern Calif, Chan Div Occupat Sci & Occupat Therapy, Neural Plast & Neurorehabil Lab, Los Angeles, CA 90007 USA.
   [Liew, Sook-Lei] Univ Southern Calif, Div Biokinesiol & Phys Therapy, Los Angeles, CA USA.
   [Liew, Sook-Lei] Univ Southern Calif, USC Stevens Neuroimaging & Informat Inst, Keck Sch Med, Dept Neurol, Los Angeles, CA USA.
C3 University of Southern California; University of Southern California;
   University of Southern California; University of Southern California
RP Juliano, JM (corresponding author), Univ Southern Calif, Neurosci Grad Program, Los Angeles, CA 90007 USA.; Juliano, JM (corresponding author), Univ Southern Calif, Chan Div Occupat Sci & Occupat Therapy, Neural Plast & Neurorehabil Lab, Los Angeles, CA 90007 USA.
EM juliaang@usc.edu
FU National Center for Medical Rehabilitation Research [NIH K01HD091283];
   National Institute of Neurological Disorders and Stroke [NIH
   R01NS115845]
FX & nbsp;This study was funded by the National Center for Medical
   Rehabilitation Research (NIH K01HD091283) and National Institute of
   Neurological Disorders and Stroke (NIH R01NS115845).
CR Anglin JM, 2017, SCI REP-UK, V7, DOI 10.1038/srep45469
   Ayala N, 2018, EXP BRAIN RES, V236, P2439, DOI 10.1007/s00221-018-5311-6
   Bird JM, 2020, J SPORT PSYCHOL ACTI, V11, P115, DOI 10.1080/21520704.2018.1563573
   Creem SH, 2001, ACTA PSYCHOL, V107, P43, DOI 10.1016/S0001-6918(01)00021-X
   El Jamiy F, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ELECTRO INFORMATION TECHNOLOGY (EIT), P63, DOI [10.1109/EIT.2019.8834182, 10.1109/eit.2019.8834182]
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Freud E, 2018, CORTEX, V98, P34, DOI 10.1016/j.cortex.2017.02.020
   Freud E, 2015, PSYCHON B REV, V22, P1377, DOI 10.3758/s13423-015-0803-x
   Freud E, 2015, PSYCHOL RES-PSYCH FO, V79, P134, DOI 10.1007/s00426-013-0533-5
   Ganel T, 2003, NATURE, V426, P664, DOI 10.1038/nature02156
   Ganel T, 2008, CURR BIOL, V18, pR599, DOI 10.1016/j.cub.2008.04.052
   Ganel T, 2020, PSYCHOL RES-PSYCH FO, V84, P2138, DOI 10.1007/s00426-019-01216-z
   Ganel T, 2015, J VISION, V15, DOI 10.1167/15.8.18
   Ganel T, 2014, J VISION, V14, DOI 10.1167/14.7.11
   Ganel T, 2014, EXP BRAIN RES, V232, P1751, DOI 10.1007/s00221-014-3867-3
   Ganel T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036253
   Geng JJ, 2009, J COGNITIVE NEUROSCI, V21, P1584, DOI 10.1162/jocn.2009.21103
   Goodale MA, 2005, PROG BRAIN RES, V149, P269, DOI 10.1016/S0079-6123(05)49019-6
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Goodale MA, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2014.0337
   Goodale MA, 2011, VISION RES, V51, P1567, DOI 10.1016/j.visres.2010.07.027
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Heath M, 2017, EXP BRAIN RES, V235, P3003, DOI 10.1007/s00221-017-5025-1
   Heath M, 2017, EXP BRAIN RES, V235, P1701, DOI 10.1007/s00221-017-4913-8
   Hibbard PB, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0062-7
   Holmes SA, 2013, BRAIN COGNITION, V82, P18, DOI 10.1016/j.bandc.2013.02.005
   Holzwarth Valentin, 2021, ICVARS 2021: 2021 the 5th International Conference on Virtual and Augmented Reality Simulations, P42, DOI 10.1145/3463914.3463921
   Hornsey RL, 2021, VIRTUAL REAL-LONDON, V25, P1087, DOI 10.1007/s10055-021-00500-x
   Hu B, 2011, J VISION, V11, DOI 10.1167/11.7.23
   Huber T, 2017, SURG ENDOSC, V31, P4472, DOI 10.1007/s00464-017-5500-6
   Jost K, 2016, COGN AFFECT BEHAV NE, V16, P207, DOI 10.3758/s13415-015-0380-5
   Juliano J. M., 2021, RES SQ, DOI [10.21203/rs.3.rs-1139453/v1, DOI 10.21203/RS.3.RS-1139453/V1]
   Juliano JM, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00678-2
   Kelly J. W., 2022, PSYARXIV, P1
   Kelly JW, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.850471
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Levin MF, 2020, EXPERT REV NEUROTHER, V20, P195, DOI [10.1080/14737175.2020.1727741, 10.1007/978-3-030-64455-0_1]
   Mao RDQ, 2021, J SURG RES, V268, P40, DOI 10.1016/j.jss.2021.06.045
   MILNER AD, 1991, BRAIN, V114, P405, DOI 10.1093/brain/114.1.405
   Minini L, 2010, J NEUROPHYSIOL, V104, P169, DOI 10.1152/jn.00790.2009
   Mon-Williams M, 1999, EXP BRAIN RES, V128, P578, DOI 10.1007/s002210050885
   Ozana A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.573352
   Ozana A, 2020, PSYCHOL RES-PSYCH FO, V84, P2144, DOI 10.1007/s00426-019-01210-5
   Ozana A, 2019, EXP BRAIN RES, V237, P2011, DOI 10.1007/s00221-019-05572-5
   Ozana A, 2018, EXP BRAIN RES, V236, P1775, DOI 10.1007/s00221-018-5265-8
   Ozana A, 2018, ATTEN PERCEPT PSYCHO, V80, P564, DOI 10.3758/s13414-017-1443-1
   Ozana A, 2019, PSYCHOL RES-PSYCH FO, V83, P977, DOI 10.1007/s00426-017-0913-3
   Parker AJ, 2007, NAT REV NEUROSCI, V8, P379, DOI 10.1038/nrn2131
   Ping JM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1124, DOI [10.1109/VR.2019.8798174, 10.1109/vr.2019.8798174]
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Thoma V, 2011, NEUROIMAGE, V57, P513, DOI 10.1016/j.neuroimage.2011.04.035
NR 53
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 8
PY 2022
VL 3
AR 923943
DI 10.3389/frvir.2022.923943
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XQ0
UT WOS:001023314600001
OA gold
DA 2024-07-18
ER

PT J
AU Fang, Y
   Qiao, YJ
   Zeng, FR
   Zhang, KK
   Zhao, TS
AF Fang, Ying
   Qiao, Yangjun
   Zeng, Fanrong
   Zhang, Keke
   Zhao, Tiesong
TI A human-in-the-loop haptic interaction with subjective evaluation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptic interaction; subjective evaluation; quality of experience;
   teleoperation; multimedia
AB To date, one of the challenges in Human-Computer Interaction (HCI) is fully immersive multisensory remote physical interaction technologies. The applications of haptic perception in HCI can enrich the interaction details and effectively improve the immersion and realism of interaction. In the human-in-the-loop haptic interaction system, the quality of experience (QoE) of the human operator plays an essential role. However, QoE in haptic interaction is still in its infancy. Based on the typical application scenarios of haptic operation, the paper constructs a haptic-visual interaction framework and analyzes the QoE influencing factors. Through subjective evaluation experiments, the paper establishes a haptic interaction database that can provide a research basis for further exploring the relationship between various influencing factors and interactive QoE.
C1 [Fang, Ying; Zeng, Fanrong; Zhang, Keke; Zhao, Tiesong] Fuzhou Univ, Fujian Key Lab Intelligent Proc & Wireless Transmi, Fuzhou, Peoples R China.
   [Qiao, Yangjun] Sangfor Technol, Shenzhen, Peoples R China.
   [Zhao, Tiesong] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Fuzhou University; Peng Cheng Laboratory
RP Zhao, TS (corresponding author), Fuzhou Univ, Fujian Key Lab Intelligent Proc & Wireless Transmi, Fuzhou, Peoples R China.; Zhao, TS (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.
EM t.zhao@fzu.edu.cn
FU National Science Foundation of China [62171134]; Natural Science
   Foundation of Fujian Province, China [2022J02015]
FX Funding This work was supported in part by the National Science
   Foundation of China (Grant No. 62171134) and in part by the Natural
   Science Foundation of Fujian Province, China (Grant No. 2022J02015).
CR Chaudhari R., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P539, DOI 10.1109/WHC.2011.5945543
   Hamam A, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2540991
   Hamam A, 2013, IEEE T INSTRUM MEAS, V62, P3315, DOI 10.1109/TIM.2013.2272859
   Hoshino S., 2011, P IEEE INT WORKSH TE, P1, DOI [10.1109/CQR.2011.5996082, DOI 10.1109/CQR.2011.5996082]
   Jay C, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1275511.1275514
   Liu MC, 2019, ARTERIOSCL THROM VAS, V39, P48, DOI 10.1161/ATVBAHA.118.311714
   Qi Zeng, 2013, 2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE), P466, DOI 10.1109/GCCE.2013.6664891
   Tasaka S., 2019, IEEE ICC
   Tasaka S, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511202
   Tatematsu A., 2010, Communications Quality and Reliability (CQR), 2010 IEEE International Workshop Technical Committee on, P1, DOI [DOI 10.1109/CQR.2010.5619913, 10.1109/CQR.2010.5619913]
   Xue H., 2019, IEEE 5 INT C MULT BI
   Zhang W., 2019, IEEE 5 INT C MULTIME
   Zhao TS, 2017, IEEE COMMUN SURV TUT, V19, P285, DOI 10.1109/COMST.2016.2619982
NR 13
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 26
PY 2022
VL 3
AR 949324
DI 10.3389/frvir.2022.949324
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0HD4
UT WOS:001020141400001
OA gold
DA 2024-07-18
ER

PT J
AU Elsner, J
   Reinerth, G
   Figueredo, L
   Naceri, A
   Walter, U
   Haddadin, S
AF Elsner, Jean
   Reinerth, Gerhard
   Figueredo, Luis
   Naceri, Abdeldjallil
   Walter, Ulrich
   Haddadin, Sami
TI PARTI-A Haptic Virtual Reality Control Station for Model-Mediated
   Robotic Applications
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptics; virtual reality; robotics; digital twin; simulation; model
   mediated; control; teleoperation
ID COLLISIONS
AB In this paper, we introduce a tele-robotic station called "PARTI" that leverages state-of-the-art robotics and virtual reality technology to enable immersive haptic interaction with simulated and remote environments through robotic avatars. Our hardware-in-the-loop framework integrates accurate multibody system dynamics and frictional contacts with digital twins of our robots in a virtual environment with real-time computational capabilities. This model mediated hardware-in-the-loop approach to robotic control allows a teleoperator to use the PARTI system to teach, evaluate, and control various robotic applications. In the current contribution, we focus on the general system description, integrated simulation and control framework, and a series of experiments highlighting the advantages of our approach.
C1 [Elsner, Jean; Reinerth, Gerhard; Figueredo, Luis; Naceri, Abdeldjallil; Haddadin, Sami] Tech Univ Munich TUM, Munich Inst Robot & Machine Intelligence MIRMI, Munich, Germany.
   [Elsner, Jean; Reinerth, Gerhard; Walter, Ulrich] Tech Univ Munich TUM, Chair Astronaut, TUM Sch Engn & Design, Munich, Germany.
C3 Technical University of Munich; Technical University of Munich
RP Elsner, J (corresponding author), Tech Univ Munich TUM, Munich Inst Robot & Machine Intelligence MIRMI, Munich, Germany.; Elsner, J (corresponding author), Tech Univ Munich TUM, Chair Astronaut, TUM Sch Engn & Design, Munich, Germany.
EM j.elsner@tum.de
RI ; Elsner, Jean/B-4088-2019
OI Figueredo, Luis/0000-0002-0759-3000; Elsner, Jean/0000-0003-2691-0099;
   Haddadin, Sami/0000-0001-7696-4955
FU Lighthouse Initiative Geriatronics by StMWi Bayern
   [IUK-1807-0007//IUK582/001]
FX We would like to thank Nicolas Zunhammer for his valuable contributions
   to earlier prototypes of the PARTI system and Franka Emika for their
   support in developing the hardware. We especially thank Xiao Xu, who
   provided us with valuable feedback for the manuscript. We gratefully
   acknowledge the funding of the Lighthouse Initiative Geriatronics by
   StMWi Bayern (Project X, grant no. IUK-1807-0007//IUK582/001).
CR Balachandran R., 2018, IFAC-PapersOnLine, V51, P486, DOI [10.1016/j.ifacol.2018.11.587, DOI 10.1016/J.IFACOL.2018.11.587]
   Erez T, 2015, IEEE INT CONF ROBOT, P4397, DOI 10.1109/ICRA.2015.7139807
   Gaz C, 2019, IEEE ROBOT AUTOM LET, V4, P4147, DOI 10.1109/LRA.2019.2931248
   Haddadin S, 2017, IEEE T ROBOT, V33, P1292, DOI 10.1109/TRO.2017.2723903
   Hulin Thomas, 2011, IEEE International Conference on Robotics and Automation, P3441
   Kirschner RJ, 2021, IEEE INT C INT ROBOT, P4290, DOI 10.1109/IROS51168.2021.9636329
   Li X, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3066542
   Mitra P, 2007, PRESENCE-VIRTUAL AUG, V16, P367, DOI 10.1162/pres.16.4.367
   Ni DJ, 2017, ROBOTICA, V35, P1958, DOI 10.1017/S0263574716000631
   Petrea RAB, 2021, IEEE IND ELEC, DOI 10.1109/IECON48115.2021.9589424
   Ryu JH, 2007, IEEE INT CONF ROBOT, P3508, DOI 10.1109/ROBOT.2007.364015
   Sagardia M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P153, DOI 10.1145/2993369.2993386
   Schwarz M, 2021, IEEE INT C INT ROBOT, P5312, DOI 10.1109/IROS51168.2021.9636191
   Todorov E, 2014, IEEE INT CONF ROBOT, P6054, DOI 10.1109/ICRA.2014.6907751
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Trobinger M, 2021, IEEE ROBOT AUTOM LET, V6, P5857, DOI 10.1109/LRA.2021.3082012
   Valenzuela-Urrutia D, 2019, J INTELL ROBOT SYST, V96, P387, DOI 10.1007/s10846-019-00988-1
   Xu X, 2016, IEEE ACCESS, V4, P425, DOI 10.1109/ACCESS.2016.2517926
NR 18
TC 1
Z9 1
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 18
PY 2022
VL 3
AR 925794
DI 10.3389/frvir.2022.925794
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TX6
UT WOS:001021845900001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Forster, PP
   Karimpur, H
   Fiehler, K
AF Forster, Pierre-Pascal
   Karimpur, Harun
   Fiehler, Katja
TI Why we Should Rethink Our Approach to Embodiment and Presence
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE body ownership; rubber hand illusion; implied body framework; demand
   characteristics; virtual reality; presence
ID ENHANCES REALISTIC RESPONSE; RUBBER HAND; BODY OWNERSHIP; PHYSIOLOGICAL
   MEASURES; VIRTUAL ENVIRONMENTS; ILLUSION; SENSE; MODEL; LIMB;
   SOMATOPARAPHRENIA
AB When interacting with objects in the environment, it feels natural to have a body which moves in accordance to our intentions. Virtual reality (VR) provides a tool to present users with an alternative virtual body and environment. In VR, humans embody the presented virtual body and feel present in the virtual environment. Thus, embodiment and presence frequently co-occur and share some communalities. Nevertheless, both processes have been hardly considered together. Here, we review the current literature on embodiment and presence and present a new conceptual framework, the Implied Body Framework (IBF), which unifies both processes into one single construct. The IBF can be used to generate new hypotheses to further improve the theoretical conceptualisation of embodiment and presence and thus, facilitate its transfer into application.
C1 [Forster, Pierre-Pascal; Karimpur, Harun; Fiehler, Katja] Justus Liebig Univ, Expt Psychol, Giessen, Germany.
   [Forster, Pierre-Pascal; Karimpur, Harun; Fiehler, Katja] Univ Marburg, Justus Liebig Univ, Ctr Mind Brain & Behav CMBB, Giessen, Germany.
C3 Justus Liebig University Giessen; Philipps University Marburg; Justus
   Liebig University Giessen
RP Fiehler, K (corresponding author), Justus Liebig Univ, Expt Psychol, Giessen, Germany.; Fiehler, K (corresponding author), Univ Marburg, Justus Liebig Univ, Ctr Mind Brain & Behav CMBB, Giessen, Germany.
EM katja.fiehler@psychol.uni-giessen.de
RI Fiehler, Katja/KDO-5211-2024; Karimpur, Harun/D-2966-2018
OI Forster, Pierre-Pascal/0009-0002-5105-3201
CR Abdulkarim Z, 2016, ATTEN PERCEPT PSYCHO, V78, P707, DOI 10.3758/s13414-015-1016-0
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Barbin J, 2016, ANN PHYS REHABIL MED, V59, P270, DOI 10.1016/j.rehab.2016.04.001
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Chancel M., 2022, PREPRINT, DOI [10.31219/osf.io/yh2z7, DOI 10.31219/OSF.IO/YH2Z7]
   Chancel M, 2021, COGNITION, V212, DOI 10.1016/j.cognition.2021.104722
   Chancel M, 2020, ATTEN PERCEPT PSYCHO, V82, P4058, DOI 10.3758/s13414-020-02107-x
   Corneille O., 2022, PREPRINT, DOI [10.31234/osf.io/jqyvx, DOI 10.31234/OSF.IO/JQYVX]
   Crucianelli Laura, 2013, Front Psychol, V4, P703, DOI 10.3389/fpsyg.2013.00703
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Eftekharifar S., 2020, Journal of Perceptual Imaging, V3, p20502, DOI [DOI 10.2352/J.PERCEPT.IMAGING.2020.3.2.020502, 10.2352/J.Percept.Imaging.2020.3.2.020502]
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Ehrsson HH, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28177-z
   Ehrsson HH, 2009, PERCEPTION, V38, P310, DOI 10.1068/p6304
   Ehrsson HH, 2008, BRAIN, V131, P3443, DOI 10.1093/brain/awn297
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Fan CG, 2021, J EXP PSYCHOL HUMAN, V47, P810, DOI 10.1037/xhp0000904
   Fiorio M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62745-x
   Fotopoulou A, 2011, NEUROPSYCHOLOGIA, V49, P3946, DOI 10.1016/j.neuropsychologia.2011.10.011
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Fuchs X, 2016, SCI REP-UK, V6, DOI 10.1038/srep24362
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Guterstam A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213265
   Guterstam A, 2015, SCI REP-UK, V5, DOI 10.1038/srep09831
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Haggard P, 2017, NAT REV NEUROSCI, V18, P197, DOI 10.1038/nrn.2017.14
   Holle H, 2011, COGN NEUROSCI-UK, V2, P171, DOI 10.1080/17588928.2011.603828
   Jenkinson PM, 2013, NEUROPSYCHOLOGIA, V51, P1453, DOI 10.1016/j.neuropsychologia.2013.03.029
   Kalckert A, 2014, CONSCIOUS COGN, V30, P118, DOI 10.1016/j.concog.2014.08.022
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Limanowski J, 2020, CEREB CORTEX, V30, P1637, DOI 10.1093/cercor/bhz192
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Llobera J, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210537
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Lush P, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28178-y
   Lush P, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210911
   Lush P, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18591-6
   Lush P, 2021, COLLABRA-PSYCHOL, V7, DOI 10.1525/collabra.29542
   Lush P, 2020, COLLABRA-PSYCHOL, V6, DOI 10.1525/collabra.325
   Ma K, 2021, EXP BRAIN RES, V239, P2159, DOI 10.1007/s00221-021-06125-5
   Makowski D, 2017, CONSCIOUS COGN, V53, P194, DOI 10.1016/j.concog.2017.06.015
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   Marotta A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168489
   Marucci M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84196-8
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Minsky M, 2010, IEEE SPECTRUM
   Murcia-López M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P747, DOI [10.1109/VR46266.2020.000-6, 10.1109/VR46266.2020.1581156939194]
   Nichols AL, 2008, J GEN PSYCHOL, V135, P151, DOI 10.3200/GENP.135.2.151-166
   Nostadt N, 2020, ACM T HUM-ROBOT INTE, V9, DOI 10.1145/3389210
   O'Kane SH, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0233243
   ORNE MT, 1962, AM PSYCHOL, V17, P776, DOI 10.1037/h0043424
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Peperkorn HM, 2015, COMPUT HUM BEHAV, V48, P542, DOI 10.1016/j.chb.2015.02.028
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Pfister R, 2021, PSYCHON B REV, V28, P827, DOI 10.3758/s13423-020-01854-0
   Preuss N, 2019, J EXP PSYCHOL HUMAN, V45, P209, DOI 10.1037/xhp0000597
   Qu J, 2021, PSYCHON B REV, V28, P1567, DOI 10.3758/s13423-021-01931-y
   Ramachandran VS, 1996, P ROY SOC B-BIOL SCI, V263, P377, DOI 10.1098/rspb.1996.0058
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rauschnabel P. A., 2020, IMPACT VIRTUAL EMBOD, DOI [10.1007/978-3-030-37869-1, DOI 10.1007/978-3-030-37869-1_17]
   Raven J.C., 2003, Raven's Standard Progressive Matrices
   Reader A. T., 2022, PREPRINT, DOI [10.31234/osf.io/d8x9y, DOI 10.31234/OSF.IO/D8X9Y]
   Riemer M, 2019, NEUROSCI BIOBEHAV R, V104, P268, DOI 10.1016/j.neubiorev.2019.07.008
   Rohde M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021659
   Roseboom W, 2022, COLLABRA-PSYCHOL, V8, DOI 10.1525/collabra.32274
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Samad M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117178
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind Valentin, 2020, 26 ACM S VIRT REAL S, P1, DOI [10.1145/3385956.3418941, DOI 10.1145/3385956.3418941]
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Sivasubramaniam AK, 2022, PSYCHOL CONSCIOUS, V9, P356, DOI 10.1037/cns0000284
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Souza V, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3466817
   Steed A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00112
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Talsma D, 2010, TRENDS COGN SCI, V14, P400, DOI 10.1016/j.tics.2010.06.008
   Terkildsen T, 2019, INT J HUM-COMPUT ST, V126, P64, DOI 10.1016/j.ijhcs.2019.02.006
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Tsakiris M, 2010, EXP BRAIN RES, V204, P343, DOI 10.1007/s00221-009-2039-3
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   Uhlmann L, 2020, HUM BRAIN MAPP, V41, P2474, DOI 10.1002/hbm.24958
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Walsh E, 2015, PERCEPTION, V44, P709, DOI 10.1177/0301006615594266
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang FY, 2021, CLIN REHABIL, V35, P1710, DOI 10.1177/02692155211027332
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yu I, 2012, IEEE COMPUT GRAPH, V32, P36, DOI 10.1109/MCG.2012.121
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
NR 110
TC 5
Z9 6
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 4
PY 2022
VL 3
AR 838369
DI 10.3389/frvir.2022.838369
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VX9
UT WOS:001019171300001
OA gold
DA 2024-07-18
ER

PT J
AU Kumaravel, BT
   Hartmann, B
AF Kumaravel, Balasaravanan Thoravi
   Hartmann, Bjoern
TI Interactive Mixed-Dimensional Media for Cross-Dimensional Collaboration
   in Mixed Reality Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE mixed reality; asymmetric interactions; collaboration; guidance;
   mixed-dimensional media; computer supported collaborative work
AB Collaboration and guidance are key aspects of many software tasks. In traditional desktop software, such aspects are well supported through built-in collaboration functions or general-purpose techniques such as screen and video sharing. In Mixed Reality environments, where users carry out actions in a three-dimensional space, collaboration and guidance may also be required. However, other users may or may not be using the same Mixed Reality interface. Users may not have access to the same information, the same visual representation, or the same interaction affordances. These asymmetries make communication and collaboration between users harder. To address asymmetries in Mixed Reality environments, we introduce Interactive Mixed-Dimensional Media. In these media, the visual representation of information streams can be changed between 2D and 3D. Different representations can be chosen automatically, based on context, or through associated interaction techniques that give users control over exploring spatial, temporal, and dimensional levels of detail. This ensures that any information or interaction makes sense across different dimensions, interfaces and spaces. We have deployed these techniques in three different contexts: mixed-reality telepresence for physical task instruction, video-based instruction for VR tasks, and live interaction between a VR user and a non-VR user. From these works, we show that Mixed Reality environments that provide users with interactive mixed-dimensional media interfaces improve performance and user experience in collaboration and guidance tasks.
C1 [Kumaravel, Balasaravanan Thoravi; Hartmann, Bjoern] Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA.
C3 University of California System; University of California Berkeley
RP Kumaravel, BT (corresponding author), Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA.
EM bala@eecs.berkeley.edu
CR Anderson F., 2013, P 26 ANN ACM S US IN, P311, DOI [DOI 10.1145/2501988.2502045, 10.1145/2501988.2502045]
   [Anonymous], 2011, P 24 ANN ACM S US IN
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2003, Proceedings of the 2003 Conference on Human Factors in Computing Systems, DOI [DOI 10.1145/642611.642701, 10.1145/642611.642701]
   Baudisch P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P31, DOI 10.1145/502348.502354
   Bauer M, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P10, DOI 10.1109/ISWC.1998.729524
   Benko H., 2014, P 27 ANN ACM S US IN, P645, DOI DOI 10.1145/2642918.2647402
   Botden SMBI, 2008, SIMUL HEALTHC, V3, P97, DOI 10.1097/SIH.0b013e3181659e91
   Botden SMBI, 2009, SURG ENDOSC, V23, P1693, DOI 10.1007/s00464-008-0144-1
   Budrionis A, 2013, INTERACT J MED RES, V2, P73, DOI 10.2196/ijmr.2611
   Buxton Bill., 2007, MICROSOFT RES, V56, P1
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cheng L.-T., 2004, Computer Supported Cooperative Work Conference Proceedings, P25, DOI 10.1145/1031607.1031612
   Cheng LP, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P797, DOI 10.1145/3126594.3126667
   Chi PY, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P93
   Chiu-Hsuan Wang, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P805, DOI 10.1145/3379337.3415868
   Nguyen C, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P267, DOI 10.1145/3126594.3126659
   D'Angelo S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6245, DOI 10.1145/3025453.3025573
   Dixon M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1525
   Eagan JamesR., 2011, Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology. UIST'11, P225, DOI [10.1145/2047196.2047226, DOI 10.1145/2047196.2047226]
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fraser M., 1999, 99 UIST. Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology, P27, DOI 10.1145/320719.322580
   Fuchs H, 2014, COMPUTER, V47, P46, DOI 10.1109/MC.2014.185
   Greenhalgh C, 2002, P IEEE VIRT REAL ANN, P101, DOI 10.1109/VR.2002.996512
   Grossman T, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1515
   Gugenheimer J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299028
   Gugenheimer J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173628
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Hamilton WA, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1315, DOI 10.1145/2556288.2557048
   Hartmann Jeremy, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P445, DOI 10.1145/3379337.3415849
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Henderson StevenJ., 2007, Augmented reality for maintenance and repair
   Ishii H., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P525, DOI 10.1145/142750.142977
   Ishii H., 1990, CSCW 90 Los Angeles. Proceedings of the Conference on Computer-Supported Cooperative Work, P13, DOI 10.1145/99332.99337
   ISHII H, 1994, COMMUN ACM, V37, P83, DOI 10.1145/179606.179687
   Izadi Izadi Shahram Shahram, Proceedings o f UIST (User Interface Software and Technology), P159, DOI [10.1145/964696.964714, DOI 10.1145/964696.964714, 10.1145/964696.964714 10.1145/964696.964714]
   Johansen Robert, 1988, GroupWare: Computer Support for Business Teams
   Kumar B, 2019, TUTORIVR VIDEO BASED, P1, DOI 10.1007/978-981-13-9016-6_1
   Kumaravel Balasaravanan Thoravi, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P182, DOI 10.1145/3379337.3415827
   Kumaravel BT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517508
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Kunert A., 2014, P 17 ACM C COMPUTER, P1388
   Lessel P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1571, DOI 10.1145/3025453.3025708
   LubomirBourdev ShaiAvidan, 2011, P 24 ANN ACM S USER, P135, DOI DOI 10.1145/2047196.2047213.URL
   Ma SG, 2021, PROC CVPR IEEE, P64, DOI 10.1109/CVPR46437.2021.00013
   Marwecki S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173815
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Murphy-Hill E, 2015, COMPUT SUPP COOP W J, V24, P389, DOI 10.1007/s10606-015-9230-9
   Mysore A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P703, DOI 10.1145/3126594.3126628
   Neider J., 1993, OPENGL PROGRAMMING G
   Pires K., 2015, P 6 ACM MULT SYST C, P225, DOI DOI 10.1145/2713168.2713195
   Ponto K, 2012, IEEE T VIS COMPUT GR, V18, P607, DOI 10.1109/TVCG.2012.41
   Ranjan A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1177
   Smith T., 2013, P 11 EUROPEAN C INTE, P131, DOI [10.1145/2465958.2465971, DOI 10.1145/2465958.2465971]
   Snowdon Dave., 2001, COLLABORATIVE VIRTUA, P3, DOI DOI 10.1007/978-1-4471-0685-2_1
   von Willich J, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P487, DOI 10.1145/3322276.3322334
   Warner J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P435, DOI 10.1145/3242587.3242591
   Xia HJ, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P853, DOI 10.1145/3242587.3242597
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
NR 59
TC 2
Z9 2
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 12
PY 2022
VL 3
AR 766336
DI 10.3389/frvir.2022.766336
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZA9
UT WOS:001019253500001
OA gold
DA 2024-07-18
ER

PT J
AU Zikas, P
   Kateros, S
   Lydatakis, N
   Kentros, M
   Geronikolakis, E
   Kamarianakis, M
   Evangelou, G
   Kartsonaki, I
   Apostolou, A
   Birrenbach, T
   Exadaktylos, AK
   Sauter, TC
   Papapagiannakis, G
AF Zikas, Paul
   Kateros, Steve
   Lydatakis, Nick
   Kentros, Mike
   Geronikolakis, Efstratios
   Kamarianakis, Manos
   Evangelou, Giannis
   Kartsonaki, Ioanna
   Apostolou, Achilles
   Birrenbach, Tanja
   Exadaktylos, Aristomenis K.
   Sauter, Thomas C.
   Papapagiannakis, George
TI Virtual Reality Medical Training for COVID-19 Swab Testing and Proper
   Handling of Personal Protective Equipment: Development and Usability
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; medical training; COVID-19; virtual reality
   application; effective training; swab testing
AB Efficient and riskless training of healthcare professionals is imperative as the battle against the Covid-19 pandemic still rages. Recent advances in the field of Virtual Reality (VR), both in software and hardware level, unlocked the true potential of VR medical education (Hooper et al., The Journal of Arthroplasty, 2019, 34 (10), 2,278-2,283; Almarzooq et al., Virtual learning during the COVID-19 pandemic: a disruptive technology in graduate medical education, 2020; Wayne et al., Medical education in the time of COVID-19, 2020; Birrenbach et al., JMIR Serious Games, 2021, 9 (4), e29586). The main objective of this work is to describe the algorithms, models and architecture of a medical virtual reality simulation aiming to train medical personnel and volunteers in properly performing Covid-19 swab testing and using protective measures, based on a world-standard hygiene protocol. The learning procedure is carried out in a novel and gamified way that facilitates skill transfer from virtual to real world, with performance that matches and even exceeds traditional methods, as shown in detail in (Birrenbach et al., JMIR Serious Games, 2021, 9 (4), e29586). In this work we are providing all computational science methods, models together with the necessary algorithms and architecture to realize this ambitions and complex task verified via an in-depth usability study with year 3-6 medical school students.
C1 [Zikas, Paul; Kateros, Steve; Lydatakis, Nick; Kentros, Mike; Geronikolakis, Efstratios; Kamarianakis, Manos; Evangelou, Giannis; Apostolou, Achilles; Papapagiannakis, George] Inst Comp Sci, Fdn Res & Technol FORTH Greece, Iraklion, Greece.
   [Zikas, Paul; Kateros, Steve; Lydatakis, Nick; Kentros, Mike; Geronikolakis, Efstratios; Kamarianakis, Manos; Evangelou, Giannis; Kartsonaki, Ioanna; Apostolou, Achilles; Papapagiannakis, George] Univ Crete, Dept Comp Sci, Iraklion, Greece.
   [Zikas, Paul; Kateros, Steve; Lydatakis, Nick; Kentros, Mike; Geronikolakis, Efstratios; Kamarianakis, Manos; Evangelou, Giannis; Kartsonaki, Ioanna; Apostolou, Achilles; Papapagiannakis, George] ORamaVR, Iraklion, Greece.
   [Kamarianakis, Manos] Univ Crete, Dept Math & Appl Math, Iraklion, Greece.
   [Birrenbach, Tanja; Exadaktylos, Aristomenis K.; Sauter, Thomas C.] Univ Hosp Bern, Dept Emergency Med, Inselspital, Bern, Switzerland.
C3 University of Crete; University of Crete; University of Bern; University
   Hospital of Bern
RP Kamarianakis, M (corresponding author), Inst Comp Sci, Fdn Res & Technol FORTH Greece, Iraklion, Greece.; Kamarianakis, M (corresponding author), Univ Crete, Dept Comp Sci, Iraklion, Greece.; Kamarianakis, M (corresponding author), ORamaVR, Iraklion, Greece.; Kamarianakis, M (corresponding author), Univ Crete, Dept Math & Appl Math, Iraklion, Greece.
EM kamarianakis@uoc.gr
FU European Regional Development Fund of the European Union; Greek national
   funds through the Operational Program Competitiveness, Entrepreneurship
   and Innovation [T1EDK-01149, T1EDK-01448]; European Union [871793];
   Touring Club Switzerland
FX The CVRSB project was co-financed by European Regional Development Fund
   of the European Union and Greek national funds through the Operational
   Program Competitiveness, Entrepreneurship and Innovation, under the call
   RESEARCH - CREATE-INNOVATE (project codes: T1EDK-01149 and T1EDK-01448).
   The project also received funding from the European Union's Horizon 2020
   research and innovation program under grant agreement No 871793. TS
   holds an endowed professorship supported by the Touring Club
   Switzerland. The sponsor has no influence on the research conducted, in
   particular on the results or the decision to publish.
CR Almarzooq Z., 2020, Virtual learning during the COVID-19 pandemic: a disruptive technology in graduate medical education
   Beam EL, 2011, AM J INFECT CONTROL, V39, P415, DOI 10.1016/j.ajic.2010.07.009
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Besta F. I. I. N. C, 2021, MIND VR VIRTUAL REAL
   Birrenbach T, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29586
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Centers for Disease Control and Prevention, 2019, PROT HEALTHC PERS HA
   CoronaVRus, 2020, CORONAVRUS APPL
   Edigin E, 2020, MED EDUC ONLINE, V25, DOI 10.1080/10872981.2020.1774318
   EonReality, 2021, COVID 19 VIRT RAP TE
   Gil-Gómez JA, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071589
   HART S G, 1988, P139
   Hong KH, 2020, ANN LAB MED, V40, P351, DOI 10.3343/alm.2020.40.5.351
   Hooper J, 2019, J ARTHROPLASTY, V34, P2278, DOI 10.1016/j.arth.2019.04.002
   Hung PP, 2015, CIN-COMPUT INFORM NU, V33, P49, DOI 10.1097/CIN.0000000000000125
   John A, 2017, MED EDUC ONLINE, V22, DOI 10.1080/10872981.2017.1264125
   Kamarianakis M, 2021, LECT NOTES COMPUT SC, V13002, P694, DOI 10.1007/978-3-030-89029-2_52
   Kamarianakis M, 2021, ADV APPL CLIFFORD AL, V31, DOI 10.1007/s00006-021-01151-6
   Kaplan A. D., 2020, EFFECTS VIRTUAL REAL, p0018720820904229
   Kätsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Lapolla P, 2020, POSTGRAD MED J, V96, P375, DOI 10.1136/postgradmedj-2020-137876
   Lerner D., 2020, IMMERSIVE MULTIUSER
   Lewis J. R., 1991, SIGCHI Bulletin, V23, P78, DOI 10.1145/122672.122692
   Mantovani F, 2003, EMERG COMMUNICAT, V5, P167
   Marty FM, 2020, NEW ENGL J MED, V382, DOI [10.1056/NEJMc2015949, 10.1056/NEJMvcm2010260]
   Nagoshi Y, 2019, J EDUC EVAL HEALTH P, V16, DOI 10.3352/jeehp.2019.16.31
   Papagiannakis G., 2020, MAGES 3 0 TYING KNOT, P1, DOI [10.1145/3388536.3407888, DOI 10.1145/3388536.3407888]
   Sauro J., 2011, USER EXPERIENCE MAGA, V10
   Singh RP, 2020, DIABETES METAB SYND, V14, P661, DOI 10.1016/j.dsx.2020.05.011
   SituationCovid, 2021, SITUATIONCOVID OC PA
   Tabatabai Shima, 2020, J Adv Med Educ Prof, V8, P140, DOI 10.30476/jamp.2020.86070.1213
   Usoh M, 2006, Using Presence Questionnaires in Reality, DOI [10.1162/105474600566989, DOI 10.1162/105474600566989]
   Vandenberg O, 2021, NAT REV MICROBIOL, V19, P171, DOI 10.1038/s41579-020-00461-z
   Verbeek JH, 2020, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011621.pub5
   Wayne D. B., 2020, MED ED TIME COVID 19
   World Health Organization, 2009, WHO WHO GUID HAND HL
   Wyllie AL, 2020, NEW ENGL J MED, V383, P1283, DOI 10.1056/NEJMc2016359
   Zhang T, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/18153
   Zikas P, 2020, VISUAL COMPUT, V36, P1965, DOI 10.1007/s00371-020-01919-0
NR 41
TC 3
Z9 3
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 4
PY 2022
VL 2
AR 740197
DI 10.3389/frvir.2021.740197
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TI5
UT WOS:001021830800001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Reski, N
   Alissandrakis, A
   Kerren, A
AF Reski, Nico
   Alissandrakis, Aris
   Kerren, Andreas
TI An Empirical Evaluation of Asymmetric Synchronous Collaboration
   Combining Immersive and Non-Immersive Interfaces Within the Context of
   Immersive Analytics
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE asymmetric user roles; computer-supported cooperative work;
   heterogeneous display and interaction technologies; immersive analytics;
   empirical evaluation; spatio-temporal data exploration; synchronous
   remote collaboration; virtual reality
ID SUS
AB Collaboration is an essential part of data analysis, allowing multiple users to combine their expertise and to debate about the interpretation of data discoveries using their contextual knowledge. The design of collaborative interfaces within the context of Immersive Analytics remains challenging, particularly due to the various user-centered characteristics of immersive technologies. In this article, we present the use case of a system that enables multiple users to synchronously explore the same data in a collaborative scenario that combines immersive and non-immersive interfaces in an asymmetric role setup. Such a setup allows for bridging the gap when applying heterogeneous display and interaction technologies, enabling each analyst to have an independent and different view of the data, while maintaining important collaborative aspects during the joint data exploration. We developed an immersive VR environment (head-mounted display, 3D gestural input) and a non-immersive desktop terminal (monitor, keyboard and mouse) centered around spatio-temporal data exploration. Supported through a real-time communication interface, synchronous collaborative features are integrated in both interfaces, facilitating the users in their ability to establish a shared context and to make spatio-temporal references. We conducted an empirical evaluation with five participant pairs (within-subject design) to investigate aspects of usability, user engagement, and collaboration during a confirmative analysis task. Synthesis of questionnaire results in combination with additional log file analysis, audio activity analysis, and observations, revealed good usability scores, high user engagement, as well as overall close and balanced collaboration of enthusiastic pairs during the task completion independent of their interface type, validating our system approach in general. Further supported through the self-constructed Spatio-Temporal Collaboration Questionnaire, we are able to contribute with discussion and considerations of the presented scenario and the synchronous collaborative features for the design of similar applications.
C1 [Reski, Nico; Alissandrakis, Aris] Linnaeus Univ, Dept Comp Sci & Media Technol, VRxAR Labs, Vaxjo, Sweden.
   [Kerren, Andreas] Linnaeus Univ, Dept Comp Sci & Media Technol, ISOVIS, Vaxjo, Sweden.
   [Kerren, Andreas] Linkoping Univ, Dept Sci & Technol, iVis, Norrkoping, Sweden.
C3 Linnaeus University; Linnaeus University; Linkoping University
RP Reski, N (corresponding author), Linnaeus Univ, Dept Comp Sci & Media Technol, VRxAR Labs, Vaxjo, Sweden.
EM nico.reski@lnu.se
RI Alissandrakis, Aris/F-2265-2015; Kerren, Andreas/AAV-9187-2020
OI Alissandrakis, Aris/0000-0003-4162-6475; Kerren,
   Andreas/0000-0002-0519-2537; Reski, Nico/0000-0001-7485-8649
FU ELLIIT environment for strategic research in Sweden
FX The authors wish to thank Jukka Tyrkkoe for early discussions in regard
   to the user interaction study task, all the participants of the user
   interaction study, as well as the reviewers for their comments that
   helped to improve the manuscript. This work was partially supported
   through the ELLIIT environment for strategic research in Sweden.
CR Aigner W., 2011, HUMAN COMPUTER INTER, DOI DOI 10.1007/978-0-85729-079-3
   Andriessen J. H. E., 2001, COMPUT SUPP COOP W J, P89, DOI [10.1007/978-1-4471-0067-6_6, DOI 10.1007/978-1-4471-0067-6_6]
   [Anonymous], 2017, Good research practice
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Benford S., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P223
   BENFORD S, 1993, PROCEEDINGS OF THE THIRD EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK ( ECSCW 93 ), P109
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Büschel W, 2018, LECT NOTES COMPUT SC, V11190, P95, DOI 10.1007/978-3-030-01388-2_4
   Butcher PWS, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312798
   Casarin Julien, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274298
   Cavallo M, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364242
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cruz A, 2015, INT C COMP SUPP COOP, P419, DOI 10.1109/CSCWD.2015.7230996
   DIX A, 1994, COMP SUPPORT COMP W, P9
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Endsley M. R., 1988, Proceedings of the IEEE 1988 National Aerospace and Electronics Conference: NAECON 1988 (Cat. No.88CH2596-5), P789, DOI 10.1109/NAECON.1988.195097
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Gutwin C., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P207, DOI 10.1145/289444.289495
   Gutwin C., 2002, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V11, P411, DOI 10.1023/A:1021271517844
   Hackathorn R, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P44, DOI 10.1109/IMMERSIVE.2016.7932382
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Heer J, 2007, IEEE CONF VIS ANAL, P171, DOI 10.1109/VAST.2007.4389011
   Nguyen H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1098, DOI [10.1109/VR.2019.8797845, 10.1109/vr.2019.8797845]
   IJsselsteijn Wijnand A, 2013, The Game Experience Questionnaire
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Isenberg T., 2014, P VIS WORKSH DEATH D, P1
   Johansen Robert, 1988, GroupWare: Computer Support for Business Teams
   Khadka R., 2018, P PRACTICE EXPERIENC, P1, DOI [10.1145/3219104.3229283, DOI 10.1145/3219104.3229283]
   Kim K., 2010, Proceedings of the ACM Conference on Interactive Tabletops and Surfaces, P231, DOI DOI 10.1145/1936652.1936694
   Kolence K.W., 1973, ACM SIGMETRICS Perform. Eval. Rev, V2, P31, DOI [10.1145/1113644.1113647, DOI 10.1145/1113644.1113647]
   KOLENCE KW, 1973, ACM SIGMETRICS PERFO, V2, P2, DOI DOI 10.1145/1041613.1041614
   LaValle S.M., 2020, Virtual Reality
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee J, 2020, MULTIMED TOOLS APPL, V79, P979, DOI 10.1007/s11042-019-08220-w
   Lundblad P, 2010, IEEE INT CONF INF VI, P313, DOI 10.1109/IV.2010.51
   Nguyen TV, 2014, CLIN CASE DERMATOL, P1, DOI [10.1007/978-1-4471-4312-3, 10.1109/3DCVE.2014.7160928]
   Norwegian National Committee for Research Ethics in Science and Technology (NENT), 2016, GUID RES ETH SCI TEC
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Peter M., 2018, TAG 15 WORKSH GI FAC, P83
   Pinelle D., 2003, ACM Transactions on Computer-Human Interaction, V10, P281, DOI 10.1145/966930.966932
   Poels K., 2007, D3.3: Game Experience Questionnaire: development of a self-report measure to assess the psychological impact of digital games
   REID G B, 1988, P185
   Reski N., 2020, P 11 NORD C HUM COMP, P1, DOI [10.1145/3419249.3420171, DOI 10.1145/3419249.3420171]
   Reski N., 2020, P 11 NORD C HUM COMP, p5:1, DOI [10.1145/3419249.3420102, DOI 10.1145/3419249.3420102]
   Rheinberg F., 2003, DIAGNOSTIK MOTIVATIO, P261, DOI DOI 10.1007/S11031-008-9102-4
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Skarbez R, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00082
   Snowdon Dave., 2001, COLLABORATIVE VIRTUA, P3, DOI DOI 10.1007/978-1-4471-0685-2_1
   Sugiura Y, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284416
   Thomsen Lui Albak., 2019, Tidsskr. Laring Og Medier LOM, V12, P2019, DOI DOI 10.7146/LOM.V12I20.109391
   Wang X., 2019, P 2019 ACM C HUMAN F, P8
   Ward M., 2015, Interactive data visualization: Foundations, techniques, and applications
   Welsford-Ackroyd F., 2020, 2020 IEEE C VIRT REA, P2, DOI [10.1109/vrw50115.2020.00186, DOI 10.1109/VRW50115.2020.00186]
   Widestrom J., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P165, DOI 10.1145/351006.351035
NR 62
TC 10
Z9 11
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 17
PY 2022
VL 2
AR 743445
DI 10.3389/frvir.2021.743445
PG 29
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SZ0
UT WOS:001021821300001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Tong, LW
   Lindeman, RW
   Regenbrecht, H
AF Tong, Lingwei
   Lindeman, Robert W.
   Regenbrecht, Holger
TI Adaptive Playback Control: A Framework for Cinematic VR Creators to
   Embrace Viewer Interaction
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE cinematic VR; digital storytelling; interaction; 360-degree video;
   framework; authoring tools; virtual reality
ID VIRTUAL-REALITY; EXPERIENCE
AB Content creators have been trying to produce engaging and enjoyable Cinematic Virtual Reality (CVR) experiences using immersive media such as 360-degree videos. However, a complete and flexible framework, like the filmmaking grammar toolbox for film directors, is missing for creators working on CVR, especially those working on CVR storytelling with viewer interactions. Researchers and creators widely acknowledge that a viewer-centered story design and a viewer's intention to interact are two intrinsic characteristics of CVR storytelling. In this paper, we stand on that common ground and propose Adaptive Playback Control (APC) as a set of guidelines to assist content creators in making design decisions about the story structure and viewer interaction implementation during production. Instead of looking at everything CVR covers, we set constraints to focus only at cultural heritage oriented content using a guided-tour style. We further choose two vital elements for interactive CVR: the narrative progression (director vs. viewer control) and visibility of viewer interaction (implicit vs. explicit) as the main topics at this stage. We conducted a user study to evaluate four variants by combining these two elements, and measured the levels of engagement, enjoyment, usability, and memory performance. One of our findings is that there were no differences in the objective results. Combining objective data with observations of the participants' behavior we provide guidelines as a starting point for the application of the APC framework. Creators need to choose if the viewer will have control over narrative progression and the visibility of interaction based on whether the purpose of a piece is to invoke emotional resonance or promote efficient transfer of knowledge. Also, creators need to consider the viewer's natural tendency to explore and provide extra incentives to invoke exploratory behaviors in viewers when adding interactive elements. We recommend more viewer control for projects aiming at viewer's participation and agency, but more director control for projects focusing on education and training. Explicit (vs. implicit) control will also yield higher levels of engagement and enjoyment if the viewer's uncertainty of interaction consequences can be relieved.
C1 [Tong, Lingwei; Lindeman, Robert W.] Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
   [Regenbrecht, Holger] Univ Otago, Dept Informat Sci, Dunedin, New Zealand.
C3 University of Canterbury; University of Otago
RP Tong, LW (corresponding author), Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
EM kris.tong@pg.canterbury.ac.nz
FU HIT Lab NZ; University of Canterbury
FX The authors would like to thank the support of other researchers from
   HIT Lab NZ, University of Canterbury, and research members from the New
   Zealand Science for Technological Innovation National Science Challenge
   (NSC) project Atea.
CR [Anonymous], 2013, Film Art: An Introduction
   [Anonymous], 2005, P 1 AAAI C ART INT I
   [Anonymous], 2017, Journal of Media Practice, DOI DOI 10.1080/14682753.2017.1305838
   Bender S., 2019, Media Practice and Education, V20, P277, DOI [10.1080/25741136.2018.1464743, DOI 10.1080/25741136.2018.1464743]
   Bevan C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300736
   Brewster S., 2017, DESIGNING REAL FEELI
   Carstensdottir E, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'19), DOI 10.1145/3337722.3337730
   Dooley K, 2017, STUD AUSTRALAS CINE, V11, P161, DOI 10.1080/17503175.2017.1387357
   Ferguson C, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103671
   Gödde M, 2018, LECT NOTES COMPUT SC, V10910, P184, DOI 10.1007/978-3-319-91584-5_15
   Gustafsson A., 2009, COMPUT ENTERTAIN, V7, P1, DOI [10.1145/1658866.1658873, DOI 10.1145/1658866.1658873]
   Habgood J, 2018, PROC EUR CONF GAME, P175
   Hassan R, 2020, DIGIT JOURNAL, V8, P195, DOI 10.1080/21670811.2018.1517604
   Ibanez J., 2003, Virtual Reality, V7, P30, DOI 10.1007/s10055-003-0112-y
   Ip HHS, 2019, IEEE T LEARN TECHNOL, V12, P503, DOI 10.1109/TLT.2018.2878700
   Koenitz H., 2015, INTERACTIVE DIGITAL, P91
   Lingwei Tong, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P45, DOI 10.1145/3441000.3441063
   LORCH RF, 1993, J EDUC PSYCHOL, V85, P281, DOI 10.1037/0022-0663.85.2.281
   Lyk PB, 2020, ELECTRON J E-LEARN, V18, P219, DOI [10.34190/EJEL.20.18.3.002, 10.34190/JEL.20.18.3.002]
   Mateas M, 2006, SOCIALLY INTELLIGENT, P221, DOI [10.1007/0-306-47373-9_27, DOI 10.1007/0-306-47373-9_27]
   Moser C, 2015, INT J HUM-COMPUT INT, V31, P146, DOI 10.1080/10447318.2014.986639
   Mulholland Paul, 2013, Interactive Storytelling (Lecture Notes in Computer Science, V8230, P121, DOI 10
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Pagano A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093182
   Pillai Jayesh S., 2019, Proceedings - CVMP 2019: 16th ACM SIGGRAPH European Conference on Visual Media Production, P1, DOI [10.1145/3359998.3369402, DOI 10.1145/3359998.3369402]
   Pope VC, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4468, DOI 10.1145/3025453.3025581
   Rezk AM, 2020, LECT NOTES COMPUT SC, V12497, P178, DOI 10.1007/978-3-030-62516-0_16
   Roth C, 2018, LECT NOTES COMPUT SC, V11318, P93, DOI 10.1007/978-3-030-04028-4_7
   Rothe S, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010019
   Rothe S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1733, DOI [10.1109/VR.2019.8798189, 10.1109/vr.2019.8798189]
   Ryan ML, 2008, LECT NOTES COMPUT SC, V5334, P6, DOI 10.1007/978-3-540-89454-4_2
   Schmitz A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P63, DOI [10.1109/VR46266.2020.1581102716289, 10.1109/VR46266.2020.00-80]
   Sengun S., 2013, LECT NOTES COMPUTER, V8230, P180, DOI [10.1007/978-3-319-02756-2_22, DOI 10.1007/978-3-319-02756-2_22]
   Shah SHH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072248
   Sharaha I., 2016, COMPUTER SCI INFORM, P21, DOI [10.5121/csit.2016.61002, DOI 10.5121/CSIT.2016.61002]
   Sharples M., 2013, MUSEUM COMMUNICATION, P20
   Syrett H, 2017, L N INST COMP SCI SO, V178, P197, DOI 10.1007/978-3-319-49616-0_19
   Tong LW, 2021, COMPUTERS, V10, DOI 10.3390/computers10050066
   Ursu MF, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1412196.1412198
   Verdugo R, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2043612.2043617
   Yu Kaho Albert, 2019, 2019 IEEE 2nd Workshop on Animation in Virtual and Augmented Environments (ANIVAE). Proceedings, P1, DOI 10.1109/ANIVAE47543.2019.9050930
NR 41
TC 3
Z9 3
U1 3
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 14
PY 2022
VL 2
AR 798306
DI 10.3389/frvir.2021.798306
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2UL2
UT WOS:001021859500001
OA gold
DA 2024-07-18
ER

PT J
AU Ouverson, KM
   Scherber, C
   Oldham, E
   Gilbert, SB
AF Ouverson, Kaitlyn Michelle
   Scherber, Carsten
   Oldham, Emily
   Gilbert, Stephen B.
TI What Does "Asymmetric VR" Mean? A Directed Content Analysis of
   Co-Located Use of VR by Users on Reddit
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE asymmetric virtual reality; mixed reality; extended reality; co-located
   technology; online asymmetric VR; directed content analysis; qualitative
   content analysis
ID COLLABORATION; AGREEMENT
AB Technology is often framed in terms of space and time of use, such that a mobile phone is used to either send asynchronous messages or host synchronous conversations with remote others, while a classroom smartboard supports co-located, synchronous learning. As the technology becomes more immersive, the applicability of frameworks such as the time/place matrix becomes less clear. This study attempts to provide clarity by applying the Composite framework for Asymmetric VR (CAVR) to online forum descriptions of the use of immersive virtual reality (VR) in co-located groups. A related framework, Roles of Technology, is also explored; however, the authors argue the framework must be expanded before application of it beyond mobile technology. To better understand one possible solution to co-located VR's isolation problem, a directed content analysis was conducted, exploring the discussion of co-located and asymmetric VR use on various subreddits. As a result, 11 patterns of co-located use of VR, including 8 which specify asymmetric VR designs, are identified. The researchers update the dimensions of CAVR according to these results, compare CAVR to another nascent framework, and offer suggestions for future work and applicability to practice. This work is intended to help guide future creation and research of asymmetric VR experiences through the deconstruction of existing asymmetric VR experiences to their key parts via the application of CAVR.
C1 [Ouverson, Kaitlyn Michelle; Gilbert, Stephen B.] Iowa State Univ, Human Comp Interact, Ames, IA 50011 USA.
   [Scherber, Carsten; Oldham, Emily; Gilbert, Stephen B.] Iowa State Univ, Ind & Mfg Syst Engn, Ames, IA 50011 USA.
C3 Iowa State University; Iowa State University
RP Ouverson, KM; Gilbert, SB (corresponding author), Iowa State Univ, Human Comp Interact, Ames, IA 50011 USA.; Gilbert, SB (corresponding author), Iowa State Univ, Ind & Mfg Syst Engn, Ames, IA 50011 USA.
EM kmo@iastate.edu; gilbert@iastate.edu
RI Gilbert, Stephen/F-3138-2018
OI Gilbert, Stephen/0000-0002-5332-029X
CR [Anonymous], 2019, VR, DOI DOI 10.1145/3290605.3300794
   Basak D., 2016, THESIS NEW YORK U NY
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   Benford Steve, 2012, P SIGCHI C HUM FACT, P2005, DOI [DOI 10.1145/2207676.2208347, 10.1145/2207676.2208347, 10.1145/2207676.2208347event-place:Austin,Texas,USA, DOI 10.1145/2207676.2208347EVENT-PLACE:AUSTIN,TEXAS,USA]
   Bergh DD, 2019, J MANAGE, V45, P122, DOI 10.1177/0149206318798026
   Bradner E, 2005, IEEE T PROF COMMUN, V48, P68, DOI 10.1109/TPC.2004.843299
   Brown Dalvin, 2021, WASH. POST
   Brown JA, 2019, GERONTOL GERIATR MED, V5, DOI 10.1177/2333721419885287
   Bruun-Pedersen JR, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P216, DOI 10.1109/ICHI.2016.31
   Collins K.M. T., 2010, SAGE handbook of mixed methods in social behavioral research: Second edition, P353
   CONGER AJ, 1980, PSYCHOL BULL, V88, P322, DOI 10.1037/0033-2909.88.2.322
   Creswell J. W., 2018, QUAL INQ
   De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207
   Dix A., 2004, Human-Computer Interaction, VThird, P123
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fillmore H., 2020, EXPERT INSIGHTS
   Gamer M., 2012, PACKAGE IRR 0 84 1
   Grasset R, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P90
   Gugenheimer J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173628
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Harris J., 2019, Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI, V19, P1, DOI DOI 10.1145/3290605.3300239
   Harris J, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P350, DOI 10.1145/2967934.2968113
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Hunicke R., 2004, AAAI WORKSHOP TECHNI, P1
   Ibayashi H., 2015, SIGGRAPH ASIA 2015 P, P2, DOI DOI 10.1145/2820926.2820948
   Janson H, 2004, EDUC PSYCHOL MEAS, V64, P62, DOI 10.1177/0013164403260195
   Johansen Robert, 1988, GroupWare: Computer Support for Business Teams
   Karaosmanoglu Sukran, 2021, P 2021 CHI C HUMAN F
   Kaye LK, 2016, COMPUT HUM BEHAV, V55, P286, DOI 10.1016/j.chb.2015.09.023
   Kraus M., 2015, Proceedings of the 2015 Virtual Reality International Conference on ZZZ - VRIC'15, 08-10-Apri, P1, DOI [DOI 10.1145/2806173.2806198, 10.1145/2806173, DOI 10.1145/2806173]
   Krippendorff K., 2018, CONTENT ANAL INTRO I
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Marlow SL, 2017, HUM RESOUR MANAGE R, V27, P575, DOI 10.1016/j.hrmr.2016.12.005
   McKendrick J., 2021, Forbes
   McVeigh-Schultz J., 2018, P 19 INT ACM SIGACCE, V18, P289, DOI DOI 10.1145/3197391.3205451
   Nardi B. A., 2005, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V14, P91, DOI 10.1007/s10606-004-8127-9
   Neeley T., 2021, HARV BUSINESS REV
   Neuendorf K. A., 2017, The content analysis guidebook, V2nd, DOI 10.4135/9781071802878
   Olin Patrick Aggergaard, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P112, DOI 10.1145/3441000.3441070
   Olsson T, 2020, COMPUT SUPP COOP W J, V29, P29, DOI 10.1007/s10606-019-09345-0
   Ouverson Kaitlyn M., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449079
   Patrao B, 2020, INT J ONLINE BIOMED, V16, P43, DOI 10.3991/ijoe.v16i04.11876
   Rivera I., 2019, PACKAGE REDDITEXTRAC
   Rogers E., 2003, The Diffusion of Innovations (Fifth), DOI DOI 10.1007/S10460-007-9072-2
   Rogers K, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694660
   RStudio Team, 2021, RStudio: Integrated development for R (1.4.1106)
   Shao Y., 2019, RABBOT - Exploring Shared Awareness in Virtual Reality [OCAD University]
   Simon A, 2005, LECT NOTES COMPUT SC, V3585, P364, DOI 10.1007/11555261_31
   Sohrab SG, 2015, SMALL GR RES, V46, P489, DOI 10.1177/1046496415599068
   Steed A, 2012, IEEE COMPUT GRAPH, V32, P10, DOI 10.1109/MCG.2012.110
   Steinmacher I, 2010, LECT NOTES COMPUT SC, V6257, P185, DOI 10.1007/978-3-642-15714-1_15
   Thomsen LA., 2019, Tidsskriftet Laring Og Medier (LOM), V12, P1, DOI DOI 10.7146/LOM.V12I20.109391
   Voida A, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P313
NR 53
TC 2
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 10
PY 2021
VL 2
AR 765881
DI 10.3389/frvir.2021.765881
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2RR3
UT WOS:001021787200001
OA gold
DA 2024-07-18
ER

PT J
AU Sun, YL
   Won, AS
AF Sun, Yilu
   Won, Andrea Stevenson
TI Despite Appearances: Comparing Emotion Recognition in Abstract and
   Humanoid Avatars Using Nonverbal Behavior in Social Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; emotion perception; nonverbal communication;
   personality traits; emotional states; expansiveness of gesture; avatars;
   proximity
ID POINT-LIGHT; BODY EXPRESSIONS; PERCEPTION; PERSONALITY; COMMUNICATION;
   ENVIRONMENTS; CHARACTERS; OWNERSHIP; MOVEMENT; MOTION
AB The ability to perceive emotional states is a critical part of social interactions, shaping how people understand and respond to each other. In face-to-face communication, people perceive others' emotions through observing their appearance and behavior. In virtual reality, how appearance and behavior are rendered must be designed. In this study, we asked whether people conversing in immersive virtual reality (VR) would perceive emotion more accurately depending on whether they and their partner were represented by realistic or abstract avatars. In both cases, participants got similar information about the tracked movement of their partners' heads and hands, though how this information was expressed varied. We collected participants' self-reported emotional state ratings of themselves and their ratings of their conversational partners' emotional states after a conversation in VR. Participants' ratings of their partners' emotional states correlated to their partners' self-reported ratings regardless of which of the avatar conditions they experienced. We then explored how these states were reflected in their nonverbal behavior, using a dyadic measure of nonverbal behavior (proximity between conversational partners) and an individual measure (expansiveness of gesture). We discuss how this relates to measures of social presence and social closeness.
C1 [Sun, Yilu; Won, Andrea Stevenson] Cornell Univ, Dept Commun, Ithaca, NY 14850 USA.
C3 Cornell University
RP Won, AS (corresponding author), Cornell Univ, Dept Commun, Ithaca, NY 14850 USA.
EM a.s.won@cornell.edu
CR Andre E., 2000, 4 INT C AUT AG BARC
   Argyle Michael, 2013, Bodily communication
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Bailenson J, 2018, JAMA PEDIATR, V172, P905, DOI 10.1001/jamapediatrics.2018.1909
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Borkenau P, 2004, J PERS SOC PSYCHOL, V86, P599, DOI 10.1037/0022-3514.86.4.599
   CAMPBELL A, 1978, BRIT J SOC CLIN PSYC, V17, P31, DOI 10.1111/j.2044-8260.1978.tb00893.x
   Clarke TJ, 2005, PERCEPTION, V34, P1171, DOI 10.1068/p5203
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dael N, 2013, PERCEPTION, V42, P642, DOI 10.1068/p7364
   Dael N, 2012, EMOTION, V12, P1085, DOI 10.1037/a0025737
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   DEMEIJER M, 1989, J NONVERBAL BEHAV, V13, P247, DOI 10.1007/BF00990296
   Dodds T., 2010, 23 ANN C COMPUTER AN, P1
   Doyle C.M., 2017, The Science of Facial Expression
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Enea V, 2016, SOC NEUROSCI-UK, V11, P495, DOI 10.1080/17470919.2015.1114020
   Facebook, 2019, FAC SPAC
   Fong K, 2015, PERS SOC PSYCHOL B, V41, P237, DOI 10.1177/0146167214562761
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   Garau M., 2003, IMPACT AVATAR FIDELI
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Gunes H, 2007, J NETW COMPUT APPL, V30, P1334, DOI 10.1016/j.jnca.2006.09.007
   Hertenstein MJ, 2009, EMOTION, V9, P566, DOI 10.1037/a0016108
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kobylinski P, 2019, ADV INTELL SYST COMP, V903, P393, DOI 10.1007/978-3-030-11051-2_60
   Koppensteiner M, 2013, J EXP SOC PSYCHOL, V49, P1137, DOI 10.1016/j.jesp.2013.08.002
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Li CJ, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P191, DOI 10.1145/3267851.3267870
   Lorey B, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042169
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   MATTHEWS G, 1990, BRIT J PSYCHOL, V81, P17, DOI 10.1111/j.2044-8295.1990.tb02343.x
   McCleary Richard., 1980, APPL TIME SERIES ANA
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Missana M, 2015, DEVELOPMENTAL SCI, V18, P243, DOI 10.1111/desc.12209
   Montagne B, 2007, PERCEPT MOTOR SKILL, V104, P589, DOI 10.2466/PMS.104.2.589-598
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Nowak KL, 2005, J COMPUT-MEDIAT COMM, V11
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Shaikh O, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P681, DOI 10.1109/VR.2018.8446398
   Shin M, 2019, COMPUT HUM BEHAV, V94, P100, DOI 10.1016/j.chb.2019.01.016
   Sun Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221803
   Tarr B, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21765-4
   Thomas J., 2017, ICAT EGVE AD AUSTR N, P97
   Tickle-Degnen Linda., 1987, Group rapport and nonverbal behavior
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   von der Pütten AM, 2010, LECT NOTES ARTIF INT, V6356, P208, DOI 10.1007/978-3-642-15892-6_23
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wei W. W., 2006, The Oxford Handbook of Quantitative Methods in Psychology, V2
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Won AS, 2018, SOC PSYCHOL PERS SCI, V9, P372, DOI 10.1177/1948550617707017
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yee N., 2008, ARTIFACT J PRACT, V2, P88, DOI [10.1080/17493460903020398, DOI 10.1080/17493460903020398]
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2011, SOC PSYCHOL PERS SCI, V2, P5, DOI 10.1177/1948550610379056
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 66
TC 2
Z9 2
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 27
PY 2021
VL 2
AR 694453
DI 10.3389/frvir.2021.694453
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TE3
UT WOS:001021826600001
OA gold
DA 2024-07-18
ER

PT J
AU Genay, A
   Lécuyer, A
   Hachet, M
AF Genay, Adelaide
   Lecuyer, Anatole
   Hachet, Martin
TI Virtual, Real or Mixed: How Surrounding Objects Influence the Sense of
   Embodiment in Optical See-Through Experiences?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE sense of embodiment; augmented reality; user study; optical see-through;
   mixed reality
ID RUBBER HAND ILLUSION; BODY OWNERSHIP; AUGMENTED REALITY; INTEGRATION
AB This paper studies the sense of embodiment of virtual avatars in Mixed Reality (MR) environments visualized with an Optical See-Through display. We investigated whether the content of the surrounding environment could impact the user's perception of their avatar, when embodied from a first-person perspective. To do so, we conducted a user study comparing the sense of embodiment toward virtual robot hands in three environment contexts which included progressive quantities of virtual content: real content only, mixed virtual/real content, and virtual content only. Taken together, our results suggest that users tend to accept virtual hands as their own more easily when the environment contains both virtual and real objects (mixed context), allowing them to better merge the two "worlds". We discuss these results and raise research questions for future work to consider.
C1 [Genay, Adelaide; Hachet, Martin] Inria Bordeaux Sud Ouest, Talence, France.
   [Genay, Adelaide; Lecuyer, Anatole] Inria Rennes Bretagne Atlantique, Rennes, France.
C3 Universite de Rennes
RP Genay, A (corresponding author), Inria Bordeaux Sud Ouest, Talence, France.; Genay, A (corresponding author), Inria Rennes Bretagne Atlantique, Rennes, France.
EM adelaide.genay@inria.fr
OI Genay, Adelaide/0000-0003-3151-1164
CR Azhar S, 2018, ICERI PROC, P3720
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bailey JO, 2016, PRESENCE-TELEOP VIRT, V25, P222, DOI 10.1162/PRES_a_00263
   Bainbridge W.S., 2004, Berkshire encyclopedia of human-computer interaction, V1
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Beier G., 1999, Report Psychologie, V24, P684
   Braun N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111967
   Costantini M, 2007, CONSCIOUS COGN, V16, P229, DOI 10.1016/j.concog.2007.01.001
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Eckhoff D., 2019, EXPLORING PERCEPTUAL, P4
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Evans Gabriel., 2017, EVALUATING MICROSOFT
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Fribourg R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P273, DOI 10.1109/VR.2018.8448293
   Gilbers C., 2017, THESIS ULTRECHT U UT
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Haans A, 2008, BODY IMAGE, V5, P389, DOI 10.1016/j.bodyim.2008.04.003
   Hachet Martin., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, P587, DOI [DOI 10.1145/2047196.2047273, 10.1145/2047196.2047273]
   Hilliges Otmar, 2012, P SIGCHI C HUMAN FAC, P2421, DOI [10.1145/2207676.2208405, DOI 10.1145/2207676.2208405]
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Javornik A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4838, DOI 10.1145/3025453.3025722
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Kaneko F, 2019, FRONT SYST NEUROSCI, V13, DOI 10.3389/fnsys.2019.00076
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kress B, 2013, PROC SPIE, V8720, DOI 10.1117/12.2015654
   Kurillo G, 2011, STUD HEALTH TECHNOL, V163, P290, DOI 10.3233/978-1-60750-706-2-290
   Lamounier E., 2012, J BIOENGINEER BIOMED, V1, P2
   Levenson H., 1981, Research with the locus of control construct, P15
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Lira M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16137-3
   Lloyd DM, 2007, BRAIN COGNITION, V64, P104, DOI 10.1016/j.bandc.2006.09.013
   Lugrin J.-L., 2015, Anthropomorphism and illusion of virtual body ownership, DOI [10.2312/EGVE.20151303, DOI 10.2312/EGVE.20151303]
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Mölbert SC, 2018, PSYCHOL MED, V48, P642, DOI 10.1017/S0033291717002008
   Nimcharoen C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P158, DOI 10.1109/ISMAR-Adjunct.2018.00057
   Nishino W, 2017, IEEE SYS MAN CYBERN, P1046, DOI 10.1109/SMC.2017.8122749
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Rosa N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1138, DOI [10.1109/vr.2019.8798055, 10.1109/VR.2019.8798055]
   Rossier J, 2002, ANN MED-PSYCHOL, V160, P138, DOI 10.1016/S0003-4487(01)00111-1
   ROTTER JB, 1966, PSYCHOL MONOGR, V80, P1, DOI 10.1037/h0092976
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Skola F, 2016, VISUAL COMPUT, V32, P761, DOI 10.1007/s00371-016-1246-8
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Suzuki K, 2013, NEUROPSYCHOLOGIA, V51, P2909, DOI 10.1016/j.neuropsychologia.2013.08.014
   Tang A., 2004, Proceedings of Presence, Seventh Annual International Workshop on Presence, Valencia, Spain, P204
   Hoang TN, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P253, DOI 10.1145/3196709.3196724
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang K, 2017, IEEE ACCESS, V5, P10700, DOI 10.1109/ACCESS.2017.2711058
   Wolf E., 2020, BODY WEIGHT PERCEPTI
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 58
TC 2
Z9 2
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 4
PY 2021
VL 2
AR 679902
DI 10.3389/frvir.2021.679902
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AR9
UT WOS:001019296700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Liebherr, M
   Mueller, SM
   Schweig, S
   Maas, N
   Schramm, D
   Brand, M
AF Liebherr, Magnus
   Mueller, Silke M.
   Schweig, Stephan
   Maas, Niko
   Schramm, Dieter
   Brand, Matthias
TI Stress and Simulated Environments: Insights From Physiological Marker
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE simulator sickness; aging; stress; simulated environment; driving
   performance
ID DRIVING SIMULATOR; AGE-DIFFERENCES; DRIVER STRESS; DECISION-MAKING;
   ADULT DRIVERS; HEART-RATE; ON-ROAD; PERFORMANCE; RESPONSES; EXPERIENCE
AB Driving in a simulator might induce stress because of the confrontation with new environments, dealing with new technologies, and experience with symptoms of simulator sickness, which, in turn, may influence individuals' driving performance. The present study aims to provide a better understanding of the association between simulated environments and humans' stress level under consideration of age, simulator adaptation, experience with simulator sickness, and driving performance. Data from 164 participants (M = 61.62 years, SD = 12.66 years, ranging from 25 to 89 years, 42 women) were analyzed in the present study. During three measurement times, participants completed an advance first simulator drive (T0), followed by an online survey, assessing experience with simulator sickness (T1), and a second simulator drive (T2) including pre- and post-cortisol measurements. The hypothesized model shows no correlations of driving performance with experience with simulator sickness or stress level before and after a further simulator drive. Beyond the effect of age, previous experience with simulator sickness does further account for stress-level changes following a simulated drive but current driving performance did not. The present study provides relevant findings for future studies in the field of simulated environments.
C1 [Liebherr, Magnus; Mueller, Silke M.; Brand, Matthias] Univ Duisburg Essen, Dept Gen Psychol Cognit, Duisburg, Germany.
   [Liebherr, Magnus; Mueller, Silke M.; Brand, Matthias] Erwin L Hahn Inst Magnet Resonance Imaging, Essen, Germany.
   [Liebherr, Magnus; Schweig, Stephan; Maas, Niko; Schramm, Dieter] Univ Duisburg Essen, Dept Mechatron, Duisburg, Germany.
C3 University of Duisburg Essen; University of Duisburg Essen; University
   of Duisburg Essen
RP Liebherr, M (corresponding author), Univ Duisburg Essen, Dept Gen Psychol Cognit, Duisburg, Germany.; Liebherr, M (corresponding author), Erwin L Hahn Inst Magnet Resonance Imaging, Essen, Germany.; Liebherr, M (corresponding author), Univ Duisburg Essen, Dept Mechatron, Duisburg, Germany.
EM magnus.liebherr@uni-due.de
RI Brand, Matthias/B-1109-2011; Schramm, Dieter Hermann/S-2768-2019
OI Schramm, Dieter Hermann/0000-0002-7945-1853; Mueller, Silke
   M./0000-0002-6627-2661
CR AlAbsi M, 1997, PSYCHOPHYSIOLOGY, V34, P266, DOI 10.1111/j.1469-8986.1997.tb02397.x
   ALDWIN CM, 1991, J GERONTOL, V46, pP174, DOI 10.1093/geronj/46.4.P174
   Andrews EC, 2012, ACCIDENT ANAL PREV, V45, P660, DOI 10.1016/j.aap.2011.09.047
   [Anonymous], 2013, P SIGCHI C HUMAN FAC, DOI [10.1145/2470654.2470703, DOI 10.1145/2470654.2470703]
   Anstey KJ, 2005, CLIN PSYCHOL REV, V25, P45, DOI 10.1016/j.cpr.2004.07.008
   Arthur W, 1998, HUM PERFORM, V11, P57, DOI 10.1207/s15327043hup1101_3
   Arthur W, 2010, HUM PERFORM, V23, P428, DOI 10.1080/08959285.2010.515277
   ASHTON H, 1972, BRIT J PHARMACOL, V45, P532, DOI 10.1111/j.1476-5381.1972.tb08111.x
   Brandtner A, 2019, TRANSPORT RES F-TRAF, V64, P440, DOI 10.1016/j.trf.2019.05.019
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Cabib S, 2012, NEUROSCI BIOBEHAV R, V36, P79, DOI 10.1016/j.neubiorev.2011.04.012
   Cantin V, 2009, ACCIDENT ANAL PREV, V41, P763, DOI 10.1016/j.aap.2009.03.019
   Choukèr A, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010752
   Clapp JD, 2011, J ANXIETY DISORD, V25, P592, DOI 10.1016/j.janxdis.2011.01.008
   Classen S, 2011, AM J OCCUP THER, V65, P179, DOI 10.5014/ajot.2011.000802
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Cohen J, 2002, CURR OPIN NEUROBIOL, V12, P223, DOI 10.1016/S0959-4388(02)00314-8
   Cohen J., 2013, APPL MULTIPLE REGRES
   Cooper JM, 2008, HUM FACTORS, V50, P893, DOI 10.1518/001872008X374983
   Dickerson SS, 2004, PSYCHOL BULL, V130, P355, DOI 10.1037/0033-2909.130.3.355
   Diehl M, 1996, PSYCHOL AGING, V11, P127, DOI 10.1037/0882-7974.11.1.127
   Domeyer JE, 2013, ACCIDENT ANAL PREV, V53, P127, DOI 10.1016/j.aap.2012.12.039
   DORN L, 1995, EUR J PERSONALITY, V9, P25, DOI 10.1002/per.2410090103
   Engström J, 2005, TRANSPORT RES F-TRAF, V8, P97, DOI 10.1016/j.trf.2005.04.012
   EVERSMANN T, 1978, Aviation Space and Environmental Medicine, V49, P53
   FOLKMAN S, 1987, PSYCHOL AGING, V2, P171, DOI 10.1037/0882-7974.2.2.171
   Garcia A., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P1551, DOI [DOI 10.1177/154193121005401941, 10.1518/107118110X12829370088967, DOI 10.1518/107118110X12829370088967]
   Gathmann B, 2014, EXP BRAIN RES, V232, P957, DOI 10.1007/s00221-013-3808-6
   GULIAN E, 1989, ERGONOMICS, V32, P585, DOI 10.1080/00140138908966134
   Hayes A. F., 2013, Introduction to mediation, moderation, and conditional process analysis: a regression -based approach
   Hill JD, 2007, TRANSPORT RES F-TRAF, V10, P177, DOI 10.1016/j.trf.2006.09.002
   Jäncke L, 2008, NEUROREPORT, V19, P1127, DOI 10.1097/WNR.0b013e3283056521
   Jeon M., 2011, Proceedings of the 3rd International Conference on Automotive User Interfaces and Interactive Vehicular Applications, P137, DOI DOI 10.1145/2381416.2381438
   Johnson MJ, 2011, INT J PSYCHOPHYSIOL, V81, P203, DOI 10.1016/j.ijpsycho.2011.06.012
   Joshi SS, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P40, DOI 10.1109/ISCO.2017.7856028
   Juster RP, 2012, STRESS, V15, P569, DOI 10.3109/10253890.2012.661494
   Kalbe E, 2004, INT J GERIATR PSYCH, V19, P136, DOI 10.1002/gps.1042
   Kang NE, 2008, INT J HUM-COMPUT ST, V66, P425, DOI 10.1016/j.ijhcs.2007.12.003
   Kessler J., 2000, Psycho, V26, P343, DOI DOI 10.1016/S0197-4580(00)82813-4
   Konstantopoulos P, 2010, ACCIDENT ANAL PREV, V42, P827, DOI 10.1016/j.aap.2009.09.022
   Large DR, 2018, ADV INTELL SYST, V597, P583, DOI 10.1007/978-3-319-60441-1_57
   Lee HC, 2003, J SAFETY RES, V34, P453, DOI 10.1016/j.jsr.2003.09.007
   Lee HC, 2003, ACCIDENT ANAL PREV, V35, P797, DOI 10.1016/S0001-4575(02)00083-0
   Lee YH, 2003, AVIAT SPACE ENVIR MD, V74, P1078
   LEVENSON RW, 1980, J ABNORM PSYCHOL, V89, P528, DOI 10.1037/0021-843X.89.4.528
   Liebherr M., 2019, TRANSPORTATION RES I, V3, DOI [10.1016/j.trip.2019.100077, DOI 10.1016/J.TRIP.2019.100077]
   Liebherr M, 2020, ERGONOMICS, V63, P1271, DOI 10.1080/00140139.2020.1778095
   Maas N., 2014, 10 INT C MECHATRONIC, P1, DOI 10.1109/mesa.2014
   Maas N., 2017, THESIS UNIVERSITATSB
   MATTHEWS G, 1991, PERS INDIV DIFFER, V12, P535, DOI 10.1016/0191-8869(91)90248-A
   Matthews G, 1998, HUM FACTORS, V40, P136, DOI 10.1518/001872098779480569
   Matthews G, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P579
   Matthews G, 1999, HUM FAC ERG SOC P, P1007
   McEwen Bruce S, 2010, Ann N Y Acad Sci, V1204 Suppl, pE38, DOI 10.1111/j.1749-6632.2010.05568.x
   McEwen BS, 1998, NEW ENGL J MED, V338, P171, DOI 10.1056/NEJM199801153380307
   Nieoullon A, 2002, PROG NEUROBIOL, V67, P53, DOI 10.1016/S0301-0082(02)00011-4
   Otto B, 2006, AUTON NEUROSCI-BASIC, V129, P17, DOI 10.1016/j.autneu.2006.07.010
   Ramos BP, 2007, PHARMACOL THERAPEUT, V113, P523, DOI 10.1016/j.pharmthera.2006.11.006
   Reimer B., 2006, ADV TRANSP STUD SPEC, P9
   Reimer B, 2011, ERGONOMICS, V54, P932, DOI 10.1080/00140139.2011.604431
   Rimini-Doering M., 2001, P 1 INT DRIV S HUM F, P58
   Roenker DL, 2003, HUM FACTORS, V45, P218, DOI 10.1518/hfes.45.2.218.27241
   Ronen A, 2013, TRANSPORT RES F-TRAF, V18, P94, DOI 10.1016/j.trf.2012.12.007
   ROSCOE AH, 1992, BIOL PSYCHOL, V34, P259, DOI 10.1016/0301-0511(92)90018-P
   Sahami S, 2009, TRANSPORT RES REC, P94, DOI 10.3141/2138-13
   Schwabe L, 2008, NEUROBIOL LEARN MEM, V90, P44, DOI 10.1016/j.nlm.2008.02.002
   Siu OL, 2003, INT J PSYCHOL, V38, P337, DOI 10.1080/00207590344000024
   Stanney K. M., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2114
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Starcke K, 2008, BEHAV NEUROSCI, V122, P1352, DOI 10.1037/a0013281
   Sterling P., 1988, Handbook of Life Stress, Cognition and Health, January 1988, DOI [DOI 10.1016/0005-7967(90)90076-U, 10.1016/s0018-506x(02)00024-7]
   Sterling P, 2012, PHYSIOL BEHAV, V106, P5, DOI 10.1016/j.physbeh.2011.06.004
   Struthers CW, 2000, RES HIGH EDUC, V41, P581, DOI 10.1023/A:1007094931292
   Thapa R, 2015, TRAFFIC INJ PREV, V16, P461, DOI 10.1080/15389588.2014.969803
   Thiffault P, 2003, ACCIDENT ANAL PREV, V35, P381, DOI 10.1016/S0001-4575(02)00014-3
   Thomée S, 2007, COMPUT HUM BEHAV, V23, P1300, DOI 10.1016/j.chb.2004.12.007
   Uchiyama Y, 2003, NEUROSCI LETT, V352, P199, DOI 10.1016/j.neulet.2003.08.072
   Ungs T. J., 1987, PROC HUM FACTORS SOC, V31, P505, DOI [10.1177/154193128703100505, DOI 10.1177/154193128703100505]
   von Mammen S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P325, DOI 10.1145/2993369.2996349
   Westman M, 1996, WORK STRESS, V10, P165, DOI 10.1080/02678379608256795
   Wolf OT, 2019, ROUT INT HANDB, P441
   Wolf OT, 2009, BRAIN RES, V1293, P142, DOI 10.1016/j.brainres.2009.04.013
   Wolf OT, 2001, PSYCHONEUROENDOCRINO, V26, P711, DOI 10.1016/S0306-4530(01)00025-7
   Wood JM, 2002, HUM FACTORS, V44, P482, DOI 10.1518/0018720024497664
   Yamaguchi M, 2007, J INT MED RES, V35, P91, DOI 10.1177/147323000703500109
   Ylonen H, 1997, AVIAT SPACE ENVIR MD, V68, P601
NR 86
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 21
PY 2021
VL 2
AR 618855
DI 10.3389/frvir.2021.618855
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TY0
UT WOS:001021846300001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Joyner, JS
   Vaughn-Cooke, M
   Benz, HL
AF Joyner, Janell S.
   Vaughn-Cooke, Monifa
   Benz, Heather L.
TI Comparison of Dexterous Task Performance in Virtual Reality and
   Real-World Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE activities of daily living; performance metrics; virtual task
   environment; upper limb prosthesis; functional performance
ID BLOCKS TEST; DEKA ARM; LIMB; PROSTHESES; OPTIMIZE; HAND; BOX;
   RESPONSIVENESS; INTERVENTIONS; INDIVIDUALS
AB Virtual reality is being used to aid in prototyping of advanced limb prostheses with anthropomorphic behavior and user training. A virtual version of a prosthesis and testing environment can be programmed to mimic the appearance and interactions of its real-world counterpart, but little is understood about how task selection and object design impact user performance in virtual reality and how it translates to real-world performance. To bridge this knowledge gap, we performed a study in which able-bodied individuals manipulated a virtual prosthesis and later a real-world version to complete eight activities of daily living. We examined subjects' ability to complete the activities, how long it took to complete the tasks, and number of attempts to complete each task in the two environments. A notable result is that subjects were unable to complete tasks in virtual reality that involved manipulating small objects and objects flush with the table, but were able to complete those tasks in the real world. The results of this study suggest that standardization of virtual task environment design may lead to more accurate simulation of real-world performance.
C1 [Joyner, Janell S.; Vaughn-Cooke, Monifa] Univ Maryland College Pk, Dept Mech Engn, College Pk, MD 20742 USA.
   [Joyner, Janell S.; Benz, Heather L.] US Food & Drug Adm Ctr Devices & Radiol Hlth, Ctr Devices & Radiol Hlth, Off Sci & Engn Labs, Silver Spring, MD 20993 USA.
   [Joyner, Janell S.] Oak Ridge Inst Sci & Educ, Oak Ridge, TN 37830 USA.
C3 University System of Maryland; University of Maryland College Park; US
   Food & Drug Administration (FDA); Oak Ridge Associated Universities;
   United States Department of Energy (DOE); Oak Ridge Institute for
   Science & Education
RP Joyner, JS (corresponding author), Univ Maryland College Pk, Dept Mech Engn, College Pk, MD 20742 USA.; Joyner, JS (corresponding author), US Food & Drug Adm Ctr Devices & Radiol Hlth, Ctr Devices & Radiol Hlth, Off Sci & Engn Labs, Silver Spring, MD 20993 USA.; Joyner, JS (corresponding author), Oak Ridge Inst Sci & Educ, Oak Ridge, TN 37830 USA.
EM jjoyner2@terpmail.umd.edu
RI Vaughn-Cooke, Monifa/JRX-4059-2023; Benz, Heather L/JBJ-6744-2023
OI Vaughn-Cooke, Monifa/0000-0003-3577-3321; 
FU Defense Advanced Research Projects Agency (DARPA) BTO through the
   DARPA-FDA IAA [224-14-6009]
FX This work was sponsored by the Defense Advanced Research Projects Agency
   (DARPA) BTO through the DARPA-FDA IAA No. 224-14-6009.
CR Armiger R. S., 2011, J HOPKINS APL TECH D
   Belter JT, 2013, J REHABIL RES DEV, V50, P599, DOI 10.1682/JRRD.2011.10.0188
   Biddiss E, 2007, AM J PHYS MED REHAB, V86, P977, DOI 10.1097/PHM.0b013e3181587f6c
   Biddiss E, 2007, DISABIL REHABIL-ASSI, V2, P346, DOI 10.1080/17483100701714733
   Biddiss EA, 2007, PROSTHET ORTHOT INT, V31, P236, DOI 10.1080/03093640600994581
   Blana D, 2016, J ELECTROMYOGR KINES, V29, P21, DOI 10.1016/j.jelekin.2015.06.010
   Bloomer Conor, 2018, Phys Med Rehabil Res, V3, P1
   Carey SL, 2009, PROSTHET ORTHOT INT, V33, P179, DOI 10.1080/03093640802613229
   Carruthers G, 2008, CONSCIOUS COGN, V17, P1302, DOI 10.1016/j.concog.2008.02.001
   Ciocarlie M., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4122, DOI 10.1109/IROS.2005.1545525
   Cordella F, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00209
   Cornwell AS, 2012, J REHABIL RES DEV, V49, P395, DOI 10.1682/JRRD.2011.03.0040
   Davoodi R., 2004, 26 ANN INT C IEEE EN
   Davoodi R, 2011, STUD HEALTH TECHNOL, V163, P156, DOI 10.3233/978-1-60750-706-2-156
   Dosen S, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0047-z
   Gamberini L, 2000, CYBERPSYCHOL BEHAV, V3, P337, DOI 10.1089/10949310050078779
   George JA, 2020, J NEUROSCI METH, V330, DOI 10.1016/j.jneumeth.2019.108462
   Giboin LS, 2015, HUM MOVEMENT SCI, V44, P22, DOI 10.1016/j.humov.2015.08.012
   Harada Akitoshi, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P273, DOI 10.1109/ICAL.2010.5585294
   Haverkate L, 2016, PROSTHET ORTHOT INT, V40, P109, DOI 10.1177/0309364614554030
   Hebert JS, 2014, J REHABIL RES DEV, V51, P919, DOI 10.1682/JRRD.2013.10.0228
   Hebert JS, 2012, J REHABIL RES DEV, V49, P1163, DOI 10.1682/JRRD.2011.10.0207
   Hignett S., 2019, INTEGRATING MACRO MI
   Hofmann M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1769, DOI 10.1145/2858036.2858340
   Holl M., 2018, EFFICIENT PHYS BASED, DOI [10.1109/VR.2018.8448284, DOI 10.1109/VR.2018.8448284]
   Hoshigawa S, 2015, IEEE ENG MED BIO, P4781, DOI 10.1109/EMBC.2015.7319463
   Hussaini A, 2017, PROSTHET ORTHOT INT, V41, P286, DOI 10.1177/0309364616660248
   Iturrate I, 2018, NEUROIMAGE, V181, P635, DOI 10.1016/j.neuroimage.2018.07.055
   Ivorra E., 2018, MULTIMODAL COMPUTER, DOI [10.1109/METROI4.2018.8428330, DOI 10.1109/METROI4.2018.8428330]
   Katyal K. D., 2014, COLLABORATIVE BCI AP, DOI [10.1109/SMC.2014.6974124, DOI 10.1109/SMC.2014.6974124]
   Katyal KD, 2013, I IEEE EMBS C NEUR E, P1274, DOI 10.1109/NER.2013.6696173
   Kearns NT, 2018, ARCH PHYS MED REHAB, V99, P1789, DOI 10.1016/j.apmr.2018.04.021
   Kim JS, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P994, DOI 10.1109/IROS.2016.7759170
   Kluger DT, 2019, IEEE T NEUR SYS REH, V27, P876, DOI 10.1109/TNSRE.2019.2908817
   Kontson K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177965
   Kumar AR, 2019, 2019 DESIGN OF MEDICAL DEVICES CONFERENCE, DOI 10.1115/DMD2019-3242
   Kumar V, 2015, IEEE-RAS INT C HUMAN, P657, DOI 10.1109/HUMANOIDS.2015.7363441
   Lambrecht Joris M, 2011, J Prosthet Orthot, V23, P89
   Levin MF, 2015, IEEE T NEUR SYS REH, V23, P1047, DOI 10.1109/TNSRE.2014.2387412
   Lim J. H., 2019, C NEUR INF PROC SYST
   Lin J., 2016, SIGGRAPH ASIA 2016 V, P1
   Lin KC, 2010, J REHABIL RES DEV, V47, P563, DOI 10.1682/JRRD.2009.09.0155
   MATHIOWETZ V, 1985, AM J OCCUP THER, V39, P386, DOI 10.5014/ajot.39.6.386
   McGimpsey G., 2017, Limb Prosthetics Services and Devices
   McMahan Ryan P., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P59, DOI 10.1007/978-3-319-39907-2_6
   McMullen DP, 2014, IEEE T NEUR SYS REH, V22, P784, DOI 10.1109/TNSRE.2013.2294685
   Miranda RA, 2015, J NEUROSCI METH, V244, P52, DOI 10.1016/j.jneumeth.2014.07.019
   Nakamura G, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417728452
   Newell K.M., 1996, RES ECOL PS, P393
   Nissler C, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf35f
   Odette K., 2019, PHYS BASED VIRTUAL R
   Odhner LU, 2013, IEEE T AUTOM SCI ENG, V10, P625, DOI 10.1109/TASE.2013.2240298
   Park Jungle, 2010, INT C CONTR AUT SYST
   Patrick J, 2000, INSTR SCI, V28, P51, DOI 10.1023/A:1003583420137
   Perry BN, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00785
   Phelan I, 2015, P IEEE VIRT REAL ANN, P353, DOI 10.1109/VR.2015.7223441
   Polygerinos P, 2015, INT C REHAB ROBOT, P55, DOI 10.1109/ICORR.2015.7281175
   Pons JL, 2005, ROBOTICA, V23, P311, DOI 10.1017/S026357470400133X
   Prahm C, 2018, PM&R, V10, P1252, DOI 10.1016/j.pmrj.2018.09.027
   Prahm C, 2017, JMIR SERIOUS GAMES, V5, DOI 10.2196/games.6026
   Radhakrishnan M., 2019, DESIGN ASSESSMENT MY
   Reilly M, 2020, J BIOMECH, V108, DOI 10.1016/j.jbiomech.2020.109843
   Resnik L, 2018, PROSTHET ORTHOT INT, V42, P534, DOI 10.1177/0309364617729924
   Resnik L, 2014, PROSTHET ORTHOT INT, V38, P456, DOI 10.1177/0309364613506914
   Resnik L, 2014, J REHABIL RES DEV, V51, P27, DOI 10.1682/JRRD.2013.03.0068
   Resnik L, 2014, J REHABIL RES DEV, V51, P15, DOI 10.1682/JRRD.2013.02.0056
   Resnik L, 2013, ARCH PHYS MED REHAB, V94, P488, DOI 10.1016/j.apmr.2012.10.004
   Resnik L, 2012, ARCH PHYS MED REHAB, V93, P710, DOI 10.1016/j.apmr.2011.11.010
   Resnik L, 2011, J REHABIL RES DEV, V48, P707, DOI 10.1682/JRRD.2010.07.0127
   Resnik LJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191326
   Salvendy G., 2012, Handbook of human factors and ergonomics, V4, DOI [10.1002/9781118131350, DOI 10.1002/9781118131350]
   Sears ED, 2010, J HAND SURG-AM, V35A, P30, DOI 10.1016/j.jhsa.2009.09.008
   Stachowsky M, 2016, IEEE-ASME T MECH, V21, P2214, DOI 10.1109/TMECH.2016.2551557
   Stickel C, 2010, LECT NOTES COMPUT SC, V6389, P278
   Stone RJ, 2001, LECT NOTES COMPUT SC, V2058, P1
   Tabor A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1352, DOI 10.1145/3025453.3025676
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Valevicius AM, 2020, CLIN BIOMECH, V72, P122, DOI 10.1016/j.clinbiomech.2019.12.002
   van der Laan TMJ, 2019, J HAND THER, V32, P368, DOI 10.1016/j.jht.2017.12.003
   van der Riet D., 2013, AFR POINT PIM MAUR, DOI [10.1109/AFRCON.2013.6757590, DOI 10.1109/AFRCON.2013.6757590]
   van Dijk L, 2016, IEEE T NEUR SYS REH, V24, P1384, DOI 10.1109/TNSRE.2015.2502424
   Wang S, 2018, PM&R, V10, P951, DOI 10.1016/j.pmrj.2018.02.008
   Wang W, 2017, SOFT ROBOT, V4, P379, DOI 10.1089/soro.2016.0081
   Woodward R. B., 2018, ROBUST PATTERN RECOG, DOI [10.1109/EMBC.2018.8513183, DOI 10.1109/EMBC.2018.8513183]
   Zheng Joshua Z., 2011, IEEE International Conference on Robotics and Automation, P4169
   Ziegler-Graham K, 2008, ARCH PHYS MED REHAB, V89, P422, DOI 10.1016/j.apmr.2007.11.005
   Zuniga Jorge, 2015, BMC Res Notes, V8, P10, DOI 10.1186/s13104-015-0971-9
NR 87
TC 6
Z9 7
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 20
PY 2021
VL 2
AR 599274
DI 10.3389/frvir.2021.599274
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WP9
UT WOS:001023288500001
OA gold
DA 2024-07-18
ER

PT J
AU Pimentel, D
   Foxman, M
   Davis, DZ
   Markowitz, DM
AF Pimentel, Daniel
   Foxman, Maxwell
   Davis, Donna Z. Z.
   Markowitz, David M. M.
TI Virtually Real, But Not Quite There: Social and Economic Barriers to
   Meeting Virtual Reality's True Potential for Mental Health
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE coronavirus; social connection; COVID-19; loneliness; mental health;
   virtual reality
ID EXPOSURE THERAPY; LONELINESS; STRESS; ANXIETY
AB Strategies to mitigate the spread of COVID-19, namely quarantine and social distancing protocols, have exposed a troubling paradox: mandated isolation meant to preserve well-being has inadvertently contributed to its decline. Prolonged isolation has been associated with widespread loneliness and diminished mental health, with effects compounded by limited face-to-face access to clinical and social support systems. While remote communication technologies (e.g., video chat) can connect individuals with healthcare providers and social networks, remote technologies might have limited effectiveness in clinical and social contexts. In this review, we articulate the promise of Virtual Reality as a conduit to clinical resources and social connection. Furthermore, we outline various social and economic factors limiting the virtual reality industry's ability to maximize its potential to address mental health issues brought upon by the pandemic. These barriers are delineated across five dimensions: sociocultural, content, affordability, supply chain, and equitable design. After examining potential short- and long-term solutions to these hurdles, we outline potential avenues for applied and theoretical research seeking to validate these solutions. Through this evaluation we seek to (a) emphasize virtual reality's capacity to improve mental health by connecting communities to clinical and social support systems, (b) identify socioeconomic barriers preventing users from accessing these systems through virtual reality, and (c) discuss solutions that ensure these systems can be equitably accessed via changes to existing and future virtual reality infrastructures.
C1 [Pimentel, Daniel; Davis, Donna Z. Z.] Univ Oregon, Sch Journalism & Commun, Oregon Real Lab, Portland, OR 97209 USA.
   [Pimentel, Daniel; Foxman, Maxwell; Davis, Donna Z. Z.; Markowitz, David M. M.] Univ Oregon, Sch Journalism & Commun, Eugene, OR 97403 USA.
C3 University of Oregon; University of Oregon
RP Pimentel, D (corresponding author), Univ Oregon, Sch Journalism & Commun, Oregon Real Lab, Portland, OR 97209 USA.; Pimentel, D (corresponding author), Univ Oregon, Sch Journalism & Commun, Eugene, OR 97403 USA.
EM pimend@uoregon.edu
RI Foxman, Maxwell/IXD-9933-2023
OI Foxman, Maxwell/0000-0001-6499-4372; Pimentel,
   Daniel/0000-0002-7512-4484
CR Bahng S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376582
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Baranowski T, 2016, GAMES HEALTH J, V5, P1, DOI 10.1089/g4h.2015.0026
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Cacioppo J. T, 2008, Loneliness: Human nature and the need for social connection, P317
   Cacioppo S, 2015, PERSPECT PSYCHOL SCI, V10, P238, DOI 10.1177/1745691615570616
   Chia A, 2020, INTERNET POLICY REV, V9, DOI 10.14763/2020.4.1515
   Connolly SL, 2020, CLIN PSYCHOL-SCI PR, V27, DOI 10.1111/cpsp.12311
   Consalvo Mia, 2009, Cheating: Gaining Advantage in Videogames
   Cook DM, 2019, PROCEEDINGS OF CHIUXID 2019: 5TH INTERNATIONAL ACM IN-COOPERATION HCI AND UX CONFERENCE, P147, DOI 10.1145/3328243.3328262
   Crawford J., 2020, J APPL LEARNING TEAC, V3, P1, DOI [DOI 10.37074/JALT.2020.3.1.7, https://doi.org/10.37074/jalt.2020.3.1.7]
   Czeisler MÉ, 2020, MMWR-MORBID MORTAL W, V69, P1049, DOI [10.1101/2020.04.22.20076141v1, 10.15585/mmwr.mm6932a1]
   Davis D.Z., 2014, J VIRTUAL WORLDS RES, V7, P1, DOI DOI 10.4101/JVWR.V7I3.7068
   Davis D. Z., 2020, HUMAN MACH COMMUN, V2
   de Regt A, 2020, BUS HORIZONS, V63, P737, DOI 10.1016/j.bushor.2020.08.002
   Difede J, 2006, ANN NY ACAD SCI, V1071, P500, DOI 10.1196/annals.1364.052
   Diniz BernardoP., 2020, Journal of Technology in Behavioral Science, V6, P3, DOI [10.1007/s41347-020-00152-9, DOI 10.1007/S41347-020-00152-9]
   Dodd L., 2020, 2 LIFE ENJOYS SURPRI
   Egan J., 2020, The pandemic is causing the rise of making real money from virtual worlds
   Eisenberger NI, 2012, NAT NEUROSCI, V15, P669, DOI 10.1038/nn.3086
   Foxman M., 2020, EXT ABSTR 2020 ANN S, P237
   Foxman M., 2018, THESIS NEW YORK, DOI [10.7916/D8M05NH3, DOI 10.7916/D8M05NH3]
   Foxman M, 2019, SOC MEDIA SOC, V5, DOI 10.1177/2056305119880177
   Golding D, 2019, CONVERGENCE-US, V25, P340, DOI 10.1177/1354856517738171
   Greenberg N, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m1211
   Guimaraes M, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423879
   Hamari J, 2017, INT J INFORM MANAGE, V37, P1449, DOI 10.1016/j.ijinfomgt.2016.09.004
   Harley D, 2020, CONVERGENCE-US, V26, P1144, DOI 10.1177/1354856519860237
   Hawkley LC, 2015, PHILOS T R SOC B, V370, DOI 10.1098/rstb.2014.0114
   Holt-Lunstad J, 2015, PERSPECT PSYCHOL SCI, V10, P227, DOI 10.1177/1745691614568352
   Huskamp HA, 2018, PSYCHIAT SERV, V69, P217, DOI 10.1176/appi.ps.201600516
   Imperatori C, 2020, CYBERPSYCH BEH SOC N, V23, P782, DOI 10.1089/cyber.2020.0339
   Jang Y, 2019, TELEMAT INFORM, V42, DOI 10.1016/j.tele.2019.101239
   Kalyanaraman S., 2019, MEDIA EFFECTS ADV TH, V4th, DOI [10.4324/9780429491146-26, DOI 10.4324/9780429491146-26]
   Kassner MP, 2012, CYBERPSYCH BEH SOC N, V15, P399, DOI 10.1089/cyber.2012.0113
   Killgore WDS, 2020, PSYCHIAT RES, V290, DOI 10.1016/j.psychres.2020.113117
   Klinenberg E, 2016, AM J PUBLIC HEALTH, V106, P786, DOI 10.2105/AJPH.2016.303166
   Krendl AC, 2021, J GERONTOL B-PSYCHOL, V76, pE53, DOI 10.1093/geronb/gbaa110
   Kuchera B., 2020, BEST VR DEVICE IS HA
   Lal S, 2014, PSYCHIAT SERV, V65, P24, DOI 10.1176/appi.ps.201300009
   lemonde, MONDE 2 LIFE MINECRA
   Liszio S, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102086
   Lo CB, 2020, PEDIATRICS, V145, DOI 10.1542/peds.2019-1536
   Loades ME, 2020, J AM ACAD CHILD PSY, V59, P1218, DOI 10.1016/j.jaac.2020.05.009
   Lotte F., 2012, PRACTICAL BRAINCOMPU, P197, DOI [10.1007/978-3-642-29746-5_10, DOI 10.1007/978-3-642-29746-5_10]
   Luchetti M, 2020, AM PSYCHOL, V75, P897, DOI 10.1037/amp0000690
   Mantovani E, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00926
   Marbury D., 2020, WHAT DOES FUTURE HOL
   Marchand WR, 2012, J PSYCHIATR PRACT, V18, P233, DOI 10.1097/01.pra.0000416014.53215.86
   Martin S., 2019, REALITY MIGHT BE NEX
   Miller MR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74486-y
   Moreno C, 2020, LANCET PSYCHIAT, V7, P813, DOI 10.1016/S2215-0366(20)30307-2
   Nambisan Satish, 2017, AMA J Ethics, V19, P1106, DOI 10.1001/journalofethics.2017.19.11.stas1-1711
   Nandi S, 2021, SUSTAIN PROD CONSUMP, V27, P10, DOI 10.1016/j.spc.2020.10.019
   Olfson M, 2019, JAMA PSYCHIAT, V76, P152, DOI 10.1001/jamapsychiatry.2018.3550
   Oliver MB, 2003, LEA COMMUN SER, P85
   Olsen J, 2018, DISABIL SOC, V33, P1160, DOI 10.1080/09687599.2018.1459228
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Ospina-Pinillos L, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9716
   Palmer K, 2020, AGING CLIN EXP RES, V32, P1189, DOI 10.1007/s40520-020-01601-4
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pedram S, 2020, COMPUT HUM BEHAV, V105, DOI 10.1016/j.chb.2019.106223
   Petrara D., 2020, HEALTHCARE 40 WILL P
   Picard RW, 2016, IEEE MULTIMEDIA, V23, P3, DOI 10.1109/MMUL.2016.38
   Playstation, 2020, ACC OPT LAST 2
   Powell W, 2020, CYBERPSYCH BEH SOC N, V23, P185, DOI 10.1089/cyber.2019.0409
   Riva G, 2015, Immersed in Media, P283, DOI [DOI 10.1007/978-3-319-10190-3_12, 10.1007/978-3-319-10190-3_12]
   Riva G, 2020, CYBERPSYCH BEH SOC N, V23, P581, DOI 10.1089/cyber.2020.29194.gri
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rizzo A. S., 2019, INFRARED TECHNOLOGY, P300
   Rothbaum BO, 2001, J CLIN PSYCHIAT, V62, P617, DOI 10.4088/JCP.v62n0808
   Seifert A, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00568
   Singh RP, 2020, DIABETES METAB SYND, V14, P661, DOI 10.1016/j.dsx.2020.05.011
   Spiegel Brennan., 2020, VRx: How Virtual Therapeutics Will Revolutionize Medicine
   Srivastava Kalpana, 2014, Ind Psychiatry J, V23, P83, DOI 10.4103/0972-6748.151666
   SteamCharts, 2020, STEAMCHARTS ALTSP VR
   Steed A., 2020, Interactions, V27, P62, DOI DOI 10.1145/3406098
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   SuperData, 2020, SUPERDATA XR Q2 2020
   Tamplin J, 2020, J TELEMED TELECARE, V26, P365, DOI 10.1177/1357633X19828463
   Tarr B, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21765-4
   Thai KTP, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P468, DOI [10.1109/VRW50115.2020.0-177, 10.1109/VRW50115.2020.00099]
   Tran J. J., 2019, REFRESHABLE BRAILLE
   Valmaggia LR, 2016, PSYCHIAT RES, V236, P189, DOI 10.1016/j.psychres.2016.01.015
   van Tilburg TG, 2021, J GERONTOL B-PSYCHOL, V76, pE249, DOI 10.1093/geronb/gbaa111
   Wiederhold BK, 2018, CYBERPSYCH BEH SOC N, V21, P739, DOI 10.1089/cyber.2018.29132.bkw
   Wiederhold BK, 2019, CYBERPSYCH BEH SOC N, V22, P3, DOI 10.1089/cyber.2018.29136.bkw
   Zeng N, 2018, J CLIN MED, V7, DOI 10.3390/jcm7030042
   Zhou XY, 2020, TELEMED E-HEALTH, V26, P377, DOI 10.1089/tmj.2020.0068
   ZILLMANN D, 1988, AM BEHAV SCI, V31, P327, DOI 10.1177/000276488031003005
NR 91
TC 13
Z9 15
U1 4
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 17
PY 2021
VL 2
AR 627059
DI 10.3389/frvir.2021.627059
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TL7
UT WOS:001021834000001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Palmisano, S
   Allison, RS
   Kim, J
AF Palmisano, Stephen
   Allison, Robert S.
   Kim, Juno
TI Cybersickness in Head-Mounted Displays Is Caused by Differences in the
   User's Virtual and Physical Head Pose
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE head-mounted display; motion sickness; cybersickness; motion-to-photon
   latency; sensory conflict; postural instability
ID VISUALLY INDUCED MOTION; CONSOLE VIDEO GAMES; POSTURAL INSTABILITY;
   SENSORY CONFLICT; OPTOKINETIC NYSTAGMUS; SIMULATOR SICKNESS;
   EYE-MOVEMENT; SEX-DIFFERENCES; OPTICAL-FLOW; OCULUS RIFT
AB Sensory conflict, eye-movement, and postural instability theories each have difficulty accounting for the motion sickness experienced during head-mounted display based virtual reality (HMD VR). In this paper we review the limitations of existing theories in explaining cybersickness and propose a practical alternative approach. We start by providing a clear operational definition of provocative motion stimulation during active HMD VR. In this situation, whenever the user makes a head movement, his/her virtual head will tend to trail its true position and orientation due to the display lag (or motion to photon latency). Importantly, these differences in virtual and physical head pose (DVP) will vary over time. Based on our own research findings, we propose that cybersickness in HMD VR is triggered by large magnitude, time-varying patterns of DVP. We then show how this hypothesis can be tested by: (1) systematically manipulating display lag magnitudes and head movement speeds across HMD VR conditions; and (2) comparing the estimates of the user's DVP in each of these conditions to their own reports of cybersickness severity. We believe that this approach will allow researchers to precisely predict which situations will (and will not) be provocative for cybersickness in HMD VR.
C1 [Palmisano, Stephen] Univ Wollongong, Sch Psychol, Wollongong, NSW, Australia.
   [Allison, Robert S.] York Univ, Ctr Vis Res, Toronto, ON, Canada.
   [Allison, Robert S.] York Univ, Dept Elect Engn & Comp Sci, Toronto, ON, Canada.
   [Kim, Juno] Univ New South Wales, Sch Optometry & Vis Sci, Sydney, NSW, Australia.
C3 University of Wollongong; York University - Canada; York University -
   Canada; University of New South Wales Sydney
RP Palmisano, S (corresponding author), Univ Wollongong, Sch Psychol, Wollongong, NSW, Australia.
EM stephenp@uow.edu.au
RI ; Palmisano, Stephen/O-1553-2018
OI Kim, Juno/0000-0003-1300-9875; Allison, Robert/0000-0002-4485-2665;
   Palmisano, Stephen/0000-0002-9140-5681
FU NUW Alliance grant; Australian Research Council (ARC) [FT140100535]
FX & nbsp;This paper was supported by a UOW study leave assistance grant to
   SP (including open access publication fees), an NUW Alliance grant to SP
   and JK, and an Australian Research Council (ARC) Future Fellowship
   awarded to JK (FT140100535).
CR Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   Allison RS, 1999, PERCEPTION, V28, P299, DOI 10.1068/p2891
   Andersen D, 2018, LECT NOTES COMPUT SC, V11162, P73, DOI 10.1007/978-3-030-01790-3_5
   [Anonymous], 1975, Motion sickness
   APT L, 1973, AM J OPHTHALMOL, V76, P533, DOI 10.1016/0002-9394(73)90743-5
   Apthorp D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113897
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BAJURA M, 1995, IEEE COMPUT GRAPH, V15, P52, DOI 10.1109/38.403828
   BALTZLEY DR, 1989, AVIAT SPACE ENVIR MD, V60, P1043
   Bernardo A, 2017, WORLD NEUROSURG, V106, P1015, DOI 10.1016/j.wneu.2017.06.140
   BINGHAM GP, 1993, VISION RES, V33, P777, DOI 10.1016/0042-6989(93)90197-5
   Biocca Frank., 1992, Presence: Teleoperators Virtual Environments, V1, P334, DOI [DOI 10.1162/PRES.1992.1.3.334, 10.1162/pres.1992.1.3.334]
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bles W, 2000, CURR OPIN NEUROL, V13, P19, DOI 10.1097/00019052-200002000-00005
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bonato F, 2005, AVIAT SPACE ENVIR MD, V76, P823
   Bonato F, 2004, AVIAT SPACE ENVIR MD, V75, P306
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Bonnet CT, 2006, HUM MOVEMENT SCI, V25, P800, DOI 10.1016/j.humov.2006.03.001
   Bos JE, 2002, BIOL CYBERN, V86, P191, DOI 10.1007/s00422-001-0289-7
   Bos JE, 1998, BRAIN RES BULL, V47, P537, DOI 10.1016/S0361-9230(98)00088-4
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   boyd D., 2014, Is the Oculus Rift sexist?
   BRONSTEIN AM, 1988, EXP BRAIN RES, V71, P406
   Bubka A, 2003, AVIAT SPACE ENVIR MD, V74, P315
   Bubka A, 2007, AVIAT SPACE ENVIR MD, V78, P383
   Cao S, 2020, VIRTUAL REAL-LONDON, V24, P503, DOI 10.1007/s10055-019-00412-x
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Caserman P, 2019, LECT NOTES COMPUT SC, V11863, P57, DOI 10.1007/978-3-030-34644-7_5
   Ch'ng E, 2009, J CULT HERIT, V10, P458, DOI 10.1016/j.culher.2009.02.001
   Chang CH, 2013, EXP BRAIN RES, V229, P235, DOI 10.1007/s00221-013-3609-y
   Chang CH, 2012, EXP BRAIN RES, V217, P299, DOI 10.1007/s00221-011-2993-4
   Chang E, 2013, INT WINT WORKSH BR, P62, DOI 10.1109/IWW-BCI.2013.6506631
   Chen DJZ, 2011, I-PERCEPTION, V2, P415
   Chen E, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00004
   Chen W, 2016, AEROSP MED HUM PERF, V87, P128, DOI 10.3357/AMHP.4327.2016
   CHEUNG BSK, 1991, AVIAT SPACE ENVIR MD, V62, P527
   Claremont CA., 1931, PSYCHE, V11, P86
   CLARK B, 1970, ACTA OTO-LARYNGOL, V69, P231, DOI 10.3109/00016487009123358
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cobb SVG, 1999, APPL ERGON, V30, P47, DOI 10.1016/S0003-6870(98)00038-6
   Cobb SVG, 1998, BRAIN RES BULL, V47, P459, DOI 10.1016/S0361-9230(98)00104-X
   Collewijn H, 2000, J NEUROPHYSIOL, V84, P376, DOI 10.1152/jn.2000.84.1.376
   Cook HE, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01901
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   de Graaf B, 1998, BRAIN RES BULL, V47, P489, DOI 10.1016/S0361-9230(98)00116-6
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   DiZio P, 1997, ADV HUM FACT ERGON, V21, P893
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Duh HBL, 2004, PRESENCE-TELEOP VIRT, V13, P578, DOI 10.1162/1054746042545283
   Ebenholtz S.M., 1992, Teleoperators and Virtual Environments, V1, P302, DOI DOI 10.1162/PRES.1992.1.3.302
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Elliman J., 2016, 2016 8th International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES), Barcelona, P1, DOI [10.1109/VS-GAMES.2016.7590377, DOI 10.1109/VS-GAMES.2016.7590377]
   Ellis S.R., 2004, Proceedings of the Human Factors and Ergonomics Society 48th annual meeting, P2632, DOI DOI 10.1177/154193120404802306
   Eubanks James Coleman, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P490, DOI 10.1007/978-3-319-39907-2_47
   Flanagan MB, 2004, J VESTIBUL RES-EQUIL, V14, P335
   Flanagan MB, 2002, AVIAT SPACE ENVIR MD, V73, P1067
   FRANK LH, 1988, HUM FACTORS, V30, P201, DOI 10.1177/001872088803000207
   Freiwald JP, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281521
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Golding JF, 2016, HAND CLINIC, V137, P371, DOI 10.1016/B978-0-444-63437-5.00027-3
   Golding JF, 2001, AVIAT SPACE ENVIR MD, V72, P188
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Gonizzi Barsanti S., 2015, P 25 INT CIPA S
   Grabherr L, 2008, EXP BRAIN RES, V186, P677, DOI 10.1007/s00221-008-1350-8
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Guedry F. E, 1991, MOTION SICKNESS SIGN, P1
   GUEDRY FE, 1961, AEROSPACE MED, V32, P487
   Guedry FE., 1974, VESTIBULAR SYSTEM 2, P3, DOI [10.1007/978-3-642-65920-1_1, DOI 10.1007/978-3-642-65920-1_1]
   Guo C. T., 2012, P ANN M HUM FACT ERG, P22
   Guo CCT, 2017, APPL ERGON, V63, P1, DOI 10.1016/j.apergo.2017.03.011
   Gupta VK, 2005, MED HYPOTHESES, V64, P1177, DOI 10.1016/j.mehy.2004.11.031
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Hogue J., 1999, P 15 AER DEC SYST TE, P1724, DOI [10.2514/6.1999-1724, DOI 10.2514/6.1999-1724]
   Howard I.P., 1982, HUMAN VISUAL ORIENTA
   HOWARD IP, 1994, PERCEPTION, V23, P753, DOI 10.1068/p230753
   Howard IP, 2001, PERCEPTION, V30, P583, DOI 10.1068/p3106
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   Howarth PA, 1999, APPL ERGON, V30, P39, DOI 10.1016/S0003-6870(98)00041-6
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Hu SQ, 1997, AVIAT SPACE ENVIR MD, V68, P306
   Hu SQ, 1998, AVIAT SPACE ENVIR MD, V69, P1162
   Jennings S, 2004, J AIRCRAFT, V41, P1327, DOI 10.2514/1.449
   Jennings S., 2000, HUM FACTORS, V44, P69
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Ji JTT, 2009, HUM FACTORS, V51, P739, DOI 10.1177/0018720809349708
   Jones JA, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS, P77, DOI 10.1109/CTS.2015.7210403
   Karmali F, 2014, J NEUROPHYSIOL, V111, P2393, DOI 10.1152/jn.00332.2013
   Kennedy R S, 1968, Acta Otolaryngol, V66, P533, DOI 10.3109/00016486809126317
   Kennedy R.S., 1990, MOTION SPACE SICKNES, P317, DOI DOI 10.1207/S15327108IJAP0303_3
   Kennedy R. S., 1994, VIRT INTERF RES APPL, V2, P1
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1996, INT J HUM-COMPUT INT, V8, P25, DOI 10.1080/10447319609526139
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kennedy RS., 1994, Proceedings of "Virtual Reality and Medicine: The Cutting Edge.", P111
   Keshavarz B, 2017, J EXP PSYCHOL-APPL, V23, P85, DOI 10.1037/xap0000107
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Keshavarz Behrang., 2014, Handbook of Virtual Environments: Design, Implementation, and Applications Issue September, P647, DOI [DOI 10.1201/B17360-32, https://doi.org/10.1201/b17360-32]
   Khor WS, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.12.23
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kim J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00248
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kingdon K. S., 2001, P HUMAN FACTORS ERGO
   Kinsella A, 2016, AEROSP MED HUM PERF, V87, P604, DOI 10.3357/AMHP.4351.2016
   Kiruluta A, 1997, IEEE T SYST MAN CY B, V27, P326, DOI 10.1109/3477.558841
   Konrad R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3361330
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Koslucher F, 2015, AEROSP MED HUM PERF, V86, P787, DOI 10.3357/AMHP.4243.2015
   Kudo H., 2000, P 22 ANN INT C IEEE
   Kuiper OX, 2019, DISPLAYS, V58, P82, DOI 10.1016/j.displa.2018.10.001
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lackner JR, 2006, EXP BRAIN RES, V175, P377, DOI 10.1007/s00221-006-0697-y
   Lackner JR, 2020, J NEUROPHYSIOL, V123, P1206, DOI 10.1152/jn.00139.2019
   Lawson B D, 2005, P 11 INT C HUM COMP, P1
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lee D. N., 1975, Journal of Human Movement Studies, V1, P87, DOI DOI 10.3758/BF03199297
   Lewis T., 2015, When will virtual-reality headsets stop making people sick?
   LISHMAN JR, 1973, PERCEPTION, V2, P287, DOI 10.1068/p020287
   Luu W., 2019, P SIGGRAPH AS SIGGRA, DOI [10.1145/3355056.3364590, DOI 10.1145/3355056.3364590]
   MacNeilage PR, 2010, J NEUROPHYSIOL, V104, P765, DOI 10.1152/jn.01067.2009
   Mania Katerina., 2004, Proceedings of the 1st Symposium on Applied Perception in Graphics and Visualization, APGV '04, P39, DOI [10.1145/1012551.1012559, DOI 10.1145/1012551.1012559]
   MAPP AP, 1986, VISION RES, V26, P1163, DOI 10.1016/0042-6989(86)90050-7
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Min YK, 2006, PERCEPT MOTOR SKILL, V103, P197, DOI 10.2466/PMS.103.5.197-209
   Money K. E., 1970, NASA SPECIAL PUBLICA, V187, P35
   MONEY KE, 1983, AVIAT SPACE ENVIR MD, V54, P208
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nalivaiko Eugene, 2014, Temperature (Austin), V1, P164, DOI 10.4161/23328940.2014.982047
   Nishiike S, 2013, J MED INVESTIG, V60, P236
   Nooij SAE, 2018, EXP BRAIN RES, V236, P3031, DOI 10.1007/s00221-018-5340-1
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   OHMI M, 1987, PERCEPTION, V16, P17, DOI 10.1068/p160017
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Ortegon-Sarmiento Tatiana, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P521, DOI 10.1007/978-3-319-39907-2_50
   Palmisano S, 2007, AVIAT SPACE ENVIR MD, V78, P951, DOI 10.3357/ASEM.2079.2007
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Phan V. T., 2010, INT J COMPUT APPL, V4, P26, DOI [10.5120/809-1149, DOI 10.5120/809-1149]
   Pierre MES, 2015, DISPLAYS, V36, P1, DOI 10.1016/j.displa.2014.10.005
   Pot-Kolder R, 2018, CYBERPSYCH BEH SOC N, V21, P187, DOI 10.1089/cyber.2017.0082
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   Prothero JD, 1999, AVIAT SPACE ENVIR MD, V70, P277
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reed-Jones RJ, 2008, NEUROSCI LETT, V435, P204, DOI 10.1016/j.neulet.2008.02.047
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Roditi RE, 2012, JARO-J ASSOC RES OTO, V13, P381, DOI 10.1007/s10162-012-0318-3
   ROLNICK A, 1991, ERGONOMICS, V34, P867, DOI 10.1080/00140139108964831
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seno T, 2017, I-PERCEPTION, V8, DOI [10.1177/2041669518774069, 10.1177/2041669517742176]
   Seok Han Kwang, 2019, [Journal of the Korea Convergence Society, 한국융합학회논문지], V10, P139, DOI 10.15207/JKCS.2019.10.6.139
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Simons R., 2003, P HELM HEAD MOUNT DI
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Smart LJ, 2014, ECOL PSYCHOL, V26, P301, DOI 10.1080/10407413.2014.958029
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   STERN RM, 1990, AVIAT SPACE ENVIR MD, V61, P712
   STOFFREGEN T A, 1991, Ecological Psychology, V3, P159, DOI 10.1207/s15326969eco0303_1
   Stoffregen TA, 2000, HUM FACTORS, V42, P458, DOI 10.1518/001872000779698097
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 2008, HUM FACTORS, V50, P322, DOI 10.1518/001872008X250755
   Stoffregen TA, 2014, EXP BRAIN RES, V232, P1389, DOI 10.1007/s00221-014-3859-3
   Stoffregen TA, 2010, ECOL PSYCHOL, V22, P169, DOI 10.1080/10407413.2010.496645
   Tanahashi S, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-39
   Tate DL, 1997, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VRAIS.1997.583045
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Thornton WE, 2013, AVIAT SPACE ENVIR MD, V84, P716, DOI 10.3357/ASEM.3449.2013
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Valko Y, 2012, J NEUROSCI, V32, P13537, DOI 10.1523/JNEUROSCI.2157-12.2012
   van Waveren JMP, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P37, DOI 10.1145/2993369.2993375
   Villani D., 2007, Int. J. Stress Manag. Copyr, V14, P260, DOI [DOI 10.1037/1072-5245.14.3.260, 10.1037/1072-5245.14.3.260https://dx.doi.org/10.1037/1072-5245.14.3.260, DOI 10.1037/1072-5245.14.3.260HTTPS://DX.DOI.ORG/10.1037/1072-5245.14.3.260]
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Warwick-Evans LA, 1998, BRAIN RES BULL, V47, P465, DOI 10.1016/S0361-9230(98)00090-2
   Webb NA, 2003, AVIAT SPACE ENVIR MD, V74, P622
   Webb NA, 2002, AVIAT SPACE ENVIR MD, V73, P351
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Wiederhold BK, 2014, CYBERPSYCH BEH SOC N, V17, P346, DOI 10.1089/cyber.2014.0207
   Wu WX, 2013, PRESENCE-TELEOP VIRT, V22, P20, DOI 10.1162/PRES_a_00131
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yildirim C, 2019, DISPLAYS, V59, P35, DOI 10.1016/j.displa.2019.07.002
   Yokokohji Y., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P247, DOI 10.1109/VR.2000.840505
   Yokota Y, 2005, ACTA OTO-LARYNGOL, V125, P280, DOI 10.1080/00016480510003192
   Zhao JB, 2017, P IEEE VIRT REAL ANN, P313, DOI 10.1109/VR.2017.7892302
NR 214
TC 50
Z9 52
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 12
PY 2020
VL 1
AR 587698
DI 10.3389/frvir.2020.587698
PG 24
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4TA3
UT WOS:001023194400001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Thomaschewski, L
   Feld, N
   Weyers, B
   Kluge, A
AF Thomaschewski, Lisa
   Feld, Nico
   Weyers, Benjamin
   Kluge, Annette
TI I sense that there is someone else: an exploratory study on the
   influence of the media richness of Augmented Reality-based assistance
   systems on team experience and performance
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE avatar; spatially dispersed teams; augmented reality; team experience;
   team performance; work group cohesiveness; co-presence; social presence
ID JOINT ACTION; CUED-RECALL; INFORMATION
AB Based on the results of two laboratory studies, we show how the implementation of minimalistic social and task-relevant cues in Augmented Reality-based assistance systems for spatially dispersed teams impact team experience while not affecting team performance. In study 1 (N = 224) we investigated the Ambient Awareness Tool, which supports spatially dispersed teams in their temporal coordination when multiple team tasks or team and individual tasks must be executed in parallel. We found that adding a progress bar to the interface led to a significant increase in the perception of work group cohesiveness (diff = 0.34, p = .03, CI: [-0.65; -0.03], d = 0.39), but did not affect team performance (p = .92, eta(2) = 0.03). In study 2 (N = 23) we piloted an AR-based avatar representation of a spatially dispersed team member and evaluated whether the interactivity of the avatar impacts the perception of co- and social presence as well as team performance. An interactive avatar increased the perception of co- and social presence (co-presence: diff = 2.7, p < .001, eta(2) = 0.20; social presence: diff = 1.2, p = .001, eta(2) = 0.06). Team performance did not differ significantly (p = .177, eta(2) = 0.01). These results indicate that even minor social and task-relevant cues in the interface can significantly impact team experience and provide valuable insights for designing human-centered health-promoting AR-based assistance systems for spatially dispersed teams in the vocational context with minimal means.
C1 [Thomaschewski, Lisa; Kluge, Annette] Ruhr Univ Bochum, Chair Work Org & Business Psychol, Bochum, Germany.
   [Feld, Nico; Weyers, Benjamin] Univ Trier, Human Comp Interact, Trier, Germany.
C3 Ruhr University Bochum; Universitat Trier
RP Thomaschewski, L (corresponding author), Ruhr Univ Bochum, Chair Work Org & Business Psychol, Bochum, Germany.
EM lisa.thomaschewski@rub.de
FU This work was partly funded by the DFG (Deutsche
   Forschungsgemeinschaft), grant numbers KL2207/7-1 and WE5408/3-1.
   [KL2207/7-1, WE5408/3-1]; DFG (Deutsche Forschungsgemeinschaft)
FX This work was partly funded by the DFG (Deutsche
   Forschungsgemeinschaft), grant numbers KL2207/7-1 and WE5408/3-1.r This
   work was partly funded by the DFG (Deutsche Forschungsgemeinschaft),
   grant numbers KL2207/7-1 and WE5408/3-1.
CR Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bardram J. E., 2000, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V9, P157, DOI 10.1023/A:1008748724225
   Bergiel B.J., 2008, MANAGE RES NEWS, V31, P99, DOI [DOI 10.1108/01409170810846821, 10.1108/01409170810846821]
   Boos M, 2017, Fuhrung und Zusammenarbeit in verteilten Teams
   Brown G., 2020, P C MENSCH COMP NEW
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Casanueva J., 2001, Hardware, software and peopleware
   Cascio WF, 2000, ACAD MANAGE EXEC, V14, P81, DOI 10.5465/AME.2000.4468068
   Chidambaram L, 1996, MIS QUART, V20, P143, DOI 10.2307/249476
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   Frank B, 2018, INT J IND ERGONOM, V67, P123, DOI 10.1016/j.ergon.2018.05.007
   Frank B, 2017, ADV INTELL SYST, V488, P3, DOI 10.1007/978-3-319-41691-5_1
   Fussell S. R., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P21, DOI 10.1145/358916.358947
   Hagemann V, 2012, EMPL RELAT, V34, P322, DOI 10.1108/01425451211217734
   Harms C., 2004, 7 ANN INT WORKSH PRE
   Johansen Robert, 1988, GroupWare: Computer Support for Business Teams
   Kang S., 2008, P 41 ANN HAW INT C S
   Kang SH, 2013, COMPUT HUM BEHAV, V29, P1169, DOI 10.1016/j.chb.2012.10.010
   Kirkman BL, 2002, ACAD MANAGE EXEC, V16, P67, DOI 10.5465/AME.2002.8540322
   Korsgaard MA, 2010, HUM-COMPUT INT-SPRIN, P253, DOI 10.1007/978-1-84882-825-4_20
   Kraut R.E., 2002, P 2002 ACM C COMPUTE, P31
   Marks MA, 2001, ACAD MANAGE REV, V26, P356, DOI 10.5465/AMR.2001.4845785
   Mohammed S, 2015, EUR J WORK ORGAN PSY, V24, P693, DOI 10.1080/1359432X.2015.1024664
   Mohammed S, 2014, J APPL PSYCHOL, V99, P404, DOI 10.1037/a0035640
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Raghuram S, 2001, J MANAGE, V27, P383, DOI 10.1016/S0149-2063(01)00097-6
   Riordan CM, 1999, EDUC PSYCHOL MEAS, V59, P310, DOI 10.1177/00131649921969866
   Rockmann KW, 2008, ORGAN BEHAV HUM DEC, V107, P106, DOI 10.1016/j.obhdp.2008.02.002
   Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009
   Tangirala S, 2006, ORGAN BEHAV HUM DEC, V100, P1, DOI 10.1016/j.obhdp.2005.11.002
   Thomaschewski L., 2023, Everyday virtual and augmented reality, P57
   Thomaschewski L, 2021, COGN SYST RES, V68, P1, DOI 10.1016/j.cogsys.2020.12.001
   Vesper C, 2016, COGNITION, V153, P118, DOI 10.1016/j.cognition.2016.05.002
   Warkentin ME, 1997, DECISION SCI, V28, P975, DOI 10.1111/j.1540-5915.1997.tb01338.x
   Weyers Benjamin, 2015, International Journal of Information Systems for Crisis Response and Management, V7, P59, DOI 10.4018/IJISCRAM.2015040104
NR 37
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 15
PY 2023
VL 4
AR 1163337
DI 10.3389/frvir.2023.1163337
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA T4KW0
UT WOS:001077703100001
OA gold
DA 2024-07-18
ER

PT J
AU Bachmann, M
   Subramaniam, A
   Born, J
   Weibel, D
AF Bachmann, Manuel
   Subramaniam, Abimanju
   Born, Jonas
   Weibel, David
TI Virtual reality public speaking training: effectiveness and user
   technology acceptance
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; public speaking; training; social anxiety; speech
   performance; technology acceptance model
ID PERCEIVED EASE; SOCIAL PHOBIA; ANXIETY; BEHAVIOR; THERAPY; SKILLS; MODEL
AB Public speaking is a fundamental task in many professional or personal situations. At the same time, there is widespread fear of it, and it takes practice to present well. Previous studies suggest that Virtual Reality Public Speaking Training (VRPST) offers a promising opportunity for this. However, studies evaluating objective and subjective indicators are lacking so far, and valid control conditions are missing in previous studies. We aimed to overcome these drawbacks. In our experiment, participants (N = 42) had the task of presenting a card game to a four-person audience using five provided PowerPoint slides within a time limit of 5 minutes. They prepared either using VRPST or using common self-directed preparation (control condition), being randomly assigned to a condition. Both groups were instructed to prepare for the task at home and given 30 min to learn the rules of the game and present them using the slides. The control group was given an additional 30 min to prepare individually for the presentation task at home. The experimental group received an additional 30-min VRPST session. This training session was done without specific feedback and the presentation was repeated three times. The quality of the rule explanation, the audience-assessed presentation quality, and the subjects' self-assessed presentation quality were measured. Our results indicate that the VRPST is effective. Subjects who completed the VRPST did a better job of explaining the rules and were better rated by the audience. In addition, the experimental subjects also tended to rate their presentation better in the VRPST condition. Further analyses of those participants who completed the VRPST show high technology acceptance. Our results show the VR training had a significant performance-enhancing effect and that participants would use the VRPST if it were available to them. It seems that practicing a presentation in VR is useful and even better than a conventional preparation.
C1 [Bachmann, Manuel; Born, Jonas] Bern Univ Appl Sci, Inst Specialized Didact Profess Dev & Digitalizat, Dept Social Work, Bern, Switzerland.
   [Subramaniam, Abimanju; Weibel, David] Univ Bern, Dept Psychol, Bern, Switzerland.
C3 University of Bern
RP Bachmann, M (corresponding author), Bern Univ Appl Sci, Inst Specialized Didact Profess Dev & Digitalizat, Dept Social Work, Bern, Switzerland.
EM manuel.bachmann@bfh.ch
RI Bachmann, Manuel/AAZ-7483-2020
OI Bachmann, Manuel/0000-0001-7133-7215; Subramaniam,
   Abimanju/0000-0002-4382-3838
CR ALLEN M, 1989, COMMUN EDUC, V38, P54, DOI 10.1080/03634528909378740
   Anderson PL, 2005, DEPRESS ANXIETY, V22, P156, DOI 10.1002/da.20090
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Barreda-Angeles M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107047
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Boetje J, 2021, J COMPUT ASSIST LEAR, V37, P253, DOI 10.1111/jcal.12484
   Bombari D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00869
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Daassi M, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103453
   Daniels M. M., 2021, IOP Conference Series: Materials Science and Engineering, V1077, DOI 10.1088/1757-899X/1077/1/012047
   Daniels M. M., 2020, IOP Conference Series: Materials Science and Engineering, V803, DOI 10.1088/1757-899X/803/1/012003
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dobricki M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251562
   Dunbar NE, 2006, INNOV HIGH EDUC, V31, P115, DOI 10.1007/s10755-006-9012-x
   Furmark T, 1999, SOC PSYCH PSYCH EPID, V34, P416, DOI 10.1007/s001270050163
   Gasteiger N, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/31644
   Hamm AO, 2009, PSYCHIAT CLIN N AM, V32, P577, DOI 10.1016/j.psc.2009.05.008
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   JAMES JE, 1986, BEHAV PSYCHOTHER, V14, P183, DOI 10.1017/S0141347300014725
   Jaradat Mohammed-Issa Riad Mousa, 2014, International Journal of Business Information Systems, V16, P271, DOI 10.1504/IJBIS.2014.063768
   Joughin G, 2007, STUD HIGH EDUC, V32, P323, DOI 10.1080/03075070701346873
   Latu IM, 2013, J EXP SOC PSYCHOL, V49, P444, DOI 10.1016/j.jesp.2013.01.003
   Lee HW, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.753019
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Mast MS, 2018, HUM RESOUR DEV Q, V29, P125, DOI 10.1002/hrdq.21307
   Overholser J., 2002, Journal of Contemporary Psychotherapy, V32, P125, DOI DOI 10.1023/A:1020534025102
   Palm M., 2022, Eggenstein-leopoldshafen: 10 traders
   Palmas F, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P463, DOI 10.1109/VR50410.2021.00070
   Palmas F, 2019, INT SYM MIX AUGMENT, P363, DOI 10.1109/ISMAR.2019.00034
   Pathak A., 2015, INT J EVALUATION RES, V4, P179, DOI [10.11591/ijere.v4i4.4509, DOI 10.11591/IJERE.V4I4.4509]
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Poeschl S., 2017, Frontiers in ICT, V4, P13, DOI DOI 10.3389/FICT.2017.00013
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   RICKHAM PP, 1964, BRIT MED J, V2, P173
   Ruscio AM, 2008, PSYCHOL MED, V38, P15, DOI 10.1017/S0033291707001699
   Scharfenberger J., 2012, Der Einfluss von presence, Immersion und fokussierter Aufmerksamkeit auf die Technologieakzeptanz in virtuellen realitaten: Na
   Schroeder R., 2008, Journal of Virtual Worlds Research: Past, Present Future, V1, P2, DOI 10.4101/jvwr.v1i1.294
   Silva P., 2015, Information seeking behavior and technology adoption: Theories and trends, P205, DOI DOI 10.4018/978-1-4666-8156-9.CH013
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Sülter RE, 2022, COMPUT EDUC, V178, DOI 10.1016/j.compedu.2021.104384
   Takac M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216288
   Tivian XI GmbH, 2021, Online Survey Software: Surveys Made Easy With Unipark
   Valls-Rates I, 2022, FRONT COMMUN, V7, DOI 10.3389/fcomm.2022.910952
   Van Ginkel S, 2020, J COMPUT ASSIST LEAR, V36, P412, DOI 10.1111/jcal.12424
   Venkatesh V, 1996, DECISION SCI, V27, P451, DOI 10.1111/j.1540-5915.1996.tb01822.x
   Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Weber S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.628298
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Wörtwein T, 2015, INT CONF AFFECT, P187, DOI 10.1109/ACII.2015.7344570
   WOLPE J, 1968, Conditional Reflex, V3, P234
   Yadav M, 2022, IEEE T AFFECT COMPUT, V13, P1168, DOI 10.1109/TAFFC.2020.3048299
   Zhou HY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093988
NR 55
TC 1
Z9 1
U1 4
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 13
PY 2023
VL 4
AR 1242544
DI 10.3389/frvir.2023.1242544
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA T0GH2
UT WOS:001074852900001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Steed, A
   Archer, D
   Izzouzi, L
   Numan, N
   Shapiro, K
   Swapp, D
   Lammiman, D
   Lindeman, RW
AF Steed, Anthony
   Archer, Dan
   Izzouzi, Lisa
   Numan, Nels
   Shapiro, Kalila
   Swapp, David
   Lammiman, Dinah
   Lindeman, Robert W.
TI Immersive competence and immersive literacy: Exploring how users learn
   about immersive experiences
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive; virtual reality; mixed reality; user experience; literacy;
   competence
ID VIRTUAL-REALITY; OWNERSHIP
AB While immersive experiences mediated through near-eye displays are still a relatively immature medium, there are millions of consumer devices in use. The level of awareness of the forms of the interface and media will vary enormously across the potential audience. Users might own personal devices or might encounter immersive systems in various venues. We introduce the term immersive competence to refer to the general practical knowledge and skills that users accumulate about how typical immersive interfaces work-the ways in which buttons are used, main locomotion techniques, etc. We then introduce the term immersive literacy to refer to awareness of how immersive interfaces are unique, when they might be appropriate, typical forms of media, etc. We sketch out how users develop competence and literacy with immersive media, and then highlight various open questions that are raised.
C1 [Steed, Anthony; Archer, Dan; Izzouzi, Lisa; Numan, Nels; Shapiro, Kalila; Swapp, David] UCL, Dept Comp Sci, London, England.
   [Lammiman, Dinah] UCL, Dept Anthropol, London, England.
   [Lindeman, Robert W.] Univ Canterbury, Human Interface Technol Lab, Christchurch, New Zealand.
C3 University of London; University College London; University of London;
   University College London; University of Canterbury
RP Steed, A (corresponding author), UCL, Dept Comp Sci, London, England.
EM a.steed@ucl.ac.uk
OI Shapiro, Kalila/0009-0007-1293-7916; Swapp, David/0000-0002-9335-8663;
   Steed, Anthony/0000-0001-9034-3020
CR Bailenson J., 2018, EXPERIENCE DEMAND WH
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bawden D, 2001, J DOC, V57, P218, DOI 10.1108/EUM0000000007083
   BBC Virtual Reality, 2019, MAK VR REAL STOR AUD
   Bevan C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300736
   Blanchard C., 1990, Computer Graphics, V24, P35, DOI 10.1145/91394.91409
   Bolas M., 2014, DYNAMIC FIELD VIEW T
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Burn A., 2007, J ED MULTIMEDIA HYPE, V16, P323
   Chilana PK, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2337
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   de Gelder B, 2018, BRIT J PSYCHOL, V109, P421, DOI 10.1111/bjop.12308
   Delaney B., 2017, VIRTUAL REALITY 1 0
   Dewez D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445379
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Emerson D., 2019, TAKING VR STORIES UK
   Grau O, 2003, LEONARDO SER, P1
   Grimsdale C., 1991, IEE C REAL WORLD VIS, p11/1
   Hartmann T, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694048
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Held R. M., 1992, Presence: Teleoperators and Virtual Environments, V1, P109, DOI [https://doi.org/10.1162/pres.1992.1.1.109, 10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Horton F.W., 1983, B AM SOC INFORM INF, V9, P14
   Ioannidis P, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3439862
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI 10.1145/2792790
   Kalawsky R., 1993, SCI VIRTUAL REALITY
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kent S., 2010, ULTIMATE HIST VIDEO
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lanier J., 2017, DAWN NEW EVERYTHING, V1st
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Laurel Brenda., 2014, COMPUTERS THEATRE, V2nd
   Lee J, 2019, TELEMAT INFORM, V39, P37, DOI 10.1016/j.tele.2018.12.006
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   MacQuarrie A, 2017, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VR.2017.7892230
   Manis KT, 2019, J BUS RES, V100, P503, DOI 10.1016/j.jbusres.2018.10.021
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Meta Inc, 2022, VR LOC DES GUID
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Mine M., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P11, DOI 10.1145/769953.769955
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Oakes J., 2018, XR DEV C 2018
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pan X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146837
   Pan Y, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364270
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pine BJ, 1998, HARVARD BUS REV, V76, P97
   Potter WJ, 2010, J BROADCAST ELECTRON, V54, P675, DOI 10.1080/08838151.2011.521462
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Rheingold Howard., 1992, VIRTUAL REALITY REVO
   Sagnier C, 2020, INT J HUM-COMPUT INT, V36, P993, DOI 10.1080/10447318.2019.1708612
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sherman W. R., 1995, Computer Graphics, V29, P37, DOI 10.1145/216876.216887
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   Silverblatt Art., 2009, Approaches to Media Literacy: A Handbook, V2nd
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Spante M, 2018, COGENT EDUC, V5, DOI 10.1080/2331186X.2018.1519143
   Steed A, 2021, IEEE T VIS COMPUT GR, V27, P4171, DOI 10.1109/TVCG.2021.3106431
   Steed A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00112
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tennent P, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3369394
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vuorikari Riina, 2022, EUR 31006 EN, JRC128415
   Watson Z., 2019, BBC SHARES INSIGHTS
   Whitehead M., 2001, European Journal of Physical Education, V6, P127
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zhao Y, 2021, COMPUT EDUC, V168, DOI 10.1016/j.compedu.2021.104212
   Zlotowski JA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00883
   Zuckerberg M, 2021, Founders Letter
NR 81
TC 2
Z9 2
U1 11
U2 20
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 23
PY 2023
VL 4
AR 1129242
DI 10.3389/frvir.2023.1129242
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WQ6
UT WOS:001023289200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Sakuma, H
   Takahashi, H
   Ogawa, K
   Ishiguro, H
AF Sakuma, Hiroshi
   Takahashi, Hideyuki
   Ogawa, Kohei
   Ishiguro, Hiroshi
TI Immersive role-playing with avatars leads to adoption of others'
   personalities
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE avatar; personality; adoption; virtual reality; role-play; third-person
   perspective; virtual beings
ID SELF-REPRESENTATION; ONLINE; SKIN
AB In modern society, where nations and even individuals are divided, building bridges between people of different personalities and backgrounds is essential to achieve harmonious coexistence. In recent years, research has been conducted on the use of technologies to bridge this gap. In this study, the effectiveness of using immersive virtual reality (IVR) technology to play the role of a stranger in helping people learn about and empathize with others was investigated. Specifically, participants were asked to role-play a first-time stranger in an IVR environment after being given prior information about the stranger via a preparatory video. The effects of role-playing between acting as a target stranger through his or her avatar in an immersive environment, acting through a different avatar in an immersive environment, and acting through his or her avatars in a non-immersive interface were compared. The results showed that using IVR technology with an exact avatar to play the target person was found to have the greatest effect on the participants' personalities and thoughts as well as increasing their empathy for that individual. This finding suggests that IVR technology may be an effective tool for bridging the gap between people from different backgrounds.
C1 [Sakuma, Hiroshi] Univ Tokyo, Grad Sch Arts & Sci, Tokyo, Japan.
   [Sakuma, Hiroshi; Takahashi, Hideyuki; Ishiguro, Hiroshi] Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
   [Ogawa, Kohei] Nagoya Univ, Grad Sch Engn Informat & Commun Engn, Nagoya, Japan.
C3 University of Tokyo; Osaka University; Nagoya University
RP Sakuma, H (corresponding author), Univ Tokyo, Grad Sch Arts & Sci, Tokyo, Japan.; Sakuma, H (corresponding author), Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
EM hiroshi.sakuma@acm.org
FU Masason Foundation
FX & nbsp;This work was supported by the Masason Foundation.
CR [Anonymous], 1988, FDN PSYCHODRAMA
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Banakou D, 2009, 13TH PANHELLENIC CONFERENCE ON INFORMATICS, PROCEEDINGS, P207, DOI 10.1109/PCI.2009.9
   Bedder RL, 2019, COGNITION, V184, P1, DOI 10.1016/j.cognition.2018.11.010
   Bermudez J. L., 2011, BODILY AWARENESS SEL, P157
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Ehrsson HH, 2020, MULTISENSORY PERCEPTION: FROM LABORATORY TO CLINIC, P179, DOI 10.1016/B978-0-12-812492-5.00008-5
   Farmer H, 2012, CONSCIOUS COGN, V21, P1242, DOI 10.1016/j.concog.2012.04.011
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   GRUDIN J, 1994, COMPUTER, V27, P19, DOI 10.1109/2.291294
   Haley KJ, 2005, EVOL HUM BEHAV, V26, P245, DOI 10.1016/j.evolhumbehav.2005.01.002
   Hu Rong., 2011, Proc. of ACM RecSys, P197
   Izuma K, 2011, P NATL ACAD SCI USA, V108, P17302, DOI 10.1073/pnas.1107038108
   Izuma K, 2010, J COGNITIVE NEUROSCI, V22, P621, DOI 10.1162/jocn.2009.21228
   Kellermann P.F., 1992, FOCUS PSYCHODRAMA TH
   Khan RF, 2014, INT J HUM-COMPUT INT, V30, P142, DOI 10.1080/10447318.2013.839904
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   McNeill WilliamH., 2022, Keeping Together in Time
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mifune N, 2010, EVOL HUM BEHAV, V31, P109, DOI 10.1016/j.evolhumbehav.2009.09.004
   Mitchell JP, 2006, NEURON, V50, P655, DOI 10.1016/j.neuron.2006.03.040
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Rivas AIB, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.695673
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Sakuma H., 2021, J JPN SOC ARTIF INTE, V36, P702
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Tacikowski P, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101429
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Thomson R, 2015, COMPUT HUM BEHAV, V51, P285, DOI 10.1016/j.chb.2015.04.068
   Tkalcic Marko., 2009, P 5 WORKSHOP EMOTION, P30
   Tommasel A, 2015, ONLINE INFORM REV, V39, P812, DOI 10.1108/OIR-04-2015-0107
   Wiltermuth SS, 2009, PSYCHOL SCI, V20, P1, DOI 10.1111/j.1467-9280.2008.02253.x
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zanbaka C., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1153
NR 39
TC 3
Z9 3
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 3
PY 2023
VL 4
AR 1025526
DI 10.3389/frvir.2023.1025526
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WP4
UT WOS:001023288000001
OA gold
DA 2024-07-18
ER

PT J
AU Roy, MJ
   Bellini, P
   Kruger, SE
   Dunbar, K
   Atallah, H
   Haight, T
   Vermetten, E
AF Roy, Michael J.
   Bellini, Paula
   Kruger, Sarah E.
   Dunbar, Kerri
   Atallah, Hannah
   Haight, Thaddeus
   Vermetten, Eric
TI Randomized controlled trial of motion-assisted exposure therapy for
   posttraumatic stress disorder after mild traumatic brain injury, with
   and without an eye movement task
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE combat stress; posttraumatic stress (PTSD); traumatic brain injury;
   virtual reality; eye movement
ID WORKING-MEMORY; DUAL-ATTENTION; SYMPTOMS; DESENSITIZATION;
   REHABILITATION; INTERVENTIONS; PSYCHOTHERAPY; ENVIRONMENT; PTSD
AB Background and Purpose: PTSD and mTBI are persistent and frequently comorbid after combat, yet current therapies often achieve only modest impact. A novel exposure-based "walk and talk" cognitive therapy, Motion-Assisted, Multi-Modal Memory Desensitization and Reconsolidation (3MDR), featuring participant-selected music and pictures and an eye movement (EM) task in an immersive virtual environment, has shown efficacy in treatment-resistant male veterans, but has not been studied in women or after TBI. The EM task is adapted from eye movement desensitization and reprocessing (EMDR) therapy, but dismantling studies of EMDR have questioned EM benefit. This pilot study assesses 3MDR in male and female veterans with comorbid PTSD and mTBI, and the impact of EM on response. We hypothesized that 3MDR would prove efficacious, both with (EM+) and without EM (EM-).Design: Participants with probable PTSD (PCL-5 = 34) and mTBI were randomized to EM + or EM-across 10 sessions. Participants provided songs and pictures that they rated on impactfulness. While walking in the 3MDR virtual environment, participants started with a song to bring them back to the time of their trauma, and then traversed two hallways, actively walking toward emotionally evocative pictures that they then discussed with their therapist. Key words or feelings they expressed were superimposed over the picture, then read aloud, whereupon EM + participants recited numbers flashing on a ball crisscrossing the picture. These procedures were repeated for multiple pictures per session. A song to return the participant to present day closed each session. Change in PCL-5 score from pre-to post-intervention was the primary outcome, with additional measures at 3 and 6 months.Results: Sixteen (80%) of 20 participants completed the intervention (8 EM+, 8 EM-); 9 (6 EM+, 3 EM-) had resolution of PTSD diagnosis and two improved significantly without resolution. Average PCL-5 score declined from 52.0 (95% confidence intervals: 46.3, 57.7) at baseline to 33.6 (24.3, 42.9) post-intervention (p < 0.01). The EM + group achieved statistically significant improvement (p = 0.01) while the EM-did not (p = 0.10).Conclusion: For veterans with PTSD and comorbid mTBI, 3MDR is effective, and the EM component may add value. Confirmation with larger studies is important.
C1 [Roy, Michael J.; Bellini, Paula; Dunbar, Kerri; Atallah, Hannah] Uniformed Serv Univ Hlth Sci, Dept Med, Bethesda, MD 20814 USA.
   [Roy, Michael J.; Bellini, Paula; Dunbar, Kerri; Atallah, Hannah; Haight, Thaddeus] Uniformed Serv Univ Hlth Sci, Ctr Neurosci & Regenerat Med, Bethesda, MD 20814 USA.
   [Roy, Michael J.] Walter Reed Natl Mil Med Ctr, Bethesda, MD 20814 USA.
   [Bellini, Paula; Dunbar, Kerri; Atallah, Hannah; Haight, Thaddeus] Henry M Jackson Fdn, Bethesda, MD USA.
   [Kruger, Sarah E.] Walter Reed Natl Mil Med Ctr, Natl Intrepid Ctr Excellence, Bethesda, MD USA.
   [Vermetten, Eric] Leiden Univ, Dept Psychiat, Med Ctr, Leiden, Netherlands.
C3 Uniformed Services University of the Health Sciences - USA; Uniformed
   Services University of the Health Sciences - USA; Walter Reed National
   Military Medical Center; Henry M. Jackson Foundation for the Advancement
   of Military Medicine, Inc; Walter Reed National Military Medical Center;
   Leiden University - Excl LUMC; Leiden University; Leiden University
   Medical Center (LUMC)
RP Roy, MJ (corresponding author), Uniformed Serv Univ Hlth Sci, Dept Med, Bethesda, MD 20814 USA.; Roy, MJ (corresponding author), Uniformed Serv Univ Hlth Sci, Ctr Neurosci & Regenerat Med, Bethesda, MD 20814 USA.; Roy, MJ (corresponding author), Walter Reed Natl Mil Med Ctr, Bethesda, MD 20814 USA.
EM MDMichael.roy@usuhs.edu
OI Roy, Michael/0000-0001-6727-774X
FU Center for Rehabilitation Sciences Research
FX This study was funded by the Center for Rehabilitation Sciences
   Research, and was provided with referrals and informatics support from
   the Center for Neuroscience and Regenerative Medicine, both at Uniformed
   Services University, and with logistical support and infrastructure at
   the National Intrepid Center of Excellence, Walter Reed National
   Military Medical Center (WRNMMC). The study design was approved by the
   WRNMMC Institutional Review Board at Walter Reed National Military
   Medical Center, protocol # WRNMMC-2018-0201, and was posted on
   clinicaltrials.gov, # NCT03796936.
CR Albright DL, 2010, BEHAV INTERVENT, V25, P1, DOI 10.1002/bin.295
   Beidel DC, 2019, J ANXIETY DISORD, V61, P64, DOI 10.1016/j.janxdis.2017.08.005
   Bisson JI, 2020, ACTA PSYCHIAT SCAND, V142, P141, DOI 10.1111/acps.13200
   Collins JD, 2015, WORK, V50, P121, DOI 10.3233/WOR-141927
   Costanzo ME, 2014, NEUROSCI LETT, V577, P11, DOI 10.1016/j.neulet.2014.05.054
   Dunbar KE, 2019, CYBERPSYCH BEH SOC N, V22, P761, DOI 10.1089/cyber.2019.0296
   Feinberg C, 2021, JAMA NEUROL, V78, P596, DOI 10.1001/jamaneurol.2020.5079
   Foa EB, 2018, JAMA-J AM MED ASSOC, V319, P354, DOI 10.1001/jama.2017.21242
   Gunter RW, 2008, BEHAV RES THER, V46, P913, DOI 10.1016/j.brat.2008.04.006
   Jetly C. R., 2017, 2017 INT C VIRTUAL R, P1, DOI [10.1109/ICVR.2017.8007474, DOI 10.1109/ICVR.2017.8007474]
   Kennedy JE, 2010, NEUROREHABILITATION, V26, P223, DOI 10.3233/NRE-2010-0558
   Lee CW, 2013, J BEHAV THER EXP PSY, V44, P231, DOI 10.1016/j.jbtep.2012.11.001
   Lee DJ, 2016, DEPRESS ANXIETY, V33, P792, DOI 10.1002/da.22511
   Loucks L, 2019, J ANXIETY DISORD, V61, P55, DOI 10.1016/j.janxdis.2018.06.004
   Mert A., 2011, J CYBERTHERAPY REHAB, V4
   Minen M, 2019, HEADACHE, V59, P151, DOI 10.1111/head.13455
   Nijdam MJ, 2018, EUR J PSYCHOTRAUMATO, V9, DOI 10.1080/20008198.2018.1458568
   Onakomaiya MM, 2017, MIL MED, V182, P128, DOI 10.7205/MILMED-D-16-00054
   Patel GJ, 2016, J EMDR PRACT RES, V10, P13, DOI 10.1891/1933-3196.10.1.13
   Rapcencu AE, 2017, PSYCHONEUROENDOCRINO, V82, P1, DOI 10.1016/j.psyneuen.2017.04.010
   Rauch Sheila A M, 2017, Focus (Am Psychiatr Publ), V15, P406, DOI 10.1176/appi.focus.20170021
   Robertson R., 2012, Mental Health and Physical Activity, V5, P66, DOI [DOI 10.1016/J.MHPA.2012.03.002, DOI 10.1016/J.MHPA.2012.03]
   Rosenbaum S, 2016, AUSTRALAS PSYCHIATRY, V24, P49, DOI 10.1177/1039856215590252
   Roy MJ, 2014, STUD HEALTH TECHNOL, V199, P61, DOI 10.3233/978-1-61499-401-5-61
   Roy MJ, 2010, ANN NY ACAD SCI, V1208, P142, DOI 10.1111/j.1749-6632.2010.05689.x
   Sack M, 2016, PSYCHOTHER PSYCHOSOM, V85, P357, DOI 10.1159/000447671
   Samara Zoe, 2011, Front Psychiatry, V2, P4, DOI 10.3389/fpsyt.2011.00004
   Schubert SJ, 2011, J ANXIETY DISORD, V25, P1, DOI 10.1016/j.janxdis.2010.06.024
   Shapiro F., 1989, J TRAUMA STRESS, V2, P199, DOI [DOI 10.1002/JTS.2490020207, 10.1002/jts.2490020207]
   Steenkamp MM, 2015, JAMA-J AM MED ASSOC, V314, P489, DOI 10.1001/jama.2015.8370
   VA/DOD, 2017, CLIN PRACTICE GUIDEL
   van den Hout MA, 2010, APPL COGNITIVE PSYCH, V24, P303, DOI 10.1002/acp.1677
   van Gelderen MJ, 2020, PSYCHOTHER PSYCHOSOM, V89, P215, DOI 10.1159/000505977
   van Gelderen MJ, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00176
   Vermetten E, 2013, STUD HEALTH TECHNOL, V191, P125, DOI 10.3233/978-1-61499-282-0-125
NR 35
TC 1
Z9 1
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 22
PY 2022
VL 3
AR 1005774
DI 10.3389/frvir.2022.1005774
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XY5
UT WOS:001023323200001
OA gold
DA 2024-07-18
ER

PT J
AU Kiser, DP
   Gromer, D
   Pauli, P
   Hilger, K
AF Kiser, Dominik P. P.
   Gromer, Daniel
   Pauli, Paul
   Hilger, Kirsten
TI A virtual reality social conditioned place preference paradigm for
   humans: Does trait social anxiety affect approach and avoidance of
   virtual agents?
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE retranslational research; conditioned place preference;
   approach-avoidance; social anxiety; virtual reality; personality traits;
   individual differences
ID ADULT MALE; REWARD; RESPONSES; DISORDER; FACES; SELF; ADOLESCENT;
   CONCURRENT; QUESTIONS; RELEVANT
AB Approach and avoidance of positive and negative social cues are fundamental to prevent isolation and ensure survival. High trait social anxiety is characterized by an avoidance of social situations and extensive avoidance is a risk factor for the development of social anxiety disorder (SAD). Therefore, experimental methods to assess social avoidance behavior in humans are essential. The social conditioned place preference (SCPP) paradigm is a well-established experimental paradigm in animal research that is used to objectively investigate social approach-avoidance mechanisms. We retranslated this paradigm for human research using virtual reality. To this end, 58 healthy adults were exposed to either a happy- or angry-looking virtual agent in a specific room, and the effects of this encounter on dwell time as well as evaluation of this room in a later test without an agent were examined. We did not observe a general SCPP effect on dwell time or ratings but discovered a moderation by trait social anxiety, in which participants with higher trait social anxiety spent less time in the room in which the angry agent was present before, suggesting that higher levels of trait social anxiety foster conditioned social avoidance. However, further studies are needed to verify this observation and substantiate an association with social anxiety disorder. We discussed the strengths, limitations, and technical implications of our paradigm for future investigations to more comprehensively understand the mechanisms involved in social anxiety and facilitate the development of new personalized treatment approaches by using virtual reality.
C1 [Kiser, Dominik P. P.; Gromer, Daniel; Pauli, Paul; Hilger, Kirsten] Univ Wurzburg, Dept Psychol 1, Wurzburg, Germany.
C3 University of Wurzburg
RP Hilger, K (corresponding author), Univ Wurzburg, Dept Psychol 1, Wurzburg, Germany.
EM kirsten.hilger@uni-wuerzburg.de
FU Volkswagen Foundation [AZ 94 102]; German Federal Ministry of Education
   and Research within the research project "SKRIBT" [FKZ: 12N9636];
   Wuerzburg University
FX This study was supported by the Volkswagen Foundation (AZ 94 102). The
   PsyCave was financed by the German Federal Ministry of Education and
   Research within the research project "SKRIBT" (FKZ: 12N9636). This
   publication was supported by open-access funds from Wuerzburg
   University.
CR Achenbach J., 2017, P ACM S VIRT REAL SO
   Alvi T, 2020, J ABNORM PSYCHOL, V129, P108, DOI 10.1037/abn0000493
   Asher M, 2017, CLIN PSYCHOL REV, V56, P1, DOI 10.1016/j.cpr.2017.05.004
   Astur RS, 2016, BEHAV BRAIN RES, V297, P15, DOI 10.1016/j.bbr.2015.09.042
   Astur RS, 2014, BEHAV BRAIN RES, V267, P173, DOI 10.1016/j.bbr.2014.03.018
   Baron D, 2020, NEUROBIOL LEARN MEM, V172, DOI 10.1016/j.nlm.2020.107235
   Barth J., 2003, Z MED PSYCHOL, V12, P4
   BEIDEL DC, 1989, BEHAV THER, V20, P417, DOI 10.1016/S0005-7894(89)80060-7
   Bögels SM, 2010, DEPRESS ANXIETY, V27, P168, DOI 10.1002/da.20670
   CALCAGNETTI DJ, 1992, PHYSIOL BEHAV, V51, P667, DOI 10.1016/0031-9384(92)90101-7
   CARVER CS, 1994, J PERS SOC PSYCHOL, V67, P319, DOI 10.1037/0022-3514.67.2.319
   Childs E, 2016, ADDICTION, V111, P2157, DOI 10.1111/add.13540
   Childs E, 2009, BIOL PSYCHIAT, V65, P900, DOI 10.1016/j.biopsych.2008.11.016
   Corr PJ, 2012, NEUROSCI BIOBEHAV R, V36, P2339, DOI 10.1016/j.neubiorev.2012.09.013
   Costa P. T., 1989, Neo five-factor inventory (neo-ffi), P3
   Cross SE, 1997, PSYCHOL BULL, V122, P5, DOI 10.1037/0033-2909.122.1.5
   Cross SE, 2011, PERS SOC PSYCHOL REV, V15, P142, DOI 10.1177/1088868310373752
   DARLING F. F., 1952, AUK, V69, P183
   Dawel A, 2022, BEHAV RES METHODS, V54, P1889, DOI 10.3758/s13428-021-01705-3
   Dawel A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00462
   DIAMOND R, 1986, J EXP PSYCHOL GEN, V115, P107, DOI 10.1037/0096-3445.115.2.107
   Dimberg U, 1996, MOTIV EMOTION, V20, P149, DOI 10.1007/BF02253869
   DIMBERG U, 1982, PSYCHOPHYSIOLOGY, V19, P643, DOI 10.1111/j.1469-8986.1982.tb02516.x
   Dixon LM, 2013, APPL ANIM BEHAV SCI, V148, P164, DOI 10.1016/j.applanim.2013.07.012
   Douglas LA, 2004, DEV PSYCHOBIOL, V45, P153, DOI 10.1002/dev.20025
   Emmelkamp PMG, 2021, ANNU REV CLIN PSYCHO, V17, P495, DOI 10.1146/annurev-clinpsy-081219-115923
   Everitt BJ, 2018, PHILOS T R SOC B, V373, DOI 10.1098/rstb.2017.0027
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fydrich T., 2002, DIAGNOSTISCHE VERFAH, P335
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   Golden SA, 2017, GENES BRAIN BEHAV, V16, P44, DOI 10.1111/gbb.12310
   Gray J.A., 1972, The biological bases of individual behavior, P372
   Gromer D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85678-5
   Gromer D, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00372
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Hiller LT, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00187
   Hogarth L, 2006, ADDICTION, V101, P1153, DOI 10.1111/j.1360-0443.2006.01459.x
   Iacobucci D, 2017, BEHAV RES METHODS, V49, P403, DOI 10.3758/s13428-016-0827-9
   Iacobucci D, 2016, BEHAV RES METHODS, V48, P1308, DOI 10.3758/s13428-015-0624-x
   Ikemoto S, 2005, SYNAPSE, V56, P57, DOI 10.1002/syn.20124
   Johnson RR, 2004, J BUS TECH COMMUN, V18, P251, DOI 10.1177/1050651904182008
   Kirlic N, 2017, BEHAV RES THER, V96, P14, DOI 10.1016/j.brat.2017.04.010
   Kummer K, 2011, FRONT BEHAV NEUROSCI, V5, DOI 10.3389/fnbeh.2011.00080
   Kummer KK, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00363
   Latoschik M. E., 2017, P ACM S VIRT REAL SO
   Linhardt M, 2022, BEHAV BRAIN RES, V426, DOI 10.1016/j.bbr.2022.113834
   Lissek S, 2008, AM J PSYCHIAT, V165, P124, DOI 10.1176/appi.ajp.2007.06091513
   Lovibond PF, 2002, J EXP PSYCHOL-ANIM B, V28, P3, DOI 10.1037//0097-7403.28.1.3
   Malkesman O, 2005, BEHAV BRAIN RES, V164, P1, DOI 10.1016/j.bbr.2005.04.023
   MARKUS HR, 1991, PSYCHOL REV, V98, P224, DOI 10.1037/0033-295X.98.2.224
   McGlynn F.D., 1981, Clinical Psychology Review, V1, P149, DOI 10.1016/0272-7358(81)90001-5
   Molet M, 2013, BEHAV PROCESS, V92, P31, DOI 10.1016/j.beproc.2012.10.001
   Mühlberger A, 2008, CYBERPSYCHOL BEHAV, V11, P425, DOI 10.1089/cpb.2007.0084
   Mühlberger A, 2011, SOC COGN AFFECT NEUR, V6, P321, DOI 10.1093/scan/nsq039
   Nikitin J., 2021, HDB SOLITUDE PSYCHOL
   Öhman A, 2009, SCAND J PSYCHOL, V50, P543, DOI 10.1111/j.1467-9450.2009.00784.x
   Palmisano AN, 2018, ADDICT BEHAV, V77, P51, DOI 10.1016/j.addbeh.2017.09.008
   Paredes RG, 1997, BEHAV NEUROSCI, V111, P123, DOI 10.1037/0735-7044.111.1.123
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Reichenberger J, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00035
   Rice K., 2021, J Depress Anxiety, V10, P2167, DOI [DOI 10.35248/2167-1044.21.10.406, 10.35248/2167-1044.21.10.406]
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Riva G, 2009, BRIT J GUID COUNS, V37, P337, DOI 10.1080/03069880902957056
   Ruscio AM, 2010, J ABNORM PSYCHOL, V119, P662, DOI 10.1037/a0019341
   Schmidt KL, 2001, YEARB PHYS ANTHROPOL, V44, P3, DOI 10.1002/ajpa.20001
   Schneier FR, 2002, PSYCHIAT CLIN N AM, V25, P757, DOI 10.1016/S0193-953X(02)00018-7
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Schwabe K, 2006, BEHAV BRAIN RES, V168, P150, DOI 10.1016/j.bbr.2005.11.005
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Shipman SL, 2006, 2006 INTERNATIONAL WORKSHOP ON VIRTUAL REHABILITATION, P58, DOI 10.1109/IWVR.2006.1707528
   Smits DJM, 2006, EUR J PERSONALITY, V20, P255, DOI 10.1002/per.583
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Stein MB, 2002, J NERV MENT DIS, V190, P219, DOI 10.1097/00005053-200204000-00002
   Stein MB, 2008, LANCET, V371, P1115, DOI 10.1016/S0140-6736(08)60488-2
   Taber KS, 2018, RES SCI EDUC, V48, P1273, DOI 10.1007/s11165-016-9602-2
   Tavakol M, 2011, INT J MED EDUC, V2, P53, DOI 10.5116/ijme.4dfb.8dfd
   Thiel KJ, 2008, DRUG ALCOHOL DEPEN, V96, P202, DOI 10.1016/j.drugalcdep.2008.02.013
   Thiel KJ, 2009, PSYCHOPHARMACOLOGY, V204, P391, DOI 10.1007/s00213-009-1470-2
   Torro-Alves N., 2016, Psychology and Neuroscience, V9, P1, DOI [10.1037/pne0000042, DOI 10.1037/PNE0000042]
   Tzschentke TM, 2007, ADDICT BIOL, V12, P227, DOI 10.1111/j.1369-1600.2007.00070.x
   van den Akker K, 2013, APPETITE, V70, P73, DOI 10.1016/j.appet.2013.06.092
   VANDERKOOY D, 1982, BRAIN RES, V243, P107, DOI 10.1016/0006-8993(82)91124-6
   Vincelli F, 1999, Cyberpsychol Behav, V2, P241, DOI 10.1089/cpb.1999.2.241
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Walz N, 2016, BIOL PSYCHIAT, V80, P390, DOI 10.1016/j.biopsych.2015.12.016
   Weyers P, 2006, PSYCHOPHYSIOLOGY, V43, P450, DOI 10.1111/j.1469-8986.2006.00451.x
   Wieser MJ, 2010, PSYCHOPHYSIOLOGY, V47, P271, DOI 10.1111/j.1469-8986.2009.00938.x
   Wieser MJ, 2009, J ANXIETY DISORD, V23, P93, DOI 10.1016/j.janxdis.2008.04.004
   Yates JR, 2013, DRUG ALCOHOL DEPEN, V129, P240, DOI 10.1016/j.drugalcdep.2013.02.024
   Zanbaka C. A., 2007, C HUM FACT COMP SYST
NR 90
TC 1
Z9 1
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 8
PY 2022
VL 3
AR 916575
DI 10.3389/frvir.2022.916575
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4TG5
UT WOS:001023200700001
OA Green Published, gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Thiel, FJ
   Steed, A
AF Thiel, Felix J.
   Steed, Anthony
TI Developing an Accessibility Metric for VR Games Based on Motion Data
   Captured Under Game Conditions
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; accessibility; motion analysis; video games; user
   study; motion capture
AB Virtual Reality (VR) games are not as accessible as conventional video games because they heavily rely on the motion of the body as the main means of input. This causes large accessibility issues because it prevents some physically impaired players from using them. It also makes it more difficult to develop accessibility tools to address the issues. Given these challenges, it is of particular importance that an impaired player can determine whether they will be able to play a game before they buy it. We propose the first prototype of a metric that aims at visually presenting the important aspects of the body motion that a game requires. Instead of manual classification, the metric is based on data captured from able-bodied players that play the game as designed. In this work, we introduce the metric itself, demonstrate how it differentiates six popular VR games based on data we collected in a user study, and discuss limitations and routes for further development.
C1 [Thiel, Felix J.; Steed, Anthony] UCL, Dept Comp Sci, Virtual Environm & Comp Graph, London, England.
C3 University of London; University College London
RP Thiel, FJ (corresponding author), UCL, Dept Comp Sci, Virtual Environm & Comp Graph, London, England.
EM felix.thiel.18@ucl.ac.uk
OI Steed, Anthony/0000-0001-9034-3020
CR [Anonymous], 2009, Biomechanics and motor control of human movement
   Beeston J, 2018, LECT NOTES COMPUT SC, V10896, P245, DOI 10.1007/978-3-319-94277-3_40
   Chung Gu-Young, 2016, J Phys Ther Sci, V28, P1584, DOI 10.1589/jpts.28.1584
   Gerling K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376265
   Giraud T, 2016, HUM MOVEMENT SCI, V49, P9, DOI 10.1016/j.humov.2016.05.009
   Heron Michael James, 2018, Computer Games Journal, V7, P75, DOI 10.1007/s40869-018-0056-9
   Heron Michael James, 2018, Computer Games Journal, V7, P97, DOI 10.1007/s40869-018-0057-8
   Heron M.J., 2016, The Computer Games Journal, V5, P91, DOI [10.1007/s40869-016-0028-x, DOI 10.1007/S40869-016-0028-X]
   Maes PJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054682
   Mott ME, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI [10.1145/3396956.3396969, 10.1145/3373625.3416998]
   Nagymate G., 2018, RECENT INNOV MECHATR, V5, P1, DOI DOI 10.17667/RIIM.2018.1/13
   Nishida K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171535
   Pesántez-Cabrera P, 2020, IEEE INT CONF SERIOU, DOI 10.1109/segah49190.2020.9201655
   von Laban Rudolf., 1971, The Mastery of Movement, V3rd
NR 14
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 22
PY 2022
VL 3
AR 909357
DI 10.3389/frvir.2022.909357
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WN4
UT WOS:001019186800001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Boyce, MW
   Thomson, RH
   Cartwright, JK
   Feltner, DT
   Stainrod, CR
   Flynn, J
   Ackermann, C
   Emezie, J
   Amburn, CR
   Rovira, E
AF Boyce, Michael W.
   Thomson, Robert H.
   Cartwright, Joel K.
   Feltner, David T.
   Stainrod, Cortnee R.
   Flynn, Jeremy
   Ackermann, Christian
   Emezie, John
   Amburn, Charles R.
   Rovira, Ericka
TI Enhancing Military Training Using Extended Reality: A Study of Military
   Tactics Comprehension
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE EXtended reality (XR); Microsoft HoloLens; United States military
   academy (USMA); system usability scale; NASA-TLX; battlespace
   visualization and interaction (BVI); augmented REality sand table
   (ARES); simulation and training
ID 2D; 3D; COMBINATION; DESIGN
AB This study identifies that increasing the fidelity of terrain representation does not necessarily increase overall understanding of the terrain in a simulated mission planning environment using the Battlefield Visualization and Interaction software (BVI; formerly known as ARES (M. W. Boyce et al., International Conference on Augmented Cognition, 2017, 411-422). Prior research by M. Boyce et al. (Military Psychology, 2019, 31(1), 45-59) compared human performance on a flat surface (tablet) versus topographically-shaped surface (BVI on a sand table integrated with top-down projection). Their results demonstrated that the topographically-shaped surface increased the perceived usability of the interface and reduced cognitive load relative to the flat interface, but did not affect overall task performance (i.e., accuracy and response time). The present study extends this work by adding BVI onto a Microsoft HoloLens & TRADE;. A sample of 72 United States Military Academy cadets used BVI on three different technologies: a tablet, a sand table (a projection-based display onto a military sand table), and on the HoloLens & TRADE; in a within-subjects design. Participants answered questions regarding military tactics in the context of conducting an attack in complex terrain. While prior research (Dixon et al., Display Technologies and Applications for Defense, Security, and Avionics III, 2009, 7327) suggested that the full 3D visualization used by the Hololens & TRADE; should improve performance relative to the sand table and tablet, our results demonstrated that the HoloLens & TRADE; performed relatively worse than the other modalities in accuracy, response time, cognitive load, and usability. Implications and limitations of this work will be discussed.
C1 [Boyce, Michael W.; Amburn, Charles R.] US Army DEVCOM Soldier Ctr, Simulat & Training Technol Ctr, Orlando, FL 32826 USA.
   [Boyce, Michael W.; Thomson, Robert H.; Cartwright, Joel K.; Feltner, David T.; Ackermann, Christian; Emezie, John; Rovira, Ericka] US Mil Acad, Dept Behav Sci & Leadership, West Point, NY 10996 USA.
   [Boyce, Michael W.; Thomson, Robert H.] US Mil Acad, Army Cyber Inst, West Point, NY 10996 USA.
   [Stainrod, Cortnee R.; Flynn, Jeremy] Univ Cent Florida, Inst Simulat & Training, Orlando, FL USA.
C3 United States Department of Defense; United States Army; United States
   Military Academy; United States Military Academy; Army Cyber Institute
   (ACI); United States Department of Defense; United States Army; State
   University System of Florida; University of Central Florida
RP Boyce, MW (corresponding author), US Army DEVCOM Soldier Ctr, Simulat & Training Technol Ctr, Orlando, FL 32826 USA.; Boyce, MW (corresponding author), US Mil Acad, Dept Behav Sci & Leadership, West Point, NY 10996 USA.; Boyce, MW (corresponding author), US Mil Acad, Army Cyber Inst, West Point, NY 10996 USA.
EM michael.w.boyce11.civ@army.mil
OI Thomson, Robert/0000-0001-9298-2870
CR Ahlstrom V., 2007, HUMAN FACTORS CRITER
   AMBURN C R, 2015, The augmented reality sand table(ARES)R
   [Anonymous], 1988, P HUM FACTORS SOC AN, DOI [DOI 10.1177/154193128803200232, 10.1177/154193128803200232]
   ARETZ AJ, 1991, HUM FACTORS, V33, P85, DOI 10.1177/001872089103300107
   Army U., 2012, OFFENSE DEFENSE
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Boyce Michael W., 2017, Augmented Cognition: Enhancing Cognition and Behavior in Complex Human Environments. 11th International Conference, AC 2017, held as part of HCI International 2017. Proceedings: LNAI 10285, P411, DOI 10.1007/978-3-319-58625-0_30
   Boyce M.W., 2016, Effect of topography on learning military tactics-integration of generalized intelligent framework for tutoring (gift) and augmented reality sandtable (ares)
   Boyce MW, 2019, MIL PSYCHOL, V31, P45, DOI 10.1080/08995605.2018.1529487
   BROADBENT DE, 1982, ACTA PSYCHOL, V50, P253, DOI 10.1016/0001-6918(82)90043-9
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Carrera CC, 2017, J GEOGR, V116, P197, DOI 10.1080/00221341.2016.1248857
   Coltekin A., 2020, GEOSPATIAL INFORM VI, P229
   Council N. R., 1997, TACTICAL DISPLAY SOL
   Dixon Sharon, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7327, DOI 10.1117/12.820853
   Gawlik-Kobylinska M., 2020, P 2020 9 INT C ED IN, P144
   Goldstein P., 2020, ARMY USES AR MAKETRA
   Hall DS, 2012, J COGN ENG DECIS MAK, V6, P165, DOI 10.1177/1555343412440696
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Haskell I.D., 1993, INT J AVIAT PSYCHOL, V3, P87
   Herbert G, 2015, CARTOGR GEOGR INF SC, V42, P22, DOI 10.1080/15230406.2014.987694
   Hocraffer A, 2017, APPL ERGON, V58, P66, DOI 10.1016/j.apergo.2016.05.011
   Hoonakker Peter, 2011, IIE Trans Healthc Syst Eng, V1, P131
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Kenney C. M., 2021, ARMY DELAYSIVAS DISP
   Martin L., 2019, 3 TECHNOLOGIES TRANS
   O'Banion M.S., 2020, Surveying and Land Information Science, V79, P15
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   Rapp D.N., 2007, J GEOSCIENCE ED, V55, P5, DOI 10.5408/1089-9995-55.1.5
   Roo JS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P787, DOI 10.1145/3126594.3126638
   Sauro J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2215, DOI 10.1145/1978942.1979266
   Sprigg S., 2020, AUGANIX
   St John M, 2001, HUM FACTORS, V43, P79, DOI 10.1518/001872001775992534
   St John M., 2000, NAVIGATING 2 DIMENSI
   Tory M, 2006, IEEE T VIS COMPUT GR, V12, P2, DOI 10.1109/TVCG.2006.17
   TREISMAN AM, 1964, BRIT MED BULL, V20, P12, DOI 10.1093/oxfordjournals.bmb.a070274
   Verma J., 2020, Determining Sample Size and Power in Research Studies, P55, DOI DOI 10.1007/978-981-15-5204-55
   Wickens Chris, 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P686, DOI 10.1177/1541931218621155
   Wickens C. D., 2000, P HUM FACT ERG SOC A, V44, DOI [10.1177/154193120004402119, DOI 10.1177/154193120004402119]
   Wickens CD, 1995, HUM FACTORS, V37, P473, DOI 10.1518/001872095779049408
   Xiao Yuan-mei, 2005, Zhonghua Lao Dong Wei Sheng Zhi Ye Bing Za Zhi, V23, P178
NR 41
TC 5
Z9 5
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 8
PY 2022
VL 3
AR 754627
DI 10.3389/frvir.2022.754627
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2RU5
UT WOS:001021790500001
OA gold
DA 2024-07-18
ER

PT J
AU Misersky, J
   Peeters, D
   Flecken, M
AF Misersky, Julia
   Peeters, David
   Flecken, Monique
TI The Potential of Immersive Virtual Reality for the Study of Event
   Perception
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; event perception; eye tracking; cave; motion events
ID COGNITION; LANGUAGE
AB In everyday life, we actively engage in different activities from a first-person perspective. However, experimental psychological research in the field of event perception is often limited to relatively passive, third-person computer-based paradigms. In the present study, we tested the feasibility of using immersive virtual reality in combination with eye tracking with participants in active motion. Behavioral research has shown that speakers of aspectual and non-aspectual languages attend to goals (endpoints) in motion events differently, with speakers of non-aspectual languages showing relatively more attention to goals (endpoint bias). In the current study, native speakers of German (non-aspectual) and English (aspectual) walked on a treadmill across 3-D terrains in VR, while their eye gaze was continuously tracked. Participants encountered landmark objects on the side of the road, and potential endpoint objects at the end of it. Using growth curve analysis to analyze fixation patterns over time, we found no differences in eye gaze behavior between German and English speakers. This absence of cross-linguistic differences was also observed in behavioral tasks with the same participants. Methodologically, based on the quality of the data, we conclude that our dynamic eye-tracking setup can be reliably used to study what people look at while moving through rich and dynamic environments that resemble the real world.
C1 [Misersky, Julia; Flecken, Monique] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Peeters, David; Flecken, Monique] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Peeters, David] Tilburg Univ, Dept Commun & Cognit, TiCC, Tilburg, Netherlands.
   [Flecken, Monique] Univ Amsterdam, Amsterdam Ctr Language & Commun, Nijmegen, Netherlands.
   [Flecken, Monique] Univ Amsterdam, Amsterdam Ctr Language & Commun, Amsterdam, Netherlands.
C3 Max Planck Society; Max Planck Society; Tilburg University; University
   of Amsterdam; University of Amsterdam
RP Misersky, J (corresponding author), Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
EM julia.misersky@mpi.nl
RI Peeters, David/U-7720-2018
OI Peeters, David/0000-0002-7974-9246
CR Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Askamp J, 2014, INT J PSYCHOPHYSIOL, V91, P30, DOI 10.1016/j.ijpsycho.2013.09.002
   Athanasopoulos P, 2013, COGNITIVE SCI, V37, P286, DOI 10.1111/cogs.12006
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Blanco-Elorrieta E, 2018, TRENDS COGN SCI, V22, P1117, DOI 10.1016/j.tics.2018.10.001
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Campos JL, 2012, EXP BRAIN RES, V218, P551, DOI 10.1007/s00221-012-3048-1
   Cañigueral R, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00560
   Cruz-Neira C., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P59, DOI 10.1109/VRAIS.1993.378262
   Eichert N, 2018, BEHAV RES METHODS, V50, P1102, DOI 10.3758/s13428-017-0929-z
   Flecken M, 2015, LANG COGN, V7, P138, DOI 10.1017/langcog.2014.20
   Flecken M, 2014, LANG COGN, V6, P45, DOI 10.1017/langcog.2013.2
   Gramann K, 2014, INT J PSYCHOPHYSIOL, V91, P22, DOI 10.1016/j.ijpsycho.2013.09.003
   Hari R, 2015, NEURON, V88, P181, DOI 10.1016/j.neuron.2015.09.022
   Heyselaar E., 2015, INDIVIDUAL DIFFERENC
   Heyselaar E, 2021, LANG COGN NEUROSCI, V36, P440, DOI 10.1080/23273798.2020.1859568
   Holleman GA, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00721
   Hömke P, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208030
   Hutton SB, 2019, STUD NEUROSCI, P277, DOI 10.1007/978-3-030-20085-5_8
   Klein Wolfgang., 1994, Time in Language
   Knoeferle P, 2015, ATTENTION VISION LAN
   Krohn S, 2020, J MED INTERNET RES, V22, DOI 10.2196/16724
   Magliano JP, 2014, J COGN PSYCHOL, V26, P649, DOI 10.1080/20445911.2014.930042
   Mirault J., 2020, Methods in Psychology, V3, P100029, DOI [10.1016/j.metip.2020.100029, DOI 10.1016/J.METIP.2020.100029, https://doi.org/10.1016/j.metip.2020.100029]
   Mirman D., 2016, Growth curve analysis and visualization using R
   Nolle J., 2020, EVOLUTION LANGUAGE P, DOI [10.17617/2.3190925, DOI 10.17617/2.3190925]
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Peelle J. E., 2020, TIME STAND STILL EFF, DOI [10.31234/osf.io/pc3da, DOI 10.31234/OSF.IO/PC3DA]
   Peeters D, 2019, PSYCHON B REV, V26, P894, DOI 10.3758/s13423-019-01571-3
   Peeters D, 2018, BILING-LANG COGN, V21, P1035, DOI 10.1017/S1366728917000396
   Peeters D, 2018, BEHAV RES METHODS, V50, P1047, DOI 10.3758/s13428-017-0925-3
   Pinti P, 2020, ANN NY ACAD SCI, V1464, P5, DOI 10.1111/nyas.13948
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Sassenhagen J, 2016, BRAIN LANG, V162, P42, DOI 10.1016/j.bandl.2016.08.001
   Sauppe S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01648
   Schilbach L, 2013, BEHAV BRAIN SCI, V36, P393, DOI 10.1017/S0140525X12000660
   Shamay-Tsoory SG, 2019, PERSPECT PSYCHOL SCI, V14, P841, DOI 10.1177/1745691619856350
   Steptoe W., 2008, P 2008 ACM C COMP SU, DOI [10.1145/1460563.1460593, DOI 10.1145/1460563.1460593]
   Swallow KM, 2018, COGNITION, V177, P249, DOI 10.1016/j.cognition.2018.04.019
   Tromp J, 2018, BEHAV RES METHODS, V50, P862, DOI 10.3758/s13428-017-0911-9
   von Stutterheim C, 2012, LINGUISTICS, V50, P833, DOI 10.1515/ling-2012-0026
   Willems RM, 2015, COGNITIVE NEUROSCIENCE OF NATURAL LANGUAGE USE, P1
NR 44
TC 0
Z9 0
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 1
PY 2022
VL 3
AR 697934
DI 10.3389/frvir.2022.697934
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZV6
UT WOS:001019274300001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Katifori, A
   Lougiakis, C
   Roussou, M
AF Katifori, Akrivi
   Lougiakis, Christos
   Roussou, Maria
TI Exploring the Effect of Personality Traits in VR Interaction: The
   Emergent Role of Perspective-Taking in Task Performance
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; VR interaction; object manipulation; task performance;
   personality traits; perspective-taking; user modeling
ID VIRTUAL-REALITY; EMPATHY; QUESTIONNAIRE; DISSOCIATION; ABSORPTION;
   IMMERSION; VALIDITY
AB In this work we explore the effect of personality traits on user interaction in virtual reality (VR), on the less widely studied aspect of task performance during object manipulation. We conducted an experiment measuring the performance of 39 users interacting with a virtual environment using the virtual hand metaphor to execute a simple selection and positioning task, with or without virtual obstacles. Our findings suggest concrete correlations between user personality traits and behavior data. Perspective-taking, in particular, seems to be strongly affecting task performance, highlighting the need for further research. Besides the wider implications of our results in relation to the effect of personality on how users experience VR, our main contribution lies in identifying specific traits that should be taken into account when designing experiments involving users performing such tasks. The study of these traits may also significantly advance our understanding of personality traits as part of the user model in a wider range of VR applications, including those offering personalization and recommendation functionality.
C1 [Katifori, Akrivi; Lougiakis, Christos; Roussou, Maria] Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens, Greece.
   [Katifori, Akrivi; Lougiakis, Christos] ATHENA Res & Innovat Ctr, Athens, Greece.
C3 National & Kapodistrian University of Athens
RP Katifori, A (corresponding author), Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens, Greece.; Katifori, A (corresponding author), ATHENA Res & Innovat Ctr, Athens, Greece.
EM vivi@di.uoa.gr
CR Alsina I., 2005, PRESENCE 2005, P133
   Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   Antoniou A, 2019, LECT NOTES COMPUT SC, V11385, P422, DOI 10.1007/978-3-030-11548-7_41
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Barbot B, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106431
   Bergström J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445193
   BERNSTEIN EM, 1986, J NERV MENT DIS, V174, P727, DOI 10.1097/00005053-198612000-00004
   Bissonnette J, 2016, VIRTUAL REAL-LONDON, V20, P71, DOI 10.1007/s10055-016-0283-y
   Bowman D. A., 2004, 3D USER INTERFACES T, V1st edn, P512
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Canales R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343132
   Caspi A, 2005, ANNU REV PSYCHOL, V56, P453, DOI 10.1146/annurev.psych.55.090902.141913
   Costa PT, 1992, Revised NEO Personality Inventory (NEO PI-R) and NEO Five-Factor Inventory (NEO-FFI), P101
   Cummings J. A., 2019, INTRO PSYCHOLOGYUNIV
   Davis M. H., 1996, EMPATHY SOCIAL PSYCH, V1st edn, P271
   Davis M. H., 1980, JSAS CATALOG SELECTE, V10, P85, DOI DOI 10.1037/0022-3514.44.1.113
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Eskes P, 2016, COMPUT HUM BEHAV, V59, P39, DOI 10.1016/j.chb.2016.01.024
   Favaretto R, 2017, SIBGRAPI, P223, DOI 10.1109/SIBGRAPI.2017.36
   Flavell J H, 1977, Nebr Symp Motiv, V25, P43
   González RJ, 2017, ANTHROPOL TODAY, V33, P9, DOI 10.1111/1467-8322.12348
   Graumann C. F., 2002, PERSPECTIVE PERSPECT, P25, DOI [10.1075/hcp.9.04gra, DOI 10.1075/HCP.9]
   Gunter B., 2016, PSYCHOL CONSUMER PRO
   Hale K S., 2014, Handbook of Virtual Environments: Design, Implementation, and Applications, V0th, DOI DOI 10.1201/B17360
   Hand C, 1997, COMPUT GRAPH FORUM, V16, P269, DOI 10.1111/1467-8659.00194
   Jankowski J., 2013, EUROGRAPHICS 2013 ST, P65, DOI [10.2312/conf/EG2013/stars/065-093, DOI 10.2312/CONF/EG2013/STARS/065-093]
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Jia Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2001, DOI 10.1145/2858036.2858515
   Kizony R, 2006, CYBERPSYCHOL BEHAV, V9, P687
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Laarni J., 2004, P 7 ANN INT WORKSHOP, P88
   Lackey SJ, 2016, ERGONOMICS, V59, P1060, DOI 10.1080/00140139.2015.1122234
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.00-32, 10.1109/VR46266.2020.1581086151885]
   Masurovsky A, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040091
   McDonald J.D., 2008, ENQUIRE, V1, P75
   Mori A, 2016, EDUC PSYCHOL REV, V28, P267, DOI 10.1007/s10648-015-9306-6
   Murray CD, 2007, COMPUT HUM BEHAV, V23, P1347, DOI 10.1016/j.chb.2004.12.010
   Piaget J., 2003, PSYCHOL INTELLIGENCE, DOI [10.4324/9780203164730, DOI 10.4324/9780203164730]
   Piaget J., 1967, CHILDS CONCEPT SPACE, P490
   Poupyrev I., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P21, DOI 10.1145/261135.261141
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Qin H, 2009, INT J HUM-COMPUT INT, V25, P107, DOI 10.1080/10447310802546732
   Roberts BW, 2007, PERSPECT PSYCHOL SCI, V2, P313, DOI 10.1111/j.1745-6916.2007.00047.x
   ROTTER JB, 1966, PSYCHOL MONOGR, V80, P1, DOI 10.1037/h0092976
   Sacau A., 2005, 8 INT WORKSHOP PRESE, P143
   Sacau A, 2008, COMPUT HUM BEHAV, V24, P2255, DOI 10.1016/j.chb.2007.11.001
   Sas C, 2003, PRESENCE-TELEOP VIRT, V12, P523, DOI 10.1162/105474603322761315
   Schutte NS, 2017, MOTIV EMOTION, V41, P708, DOI 10.1007/s11031-017-9641-7
   SELMAN RL, 1971, CHILD DEV, V42, P1721, DOI 10.2307/1127580
   SELMAN RL, 1974, CHILD DEV, V45, P803
   SHEEHAN PW, 1967, J CLIN PSYCHOL, V23, P386, DOI 10.1002/1097-4679(196707)23:3<386::AID-JCLP2270230328>3.0.CO;2-S
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Slater M., 1996, ACM VIRTUAL REALITY, P163, DOI [DOI 10.1145/3304181.3304216, 10.1145/3304181.3304216]
   Tcha-Tokey K, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927955
   TELLEGEN A, 1974, J ABNORM PSYCHOL, V83, P268, DOI 10.1037/h0036681
   Ucho A., 2016, Asia Pacific Journal of Education, Arts and Sciences, V3, P1
   Uliaszek AA, 2010, ANXIETY STRESS COPIN, V23, P363, DOI 10.1080/10615800903377264
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Ventura S, 2020, CYBERPSYCH BEH SOC N, V23, P667, DOI 10.1089/cyber.2019.0681
   Walinga J., 2010, Introduction to psychology
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Weibel D., 2009, CYBERPSYCHOLOGY, V13, p100722182519069, DOI [10.1089/cpb.2009.0171, DOI 10.1089/CPB.2009.0171]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zappala S., 2014, Journal for Perspectives of Economic, Political, and Social Integration, V19, P55, DOI DOI 10.2478/V10241-012-0007-5
NR 68
TC 3
Z9 3
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 4
PY 2022
VL 3
AR 860916
DI 10.3389/frvir.2022.860916
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AC9
UT WOS:001019281700001
OA gold
DA 2024-07-18
ER

PT J
AU Lochhead, I
   Hedley, N
   Çöltekin, A
   Fisher, B
AF Lochhead, Ian
   Hedley, Nick
   Coltekin, Arzu
   Fisher, Brian
TI The Immersive Mental Rotations Test: Evaluating Spatial Ability in
   Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE spatial ability; mental rotation; virtual reality; 3D geovisualization;
   spatial knowledge
ID SEX-DIFFERENCES; GENDER-DIFFERENCES; INDIVIDUAL-DIFFERENCES;
   PERFORMANCE; TASK; VISUALIZATION; METAANALYSIS; DIFFERENCE; VANDENBERG;
   ANIMATION
AB Advancements in extended reality (XR) have inspired new uses and users of advanced visualization interfaces, transforming geospatial data visualization and consumption by enabling interactive 3D geospatial data experiences in 3D. Conventional metrics (e.g., mental rotations test (MRT)) are often used to assess and predict the appropriateness of these visualizations without accounting for the effect the interface has on those metrics. We developed the Immersive MRT (IMRT) to evaluate the impact that virtual reality (VR) based visualizations and 3D virtual environments have on mental rotation performance. Consistent with previous work, the results of our pilot study suggest that mental rotation tasks are performed more accurately and rapidly with stereo 3D stimuli than with 2D images of those stimuli.
C1 [Lochhead, Ian; Hedley, Nick] Simon Fraser Univ, Dept Geog, Spatial Interface Res Lab, Burnaby, BC, Canada.
   [Coltekin, Arzu] Univ Appl Sci & Arts Northwestern Switzerland FHN, Inst Interact Technol IIT, Brugg, Switzerland.
   [Fisher, Brian] Simon Fraser Univ, Sch Interact Arts & Technol, Integrated Sci Lab, Surrey, BC, Canada.
C3 Simon Fraser University; FHNW University of Applied Sciences & Arts
   Northwestern Switzerland; Simon Fraser University
RP Lochhead, I (corresponding author), Simon Fraser Univ, Dept Geog, Spatial Interface Res Lab, Burnaby, BC, Canada.
EM ian_lochhead@sfu.ca
RI Çöltekin, Arzu/ACY-8666-2022
OI Çöltekin, Arzu/0000-0002-3178-3509
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [PGSD3-518954-2018]
FX We acknowledge the support of the Natural Sciences and Engineering
   Research Council of Canada (NSERC), (PGSD3-518954-2018).
CR Alqahtani S., 2017, J. Comput. Eng. Inf. Technol, V6, P4, DOI [10.4172/2324-9307.1000180, DOI 10.4172/2324-9307.1000180]
   Astur RS, 2004, BEHAV BRAIN RES, V151, P103, DOI 10.1016/j.bbr.2003.08.024
   Caissie A.F., 2009, The Open Psychology Journal, V2, P94, DOI DOI 10.2174/1874350100902010094
   Casey B.M., 2013, Handbook of spatial cognition, P117, DOI DOI 10.1037/13936-007
   CASEY MB, 1989, NEUROPSYCHOLOGIA, V27, P689, DOI 10.1016/0028-3932(89)90113-9
   Collins DW, 1997, BEHAV NEUROSCI, V111, P845, DOI 10.1037/0735-7044.111.4.845
   Coltekin, 2020, Manual of digital earth, P229
   Coltekin A, 2016, INT ARCH PHOTOGRAMM, V41, P387, DOI 10.5194/isprsarchives-XLI-B2-387-2016
   Coltekin A., 2017, INT J CARTOGR, V3, P115, DOI DOI 10.1080/23729333.2017.1302910
   Çöltekin A, 2018, CARTOGR GEOGR INF SC, V45, P339, DOI 10.1080/15230406.2017.1344569
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Datta S., 2016, The International Journal of Indian Psychology, V3, P91, DOI [10.25215/0302.082, DOI 10.25215/0302.082]
   Debelak R, 2014, LEARN INDIVID DIFFER, V29, P8, DOI 10.1016/j.lindif.2013.10.003
   Devaux A, 2018, ISPRS ANN PHOTO REM, V4-4, P41, DOI 10.5194/isprs-annals-IV-4-41-2018
   Hays TA, 1996, J EDUC COMPUT RES, V14, P139, DOI 10.2190/60Y9-BQG9-80HX-UEML
   Hedley N. R., 2003, 21 INT CART C CART R
   HEGARTY M, 1994, MEM COGNITION, V22, P411, DOI 10.3758/BF03200867
   Hegarty M., 2014, SPACE MIND, V75.98, DOI [10.7551/mitpress/9811.003.0005, DOI 10.7551/MITPRESS/9811.003.0005]
   Hinze S.R., 2014, Space in Mind: Concepts for Spatial Learning and Education, P99
   Hoyek N, 2012, J INDIVID DIFFER, V33, P62, DOI 10.1027/1614-0001/a000063
   Hruby F, 2019, INT J DIGIT EARTH, V12, P123, DOI 10.1080/17538947.2018.1501106
   Huk T, 2006, J COMPUT ASSIST LEAR, V22, P392, DOI 10.1111/j.1365-2729.2006.00180.x
   Johnson W, 2005, INTELLIGENCE, V33, P393, DOI 10.1016/j.intell.2004.12.002
   Kaufmann H., 2008, P INT C GEOMETRY GRA
   Laramee R., 2007, HUMAN CENTERED VISUA, P231, DOI DOI 10.1007/978-3-540-71949-6
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.1111/j.1467-8624.1985.tb00213.x
   Lochhead I, 2018, ISPRS ANN PHOTO REM, V4-4, P33, DOI 10.5194/isprs-annals-IV-4-W6-33-2018
   Lokka IE, 2019, INT J DIGIT EARTH, V12, P137, DOI 10.1080/17538947.2017.1349842
   MacEachren A., 1999, Proceedings of the 1999 workshop on new paradigms in information visualization and manipulation in conjunction with the eighth ACM international conference on Information and knowledge management, P35, DOI [DOI 10.1145/331770.331781, 10]
   MacEachren A.M., 2001, Cartogr. Geogr. Inf. Sci, V28, P3, DOI [DOI 10.1559/152304001782173970, 10.1559/152304001782173970]
   Maceachren AM, 1997, COMPUT GEOSCI, V23, P335, DOI 10.1016/S0098-3004(97)00018-6
   Malinowski JC, 2001, PERCEPT MOTOR SKILL, V92, P19, DOI 10.2466/PMS.92.1.19-30
   Marusan M., 2006, P 3 CENTR EUR MULT V, P77
   MAYER RE, 1994, J EDUC PSYCHOL, V86, P389, DOI 10.1037/0022-0663.86.3.389
   McWilliams W, 1997, PERCEPT MOTOR SKILL, V85, P297, DOI 10.2466/pms.1997.85.1.297
   Moè A, 2012, LEARN INDIVID DIFFER, V22, P20, DOI 10.1016/j.lindif.2011.11.001
   Mok MMC, 2013, EDUC ASIA PAC REG-IS, V18, P203, DOI 10.1007/978-94-007-4507-0_11
   Monahan JS, 2008, BEHAV RES METHODS, V40, P422, DOI 10.3758/BRM.40.2.422
   Newcombe N.S., 2014, Space in Mind: Concepts for Spatial Learning and Education, P323
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Peters M, 2008, BRAIN COGNITION, V66, P260, DOI 10.1016/j.bandc.2007.09.003
   Peters Michael, 2005, Brain Cogn, V57, P176, DOI 10.1016/j.bandc.2004.08.052
   Pulver Y., 2020, ISPRS ANN PHOTOGRAMM, VV-4-2020, P171, DOI [10.5194/isprs-Annals-V-4-2020-171-2020, DOI 10.5194/ISPRS-ANNALS-V-4-2020-171-2020]
   Rydvanskiy R, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020082
   Sanchez CA, 2009, INT J HUM-COMPUT ST, V67, P475, DOI 10.1016/j.ijhcs.2008.12.003
   Scali RM, 2000, SEX ROLES, V43, P359, DOI 10.1023/A:1026699310308
   Schnürer R, 2020, INFORM VISUAL, V19, P183, DOI 10.1177/1473871619896103
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Slocum T., 2001, CARTOGR GEOGR INFORM, V28, P61, DOI [10.1559/152304001782173998, DOI 10.1559/152304001782173998]
   Uttal DH, 2013, PSYCHOL BULL, V139, P352, DOI 10.1037/a0028446
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   VOYER D, 1995, PSYCHOL BULL, V117, P250, DOI 10.1037/0033-2909.117.2.250
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wai J, 2009, J EDUC PSYCHOL, V101, P817, DOI 10.1037/a0016127
   Zhao JY, 2019, GEO-SPAT INF SCI, V22, P237, DOI 10.1080/10095020.2019.1621544
NR 56
TC 13
Z9 13
U1 6
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 31
PY 2022
VL 3
AR 820237
DI 10.3389/frvir.2022.820237
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TN2
UT WOS:001021835500001
OA gold
DA 2024-07-18
ER

PT J
AU Kyrlitsias, C
   Michael-Grigoriou, D
AF Kyrlitsias, Christos
   Michael-Grigoriou, Despina
TI Social Interaction With Agents and Avatars in Immersive Virtual
   Environments: A Survey
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; agents; avatars; social presence; social interaction
ID SELF-REPRESENTATION; REALITY; HUMANS; BODY; EXPOSURE; BEHAVIOR;
   METAANALYSIS; TECHNOLOGY; EMBODIMENT; OWNERSHIP
AB Immersive virtual reality technologies are used in a wide range of fields such as training, education, health, and research. Many of these applications include virtual humans that are classified into avatars and agents. An overview of the applications and the advantages of immersive virtual reality and virtual humans is presented in this survey, as well as the basic concepts and terminology. To be effective, many virtual reality applications require that the users perceive and react socially to the virtual humans in a realistic manner. Numerous studies show that people can react socially to virtual humans; however, this is not always the case. This survey provides an overview of the main findings regarding the factors affecting the social interaction with virtual humans within immersive virtual environments. Finally, this survey highlights the need for further research that can lead to a better understanding of human-virtual human interaction.
C1 [Kyrlitsias, Christos; Michael-Grigoriou, Despina] Cyprus Univ Technol, Dept Multimedia & Graph Arts, GET Lab, Limassol, Cyprus.
C3 Cyprus University of Technology
RP Michael-Grigoriou, D (corresponding author), Cyprus Univ Technol, Dept Multimedia & Graph Arts, GET Lab, Limassol, Cyprus.
EM despina.grigoriou@cut.ac.cy
RI Michael-Grigoriou, Despina/ABE-5748-2022
OI Michael-Grigoriou, Despina/0000-0003-0824-7684
FU budget of the Cyprus University of Technology [ED-DESPINA
   MICHAIL-300155-310200-3319]
FX Funding This work has been partially funded by ED-DESPINA
   MICHAIL-300155-310200-3319 budget of the Cyprus University of
   Technology.
CR [Anonymous], 2010, IJVR, DOI DOI 10.20870/IJVR.2010.9.4.2784
   ASCH SE, 1956, PSYCHOL MONOGR, V70, P1, DOI 10.1037/h0093718
   Bailenson J., 2004, Encyclopedia of human-computer interaction, P62
   Bailey JO, 2019, J APPL DEV PSYCHOL, V64, DOI 10.1016/j.appdev.2019.101052
   Balan Oana, 2020, HCI International 2020 - Late Breaking Papers. Virtual and Augmented Reality. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12428), P12, DOI 10.1007/978-3-030-59990-4_2
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Barley S.R., 1988, KNOWLEDGE PRACTICE M, P497
   Beall A., 2003, P HCI INT
   Bell IH, 2020, DIALOGUES CLIN NEURO, V22, P169, DOI 10.31887/DCNS.2020.22.2/lvalmaggia
   Bellanca JL, 2019, MINING METALL EXPLOR, V36, P597, DOI 10.1007/s42461-018-0046-2
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Biocca F., 2006, Journal of Computer-Mediated Communication., V3, DOI DOI 10.1111/J.1083-6101.1997.TB00070.X
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Blascovich J, 2002, COMP SUPP COMP W SER, P127
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bombari D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00869
   Botella C, 2015, NEUROPSYCH DIS TREAT, V11, P2533, DOI 10.2147/NDT.S89542
   Botella C, 2009, PSYCHNOLOGY J, V7, P77
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chesham RK, 2018, BEHAV CHANGE, V35, P152, DOI 10.1017/bec.2018.15
   Christofi M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01242
   Christofi M, 2016, P I CON VIR SYS MULT, P63
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   de Melo CM, 2015, IEEE T AFFECT COMPUT, V6, P127, DOI 10.1109/TAFFC.2014.2332471
   Dennett Daniel Clement, 1987, The intentional stance
   Dzardanova E, 2022, VIRTUAL REAL-LONDON, V26, P737, DOI 10.1007/s10055-021-00564-9
   Falconer CJ, 2016, BJPSYCH OPEN, V2, P74, DOI 10.1192/bjpo.bp.115.002147
   Felnhofer A., 2012, P INT SOC PRESENCE R
   Felnhofer A, 2018, COMPUT HUM BEHAV, V80, P399, DOI 10.1016/j.chb.2017.11.031
   Foreman N., 2009, Themes in Science and Technology Education, P225
   FORSYTHE R, 1994, GAME ECON BEHAV, V6, P347, DOI 10.1006/game.1994.1021
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Friedman D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00943
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   Gonzalez-Franco M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209704
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Grivokostopoulou F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051739
   Groom V, 2009, INT J HUM-COMPUT ST, V67, P842, DOI 10.1016/j.ijhcs.2009.07.001
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Guadagno RE, 2011, COMPUT HUM BEHAV, V27, P2380, DOI 10.1016/j.chb.2011.07.017
   Guimaraes M, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423879
   Gunkel S, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P233, DOI 10.1145/3210825.3213566
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Heldal I, 2005, P IEEE VIRT REAL ANN, P171
   Hoyt CL, 2003, PRESENCE-TELEOP VIRT, V12, P183, DOI 10.1162/105474603321640932
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   Johnson WL, 2018, AI MAG, V39, P33, DOI 10.1609/aimag.v39i2.2793
   Kelly J. R., 2007, ENCY SOCIAL PSYCHOL, V1, P599, DOI [10.4135/9781412956253.n357, DOI 10.4135/9781412956253.N357]
   Kiesler S., 1997, Human values and the design of computer technology, P191
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim K, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P17, DOI 10.1109/AIVR46125.2019.00013
   Kinateder M, 2015, FIRE SAFETY J, V78, P24, DOI 10.1016/j.firesaf.2015.07.002
   Kosloff S., 2007, ENCY SOCIAL PSYCHOL, V1, P329
   Kothgassner O. D., 2020, Annals of the International Communication Association, V44, P210, DOI [DOI 10.1080/23808985.2020.1792790, https://doi.org/10.1080/23808985.2020.1792790]
   Kozlak M., 2013, Vision Based Systems for UAV Applications, V481, P327
   Kyrlitsias C, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00023
   Kyrlitsias C, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02254
   Kyrlitsias C, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1804
   Lateef Fatimah, 2010, J Emerg Trauma Shock, V3, P348, DOI 10.4103/0974-2700.70743
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Lee M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.628246
   Li J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300897
   Lok B., 2006, Virtual Reality, V10, P185, DOI [10.1007/s10055-006-0037-3, DOI 10.1007/S10055-006-0037-3]
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Maister L, 2013, COGNITION, V128, P170, DOI 10.1016/j.cognition.2013.04.002
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P349, DOI 10.1111/jcal.12335
   Mal D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P545, DOI [10.1109/VRW50115.2020.0-152, 10.1109/VRW50115.2020.00124]
   McCall C, 2015, CONSCIOUS COGN, V38, P60, DOI 10.1016/j.concog.2015.09.011
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   MILGRAM S, 1963, J ABNORM PSYCHOL, V67, P371, DOI 10.1037/h0040525
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Najm A., 2020, ICAT EGVE 2020 INT C, DOI [10.2312/egve.20201269, DOI 10.2312/EGVE.20201269]
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703
   Nazligul MD, 2017, COMM COM INF SC, V748, P191, DOI 10.1007/978-3-319-64218-5_15
   Neyret S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62932-w
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   Pan X., 2008, PRESENCE 2008 11 ANN, P100
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Parsons TD, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7040042
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Perry J.S., 2018, IBM developerWorks, P1
   Petrovic VM, 2018, IEEE ACCESS, V6, P39976, DOI 10.1109/ACCESS.2018.2855970
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Rahani Vida Kabiri, 2018, J Med Signals Sens, V8, P231, DOI 10.4103/jmss.JMSS_27_18
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Rizzo A., 2016, ED PRACT, P255, DOI [10.1002/9781118952788.ch18, DOI 10.1002/9781118952788.CH18]
   Roth Daniel, 2015, i-com: A Journal of Interactive and Cooperative Media, V14, P107, DOI 10.1515/icom-2015-0030
   Roth D, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P69, DOI 10.1145/3267782.3267791
   Roth D, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P103, DOI 10.1109/ISMAR-Adjunct.2018.00044
   Roth D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P215, DOI 10.1109/VR.2018.8447550
   Roth D, 2017, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2017.7892275
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   ROTHBAUM BO, 1995, BEHAV THER, V26, P547, DOI 10.1016/S0005-7894(05)80100-5
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Seinfeld S, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01969
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2014, COMPUTER, V47, P24, DOI 10.1109/MC.2014.198
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Stavroulia KE, 2019, INT J INF LEARN TECH, V36, P192, DOI 10.1108/IJILT-11-2018-0127
   Strojny PM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01252
   Takac M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216288
   Takahashi T, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P153, DOI 10.1145/3284432.3284436
   Tarr MJ, 2002, NAT NEUROSCI, V5, P1089, DOI 10.1038/nn948
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Taranilla RV, 2022, INTERACT LEARN ENVIR, V30, P608, DOI 10.1080/10494820.2019.1674886
   von der Pütten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wegener D., 2007, Encyclopedia of Social Psychology, P276
   Wiederhold BK, 2019, CYBERPSYCH BEH SOC N, V22, P3, DOI 10.1089/cyber.2018.29136.bkw
   Wilson CJ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/151702
   Xi M., 2016, 2016 IEEE VIRT REAL, P315, DOI [10.1109/VR.2016.7504780, DOI 10.1109/VR.2016.7504780]
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Yildirim C., 2021, 2021 3 INT C TRANSDI, P17, DOI [10.1109/TransAI51903.2021.00011, DOI 10.1109/TRANSAI51903.2021.00011]
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
NR 135
TC 30
Z9 31
U1 15
U2 23
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 11
PY 2022
VL 2
AR 786665
DI 10.3389/frvir.2021.786665
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8XF0
UT WOS:001019204600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Preechayasomboon, P
   Rombokas, E
AF Preechayasomboon, Pornthep
   Rombokas, Eric
TI Haplets: Finger-Worn Wireless and Low-Encumbrance Vibrotactile Haptic
   Feedback for Virtual and Augmented Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE haptics; virtual reality; augmented reality; spatial computing; sensory
   feedback; human computer interface
AB We introduce Haplets, a wearable, low-encumbrance, finger-worn, wireless haptic device that provides vibrotactile feedback for hand tracking applications in virtual and augmented reality. Haplets are small enough to fit on the back of the fingers and fingernails while leaving the fingertips free for interacting with real-world objects. Through robust physically-simulated hands and low-latency wireless communication, Haplets can render haptic feedback in the form of impacts and textures, and supplements the experience with pseudo-haptic illusions. When used in conjunction with handheld tools, such as a pen, Haplets provide haptic feedback for otherwise passive tools in virtual reality, such as for emulating friction and pressure-sensitivity. We present the design and engineering for the hardware for Haplets, as well as the software framework for haptic rendering. As an example use case, we present a user study in which Haplets are used to improve the line width accuracy of a pressure-sensitive pen in a virtual reality drawing task. We also demonstrate Haplets used during manipulation of objects and during a painting and sculpting scenario in virtual reality. Haplets, at the very least, can be used as a prototyping platform for haptic feedback in virtual reality.
C1 [Preechayasomboon, Pornthep; Rombokas, Eric] Univ Washington, Rombolabs, Mech Engn, Seattle, WA 98195 USA.
   [Rombokas, Eric] Univ Washington, Elect Engn, Seattle, WA USA.
C3 University of Washington; University of Washington Seattle; University
   of Washington; University of Washington Seattle
RP Preechayasomboon, P (corresponding author), Univ Washington, Rombolabs, Mech Engn, Seattle, WA 98195 USA.
EM prnthp@uw.edu
RI Preechayasomboon, Pornthep/GZK-7791-2022
OI Preechayasomboon, Pornthep/0000-0002-0538-394X
CR Achibet M, 2017, IEEE SYMP 3D USER, P103, DOI 10.1109/3DUI.2017.7893325
   Ando H., 2007, P INT C ADV COMPUTER, P292, DOI [10.1145/1255047.1255131, DOI 10.1145/1255047.1255131]
   Caballero DE, 2019, IEEE T HAPTICS, V12, P78, DOI 10.1109/TOH.2018.2859940
   Chan S., 2021, HASTI HAPTIC AUDIO S, V6
   Choi I, 2021, IEEE T VIS COMPUT GR, V27, P4387, DOI 10.1109/TVCG.2020.3002245
   Cipriani C, 2012, IEEE T BIO-MED ENG, V59, P400, DOI 10.1109/TBME.2011.2173342
   Cobos Guzman S, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2246, DOI 10.1109/IROS.2008.4651053
   Elsayed Hesham., 2020, Proceedings of the 26th ACM Symposium on Virtual Reality Software and Technology, P1, DOI DOI 10.1145/3385956.3418953
   Fishel Jeremy A, 2012, Front Neurorobot, V6, P4, DOI 10.3389/fnbot.2012.00004
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   Han SC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392452
   Hinchet R, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P901, DOI 10.1145/3242587.3242657
   Hsieh MJ, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P29, DOI 10.1145/2935334.2935358
   Israr A, 2019, LECT NOTES COMPUT SC, V11786, P217, DOI 10.1007/978-3-030-30033-3_17
   Johansson RS, 2009, NAT REV NEUROSCI, V10, P345, DOI 10.1038/nrn2621
   Kim H., 2018, HAPCUBE, DOI [10.1145/3173574.3174075, DOI 10.1145/3173574.3174075]
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Lengyel G, 2019, ELIFE, V8, DOI 10.7554/eLife.43942
   Peng YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376847
   Pezent E, 2021, IEEE T HAPTICS, V14, P225, DOI 10.1109/TOH.2020.3002696
   Pezent E, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P1, DOI [10.1109/whc.2019.8816098, 10.1109/WHC.2019.8816098]
   Preechayasomboon P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376512
   Rekimoto J., 2009, P 27 INT C HUM FACT, P2519, DOI [10.1145/1520340.1520356, DOI 10.1145/1520340.1520356]
   Rokhmanova N, 2019, INT C REHAB ROBOT, P1215, DOI [10.1109/ICORR.2019.8779518, 10.1109/icorr.2019.8779518]
   Salazar SV, 2020, IEEE T HAPTICS, V13, P167, DOI 10.1109/TOH.2020.2967389
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Schorr SB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3115, DOI 10.1145/3025453.3025744
   Shigeyama J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300241
   Sie A, 2018, P IEEE RAS-EMBS INT, P219, DOI 10.1109/BIOROB.2018.8487652
   Teng SY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445099
   Zhou Q, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376313
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 34
TC 11
Z9 11
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 20
PY 2021
VL 2
AR 738613
DI 10.3389/frvir.2021.738613
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZL7
UT WOS:001019264300001
OA gold
DA 2024-07-18
ER

PT J
AU McMahan, T
   Duffield, T
   Parsons, TD
AF McMahan, Timothy
   Duffield, Tyler
   Parsons, Thomas D. D.
TI Feasibility Study to Identify Machine Learning Predictors for a Virtual
   School Environment: Virtual Reality Stroop Task
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE adaptive virtual environments; neuropsychological assessment; cognitive;
   machine learning; adaptive assessment
ID ADHD; VARIABILITY; DEMANDS
AB An adaptive virtual school environment can offer cognitive assessments (e.g., Virtual Classroom Stroop Task) with user-specific distraction levels that mimic the conditions found in a student's actual classroom. Former iterations of the virtual reality classroom Stroop tasks did not adapt to user performance in the face of distractors. While advances in virtual reality-based assessments provide potential for increasing assessment of cognitive processes, less has been done to develop these simulations into personalized virtual environments for improved assessment. An adaptive virtual school environment offers the potential for dynamically adapting the difficulty level (e.g., level and amount of distractors) specific to the user's performance. This study aimed to identify machine learning predictors that could be utilized for cognitive performance classifiers, from participants (N = 60) using three classification techniques: Support Vector Machines (SVM), Naive Bayes (NB), and k-Nearest Neighbors (kNN). Participants were categorized into either high performing or low performing categories based upon their average calculated throughput performance on tasks assessing their attentional processes during a distraction condition. The predictors for the classifiers used the average cognitive response time and average motor response dwell time (amount of time response button was pressed) for each section of the virtual reality-based Stroop task totaling 24 predictors. Using 10-fold cross validation during the training of the classifiers, revealed that the SVM (86.7%) classifier was the most robust classifier followed by Naive Bayes (81.7%) and KNN (76.7%) for identifying cognitive performance. Results from the classifiers suggests that we can use average response time and dwell time as predictors to adapt the social cues and distractors in the environment to the appropriate difficulty level for the user.
C1 [McMahan, Timothy; Parsons, Thomas D. D.] Univ North Texas, iCenter Affect Neurotechnol, Denton, TX 76205 USA.
   [Duffield, Tyler] Oregon Hlth & Sci Univ, Portland, OR USA.
C3 University of North Texas System; University of North Texas Denton;
   Oregon Health & Science University
RP Parsons, TD (corresponding author), Univ North Texas, iCenter Affect Neurotechnol, Denton, TX 76205 USA.
EM thomas.parsons@unt.edu
CR Brosco JP, 2016, JAMA PEDIATR, V170, P396, DOI 10.1001/jamapediatrics.2015.4132
   Diaz-Orueta U, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00361
   Duffield TC, 2018, CHILD NEUROPSYCHOL, V24, P1129, DOI 10.1080/09297049.2017.1375473
   Gibbons RD, 2008, PSYCHIAT SERV, V59, P361, DOI 10.1176/ps.2008.59.4.361
   Gibbons RD, 2016, ANNU REV CLIN PSYCHO, V12, P83, DOI 10.1146/annurev-clinpsy-021815-093634
   Huang-Pollock CL, 2012, J ABNORM PSYCHOL, V121, P360, DOI 10.1037/a0027205
   Iriarte Y, 2016, J ATTEN DISORD, V20, P542, DOI 10.1177/1087054712465335
   Kofler MJ, 2008, J CHILD PSYCHOL PSYC, V49, P59, DOI 10.1111/j.1469-7610.2007.01809.x
   Kofler MJ, 2016, CLIN PSYCHOL REV, V46, P12, DOI 10.1016/j.cpr.2016.04.004
   Kofler MJ, 2013, CLIN PSYCHOL REV, V33, P795, DOI 10.1016/j.cpr.2013.06.001
   Lalonde G, 2013, J NEUROSCI METH, V219, P76, DOI 10.1016/j.jneumeth.2013.07.005
   MACLEOD CM, 1992, J EXP PSYCHOL GEN, V121, P12, DOI 10.1037/0096-3445.121.1.12
   Melara RD, 2003, PSYCHOL REV, V110, P422, DOI 10.1037/0033-295X.110.3.422
   Norman D. A., 1986, CONSCIOUS SELF REGUL, V1, P1, DOI [10.1007/978-1-4757-0629-1_1, DOI 10.1007/978-1-4757-0629-1_1]
   Parsons TD, 2019, NEUROPSYCHOL REV, V29, P338, DOI 10.1007/s11065-019-09407-6
   Parsons TD, 2016, J AUTISM DEV DISORD, V46, P1255, DOI 10.1007/s10803-015-2663-7
   Pelham WE, 2011, J ABNORM CHILD PSYCH, V39, P1085, DOI 10.1007/s10802-011-9529-z
   Reise SP, 2009, ANNU REV CLIN PSYCHO, V5, P27, DOI 10.1146/annurev.clinpsy.032408.153553
   Rizzo AA, 2006, CNS SPECTRUMS, V11, P35, DOI 10.1017/S1092852900024196
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Thorne DR, 2006, BEHAV RES METHODS, V38, P569, DOI 10.3758/BF03193886
NR 21
TC 3
Z9 4
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 9
PY 2021
VL 2
AR 673191
DI 10.3389/frvir.2021.673191
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SZ9
UT WOS:001021822200001
OA gold
DA 2024-07-18
ER

PT J
AU Pinnow, D
   Hubbard, HI
   Meulenbroek, PA
AF Pinnow, DeAnna
   Hubbard, H. Isabel
   Meulenbroek, Peter A.
TI Computer- Assessment of Attention and Memory Utilizing Ecologically
   Valid Distractions: A Scoping Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE attention; memory; scoping review; distraction; computer assisted
ID TRAUMATIC BRAIN-INJURY; VIRTUAL-REALITY; WORKING-MEMORY;
   DEFICIT/HYPERACTIVITY DISORDER; NEUROPSYCHOLOGICAL ASSESSMENT; AUDITORY
   DISTRACTION; CHILDREN; ADHD; PERFORMANCE; CLASSROOM
AB Introduction: Deficits in the cognitive domains of attention and memory leave a large impact on everyday activities that are not easily captured in the clinical environment. Therefore, clinicians are compelled to utilize assessment tools that elicit everyday functioning that include real-world contexts and distractions. As a result, the use of computer-assisted assessment has emerged as a tool for capturing everyday functioning in a variety of environments. The purpose of this scoping review is to map how virtual reality, augmented reality, and computer-based programs have implemented distractions for clinical populations.Methods: A scoping review of peer reviewed publications was conducted by searching Pubmed, PsychInfo, Web of Science, Rehabdata, and Scopus databases (1960-October 20, 2020). Authors completed hand-searches for additional published and unpublished studies.Results: Of 616 titles screened, 23 articles met inclusion criteria to include in this review. Primary distraction display modalities included computer monitor displays (n = 12) and head mounted displays (HMD) (n = 7). While computer-assisted assessments included distractions, no systematic approach was utilized to implement them. Primary distractions included both auditory and visual stimuli that were relevant to the task and/or simulated environment. Additional distraction characteristics emerged including location, timing, and intensity that can contribute to overall noticeability.Conclusion: From this review, the authors examined the literature on the implementation of distractions in simulated programming. The authors make recommendations regarding identification, measurement, and programming with suggestions that future studies examining metrics of attention to implement distraction in measurable and meaningful ways. Further, the authors propose that distraction does not universally impact performance negatively but can also enhance performance for clinical populations (e.g. additional sensory stimuli to support focused attention).
C1 [Pinnow, DeAnna; Hubbard, H. Isabel; Meulenbroek, Peter A.] Univ Kentucky, Dept Commun Sci & Disorders, Lexington, KY 40506 USA.
C3 University of Kentucky
RP Pinnow, D (corresponding author), Univ Kentucky, Dept Commun Sci & Disorders, Lexington, KY 40506 USA.
EM deannapinnow@uky.edu
RI Meulenbroek, Peter/AFS-8402-2022
OI Meulenbroek, Peter/0000-0003-4233-9910
CR Abikoff H, 1996, J LEARN DISABIL-US, V29, P238, DOI 10.1177/002221949602900302
   Adams R, 2009, CHILD NEUROPSYCHOL, V15, P120, DOI 10.1080/09297040802169077
   Adreon D, 2007, INTERV SCH CLIN, V42, P271, DOI 10.1177/10534512070420050201
   Ansado J, 2018, ANN REV CYBERTHERAPY, V16, P101
   Baars BJ, 2010, COGNITION, BRAIN, AND CONSCIOUSNESS: INTRODUCTION TO COGNITIVE NEUROSCIENCE, 2ND EDITION, P1
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Banire B, 2021, UNIVERSAL ACCESS INF, V20, P785, DOI 10.1007/s10209-020-00749-0
   Bar-Haim Y, 2007, PSYCHOL BULL, V133, P1, DOI 10.1037/0033-2909.133.1.1
   Barkley R A, 1997, J Int Neuropsychol Soc, V3, P359
   Barkley Russell A, 2004, J Psychiatr Pract, V10, P39, DOI 10.1097/00131746-200401000-00005
   Beaman CP, 1997, J EXP PSYCHOL LEARN, V23, P459, DOI 10.1037/0278-7393.23.2.459
   Beaman CP, 2005, APPL COGNITIVE PSYCH, V19, P1041, DOI 10.1002/acp.1134
   Beck A.T., 1993, BECK ANXIETY INVENTO, DOI [10.1037/t02025-000, DOI 10.1037/T02025-000]
   Beck AT, 1996, Psychol Assess, DOI [10.1037/t00742-000, DOI 10.1037/T00742-000]
   Bellani M, 2011, EPIDEMIOL PSYCH SCI, V20, P235, DOI 10.1017/S2045796011000448
   Biss RK, 2020, J INT NEUROPSYCH SOC, V26, P851, DOI 10.1017/S1355617720000429
   Boll S, 2009, PSYCHOPHYSIOLOGY, V46, P645, DOI 10.1111/j.1469-8986.2009.00803.x
   Brewer T. L., 1998, DISSERT ABSTR, P0599
   Brewer TL, 2002, RES NURS HEALTH, V25, P269, DOI 10.1002/nur.10045
   BROADBENT DE, 1982, BRIT J CLIN PSYCHOL, V21, P1, DOI 10.1111/j.2044-8260.1982.tb01421.x
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Clancy TA, 2006, J CLIN CHILD ADOLESC, V35, P203, DOI 10.1207/s15374424jccp3502_4
   Conners CK., 1995, CONNERSCONTINUOUS PE
   CORKUM PV, 1993, J CHILD PSYCHOL PSYC, V34, P1217, DOI 10.1111/j.1469-7610.1993.tb01784.x
   Couillet J, 2010, NEUROPSYCHOL REHABIL, V20, P321, DOI 10.1080/09602010903467746
   Díaz-Orueta U, 2014, CHILD NEUROPSYCHOL, V20, P328, DOI 10.1080/09297049.2013.792332
   Dockree PM, 2004, COGNITIVE BRAIN RES, V20, P403, DOI 10.1016/j.cogbrainres.2004.03.019
   ELIASON MJ, 1987, J LEARN DISABIL, V20, P614, DOI 10.1177/002221948702001007
   Faria AL, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0204-z
   Fleischer AS, 2012, SCAND J DISABIL RES, V14, P177, DOI 10.1080/15017419.2011.558236
   Forster S, 2007, PSYCHOL SCI, V18, P377, DOI 10.1111/j.1467-9280.2007.01908.x
   Franzen M. D., 1996, ECOLOGICAL VALIDITY, P91
   Gelbar NW, 2014, J AUTISM DEV DISORD, V44, P2593, DOI 10.1007/s10803-014-2135-5
   Harrington DL, 2020, HUM BRAIN MAPP, V41, P1195, DOI 10.1002/hbm.24868
   Hartnedy S, 2000, BEHAV INTERVENT, V15, P261, DOI 10.1002/1099-078X(200007/09)15:3<261::AID-BIN60>3.0.CO;2-N
   Hughes R W, 2003, Noise Health, V6, P63
   Hughes RW, 2014, PSYCH J, V3, P30, DOI 10.1002/pchj.44
   Jones D. M., 1992, HDB HUMAN PERFORMANC, P29, DOI [10.1016/b978-0-12-650351-7.50008-1, DOI 10.1016/B978-0-12-650351-7.50008-1]
   Kahneman D., 1973, Attention and effort
   KENNEDY RS, 1992, AVIAT SPACE ENVIR MD, V63, P588
   Kibby MY, 1998, ARCH CLIN NEUROPSYCH, V13, P523, DOI 10.1016/S0887-6177(97)00038-3
   Knight RG, 2006, J INT NEUROPSYCH SOC, V12, P8, DOI 10.1017/S1355617706060048
   Kratz AL, 2020, ACR OPEN RHEUMATOL, V2, P214, DOI 10.1002/acr2.11130
   Kratz AL, 2020, ARTHRIT CARE RES, V72, P1669, DOI 10.1002/acr.24089
   Krawczyk DC, 2008, NEUROPSYCHOLOGIA, V46, P2020, DOI 10.1016/j.neuropsychologia.2008.02.001
   Krch D., 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P15, DOI 10.1109/ICVR.2013.6662092
   Lalonde G, 2013, J NEUROSCI METH, V219, P76, DOI 10.1016/j.jneumeth.2013.07.005
   Lengenfelder J, 2002, J HEAD TRAUMA REHAB, V17, P26, DOI 10.1097/00001199-200202000-00005
   Leung JP, 2000, J DEV PHYS DISABIL, V12, P187, DOI 10.1023/A:1009409720485
   Levin HS, 2008, J NEUROSURG-PEDIATR, V1, P461, DOI 10.3171/PED/2008/1/6/461
   Levin HS, 2005, PEDIATR NEUROL, V33, P79, DOI 10.1016/j.pediatrneurol.2005.02.002
   Levin HS, 2004, NEUROPSYCHOLOGY, V18, P240, DOI 10.1037/0894-4105.18.2.240
   Lutz R. L., 1999, VOCATIONAL EVAL WORK, V32, P47, DOI [10.1111/1467-9361.00050, DOI 10.1111/1467-9361.00050]
   Marcotte T.D., 2010, NEUROPSYCHOLOGY EVER
   Marcotte T.D., 2010, NEUROPSYCHOLOGY EVER, P5
   McDermid AJ, 1996, PAIN, V66, P133, DOI 10.1016/0304-3959(96)03059-X
   Mioshi E, 2006, INT J GERIATR PSYCH, V21, P1078, DOI 10.1002/gps.1610
   Moore EL, 2006, BRAIN INJURY, V20, P117, DOI 10.1080/02699050500443558
   Moser JS, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00466
   Mozgai S, 2019, PSYCHOL INQ, V30, P231, DOI 10.1080/1047840X.2019.1693873
   Neisser U., 1978, PRACTICAL ASPECTS ME, P3
   Newcorn JH, 2001, J AM ACAD CHILD PSY, V40, P137, DOI 10.1097/00004583-200102000-00008
   Nolin P, 2009, STUD HEALTH TECHNOL, V144, P240, DOI 10.3233/978-1-60750-017-9-240
   Ouellet É, 2018, J NEUROSCI METH, V303, P126, DOI 10.1016/j.jneumeth.2018.03.010
   Park P, 2020, J INT NEUROPSYCH SOC, V26, P418, DOI 10.1017/S1355617719001280
   Parsons TD, 2007, CHILD NEUROPSYCHOL, V13, P363, DOI 10.1080/13825580600943473
   Parsons TD, 2016, J AUTISM DEV DISORD, V46, P1255, DOI 10.1007/s10803-015-2663-7
   Pillay Y, 2012, J COLL STUD PSYCHOTH, V26, P140, DOI 10.1080/87568225.2012.659161
   Pollak Y, 2009, NEUROPSYCHOLOGY, V23, P679, DOI 10.1037/a0016281
   Potvin MJ, 2011, BRAIN INJURY, V25, P192, DOI 10.3109/02699052.2010.541896
   Pretus C, 2020, J ATTEN DISORD, V24, P1530, DOI 10.1177/1087054716648776
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Remington A, 2019, RES DEV DISABIL, V85, P197, DOI 10.1016/j.ridd.2018.12.006
   Rizzo A. S., 2019, Virtual reality for psychological and neurocognitive interventions
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Rizzo AA, 1997, J HEAD TRAUMA REHAB, V12, P1, DOI 10.1097/00001199-199712000-00002
   Robertson I.H., 1994, TEST EVERYDAY ATTENT
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   Ryan JJ, 2001, PERSP INDIV, P19
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sbordone RJ, 1996, NEUROREHABILITATION, V7, P15, DOI 10.3233/NRE-1996-7103
   Schnabel R, 2012, CLIN NEUROPSYCHOL, V26, P769, DOI 10.1080/13854046.2012.693541
   Schultheis MT, 2002, J HEAD TRAUMA REHAB, V17, P378, DOI 10.1097/00001199-200210000-00002
   Sciberras E, 2014, PEDIATRICS, V133, P801, DOI 10.1542/peds.2013-3686
   Sergeant J.A., 1999, Handbook of Disruptive Behavior Disorders
   Sergeant JA, 2005, BIOL PSYCHIAT, V57, P1248, DOI 10.1016/j.biopsych.2004.09.010
   Silverberg ND, 2007, J INT NEUROPSYCH SOC, V13, P898, DOI 10.1017/S1355617707071135
   Spooner DM, 2006, ARCH CLIN NEUROPSYCH, V21, P327, DOI 10.1016/j.acn.2006.04.004
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Sugishita M., 2009, JPN J COGN NEUROSCI, V11, P87, DOI [10.11253/ninchishinkeikagaku.11.87, DOI 10.11253/NINCHISHINKEIKAGAKU.11.87, DOI 10.11253/ninchishinkeikagaku.11.87]
   TANNOCK R, 1995, J AM ACAD CHILD PSY, V34, P886, DOI 10.1097/00004583-199507000-00012
   Tricco AC, 2016, BMC MED RES METHODOL, V16, DOI 10.1186/s12874-016-0116-4
   Trudel TM, 1998, REHABIL PSYCHOL, V43, P267, DOI 10.1037/0090-5550.43.4.267
   Uitvlugt MG, 2016, COGN AFFECT BEHAV NE, V16, P289, DOI 10.3758/s13415-015-0389-9
   van der Linden WJ, 2008, Z PSYCHOL, V216, P3, DOI 10.1027/0044-3409.216.1.3
   van Mourik R, 2007, CLIN NEUROPHYSIOL, V118, P1855, DOI 10.1016/j.clinph.2007.05.007
   Wechsler D., 2008, Wechsler Adult Intelligence Scale, V4th, DOI DOI 10.1037/T15169-000
   Wilson B., 2004, Cambridge Test of Prospective Memory
   Wilson B., 1985, RIVERMEAD BEHAV MEMO
   Wilson BA., 1996, Behavioural Assessment of the Dysexecutive Syndrome
   Wood RL, 2006, ARCH CLIN NEUROPSYCH, V21, P429, DOI 10.1016/j.acn.2005.06.014
   Yeh SC, 2020, IEEE T NEUR SYS REH, V28, P1899, DOI 10.1109/TNSRE.2020.3004545
   Yesavage JA., 1986, CLIN GERONTOLOGIST, V5, P165, DOI [10.1300/J018v05n01_09, DOI 10.1300/J018V05N01_09]
   ZENTALL SS, 1987, J ABNORM CHILD PSYCH, V15, P519, DOI 10.1007/BF00917238
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 106
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 14
PY 2021
VL 2
AR 685921
DI 10.3389/frvir.2021.685921
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZD9
UT WOS:001019256500001
OA gold
DA 2024-07-18
ER

PT J
AU Li, Y
   Hu, DH
   Wang, BY
   Bowman, DA
   Lee, SW
AF Li, Yuan
   Hu, Donghan
   Wang, Boyuan
   Bowman, Doug A. A.
   Lee, Sang Won
TI The Effects of Incorrect Occlusion Cues on the Understanding of
   Barehanded Referencing in Collaborative Augmented Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; collaboration; occlusion; hand referencing; spatial
   referencing
ID TO-FACE COMMUNICATION; INFORMATION; GESTURES
AB In many collaborative tasks, the need for joint attention arises when one of the users wants to guide others to a specific location or target in space. If the collaborators are co-located and the target position is in close range, it is almost instinctual for users to refer to the target location by pointing with their bare hands. While such pointing gestures can be efficient and effective in real life, performance will be impacted if the target is in augmented reality (AR), where depth cues like occlusion may be missing if the pointer's hand is not tracked and modeled in 3D. In this paper, we present a study utilizing head-worn AR displays to examine the effects of incorrect occlusion cues on spatial target identification in a collaborative barehanded referencing task. We found that participants' performance in AR was reduced compared to a real-world condition, but also that they developed new strategies to cope with the limitations of AR. Our work also identified mixed results of the effect of spatial relationships between users.
C1 [Li, Yuan; Hu, Donghan; Wang, Boyuan; Bowman, Doug A. A.; Lee, Sang Won] Virginia Tech, Coll Engn, Ctr Human Comp Interact, Dept Comp Sci, Blacksburg, VA 24061 USA.
C3 Virginia Polytechnic Institute & State University
RP Li, Y (corresponding author), Virginia Tech, Coll Engn, Ctr Human Comp Interact, Dept Comp Sci, Blacksburg, VA 24061 USA.
EM yli92@vt.edu
OI Lee, Sang Won/0000-0002-1026-315X
CR Alibali M.W., 2005, Spatial Cognition and Computation, V5, P307, DOI [10.1207/s15427633scc05042, DOI 10.1207/S15427633SCC0504_2]
   Alibali MW, 2001, J MEM LANG, V44, P169, DOI 10.1006/jmla.2000.2752
   Allen G.L., 2003, Spatial Cognition and Computation, V3, P259, DOI DOI 10.1207/S15427633SCC0304_1
   [Anonymous], 2000, Language and Gesture, DOI [10.1017/CBO9780511620850.017, DOI 10.1017/CBO9780511620850.017]
   [Anonymous], 2017, P INT C COMP VIS ICC
   Baldwin D. A., 1995, JOINT ATTENTION ITS, P131
   Beattie G, 1999, J LANG SOC PSYCHOL, V18, P438, DOI 10.1177/0261927X99018004005
   Boboc RG, 2019, COMM COM INF SC, V904, P46, DOI 10.1007/978-3-030-05819-7_5
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Breen DE, 1996, COMPUT GRAPH FORUM, V15, pC11, DOI 10.1111/1467-8659.1530011
   Chastine J. W., 2008, P GRAPHICS INTERFACE, P275
   Chastine J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P117
   Chetverikov A, 2014, ACTA PSYCHOL, V151, P206, DOI 10.1016/j.actpsy.2014.06.012
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   COHEN AA, 1973, J PERS SOC PSYCHOL, V28, P276, DOI 10.1037/h0035792
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   DIX A, 1994, COMP SUPPORT COMP W, P9
   Hayashi K., 2005, P 2005 INT C AUGMENT, P180
   He ZY, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312761
   Huang WD, 2018, J MULTIMODAL USER IN, V12, P77, DOI 10.1007/s12193-017-0250-2
   Jeffrey W., 2007, THESIS US, pAAI3278579
   Kim S, 2020, IEEE ACCESS, V8, P224145, DOI 10.1109/ACCESS.2020.3043783
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kirk D. S., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1191
   Kita S, 2003, J MEM LANG, V48, P16, DOI 10.1016/S0749-596X(02)00505-3
   Kiyokawa K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P133, DOI 10.1109/ISMAR.2003.1240696
   Lee Gun A, 2004, PROC 2004 ACM SIGGRA, P419
   MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Mendez E., 2009, Proc. ACM Sym. Vir. Real- ity Softw. Technol., P247, DOI [10.1145/1643928.1643988, DOI 10.1145/1643928.1643988]
   Mon-Williams M, 2000, ERGONOMICS, V43, P391, DOI 10.1080/001401300184486
   NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614
   Oda O, 2012, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2012.6402558
   Olson GM, 2000, HUM-COMPUT INTERACT, V15, P139, DOI 10.1207/S15327051HCI1523_4
   Oviatt S., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P95, DOI 10.1145/238386.238438
   Oviatt Sharon., 1997, REFERRING PHENOMENA, P1
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Szalavari Z., 1998, Virtual Reality, V3, P37, DOI 10.1007/BF01409796
   Tang A, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P271
   WANN JP, 1995, VISION RES, V35, P2731, DOI 10.1016/0042-6989(95)00018-U
   Whittaker S, 2003, HUM-COMPUT INTERACT, V18, P149, DOI 10.1207/S15327051HCI1812_6
   Yamashita J., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P543
   Yoon B, 2020, INT SYM MIX AUGMENT, P520, DOI 10.1109/ISMAR50242.2020.00080
   Yuan L., 2019, S SPAT US INT SUI 19
   ZAHN GL, 1991, COMMUN RES, V18, P737, DOI 10.1177/009365091018006002
NR 47
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 1
PY 2021
VL 2
AR 681585
DI 10.3389/frvir.2021.681585
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AV3
UT WOS:001019300100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Embol, L
   Hutters, C
   Junker, A
   Reipur, D
   Adjorlu, A
   Nordahl, R
   Serafin, S
AF Embol, Lasse
   Hutters, Carl
   Junker, Andreas
   Reipur, Daniel
   Adjorlu, Ali
   Nordahl, Rolf
   Serafin, Stefania
TI HearMeVirtual Reality: Using Virtual Reality to Facilitate Empathy
   Between Hearing Impaired Children and Their Parents
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; cochlear implants; simulation; empathy; hearing loss
ID COCHLEAR-IMPLANT; SOUND LOCALIZATION; SPEECH-INTELLIGIBILITY; AUDITORY
   LOCALIZATION; BILATERAL USERS; NOISE; RECOGNITION; TECHNOLOGY;
   EMBODIMENT; LISTENERS
AB Cochlear implants (CI) enable hearing in individuals with sensorineural hearing loss, albeit with difficulties in speech perception and sound localization. In noisy environments, these difficulties are disproportionately greater for CI users than for children with no reported hearing loss. Parents of children with CIs are motivated to experience what CIs sound like, but options to do so are limited. This study proposes using virtual reality to simulate having CIs in a school setting with two contrasting settings: a noisy playground and a quiet classroom. To investigate differences between hearing conditions, an evaluation utilized a between-subjects design with 15 parents (10 female, 5 male; age M = 38.5, SD = 6.6) of children with CIs with no reported hearing loss. In the virtual environment, a word recognition and sound localization test using an open-set speech corpus compared differences between simulated unilateral CI, simulated bilateral CI, and normal hearing conditions in both settings. Results of both tests indicate that noise influences word recognition more than it influences sound localization, but ultimately affects both. Furthermore, bilateral CIs are equally to or significantly beneficial over having a simulated unilateral CI in both tests. A follow-up qualitative evaluation showed that the simulation enabled users to achieve a better understanding of what it means to be an hearing impaired child.
C1 [Embol, Lasse; Hutters, Carl; Junker, Andreas; Reipur, Daniel; Adjorlu, Ali; Nordahl, Rolf; Serafin, Stefania] Aalborg Univ, Dept Architecture, Multisensory Experience Lab, Copenhagen, Denmark.
   [Embol, Lasse; Hutters, Carl; Junker, Andreas; Reipur, Daniel; Adjorlu, Ali; Nordahl, Rolf; Serafin, Stefania] Aalborg Univ, Dept Design, Multisensory Experience Lab, Copenhagen, Denmark.
   [Embol, Lasse; Hutters, Carl; Junker, Andreas; Reipur, Daniel; Adjorlu, Ali; Nordahl, Rolf; Serafin, Stefania] Aalborg Univ, Dept Media Technol, Multisensory Experience Lab, Copenhagen, Denmark.
C3 Aalborg University; Aalborg University; Aalborg University
RP Serafin, S (corresponding author), Aalborg Univ, Dept Architecture, Multisensory Experience Lab, Copenhagen, Denmark.; Serafin, S (corresponding author), Aalborg Univ, Dept Design, Multisensory Experience Lab, Copenhagen, Denmark.; Serafin, S (corresponding author), Aalborg Univ, Dept Media Technol, Multisensory Experience Lab, Copenhagen, Denmark.
EM sts@create.aau.dk
OI Serafin, Stefania/0000-0001-6971-1132; Adjorlu, Ali/0000-0001-5414-8631
CR Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   Andersen O. D., 2011, SPECIALPAEDAGOGIK, V31, P43
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bailey JO, 2016, PRESENCE-TELEOP VIRT, V25, P222, DOI 10.1162/PRES_a_00263
   Beijen JW, 2007, OTOL NEUROTOL, V28, P479, DOI 10.1097/MAO.0b013e3180430179
   Ben Nsir C, 2019, MEDITERR MICROW SYMP, DOI [10.1109/mms48040.2019.9157327, 10.1145/3290605.3300528]
   Benedek J., 2002, P USABILITY PROFESSI, P57
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Brewer MB, 2014, HANDBOOK OF RESEARCH METHODS IN SOCIAL AND PERSONALITY PSYCHOLOGY, SECOND EDITION, P11
   Croghan NBH, 2017, J ACOUST SOC AM, V142, pEL537, DOI 10.1121/1.5016044
   Cucis P., 2018, MMC_C, V79, P179, DOI [10.18280/mmc_c.790405, DOI 10.18280/MMC_C.790405]
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   de la Torre Vega A., 2004, COCHLEAR IMPLANT SIM
   Decibel dk., 2016, FORST TID MED HOR
   Despret Vinciane., 2004, Body and Society, V10, P111, DOI 10.1177/1357034X04042938
   Dorman M., 2018, DEMONSTRATION CI MAT
   Dorman M., 2019, WHAT COCHLEAR IMPLAN
   Dorman MF, 2016, AUDIOL NEURO-OTOL, V21, P127, DOI 10.1159/000444740
   Foundation B., 2019, BLENDER
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P19, DOI 10.1007/s10162-004-5024-3
   Geers Ann E, 2007, Audiol Med, V5, P262, DOI 10.1080/16513860701659404
   Google, 2018, RES AUD UN
   Goupell MJ, 2008, J ACOUST SOC AM, V123, P2295, DOI 10.1121/1.2831738
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Holman MA, 2013, OTOL NEUROTOL, V34, P251, DOI 10.1097/MAO.0b013e31827d0922
   Hopkins Kathryn, 2015, Handb Clin Neurol, V129, P479, DOI 10.1016/B978-0-444-62630-1.00027-5
   igroup.org Project Consortium, 2016, IGR PRES QUEST IPQ
   Kalyanaraman S, 2010, J NERV MENT DIS, V198, P437, DOI 10.1097/NMD.0b013e3181e07d66
   Kearney G., 2015, AUDIO ENG SOC CONVEN
   Kerber S, 2012, EAR HEARING, V33, P445, DOI 10.1097/AUD.0b013e318257607b
   Kiger Gary., 1992, Disability, Handicap Society, V7, P71, DOI [DOI 10.1080/02674649266780061, 10.1080/02674649266780061]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kors M.J., 2020, P 2020 CHI C HUMAN F, P1
   Kral A., 2006, COCHLEAR BRAINSTEM I, P89
   Lakin JL, 2003, PSYCHOL SCI, V14, P334, DOI 10.1111/1467-9280.14481
   Laszig R, 2004, OTOL NEUROTOL, V25, P958, DOI 10.1097/00129492-200411000-00016
   Lim MY, 2011, ENTERTAIN COMPUT, V2, P223, DOI 10.1016/j.entcom.2011.02.004
   Litovsky RY, 2006, INT J AUDIOL, V45, pS78, DOI 10.1080/14992020600782956
   MATLAB, 2020, MATLAB R2020A
   MOORE JM, 1975, J SPEECH HEAR DISORD, V40, P29, DOI 10.1044/jshd.4001.29
   Moreno R, 1999, J EDUC PSYCHOL, V91, P358, DOI 10.1037/0022-0663.91.2.358
   Müller J, 2002, EAR HEARING, V23, P198
   Nielsen JB, 2014, J ACOUST SOC AM, V135, P407, DOI 10.1121/1.4835935
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [10.17011/ht/urn.201611174652, DOI 10.17011/HT/URN.201611174652]
   Nordqvist C., 2016, DEAFNESS HEARING LOS
   of America H. L. A., 2018, COCHL IMPL OTH IMPL
   On Deafness N. N. I. and Disorders O. C, 2016, COCHLEAR IMPLANTS
   Organization W. H, 2020, DEAFN HEAR LOSS
   Oticon, 2018, BARN MILJ SOC LIV
   Oticon, 2018, DERF ER BORNS HOR SA
   Oticon, 2018, HAV BARN MED HOR
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Peters B, 2004, INT CONGR SER, V1273, P462, DOI 10.1016/j.ics.2004.08.020
   Preece John P., 2010, Seminars in Hearing, V31, P37, DOI 10.1055/s-0029-1246323
   Ramsden R, 2005, OTOL NEUROTOL, V26, P988, DOI 10.1097/01.mao.0000185075.58199.22
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Schoen F, 2005, OTOL NEUROTOL, V26, P429, DOI 10.1097/01.mao.0000169772.16045.86
   Senn P, 2005, AUDIOL NEURO-OTOL, V10, P342, DOI 10.1159/000087351
   Sensimetrics, 2007, HELPS V2 HEAR LOSS P
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Silton N. R, 2019, SCI CONCEPTS HAPPINE, DOI [10.4018/978-1-5225-5918-4.ch010, DOI 10.4018/978-1-5225-5918-4.CH010]
   Smith A., 2011, INT J CREAT ARTS INT, V10, P1
   Steam, 2019, STEAMVR FRAM SOFTW
   Stevens G, 2013, EUR J PUBLIC HEALTH, V23, P146, DOI 10.1093/eurpub/ckr176
   Stickney GS, 2004, J ACOUST SOC AM, V116, P1081, DOI 10.1121/1.1772399
   Unity, 2019, UNITY SOFTWARE
   van Hoesel R, 2008, J ACOUST SOC AM, V123, P2249, DOI 10.1121/1.2875229
   VANDERHEIDEN G C., 1992, Accessible Design of Consumer Products: Guidelines for the Design of Consumer Products to Increase Their Accessibility to People with Disabilities or Who Are Aging - Working Draft 1.7
   Verschuur CA, 2005, OTOL NEUROTOL, V26, P965, DOI 10.1097/01.mao.0000185073.81070.07
   Waltzman SB, 2002, OTOLARYNG HEAD NECK, V126, P505, DOI 10.1067/mhn.2002.124472
   Wilson RH, 2007, J AM ACAD AUDIOL, V18, P522, DOI 10.3766/jaaa.18.6.7
   Wright P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P637
   Yantis S., 2014, SENSATION PERCEPTION
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zaltz Y, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051381
   Zhao Y., 2018, P 2018 CHI C HUMAN F, P1, DOI [DOI 10.1145/3173574.3173690, 10.1145/3173574.3173690]
   Zhao Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173690
NR 79
TC 4
Z9 4
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 16
PY 2021
VL 2
AR 691984
DI 10.3389/frvir.2021.691984
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TY5
UT WOS:001021846800001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Anders, D
   Berisha, A
   Selaskowski, B
   Asché, L
   Thorne, JD
   Philipsen, A
   Braun, N
AF Anders, David
   Berisha, Arbnor
   Selaskowski, Benjamin
   Asche, Laura
   Thorne, Jeremy D.
   Philipsen, Alexandra
   Braun, Niclas
TI Experimental Induction of Micro- and Macrosomatognosia: A Virtual Hand
   Illusion Study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE microsomatognosia; macrosomatognosia; virtual hand illusion; body size
   perception; EDA; body transfer illusion
ID WONDERLAND SYNDROME; RUBBER HAND; PERCEIVED OWNERSHIP; ALICE; BODY;
   SIZE; EXPERIENCE; BRAIN
AB Although body size misperceptions are known to occur under various neurological and psychiatric conditions, their neurocognitive underpinnings are not yet resolved. Accordingly, it would be beneficial to have an experimental paradigm, by which aberrant body misperceptions could be induced and systematically investigated. Expanding upon the "Virtual Hand Illusion" (VHI), this study aimed to design such a paradigm. Using a body-motion tracking system, we translated the participant's real hand position and movements to an embodiable, but resizable virtual hand model that we presented to the participants via a head-mounted display. The virtual hand's size was then systematically shrunk and enlarged in five different conditions (i.e., -50%, -25%, 0%, +25% or +50% rescaling). Applying this VHI derivate on n = 35 healthy participants, we investigated (1) if participants experience Sense of Ownership (SoO) and Sense of Agency (SoA) over a virtual hand that significantly deviates in size from their own hand, and (2) if by such size-deviant VHI induction, a change in their own hand size perception is also induced. Virtual hand embodiment was explicitly and implicitly assessed by means of self-report and EDA analysis. Questionnaire results revealed a stable SoA across all hand size conditions, while SoO parametrically decreased according to the hand scaling factor in either direction. Hand size perception, in turn, adapted according to the hand-scaling factor. In conclusion, the present study provides an important step toward an experimental paradigm that can induce and investigate aberrant body-size misperceptions.
C1 [Anders, David; Berisha, Arbnor; Selaskowski, Benjamin; Asche, Laura; Thorne, Jeremy D.; Philipsen, Alexandra; Braun, Niclas] Univ Bonn, Dept Psychiat & Psychotherapy, Bonn, Germany.
C3 University of Bonn
RP Braun, N (corresponding author), Univ Bonn, Dept Psychiat & Psychotherapy, Bonn, Germany.
EM niclas.braun@ukbonn.de
RI Selaskowski, Benjamin/KIC-0837-2024; Braun, Niclas/ITT-1944-2023
OI Selaskowski, Benjamin/0000-0002-4117-8265; Anders,
   David/0000-0001-6843-3644
CR Alimardani M, 2013, SCI REP-UK, V3, DOI 10.1038/srep02396
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   Blom JD, 2016, NEUROL-CLIN PRACT, V6, P259, DOI 10.1212/CPJ.0000000000000251
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Braun N, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00012
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   Braun N, 2016, SCI REP-UK, V6, DOI 10.1038/srep37696
   Braun N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111967
   Bui E, 2010, J NEUROPSYCH CLIN N, V22, pE16
   Choi W, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/8163098
   Dawson ME., 2017, Handbook of Psychophysiology, V4, P217, DOI [DOI 10.1017/9781107415782, 10.1017/9781107415782.010]
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dieguez S, 2017, ANN PHYS REHABIL MED, V60, P198, DOI 10.1016/j.rehab.2016.04.007
   Ehrsson HH, 2005, PLOS BIOL, V3, P2200, DOI 10.1371/journal.pbio.0030412
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Haans A, 2008, BODY IMAGE, V5, P389, DOI 10.1016/j.bodyim.2008.04.003
   Haggard P, 2009, PERCEPTION, V38, P1796, DOI 10.1068/p6399
   Holle H, 2011, COGN NEUROSCI-UK, V2, P171, DOI 10.1080/17588928.2011.603828
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Keizer A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163921
   Keizer A, 2014, NEUROPSYCHOLOGIA, V62, P26, DOI 10.1016/j.neuropsychologia.2014.07.003
   Kew J, 1998, LANCET, V351, P1934, DOI 10.1016/S0140-6736(05)78619-0
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Ma K, 2015, CONSCIOUS COGN, V36, P277, DOI 10.1016/j.concog.2015.07.008
   Möller TJ, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00474
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Ocklenburg S, 2011, LATERALITY, V16, P174, DOI 10.1080/13576500903483515
   Ogawa N, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P647, DOI 10.1109/VR.2018.8446318
   Palacios-Sánchez Leonardo, 2018, Rev. colomb. anestesiol., V46, P143, DOI 10.1097/cj9.0000000000000026
   Paqueron X, 2003, BRAIN, V126, P702, DOI 10.1093/brain/awg063
   Pavani F, 2007, PERCEPTION, V36, P1547, DOI 10.1068/p5853
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Podoll K, 1998, FORTSCHR NEUROL PSYC, V66, P338, DOI 10.1055/s-2007-995271
   Preston C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085773
   Ramachandran VS, 2009, BRAIN, V132, P1693, DOI 10.1093/brain/awp135
   Rode G, 2012, NEUROPSYCHOLOGIA, V50, P245, DOI 10.1016/j.neuropsychologia.2011.11.018
   Rohde M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021659
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Schettler A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01332
   Serino S, 2016, CYBERPSYCH BEH SOC N, V19, P127, DOI 10.1089/cyber.2015.0229
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Spychala N, 2020, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00461
   TODD J, 1955, Can Med Assoc J, V73, P701
   Tsakiris M, 2010, EXP BRAIN RES, V204, P343, DOI 10.1007/s00221-009-2039-3
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   Tunç S, 2017, PSYCHIAT CLIN PSYCH, V27, P412, DOI 10.1080/24750573.2017.1354655
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Venables PH, 1996, BIOL PSYCHOL, V43, P87, DOI 10.1016/0301-0511(96)05183-6
   Weijers NR, 2013, J NEUROL, V260, P925, DOI 10.1007/s00415-012-6827-5
   Weissenstein A, 2014, J PEDIATR NEUROSCI, V9, P303, DOI 10.4103/1817-1745.147612
   Wittkopf PG, 2017, EXP BRAIN RES, V235, P1933, DOI 10.1007/s00221-017-4930-7
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 60
TC 1
Z9 1
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2021
VL 2
AR 656788
DI 10.3389/frvir.2021.656788
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WW6
UT WOS:001023295200001
OA gold
DA 2024-07-18
ER

PT J
AU Tunur, T
   Hauze, SW
   Frazee, JP
   Stuhr, PT
AF Tunur, Tumay
   Hauze, Sean W.
   Frazee, James P.
   Stuhr, Paul T.
TI XR-Immersive Labs Improve Student Motivation to Learn Kinesiology
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; extended reality; education; motivation; learning;
   laboratory
ID VIRTUAL-REALITY; EDUCATION; ENVIRONMENT; DISPLAYS; COURSES
AB Kinesiology is an inherently spatial discipline, both physically and visually. The use of extended reality-immersive lab activities may enhance students' motivation to learn by enabling students to interact with visual content and illustrate and demonstrate kinesiology content and concepts. Using an instrumental case study method, this article assesses the use of extended reality immersion across three semesters of an upper division kinesiology course focused on motor control. This is a unique approach because it blends established physical motor control and biomechanical data collection techniques with emerging virtual reality technology to enhance-rather than replace-the lab experience. The effectiveness is measured via an experimental design to contribute to the small, but growing, body of knowledge on the efficacy of immersive learning.
C1 [Tunur, Tumay; Stuhr, Paul T.] Calif State Univ San Marcos, Kinesiol, San Marcos, CA 92096 USA.
   [Hauze, Sean W.; Frazee, James P.] San Diego State Univ, Instruct Technol Serv, San Diego, CA USA.
C3 California State University System; California State University San
   Marcos; California State University System; San Diego State University
RP Tunur, T (corresponding author), Calif State Univ San Marcos, Kinesiol, San Marcos, CA 92096 USA.
EM ttunur@csusm.edu
CR Annamalai S, 2016, EUR PROC SOC BEHAV, V14, P320, DOI 10.15405/epsbs.2016.08.45
   Argles T., 2015, GEOL TODAY, V31, P222, DOI DOI 10.1111/gto.12116
   Bennett JA, 2019, J MICROBIOL BIOL EDU, V20, DOI 10.1128/jmbe.v20i2.1658
   Biyun Huang, 2016, International Journal of Information and Education Technology, V9, P759, DOI 10.7763/IJIET.2016.V6.788
   Bloom B. S., 1968, Evaluation Comment, V1, DOI DOI 10.1021/ED063P318
   Chang YS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010105
   Chavez Bayron, 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 746), P1345, DOI 10.1007/978-3-319-77712-2_129
   Cook DA, 2009, ACAD MED, V84, P1505, DOI 10.1097/ACM.0b013e3181baf56d
   Corbin J., 2015, BASICS QUALITATIVE R
   de Vries LE, 2019, BIOCHEM MOL BIOL EDU, V47, P257, DOI 10.1002/bmb.21221
   Dede C., 2008, INT HDB INFORM TECHN, V20
   Domingo Jelia R., 2018, Journal of Educational Technology Systems, V46, P329, DOI 10.1177/0047239517736873
   Eckert D., 2020, EFFECTIVENESS VIRTUA
   ERICSSON KA, 1993, PSYCHOL REV, V100, P363, DOI 10.1037/0033-295X.100.3.363
   Hartley MD, 2015, RURAL SPEC EDUC Q, V34, P21, DOI 10.1177/875687051503400305
   Hauze SW, 2019, ADV EXP MED BIOL, V1120, P1, DOI 10.1007/978-3-030-06070-1_1
   Janssen Daniela., 2016, International Journal of Advanced Corporate Learning, V9, P20, DOI DOI 10.3991/IJAC.V9I2.6000
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jensen O., 1998, BUYER SELLER RELATIO
   Keller J. M., 1987, Journal of Instructional Development, V10, P2, DOI [10.1007/BF02905780, DOI 10.1007/BF02905780]
   Kim H, 2017, INTERACT LEARN ENVIR, V25, P543, DOI 10.1080/10494820.2016.1167744
   Klotz F., 2018, MIT SLOAN MANAGE REV, V59, P1
   Kluge Stacy, 2008, Journal of Issues in Informing Science and Information Technology Journal, V5, P127
   Koglbauer I, 2015, PROCD SOC BEHV, V209, P268, DOI 10.1016/j.sbspro.2015.11.232
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Loorbach N, 2015, BRIT J EDUC TECHNOL, V46, P204, DOI 10.1111/bjet.12138
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   O'Connor Eileen A., 2017, Journal of Educational Technology Systems, V45, P343, DOI 10.1177/0047239516673361
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rae A, 2011, COMPUT EDUC, V57, P2423, DOI 10.1016/j.compedu.2011.06.003
   Riva G., 2016, Human Computer Confluence: Transforming Human Experience Through Symbiotic Technologies, V181, eds, P55, DOI DOI 10.1515/9783110471137-004
   Sattar MU, 2019, PAK J MED SCI, V35, P852, DOI 10.12669/pjms.35.3.44
   SHUELL TJ, 1986, REV EDUC RES, V56, P411, DOI 10.2307/1170340
   Siemens G., 2005, Connectivism: learning as network creation
   Stake, 1995, The Art of Case Study Research, DOI DOI 10.1108/EB024859
   Stepan K, 2017, INT FORUM ALLERGY RH, V7, P1006, DOI 10.1002/alr.21986
   Tunur T., 2020, P 6 INT C IMM LEARN
   Urso P, 2015, INT J CHILDBIRTH EDU, V30, P33
   Walmart Case Study, 2018, FOOTST TRAILBL WALM
NR 39
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2021
VL 2
AR 625379
DI 10.3389/frvir.2021.625379
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2RN8
UT WOS:001021783700001
OA gold
DA 2024-07-18
ER

PT J
AU Madeira, O
   Gromer, D
   Latoschik, ME
   Pauli, P
AF Madeira, Octavia
   Gromer, Daniel
   Latoschik, Marc Erich
   Pauli, Paul
TI Effects of Acrophobic Fear and Trait Anxiety on Human Behavior in a
   Virtual Elevated Plus-Maze
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE elevated plus-maze; EPM; anxiety; virtual reality; translational
   neuroscience; acrophobia; trait anxiety
ID APPROACH-AVOIDANCE CONFLICT; SENSATION SEEKING; SUBLIMINAL THREAT;
   SELF-REPORT; OPEN-FIELD; UNCERTAINTY; INTOLERANCE; VULNERABILITY;
   SUBTHRESHOLD; STIMULATION
AB The Elevated Plus-Maze (EPM) is a well-established apparatus to measure anxiety in rodents, i.e., animals exhibiting an increased relative time spent in the closed vs. the open arms are considered anxious. To examine whether such anxiety-modulated behaviors are conserved in humans, we re-translated this paradigm to a human setting using virtual reality in a Cave Automatic Virtual Environment (CAVE) system. In two studies, we examined whether the EPM exploration behavior of humans is modulated by their trait anxiety and also assessed the individuals' levels of acrophobia (fear of height), claustrophobia (fear of confined spaces), sensation seeking, and the reported anxiety when on the maze. First, we constructed an exact virtual copy of the animal EPM adjusted to human proportions. In analogy to animal EPM studies, participants (N = 30) freely explored the EPM for 5 min. In the second study (N = 61), we redesigned the EPM to make it more human-adapted and to differentiate influences of trait anxiety and acrophobia by introducing various floor textures and lower walls of closed arms to the height of standard handrails. In the first experiment, hierarchical regression analyses of exploration behavior revealed the expected association between open arm avoidance and Trait Anxiety, an even stronger association with acrophobic fear. In the second study, results revealed that acrophobia was associated with avoidance of open arms with mesh-floor texture, whereas for trait anxiety, claustrophobia, and sensation seeking, no effect was detected. Also, subjects' fear rating was moderated by all psychometrics but trait anxiety. In sum, both studies consistently indicate that humans show no general open arm avoidance analogous to rodents and that human EPM behavior is modulated strongest by acrophobic fear, whereas trait anxiety plays a subordinate role. Thus, we conclude that the criteria for cross-species validity are met insufficiently in this case. Despite the exploratory nature, our studies provide in-depth insights into human exploration behavior on the virtual EPM.
C1 [Madeira, Octavia; Gromer, Daniel; Pauli, Paul] Univ Wurzburg, Dept Psychol Biol Psychol Clin Psychol & Psychothe, Biol Psychol, Wurzburg, Germany.
   [Latoschik, Marc Erich] Univ Wurzburg, Dept Human Comp Interact, Wurzburg, Germany.
   [Pauli, Paul] Univ Wurzburg, Ctr Mental Hlth, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg; University of Wurzburg
RP Madeira, O (corresponding author), Univ Wurzburg, Dept Psychol Biol Psychol Clin Psychol & Psychothe, Biol Psychol, Wurzburg, Germany.
EM octavia.madeira@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600; Madeira,
   Octavia/0000-0003-1427-6449
CR [Anonymous], 2012, TASCHENFUHRER ICD 10
   Aupperle RL, 2011, BEHAV BRAIN RES, V225, P455, DOI 10.1016/j.bbr.2011.08.003
   BARNETT S A, 1975, P318
   Beauducel A, 2003, DIAGNOSTICA, V49, P61, DOI 10.1026//0012-1924.49.2.61
   Biedermann SV, 2017, BMC BIOL, V15, DOI 10.1186/s12915-017-0463-6
   Boecker L, 2019, NEUROSCI BIOBEHAV R, V103, P230, DOI 10.1016/j.neubiorev.2019.05.019
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Braun AA, 2011, PHARMACOL BIOCHEM BE, V97, P406, DOI 10.1016/j.pbb.2010.09.013
   Carleton RN, 2007, J ANXIETY DISORD, V21, P105, DOI 10.1016/j.janxdis.2006.03.014
   Carleton RN, 2016, J ANXIETY DISORD, V41, P5, DOI 10.1016/j.janxdis.2016.03.011
   Carleton RN, 2012, J ANXIETY DISORD, V26, P468, DOI 10.1016/j.janxdis.2012.01.011
   Carobrez AP, 2005, NEUROSCI BIOBEHAV R, V29, P1193, DOI 10.1016/j.neubiorev.2005.04.017
   Carter RM, 2001, DEPRESS ANXIETY, V13, P78, DOI 10.1002/da.1020
   Clark L, 2012, PSYCHOPHYSIOLOGY, V49, P1436, DOI 10.1111/j.1469-8986.2012.01454.x
   COHEN DC, 1977, BEHAV THER, V8, P17, DOI 10.1016/S0005-7894(77)80116-0
   Diemer J, 2016, J ANXIETY DISORD, V37, P30, DOI 10.1016/j.janxdis.2015.10.007
   Dobricki M, 2016, HELIYON, V2, DOI 10.1016/j.heliyon.2016.e00173
   Gallagher MW, 2014, COGNITIVE THER RES, V38, P571, DOI 10.1007/s10608-014-9624-x
   Gould TD, 2009, NEUROMETHODS, V42, P1, DOI 10.1007/978-1-60761-303-9_1
   Griebel G, 2013, NAT REV DRUG DISCOV, V12, P667, DOI 10.1038/nrd4075
   Grillon C, 2019, NEUROPSYCHOPHARMACOL, V44, P1999, DOI 10.1038/s41386-019-0445-1
   Grillon C, 2016, BIOL PSYCHIAT, V80, P343, DOI 10.1016/j.biopsych.2016.07.003
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Haaker J, 2019, NEUROSCI BIOBEHAV R, V107, P329, DOI 10.1016/j.neubiorev.2019.09.020
   Hagenaars MA, 2014, NEUROSCI BIOBEHAV R, V47, P165, DOI 10.1016/j.neubiorev.2014.07.021
   Hofmann S.G., 2009, Oxford handbook of anxiety related disorders, P34
   Hogg S, 1996, PHARMACOL BIOCHEM BE, V54, P21, DOI 10.1016/0091-3057(95)02126-4
   Hueweler R, 2009, BEHAV RES THER, V47, P345, DOI 10.1016/j.brat.2009.01.011
   IBM Corp, 2016, IBM SPSS Statistics for Windows, Version 22.0
   Karsten J, 2011, J AFFECT DISORDERS, V129, P236, DOI 10.1016/j.jad.2010.09.006
   Kinateder M, 2014, TRANSPORT RES F-TRAF, V26, P116, DOI 10.1016/j.trf.2014.06.003
   Kindt M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086462
   Kirlic N, 2017, BEHAV RES THER, V96, P14, DOI 10.1016/j.brat.2017.04.010
   Komada Munekazu, 2008, J Vis Exp, DOI 10.3791/1088
   Lang P. J., 1985, Anxiety and the anxiety disorders
   Laux L., 1981, Das State-Trait-Angstinventar. Theoretische Grundlagen und Handanweisung
   Li W, 2007, COGN AFFECT BEHAV NE, V7, P25, DOI 10.3758/CABN.7.1.25
   Lonsdorf TB, 2017, NEUROSCI BIOBEHAV R, V77, P247, DOI 10.1016/j.neubiorev.2017.02.026
   Madeira O, 2017, J NEURAL TRANSM, V124, P1309
   Maner JK, 2006, BEHAV THER, V37, P181, DOI 10.1016/j.beth.2005.11.003
   MONTGOMERY KC, 1955, J COMP PHYSIOL PSYCH, V48, P254, DOI 10.1037/h0043788
   Morriss J, 2019, J EXP PSYCHOPATHOL, V10, DOI 10.1177/2043808719834451
   PELLOW S, 1985, J NEUROSCI METH, V14, P149, DOI 10.1016/0165-0270(85)90031-7
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Radomsky AS, 2001, J ANXIETY DISORD, V15, P287, DOI 10.1016/S0887-6185(01)00064-0
   Ramos A, 2008, BEHAV BRAIN RES, V193, P277, DOI 10.1016/j.bbr.2008.06.007
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reuman L, 2015, J BEHAV THER EXP PSY, V47, P111, DOI 10.1016/j.jbtep.2014.12.002
   Roelofs K, 2010, PSYCHOL SCI, V21, P1575, DOI 10.1177/0956797610384746
   Rösler L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53683-4
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schubert T, 2001, Teleoperators Virtual Environ, V41, P115
   Shihata S, 2016, J ANXIETY DISORD, V41, P115, DOI 10.1016/j.janxdis.2016.05.001
   Spielberger C.D., 2013, Anxiety: Current trends in theory and research
   Spielberger C.D., 1966, ANXIETY BEHAV, DOI DOI 10.1016/B978-1-4832-3131-0.50006-8
   TREIT D, 1993, PHARMACOL BIOCHEM BE, V44, P463, DOI 10.1016/0091-3057(93)90492-C
   VANDENHOUT M, 1995, BEHAV RES THER, V33, P451, DOI 10.1016/0005-7967(94)00062-O
   Walz N, 2016, BIOL PSYCHIAT, V80, P390, DOI 10.1016/j.biopsych.2015.12.016
   Yang Y, 2016, SOC COGN AFFECT NEUR, V11, P1245, DOI 10.1093/scan/nsw024
   ZUCKERMAN M, 1978, J CONSULT CLIN PSYCH, V46, P139, DOI 10.1037/0022-006X.46.1.139
NR 61
TC 3
Z9 4
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 20
PY 2021
VL 2
AR 635048
DI 10.3389/frvir.2021.635048
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VA2
UT WOS:001019147200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Pospick, CH
   Rosenberg, ES
AF Pospick, Courtney Hutton
   Rosenberg, Evan Suma
TI Creating and manipulating 3D paths with mixed reality spatial interfaces
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE human-computer interaction (HCI); 3D user interface design; 3D path
   planning; virtual reality (VR); augmented reality (AR); mixed reality
   (MR); user studies
ID VIRTUAL ENVIRONMENTS; DESIGN; EXPERIENCE; NAVIGATION
AB Mixed reality offers unique opportunities to situate complex tasks within spatial environments. One such task is the creation and manipulation of intricate, three-dimensional paths, which remains a crucial challenge in many fields, including animation, architecture, and robotics. This paper presents an investigation into the possibilities of spatially situated path creation using new virtual and augmented reality technologies and examines how these technologies can be leveraged to afford more intuitive and natural path creation. We present a formative study (n = 20) evaluating an initial path planning interface situated in the context of augmented reality and human-robot interaction. Based on the findings of this study, we detail the development of two novel techniques for spatially situated path planning and manipulation that afford intuitive, expressive path creation at varying scales. We describe a comprehensive user study (n = 36) investigating the effectiveness, learnability, and efficiency of both techniques when paired with a range of canonical placement strategies. The results of this study confirm the usability of these interaction metaphors and provide further insight into how spatial interaction can be discreetly leveraged to enable interaction at scale. Overall, this work contributes to the development of 3DUIs that expand the possibilities for situating path-driven tasks in spatial environments.
C1 [Pospick, Courtney Hutton; Rosenberg, Evan Suma] Univ Minnesota, Dept Comp Sci & Engn, Illusioneering Lab, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Pospick, CH (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Illusioneering Lab, Minneapolis, MN 55455 USA.
EM hutt070@umn.edu
RI Hutton Pospick, Courtney/HKV-7513-2023
OI Hutton Pospick, Courtney/0000-0002-4203-1513
CR Abtahi Parastoo, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130899
   Alexandrovsky D., 2020, P 2020 CHI C HUM FAC, P1
   Berger L, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P19, DOI 10.1145/3282894.3282932
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 2001, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2001.913781
   BRADLEY JV, 1958, J AM STAT ASSOC, V53, P525, DOI 10.2307/2281872
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Burri M., 2012, 2012 2nd International Conference on Applied Robotics for the Power Industry (CARPI 2012), P70, DOI 10.1109/CARPI.2012.6473374
   Cauchard JR, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P361, DOI 10.1145/2750858.2805823
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chheang V, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P547, DOI 10.1109/VRW55335.2022.00129
   Cohen J. M., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P17, DOI 10.1145/300523.300655
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   Do T. V., 2010, Int. J. Math. Comput. Sci., V4, P377
   Dreamteck, 2021, Dreamteck splines
   EGAN DE, 1989, ACM T INFORM SYST, V7, P30, DOI 10.1145/64789.64790
   Ekstrom AD, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00803
   Elm W., 1985, P HUMAN FACTORS SOC, P927, DOI [10.1177/154193128502901006, DOI 10.1177/154193128502901006]
   Englmeier D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P345, DOI 10.1109/VR50410.2021.00057
   Finstad K, 2010, J USABILITY STUD, V5, P104
   Finstad K, 2010, INTERACT COMPUT, V22, P323, DOI 10.1016/j.intcom.2010.04.004
   Gabbard J. L., 1997, A taxonomy of usability characteristics in virtual environments
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Ha T, 2012, INTERACT COMPUT, V24, P10, DOI 10.1016/j.intcom.2011.06.006
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   Hartson HR, 2003, INT J HUM-COMPUT INT, V15, P145, DOI 10.1207/S15327590IJHC1501_13
   Igarashi T., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P173, DOI 10.1145/288392.288599
   Jetter HC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376652
   Keefe DF, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P51
   Keefe DF, 2007, IEEE T VIS COMPUT GR, V13, P1067, DOI 10.1109/TVCG.2007.1060
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Krings Sarah Claudia, 2022, EICS '22 Companion: Companion of the 2022 ACM SIGCHI Symposium on Engineering Interactive Computing Systems, P14, DOI 10.1145/3531706.3536452
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9, DOI DOI 10.1145/364338.3643391,2
   Lee C., 2010, 2010 IEEE VIRT REAL
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.00-32, 10.1109/VR46266.2020.1581086151885]
   Marvel JA, 2020, ACM T HUM-ROBOT INTE, V9, DOI 10.1145/3385009
   Muffato V, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10040204
   Muller H., 2014, Ways of Knowing in HCI, P229, DOI [DOI 10.1007/978-1-4939-0378-8_10, 10.1007/978-1-4939-0378-810, DOI 10.1007/978-1-4939-0378-810]
   Paterson J, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3362742
   Pfeiffer-Lessmann N, 2018, COMM COM INF SC, V851, P311, DOI 10.1007/978-3-319-92279-9_42
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Quintero CP, 2018, IEEE INT C INT ROBOT, P1838, DOI 10.1109/IROS.2018.8593700
   Ragan E, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P287, DOI 10.1109/VR.2009.4811058
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Sanna A, 2013, ENTERTAIN COMPUT, V4, P179, DOI 10.1016/j.entcom.2013.01.001
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Sharon T., 2016, Validating product ideas: through lean user research
   Smith PA, 1996, INTERACT COMPUT, V8, P365, DOI 10.1016/S0953-5438(97)83779-4
   State Fair M., 2022, Media fact sheet. Tech. Rep
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Fernandez RAS, 2016, INT CONF UNMAN AIRCR, P1013, DOI 10.1109/ICUAS.2016.7502665
   Tullis T., 2013, Measuring the User Experience: Collecting, Analyzing, and Presenting Usability Metrics
   Vaquero-Melchor D, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3368420
   Venkatakrishnan R, 2023, IEEE T VIS COMPUT GR, V29, P2258, DOI 10.1109/TVCG.2023.3247041
   Vortmann Lisa-Marie, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382889
   Wagener N., 2020, P 26 ACM S VIRT REAL, P11
   Wilson JR, 1997, ERGONOMICS, V40, P1057, DOI 10.1080/001401397187603
   Wolbers T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00571
   Wyss HP, 2006, IEEE Symposium on 3D User Interfaces 2006, Proceedings, P59, DOI 10.1109/TRIDUI.2006.1618271
   Yu K, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P895, DOI 10.1109/VRW55335.2022.00301
   Zhai SM, 1999, J VISUAL LANG COMPUT, V10, P3, DOI 10.1006/jvlc.1998.0113
NR 64
TC 0
Z9 0
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 6
PY 2023
VL 4
AR 1192757
DI 10.3389/frvir.2023.1192757
PG 21
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CY5C5
UT WOS:001128795700001
OA gold
DA 2024-07-18
ER

PT J
AU Cahill, TJ
   Cummings, JJ
AF Cahill, Tiernan J. J.
   Cummings, James J. J.
TI Effects of congruity on the state of user presence in virtual
   environments: Results from a breaching experiment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE presence; congruity; plausibility illusion; mental models; genre;
   experiment
ID IMMERSION; REALITY; BREAKS
AB The present study investigates how the user state of presence is affected by contingencies in the design of virtual environments. The theoretical framework of congruity is herein explicated, which builds upon the concept of plausibility illusion as one of the essential prerequisites for presence, and which systematically explains and predicts presence in terms of alignment between schemata in the user's memory and stimuli presented within the virtual environment. Three dimensions of congruity are explicated and discussed: sensory, environmental, and thematic. A series of breaching experiments were conducted in a virtual environment testing the effects of each dimension of incongruity on presence. These experiments were inconclusive regarding the effects of sensory and environmental congruity; however, the results strongly suggest that the state of presence is contingent upon thematic congruity in virtual environments. This finding has theoretical significance insofar as it points towards the necessity of considering genre and cultural context in predicting user states in virtual environments. The study also has practical relevance to designers and developers of content for virtual reality in that it identifies a critical psychological consideration for the user experience that is absent from existing models.
C1 [Cahill, Tiernan J. J.; Cummings, James J. J.] Boston Univ, Coll Commun, Div Emerging Media Studies, Boston, MA 02215 USA.
C3 Boston University
RP Cahill, TJ (corresponding author), Boston Univ, Coll Commun, Div Emerging Media Studies, Boston, MA 02215 USA.
EM tjcahill@bu.edu
RI Cahill, Tiernan/AAH-5647-2019
OI Cahill, Tiernan/0000-0001-5715-9192
CR Amenabar T., 2022, PLAYSTATION REVEALS
   [Anonymous], 1963, Motivation and Social Interaction. Cognitive Determinants
   Apperley TH, 2006, SIMULAT GAMING, V37, P6, DOI 10.1177/1046878105282278
   Arsenault D., 2009, ELUDAMOS J COMPUTER, V3, P149, DOI [10.7557/23.6003, DOI 10.7557/23.6003]
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Battaglia PW, 2013, P NATL ACAD SCI USA, V110, P18327, DOI 10.1073/pnas.1306572110
   Beckhaus S, 2011, VIRTUAL REALITIES: DAGSTUHL SEMINAR 2008, P39, DOI 10.1007/978-3-211-99178-7_3
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Cahill T. J., 2018, PRESENCE 2018
   Clarke RI, 2017, GAMES CULT, V12, P445, DOI 10.1177/1555412015591900
   Cummings JJ, 2023, VIRTUAL REAL-LONDON, V27, P1357, DOI 10.1007/s10055-022-00736-1
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dickson B., 2018, THERES MAJOR LACK QU
   Garau M, 2008, PRESENCE-TELEOP VIRT, V17, P293, DOI 10.1162/pres.17.3.293
   Garfinkel Harold, 1967, STUDIES ETHNOMETHODO
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Hartmann T, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694048
   International Data Corporation, 2021, SPEND EM DEV CAT INC
   International Data Corporation, 2022, AR VR HEADS SHIPM GR
   Ismail N., 2017, WHATS HOLDING VIRTUA
   Jung SC, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.693327
   Kassambara Alboukadel, 2023, CRAN
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Livingstone S., 2013, Making Sense of Television: The Psychology of Audience Interpretation
   LIVINGSTONE SM, 1993, J COMMUN, V43, P5, DOI 10.1111/j.1460-2466.1993.tb01298.x
   Mangiafico Salvatore, 2024, CRAN
   Martindale J., 2020, OCULUS QUEST VS OCUL
   OKane Josh, 2020, The Globe and Mail
   Ovide S., 2022, The New York Times
   Piaget J., 1930, CHILDS CONCEPTION PH
   Renaud P, 2002, IEEE T INF TECHNOL B, V6, P235, DOI [10.1109/TITB.2002.802381, 10.1109/TITB.2002.802381.]
   Revelle William, 2024, CRAN
   Rey B, 2011, PRESENCE-TELEOP VIRT, V20, P273, DOI 10.1162/PRES_a_00049
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rovira A, 2009, FRONT BEHAV NEUROSCI, V3, DOI 10.3389/neuro.08.059.2009
   SCHMIDT SJ, 1987, POETICS, V16, P371, DOI 10.1016/0304-422X(87)90028-3
   Skarbez R. T., 2016, Plausibility illusion in virtual environments (Doctoral Dissertation)
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2002, PRESENCE-TELEOP VIRT, V11, P435, DOI 10.1162/105474602760204327
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Vorderer P., 2004, Mec spatial presence questionnaire
   Weber S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.628298
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 48
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 9
PY 2023
VL 4
AR 1048812
DI 10.3389/frvir.2023.1048812
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RR3
UT WOS:001023159300001
OA gold
DA 2024-07-18
ER

PT J
AU Stuart, J
   Stephen, A
   Aul, K
   Bumbach, MD
   Huffman, S
   Russo, B
   Lok, B
AF Stuart, Jacob
   Stephen, Anita
   Aul, Karen
   Bumbach, Michael D.
   Huffman, Shari
   Russo, Brooke
   Lok, Benjamin
TI Using augmented reality filters to display time-based visual cues
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; visual cue training; healthcare; simulation;
   symptoms; fidelity; realism
ID SIMULATION
AB Introduction: Healthcare education commonly uses practices like moulage to represent visual cues (e.g., symptoms). Unfortunately, current practices have limitations in accurately representing visual symptoms that develop over time. To address this challenge, we applied augmented reality (AR) filters to images displayed on computer screens to enable real-time interactive visualizations of symptom development. Additionally, this study explores the impact of object and filter fidelity on users' perceptions of visual cues during training, providing evidence-based recommendations on the effective use of filters in healthcare education.Methods: We conducted a 2 x 2 within-subjects study that involved second-year nursing students (N = 55) from the University of Florida. The study manipulated two factors: filter fidelity and object fidelity. Filter fidelity was manipulated by applying either a filter based on a medical illustration image or a filter based on a real symptom image. Object fidelity was manipulated by overlaying the filter on either a medical manikin image or a real person image. To ensure that potential confounding variables such as lighting or 3D tracking did not affect the results, 101 images were pre-generated for each of the four conditions. These images mapped to the transparency levels of the filters, which ranged from 0 to 100. Participants interacted with the images on a computer screen using visual analog scales, manipulating the transparency of the symptoms until they identified changes occurring on the image and distinct symptom patterns. Participants also rated the severity and realism of each condition and provided feedback on how the filter and object fidelities impacted their perceptions.Results: We found evidence that object and filter fidelity impacted user perceptions of symptom realism and severity and even affected users' abilities to identify the symptoms. This includes symptoms being seen as more realistic when overlaid on the real person, symptoms being identified at earlier stages of development when overlaid on the manikin, and symptoms being seen as most severe when the real-image filter was overlayed on the manikin.Conclusion: This work implemented a novel approach that uses AR filters to display visual cues that develop over time. Additionally, this work's investigation into fidelity allows us to provide evidence-based recommendations on how and when AR filters can be effectively used in healthcare education.
C1 [Stuart, Jacob; Lok, Benjamin] Univ Florida, Virtual Experiences Res Grp, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
   [Stephen, Anita; Bumbach, Michael D.; Huffman, Shari; Russo, Brooke] Univ Florida, Coll Nursing, Gainesville, FL USA.
   [Aul, Karen] Univ S Florida, Coll Nursing, Tampa, FL USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of Florida; State University
   System of Florida; University of South Florida
RP Stuart, J (corresponding author), Univ Florida, Virtual Experiences Res Grp, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
EM JacobStuart@ufl.edu
OI Stuart, Jacob/0000-0003-2103-5782; Lok, Benjamin/0000-0002-1190-3729
FU National Science Foundation [1800961, 1800947]
FX This work was funded by the National Science Foundation award numbers
   1800961 and 1800947.
CR [Anonymous], 2019, SKIN RASHES
   BioDigital, 2023, BIODIGITAL HUMAN
   Bonewit-West K., 2014, TODAYS MEDICAL ASSIS
   Brown Anthony F, 2003, Emerg Med (Fremantle), V15, P315, DOI 10.1046/j.1442-2026.2003.00468.x
   Coffman S, 2023, TEACH LEARN NURS, V18, P232, DOI 10.1016/j.teln.2022.09.012
   Daher S, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P99, DOI 10.1145/3267851.3267876
   Diaz C, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P111, DOI 10.1109/ISMAR.2017.28
   Do TD, 2020, INT SYM MIX AUGMENT, P64, DOI 10.1109/ISMAR50242.2020.00026
   Flynn D, 2004, EUR J PSYCHOL ASSESS, V20, P49, DOI 10.1027/1015-5759.20.1.49
   Hernandez Y., 2016, DESIGNING EMPATHETIC
   Herron EK, 2017, CLIN SIMUL NURS, V13, P331, DOI 10.1016/j.ecns.2017.05.011
   Huber BJ, 2022, NURSE EDUC PRACT, V59, DOI 10.1016/j.nepr.2021.103131
   Kahneman D, 1982, JUDGMENT UNCERTAINTY, DOI DOI 10.1097/00001888-199907000-00012
   Kiekkas Panagiotis, 2007, Nurs Crit Care, V12, P34, DOI 10.1111/j.1478-5153.2006.00193.x
   Knapp P, 2022, PERSPECT MED EDUC, V11, P309, DOI 10.1007/s40037-022-00736-6
   Krasnoryadtseva A, 2020, PATIENT EDUC COUNS, V103, P556, DOI 10.1016/j.pec.2019.09.026
   Lammers R, 2014, PREHOSP EMERG CARE, V18, P295, DOI 10.3109/10903127.2013.856501
   Lee SK, 2003, J TRAUMA, V55, P651, DOI 10.1097/01.TA.0000035092.83759.29
   Liang CJ, 2021, VIRTUAL REAL-LONDON, V25, P575, DOI 10.1007/s10055-020-00475-1
   Lok B, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.68
   Lupus Trust, 2021, DISC LUP
   Massie JP, 2021, J NATL MED ASSOC, V113, P88, DOI 10.1016/j.jnma.2020.07.013
   Mayo Clinic, 2021, HEN SCHONL PURPURA
   Mayo Clinic Staff, 2021, LUPUS
   Merenda C, 2019, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2019.00-10
   Merenda C, 2019, IEEE INT VEH SYM, P1679, DOI [10.1109/IVS.2019.8813863, 10.1109/ivs.2019.8813863]
   Messersmith Glenn, 2012, DISPLAY ADJUSTMENT
   Naji Rad S., 2022, MALAR RASH
   Noll C, 2017, JMIR MHEALTH UHEALTH, V5, DOI 10.2196/mhealth.7943
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Plass Jan L., 2009, Journal of Computing in Higher Education, V21, P31, DOI 10.1007/s12528-009-9011-x
   Qualtrics, 2020, Qualtrics
   Robinson MK, 1999, CONTACT DERMATITIS, V41, P65
   Snap Inc, 2021, LENS STUD
   Stokes-Parish Jessica, 2019, Adv Simul (Lond), V4, P16, DOI 10.1186/s41077-019-0103-z
   Stokes-Parish Jessica B, 2020, Adv Simul (Lond), V5, P23, DOI 10.1186/s41077-020-00142-0
   Stuart J, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.864676
   Sundar S.S., 2008, Digital media, youth, and credibility, P73, DOI 10.1162/dmal.9780262562324.073
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   Wanat KA, 2013, J AM ACAD DERMATOL, V69, P816, DOI 10.1016/j.jaad.2013.03.045
   Watts PI, 2021, CLIN SIMUL NURS, V58, P14, DOI 10.1016/j.ecns.2021.08.009
   Xu K, 2020, J COMPUT-MEDIAT COMM, V25, P32, DOI 10.1093/jcmc/zmz023
   Zorn Jennifer, 2018, J Physician Assist Educ, V29, P99, DOI 10.1097/JPA.0000000000000205
NR 43
TC 0
Z9 0
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 14
PY 2023
VL 4
AR 1127000
DI 10.3389/frvir.2023.1127000
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L5AW8
UT WOS:001023399600001
OA gold
DA 2024-07-18
ER

PT J
AU Grübel, J
AF Grubel, Jascha
TI The design, experiment, analyse, and reproduce principle for
   experimentation in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; digital twin; framework; reproducibility; experiments;
   experimentation
AB Conducting experiments in virtual reality (VR) requires a complex setup of hardware, software, experiment design and implementation, and data collection which is supported by frameworks that provide pre-determined features for scientists to implement their experiment in VR. These VR frameworks have proliferated exponentially since the start of the millennia, and unfortunately, they both only differ slightly from one another and often miss one or more of the key features required by the researcher. Therefore, it has become less clear to researchers which framework to choose for what task and to what benefit. I introduce the design, experiment, analyse, and reproduce (DEAR) principle to develop a new perspective on VR frameworks through a holistic approach to experimentation (i.e., the process of conducting an experiment). The DEAR principle lays out the core components that future frameworks should entail. Most previous VR frameworks have focussed on the design phase and sometimes on the experiment phase to help researchers create and conduct experiments. However, being able to create an experiment with a framework is not sufficient for wide adoption. Ultimately, I argue that it is important to take reproducibility seriously to overcome the limitations of current frameworks. Once experiments are fully reproducible through automation, the adaptation of new experiments becomes easier. Hopefully, researchers can find ways to converge in the use of frameworks or else frameworks may become a hindrance instead of a help.
C1 [Grubel, Jascha] Swiss Fed Inst Technol, Chair Cognit Sci, Dept Humanities Social & Polit Sci, Zurich, Switzerland.
   [Grubel, Jascha] Swiss Fed Inst Technol, Game Technol Ctr, Dept Comp Sci, Zurich, Switzerland.
   [Grubel, Jascha] Harvard Univ, Sch Engn & Appl Sci, Visual Comp Grp, Zurich, Switzerland.
   [Grubel, Jascha] Swiss Fed Inst Technol, Ctr Sustainable Future Mobil, Dept Civil Environm & Geomat Engn, Zurich, Switzerland.
   [Grubel, Jascha] Swiss Fed Inst Technol, Chair Geoinformat Engn, Dept Civil Environm & Geomat Engn, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; Swiss Federal
   Institutes of Technology Domain; ETH Zurich; Swiss Federal Institutes of
   Technology Domain; ETH Zurich; Swiss Federal Institutes of Technology
   Domain; ETH Zurich
RP Grübel, J (corresponding author), Swiss Fed Inst Technol, Chair Cognit Sci, Dept Humanities Social & Polit Sci, Zurich, Switzerland.; Grübel, J (corresponding author), Swiss Fed Inst Technol, Game Technol Ctr, Dept Comp Sci, Zurich, Switzerland.; Grübel, J (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Visual Comp Grp, Zurich, Switzerland.; Grübel, J (corresponding author), Swiss Fed Inst Technol, Ctr Sustainable Future Mobil, Dept Civil Environm & Geomat Engn, Zurich, Switzerland.; Grübel, J (corresponding author), Swiss Fed Inst Technol, Chair Geoinformat Engn, Dept Civil Environm & Geomat Engn, Zurich, Switzerland.
EM jgruebel@ethz.ch
RI Grübel, Jascha/AAX-4975-2020
OI Grübel, Jascha/0000-0002-6428-4685
FU ETH Zurich [ETH-15 16-2]; JG was supported by an ETH Zurich Doc.Mobility
   Fellowship
FX This research was funded by ETH Zurich (grant number ETH-15 16-2), and
   JG was supported by an ETH Zurich Doc.Mobility Fellowship. Open access
   funding was provided by ETH Zurich.
CR Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716
   Aguilar L., EXPT CODE CONCEPT RE, DOI [10.48550/ARXIV.2202.12050, DOI 10.48550/ARXIV.2202.12050]
   Allen B., 2001, P IEEE
   Almaatouq A, 2020, Arxiv, DOI arXiv:2006.11398
   Alsbury-Nealy K. etal, 2020, Openmaze: An open-source toolbox for creating virtual environment experiments
   Annett M., 2009, P IEEE VR 2009 WORKS, P131
   [Anonymous], 1968, P DEC 9 11 1968 FALL
   Ayaz H, 2008, BEHAV RES METHODS, V40, P353, DOI 10.3758/BRM.40.1.353
   Bebko AO, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520938400
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Burgelman JC, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00043
   Camerer CF, 2018, NAT HUM BEHAV, V2, P637, DOI 10.1038/s41562-018-0399-z
   Cherrueau RA, 2018, IEEE CONF COMPUT, P336
   Colombo G., 2022, 4 INTERDISCIP NAVIG, V2022, P14, DOI [10.3929/ethz-b-000594027, DOI 10.3929/ETHZ-B-000594027]
   Colombo G., 2023, CHI 2023 STUD GAME C, V8, P1
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Dalton RC, 2003, ENVIRON BEHAV, V35, P107, DOI 10.1177/0013916502238867
   Evans DS., 2008, INVISIBLE ENGINES SO
   Gaggioli A., 2001, Towards CyberPsychology: Mind, Cognitions and Society in the Internet Age, P157
   Gonzales J., 2015, The promise of pre-registration in psychological research
   Gosselin RD, 2020, BIOESSAYS, V42, DOI 10.1002/bies.201900189
   Grieves M., 2017, TRANSDISCIPLINARY PE, P85, DOI [DOI 10.1007/978-3-319-38756-7_4, 10.1007/978-3-319-38756-7_4]
   Grubel J., 2023, HDB DIGITAL TWINS
   Grübel J, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14133095
   Grübel J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184682
   Grübel J, 2017, LECT NOTES ARTIF INT, V10523, P159, DOI 10.1007/978-3-319-68189-4_10
   Howie S, 2021, VIRTUAL REAL-LONDON, V25, P447, DOI 10.1007/s10055-020-00463-5
   Innocenti A, 2017, J BEHAV EXP ECON, V69, P71, DOI 10.1016/j.socec.2017.06.001
   Ioannidis JPA, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002264
   Marcus RW, 2019, J NEUROSCI METH, V326, DOI 10.1016/j.jneumeth.2019.108374
   Mossel Annette, 2012, International Journal of Virtual Reality, V11, P1
   Moulec G. L., 2017, P 23 ACM S VIRT REAL, V1
   Munafò MR, 2018, NATURE, V553, P399, DOI 10.1038/d41586-018-01023-3
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008
   Reardon S, 2016, NATURE, V530, P264, DOI 10.1038/nature.2016.19335
   Schinazi VR, 2013, HIPPOCAMPUS, V23, P515, DOI 10.1002/hipo.22111
   Schneider S., 2018, P 36 ECAADE C CUMINC, P10
   Schuetz I, 2023, BEHAV RES METHODS, V55, P570, DOI 10.3758/s13428-022-01831-6
   Stark PB, 2018, NATURE, V557, P613, DOI 10.1038/d41586-018-05256-0
   Starrett MJ, 2021, BEHAV RES METHODS, V53, P1046, DOI 10.3758/s13428-020-01481-6
   Tramberend H, 1999, P IEEE VIRT REAL ANN, P14, DOI 10.1109/VR.1999.756918
   Ugwitz P, 2021, BEHAV RES METHODS, V53, P1581, DOI 10.3758/s13428-020-01510-4
   Vandevoorde David, 2002, C++ Templates: The Complete Guide, Portable Documents
   Wang YF, 2020, SOFTWARE PRACT EXPER, V50, P1305, DOI 10.1002/spe.2814
   Weibel RP, 2018, JOVE-J VIS EXP, DOI 10.3791/58318
   Weisberg SM, 2023, J EXP PSYCHOL LEARN, V49, P575, DOI 10.1037/xlm0001146
   Whyte J., 2003, Electronic Journal of Information Technology in Construction, V8
   Zhao HT, 2018, JOVE-J VIS EXP, DOI 10.3791/58155
NR 48
TC 1
Z9 1
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 12
PY 2023
VL 4
AR 1069423
DI 10.3389/frvir.2023.1069423
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4UZ1
UT WOS:001023245400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Barreda-Angeles, M
   Hartmann, T
AF Barreda-Angeles, Miguel
   Hartmann, Tilo
TI Hooked on the metaverse? Exploring the prevalence of addiction to
   virtual reality applications
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE addiction; compulsive use; video games; social virtual reality; spatial
   presence; embodiment
ID GAMES; IDENTIFICATION; METAANALYSIS; PORNOGRAPHY; VALIDATION; ILLUSION;
   SCALE; FLOW
AB Similar to debates about other new media technologies in the past, with the popularization of virtual reality (VR) technologies, concerns are raised about their potential to breed media addiction. In response to these concerns, the aim of this research was to provide a first examination of the prevalence of addiction to VR application use. An online survey was conducted among frequent VR users (N = 754), and measures of the different components of addiction were obtained, as well as demographics, hours of weekly use, type of apps used, and feelings of spatial presence and embodiment during VR app use. The results indicate that between 2% and 20% of users reveal compulsive VR use, depending on the classification criteria used. These prevalence estimates are similar to those of other activities such as the use of (non-VR) video games or the use of social networking sites. Therefore, the results suggest that VR applications do not have a higher addictive potential than other more traditional technologies. However, feelings of embodiment when using VR positively predict addiction. This may suggest that future developments of VR technology could, perhaps, also increase its addictive potential compared to other technologies.
C1 [Barreda-Angeles, Miguel] Univ Amsterdam, Dept Commun Sci, Amsterdam, Netherlands.
   [Hartmann, Tilo] Vrije Univ Amsterdam, Dept Commun Sci, Amsterdam, Netherlands.
C3 University of Amsterdam; Vrije Universiteit Amsterdam
RP Barreda-Angeles, M (corresponding author), Univ Amsterdam, Dept Commun Sci, Amsterdam, Netherlands.
EM m.barredaangeles@uva.nl
RI Hartmann, Tilo/B-7084-2011
OI Hartmann, Tilo/0000-0002-1862-7595
CR Acena D, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451673
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Ball M., 2022, METAVERSE IT WILL RE
   Bandalos DL, 2014, STRUCT EQU MODELING, V21, P102, DOI 10.1080/10705511.2014.859510
   Barreda-Angeles M, 2021, COMMUN MONOGR, V88, P154, DOI 10.1080/03637751.2020.1803496
   Barreda-Angeles M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107047
   Barreda-Angeles M, 2020, CYBERPSYCH BEH SOC N, V23, P683, DOI 10.1089/cyber.2019.0665
   Carlisle K, 2021, PSYCHOL REP, V124, P2613, DOI 10.1177/0033294120965476
   Charlton JP, 2007, COMPUT HUM BEHAV, V23, P1531, DOI 10.1016/j.chb.2005.07.002
   Chen HN, 2010, COMMUN STAT-SIMUL C, V39, P860, DOI 10.1080/03610911003650383
   Cheng C, 2021, ADDICT BEHAV, V117, DOI 10.1016/j.addbeh.2021.106845
   Chou TJ, 2003, CYBERPSYCHOL BEHAV, V6, P663, DOI 10.1089/109493103322725469
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Elsey JWB, 2019, COMPUT HUM BEHAV, V97, P35, DOI 10.1016/j.chb.2019.02.031
   Freeman G, 2021, PROCEEDINGS OF THE 2021 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2021, P84, DOI 10.1145/3452918.3458805
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Griffiths M., 2005, Journal of Substance use, V10, P191, DOI DOI 10.1080/14659890500114359
   Griffiths MD, 2016, ADDICT BEHAV, V53, P193, DOI 10.1016/j.addbeh.2015.11.001
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Huddleston T., 2022, THIS IS CREATING MOR
   Hull DC, 2013, J BEHAV ADDICT, V2, P145, DOI 10.1556/JBA.2.2013.005
   Hussain Z, 2012, ADDICT RES THEORY, V20, P359, DOI 10.3109/16066359.2011.640442
   Ialongo C, 2016, BIOCHEM MEDICA, V26, P150, DOI 10.11613/BM.2016.015
   Jourabloo A., 2022, P IEEE CVF C COMP VI, P20323
   Kaimara P, 2022, VIRTUAL REAL-LONDON, V26, P697, DOI 10.1007/s10055-021-00563-w
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim HS, 2022, ADDICT BEHAV, V126, DOI 10.1016/j.addbeh.2021.107183
   King D, 2010, INT J MENT HEALTH AD, V8, P90, DOI 10.1007/s11469-009-9206-4
   King DL, 2020, CLIN PSYCHOL REV, V77, DOI 10.1016/j.cpr.2020.101831
   Kuss DJ, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14030311
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lee ZWY, 2021, INFORM SYST J, V31, P33, DOI 10.1111/isj.12292
   Lemmens JS, 2022, VIRTUAL REAL-LONDON, V26, P223, DOI 10.1007/s10055-021-00555-w
   Lemmens JS, 2009, MEDIA PSYCHOL, V12, P77, DOI 10.1080/15213260802669458
   Love T, 2015, BEHAV SCI-BASEL, V5, P388, DOI 10.3390/bs5030388
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Mancini T, 2019, COMPUT HUM BEHAV, V92, P297, DOI 10.1016/j.chb.2018.11.007
   Merkx C, 2021, TOURISM MANAGE, V87, DOI 10.1016/j.tourman.2021.104394
   Nakamura J., 2002, Handbook of Positive Psychology, DOI DOI 10.1007/978-94-017-9088-8_16
   Noone G., 2022, TECH MONITOR, V24
   Oh J, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202007772
   Orben A, 2020, PERSPECT PSYCHOL SCI, V15, P1143, DOI 10.1177/1745691620919372
   Pan YC, 2020, NEUROSCI BIOBEHAV R, V118, P612, DOI 10.1016/j.neubiorev.2020.08.013
   Park S, 2009, LECT NOTES COMPUT SC, V5613, P378, DOI 10.1007/978-3-642-02583-9_42
   Rehbein F, 2021, CURR ADDICT REP, V8, P263, DOI 10.1007/s40429-021-00367-7
   Rho MJ, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15010040
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rosseel Y, 2012, J STAT SOFTW, V48, P1, DOI 10.18637/jss.v048.i02
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stavropoulos V, 2019, INT J MENT HEALTH AD, V17, P880, DOI 10.1007/s11469-018-9891-y
   Sternlicht L., 2022, Family addictionJanuary 2
   Stevens MWR, 2021, AUST NZ J PSYCHIAT, V55, P553, DOI 10.1177/0004867420962851
   Van Looy J, 2012, MEDIA PSYCHOL, V15, P197, DOI 10.1080/15213269.2012.674917
   World Health Organization, 2019, International statistical classification of diseases and related health problems, V11th
   Yee N, 2006, CYBERPSYCHOL BEHAV, V9, P772, DOI 10.1089/cpb.2006.9.772
NR 62
TC 6
Z9 6
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 10
PY 2022
VL 3
AR 1031697
DI 10.3389/frvir.2022.1031697
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VJ2
UT WOS:001023255500001
OA gold
DA 2024-07-18
ER

PT J
AU Begout, P
   Kubicki, S
   Bricard, E
   Duval, T
AF Begout, Pierre
   Kubicki, Sebastien
   Bricard, Emmanuel
   Duval, Thierry
TI Augmented Reality Authoring of Digital Twins: Design, Implementation and
   Evaluation in an Industry 4.0 Context
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE digital twin; augmented reality; gestural interaction; industry 4; 0; AR
   authoring
ID FRAMEWORK; FUTURE
AB This paper deals with Digital Twins (DTs) for Industry 4.0 factories, and their implementation in the context of a reconfigurable factory. This context implies a modification of the layout of the workstations during production, and thus requires a live update of the digital twins according to these modifications. We needed this update done by the operators directly on the workstations using an AR authoring tool. A literature review helped us to determine the criteria that a tool should fulfill in order to achieve this goal. The most important criteria are that the tool should be suitable for use by operators not trained in AR, that the learning curve should be short, and that it should be usable in a reconfigurable factory context. We created a DT containing all the necessary factory data and 3D models of the workstation interaction zones of a real assembly line. We then developed a tool enabling operators to match the DTs with their physical twin (PT) in AR, as well as to update their position in case of a reconfiguration. The experimentation we carried out confirms our analysis and shows us that it is possible to deploy a DT in a factory quite simply if the positioning of the DTs is done by direct manipulation (the 3D objects are co-located with the operator's hand) with the help of an AR display device.
C1 [Begout, Pierre; Duval, Thierry] IMT Atlantique, Brest, France.
   [Begout, Pierre; Bricard, Emmanuel] Elm Leblanc, Drancy, France.
   [Begout, Pierre; Kubicki, Sebastien; Duval, Thierry] CNRS, UMR, Lab STICC, Lorient, France.
   [Kubicki, Sebastien] ENIB, Brest, France.
C3 IMT - Institut Mines-Telecom; IMT Atlantique; Centre National de la
   Recherche Scientifique (CNRS); Ecole Nationale d'Ingenieurs de Brest
   (ENIB)
RP Begout, P (corresponding author), IMT Atlantique, Brest, France.; Begout, P (corresponding author), Elm Leblanc, Drancy, France.; Begout, P (corresponding author), CNRS, UMR, Lab STICC, Lorient, France.
EM pierre.begout@imt-atlantique.fr
CR Bégout P, 2020, LECT NOTES COMPUT SC, V12243, P304, DOI 10.1007/978-3-030-58468-9_22
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Erkoyuncu JA, 2017, CIRP ANN-MANUF TECHN, V66, P465, DOI 10.1016/j.cirp.2017.04.006
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Frigo Mauricio A., 2016, Journal of Industrial and Intelligent Information, V4, P125, DOI 10.18178/jiii.4.2.125-130
   Funk M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P934, DOI 10.1145/2971648.2971706
   Gimeno J, 2013, COMPUT IND, V64, P1263, DOI 10.1016/j.compind.2013.06.012
   Grieves M., 2014, White paper
   Grieves M., 2017, TRANSDISCIPLINARY PE, P85, DOI [DOI 10.1007/978-3-319-38756-7_4, 10.1007/978-3-319-38756-7_4]
   Guitard L., 2020, IFIP ADV INF COMMUN, V594, P139, DOI [10.1007/978-3-030-62807-9_12, DOI 10.1007/978-3-030-62807-9_12]
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Havard V, 2021, VIRTUAL REAL-LONDON, V25, P999, DOI 10.1007/s10055-020-00493-z
   Havard V, 2019, PROD MANUF RES, V7, P472, DOI 10.1080/21693277.2019.1660283
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Jones D, 2020, CIRP J MANUF SCI TEC, V29, P36, DOI 10.1016/j.cirpj.2020.02.002
   Ke SQ, 2019, PROC CIRP, V83, P753, DOI 10.1016/j.procir.2019.04.103
   Kostic Zona., 2012, INT J COMPUTER SCI I, V9, P181
   Ledermann F, 2005, P IEEE VIRT REAL ANN, P187
   Leng JW, 2021, J MANUF SYST, V60, P119, DOI 10.1016/j.jmsy.2021.05.011
   Leng JW, 2021, J CLEAN PROD, V306, DOI 10.1016/j.jclepro.2021.127278
   Leng JW, 2020, ROBOT CIM-INT MANUF, V63, DOI 10.1016/j.rcim.2019.101895
   Leng JW, 2020, IEEE T SYST MAN CY-S, V50, P182, DOI 10.1109/TSMC.2019.2930418
   Leng JW, 2021, INT J COMPUT INTEG M, V34, P783, DOI 10.1080/0951192X.2019.1667032
   Leng JW, 2019, J AMB INTEL HUM COMP, V10, P1155, DOI 10.1007/s12652-018-0881-5
   Liu Q, 2019, INT J PROD RES, V57, P3903, DOI 10.1080/00207543.2018.1471243
   Lyonnet B., 2016, INT J COMPUT THEORY, V8, DOI [10.13140/2.1.2911.2642, DOI 10.13140/2.1.2911.2642]
   Noel F., 2020, IFIP ADV INF COMMUN, V594, P128, DOI [10.1007/978-3-030-62807-9_11, DOI 10.1007/978-3-030-62807-9_11]
   Paelke V, 2014, 2014 IEEE EMERGING TECHNOLOGY AND FACTORY AUTOMATION (ETFA)
   Rabah S, 2018, PROCEDIA MANUF, V17, P460, DOI 10.1016/j.promfg.2018.10.070
   Revetria R, 2019, 2019 SPRING SIMULATION CONFERENCE (SPRINGSIM), DOI 10.23919/springsim.2019.8732917
   Riexinger G, 2018, PROC CIRP, V72, P1124, DOI 10.1016/j.procir.2018.03.160
   Rosen R, 2015, IFAC PAPERSONLINE, V48, P567, DOI 10.1016/j.ifacol.2015.06.141
   Schroeder G, 2016, IEEE INTL CONF IND I, P522, DOI 10.1109/INDIN.2016.7819217
   Shao GD, 2020, MANUF LETT, V24, P105, DOI 10.1016/j.mfglet.2020.04.004
   Tao F, 2019, IEEE T IND INFORM, V15, P2405, DOI 10.1109/TII.2018.2873186
   Villanueva A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376146
   Yang J, 2022, MACHINES, V10, DOI 10.3390/machines10020075
   Zhang CY, 2019, PROC CIRP, V83, P118, DOI 10.1016/j.procir.2019.03.141
   Zhu J, 2013, INT J ADV MANUF TECH, V66, P1699, DOI 10.1007/s00170-012-4451-2
   Zhu ZX, 2019, PROC CIRP, V81, P898, DOI 10.1016/j.procir.2019.03.223
NR 41
TC 3
Z9 3
U1 4
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 30
PY 2022
VL 3
AR 918685
DI 10.3389/frvir.2022.918685
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YI0
UT WOS:001019234200001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Latoschik, ME
   Wienrich, C
AF Latoschik, Marc Erich
   Wienrich, Carolin
TI Congruence and Plausibility, Not Presence: Pivotal Conditions for XR
   Experiences and Effects, a Novel Approach
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE XR; experience; presence; congruence; plausibility; coherence; theory;
   prediction
AB Presence is often considered the most important quale describing the subjective feeling of being in a computer-generated and/or computer-mediated virtual environment. The identification and separation of orthogonal presence components, i.e., the place illusion and the plausibility illusion, has been an accepted theoretical model describing Virtual Reality (VR) experiences for some time. This perspective article challenges this presence-oriented VR theory. First, we argue that a place illusion cannot be the major construct to describe the much wider scope of virtual, augmented, and mixed reality (VR, AR, MR: or XR for short). Second, we argue that there is no plausibility illusion but merely plausibility, and we derive the place illusion caused by the congruent and plausible generation of spatial cues and similarly for all the current model's so-defined illusions. Finally, we propose congruence and plausibility to become the central essential conditions in a novel theoretical model describing XR experiences and effects.
C1 [Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
   [Wienrich, Carolin] Univ Wurzburg, Human Technol Syst Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Latoschik, ME (corresponding author), Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
EM marc.latoschik@uni.wuerzburg.de
FU German Ministry of Science and Education (BMBF) [16SV8219, 16SV8781]; EU
   [824128]; Open-Access Publication Fund of the University of Wurzburg
FX This publication was supported by the Open-Access Publication Fund of
   the University of Wurzburg, by the XR Hub Bavaria, the German Ministry
   of Science and Education (BMBF) in the projects ViTraS (Grant 16SV8219)
   and HiAvA (Grant 16SV8781), and the EU in the project VIRTUALTIMES
   (Grant 824128).
CR CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Jerome L. W., 2007, Psychological Services, V4, P75, DOI [https://doi.org/10.1037/1541-1559.4.2.75, DOI 10.1037/1541-1559.4.2.75]
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Lombard Matthew., 2015, Immersed in media: Telepresence theory, measurement & technology
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Minsky M., 1980, OMNI, V2, P45, DOI DOI 10.1145/566654.566630
   Schubert T., 2002, PRESENCE 2002 P 5 IN, P53
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wienrich Carolin, 2020, i-com: Journal of Interactive Media, V19, P103, DOI 10.1515/icom-2020-0008
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 19
TC 20
Z9 20
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 16
PY 2022
VL 3
AR 694433
DI 10.3389/frvir.2022.694433
PG 6
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PQ9
UT WOS:001021734400001
OA Green Submitted, gold, Green Published
DA 2024-07-18
ER

PT J
AU Pouke, M
   Center, EG
   Chambers, AP
   Pouke, S
   Ojala, T
   Lavalle, SM
AF Pouke, Matti
   Center, Evan G.
   Chambers, Alexis P.
   Pouke, Sakaria
   Ojala, Timo
   Lavalle, Steven M.
TI The Body Scaling Effect and Its Impact on Physics Plausibility
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; perception; scaling; embodiment; human factors;
   plausibility
ID ILLUSORY OWNERSHIP; PERCEPTION
AB In this study we investigated the effect of body ownership illusion-based body scaling on physics plausibility in Virtual Reality (VR). Our interest was in examining whether body ownership illusion-based body scaling could affect the plausibility of rigid body dynamics similarly to altering VR users' scale by manipulating their virtual interpupillary distance and viewpoint height. The procedure involved the conceptual replication of two previous studies. We investigated physics plausibility with 40 participants under two conditions. In our synchronous condition, we used visuo-tactile stimuli to elicit a body ownership illusion of inhabiting an invisible doll-sized body on participants reclining on an exam table. Our asynchronous condition was otherwise similar, but the visuo-tactile stimuli were provided asynchronously to prevent the onset of the body ownership illusion. We were interested in whether the correct approximation of physics (true physics) or physics that are incorrect and appearing as if the environment is five times larger instead (movie physics) appear more realistic to participants as a function of body scale. We found that movie physics did appear more realistic to participants under the body ownership illusion condition. However, our hypothesis that true physics would appear more realistic in the asynchronous condition was unsupported. Our exploratory analyses revealed that movie physics were perceived as plausible under both conditions. Moreover, we were not able to replicate previous findings from literature concerning object size estimations while inhabiting a small invisible body. However, we found a significant opposite effect regarding size estimations; the object sizes were on average underestimated during the synchronous visuo-tactile condition when compared to the asynchronous condition. We discuss these unexpected findings and the potential reasons for the results, and suggest avenues for future research.
C1 [Pouke, Matti; Center, Evan G.; Chambers, Alexis P.; Pouke, Sakaria; Ojala, Timo; Lavalle, Steven M.] Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Ubiquitous Comp, Oulu, Finland.
C3 University of Oulu
RP Pouke, M (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Ubiquitous Comp, Oulu, Finland.
EM matti.pouke@oulu.fi
OI Center, Evan/0009-0008-4541-713X
CR Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bhalla M, 1999, J EXP PSYCHOL HUMAN, V25, P1076, DOI 10.1037/0096-1523.25.4.1076
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Cross R, 2004, AM J PHYS, V72, P305, DOI 10.1119/1.1634964
   Deng Z, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/3264342
   Hutchison JJ, 2006, SPAN J PSYCHOL, V9, P332, DOI 10.1017/S1138741600006235
   Jeffreys H., 1998, The theory of probability
   Jörges B, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00203
   Kim J., 2017, P 27 INT C ARTIFICIA, P153, DOI DOI 10.5555/3298830.32988592
   Langbehn E, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P211, DOI 10.1109/3DUI.2016.7460054
   Lee MD., 2014, Bayesian cognitive modeling: A practical course, DOI DOI 10.1017/CBO9781139087759
   Linkenauger SA, 2010, PSYCHOL SCI, V21, P1318, DOI 10.1177/0956797610380700
   Makowski D., 2019, J OPEN SOURCE SOFTW, V4, P1541, DOI DOI 10.21105/JOSS.01541
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   McIntyre J, 2001, NAT NEUROSCI, V4, P693, DOI 10.1038/89477
   Millet G, 2008, LECT NOTES COMPUT SC, V5024, P847, DOI 10.1007/978-3-540-69057-3_107
   Morey Richard D, 2024, CRAN
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Ogawa N., 2017, P 8 AUGM HUM INT C, DOI [DOI 10.1145/3041164.3041204, 10.1145/3041164.3041204]
   Pouke M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.655744
   Pouke M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P913, DOI [10.1109/VR46266.2020.00116, 10.1109/VR46266.2020.1580974317169]
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Senot P, 2005, J NEUROPHYSIOL, V94, P4471, DOI 10.1152/jn.00527.2005
   Serino S, 2020, COGN PROCESS, V21, P509, DOI 10.1007/s10339-020-00977-5
   Sitti M, 2007, IEEE ROBOT AUTOM MAG, V14, P53, DOI 10.1109/MRA.2007.339606
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van der Hoort B, 2016, SCI REP-UK, V6, DOI 10.1038/srep34530
   van der Hoort B, 2014, ATTEN PERCEPT PSYCHO, V76, P1414, DOI 10.3758/s13414-014-0664-9
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   van Doorn J, 2020, J APPL STAT, V47, P2984, DOI 10.1080/02664763.2019.1709053
   Wagenmakers E.J., 2017, PSYCHOL SCI SCRUTINY, DOI [10.1002/9781119095910.ch8, DOI 10.1002/9781119095910.CH8]
   Weber S, 2020, VIRTUAL REAL-LONDON, V24, P385, DOI 10.1007/s10055-019-00402-z
   Zhou Q, 2000, PROC SPIE, V4194, P56, DOI 10.1117/12.403703
NR 39
TC 2
Z9 2
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 26
PY 2022
VL 3
AR 869603
DI 10.3389/frvir.2022.869603
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AZ9
UT WOS:001019304800001
OA gold, Green Published, Green Accepted
DA 2024-07-18
ER

PT J
AU Ong, T
   Wilczewski, H
   Soni, H
   Nisbet, Q
   Paige, SR
   Barrera, JF
   Welch, BM
   Bunnell, BE
AF Ong, Triton
   Wilczewski, Hattie
   Soni, Hiral
   Nisbet, Quinn
   Paige, Samantha R.
   Barrera, Janelle F.
   Welch, Brandon M.
   Bunnell, Brian E.
TI The Symbiosis of Virtual Reality Exposure Therapy and Telemental Health:
   A Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; exposure therapy; VRET; telemedicine; telehealth;
   phobia; anxiety; mental health
ID SOCIAL ANXIETY DISORDER; MENTAL-HEALTH; COVID-19; IMPACT; PHOBIA; FEAR;
   TECHNOLOGY; INTERVENTIONS; METAANALYSIS; PSYCHOTHERAPY
AB Phobias and related anxiety are common and costly mental health disorders. Experts anticipate the prevalence of phobias will increase due to the COVID-19 pandemic. Exposure therapies have been established as effective and reliable treatments for anxiety, including recent innovations in virtual reality-based exposure therapy (VRET). With the recent advent of telemental health (TMH), VRET is poised to become mainstream. The combination of VRET and TMH has the potential to extend provider treatment options and improve patient care experiences. In this narrative review, we describe how recent events have accelerated VRET + TMH, identify barriers to VRET + TMH implementation, and discuss strategies to navigate those barriers.
C1 [Ong, Triton; Wilczewski, Hattie; Soni, Hiral; Nisbet, Quinn; Paige, Samantha R.; Barrera, Janelle F.; Welch, Brandon M.; Bunnell, Brian E.] Doxy Me Inc, Doxy Me Res, Rochester, NY 14623 USA.
   [Barrera, Janelle F.; Bunnell, Brian E.] Med Univ South Carolina, Biomed Informat Ctr, Publ Hlth & Sci, Charleston, SC USA.
   [Welch, Brandon M.] Univ S Florida, Dept Psychiat & Behav Neurosci, Innovat Mental Hlth Lab, Tampa, FL USA.
C3 Medical University of South Carolina; State University System of
   Florida; University of South Florida
RP Ong, T (corresponding author), Doxy Me Inc, Doxy Me Res, Rochester, NY 14623 USA.
EM triton.ong@doxy.me
RI Bunnell, Brian/IWM-3644-2023
OI Bunnell, Brian/0000-0002-4964-0688; Wilczewski,
   Hattie/0000-0002-3034-0087
FU National Institute of Mental Health [K23MH118482, R41MH126734]; National
   Cancer Institute [K07CA211786]
FX Funding BB was funded by the National Institute of Mental Health (Grant
   Numbers. K23MH118482 and R41MH126734) and BW was funded by the National
   Cancer Institute (Grant Number. K07CA211786).
CR Aboujaoude E, 2018, WORLD PSYCHIATRY, V17, P277, DOI 10.1002/wps.20551
   Adams SM, 2018, J AM PSYCHIAT NURSES, V24, P295, DOI 10.1177/1078390318763963
   Almathami HKY, 2020, J MED INTERNET RES, V22, DOI 10.2196/16407
   Anderson PL, 2020, CURR OPIN PSYCHOL, V36, P153, DOI 10.1016/j.copsyc.2020.10.001
   [Anonymous], 2020, LANCET INFECT DIS, V20, P875, DOI 10.1016/S1473-3099(20)30565-X
   Arjmand HA, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.635158
   Atske S., 2019, MOBILE TECHNOLOGY HO
   Baier AL, 2021, TRAIN EDUC PROF PSYC, V15, P259, DOI 10.1037/tep0000359
   Balan O., 2020, HCI INT 2020 LATE BR, P12
   BBC News, 2021, BBC NEWS
   Beard L, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1192
   Becker CB, 2004, BEHAV RES THER, V42, P277, DOI 10.1016/S0005-7967(03)00138-4
   Benbow AA, 2019, J ANXIETY DISORD, V61, P18, DOI 10.1016/j.janxdis.2018.06.006
   Berkowitz SA, 2021, JAMA INTERN MED, V181, P699, DOI 10.1001/jamainternmed.2020.7048
   Berman NC, 2021, J BEHAV THER EXP PSY, V70, DOI 10.1016/j.jbtep.2020.101615
   Best Paul, 2022, J Technol Behav Sci, V7, P100, DOI 10.1007/s41347-021-00214-6
   Birckhead B, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11973
   Boeldt D, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00773
   Bonsaksen T, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9070903
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Boulos MNK, 2007, HEALTH INFO LIBR J, V24, P233, DOI 10.1111/J.1471-1842.2007.00733.x
   Boydstun CD, 2021, TRANSL ISS PSYCH SCI, V7, P315, DOI 10.1037/tps0000282
   Bridgland VME, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0240146
   Brinkman WP, 2010, INTERACT COMPUT, V22, P299, DOI 10.1016/j.intcom.2010.03.005
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Brown M., 2021, REMOTE WORK ANXIETY
   Bunnell BE, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17228525
   Bush J, 2008, COMPUT HUM BEHAV, V24, P1032, DOI 10.1016/j.chb.2007.03.006
   Carlsen A., 2021, How Is The COVID-19 Vaccination Campaign Going
   Cavicchioli M, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9010101
   CDC, 2021, WHAT YOU NEED KNOW V
   Chan S, 2018, CURR PSYCHIAT REP, V20, DOI 10.1007/s11920-018-0954-3
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chartier MJ, 2003, SOC PSYCH PSYCH EPID, V38, P728, DOI 10.1007/s00127-003-0720-6
   Chatterjee SS, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102071
   Chesham RK, 2018, BEHAV CHANGE, V35, P152, DOI 10.1017/bec.2018.15
   Cowan KE, 2019, MAYO CLIN PROC, V94, P2510, DOI 10.1016/j.mayocp.2019.04.018
   Curcio C, 2020, STIGMA HEALTH, V5, P125, DOI 10.1037/sah0000183
   Danziger CR, 2021, EUR J PEDIATR, V180, P201, DOI 10.1007/s00431-020-03736-y
   Davidson J, 2005, SOC SCI MED, V61, P2155, DOI 10.1016/j.socscimed.2005.04.030
   de Oliveira-Souza R, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00590
   de Vries YA, 2021, J AFFECT DISORDERS, V288, P199, DOI 10.1016/j.jad.2021.04.001
   Deacon B.J., 2013, Handbook of Treating Variants and Complications of Anxiety Disorders, P363, DOI DOI 10.1007/978-1-4614-6458-7_23
   Demers M, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.601898
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Di Carlo F, 2021, INT J CLIN PRACT, V75, DOI 10.1111/ijcp.13716
   Donker T, 2019, JAMA PSYCHIAT, V76, P682, DOI 10.1001/jamapsychiatry.2019.0219
   Du J, 2020, GEN HOSP PSYCHIAT, V67, P144, DOI 10.1016/j.genhosppsych.2020.03.011
   Eshuis LV, 2021, J PSYCHIATR RES, V143, P516, DOI 10.1016/j.jpsychires.2020.11.030
   Fairburn CG, 2017, BEHAV RES THER, V88, P19, DOI 10.1016/j.brat.2016.08.012
   Fang XY, 2020, J AFFECT DISORDERS, V276, P441, DOI 10.1016/j.jad.2020.06.078
   Fehm L, 2008, SOC PSYCH PSYCH EPID, V43, P257, DOI 10.1007/s00127-007-0299-4
   Fernández-Alvarez J, 2019, J ANXIETY DISORD, V61, P3, DOI 10.1016/j.janxdis.2018.06.005
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Gajarawala SN, 2021, JNP-J NURSE PRACT, V17, P218, DOI 10.1016/j.nurpra.2020.09.013
   Gardner JS, 2020, CURR PSYCHIAT REP, V22, DOI 10.1007/s11920-020-1128-7
   Geraets CNW, 2021, CURR OPIN PSYCHOL, V41, P40, DOI 10.1016/j.copsyc.2021.02.004
   Ghosh R, 2020, MINERVA PEDIATR, V72, P226, DOI 10.23736/S0026-4946.20.05887-9
   Glass VQ, 2021, CONTEMP FAM THER, V43, P189, DOI 10.1007/s10591-021-09570-0
   Glueckauf RL, 2018, PROF PSYCHOL-RES PR, V49, P205, DOI 10.1037/pro0000188
   Goldkind L, 2021, FAM SOC, V102, P434, DOI 10.1177/1044389421997796
   Gorini A, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1029
   Gramlich MA, 2021, DEPRESS ANXIETY, V38, P626, DOI 10.1002/da.23141
   Greenwald W., 2021, PC MAGAZINE
   Gupta R, 2020, INDIAN J PSYCHIAT, V62, P370, DOI 10.4103/psychiatry.IndianJPsychiatry_523_20
   Hamilton I., 2021, NEARLY 20 FACEBOOKS
   Hartanto D, 2016, COMM COM INF SC, V604, P85, DOI 10.1007/978-3-319-32270-4_9
   Hatmaker T., 2021, WATCH LAWMAKERS GRIL
   Heaney D., 2021, QUEST PROFACE EYE TR
   HECKER JE, 1990, BEHAV PSYCHOTHER, V18, P21, DOI 10.1017/S0141347300017961
   Heiat M, 2021, ANN IG MED PREV COMU, V33, P360, DOI 10.7416/ai.2021.2446
   Heyse J., 2018, WORKSH 32 AAAI C ART
   Higgins A., 2020, WASHINGTON POST
   Hilty D.M., 2020, J TECHNOL BEHAV SCI, V5, P178, DOI [10.1007/s41347-020-00126-x, DOI 10.1007/S41347-020-00126-X]
   Hoffman JA, 2020, WORLD MED HEALTH POL, V12, P300, DOI 10.1002/wmh3.365
   Holmberg TT, 2020, CYBERPSYCH BEH SOC N, V23, P495, DOI 10.1089/cyber.2019.0295
   Horigome T, 2020, PSYCHOL MED, V50, P2487, DOI 10.1017/S0033291720003785
   Hurst L, 2019, J MED INTERNET RES, V21, DOI 10.2196/13117
   Ionescu Alina., 2021, J. technol. behave. sci, V6, P631, DOI DOI 10.1007/S41347-021-00221-7
   Jang DP, 2002, IEEE T INF TECHNOL B, V6, P213, DOI 10.1109/TITB.2002.802374
   Kaimara P, 2022, VIRTUAL REAL-LONDON, V26, P697, DOI 10.1007/s10055-021-00563-w
   Kampmann IL, 2016, BEHAV RES THER, V77, P147, DOI 10.1016/j.brat.2015.12.016
   Kelley B, 2021, 2021 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2021), P216, DOI 10.1109/ICICT52872.2021.00043
   Le K, 2021, INT REV APPL ECON, V35, P147, DOI 10.1080/02692171.2020.1853077
   Kim HHS, 2021, GERONTOLOGIST, V61, P103, DOI 10.1093/geront/gnaa168
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91573-w
   Knaak Stephanie, 2017, Healthc Manage Forum, V30, P111, DOI 10.1177/0840470416679413
   Konnopka A, 2020, PHARMACOECONOMICS, V38, P25, DOI 10.1007/s40273-019-00849-7
   Kornarakis I., 2017, VIRTUAL REALITY SERI
   Kothgassner OD, 2021, NEUROPSYCHIATRIE, V35, P68, DOI 10.1007/s40211-020-00349-7
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Kovler ML, 2021, CHILD ABUSE NEGLECT, V116, DOI 10.1016/j.chiabu.2020.104756
   Krohn S, 2020, J MED INTERNET RES, V22, DOI 10.2196/16724
   Krzystanek M, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.737351
   Labad J, 2021, PEERJ, V9, DOI 10.7717/peerj.10771
   Lehoux P, 2000, CAN J PUBLIC HEALTH, V91, P277, DOI 10.1007/BF03404289
   Lin WP, 2021, J APPL PSYCHOL, V106, P317, DOI 10.1037/apl0000896
   Lindinger-Sternart S, 2021, COUNS PSYCHOTHER RES, V21, P290, DOI 10.1002/capr.12387
   Lindner P, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00176
   Lindner P, 2019, J ANXIETY DISORD, V61, P45, DOI 10.1016/j.janxdis.2018.07.003
   Lindner P, 2017, COGN BEHAV THERAPY, V46, P404, DOI 10.1080/16506073.2017.1280843
   Liu C, 2021, STRESS HEALTH, V37, P887, DOI 10.1002/smi.3040
   Liu Q, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.573673
   Logan DE, 2021, J MED INTERNET RES, V23, DOI 10.2196/25916
   Lyons D, 2020, IRISH J PSYCHOL MED, V37, P295, DOI 10.1017/ipm.2020.40
   Maheu M.M., 2018, Journal of Technology in Behavioral Science, V3, P108, DOI DOI 10.1007/S41347-018-0046-6
   Maloney Divine, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P510, DOI 10.1145/3410404.3414266
   Mangiante S, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P30, DOI 10.1145/3097895.3097901
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Markowitz JC, 2015, AM J PSYCHIAT, V172, P430, DOI 10.1176/appi.ajp.2014.14070908
   Marloth M, 2020, CAMB Q HEALTHC ETHIC, V29, P574, DOI 10.1017/S0963180120000328
   Matamala-Gomez M, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.646902
   Matsangidou M, 2022, HUM-COMPUT INTERACT, V37, P314, DOI 10.1080/07370024.2020.1788945
   Matsuda N., 2021, REVERSE PASS THROUGH
   McGrath M., 2021, Climate change: IPCC report is 'code red for humanity'
   McKinley S., 2020, MICROSOFT AIRBAND AN
   McMurdock M., 2021, STUDENT SURVEY DEPRE
   Meyer JM, 2014, BEHAV RES THER, V54, P49, DOI 10.1016/j.brat.2014.01.004
   Mishkind MC, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0836-0
   Molfenter T, 2021, COMMUNITY MENT HLT J, V57, P1244, DOI 10.1007/s10597-021-00861-2
   Molloy D., 2021, BBC
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Mottelson A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.681482
   Nanou E., 2021, IS VIRTUAL REALITY R
   Nardi A. E., 2021, Personalized Medicine in Psychiatry, V25-26, DOI [10.1016/j.pmip.2021.100070, DOI 10.1016/J.PMIP.2021.100070]
   Nazeha N, 2020, J MED INTERNET RES, V22, DOI 10.2196/22706
   NIMH Specific Phobia, 2022, NAT I MENT HLTH
   North MM, 1997, PRESENCE-VIRTUAL AUG, V6, P127, DOI 10.1162/pres.1997.6.1.127
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Ortutay B., 2021, AP NEWS
   Pallavicini F, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/28150
   Paping C, 2010, NATO SCI PEACE SEC, V68, P203, DOI 10.3233/978-1-60750-571-6-203
   Park MJ, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00505
   Parker L, 2019, INT J LAW PSYCHIAT, V64, P198, DOI 10.1016/j.ijlp.2019.04.002
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Parsons TD, 2021, J CLIN MED, V10, DOI 10.3390/jcm10030378
   Patel P, 2020, GAMES HEALTH J, V9, P129, DOI 10.1089/g4h.2019.0052
   Pérez-Carbonell L, 2020, J THORAC DIS, V12, pS163, DOI 10.21037/jtd-cus-2020-015
   Persky S, 2020, J MED INTERNET RES, V22, DOI 10.2196/15582
   Pierce BS, 2021, AM PSYCHOL, V76, P14, DOI 10.1037/amp0000722
   Pimentel D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627059
   Pirkis J, 2021, LANCET PSYCHIAT, V8, P579, DOI 10.1016/S2215-0366(21)00091-2
   Pizzoli SFM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00479
   Ratcliffe J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445170
   Reeves R, 2022, BEHAV MODIF, V46, P937, DOI 10.1177/0145445521991102
   Rehm IC, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00186
   Reilly SE, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/21237
   Renn BN, 2021, J CLIN PSYCHIAT, V82, DOI 10.4088/JCP.21lr14037
   Riva G, 2004, ST HEAL T, V99, P255
   Riva G, 2020, CYBERPSYCH BEH SOC N, V23, P581, DOI 10.1089/cyber.2020.29194.gri
   Rizzo Albert Skip, 2018, Focus (Am Psychiatr Publ), V16, P266, DOI 10.1176/appi.focus.20180011
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Saad A, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/27404
   Saeed SA, 2021, CURR PSYCHIAT REP, V23, DOI 10.1007/s11920-021-01274-4
   Salkevicius J, 2019, INFORMATION, V10, DOI 10.3390/info10020062
   Salkevicius J, 2018, 2018 IEEE 6TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD WORKSHOPS (W-FICLOUD 2018), P209, DOI 10.1109/W-FiCloud.2018.00040
   Salokangas RKR, 2019, NORD J PSYCHIAT, V73, P125, DOI 10.1080/08039488.2018.1493748
   Sampaio M, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.576421
   Samuels J, 2021, J PSYCHIATR RES, V138, P155, DOI 10.1016/j.jpsychires.2021.03.064
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Shah K, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8821
   Shin B, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/30590
   Singh JA, 2020, J PHARM POLICY PRACT, V13, DOI 10.1186/s40545-020-00244-0
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Sorene P., 2014, J LANIERS EYEPHONE H
   Steidtmann D, 2021, TELEMED E-HEALTH, V27, P785, DOI 10.1089/tmj.2020.0305
   Stein S., 2021, HTCS NEW VR FACE TRA
   Steinman S. A., 2015, ENCY MENTAL HLTH, P186, DOI [10.1016/B978-0-12-397045-9.00266-4, DOI 10.1016/B978-0-12-397045-9.00266-4]
   Stupar-Rutenfrans S, 2017, CYBERPSYCH BEH SOC N, V20, P624, DOI 10.1089/cyber.2017.0174
   Supan J., 2021, NEW REPORT STATES US
   Sykownik P, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P546, DOI 10.1109/VR50410.2021.00079
   Tabbaa L, 2021, INT J HUM-COMPUT INT, V37, P851, DOI 10.1080/10447318.2020.1848161
   Tao GR, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-020-00801-3
   Taylor D. B., 2021, THE NEW YORK NEWS
   The Economist, 2021, THE ECONOMIST
   Tuena C, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00093
   Tuerk PW, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1092-2
   Uscher-Pines L, 2020, PSYCHIAT SERV, V71, P1143, DOI 10.1176/appi.ps.202000250
   Vinograd M., 2020, Exposure Therapy for Children with Anxiety and OCD, P3, DOI [10.1016/B978-0-12-815915-6.00001-9, DOI 10.1016/B978-0-12-815915-6.00001-9]
   Wardenaar KJ, 2017, PSYCHOL MED, V47, P1744, DOI [10.1017/S0033291717000174, 10.1017/s0033291717000174]
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Wersebe H, 2018, INT J CLIN HLTH PSYC, V18, P201, DOI 10.1016/j.ijchp.2018.06.004
   Whaibeh Emile, 2020, Curr Treat Options Psychiatry, V7, P198, DOI 10.1007/s40501-020-00210-2
   Wickens K., 2021, OCULUS QUEST 2 IS NO
   Wiederhold BK, 2019, CYBERPSYCH BEH SOC N, V22, P3, DOI 10.1089/cyber.2018.29136.bkw
   Willis DE, 2021, CTS-CLIN TRANSL SCI, V14, P2200, DOI 10.1111/cts.13077
   Wolitzky-Taylor KB, 2008, CLIN PSYCHOL REV, V28, P1021, DOI 10.1016/j.cpr.2008.02.007
   Wood DP, 2009, STUD HEALTH TECHNOL, V144, P223, DOI 10.3233/978-1-60750-017-9-223
   Wu TC, 2021, J AFFECT DISORDERS, V281, P91, DOI 10.1016/j.jad.2020.11.117
   Xiong JQ, 2020, J AFFECT DISORDERS, V277, P55, DOI 10.1016/j.jad.2020.08.001
   Yakobi M, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.16660
   Zhang T, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/18153
   Zhang WL, 2020, NEUROPSYCH DIS TREAT, V16, P2669, DOI 10.2147/NDT.S276203
NR 193
TC 3
Z9 3
U1 5
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 25
PY 2022
VL 3
AR 848066
DI 10.3389/frvir.2022.848066
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AT2
UT WOS:001019298000001
PM 37483657
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Olivier, N
   Kerbiriou, G
   Arguelaguet, F
   Avril, Q
   Danieau, F
   Guillotel, P
   Hoyet, L
   Multon, F
AF Olivier, Nicolas
   Kerbiriou, Glenn
   Arguelaguet, Ferran
   Avril, Quentin
   Danieau, Fabien
   Guillotel, Philippe
   Hoyet, Ludovic
   Multon, Franck
TI Study on Automatic 3D Facial Caricaturization: From Rules to Deep
   Learning
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE caricature; style transfer; machine learning; geometry processing; 3D
   mesh; perceptual study
ID PSYTOOLKIT
AB Facial caricature is the art of drawing faces in an exaggerated way to convey emotions such as humor or sarcasm. Automatic caricaturization has been explored both in the 2D and 3D domain. In this paper, we propose two novel approaches to automatically caricaturize input facial scans, filling gaps in the literature in terms of user-control, caricature style transfer, and exploring the use of deep learning for 3D mesh caricaturization. The first approach is a gradient-based differential deformation approach with data driven stylization. It is a combination of two deformation processes: facial curvature and proportions exaggeration. The second approach is a GAN for unpaired face-scan-to-3D-caricature translation. We leverage existing facial and caricature datasets, along with recent domain-to-domain translation methods and 3D convolutional operators, to learn to caricaturize 3D facial scans in an unsupervised way. To evaluate and compare these two novel approaches with the state of the art, we conducted the first user study of facial mesh caricaturization techniques, with 49 participants. It highlights the subjectivity of the caricature perception and the complementarity of the methods. Finally, we provide insights for automatically generating caricaturized 3D facial mesh.
C1 [Olivier, Nicolas; Kerbiriou, Glenn; Avril, Quentin; Danieau, Fabien; Guillotel, Philippe] InterDigital, Cesson Sevigne, France.
   [Olivier, Nicolas; Arguelaguet, Ferran; Hoyet, Ludovic; Multon, Franck] Univ Rennes, INRIA, CNRS, IRISA, Rennes, France.
   [Kerbiriou, Glenn] Inst Natl Sci Appl Rennes, Rennes, France.
   [Multon, Franck] Lab Mouvement Sport Sante, Bruz, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Rennes; Inria; Universite de Rennes
RP Olivier, N; Kerbiriou, G (corresponding author), InterDigital, Cesson Sevigne, France.; Olivier, N (corresponding author), Univ Rennes, INRIA, CNRS, IRISA, Rennes, France.; Kerbiriou, G (corresponding author), Inst Natl Sci Appl Rennes, Rennes, France.
EM Nicolas.Olivier@InterDigital.com; Glenn.Kerbiriou@InterDigital.com
RI Hoyet, Ludovic/IWU-9100-2023
OI Hoyet, Ludovic/0000-0002-7373-6049; Kerbiriou, Glenn/0000-0001-7782-4233
FU European Union [952?147]; Association Nationale de la Recherche et de la
   Technologie under CIFRE [2018/1656]
FX We wish to thank all the reviewers for their comments, and the
   participants in our experiment. This project has received funding from
   the European Union's Horizon 2020 research and innovation program under
   grant agreement No 952?147. This project has received funding from the
   Association Nationale de la Recherche et de la Technologie under CIFRE
   agreement No 2018/1656.
CR Akleman E., 1997, ACM SIGGRAPH, DOI DOI 10.1145/259081.259231
   Akleman E., 2004, ACM SIGGRAPH 2004 SK, DOI 10.1145/1186223.1186299
   [Anonymous], 2000, PROC VIS
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   BRENNAN SE, 1985, LEONARDO, V18, P170, DOI 10.2307/1578048
   Cai HR, 2021, GRAPH MODELS, V115, DOI 10.1016/j.gmod.2021.101103
   Cao K., 2019, ACM T GRAPHIC, V37, P1, DOI DOI 10.1145/3272127.3275046
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   Chen H., 2002, ACM MULTIMEDIA, DOI [10.1145/641007.641040, DOI 10.1145/641007.641040]
   Chen Y.-L., 2006, IEEE INT C SYST MAN, DOI [10.1109/icsmc.2006.384498, DOI 10.1109/ICSMC.2006.384498]
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Cimen G., 2012, COMPUTER INF SCI, P201, DOI [10.1007/978-1-4471-4594-3_21, DOI 10.1007/978-1-4471-4594-3_21]
   Clarke L, 2011, IEEE T VIS COMPUT GR, V17, P808, DOI 10.1109/TVCG.2010.76
   Danieau F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P784, DOI [10.1109/vr.2019.8798208, 10.1109/VR.2019.8798208]
   Eigensatz M, 2008, COMPUT GRAPH FORUM, V27, P241, DOI 10.1111/j.1467-8659.2008.01121.x
   Fujiwara T, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA137
   Gong SW, 2019, IEEE INT CONF COMP V, P4141, DOI 10.1109/ICCVW.2019.00509
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gu Z, 2022, IEEE T MULTIMEDIA, V24, P2673, DOI 10.1109/TMM.2021.3086722
   Guo YD, 2019, Arxiv, DOI arXiv:1906.00544
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huo J., 2018, BRIT MACHINE VISION
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Li PF, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P941, DOI 10.1109/ICME.2008.4607591
   Liang L, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P386, DOI 10.1109/PCCGA.2002.1167882
   Litany O, 2017, IEEE I CONF COMP VIS, P5660, DOI 10.1109/ICCV.2017.603
   Liu JF, 2009, COMPUT GRAPH FORUM, V28, P2104, DOI 10.1111/j.1467-8659.2009.01418.x
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu MY, 2017, ADV NEUR IN, V30
   Liu SK, 2013, VISUAL COMPUT, V29, P1135, DOI 10.1007/s00371-012-0756-2
   Maron H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073616
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Mo Z., 2004, ACM SIGGRAPH, DOI [10.1145/1186223.1186294, DOI 10.1145/1186223.1186294]
   Moschoglou S, 2020, INT J COMPUT VISION, V128, P2534, DOI 10.1007/s11263-020-01329-8
   Olivier N, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407930
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Redman L., 1984, DRAW CARICATURES
   Sela M, 2015, COMPUT VIS IMAGE UND, V141, P1, DOI 10.1016/j.cviu.2015.05.013
   Shi YC, 2019, PROC CVPR IEEE, P10754, DOI 10.1109/CVPR.2019.01102
   Sorkine O., 2005, Eurographics 2005-State of the Art Reports, V4, P53, DOI [10.2312/egst.20051044, DOI 10.2312/EGST.20051044]
   Stoet G, 2017, TEACH PSYCHOL, V44, P24, DOI 10.1177/0098628316677643
   Stoet G, 2010, BEHAV RES METHODS, V42, P1096, DOI 10.3758/BRM.42.4.1096
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Taigman Y., 2017, INT C LEARN REPR ICL, P1
   Wang C., 2021, IEEECVF C COMPUTER V
   Wu QY, 2018, PROC CVPR IEEE, P7336, DOI 10.1109/CVPR.2018.00766
   Xie J., 2009, Proceedings of the ACM International Conference on Multimedia, DOI 10.1145/1631272.1631403
   Ye ZP, 2021, Arxiv, DOI arXiv:2003.06841
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zell E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818126
   Zhou JY, 2016, VISUAL COMPUT, V32, P717, DOI 10.1007/s00371-016-1265-5
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 58
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 19
PY 2022
VL 2
AR 785104
DI 10.3389/frvir.2021.785104
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2UB4
UT WOS:001021849700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Huisman, T
   Ahrens, A
   MacDonald, E
AF Huisman, Thirsa
   Ahrens, Axel
   MacDonald, Ewen
TI Ambisonics Sound Source Localization With Varying Amount of Visual
   Information in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE sound localization; virtual reality; ambisonics; audiovisual; HMD
AB To reproduce realistic audio-visual scenarios in the laboratory, Ambisonics is often used to reproduce a sound field over loudspeakers and virtual reality (VR) glasses are used to present visual information. Both technologies have been shown to be suitable for research. However, the combination of both technologies, Ambisonics and VR glasses, might affect the spatial cues for auditory localization and thus, the localization percept. Here, we investigated how VR glasses affect the localization of virtual sound sources on the horizontal plane produced using either 1st-, 3rd-, 5th- or 11th-order Ambisonics with and without visual information. Results showed that with 1st-order Ambisonics the localization error is larger than with the higher orders, while the differences across the higher orders were small. The physical presence of the VR glasses without visual information increased the perceived lateralization of the auditory stimuli by on average about 2 & DEG;, especially in the right hemisphere. Presenting visual information about the environment and potential sound sources did reduce this HMD-induced shift, however it could not fully compensate for it. While the localization performance itself was affected by the Ambisonics order, there was no interaction between the Ambisonics order and the effect of the HMD. Thus, the presence of VR glasses can alter acoustic localization when using Ambisonics sound reproduction, but visual information can compensate for most of the effects. As such, most use cases for VR will be unaffected by these shifts in the perceived location of the auditory stimuli.
C1 [Huisman, Thirsa; Ahrens, Axel; MacDonald, Ewen] Tech Univ Denmark, Dept Hlth Technol, Hearing Syst Sect, Lyngby, Denmark.
   [Ahrens, Axel] Univ Southern Denmark, Inst Clin Res, Fac Hlth Sci, Odense, Denmark.
   [MacDonald, Ewen] Univ Waterloo, Syst Design Engn, Waterloo, ON, Canada.
C3 Technical University of Denmark; University of Southern Denmark;
   University of Waterloo
RP Huisman, T (corresponding author), Tech Univ Denmark, Dept Hlth Technol, Hearing Syst Sect, Lyngby, Denmark.
EM thuis@dtu.dk
OI Huisman, Thirsa/0000-0002-7650-5377; Ahrens, Axel/0000-0001-8800-2497
FU Centre for Applied Hearing research (CAHR) through a research consortium
   agreement with GN Resound, Oticon, and Widex
FX This research was supported by the Centre for Applied Hearing research
   (CAHR) through a research consortium agreement with GN Resound, Oticon,
   and Widex. The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the article.
CR Ahrens A, 2020, J ACOUST SOC AM, V147, P1368, DOI 10.1121/10.0000747
   Ahrens A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214603
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Bates E., 2007, Journal of the Acoustical Society of America, V121, P3069, DOI [10.1121/1.4781867, DOI 10.1121/1.4781867]
   Bertet S, 2013, ACTA ACUST UNITED AC, V99, P642, DOI 10.3813/AAA.918643
   Blauert J., 1997, SPATIAL HEARING PSYC
   Dufour A, 2002, VIS COGN, V9, P741, DOI 10.1080/13506280042000250
   Sanchez GME, 2017, LANDSCAPE URBAN PLAN, V167, P98, DOI 10.1016/j.landurbplan.2017.05.018
   Favrot S, 2010, ACTA ACUST UNITED AC, V96, P364, DOI 10.3813/AAA.918285
   Frank M., 2008, 25 TONM VDT INT CONV
   Freeman LCA, 2018, J ACOUST SOC AM, V143, pEL516, DOI 10.1121/1.5042759
   Genovese A., 2018, P AES INT C 2018 RED
   GERZON MA, 1973, J AUDIO ENG SOC, V21, P2
   Godfroy M, 2003, PERCEPTION, V32, P1233, DOI 10.1068/p3344
   Gori M, 2014, BRAIN, V137, P288, DOI 10.1093/brain/awt311
   Gupta R., 2018, P AES INT C 2018, P130
   Hartmann WH, 1999, PHYS TODAY, V52, P24, DOI 10.1063/1.882727
   HENDRIX C, 1995, VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM '95, PROCEEDINGS, P74
   Hruby F., 2019, KN - Journal of Cartography and Geographic Information, V69, P19, DOI DOI 10.1007/S42489-019-00003-5
   Huisman T., 2021, PSYARXIV, V26, DOI [10.31234/osf.io/5sef6, DOI 10.31234/OSF.IO/5SEF6]
   Jackson C.V., 1953, Q J EXP PSYCHOL, V5, P52, DOI [DOI 10.1080/17470215308416626, 10.1080/17470215308416626]
   Kern AC, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00020
   Kessling P., 2018, 145 AUD ENG SOC INT
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Larsson Pontus., 2007, Proceedings of the 10th Annual International Workshop on Presence, P11
   Lewald J, 2003, COGNITIVE BRAIN RES, V16, P468, DOI 10.1016/S0926-6410(03)00074-0
   MAKOUS JC, 1990, J ACOUST SOC AM, V87, P2188, DOI 10.1121/1.399186
   MUSICANT AD, 1984, J ACOUST SOC AM, V75, P1195, DOI 10.1121/1.390770
   Nordahl R., 2005, 8 ANN INT WORKSH PRE, P353
   Ocklenburg S, 2010, BRAIN COGNITION, V72, P210, DOI 10.1016/j.bandc.2009.08.013
   Odegaard B, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004649
   Oreinos C, 2015, J ACOUST SOC AM, V137, P3447, DOI 10.1121/1.4919330
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Pulkki V, 2005, IEEE T SPEECH AUDI P, V13, P105, DOI 10.1109/TSA.2004.838533
   Riecke BE, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498701
   Sampedro Llopis H., 2019, P 23 INT C AC, P747, DOI [10.18154/RWTH-CONV-239043, DOI 10.18154/RWTH-CONV-239043]
   Schwind V, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P477, DOI 10.1145/3242671.3242675
   Stenzel H., 2017, 142 AUD ENG SOC INT
   Stitt P., 2013, DAFX 2013 16 INT C D
   Stitt P, 2014, ACTA ACUST UNITED AC, V100, P937, DOI 10.3813/AAA.918773
   Suárez AS, 2019, 2019 AES INTERNATIONAL CONFERENCE ON IMMERSIVE AND INTERACTIVE AUDIO
   Tabry V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00932
   Thresh L., 2017, 143 AUDIO ENG SOC CO, V1, P489
   THURLOW WR, 1973, PERCEPT MOTOR SKILL, V36, P1171, DOI 10.2466/pms.1973.36.3c.1171
NR 44
TC 4
Z9 4
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 14
PY 2021
VL 2
AR 722321
DI 10.3389/frvir.2021.722321
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TV0
UT WOS:001021843300001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Itaguchi, Y
AF Itaguchi, Yoshihiro
TI Size Perception Bias and Reach-to-Grasp Kinematics: An Exploratory Study
   on the Virtual Hand With a Consumer Immersive Virtual-Reality Device
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE hand size perception; size estimation; reach-to-grasp movements; virtual
   reality; visuo-proprioceptive congruency
ID DISTANCE PARADOX; MOVEMENTS; QUALITY; SPACE; PAIN
AB While studies have increasingly used virtual hands and objects in virtual environments to investigate various processes of psychological phenomena, conflicting findings have been reported even at the most basic level of perception and action. To reconcile this situation, the present study aimed 1) to assess biases in size perception of a virtual hand using a strict psychophysical method and 2) to provide firm and conclusive evidence of the kinematic characteristics of reach-to-grasp movements with various virtual effectors (whole hand or fingertips only, with or without tactile feedback of a target object). Experiments were conducted using a consumer immersive virtual reality device. In a size judgment task, participants judged whether a presented virtual hand or an everyday object was larger than the remembered size. The results showed the same amplitude of underestimation (approximately 5%) for the virtual hand and the object, and no influence of object location, visuo-proprioceptive congruency, or short-term experience of controlling the virtual hand. Furthermore, there was a moderate positive correlation between actual hand size and perception bias. Analyses of reach-to-grasp movements revealed longer movement times and larger maximum grip aperture (MGA) for a virtual, as opposed to a physical, environment, but the MGA did not change when grasping was performed without tactile feedback. The MGA appeared earlier in the time course of grasping movements in all virtual reality conditions, regardless of the type of virtual effector. These findings confirm and corroborate previous evidence and may contribute to the field of virtual hand interfaces for interactions with virtual worlds.
C1 [Itaguchi, Yoshihiro] Keio Univ, Dept Psychol, Tokyo, Japan.
   [Itaguchi, Yoshihiro] Shizuoka Univ, Dept Comp Sci, Hamamatsu, Japan.
C3 Keio University; Shizuoka University
RP Itaguchi, Y (corresponding author), Keio Univ, Dept Psychol, Tokyo, Japan.; Itaguchi, Y (corresponding author), Shizuoka Univ, Dept Comp Sci, Hamamatsu, Japan.
EM itaguchi.y@gmail.com
FU Grants-in-Aid for Scientific Research [20H01785] Funding Source: KAKEN
CR Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237
   Bhargava A, 2022, IEEE T VIS COMPUT GR, V28, P4198, DOI 10.1109/TVCG.2021.3083423
   Bingham G, 2007, NEUROPSYCHOLOGIA, V45, P288, DOI 10.1016/j.neuropsychologia.2006.07.011
   Bongers RM, 2012, HUM MOVEMENT SCI, V31, P487, DOI 10.1016/j.humov.2011.07.014
   Bongers RM, 2010, LECT NOTES COMPUT SC, V6192, P271, DOI 10.1007/978-3-642-14075-4_39
   Bozzacchi C, 2015, J NEUROPHYSIOL, V114, P2242, DOI 10.1152/jn.00350.2015
   Cardinali L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49500-7
   Creem-Regehr SH, 2015, PSYCHOL LEARN MOTIV, V62, P195, DOI 10.1016/bs.plm.2014.09.006
   de Siqueira AG, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P606, DOI 10.1109/VR50410.2021.00086
   de Vignemont F, 2005, CURR BIOL, V15, P1286, DOI 10.1016/j.cub.2005.06.067
   Fossataro C, 2020, NEUROPSYCHOLOGIA, V146, DOI 10.1016/j.neuropsychologia.2020.107540
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Furmanek MP, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0525-9
   Gamberini L, 2008, NEUROPSYCHOLOGIA, V46, P1298, DOI 10.1016/j.neuropsychologia.2007.12.016
   Gandevia SC, 1999, J PHYSIOL-LONDON, V514, P609, DOI 10.1111/j.1469-7793.1999.609ae.x
   Gentilucci M, 2004, EXP BRAIN RES, V157, P496, DOI 10.1007/s00221-004-1863-8
   Gescheider G. A., 2013, Psychophysics: the fundamentals
   Hornsey RL, 2020, BEHAV RES METHODS, V52, P1587, DOI 10.3758/s13428-019-01336-9
   Itaguchi Y, 2020, J NEUROPHYSIOL, V123, P2024, DOI 10.1152/jn.00384.2019
   Itaguchi Y, 2014, EXP BRAIN RES, V232, P3613, DOI 10.1007/s00221-014-4053-3
   JAKOBSON LS, 1991, EXP BRAIN RES, V86, P199
   Jung S, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P60, DOI 10.1145/3267782.3267920
   Keizer A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163921
   Kuhlen T, 2000, PRESENCE-TELEOP VIRT, V9, P350, DOI 10.1162/105474600566853
   LEIBOWITZ H, 1966, J OPT SOC AM, V56, P1120, DOI 10.1364/JOSA.56.001120
   Levin MF, 2015, IEEE T NEUR SYS REH, V23, P1047, DOI 10.1109/TNSRE.2014.2387412
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   Linkenauger SA, 2015, NEUROPSYCHOLOGIA, V70, P393, DOI 10.1016/j.neuropsychologia.2014.10.034
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Magdalon EC, 2011, ACTA PSYCHOL, V138, P126, DOI 10.1016/j.actpsy.2011.05.015
   Marks L.E., 1998, Measurement, judgment, and decision making, P81, DOI DOI 10.1016/B978-012099975-0.50004-X
   MAUGUIERE F, 1978, BRAIN, V101, P307, DOI 10.1093/brain/101.2.307
   Mine D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232290
   Mon-Williams M, 1999, EXP BRAIN RES, V126, P578, DOI 10.1007/s002210050766
   ONO H, 1974, PERCEPT PSYCHOPHYS, V15, P301, DOI 10.3758/BF03213948
   Osumi M, 2017, EUR J PAIN, V21, P140, DOI 10.1002/ejp.910
   Ozana A, 2018, EXP BRAIN RES, V236, P1775, DOI 10.1007/s00221-018-5265-8
   Pavani F, 2007, PERCEPTION, V36, P1547, DOI 10.1068/p5853
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Sawada Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64302-y
   Stefanucci J. K., 2012, P ACM S APPL PERCEPT, P79
   Stefanucci JK, 2015, J EXP PSYCHOL-APPL, V21, P215, DOI 10.1037/xap0000051
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
NR 44
TC 3
Z9 3
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 13
PY 2021
VL 2
AR 712378
DI 10.3389/frvir.2021.712378
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YH8
UT WOS:001019234000001
OA gold
DA 2024-07-18
ER

PT J
AU Isaac, JHR
   Manivannan, M
   Ravindran, B
AF Isaac, Joseph H. R.
   Manivannan, M.
   Ravindran, Balaraman
TI Corrective Filter Based on Kinematics of Human Hand for Pose Estimation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE 3D hand tracking; biomechanics; kinematics; articulated body; computer
   vision; virtual reality
ID 3D HAND
AB Depth-based 3D hand trackers are expected to estimate highly accurate poses of the human hand given the image. One of the critical problems in tracking the hand pose is the generation of realistic predictions. This paper proposes a novel "anatomical filter" that accepts a hand pose from a hand tracker and generates the closest possible pose within the real human hand's anatomical bounds. The filter works by calculating the 26-DoF vector representing the joint angles and correcting those angles based on the real human hand's biomechanical limitations. The proposed filter can be plugged into any hand tracker to enhance its performance. The filter has been tested on two state-of-the-art 3D hand trackers. The empirical observations show that our proposed filter improves the hand pose's anatomical correctness and allows a smooth trade-off with pose error. The filter achieves the lowest prediction error when used with state-of-the-art trackers at 10% correction.
C1 [Isaac, Joseph H. R.; Ravindran, Balaraman] Indian Inst Technol Madras, Dept Comp Sci & Engn, Chennai, India.
   [Manivannan, M.] Indian Inst Technol Madras, Touch Lab, Dept Appl Mech, Chennai, India.
   [Ravindran, Balaraman] Indian Inst Technol Madras, Robert Bosch Ctr Data Scienceand Artificial Intell, Chennai, India.
   [Ravindran, Balaraman] Indian Inst Technol Madras, Dept Comp Sci & Engn, Chennai, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Madras; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Madras; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Madras
RP Isaac, JHR (corresponding author), Indian Inst Technol Madras, Dept Comp Sci & Engn, Chennai, India.
EM joeisaac@cse.iitm.ac.in
RI Isaac, Joseph Hosanna Raj/AAQ-4898-2021
OI Isaac, Joseph Hosanna Raj/0000-0003-2912-1132; Muniyandi,
   Manivannan/0000-0003-1162-1550
CR [Anonymous], 2003, BMVC CITESEER, DOI DOI 10.5244/C.17.60
   Aristidou A, 2018, VISUAL COMPUT, V34, P213, DOI 10.1007/s00371-016-1327-8
   Bradski GaryR., 1998, Computer vision face tracking for use in a perceptual user interface
   Cameron CR, 2011, 2011 IEEE SYSTEMS AND INFORMATION ENGINEERING DESIGN SYMPOSIUM (SIEDS), P127, DOI 10.1109/SIEDS.2011.5876867
   Chan S, 2013, NEUROSURGERY, V72, pA154, DOI 10.1227/NEU.0b013e3182750d26
   Chengde Wan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5147, DOI 10.1109/CVPR.2018.00540
   Chim Harvey, 2017, Plast Reconstr Surg, V140, P865, DOI 10.1097/PRS.0000000000003745
   Dang Q, 2019, TSINGHUA SCI TECHNOL, V24, P663, DOI 10.26599/TST.2018.9010100
   Delaney Martin, 2008, Proj Inf Perspect, P1
   Deng XM, 2018, IEEE T IMAGE PROCESS, V27, P1888, DOI 10.1109/TIP.2017.2779600
   El Sibai R, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P18, DOI 10.1109/COMAPP.2017.8079780
   Ferche O., 2016, Romanian Journal of Human-Computer Interaction, V9, P85
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Gustus A, 2012, BIOL CYBERN, V106, P741, DOI 10.1007/s00422-012-0532-4
   Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Hochschild J., 2015, FUNCTIONAL ANATOMY P
   Joo SI, 2014, SCI WORLD J, DOI 10.1155/2014/284827
   Kehr P., 2017, EUR J ORTHOPAEDIC SU, V27, P1029, DOI [10.1007/s00590-017-1991-z, DOI 10.1007/S00590-017-1991-Z]
   Kingma D. P., 2014, arXiv
   Lee P.-W., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, P73
   Li R, 2019, PATTERN RECOGN, V93, P251, DOI 10.1016/j.patcog.2019.04.026
   Lyubanenko V, 2017, LECT NOTES COMPUT SC, V10617, P63, DOI 10.1007/978-3-319-70353-4_6
   Malik J, 2018, LECT NOTES COMPUT SC, V11162, P3, DOI 10.1007/978-3-030-01790-3_1
   Manivannan M, 2009, PRIM CARE DIABETES, V3, P17, DOI 10.1016/j.pcd.2008.10.006
   Misra S, 2017, TENCON IEEE REGION, P1165, DOI 10.1109/TENCON.2017.8228033
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Mueller F, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322958
   Oikonomidis I, 2011, LECT NOTES COMPUT SC, V6494, P744, DOI 10.1007/978-3-642-19318-7_58
   Pelphrey KA, 2005, CEREB CORTEX, V15, P1866, DOI 10.1093/cercor/bhi064
   Quach KG, 2016, INT C PATT RECOG, P2746, DOI 10.1109/ICPR.2016.7900051
   Ross L. M., 2006, Thieme Atlas of Anatomy
   Roy K, 2017, IEEE INT CONF COMP V, P640, DOI 10.1109/ICCVW.2017.81
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Simon M, 2019, IEEE COMPUT SOC CONF, P1190, DOI 10.1109/CVPRW.2019.00158
   Stenger B, 2001, PROC CVPR IEEE, P310
   Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700
   Tang DH, 2017, IEEE T PATTERN ANAL, V39, P1374, DOI 10.1109/TPAMI.2016.2599170
   Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Torrey L., 2010, IGI Global, P242, DOI 10.4018/978-1-60566-766-9.CH011
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Xiong F, 2019, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2019.00088
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Yuan SX, 2017, PROC CVPR IEEE, P2605, DOI 10.1109/CVPR.2017.279
NR 47
TC 2
Z9 2
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 6
PY 2021
VL 2
AR 663618
DI 10.3389/frvir.2021.663618
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TG3
UT WOS:001021828600001
OA gold
DA 2024-07-18
ER

PT J
AU Xu, XH
   Mangina, E
   Campbell, AG
AF Xu, Xuanhui
   Mangina, Eleni
   Campbell, Abraham G.
TI HMD-Based Virtual and Augmented Reality in Medical Education: A
   Systematic Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; augmented reality; head-mounted display; surgery;
   medicine; systematic review; education
ID TOTAL HIP-ARTHROPLASTY; PERFORMANCE
AB Background: Virtual Reality (VR) and Augmented Reality (AR) technologies provide a novel experiential learning environment that can revolutionize medical education. These technologies have limitless potential as they provide in effect an infinite number of anatomical models to aid in foundational medical education. The 3D teaching models used within these environments are generated from medical data such as magnetic resonance imaging (MRI) or computed tomography (CT), which can be dissected and regenerated without limitations.Methods: A systematic review was carried out for existing articles until February 11, 2020, in EMBASE, PubMed, Scopus, ProQuest, Cochrane Reviews, CNKI, and OneSearch (University College Dublin Library) using the following search terms: (Virtual Reality OR Augmented Reality OR mixed reality) AND ["head-mounted" OR "face-mounted" OR "helmet-mounted" OR "head-worn" OR oculus OR vive OR HTC OR hololens OR "smart glasses" OR headset AND (training OR teaching OR education)] AND (anatomy OR anatomical OR medicine OR medical OR clinic OR clinical OR surgery OR surgeon OR surgical) AND (trial OR experiment OR study OR randomized OR randomised OR controlled OR control) NOT (rehabilitation OR recovery OR treatment) NOT ("systematic review" OR "review of literature" OR "literature review"). PRISMA guidelines were adhered to in reporting the results. All studies that examined people who are or were medical-related (novel or expert users) were included.Result: The electronic searches generated a total of 1,241 studies. After removing duplicates, 848 remained. Of those, 801 studies were excluded because the studies did not meet the criteria after reviewing the abstract. The full text of the remaining 47 studies was reviewed. After applying inclusion criteria and exclusion criteria, a total of 17 studies (1,050 participants) were identified for inclusion in the review.Conclusion: The systematic review provides the current state of the art on head-mounted device applications in medical education. Moreover, the study discusses trends toward the future and directions for further research in head-mounted VR and AR for medical education.
C1 [Xu, Xuanhui; Mangina, Eleni; Campbell, Abraham G.] Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.
C3 University College Dublin
RP Xu, XH (corresponding author), Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.
EM xuanhui.xu@ucdconnect.ie
RI Xu, Xuanhui/AAT-3800-2021
OI Xu, Xuanhui/0000-0002-6335-5672; Campbell, Abraham/0000-0001-6702-9148
FU China Scholarship Council [201908300021]
FX Funding Author XX has been supported by the China Scholarship Council
   (201908300021).
CR Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Alismail A, 2019, ADV MED EDUC PRACT, V10, P279, DOI 10.2147/AMEP.S201640
   [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI DOI 10.1371/JOURNAL.PMED.1000097
   Cai X., 2019, CHINA CONTIN MED ED, V11, P18, DOI [10.3969/j.issn.1674-9308.2019.23.008, DOI 10.3969/J.ISSN.1674-9308.2019.23.008]
   Chen Z., 2019, J TRAUMA EMERG, V7, P5, DOI [10.16746/j.cnki.11-9332/r.2019.01.002, DOI 10.16746/J.CNKI.11-9332/R.2019.01.002]
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Gutiérrez F, 2007, STUD HEALTH TECHNOL, V125, P155
   Harrington CM, 2018, J SURG EDUC, V75, P993, DOI 10.1016/j.jsurg.2017.10.010
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jiang J., 2019, CHINA MED ED TECHNOL, V34, P230, DOI [10.13566/j.cnki.cmet.cn61-1317/g4.202002028, DOI 10.13566/J.CNKI.CMET.CN61-1317/G4.202002028]
   Khalafallah A, 2010, MEDITERR J HEMATOL I, V2, DOI [10.1136/bmj.l4898, 10.4084/MJHID.2010.005]
   Larsen CR, 2012, ACTA OBSTET GYN SCAN, V91, P1015, DOI 10.1111/j.1600-0412.2012.01482.x
   Logishetty K, 2019, BONE JOINT J, V101B, P1585, DOI 10.1302/0301-620X.101B12.BJJ-2019-0643.R1
   Logishetty K, 2020, J BONE JOINT SURG AM, V102, DOI 10.2106/JBJS.19.00629
   Logishetty K, 2019, CLIN ORTHOP RELAT R, V477, P1190, DOI 10.1097/CORR.0000000000000542
   MacIntyre B., 2020, REM C PART SOC VIRT
   McGuinness LA, 2021, RES SYNTH METHODS, V12, P55, DOI 10.1002/jrsm.1411
   Meng D., 2018, MED INF, V31, P17, DOI [10.3969/j.issn.1006-1959.2018.22.006, DOI 10.3969/J.ISSN.1006-1959.2018.22.006]
   Pringle A, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P236, DOI 10.1109/ISMAR-Adjunct.2018.00075
   Pulijala Y, 2018, J ORAL MAXIL SURG, V76, P1065, DOI 10.1016/j.joms.2017.10.002
   Rojas-Muñoz E, 2019, ANN SURG, V270, P384, DOI 10.1097/SLA.0000000000002764
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Stepan K, 2017, INT FORUM ALLERGY RH, V7, P1006, DOI 10.1002/alr.21986
   Wang H, 2019, CHIN J MED ED RES, V18, P1230, DOI [10.3760/cma.j.issn.2095-1485.2019.12.011, DOI 10.3760/CMA.J.ISSN.2095-1485.2019.12.011]
   Wang P P, 2019, CHIN NURS MANAGE, V20, P176, DOI [10.3969/j.issn.1672-1756.2020.02.006, DOI 10.3969/J.ISSN.1672-1756.2020.02.006]
   Zackoff MW, 2020, PEDIATR CRIT CARE ME, V21, P477, DOI 10.1097/PCC.0000000000002249
NR 26
TC 17
Z9 18
U1 7
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 6
PY 2021
VL 2
AR 692103
DI 10.3389/frvir.2021.692103
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AN2
UT WOS:001019292000001
OA gold
DA 2024-07-18
ER

PT J
AU Li, M
   Ganni, S
   Albayrak, A
   Rutkowski, AF
   van Eijk, D
   Jakimowicz, J
AF Li, Meng
   Ganni, Sandeep
   Albayrak, Armagan
   Rutkowski, Anne F.
   van Eijk, Daan
   Jakimowicz, Jack
TI Proficiency From Immersion: A Human-Centered Design in Cross-Cultural
   Surgical Training
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersive training; virtual reality; cultural difference; intraoperative
   distractors; human-centered design
ID OPERATING-ROOM PERFORMANCE; VIRTUAL-REALITY; ENVIRONMENTS; FLOW;
   DISRUPTIONS
AB Ensuring surgeons are well-trained in various skills is of paramount importance to patient safety. Surgical simulators were introduced to laparoscopy training during the last 2 decades for basic skills training. The main drawback of current simulation-based laparoscopy training is their lack of true representation of the intro-operative experience. To create a complete surgical surrounding, the required amount of resources is demanding. Moreover, organizing immersive training with surgical teams burdens daily clinical routines. High-end virtual reality (VR) headsets bring an opportunity to generate an immersive virtual OR with accessible and affordable expenses. Pilot studies reveal that personalization and localization are key needs of the virtual operating room (VOR). They are therefore key in this study. The focus of this study was to explore the effect of different human factors, such as domain knowledge, culture, and familiarity of VR technologies, on the perception of VOR experience. A human-centered design approach was applied to investigate the presence and usability of a VOR. Sixty-four surgical practitioners joined the study in the Netherlands and India. The surgeons were referred to as "experts" and surgical trainees as "novices." The VOR system we used is composed of a laparoscopic simulator, a graphic virtual OR surrounding, and an Oculus Rift VR headset. Participants conducted the "complete Lapchol" task with the VOR. Afterward, four questionnaires were used to collect subjective ratings on presence and usability. Participant's qualitative feedback was collected using a semi-structural interview as the final stage. Results showed the surgical knowledge only affected perceived mental demand when using a VOR. The cultural difference would alter the rating on the majority of items in these questionnaires. VR experience mainly affected the judgment on presence including "quality of interface" and "reversible actions." The interaction effects between surgical knowledge either with culture difference or with VR experience were obvious. This study demonstrated the influences of cultural differences on the perception of immersion and usability. Integrating immersive technologies such as virtual reality and augmented reality to human-centered design opens a brand new horizon for health care and similar professional training.
C1 [Li, Meng; Albayrak, Armagan; van Eijk, Daan] Delft Technol Univ, Ind Design Engn Fac, Human Ctr Design Dept, Delft, Netherlands.
   [Li, Meng] Xi An Jiao Tong Univ, Mech Engn Sch, Ind Design Dept, Xian, Peoples R China.
   [Ganni, Sandeep] GSL Med Coll, Rajahmundry, India.
   [Rutkowski, Anne F.] Tilburg Univ, Tilburg Sch Econ & Management, Dept Management, Tilburg, Netherlands.
   [Jakimowicz, Jack] Catharine Hosp, Skills Lab, Eindhoven, Netherlands.
C3 Delft University of Technology; Xi'an Jiaotong University; Tilburg
   University; Catharina Hospital
RP Li, M (corresponding author), Delft Technol Univ, Ind Design Engn Fac, Human Ctr Design Dept, Delft, Netherlands.; Li, M (corresponding author), Xi An Jiao Tong Univ, Mech Engn Sch, Ind Design Dept, Xian, Peoples R China.
EM m.li-4@tudelft.nl
RI Li, Meng/KBB-4160-2024; zhen, wang/KBA-3844-2024
OI Li, Meng/0000-0002-7095-0170; 
CR [Anonymous], 2015, MENSCH AND COMPUTER, DOI [10.1515/9783110443929-016, DOI 10.1515/9783110443929-016]
   Badash I, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.12.24
   Berguer R, 2003, ARCH SURG-CHICAGO, V138, P967, DOI 10.1001/archsurg.138.9.967
   Berguer R, 2001, SURG ENDOSC-ULTRAS, V15, P1204, DOI 10.1007/s004640080030
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Douglas Y., 2000, ACM 2000 Hypertext. Proceedings of the Eleventh ACM Conference on Hypertext and Hypermedia, P153, DOI 10.1145/336296.336354
   Ganni S, 2020, INDIAN J SURG, V82, P810, DOI 10.1007/s12262-020-02131-z
   Hao C., 2019, PhD Thesis
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hekkert P, 2003, BRIT J PSYCHOL, V94, P111, DOI 10.1348/000712603762842147
   Henrich J.P., 2020, The WEIRDest People in the World: How the West Became Psychologically Peculiar and Particularly Prosperous, Farrar, Straus, and Giroux
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P61, DOI 10.1017/S0140525X0999152X
   Hornbeck RG, 2013, INT J PSYCHOL RELIG, V23, P15, DOI 10.1080/10508619.2013.735192
   Jakimowicz J. J., 2015, TRAINING MINIMAL ACC, P15, DOI [10.1007/978-1-4471-6494-4_2, DOI 10.1007/978-1-4471-6494-4_2]
   Lee GI, 2014, SURG ENDOSC, V28, P456, DOI 10.1007/s00464-013-3213-z
   Li M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P566, DOI [10.1109/VR46266.2020.00-26, 10.1109/VR46266.2020.1581301697128]
   Lin J, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2020.101040
   Meng Li, 2019, Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018). Volume X: Auditory and Vocal Ergonomics, Visual Ergonomics, Psychophysiology in Ergonomics, Ergonomics in Advanced Imaging. Advances in Intelligent Systems and Computing (AISC 827), P302, DOI 10.1007/978-3-319-96059-3_33
   Munz Y, 2004, SURG ENDOSC, V18, P485, DOI 10.1007/s00464-003-9043-7
   Naumann A., 2010, Proceedings of the 12th international conference on Human computer interaction with mobile devices and services, P401, DOI [DOI 10.1145/1851600.1851685, https://doi.org/10.1145/1851600.1851685]
   Nisbett R. E., 2003, The geography of thought: How Asians and Westerners think differentlyand why
   Parker SEH, 2010, WORLD J SURG, V34, P353, DOI 10.1007/s00268-009-0312-z
   Pilke EM, 2004, INT J HUM-COMPUT ST, V61, P347, DOI 10.1016/j.ijhcs.2004.01.004
   Pluyter JR, 2010, SURG ENDOSC, V24, P902, DOI 10.1007/s00464-009-0689-7
   PRISMA health, 2021, BEC GEN SURG
   Schijven MP, 2005, SURG ENDOSC, V19, P1220, DOI 10.1007/s00464-004-2240-1
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Strachan I. W., 2000, NATL DEFENSE BUSINES
   Taekman JM, 2010, INT ANESTHESIOL CLIN, V48, P101, DOI 10.1097/AIA.0b013e3181eace73
   van de Ven J, 2017, EUR J OBSTET GYN R B, V216, P130, DOI 10.1016/j.ejogrb.2017.07.027
   van Houwelingen BCG, 2020, SURG ENDOSC, V34, P4525, DOI 10.1007/s00464-019-07239-2
   Wiegmann DA, 2007, SURGERY, V142, P658, DOI 10.1016/j.surg.2007.07.034
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhang JJ, 2003, J BIOMED INFORM, V36, P23, DOI 10.1016/S1532-0464(03)00060-1
   Zheng B, 2012, SURG ENDOSC, V26, P2746, DOI 10.1007/s00464-012-2268-6
NR 39
TC 1
Z9 1
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 9
PY 2021
VL 2
AR 675334
DI 10.3389/frvir.2021.675334
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8YZ5
UT WOS:001019252100001
OA gold
DA 2024-07-18
ER

PT J
AU Liu, QX
   Steed, A
AF Liu, Qiaoxi
   Steed, Anthony
TI Social Virtual Reality Platform Comparison and Evaluation Using a Guided
   Group Walkthrough Method
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE collaborative virtual environment; cognitive walkthrough; usability
   inspection methods; consumer virtual reality; social virtual reality
ID USABILITY EVALUATION; ENVIRONMENTS; COMMUNICATION; BEHAVIOR; CRITERIA;
   TOOL
AB As virtual reality (VR) headsets become more commercially accessible, a range of social platforms have been developed that exploit the immersive nature of these systems. There is a growing interest in using these platforms in social and work contexts, but relatively little work into examining the usability choices that have been made. We developed a usability inspection method based on cognitive walkthrough that we call guided group walkthrough. Guided group walkthrough is applied to existing social VR platforms by having a guide walk the participants through a series of abstract social tasks that are common across the platforms. Using this method we compared six social VR platforms for the Oculus Quest. After constructing an appropriate task hierarchy and walkthrough question structure for social VR, we ran several groups of participants through the walkthrough process. We undercover usability challenges that are common across the platforms, identify specific design considerations and comment on the utility of the walkthrough method in this situation.
C1 [Liu, Qiaoxi] UCL, UCL Interact Ctr, London, England.
   [Steed, Anthony] UCL, Dept Comp Sci, London, England.
C3 University of London; University College London; University of London;
   University College London
RP Steed, A (corresponding author), UCL, Dept Comp Sci, London, England.
EM A.Steed@ucl.ac.uk
OI Steed, Anthony/0000-0001-9034-3020
CR Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Bias Randolph., 1994, USABILITY INSPECTION, P63
   Bigscreen, 2021, ABOUT US
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Blackwell Lindsay, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359202
   Blackwell L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P854, DOI [10.1109/VR.2019.8798165, 10.1109/vr.2019.8798165]
   Blanchard C., 1990, Computer Graphics, V24, P35, DOI 10.1145/91394.91409
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Damer B., 1997, Avatars! Exploring and Building Virtual Worlds on the Internet
   Fabri M, 1999, LECT NOTES ARTIF INT, V1739, P269
   Freeman G, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382923
   Gabbard J.L., 1997, TAXONOMY USABILITY C
   Geszten D, 2018, ACTA POLYTECH HUNG, V15, P67
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Hai W, 2015, PROCEEDINGS OF THE 31ST INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2016), P7, DOI 10.1145/3205326.3205345
   Hartson HR, 2001, INT J HUM-COMPUT INT, V13, P373, DOI 10.1207/S15327590IJHC1304_03
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Hindmarsh J., 2000, ACM Transactions on Computer-Human Interaction, V7, P477, DOI 10.1145/365058.365088
   Hollingsed T, 2007, SIGDOC'07: PROCEEDINGS OF THE 25TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P249
   Jadhav Dhiraj., 2013, P 11 ASIA PACIFIC C, P9, DOI [10.1145/2525194.2525202, DOI 10.1145/2525194.2525202]
   Jonas M, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P437, DOI 10.1145/3341215.3356271
   Kalawsky RS, 1999, APPL ERGON, V30, P11, DOI 10.1016/S0003-6870(98)00047-7
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kolesnichenko A, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P241, DOI 10.1145/3322276.3322352
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lewis C., 1990, SIGCHI Bulletin, P235
   Mahatody T, 2010, INT J HUM-COMPUT INT, V26, P741, DOI 10.1080/10447311003781409
   MANTOVANI G, 1995, HUM RELAT, V48, P669, DOI 10.1177/001872679504800604
   Marsh T., 1999, CHI 99, P61, DOI DOI 10.1145/632716.632756
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Microsoft, 2020, AltspaceVR
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Mozilla Corporation, 2021, Mozilla Hubs
   Murgia A, 2008, IEEE ACM DIS SIM, P252, DOI 10.1109/DS-RT.2008.25
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Pinelle D., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P455, DOI 10.1145/503376.503458
   Rec. Room, 2021, ABOUT US
   Salomoni Paola, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P387, DOI 10.1109/CCNC.2016.7444811
   Schroeder Ralph, 2010, Being There Together: Social interaction in shared virtual environments
   Schulz Ryan., 2020, Comprehensive List of Social VR Platforms and Virtual Worlds
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Spatial Systems, 2021, ABOUT US
   Stanney KM, 2003, INT J HUM-COMPUT ST, V58, P447, DOI 10.1016/S1071-5819(03)00015-6
   Stone Valerie E., 1993, Presence: Teleoperators and Virtual Environments, V2, P153
   Sutcliffe AG, 2000, BEHAV INFORM TECHNOL, V19, P415, DOI 10.1080/014492900750052679
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Tromp J, 1998, IEEE COMPUT GRAPH, V18, P53, DOI 10.1109/38.734980
   Tromp JG, 2003, PRESENCE-TELEOP VIRT, V12, P241, DOI 10.1162/105474603765879512
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   VRChat Inc, 2021, VRChat
   Weissker T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI [10.1109/VR.2019.8797807, 10.1109/vr.2019.8797807]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
   Zibrek K., 2019, Motion, interaction and games, P1, DOI [DOI 10.1145/3359566.3360064, 10.1145/3359566.3360064]
NR 61
TC 17
Z9 18
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 24
PY 2021
VL 2
AR 668181
DI 10.3389/frvir.2021.668181
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TF7
UT WOS:001021828000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Shen, SJ
   Chen, HT
   Raffe, W
   Leong, TW
AF Shen, Songjia
   Chen, Hsiang-Ting
   Raffe, William
   Leong, Tuck Wah
TI Effects of Level of Immersion on Virtual Training Transfer of Bimanual
   Assembly Tasks
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE assistive systems; head-mounted display; virtual reality; learning
   transfer; assembly; training
ID REALITY
AB The availability of consumer-facing virtual reality (VR) headsets makes virtual training an attractive alternative to expensive traditional training. Recent works showed that virtually trained workers perform bimanual assembly tasks equally well as ones trained with traditional methods. This paper presents a study that investigated how levels of immersion affect learning transfer between virtual and physical bimanual gearbox assembly tasks. The study used a with-in subject design and examined three different virtual training systems i.e., VR training with direct 3D inputs (HTC VIVE Pro), VR training without 3D inputs (Google Cardboard), and passive video-based training. 23 participants were recruited. The training effectiveness was measured by participant's performance of assembling 3D-printed copies of the gearboxes in two different timings: immediately after and 2 weeks after the training. The result showed that participants preferred immersive VR training. Surprisingly, despite being less favourable, the subjects' performance of video-based training were similar to training on HTC VIVE Pro. However, video training led to a significant performance decrease in the retention test session 2 weeks after the training.
C1 [Shen, Songjia; Raffe, William; Leong, Tuck Wah] Univ Technol Sydney, Sch Comp Sci, Sydney, NSW, Australia.
   [Chen, Hsiang-Ting] Univ Adelaide, Sch Comp Sci, Adelaide, SA, Australia.
C3 University of Technology Sydney; University of Adelaide
RP Shen, SJ (corresponding author), Univ Technol Sydney, Sch Comp Sci, Sydney, NSW, Australia.
EM songjia.shen@student.uts.edu.au
RI Chen, Hsiang-Ting/W-9252-2019; Leong, Tuck Wah/C-7936-2017
OI Chen, Hsiang-Ting/0000-0003-0873-2698; Leong, Tuck
   Wah/0000-0002-1021-9001
CR Adams R.J., 2001, HAPTICS E J IEEE ROB, V2, P1
   Bailenson J, 2008, MEDIA PSYCHOL, V11, P354, DOI 10.1080/15213260802285214
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Boud A. C., 1999, 1999 IEEE International Conference on Information Visualization (Cat. No. PR00210), P32, DOI 10.1109/IV.1999.781532
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   de Moura DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P286, DOI [10.1109/vr.2019.8798112, 10.1109/VR.2019.8798112]
   Funk M, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P222, DOI 10.1145/3056540.3056548
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Gerbaud S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P225
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Gorecky D, 2017, INT J COMPUT INTEG M, V30, P182, DOI 10.1080/0951192X.2015.1067918
   Hall C.R, 2001, Int. J. Virtual Real, V1, P61, DOI [10.20870/ijvr.2001.5.1.2669, DOI 10.20870/IJVR.2001.5.1.2669]
   Hoedt S, 2017, INT J PROD RES, V55, P7496, DOI 10.1080/00207543.2017.1374572
   Jiang MQ, 2011, VIRTUAL REALITY & AUGMENTED REALITY IN INDUSTRY, P171
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Laha B, 2012, IEEE T VIS COMPUT GR, V18, P597, DOI 10.1109/TVCG.2012.42
   Leu MC, 2013, CIRP ANN-MANUF TECHN, V62, P799, DOI 10.1016/j.cirp.2013.05.005
   Mollet N., 2007, EUROGRAPHICS ASS, DOI [10.2312/PE/VE2007Short/095-100, DOI 10.2312/PE/VE2007SHORT/095-100]
   Mollet N, 2006, LECT NOTES COMPUT SC, V3942, P334, DOI 10.1007/11736639_45
   Murcia-López M, 2018, IEEE T VIS COMPUT GR, V24, P1574, DOI 10.1109/TVCG.2018.2793638
   Oren M, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P27, DOI 10.1109/VR.2012.6180873
   Papachristos NM, 2017, IEEE INT CONF ADV LE, P477, DOI 10.1109/ICALT.2017.145
   Radu I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300774
   Ritter F, 2001, IEEE COMPUT GRAPH, V21, P11, DOI 10.1109/38.946625
   Rodriguez J., 2012, Virtual Reality and Environments, DOI DOI 10.5772/36650
   Ruthenbeck GS, 2015, J SIMUL, V9, P16, DOI 10.1057/jos.2014.14
   Schuchardt P, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P121, DOI 10.1115/IMECE2007-43781
   Shuralyov D., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P139, DOI 10.1109/3DUI.2011.5759244
   Sowndararajan A., 2008, IPTEDT 08, P1
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Young M. K., 2014, P ACM S APPL PERCEPT, P83
   Yuviler-Gavish N, 2011, INT J HUM-COMPUT ST, V69, P113, DOI 10.1016/j.ijhcs.2010.11.005
NR 36
TC 2
Z9 2
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 20
PY 2021
VL 2
AR 597487
DI 10.3389/frvir.2021.597487
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZI5
UT WOS:001019261100001
OA gold
DA 2024-07-18
ER

PT J
AU Pavlou, M
   Laskos, D
   Zacharaki, EI
   Risvas, K
   Moustakas, K
AF Pavlou, Michail
   Laskos, Dimitrios
   Zacharaki, Evangelia I. I.
   Risvas, Konstantinos
   Moustakas, Konstantinos
TI XRSISE: An XR Training System for Interactive Simulation and Ergonomics
   Assessment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; extended reality; xr training; ergonomics; digital
   human model; posture analysis; virtual workplace model; simulation
AB The use of virtual reality (VR) techniques for industrial training provides a safe and cost effective solution that contributes to increased engagement and knowledge retention levels. However, the process of experiential learning in a virtual world without biophysical constraints might contribute to muscle strain and discomfort, if ergonomic risk factors are not considered in advance. Under this scope, we have developed a digital platform which employs extended reality (XR) technologies for the creation and delivery of industrial training programs, by taking into account the users and workplace specificities through the adaptation of the 3D virtual world to the real environment. Our conceptual framework is composed of several inter-related modules: 1) the XR tutorial creation module, for automatic recognition of the sequence of actions composing a complex scenario while this is demonstrated by the educator in VR, 2) the XR tutorial execution module, for the delivery of visually guided and personalized XR training experiences, 3) the digital human model (DHM) based simulation module for creation and demonstration of job task simulations avoiding the need of an actual user and 4) the biophysics assessment module for ergonomics analysis given the input received from the other modules. Three-dimensional reconstruction and aligned projection of the objects situated in the real scene facilitated the imposition of inherent physical constraints, thereby allowed to seamlessly blend the virtual with the real world without losing the sense of presence.
C1 [Pavlou, Michail; Laskos, Dimitrios; Zacharaki, Evangelia I. I.; Risvas, Konstantinos; Moustakas, Konstantinos] Univ Patras, Dept Elect & Comp Engn, Visualizat & Virtual Real Grp, Patras, Greece.
C3 University of Patras
RP Zacharaki, EI (corresponding author), Univ Patras, Dept Elect & Comp Engn, Visualizat & Virtual Real Grp, Patras, Greece.
EM ezachar@upatras.gr
OI Laskos, Dimitrios/0000-0003-4863-8356
FU EU Horizon2020 [826299]
FX This work has been supported by the EU Horizon2020 funded project
   "Smart, Personalized and Adaptive ICT Solutions for Active, Healthy and
   Productive Aging with enhanced Workability (Ageing@Work)" under Grant
   Agreement No. 826299.
CR Ahmed S., 2018, INT DESIGN ENG TECHN, V51739
   [Anonymous], Advances in Intelligent Systems and Computing, V588, P3, DOI DOI 10.1007/978-3-319-60582-1_1
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   Azizi A, 2019, INT J INTERACT DES M, V13, P373, DOI 10.1007/s12008-018-0501-9
   Blender Online Community, 2018, BLEND 3D MOD REND PA
   Chaffin D.B., 2001, Digital human modeling for vehicle and workplace design
   Chaffin DB, 2007, HUM FACTOR ERGON MAN, V17, P475, DOI 10.1002/hfm.20087
   Cremer J., 1995, ACM Transactions on Modeling and Computer Simulation, V5, P242, DOI 10.1145/217853.217857
   Dias Barkokebas R., 2019, P 2019 INT S AUT ROB, DOI [10.22260/ISARC2019/0107, DOI 10.22260/ISARC2019/0107]
   Docs U, 2020, XR INT TOOLK 1 0 0
   Duffy V.G., 2008, HDB DIGITAL HUMAN MO
   Gerbaud S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P225
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Hignett S., 2004, HDB HUMAN FACTORS ER, P97
   KARHU O, 1977, APPL ERGON, V8, P199, DOI 10.1016/0003-6870(77)90164-8
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Manual U. L, 2020, XR PLUG IN FRAM
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   Mortensen J, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERECE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P27, DOI 10.1145/3278576.3278589
   Nousias S, 2021, IEEE T IND INFORM, V17, P980, DOI 10.1109/TII.2020.3000491
   Risvas K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P119, DOI [10.1109/VRW50115.2020.00026, 10.1109/VRW50115.2020.0-250]
   Rott J, 2018, IN C IND ENG ENG MAN, P1856, DOI 10.1109/IEEM.2018.8607656
   Seth A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006223
   Sreekanta MH, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P592, DOI [10.1109/ccwc47524.2020.9031141, 10.1109/CCWC47524.2020.9031141]
   Stanton NA, 2006, APPL ERGON, V37, P55, DOI 10.1016/j.apergo.2005.06.003
   Stanton Neville., 2013, Human factors methods: a practical guide for engineering and design
   Tanriverdi Vildan, 2001, P ACM S VIRTUAL REAL, P175
   Valve, 2020, STEAMVR UN PLUG
   Wang P, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P91, DOI 10.1109/ISMAR-Adjunct.2019.00038
   Winter D. A., 2009, Biomechanics and motor control of human movement, DOI 10.1002/9780470549148
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 31
TC 4
Z9 4
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 6
PY 2021
VL 2
AR 646415
DI 10.3389/frvir.2021.646415
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TG2
UT WOS:001021828500001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Schmidt, M
   Newbutt, N
   Schmidt, C
   Glaser, N
AF Schmidt, Matthew
   Newbutt, Nigel
   Schmidt, Carla
   Glaser, Noah
TI A Process-Model for Minimizing Adverse Effects when Using Head Mounted
   Display-Based Virtual Reality for Individuals with Autism
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE autism; virtual reality; head-mounted displays; implementation; adverse
   effects; cybersickness
ID OF-THE-ART; SPECTRUM DISORDER; YOUNG-ADULTS; EDUCATIONAL ACTIVITIES;
   CHILDREN; ADOLESCENTS; ANXIETY; INTERVENTION; ENVIRONMENTS; SKILLS
AB Interest in the use of virtual reality technologies for individuals with autism spectrum disorders has been increasing for over two decades. Recently, research interest has been growing in the area of head mounted display-based virtual reality technologies, thanks to increased availability and affordability. Affordances and theorized benefits of headset-based virtual reality for individuals with autism spectrum disorders are quite promising. However, very little attention has been given in the literature to implementation safety and ethics. This is a particular concern in light of documented adverse effects associated with headset-based virtual reality. To approach this gap, this article details how the authors approached the issue of minimizing adverse effects with related and overlapping methods, but from two separate, independent research sites-one in the United States and one in the United Kingdom. A structured within- and across-case analysis of the two independent studies was conducted to identify central implementation processes and procedures. Analysis resulted in development of a model for minimizing potential adverse effects of headset-based virtual reality for this population. We assert that our model could provide clarity in terms of design and implementation of headset-based virtual reality for individuals with autism spectrum disorders, guide implementations of future researchers and practitioners, and contribute to minimizing and controlling for potential adverse effects.
C1 [Schmidt, Matthew; Newbutt, Nigel; Schmidt, Carla] Univ Florida, Educ Technol Program, Gainesville, FL 32611 USA.
   [Glaser, Noah] Univ Connecticut, Educ Psychol, Storrs, CT USA.
C3 State University System of Florida; University of Florida; University of
   Connecticut
RP Schmidt, M (corresponding author), Univ Florida, Educ Technol Program, Gainesville, FL 32611 USA.
EM matthew.schmidt@coe.ufl.edu
OI Glaser, Noah/0000-0002-1966-2720; Schmidt, Matthew/0000-0002-8110-4367
CR American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], 2014, PROFESSIONAL ETHICAL
   [Anonymous], 2011, Code of ethics
   [Anonymous], 2013, Diagnostic and statistical manual of mental disorders
   [Anonymous], 2018, Ethical guidelines for educational research, V4th
   Becker K., 2007, Canadian Journal of Learning and Technology, V33, pn1, DOI DOI 10.21432/T2CG6H
   Bell N, 2008, CHILD GEOGR, V6, P7, DOI 10.1080/14733280701791827
   Bellani M, 2011, EPIDEMIOL PSYCH SCI, V20, P235, DOI 10.1017/S2045796011000448
   Benton L., 2011, IDEAS INTERFACE DESI
   Bozgeyikli L, 2018, IEEE T LEARN TECHNOL, V11, P133, DOI 10.1109/TLT.2017.2739747
   Braddock D., 2013, Inclusion, V1, P95
   Bradley R, 2018, J ENABLING TECHNOL, V12, P101, DOI 10.1108/JET-01-2018-0004
   Chessa M, 2019, HUM-COMPUT INTERACT, V34, P51, DOI 10.1080/07370024.2016.1243478
   Christensen Deborah L, 2016, MMWR Surveill Summ, V65, P1, DOI [10.15585/mmwr.ss6513a1, 10.15585/mmwr.ss6503a1]
   Deliens G, 2018, J AUTISM DEV DISORD, V48, P2938, DOI 10.1007/s10803-018-3561-6
   Deprey L, 2018, ASSESSMENT OF AUTISM SPECTRUM DISORDER, 2 EDITION, P308
   Dick W., 2014, SYSTEMATIC DESIGN IN
   Eaves LC, 2008, J AUTISM DEV DISORD, V38, P739, DOI 10.1007/s10803-007-0441-x
   Estes A, 2015, J AM ACAD CHILD PSY, V54, P580, DOI 10.1016/j.jaac.2015.04.005
   Factor RS, 2016, J AUTISM DEV DISORD, V46, P2548, DOI 10.1007/s10803-016-2781-x
   Fletcher-Watson S, 2014, REV J AUTISM DEV DIS, V1, P87, DOI 10.1007/s40489-013-0003-4
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Glaser N., 2020, 2020 INT CONV ASS ED
   Glaser NJ, 2020, TECHNOL KNOWL LEARN, V25, P315, DOI 10.1007/s10758-018-9369-9
   Gotham K, 2013, AUTISM RES, V6, P33, DOI 10.1002/aur.1263
   Grandin T., 2002, TEACHING TIPS CHILDR, P5
   Grynszpan O, 2014, AUTISM, V18, P346, DOI 10.1177/1362361313476767
   Hedley D, 2017, AUTISM, V21, P929, DOI 10.1177/1362361316661855
   Irish JEN, 2013, COMPUT HUM BEHAV, V29, pA17, DOI 10.1016/j.chb.2012.12.031
   Jarrold W, 2013, AUTISM RES, V6, P393, DOI 10.1002/aur.1302
   Josman N, 2008, INT J DISABIL HUM DE, V7, P49
   Kandalaft MR, 2013, J AUTISM DEV DISORD, V43, P34, DOI 10.1007/s10803-012-1544-6
   Ke F., 2020, J SPEC ED TECHNOL, V14, p016264342094560, DOI [10.1109/fie44824.2020.9273818, DOI 10.1109/FIE44824.2020.9273818]
   Ke FF, 2013, J EDUC RES, V106, P441, DOI 10.1080/00220671.2013.832999
   Kellmeyer P, 2018, CAMB Q HEALTHC ETHIC, V27, P610, DOI 10.1017/S0963180118000129
   Khowaja K, 2013, RES AUTISM SPECT DIS, V7, P1111, DOI 10.1016/j.rasd.2013.05.009
   Lidstone J, 2014, RES AUTISM SPECT DIS, V8, P82, DOI 10.1016/j.rasd.2013.10.001
   Lincoln Y., 1985, Naturalist Inquiry
   Malihi M, 2020, AUTISM, V24, P1924, DOI 10.1177/1362361320934214
   Masi A, 2017, NEUROSCI BULL, V33, P183, DOI 10.1007/s12264-017-0100-y
   Mesa-Gresa P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082486
   Miller IT, 2020, CYBERPSYCH BEH SOC N, V23, P10, DOI 10.1089/cyber.2019.0093
   Mitchell P, 2007, J AUTISM DEV DISORD, V37, P589, DOI 10.1007/s10803-006-0189-8
   Moore D., 2005, FOCUS AUTISM DEV DIS, V20, P231
   Morrison G., 2012, Designing effective instruction
   Newbutt N., 2017, Recent advances in technologies for inclusive well-being: From worn to off-body sensing, virtual worlds, and games for serious applications, P221, DOI 10.1007/978-3-319-49879-9_11
   Newbutt N., 2019, ENCY ED INFORM TECHN
   Newbutt N, 2020, CYBERPSYCH BEH SOC N, V23, P23, DOI 10.1089/cyber.2019.0206
   Newbutt N, 2016, J AUTISM DEV DISORD, V46, P3166, DOI 10.1007/s10803-016-2830-5
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Parish-Morris J, 2018, ANN REV CYBERTHERAPY, V16, P50
   Parsons Sarah, 2015, International Journal of Child-Computer Interaction, V6, P28, DOI 10.1016/j.ijcci.2015.12.002
   Parsons S, 2004, J AUTISM DEV DISORD, V34, P449, DOI 10.1023/B:JADD.0000037421.98517.8d
   Parsons S., 2013, Who chooses what I need? Child voice and user-involvement in the development of learning technologies for children with autism
   Parsons S, 2020, DISABIL SOC, V35, P201, DOI 10.1080/09687599.2019.1624152
   Parsons S, 2016, EDUC RES REV-NETH, V19, P138, DOI 10.1016/j.edurev.2016.08.001
   Pittaway E, 2010, J HUM RIGHTS PRACT, V2, P229, DOI 10.1093/jhuman/huq004
   Politis Y, 2019, ADV AUTISM, V5, P303, DOI 10.1108/AIA-01-2019-0001
   Protection of Human Subjects, 2009, CFR, V45, P46
   Rojo D, 2019, IEEE COMPUT GRAPH, V39, P104, DOI 10.1109/MCG.2018.2884272
   Russell G, 2014, J AUTISM DEV DISORD, V44, P31, DOI 10.1007/s10803-013-1849-0
   Schmidt M, 2021, INTERACT LEARN ENVIR, V29, P345, DOI 10.1080/10494820.2019.1579236
   Schmidt M, 2012, COMPUT HUM BEHAV, V28, P405, DOI 10.1016/j.chb.2011.10.011
   Self T, 2007, TOP LANG DISORD, V27, P242, DOI 10.1097/01.TLD.0000285358.33545.79
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shenton K., 2004, Education for Information, V22, P63, DOI [DOI 10.3233/EFI2004-22201, DOI 10.3233/EFI-2004-22201]
   Strickland D, 1997, ST HEAL T, V44, P81
   Strickland D, 1996, PRESENCE-TELEOP VIRT, V5, P319, DOI 10.1162/pres.1996.5.3.319
   Tavassoli T, 2016, J AUTISM DEV DISORD, V46, P287, DOI 10.1007/s10803-015-2578-3
   Taylor JL, 2014, DEV PSYCHOL, V50, P699, DOI 10.1037/a0034297
   Taylor JL, 2011, J AUTISM DEV DISORD, V41, P566, DOI 10.1007/s10803-010-1070-3
   Thomas G., 2015, DO YOUR CASE STUDY
   Thye MD, 2018, DEV COGN NEUROS-NETH, V29, P151, DOI 10.1016/j.dcn.2017.04.010
   Tobin GA, 2004, J ADV NURS, V48, P388, DOI 10.1111/j.1365-2648.2004.03207.x
   Uljarevic M, 2016, AUTISM RES, V9, P1073, DOI 10.1002/aur.1602
   van Steensel FJA, 2017, J CHILD FAM STUD, V26, P1753, DOI 10.1007/s10826-017-0687-7
   Volden J, 2009, J AUTISM DEV DISORD, V39, P388, DOI 10.1007/s10803-008-0618-y
   Wang M., 2014, Comprehensive guide to autism, P2125
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wong C, 2015, J AUTISM DEV DISORD, V45, P1951, DOI 10.1007/s10803-014-2351-z
   Yin R. K., 2018, Case Study Research and Applications: Design and Methods, DOI DOI 10.1016/J.TECHFORE.2018.10.013
NR 81
TC 19
Z9 19
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 19
PY 2021
VL 2
AR 611740
DI 10.3389/frvir.2021.611740
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2QA3
UT WOS:001021743800001
OA gold
DA 2024-07-18
ER

PT J
AU Neo, JRJ
   Won, AS
   Shepley, MM
AF Neo, Jun Rong Jeffrey
   Won, Andrea Stevenson
   Shepley, Mardelle McCuskey
TI Designing Immersive Virtual Environments for Human Behavior Research
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE immersive virtual environment; human behavior; design; prototype
   development; environmental psychology; virtual reality
ID POSTTRAUMATIC-STRESS-DISORDER; OCCUPANT BEHAVIOR; REALITY; PERFORMANCE;
   TECHNOLOGY; PERCEPTION; UNDERSTAND; RISK; TOOL
AB What are strategies for the design of immersive virtual environments (IVEs) to understand environments' influence on behaviors? To answer this question, we conducted a systematic review to assess peer-reviewed publications and conference proceedings on experimental and proof-of-concept studies that described the design, manipulation, and setup of the IVEs to examine behaviors influenced by the environment. Eighteen articles met the inclusion criteria. Our review identified key categories and proposed strategies in the following areas for consideration when deciding on the level of detail that should be included when prototyping IVEs for human behavior research: 1) the appropriate level of detail (primarily visual) in the environment: important commonly found environmental accessories, realistic textures, computational costs associated with increased details, and minimizing unnecessary details, 2) context: contextual element, cues, and animation social interactions, 3) social cues: including computer-controlled agent-avatars when necessary and animating social interactions, 4) self-avatars, navigation concerns, and changes in participants' head directions, and 5) nonvisual sensory information: haptic feedback, audio, and olfactory cues.
C1 [Neo, Jun Rong Jeffrey; Shepley, Mardelle McCuskey] Cornell Univ, Dept Design & Environm Anal, Ithaca, NY 14850 USA.
   [Won, Andrea Stevenson] Cornell Univ, Dept Commun, Ithaca, NY USA.
C3 Cornell University; Cornell University
RP Neo, JRJ (corresponding author), Cornell Univ, Dept Design & Environm Anal, Ithaca, NY 14850 USA.
EM jn458@cornell.edu
CR Ahn SJ, 2018, J MEDIA PSYCHOL-GER, V30, P91, DOI 10.1027/1864-1105/a000184
   Alshaer A, 2017, APPL ERGON, V58, P1, DOI 10.1016/j.apergo.2016.05.003
   [Anonymous], 2012, Product Design and Development
   [Anonymous], 2015, P ANN M AUSTR SPECIA
   Atesok K, 2016, J AM ACAD ORTHOP SUR, V24, P506, DOI 10.5435/JAAOS-D-15-00440
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Camburn B, 2017, DES SCI, V3, DOI 10.1017/dsj.2017.10
   Codd AM, 2011, ANAT SCI EDUC, V4, P119, DOI 10.1002/ase.214
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dickinson P, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106293
   Difede J, 2002, CYBERPSYCHOL BEHAV, V5, P529, DOI 10.1089/109493102321018169
   Fox J., 2010, CyberTherapy Rehabil, V3, P16, DOI [10.1037/e530522011-003, DOI 10.1037/E530522011-003]
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Glotzbach P. A., 1982, ECOLOGICAL PHENOMENO, P16108
   Gonzalez-Franco M., 2020, IEEE AIVR 2020
   Greenhalgh T, 2005, BRIT MED J, V331, P1064, DOI 10.1136/bmj.38636.593461.68
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Heydarian A, 2017, J BUILD PERFORM SIMU, V10, P484, DOI 10.1080/19401493.2016.1267801
   Iryo-Asano M, 2018, TRANSP RES PROC, V34, P67, DOI 10.1016/j.trpro.2018.11.015
   Joseph A, 2014, INTELL BUILD INT, V6, P155, DOI 10.1080/17508975.2014.903163
   Kooijman L, 2019, INFORMATION, V10, DOI 10.3390/info10120386
   Ledoux T, 2013, APPETITE, V71, P396, DOI 10.1016/j.appet.2013.09.006
   Lee J, 2019, COMPUT HUM BEHAV, V98, P158, DOI 10.1016/j.chb.2019.03.040
   Li BJ, 2017, PRESENCE-TELEOP VIRT, V26, P337, DOI [10.1162/PRES_a_00300, 10.1162/pres_a_00300]
   Lin J, 2020, AUTOMAT CONSTR, V113, DOI 10.1016/j.autcon.2020.103136
   Lok B., 2006, Virtual Reality, V10, P185, DOI [10.1007/s10055-006-0037-3, DOI 10.1007/S10055-006-0037-3]
   Lombart C, 2019, J RETAIL CONSUM SERV, V48, P28, DOI 10.1016/j.jretconser.2019.01.010
   Lovreglio R, 2018, ADV ENG INFORM, V38, P670, DOI 10.1016/j.aei.2018.08.018
   Lucas GM, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P22, DOI 10.1145/3308332.3329464
   Marans R.W., 2013, Environmental simulation: Research and policy issues
   Marcum CS, 2018, ANN BEHAV MED, V52, P252, DOI 10.1093/abm/kax041
   Markwart H, 2019, INT J DISAST RISK RE, V38, DOI 10.1016/j.ijdrr.2019.101235
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Metsis V, 2019, J TECHNOL HUMAN SERV, V37, P32, DOI 10.1080/15228835.2019.1604291
   Mizuchi Y, 2018, IEEE ROMAN, P196, DOI 10.1109/ROMAN.2018.8525840
   Morrongiello BA, 2015, J PEDIATR PSYCHOL, V40, P697, DOI 10.1093/jpepsy/jsv019
   Nash EB, 2000, INT J HUM-COMPUT INT, V12, P1, DOI 10.1207/S15327590IJHC1201_1
   Neo J. R. J., 2019, 69 INT COMM ASS C DC
   Oh SY, 2016, P IEEE VIRT REAL ANN, P249, DOI 10.1109/VR.2016.7504747
   Otto K.N., 2001, Product Design: Techniques in Reverse Engineering, Systematic Design, and New Product Development
   Parsons TD, 2007, CHILD NEUROPSYCHOL, V13, P363, DOI 10.1080/13825580600943473
   Persky S, 2018, APPETITE, V123, P201, DOI 10.1016/j.appet.2017.12.007
   Poelman M, 2017, BRIT FOOD J, V119, P2559, DOI 10.1108/BFJ-08-2016-0386
   Pourhoseingholi Mohamad Amin, 2012, Gastroenterol Hepatol Bed Bench, V5, P79
   Rollings KA, 2019, ENVIRON BEHAV, V51, P590, DOI 10.1177/0013916518824631
   Rollings KA, 2018, BMC PUBLIC HEALTH, V18, DOI 10.1186/s12889-018-6032-2
   Sachs NA, 2018, HERD-HEALTH ENV RES, V11, P108, DOI 10.1177/1937586718812120
   Saeidi S, 2018, AUTOMAT CONSTR, V94, P371, DOI 10.1016/j.autcon.2018.07.019
   Schwebel DC, 2008, ACCIDENT ANAL PREV, V40, P1394, DOI 10.1016/j.aap.2008.03.005
   Schwebel DC, 2012, ACCIDENT ANAL PREV, V45, P266, DOI 10.1016/j.aap.2011.07.011
   Shi YM, 2019, AUTOMAT CONSTR, V104, P197, DOI 10.1016/j.autcon.2019.04.015
   Siegrist M, 2019, FOOD RES INT, V117, P50, DOI 10.1016/j.foodres.2018.02.033
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Sobhani A, 2017, IEEE INT C INTELL TR
   Stelick A, 2018, J FOOD SCI, V83, P2047, DOI 10.1111/1750-3841.14275
   Tucker A, 2018, FIRE SAFETY J, V99, P1, DOI 10.1016/j.firesaf.2018.04.011
   Veling W, 2016, PSYCHOL MED, V46, P3339, DOI 10.1017/S0033291716002208
   Waterlander WE, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3774
   Wiederhold BK, 2017, CYBERPSYCH BEH SOC N, V20, P725, DOI 10.1089/cyber.2017.29092.bkw
   Wiederhold BK, 2010, CYBERPSYCH BEH SOC N, V13, P21, DOI 10.1089/cyber.2009.0394
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yaremych HE, 2019, J EXP SOC PSYCHOL, V85, DOI 10.1016/j.jesp.2019.103845
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
NR 66
TC 14
Z9 16
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 4
PY 2021
VL 2
AR 603750
DI 10.3389/frvir.2021.603750
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9BE5
UT WOS:001019309400001
OA gold
DA 2024-07-18
ER

PT J
AU De Witte, NAJ
   Scheveneels, S
   Sels, R
   Debard, G
   Hermans, D
   Van Daele, T
AF De Witte, Nele A. J.
   Scheveneels, Sara
   Sels, Romy
   Debard, Glen
   Hermans, Dirk
   Van Daele, Tom
TI Augmenting Exposure Therapy: Mobile Augmented Reality for Specific
   Phobia
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality exposure therapy; mixed reality; anxiety disorders;
   specific phobia; psychophysiology; skin conductance; e-mental health
ID IN-VIVO EXPOSURE; VIRTUAL-REALITY; ANXIETY DISORDERS; FEAR; ACCEPTANCE;
   VALIDATION; SYSTEM; IMPACT
AB New technologies, such as virtual reality (VR) and augmented reality (AR), can be used as an add-on to exposure therapy for common anxiety disorders. Although the benefits of VR for exposure therapy have already been demonstrated extensively in research, AR applications are only just becoming widely available. Evidence for the added value and effectiveness of AR exposure therapy (ARET) is still scarce. The current study aimed to explore whether a first markerless AR iOS app for specific phobia could induce fear for multiple animal species in a general population sample. In two experiments, participants made use of the PHOBOS AR app in a behavioral approach task (BAT), using animals for which they were anxious, but not phobic. Self-report data and physiological measures were recorded. In Experiment 1, 108 participants chose one of the seven available animal species and were allocated to either a smartphone or tablet condition. Results showed increasing levels of self-reported anxiety with increasing levels of BAT difficulty. However, this increase was smaller in individuals reporting low levels of perceived realism. No effects on heart rate (HR) could be established. In Experiment 2, 52 participants were exposed to virtual spiders. For both self-reported anxiety and the interaction with perceived realism, results were similar to those of Experiment 1. Skin conductance did increase significantly from baseline to the highest level of difficulty of the BAT, and the severity of fear of spiders also appeared to be related to the fear response in the BAT. In conclusion, the study shows that animals presented in AR through a mobile device can evoke anxiety, which is a pre-requisite for the implementation of ARET. However, further research should establish the effects of ARET in a clinical sample of people with specific phobias.
C1 [De Witte, Nele A. J.; Van Daele, Tom] Thomas More Univ Appl Sci, Expertise Unit Psychol Technol & Soc, Antwerp, Belgium.
   [Scheveneels, Sara; Hermans, Dirk; Van Daele, Tom] Katholieke Univ Leuven, Ctr Psychol Learning & Expt Psychopathol, Leuven, Belgium.
   [Sels, Romy; Debard, Glen] Thomas More Univ Appl Sci, Mobilab & Care, Geel, Belgium.
C3 KU Leuven
RP De Witte, NAJ (corresponding author), Thomas More Univ Appl Sci, Expertise Unit Psychol Technol & Soc, Antwerp, Belgium.
EM nele.dw@thomasmore.be
RI Van Daele, Tom/AAF-2373-2020; Hermans, Dirk/AAE-6657-2021
OI Van Daele, Tom/0000-0001-9237-9297; De Witte, Nele A.
   J./0000-0001-6313-7256; Debard, Glen/0000-0002-0195-4848; Scheveneels,
   Sara/0000-0003-1931-5777; Hermans, Dirk/0000-0003-4497-3982
FU KU Leuven [C16/19/02]; Thomas More University of Applied Sciences
FX This research was partially funded by KU Leuven project C16/19/02.
   Funding for open access fees was received from Thomas More University of
   Applied Sciences and KU Leuven.
CR Bandarian-Balooch S, 2015, J BEHAV THER EXP PSY, V47, P138, DOI 10.1016/j.jbtep.2014.12.006
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Böhnlein J, 2020, NEUROSCI BIOBEHAV R, V108, P796, DOI 10.1016/j.neubiorev.2019.12.009
   Botella C, 2011, COMPUT HUM BEHAV, V27, P217, DOI 10.1016/j.chb.2010.07.043
   Botella CM, 2005, CYBERPSYCHOL BEHAV, V8, P162, DOI 10.1089/cpb.2005.8.162
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Botella C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148237
   Botella C, 2010, BEHAV THER, V41, P401, DOI 10.1016/j.beth.2009.07.002
   Bretón-López J, 2010, CYBERPSYCH BEH SOC N, V13, P705, DOI 10.1089/cyber.2009.0170
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Juan MC, 2011, INT J HUM-COMPUT ST, V69, P440, DOI 10.1016/j.ijhcs.2011.03.002
   Craske M., 2013, Severity Measure for Specific Phobia-Child Age 11-17 [Measurement instrument]
   Craske MG, 2008, BEHAV RES THER, V46, P5, DOI 10.1016/j.brat.2007.10.003
   Craske MG, 2014, BEHAV RES THER, V58, P10, DOI 10.1016/j.brat.2014.04.006
   Culver NC, 2012, J BEHAV THER EXP PSY, V43, P787, DOI 10.1016/j.jbtep.2011.10.009
   De Witte N.A.J., 2017, VLAAMSE UTAUT VRAGEN
   Diemer J, 2014, WORLD J BIOL PSYCHIA, V15, P427, DOI 10.3109/15622975.2014.892632
   Dünser A, 2011, ANN REV CYBERTHERAPY, V9, P31
   Eaton WW, 2018, LANCET PSYCHIAT, V5, P678, DOI 10.1016/S2215-0366(18)30169-X
   Ebert DD, 2015, J AFFECT DISORDERS, V176, P9, DOI 10.1016/j.jad.2015.01.056
   Eisinga R, 2013, INT J PUBLIC HEALTH, V58, P637, DOI 10.1007/s00038-012-0416-3
   Etiwy M, 2019, CARDIOVASC DIAGN THE, V9, P262, DOI 10.21037/cdt.2019.04.08
   FOA EB, 1986, PSYCHOL BULL, V99, P20, DOI 10.1037/0033-2909.99.1.20
   Garcia-Palacios A, 2007, CYBERPSYCHOL BEHAV, V10, P722, DOI 10.1089/cpb.2007.9962
   Giglioli IAC, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/862942
   Jacoby RJ, 2016, CLIN PSYCHOL REV, V49, P28, DOI 10.1016/j.cpr.2016.07.001
   Juan MC, 2005, IEEE COMPUT GRAPH, V25, P31, DOI 10.1109/MCG.2005.143
   Konstantinou P, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13551
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Lindner P, 2019, SCAND J PSYCHOL, V60, P1, DOI 10.1111/sjop.12508
   McCraw KS, 2015, PSYCHOL ASSESSMENT, V27, P403, DOI 10.1037/pas0000046
   McNair DM, 1992, EDITS MANUAL PROFILE
   Menghini L, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13441
   Muris P, 1996, J BEHAV THER EXP PSY, V27, P241, DOI 10.1016/S0005-7916(96)00022-5
   Ollander S, 2016, IEEE SYS MAN CYBERN, P4362, DOI 10.1109/SMC.2016.7844917
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Sano A, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9410
   Suso-Ribera C, 2019, CYBERPSYCH BEH SOC N, V22, P31, DOI 10.1089/cyber.2017.0672
   SZYMANSKI J, 1995, J BEHAV THER EXP PSY, V26, P31, DOI 10.1016/0005-7916(94)00072-T
   Tanner BA, 2012, APPL PSYCHOPHYS BIOF, V37, P31, DOI 10.1007/s10484-011-9174-x
   Tarnogol F. M., 2018, PHOBOS AR VERSION 1
   van Lier HG, 2020, BEHAV RES METHODS, V52, P607, DOI 10.3758/s13428-019-01263-9
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Wald FDM., 1990, Nederlands Tijdschrift voor de Psychologie, V45, P86, DOI [10.1007/BF03062320, DOI 10.1007/BF03062320]
   Wrzesien M., 2011, Human-Computer Interaction, V27, P523, DOI [10.1007/978-3-642-23774-4_43, DOI 10.1007/978-3-642-23774-4_43]
   Wrzesien M, 2013, IEEE COMPUT GRAPH, V33, P80, DOI 10.1109/MCG.2013.12
   Yeh YC, 2008, COMPUT METH PROG BIO, V91, P245, DOI 10.1016/j.cmpb.2008.04.006
NR 48
TC 12
Z9 13
U1 4
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 25
PY 2020
VL 1
AR 8
DI 10.3389/frvir.2020.00008
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L6UZ1
UT WOS:001024604900001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Chen, MY
   Peljhan, M
   Sra, M
AF Chen, Mengyu
   Peljhan, Marko
   Sra, Misha
TI EntangleVR plus plus : evaluating the potential of using entanglement in
   an interactive VR scene creation system
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; quantum computing; entanglement; visual programming;
   art; creativity; interactive narratives; scene creation
AB Interactive digital stories provide a sense of flexibility and freedom to players by allowing them to make choices at key junctions. These choices advance the narrative and determine, to some degree, how the story evolves for that player. As shown in prior work, the ability to control or participate in the construction of the narrative can give the player a high level of agency that results in a stronger sense of immersion in the narrative experience. To support the design of this type of interactive storytelling, our system, EntangleVR++, borrows the idea of entanglement from quantum computing. Our use of entanglement allows creators and storytellers control over which sequences of story events take place in correlation with each other, initiated by the choices a player makes. In this work, we evaluated how well our idea of entanglement enables creators to easily and quickly design interactive Virtual reality narratives. We asked 16 participants to use our system and based on user interviews, analyses of screen recordings, and questionnaire feedback, we extracted four themes. From these themes and the study overall, we derived four authoring strategies for tool designers interested in the design of future visual interface for interactively creating virtual scenes that include relational objects and multiple outcomes driven by player interactions.
C1 [Chen, Mengyu; Peljhan, Marko; Sra, Misha] Univ Calif Santa Barbara, Dept Media Arts & Technol, Santa Barbara, CA 93106 USA.
   [Sra, Misha] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA USA.
C3 University of California System; University of California Santa Barbara;
   University of California System; University of California Santa Barbara
RP Chen, MY (corresponding author), Univ Calif Santa Barbara, Dept Media Arts & Technol, Santa Barbara, CA 93106 USA.
EM mengyuchen@ucsb.edu
FU Human-AI Integration Lab at the University of California, Santa Barbara
FX The author(s) declare financial support was received for the research,
   authorship, and/or publication of this article. This work was supported
   by the Human-AI Integration Lab at the University of California, Santa
   Barbara.
CR Aaronson S., 2013, Quantum Computing since Democritus, DOI DOI 10.1017/CBO9780511979309
   Billinghurst M., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P155, DOI 10.1145/261135.261163
   BLOCH F, 1946, PHYS REV, V70, P460, DOI 10.1103/PhysRev.70.460
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Chen MY, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489872
   Cutler Larry, 2020, SPECIAL INTEREST GRO, DOI DOI 10.1145/3388767.3407319
   Doerner R, 2015, LECT NOTES COMPUT SC, V8844, P187, DOI 10.1007/978-3-319-17043-5_11
   Dörner R, 2014, WORK SOFTW ENG, P1, DOI 10.1109/SEARIS.2014.7152795
   Finstad K, 2010, J USABILITY STUD, V5, P104
   Hempel B, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P379, DOI 10.1145/2984511.2984575
   Horst R, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364261
   Irani P., 2017, Can. Human-Computer Commun. Soc, VGI '17, P156, DOI [10.20380/gi2017.20, DOI 10.20380/GI2017.20]
   Krishnamoorthy SP, 2016, PROCEEDINGS OF FABLEARN 2016: 6TH ANNUAL CONFERENCE ON CREATIVITY AND MAKING IN EDUCATION, P41, DOI 10.1145/3003397.3003403
   Lee GA, 2005, COMMUN ACM, V48, P76, DOI 10.1145/1070838.1070840
   Li JY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376765
   Migdal P, 2022, OPT ENG, V61, DOI 10.1117/1.OE.61.8.081808
   Murray Janet H., 1997, Hamlet on the Holodeck: The Future of Narrative in Cyberspace
   Myers B. A., 1990, Journal of Visual Languages and Computing, V1, P97, DOI 10.1016/S1045-926X(05)80036-9
   Pinto-Llorente AM., 2016, TEEM'16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality s, P45, DOI [10.1145/3012430.3012495, DOI 10.1145/3012430.3012495]
   Schiavoni FL, 2017, SYMP VIRTUAL AUGMENT, P200, DOI 10.1109/SVR.2017.33
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Takala T., 2014, Ruis-a toolkit for developing virtual reality applications with spatial interaction, DOI [10.1145/2659766.2659774, DOI 10.1145/2659766.2659774]
   Tamilselvam SG, 2019, PROCEEDINGS OF THE 10TH INDIAN CONFERENCE ON HUMAN-COMPUTER INTERACTION (INDIA HCI 2019), P133, DOI 10.1145/3364183.3364202
   Weisz JD, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P523, DOI 10.1145/3242671.3242696
   Wojciechowski R., 2004, Proceedings of the ninth international conference on 3D Web technology, Monterey, CA, DOI [DOI 10.1145/985040.985060, https://doi.org/10.1145/985040.985060]
   Zable A., 2020, 26th ACM symposium on virtual reality software and technology, DOI [10.1145/3385956.3418957, DOI 10.1145/3385956.3418957]
   Zhang L., 2020, P 33 ANN ACM S USER, P342, DOI DOI 10.1145/3379337.3415824
   Zikas P, 2020, VISUAL COMPUT, V36, P1965, DOI 10.1007/s00371-020-01919-0
NR 30
TC 0
Z9 0
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 22
PY 2023
VL 4
AR 1252551
DI 10.3389/frvir.2023.1252551
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA EB5G7
UT WOS:001136455100001
OA gold
DA 2024-07-18
ER

PT J
AU Ganapathi, P
   Sorathia, K
AF Ganapathi, Priya
   Sorathia, Keyur
TI User elicited gesture-based locomotion techniques for immersive VEs in a
   seated position: a comparative evaluation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; locomotion methods; virtual travel; gesture based
   locomotion; hand interaction
ID SICKNESS
AB Locomotion is a fundamental task for exploring and interacting in virtual environments (VEs), and numerous locomotion techniques have been developed to improve the perceived realism and efficiency of movement in VEs. Gesture-based locomotion techniques have emerged as a more natural and intuitive mode of interaction than controller-based methods of travel in VEs. In this paper, we investigate the intuitiveness, comfort, ease of use, performance, presence, simulation sickness, and user preference of three user-elicited body-based gestures: the Calling gesture, Deictic Pointing gesture, and Mirror Leaning gesture. These gestures are intended to be used in three different seated multitasking scenarios involving virtual travel and various levels of hand engagement in selection. In the first study, participants compared the Calling gesture with the Tapping and Teleportation gestures for Scenario 1, which involved virtual travel only. The Calling gesture was found to be the most intuitive, with increased presence, while the Teleportation gesture was the preferred travel technique. The second study involved participants comparing the Deictic Pointing gesture with the Tapping and Teleportation gestures for Scenario 2, which involved virtual travel and one hand engaged in selection. The Deictic Pointing gesture was found to be more intuitive than the other gestures in terms of performance, comfort, ease of use, and presence. The third study introduced a new group of participants who compared the Mirror Leaning gesture with the Tapping and Teleportation gestures for Scenario 3, which involved virtual travel and both hands engaged in selection. The Mirror Leaning gesture was found to be the most intuitive, with increased presence and performance compared to the other gestures. We compared the gestures of the scenarios in three complementary search tasks: traveling in a straight-line path, moving in a directed path, and moving in an undirected path. We believe that the qualitative and quantitative measures obtained from our studies will help researchers and interaction design experts to design efficient and effective gesture-based locomotion techniques for traveling in a seated position in multitasking VEs.
C1 [Ganapathi, Priya; Sorathia, Keyur] Indian Inst Technol, Dept Design, Gauhati, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Ganapathi, P (corresponding author), Indian Inst Technol, Dept Design, Gauhati, Assam, India.
EM priyaganapathy@gmail.com
CR [Anonymous], 2013, Proceedings of Motion on Games, DOI DOI 10.1145/2522628.2522655
   Bhandari J., 2018, P 44 GRAPHICS INTERF, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018.223, DOI 10.20380/GI2018.223]
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruns CR, 2019, LANDSCAPE URBAN PLAN, V189, P296, DOI 10.1016/j.landurbplan.2019.05.006
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Caggianese G, 2020, INT J HUM-COMPUT INT, V36, P1734, DOI 10.1080/10447318.2020.1785151
   Cardoso J., 2017, GESTURE BASED LOCOMO
   Chester MR, 2002, INT J IND ERGONOM, V29, P289, DOI 10.1016/S0169-8141(01)00069-5
   Chou YH, 2009, J GERONTOL B-PSYCHOL, V64, P222, DOI 10.1093/geronb/gbp003
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   Engel David., 2008, P ACM S VIRTUAL REAL, P157, DOI [DOI 10.1145/1450579.1450612, 10.1145/1450579.1450612]
   Ferracani A, 2016, P 1 INT WORKSH MULT, P21, DOI DOI 10.1145/2983298.2983307
   Ganapathi Priya, 2022, Ergonomics for Design and Innovation: Humanizing Work and Work Environment: Proceedings of HWWE 2021. Lecture Notes in Networks and Systems (391), P1313, DOI 10.1007/978-3-030-94277-9_112
   Ganapathi P., 2019, P 12 ACM SIGGRAPH C, P1
   Griffin NN, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P211, DOI 10.1145/3242671.3242707
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231, DOI DOI 10.1145/2670473.2670512
   Hashemian AM, 2022, IEEE T VIS COMPUT GR, V28, P1792, DOI 10.1109/TVCG.2020.3025084
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Kruijff E., 2015, P 3 ACM S SPAT US IN, P103, DOI 10.1145/2788940.2788943
   McCullough M, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P107, DOI 10.1145/2804408.2804416
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Pai YS, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P189, DOI 10.1145/3152832.3152864
   Paris R, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119889
   Riecke BE, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P373, DOI 10.1109/VRW52623.2021.00075
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Tomberlin M, 2017, P IEEE VIRT REAL ANN, P299, DOI 10.1109/VR.2017.7892295
   Tregillus S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4063, DOI 10.1145/3025453.3025521
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Zanbaka C, 2004, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2004.1310068
   Zhang F, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P539
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
NR 37
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 30
PY 2023
VL 4
AR 1169654
DI 10.3389/frvir.2023.1169654
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA R5WV9
UT WOS:001065064700001
OA gold
DA 2024-07-18
ER

PT J
AU Yang, CL
   Matsumoto, K
   Yu, SP
   Sawada, L
   Arakawa, K
   Yamada, D
   Kuzuoka, H
AF Yang, Chi-Lan
   Matsumoto, Keigo
   Yu, Songping
   Sawada, Leo
   Arakawa, Kiyoaki
   Yamada, Daisuke
   Kuzuoka, Hideaki
TI Understanding the effect of a virtual moderator on people's perception
   in remote discussion using social VR
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE social VR; communication; virtual moderator; nonverbal cues; online
   discussion
ID PSYCHOLOGICAL SAFETY
AB Social VR enables people to join a remote discussion by keeping a high social presence and physical proximity using embodied avatars. However, the missing nonverbal cues, such as mutual eye contact and nuanced facial expression, make it challenging for distributed members to manage turn-taking, which could lead to unequal participation and affect trust building. Therefore, we propose a virtual moderator to make distributed members feel included by seeing their nonverbal behavior. The virtual moderator was designed with a "prompt Q & A & DPRIME; feature to enable users to share feedback and an "attention guidance" feature to encourage participation. The preliminary result of a controlled experiment in social VR with 30 participants showed that seeing the virtual moderator's body orientation enhanced participants' psychological safety. In contrast, the prompt Q & A feature enhanced the perceived co-presence of their remote counterparts. We discussed how nonverbal behavior could be designed using a virtual moderator to shape human perception of the group discussion in social VR. We also pointed out challenges when providing multiple supports simultaneously in social VR.
C1 [Yang, Chi-Lan; Matsumoto, Keigo; Yu, Songping; Sawada, Leo; Kuzuoka, Hideaki] Univ Tokyo, Cyber Interface Lab, Tokyo, Japan.
   [Arakawa, Kiyoaki; Yamada, Daisuke] Michele Holdings Co Ltd, Tokyo, Japan.
C3 University of Tokyo
RP Yang, CL; Matsumoto, K (corresponding author), Univ Tokyo, Cyber Interface Lab, Tokyo, Japan.
EM chilan.yang@cyber.t.u-tokyo.ac.jp; matsumoto@cyber.t.u-tokyo.ac.jp
RI Yang, Chi-Lan/JGZ-6215-2023; Kuzuoka, Hideaki/KIG-7464-2024
OI Yang, Chi-Lan/0000-0003-0603-2807; Kuzuoka, Hideaki/0000-0003-1252-7814
FU Michele Holdings Co., Ltd; Michele Properties Co., Ltd
FX This work was supported by Michele Holdings Co., Ltd. and Michele
   Properties Co., Ltd.
CR Abdullah Ahsan, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479597
   Arroll B, 2015, BRIT J GEN PRACT, V65, pE609, DOI 10.3399/bjgp15X686533
   Biocca F., 2003, Networked Minds Social Presence Inventory: |(Scales only, Version 1.2) Measures of co-presence, social presence, subjective symmetry
   Bradley BH, 2012, J APPL PSYCHOL, V97, P151, DOI 10.1037/a0024200
   DiMicco J. M., 2004, Computer Supported Cooperative Work Conference Proceedings, P614, DOI 10.1145/1031607.1031713
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   Edmondson A, 1999, ADMIN SCI QUART, V44, P350, DOI 10.2307/2666999
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Gillet S, 2021, 2021 16TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI, P303, DOI 10.1145/3434073.3444670
   Greenwald S W., 2017, Communications in Computer and Information Science, V725, DOI DOI 10.1007/978-3-319-60633-0_7
   Hyde J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1719, DOI 10.1145/2702123.2702465
   Ichino Junko, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3555583
   Kim S., 2020, P 2020 CHI C HUM FAC, P1
   Kuzuoka H, 2010, ACMIEEE INT CONF HUM, P285, DOI 10.1109/HRI.2010.5453182
   Lee SC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376609
   Maloney Divine, 2020, VRST '20: 26th ACM Symposium on Virtual Reality Software and Technology, DOI 10.1145/3385956.3418967
   Maznevski ML, 2000, ORGAN SCI, V11, P473, DOI 10.1287/orsc.11.5.473.15200
   Mennecke BE, 2011, DECISION SCI, V42, P413, DOI 10.1111/j.1540-5915.2011.00317.x
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Nembhard IM, 2006, J ORGAN BEHAV, V27, P941, DOI 10.1002/job.413
   O'Conaill B., 1993, Human-Computer Interaction, V8, P389, DOI 10.1207/s15327051hci0804_4
   Pan Y, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1397, DOI 10.1145/2556288.2557276
   Samrose Samiha, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161186
   Shamekhi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173965
   Sprecher S, 2021, J SOC PERS RELAT, V38, P1452, DOI 10.1177/0265407521996055
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Tickle-Degnen Linda, 1990, Psychological Inquiry, V1, P285, DOI DOI 10.1207/S15327965PLI01041
   Traum D., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P766
   VERTEGAAL R, 2002, P 2002 ACM C COMP SU, P41, DOI DOI 10.1145/587078.587085
   Vertegaal R., 2003, ACM CHI, P521, DOI 10.1145/642611.642702
   Whittaker Steve., 2003, Theories and Methods in Mediated Communication
   Yubo Kou, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274363
NR 32
TC 0
Z9 0
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 18
PY 2023
VL 4
AR 1198024
DI 10.3389/frvir.2023.1198024
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA O0YT2
UT WOS:001041171000001
OA gold
DA 2024-07-18
ER

PT J
AU Harris, DJ
   Arthur, T
   Kearse, J
   Olonilua, M
   Hassan, EK
   De Burgh, TC
   Wilson, MR
   Vine, SJ
AF Harris, D. J.
   Arthur, T.
   Kearse, J.
   Olonilua, M.
   Hassan, E. K.
   De Burgh, T. C.
   Wilson, M. R.
   Vine, S. J.
TI Exploring the role of virtual reality in military decision training
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE VR; shoot/don't-shoot; decision making; skill acquisition; cognition
ID CONSTRUCT-VALIDITY; SIMULATION; BENEFITS; THREAT
AB Introduction: Simulation methods, including physical synthetic environments, already play a substantial role in human skills training in many industries. One example is their application to developing situational awareness and judgemental skills in defence and security personnel. The rapid development of virtual reality technologies has provided a new opportunity for performing this type of training, but before VR can be adopted as part of mandatory training it should be subjected to rigorous tests of its suitability and effectiveness.Methods: In this work, we adopted established methods for testing the fidelity and validity of simulated environments to compare three different methods of training use-of-force decision making. Thirty-nine dismounted close combat troops from the UK's Royal Air Force completed shoot/don't-shoot judgemental tasks in: i) live fire; ii) virtual reality; and iii) 2D video simulation conditions. A range of shooting accuracy and decision-making metrics were recorded from all three environments.Results: The results showed that 2D video simulation posed little decision-making challenge during training. Decision-making performance across live fire and virtual reality simulations was comparable but the two may offer slightly different, and perhaps complementary, methods of training judgemental skills.Discussion: Different types of simulation should, therefore, be selected carefully to address the exact training need.
C1 [Harris, D. J.; Arthur, T.; Olonilua, M.; Hassan, E. K.; Wilson, M. R.; Vine, S. J.] Univ Exeter, Sch Publ Hlth & Sport Sci, Exeter, England.
   [Kearse, J.] Newman & Spurr Consulting, Meadows Business Pk, Camberley, England.
   [Olonilua, M.] Def Sci & Technol Lab, Porton Down, Salisbury, England.
   [De Burgh, T. C.] Cineon Training, Exeter Sci Pk Ctr, Exeter, England.
C3 University of Exeter; Defence Science & Technology Laboratory
RP Harris, DJ (corresponding author), Univ Exeter, Sch Publ Hlth & Sport Sci, Exeter, England.
EM d.j.harris@exeter.ac.uk
RI Harris, David/H-9114-2019
OI Harris, David/0000-0003-3880-3856
FU UK's Defence Science and Technology Laboratory
FX This work was supported by funding from the UK's Defence Science and
   Technology Laboratory through SERAPIS MIITTE Lot 5.
CR Alrashidi M, 2023, DISABIL REHABIL, V45, P1773, DOI 10.1080/09638288.2022.2071484
   Armstrong J., 2014, Western Criminology Review, V15, P51
   Bermejo-Berros J, 2021, VIRTUAL REAL-LONDON, V25, P1043, DOI 10.1007/s10055-021-00510-9
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Biggs AT, 2021, Q J EXP PSYCHOL, V74, P812, DOI 10.1177/1747021820985819
   Blacker KJ, 2021, HUM FACTORS, V63, P1141, DOI 10.1177/0018720820916975
   Bright E, 2012, INT J SURG, V10, P163, DOI 10.1016/j.ijsu.2012.02.012
   Green D. M., 1966, SIGNAL DETECTION THE
   Han JN, 2021, J ADV INFORM TECHNOL, V12, P302, DOI 10.12720/jait.12.4.302-310
   Harris D., 2022, PSYARXIV, DOI [10.31234/osf.io/ue58a, DOI 10.31234/OSF.IO/UE58A]
   Harris DJ, 2021, VIRTUAL REAL-LONDON, V25, P961, DOI 10.1007/s10055-021-00501-w
   Harris DJ, 2020, PSYCHOL SPORT EXERC, V50, DOI 10.1016/j.psychsport.2020.101721
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Lele A, 2013, J AMB INTEL HUM COMP, V4, P17, DOI 10.1007/s12652-011-0052-4
   Li WC, 2008, INT J AVIAT PSYCHOL, V18, P135, DOI 10.1080/10508410801926715
   Liu L, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P219, DOI 10.1109/VR.2009.4811026
   Lukosch Heide, 2019, HCI in Games. First International Conference, HCI-Games 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11595), P165, DOI 10.1007/978-3-030-22602-2_14
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P691, DOI 10.1111/jcal.12375
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Nieuwenhuys A, 2015, APPL ERGON, V48, P263, DOI 10.1016/j.apergo.2014.12.006
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   Pan X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146837
   Pan X, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00001
   Perfect P, 2014, AERONAUT J, V118, P953
   Popov Oleksandr., 2021, Systems, Decision and Control in Energy II, P243, DOI [10.1007/978-3-030-69189-914, DOI 10.1007/978-3-030-69189-914]
   Randel JM, 1996, INT J HUM-COMPUT ST, V45, P579, DOI 10.1006/ijhc.1996.0068
   Salas E, 1998, INT J AVIAT PSYCHOL, V8, P197, DOI 10.1207/s15327108ijap0803_2
   Siu KC, 2016, MIL MED, V181, P214, DOI 10.7205/MILMED-D-15-00164
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Staller M.S., 2015, J LAW ENFORCEMENT, V4, P1
   Stoffregen TA, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P111, DOI 10.1201/9781410608888.ch6
   Tabachnick B.G., 2012, Using multivariate statistics, V6th
   Valori I, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0222253
   van Dongen KW, 2007, SURG ENDOSC, V21, P1413, DOI 10.1007/s00464-006-9188-2
   Wijeyaratnam DO, 2019, EXP BRAIN RES, V237, P1431, DOI 10.1007/s00221-019-05515-0
   Williams AM., 2019, Anticipation and Decision Making in Sport, DOI [10.4324/9781315146270, DOI 10.4324/9781315146270]
   Wong K, 2018, AM J OTOLARYNG, V39, P582, DOI 10.1016/j.amjoto.2018.06.021
   Wood G, 2021, VIRTUAL REAL-LONDON, V25, P43, DOI 10.1007/s10055-020-00441-x
   Xeroulis G, 2009, SURG ENDOSC, V23, P161, DOI 10.1007/s00464-008-0120-9
NR 41
TC 5
Z9 5
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 27
PY 2023
VL 4
AR 1165030
DI 10.3389/frvir.2023.1165030
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VA6
UT WOS:001023246900001
OA gold
DA 2024-07-18
ER

PT J
AU De Witte, NAJ
   Buelens, F
   Debard, G
   Bonroy, B
   Standaert, W
   Tarnogol, F
   Van Daele, T
AF De Witte, Nele A. J.
   Buelens, Fien
   Debard, Glen
   Bonroy, Bert
   Standaert, Wout
   Tarnogol, Fernando
   Van Daele, Tom
TI Handheld or head-mounted? An experimental comparison of the potential of
   augmented reality for animal phobia treatment using smartphone and
   HoloLens 2
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE specific phobia; arachnophobia; anxiety disorders; augmented realitiy;
   head-mounted display (HMD); exposure therapy
ID IN-VIVO EXPOSURE; VIRTUAL-REALITY; ANXIETY DISORDERS; FEAR; THERAPY;
   SPIDERS; IMPACT
AB Exposure therapy is an effective treatment for specific phobia that could be further enhanced through Augmented Reality, a novel technology that can facilitate implementation of gradual exposure and promote treatment acceptability. Effective exposure interventions require stimuli evoking high levels of anxiety. Therefore, it is important to ascertain whether animals can induce anxiety in distinct Augmented Reality modalities, such as Head-Mounted Displays and smartphones, which can differ in user experience and technological embodiment. This study compared the anxiety inducing potential and experienced realism of a spider within the HoloLens 2 Augmented Reality headset and an Augmented Reality smartphone application. Sixty-five participants were exposed to a virtual spider in a 5-step Behavioral Approach Task through both the HoloLens 2 head-mounted display and the PHOBOS Augmented Reality smartphone application. Participants reported Subjective Units of Distress at each step and physiological arousal was measured using heart rate and Skin Conductance. Results show that both technological modalities induced self-reported anxiety for spiders in a Behavioral Approach Task task in a non-clinical sample. The Hololens 2 modality was also related to an skin conductance (SC) increase. Perceived realism did not differ between modalities but was associated with increased anxiety in the HoloLens 2 modality. Findings demonstrate that both implemented modalities have potential for enabling Augmented Reality Exposure Therapy, although the role of experienced realism merits additional investigation. Future research should assess the effectiveness of Augmented Reality Exposure Therapy in clinical samples and assess whether new extended reality modalities, such as passthrough virtual reality, could accommodate observed limitations and improve Augmented Reality Exposure Therapy experiences and outcomes.
C1 [De Witte, Nele A. J.; Buelens, Fien; Van Daele, Tom] Thomas More Univ Appl Sci, Expertise Unit Psychol, Technol & Soc, Antwerp, Belgium.
   [Debard, Glen; Bonroy, Bert] Thomas More Univ Appl Sci, Mobilab & Care, Geel, Belgium.
   [Standaert, Wout] Spatial Effects, Antwerp, Belgium.
   [Tarnogol, Fernando] PHOBOS AR, Buenos Aires, Argentina.
RP De Witte, NAJ (corresponding author), Thomas More Univ Appl Sci, Expertise Unit Psychol, Technol & Soc, Antwerp, Belgium.
EM Nele.dw@thomasmore.be
RI Van Daele, Tom/AAF-2373-2020
OI Van Daele, Tom/0000-0001-9237-9297; Bonroy, Bert/0000-0002-7147-5025;
   Buelens, Fien/0000-0001-6225-4979; De Witte, Nele A.
   J./0000-0001-6313-7256
CR Albakri G, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031672
   Bandarian-Balooch S, 2015, J BEHAV THER EXP PSY, V47, P138, DOI 10.1016/j.jbtep.2014.12.006
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Botella C, 2011, COMPUT HUM BEHAV, V27, P217, DOI 10.1016/j.chb.2010.07.043
   Botella CM, 2005, CYBERPSYCHOL BEHAV, V8, P162, DOI 10.1089/cpb.2005.8.162
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Bouchard S, 2014, SER ANXIETY RELAT DI, P91, DOI 10.1007/978-1-4899-8023-6_5
   Bretón-López J, 2010, CYBERPSYCH BEH SOC N, V13, P705, DOI 10.1089/cyber.2009.0170
   Choy Y, 2007, CLIN PSYCHOL REV, V27, P266, DOI 10.1016/j.cpr.2006.10.002
   Craske MG, 2014, BEHAV RES THER, V58, P10, DOI 10.1016/j.brat.2014.04.006
   De Witte NAJ, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.754337
   De Witte NAJ, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00008
   Dibbets P, 2022, COMPUT HUM BEHAV REP, V6, DOI 10.1016/j.chbr.2022.100201
   Diemer J, 2014, WORLD J BIOL PSYCHIA, V15, P427, DOI 10.3109/15622975.2014.892632
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   FOA EB, 1986, PSYCHOL BULL, V99, P20, DOI 10.1037/0033-2909.99.1.20
   Gadermann AM, 2012, DEPRESS ANXIETY, V29, P797, DOI 10.1002/da.21924
   Garcia-Palacios A, 2007, CYBERPSYCHOL BEHAV, V10, P722, DOI 10.1089/cpb.2007.9962
   Garcia-Palacios A, 2001, CYBERPSYCHOL BEHAV, V4, P341, DOI 10.1089/109493101300210231
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Healey A, 2017, J ANXIETY DISORD, V49, P12, DOI 10.1016/j.janxdis.2017.03.005
   Hentati A, 2021, INTERNET INTERV, V26, DOI 10.1016/j.invent.2021.100448
   Hillmann C., 2021, UX for XR: User Experience Design and Strategies for Immersive Technologies, DOI DOI 10.1007/978-1-4842-7020-2
   Hughes CL, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.602954
   Juan MC, 2005, IEEE COMPUT GRAPH, V25, P31, DOI 10.1109/MCG.2005.143
   Kurscheidt M., 2019, IEEE INT C HEALTHC I, P1, DOI [10.1109/ICHI.2019.8904800, DOI 10.1109/ICHI.2019.8904800]
   MAHMOUDI-NEJAD A., 2021, P AAAI C ART INT INT, V17, P164
   Maier SF, 2005, NEUROSCI BIOBEHAV R, V29, P829, DOI 10.1016/j.neubiorev.2005.03.021
   Muris P, 1996, J BEHAV THER EXP PSY, V27, P241, DOI 10.1016/S0005-7916(96)00022-5
   Oosterink FMD, 2009, EUR J ORAL SCI, V117, P135, DOI 10.1111/j.1600-0722.2008.00602.x
   Orús C, 2021, INT J HOSP MANAG, V98, DOI 10.1016/j.ijhm.2021.103019
   OST LG, 1989, BEHAV RES THER, V27, P1, DOI 10.1016/0005-7967(89)90113-7
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Premkumar P, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.694610
   Ramtohul I, 2015, HEALTH POLICY TECHN, V4, P286, DOI 10.1016/j.hlpt.2015.04.007
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Suso-Ribera C, 2019, CYBERPSYCH BEH SOC N, V22, P31, DOI 10.1089/cyber.2017.0672
   SZYMANSKI J, 1995, J BEHAV THER EXP PSY, V26, P31, DOI 10.1016/0005-7916(94)00072-T
   Tarnogol F. M., 2018, PHOBOS AR VERSION 1
   Toffolo Marieke B J, 2022, PLoS One, V17, pe0271175, DOI 10.1371/journal.pone.0271175
   van Uijen SL, 2015, J EXP PSYCHOPATHOL, V6, P112, DOI 10.5127/jep.042014
   Wrzesien M., 2011, P HUM COMP INT INTER, V6946, DOI [10.1007/978-3-642-23774-4, DOI 10.1007/978-3-642-23774-4]
   Zimmer A, 2021, J ANXIETY DISORD, V82, DOI 10.1016/j.janxdis.2021.102442
NR 43
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 16
PY 2022
VL 3
AR 1066996
DI 10.3389/frvir.2022.1066996
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WF4
UT WOS:001023277900001
OA gold
DA 2024-07-18
ER

PT J
AU Quero, S
   Diaz-Garcia, A
   Fernández-Buendía, S
   Molés, M
   Tur, C
   Castilla, D
   Cuijpers, P
   Botella, C
AF Quero, Soledad
   Diaz-Garcia, Amanda
   Fernandez-Buendia, Sara
   Moles, Mar
   Tur, Cintia
   Castilla, Diana
   Cuijpers, Pim
   Botella, Cristina
TI Efficacy of a between-session homework component delivered digitally for
   the treatment of adjustment disorders: Results from a pilot randomized
   clinical trial
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE adjustment disorder; between-session homework; internet-based therapy;
   CBT; virtual reality; efficacy; acceptability
ID COGNITIVE-BEHAVIORAL THERAPY; STRESS-RELATED DISORDERS; VIRTUAL-REALITY;
   DEPRESSION; PREVALENCE; ADHERENCE; SKILL
AB Background: Adjustment Disorder (AjD) is one of the most frequently diagnosed mental disorders worldwide. However, there is still no treatment of choice for this problem. One of the first treatment programs specifically designed for AjD is the one presented in this study, a CBT protocol that uses Virtual Reality (VR) to improve patients' adherence. Another key aspect to improve treatment outcomes is the use of between-sessions homework. However, little is known about how to increase patient engagement with these tasks. The use of Information and Communication Technologies (ICTs) can help patients to see homework as less demanding and provides greater flexibility. A previous study tested the feasibility of TEO (Online Emotional Therapy), a program to implement online homework during treatment. The aim of this study is to present session-to-session efficacy data from the homework assignment component and the patients' preferences and opinions about this component in both formats (Traditional vs. TEO). Methods: A two-arm pilot randomised clinical trial (RCT) was conducted with 57 patients with AjD. The two groups received the same CBT intervention with VR support, but one group completed homework in the traditional way and the other using TEO. Mood, self-efficacy and positive and negative emotions were measured to test the effect of the homework component in each treatment session. Preferences about the homework format were also assessed before and after treatment. Results: Both types of administration produced significant improvements in mood, self-efficacy and emotional variables after completion of the homework component and before and after each homework session. Effect sizes ranged from small to large, with no differences between groups. Regarding the acceptability of the program, most participants preferred the TEO condition both before starting the treatment and after completing the homework assignment. Overall, participants were satisfied with all homework sessions and found them useful. Again, no significant differences were found between groups. Conclusion: This is the first time that the effect of an online homework program during AjD treatment has been tested. It is proposed that this way of implementing homework could be as effective as the traditional format, but would be preferred by patients.
C1 [Quero, Soledad; Fernandez-Buendia, Sara; Moles, Mar; Tur, Cintia; Botella, Cristina] Univ Jaume 1, Dept Basic, Clin Psychol & Psychobiol, Castellon de La Plana, Spain.
   [Quero, Soledad; Botella, Cristina] CIBER Physiopathol Obes & Nutr CIBERObn, Madrid, Spain.
   [Diaz-Garcia, Amanda] Univ Zaragoza, Dept Psychol & Sociol, Teruel, Spain.
   [Castilla, Diana] Univ Valencia, Dept Personal Evaluat & Psychol Treatment, Valencia, Spain.
   [Cuijpers, Pim] Vrije Univ Amsterdam, Amsterdam Publ Hlth Res Inst, Dept Clin Neuro & Dev Psychol, Amsterdam, Netherlands.
C3 Universitat Jaume I; CIBER - Centro de Investigacion Biomedica en Red;
   CIBEROBN; University of Zaragoza; University of Valencia; Vrije
   Universiteit Amsterdam
RP Quero, S (corresponding author), Univ Jaume 1, Dept Basic, Clin Psychol & Psychobiol, Castellon de La Plana, Spain.; Quero, S (corresponding author), CIBER Physiopathol Obes & Nutr CIBERObn, Madrid, Spain.
EM squero@uji.es
RI Botella, Cristina/F-9230-2010; Cuijpers, Pim/G-1703-2013; Castilla,
   Diana/S-3733-2019
OI Botella, Cristina/0000-0001-8783-6959; Castilla,
   Diana/0000-0002-1631-1220
FU Spanish Ministerio de Ciencia, Innovacion y Universidades [RTI
   2018-100993-B-100]; 2021 Research Promotion Plan at Universitat Jaume I
   [UJI-B2021-47]; CIBEROBN, an initiative of the ISCIII [ISC III CB06
   03/0052]
FX This research was supported by Spanish Ministerio de Ciencia, Innovacion
   y Universidades (Programa Estatal I+D+i RTI 2018-100993-B-100), 2021
   Research Promotion Plan at Universitat Jaume I (UJI-B2021-47), CIBEROBN,
   an initiative of the ISCIII (ISC III CB06 03/0052).
CR Andreu-Mateu S, 2012, BEHAV PSYCHOL, V20, P323
   [Anonymous], 1992, The ICD - 10 classification of mental and behavioural disorders: Clinical descriptions and diagnostic guidelines
   [Anonymous], 2018, International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM)
   [Anonymous], 2000, Diagnostic and Statistical Manual-Text Revision
   Bachem R, 2018, J AFFECT DISORDERS, V227, P243, DOI 10.1016/j.jad.2017.10.034
   Baños RM, 2011, INT J HUM-COMPUT ST, V69, P602, DOI 10.1016/j.ijhcs.2011.06.002
   Baños RM, 2009, BRIT J GUID COUNS, V37, P347, DOI 10.1080/03069880902957064
   Beck A.T., 1979, COGNITIVE THERAPY DE
   Benbow AA, 2019, J ANXIETY DISORD, V61, P18, DOI 10.1016/j.janxdis.2018.06.006
   Botella C., 2008, Psicologia Positiva Aplicada
   Bryant MJ, 1999, COGNITIVE THER RES, V23, P381, DOI 10.1023/A:1018703901116
   Burns DD, 2000, J CONSULT CLIN PSYCH, V68, P46, DOI 10.1037/0022-006X.68.1.46
   Busch AM, 2010, BEHAV MODIF, V34, P310, DOI 10.1177/0145445510373384
   Callan JA, 2021, COGNITIVE THER RES, V45, P287, DOI 10.1007/s10608-020-10159-4
   Callan JA, 2019, BEHAV THER, V50, P285, DOI 10.1016/j.beth.2018.05.010
   Casey P, 2015, J AFFECT DISORDERS, V174, P441, DOI 10.1016/j.jad.2014.12.003
   Chan AW, 2013, ANN INTERN MED, V158, P200, DOI 10.7326/0003-4819-158-3-201302050-00583
   Chan AW, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.e7586
   Cohen J., 1988, STAT POWER ANAL BEHA
   Conklin LR, 2015, BEHAV RES THER, V72, P56, DOI 10.1016/j.brat.2015.06.011
   First MB, 1996, STRUCTURED CLIN INTE, DOI [10.1037/t07827-000, DOI 10.1037/T07827-000]
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Guillén V, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01038
   Haller E, 2021, COGNITIVE THER RES, V45, P224, DOI 10.1007/s10608-020-10136-x
   Kazantzis N, 2000, CLIN PSYCHOL-SCI PR, V7, P189, DOI 10.1093/clipsy/7.2.189
   Kazantzis N, 2010, CLIN PSYCHOL-SCI PR, V17, P144, DOI 10.1111/j.1468-2850.2010.01204.x
   Kazlauskas E, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1421819
   Maercker A, 2012, SOC PSYCH PSYCH EPID, V47, P1745, DOI 10.1007/s00127-012-0493-x
   Mausbach BT, 2010, COGNITIVE THER RES, V34, P429, DOI 10.1007/s10608-010-9297-z
   Michelle Tan Qiao Yi, 2014, 2014 IEEE Global Humanitarian Technology Conference - South Asia Satellite (GHTC-SAS), P135, DOI 10.1109/GHTC-SAS.2014.6967572
   Moher David, 2010, J Clin Epidemiol, V63, pe1, DOI [10.1016/j.ijsu.2011.10.001, 10.1136/bmj.c869, 10.1016/j.jclinepi.2010.03.004]
   NEIMEYER RA, 1990, BEHAV THER, V21, P281, DOI 10.1016/S0005-7894(05)80331-4
   O'Donnell ML, 2018, J TRAUMA STRESS, V31, P321, DOI 10.1002/jts.22295
   O'Donnell ML, 2016, AM J PSYCHIAT, V173, P1231, DOI 10.1176/appi.ajp.2016.16010071
   Perkonigg A, 2018, INT J CLIN HLTH PSYC, V18, P209, DOI 10.1016/j.ijchp.2018.05.001
   Quero S., 2011, J CYBERTHERAPY REHAB, V4, P306
   Quero S, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16203842
   Quero S, 2019, CLIN PSYCHOL PSYCHOT, V26, P204, DOI 10.1002/cpp.2342
   Rachyla I., 2022, THESIS U JAUME I VAL
   Reed GM, 2011, WORLD PSYCHIATRY, V10, P118
   Reger GM, 2013, PSYCHOL SERV, V10, P342, DOI 10.1037/a0032774
   Stirman SW, 2018, BEHAV THER, V49, P741, DOI 10.1016/j.beth.2017.12.001
   Strickland E. L., 2019, THESIS WRIGHT I CALI
   Zelviene P, 2018, NEUROPSYCH DIS TREAT, V14, P375, DOI 10.2147/NDT.S121072
NR 44
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 6
PY 2022
VL 3
AR 937606
DI 10.3389/frvir.2022.937606
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WD5
UT WOS:001023276000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Chang, Z
   Bai, HD
   Zhang, L
   Gupta, K
   He, WP
   Billinghurst, M
AF Chang, Zhuang
   Bai, Huidong
   Zhang, Li
   Gupta, Kunal
   He, Weiping
   Billinghurst, Mark
TI The impact of virtual agents' multimodal communication on brain activity
   and cognitive load in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE intelligent virtual agents; Virtual Reality; multimodal communication;
   EEG; cognitive load
ID EEG-ALPHA; PREFRONTAL CORTEX; SYSTEM; DESYNCHRONIZATION; PERFORMANCE
AB Related research has shown that collaborating with Intelligent Virtual Agents (IVAs) embodied in Augmented Reality (AR) or Virtual Reality (VR) can improve task performance and reduce task load. Human cognition and behaviors are controlled by brain activities, which can be captured and reflected by Electroencephalogram (EEG) signals. However, little research has been done to understand users' cognition and behaviors using EEG while interacting with IVAs embodied in AR and VR environments. In this paper, we investigate the impact of the virtual agent's multimodal communication in VR on users' EEG signals as measured by alpha band power. We develop a desert survival game where the participants make decisions collaboratively with the virtual agent in VR. We evaluate three different communication methods based on a within-subject pilot study: 1) a Voice-only Agent, 2) an Embodied Agent with speech and gaze, and 3) a Gestural Agent with a gesture pointing at the object while talking about it. No significant difference was found in the EEG alpha band power. However, the alpha band ERD/ERS calculated around the moment when the virtual agent started speaking indicated providing a virtual body for the sudden speech could avoid the abrupt attentional demand when the agent started speaking. Moreover, a sudden gesture coupled with the speech induced more attentional demands, even though the speech was matched with the virtual body. This work is the first to explore the impact of IVAs' interaction methods in VR on users' brain activity, and our findings contribute to the IVAs interaction design.
C1 [Chang, Zhuang; Bai, Huidong; Gupta, Kunal; Billinghurst, Mark] Univ Auckland, Auckland Bioengn Inst, Empath Comp Lab, Auckland, New Zealand.
   [Zhang, Li; He, Weiping] Northwestern Polytech Univ, Cyber Phys Interact Lab, Xian, Peoples R China.
C3 University of Auckland; Northwestern Polytechnical University
RP Chang, Z (corresponding author), Univ Auckland, Auckland Bioengn Inst, Empath Comp Lab, Auckland, New Zealand.
EM zcha621@aucklanduni.ac.nz
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Chang,
   Zhuang/0000-0003-0972-0752
FU China Scholarship Council [202008320270]
FX Funding This paper is sponsored by the China Scholarship Council (CSC
   NO. 202008320270).
CR Antonenko P, 2010, EDUC PSYCHOL REV, V22, P425, DOI 10.1007/s10648-010-9130-y
   Behrmann M, 2004, CURR OPIN NEUROBIOL, V14, P212, DOI 10.1016/j.conb.2004.03.012
   Buckner RL, 1996, SEMIN NEUROSCI, V8, P47, DOI 10.1006/smns.1996.0007
   de Melo CM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.554706
   Dey A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P220, DOI [10.1109/vr.2019.8797840, 10.1109/VR.2019.8797840]
   Fink A, 2018, NEUROPSYCHOLOGIA, V114, P118, DOI 10.1016/j.neuropsychologia.2018.04.025
   Fink A, 2014, NEUROSCI BIOBEHAV R, V44, P111, DOI 10.1016/j.neubiorev.2012.12.002
   Freeman WJ, 2002, BIOCOMP SER, V1, P1
   Gerry L, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188479
   Gevins A., 2003, Theoretical Issues in Ergonomics Science, V4, P113, DOI [DOI 10.1080/14639220210159717, 10.1080/14639220210159717]
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.000-5, 10.1109/VR46266.2020.1581313729558]
   Gupta K, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364276
   Haesler S, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P204, DOI 10.1109/ISMAR-Adjunct.2018.00067
   Hanna N. H., 2016, THESIS MACQUARIE U S
   Hantono BS, 2016, 2016 6TH INTERNATIONAL ANNUAL ENGINEERING SEMINAR (INAES), P150, DOI 10.1109/INAES.2016.7821924
   Harmony T, 1996, INT J PSYCHOPHYSIOL, V24, P161, DOI 10.1016/S0167-8760(96)00053-0
   HART S G, 1988, P139
   Hollender N, 2010, COMPUT HUM BEHAV, V26, P1278, DOI 10.1016/j.chb.2010.05.031
   Holm A, 2009, THESCIENTIFICWORLDJO, V9, P639, DOI 10.1100/tsw.2009.83
   Holz T, 2011, INT J HUM-COMPUT ST, V69, P251, DOI 10.1016/j.ijhcs.2010.10.001
   Jing ALS, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.697367
   Kevin S, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281587
   Kim K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P529, DOI [10.1109/VR46266.2020.00-30, 10.1109/VR46266.2020.1581084624004]
   Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039
   Klimesch W, 1997, INT J PSYCHOPHYSIOL, V26, P319, DOI 10.1016/S0167-8760(97)00773-3
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Klimesch W., 1992, J PSYCHOPHYSIOL, V6, P185
   Kumar N, 2016, PROCEDIA COMPUT SCI, V84, P70, DOI 10.1016/j.procs.2016.04.068
   LANG W, 1988, HUM NEUROBIOL, V6, P295
   Lécuyer A, 2008, COMPUTER, V41, P66, DOI 10.1109/MC.2008.410
   Li CJ, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P191, DOI 10.1145/3267851.3267870
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   MALACH R, 1995, P NATL ACAD SCI USA, V92, P8135, DOI 10.1073/pnas.92.18.8135
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Mustafa M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5098, DOI 10.1145/3025453.3026043
   Norouzi* N., 2019, S SPATIAL USER INTER, P1, DOI DOI 10.1007/978-3-030-04110-61
   Norouzi N., 2020, INT C ARTIFICIAL REA, P101
   Norouzi N, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P17, DOI 10.1145/3267851.3267901
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Paas F, 2003, EDUC PSYCHOL, V38, P1, DOI 10.1207/S15326985EP3801_1
   Paas F, 2004, INSTR SCI, V32, P1, DOI 10.1023/B:TRUC.0000021806.17516.d0
   Pimentel D, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.634520
   Ramchurn SD, 2016, AUTON AGENT MULTI-AG, V30, P82, DOI 10.1007/s10458-015-9286-4
   Reinhardt J, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P299, DOI 10.1145/3374920.3374956
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Stipacek A, 2003, NEUROSCI LETT, V353, P193, DOI 10.1016/j.neulet.2003.09.044
   Suzuki Y, 2015, SCI REP-UK, V5, DOI 10.1038/srep15924
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Teplan M., 2002, Measurement science review, V2, DOI DOI 10.1021/PR070350L
   Waltz JA, 1999, PSYCHOL SCI, V10, P119, DOI 10.1111/1467-9280.00118
   Wandell BA, 2007, NEURON, V56, P366, DOI 10.1016/j.neuron.2007.10.012
   Wang I, 2021, INT J HUM-COMPUT INT, V37, P1648, DOI 10.1080/10447318.2021.1898851
   Wang I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300511
   Ye ZM, 2021, INT SYM MIX AUGMENT, P239, DOI 10.1109/ISMAR52148.2021.00039
   Zhang L, 2017, IEEE T AFFECT COMPUT, V8, P176, DOI 10.1109/TAFFC.2016.2582490
   Zijlstra F.R.H., 1985, CONSTRUCTION SCALE M
NR 59
TC 3
Z9 3
U1 2
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 29
PY 2022
VL 3
AR 995090
DI 10.3389/frvir.2022.995090
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0IX0
UT WOS:001020187000001
OA gold
DA 2024-07-18
ER

PT J
AU Crolla, K
   Goepel, G
AF Crolla, Kristof
   Goepel, Garvin
TI Entering hyper-reality: "Resonance-In-Sight," a mixed-reality art
   installation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE co-virtual; city design; participatory; XR realities; metaverse
AB Enhanced virtual communicative technologies extend human perception in extraordinary ways that junction in detaching or augmenting its operator from physical reality. Prospects of the metaverse are progressing towards a possibly fully immersive cyberspace in which users will be entirely disconnected from their analogue physical surroundings. As we advance towards such an alternative reality, the practice-based research project discussed in this paper, titled "Resonance-In-Sight," foresees and demonstrates the near-future of the metaverse to be a blended hyper-reality in which fiction and reality seamlessly blend into a "Mixed Reality" (MR)-based, co-urban design environment. As digital content in such an environment creatively coexists with our physical cityscape, the research question posed by this project is how such media environment can be used as a proactive cultural educational tool to engage with and inform user audiences of otherwise challenging art-historical content. Through this demonstrator project, the article discusses and reflects on applied methods for user experience (UX) design and the development of MR mobile applications for effective mixed-reality installations. It further reports on employed "Simultaneous Localisation And Mapping" (SLAM) techniques, which are essential for merging co-virtual design content in a hybrid metaverse, and concludes with an assessment of the project's community impact from an analysis of available user data.
C1 [Crolla, Kristof] Univ Hong Kong, Dept Architecture, Bldg Simplex Lab, Pokfulam, Hong Kong, Peoples R China.
   [Goepel, Garvin] Chinese Univ Hong Kong, Sch Architecture, Shatin, Hong Kong, Peoples R China.
C3 University of Hong Kong; Chinese University of Hong Kong
RP Crolla, K (corresponding author), Univ Hong Kong, Dept Architecture, Bldg Simplex Lab, Pokfulam, Hong Kong, Peoples R China.
EM kcrolla@hku.hk
CR Acute Art, 2022, AC ART APP VIRT REAL
   Apple, 2022, APP STOR
   Apple Developer, 2021, AUGMENTED REALITY
   Art For Everyone, 2021, ABOUT US
   Artefact, 2019, MUMOK AR APP
   Bala S., 2022, CNBC
   Baudrillard, 1983, SIMULATIONS
   Belitskaja Sasha., 2021, BLOB HOUSE IHEARTBLO
   Bradbury Ray., 1950, VELDT
   Brothers Wachowski, 1999, The Matrix
   Choy Gigi., 2022, BARS GYMS CLOSE 6PM
   Dick Philip K., 1953, TROUBLE BUBBLES
   Gibson W., 1984, NEUROMANCER
   Goepel Garvin., 2022, SELF COMPASS
   Google, 2022, ANDR APPS GOOGL PLA
   Google Developers, 2021, BUILD NEW AUGM REAL
   HKMoA, 2022, MISS STAT
   HKMoA, 2019, FLAGST HOUS MUS TEA
   HKMoA, 2022, HOME
   Joy Aether LtD, 2022, RIS HKMOA
   King B., 2016, Augmented: Life in the smart lane
   Losch Christian Philip., 2021, CINEMA4D
   Matsuda K., 2016, Hyper Reality
   Meta dir., 2021, METAVERSE WELL BUILD
   Rakuten Mobile, 2021, RAK MOB RAK VISS KOB
   Reaume Amanda., 2022, WHAT IS METAVERSE ME
   Ruan QR, 2020, INTENS CARE MED, V46, P846, DOI 10.1007/s00134-020-05991-x
   Schopenhauer Arthur., 1966, WORLD WILL REPRESENT, VI.
   SK telecom dir, 2019, SKTELECOM 5G SK TEL
   Stephenson N., 1992, Snow Crash
   Unity Technologies, 2020, UNITY3D
   Weinbaum S.G., 1935, Pygmalion's Spectacles
NR 32
TC 4
Z9 4
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 21
PY 2022
VL 3
AR 1044021
DI 10.3389/frvir.2022.1044021
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YU0
UT WOS:001023344800001
OA gold
DA 2024-07-18
ER

PT J
AU Houzangbe, S
   Masson, D
   Fleury, S
   Jauregui, DAG
   Legardeur, J
   Richir, S
   Couture, N
AF Houzangbe, Samory
   Masson, Dimitri
   Fleury, Sylvain
   Jauregui, David Antonio Gomez
   Legardeur, Jeremy
   Richir, Simon
   Couture, Nadine
TI Is virtual reality the solution? A comparison between 3D and 2D creative
   sketching tools in the early design process
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE creativity and design thinking; virtual reality; user experience (UX);
   creative experience; digital tools for creativity
ID LEVEL
AB Creativity is key in the early phases of innovation processes. With the rapid evolution of technologies, designers now have access to various tools to support this activity. Virtual reality (VR) takes over multiple domains, especially during conception. However, is VR really facilitating creativity in the initial ideation phases? We compare two sketching modalities through dedicated creativity support tools (CSTs): one in VR and one on a 2D interactive whiteboard. We propose a two-part creativity task (divergent and convergent thinking) for two groups of 30 participants each. We record user experience, creative experience, and creative performance. Our results show that VR is more stimulating, attractive, and engaging. We also observe a better level of creativity for the participants using the VR CST. Our results indicate that VR is an effective and relevant tool to boost creativity and that this effect might carry over to following creative tasks.
C1 [Houzangbe, Samory; Fleury, Sylvain; Richir, Simon] HESAM Univ, Arts & Metiers Inst Technol, Lab Angevin Mecan Procedes & innovAt, Change, France.
   [Houzangbe, Samory; Masson, Dimitri; Jauregui, David Antonio Gomez; Legardeur, Jeremy; Couture, Nadine] Univ Bordeaux, ESTIA Inst Technol, Bidart, France.
C3 heSam Universite; Universite de Bordeaux
RP Houzangbe, S (corresponding author), HESAM Univ, Arts & Metiers Inst Technol, Lab Angevin Mecan Procedes & innovAt, Change, France.; Houzangbe, S (corresponding author), Univ Bordeaux, ESTIA Inst Technol, Bidart, France.
EM houzangbe@gmail.com
RI Masson, Masson/HKM-8563-2023
OI Masson, Masson/0000-0002-7072-3146; Couture, Nadine/0000-0001-7959-5227
FU Institut Carnot ARTS
FX This project was funded through the Institut Carnot ARTS research grant
   campaign of 2020.
CR Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Benedek M, 2012, PSYCHOL AESTHET CREA, V6, P273, DOI 10.1037/a0027059
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Buxton B., 2007, SKETCHING USER EXPER
   Calderon-Hernandez C, 2019, COMPUTING IN CIVIL ENGINEERING 2019: VISUALIZATION, INFORMATION MODELING, AND SIMULATION, P17
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   De Dreu CKW, 2008, J PERS SOC PSYCHOL, V94, P739, DOI 10.1037/0022-3514.94.5.739
   Drey T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376628
   Feeman Seth M., 2018, Computer-Aided Design and Applications, V15, P892, DOI 10.1080/16864360.2018.1462570
   Fillingim KB, 2021, AI EDAM, V35, P99, DOI 10.1017/S0890060420000529
   Fleury S, 2021, THINK SKILLS CREAT, V40, DOI 10.1016/j.tsc.2021.100828
   Fleury S, 2021, DIGIT CREAT, V32, P116, DOI 10.1080/14626268.2021.1915339
   Fleury S, 2020, THINK SKILLS CREAT, V36, DOI 10.1016/j.tsc.2020.100661
   Frich J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300619
   Gallagher C.L., 2017, P OF THE 2017 CHI C, P106, DOI DOI 10.1145/3027063.3048424
   Guilford J.P., 1966, Theory into Practice: Creativity, V5, P186, DOI [10.1080/00405846609542023, DOI 10.1080/00405846609542023]
   Guilford J.P., 1967, The nature of human intelligence
   Hao N, 2017, ACTA PSYCHOL, V173, P32, DOI 10.1016/j.actpsy.2016.12.005
   Hartson R., 2012, The UX Book: Process and Guidelines for Ensuring a Quality User Experience
   Hassenzahl M., 2003, AttrakDiff: Ein FragebogenZur Messung Wahrgenommener Hedonischer Und Pragmatischer Qual-itat, P187, DOI [DOI 10.1007/978-3-322-80058-9_19, 10.1007/978-3-322-80058-9_19]
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hu X., 2021, Interactions, V28, P57, DOI [10.1145/3460114, DOI 10.1145/3460114]
   Jetter HC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376652
   Kelley T., 2013, Creative confidence: Unleashing the creative potential within us all, VFirst
   Kulkarni Chinmay., 2014, Early and repeated exposure to examples improves creative work, P49, DOI DOI 10.1007/978-3-319-01303-9_4
   Lallemand C., 2015, Eur Rev Appl Psychol, V65, P239, DOI [10.1016/j.erap.2015.08, DOI 10.1016/J.ERAP.2015.08, 10.1016/j.erap.2015.08.002]
   Lee J. H., 2020, ACM SIGGRAPH 2020 LA, DOI [10.1145/3388763.3407759, DOI 10.1145/3388763.3407759]
   Lee JH, 2021, DES J, V24, P503, DOI 10.1080/14606925.2021.1912902
   Lin Y., 2020, IT IS YOUR TURN COLL, V1-14
   Lubart T.I., 2015, PSYCHOL CREATIVITE
   MacGregor JN, 2009, J PROBL SOLVING, V2, P130, DOI 10.7771/1932-6246.1062
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Marsh RL, 1996, MEM COGNITION, V24, P669, DOI 10.3758/BF03201091
   Mille C., 2020, 4 INT C COMP HUM INT
   OKUDA SM, 1991, J PSYCHOEDUC ASSESS, V9, P45, DOI 10.1177/073428299100900104
   TAFT R, 1966, PSYCHOL REP, V19, P1313, DOI 10.2466/pr0.1966.19.3f.1313
   Torrance E.P., 1974, Torrance Tests of Creative Thinking-Norms Technical Manual Research Edition-Verbal tests, Forms A and B-Figural tests, Forms A and B
   UK Design Council, 2005, DOUBL DIAM PROC MOD
   Wilson JR, 1999, APPL ERGON, V30, P3, DOI 10.1016/S0003-6870(98)00040-4
   Yang EK, 2020, DIGIT CREAT, V31, P82, DOI 10.1080/14626268.2020.1726964
   Yang XZ, 2018, ETR&D-EDUC TECH RES, V66, P1231, DOI 10.1007/s11423-018-9604-z
   Yee N., 2006, P PRESENCE 2006 9 AN
NR 44
TC 4
Z9 4
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 31
PY 2022
VL 3
AR 958223
DI 10.3389/frvir.2022.958223
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WC6
UT WOS:001023275100001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Lacoche, J
   Villain, E
   Foulonneau, A
AF Lacoche, Jeremy
   Villain, Eric
   Foulonneau, Anthony
TI Evaluating Usability and User Experience of AR Applications in VR
   Simulation
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; virtual reality; simulation; user experience;
   usability testing
AB Validating an augmented reality application in a virtual reality simulation can offer many advantages compared to testing in real conditions and can speed up development processes. With such a simulation, developers and designers do not need to have constant physical access to the real place. They can save physical navigation, experiment with different kinds of devices and isolate testing parameters. While the validity of functional testing in virtual reality simulations is not particularly challenged, the validity of such simulations to evaluate user experience and usability, similarly as in real conditions, still needs to be assessed. We then conducted a user study to explore the validity of evaluating these criteria with a virtual reality simulation tool and the importance of simulation fidelity for that purpose. Indeed, we also seek to determine whether it is necessary to simulate the limited field of view of augmented reality glasses and if the simulation can take place in a virtual world that is not a replica of the real targeted environment. To do so, we have developed an augmented reality application for smart-homes where a user can interact with different connected objects. One group of users performed the experiment in the real place with augmented reality glasses and three other groups performed the same experiment in virtual reality with various simulation conditions (field of view and environment). Users' subjective feedback and quantitative results only highlight very few differences between real-world conditions and simulation in virtual reality, whatever the simulation parameters used. These results suggest the interest in using virtual reality simulation to evaluate an augmented reality application but should be confirmed on other use cases and interaction tasks.
C1 [Lacoche, Jeremy; Villain, Eric; Foulonneau, Anthony] Orange Innovat, Paris, France.
RP Lacoche, J (corresponding author), Orange Innovat, Paris, France.
EM jeremy.lacoche@orange.com
CR Arthur JJT, 2007, PROC SPIE, V6559, DOI 10.1117/12.719695
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Brauns Sarah, 2021, Virtual, Augmented and Mixed Reality. 13th International Conference, VAMR 2021 Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings, P288, DOI 10.1007/978-3-030-77599-5_21
   Choi H., 2019, VIRTUAL, P3, DOI DOI 10.1007/978-3-030-21607-8_1
   Ellis SR, 1997, P IEEE VIRT REAL ANN, P138, DOI 10.1109/VRAIS.1997.583063
   Gaffary Y, 2017, IEEE T VIS COMPUT GR, V23, P2372, DOI 10.1109/TVCG.2017.2735078
   Grandi JG, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P23, DOI 10.1109/VRW52623.2021.00011
   HART S G, 1988, P139
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Lee C, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P77, DOI 10.1109/VR.2012.6180890
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lee C, 2009, INT SYM MIX AUGMENT, P203, DOI 10.1109/ISMAR.2009.5336464
   Martins VF, 2015, LECT NOTES COMPUT SC, V9179, P39, DOI 10.1007/978-3-319-21067-4_5
   Pfeiffer Thies, 2018, i-com: Journal of Interactive Media, V17, P179, DOI 10.1515/icom-2018-0025
   Pfeiffer-Lessmann N, 2018, COMM COM INF SC, V851, P311, DOI 10.1007/978-3-319-92279-9_42
   Ragan E, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P287, DOI 10.1109/VR.2009.4811058
   Regenbrecht H, 2021, Arxiv, DOI arXiv:2103.02831
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Soedji B., 2020, 26 ACM S VIRTUAL REA, P1, DOI [10.1145/3385956.3422088, DOI 10.1145/3385956.3422088]
   Terrier R, 2018, LECT NOTES COMPUT SC, V11162, P190, DOI 10.1007/978-3-030-01790-3_12
   Tiefenbacher Philipp, 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P226, DOI 10.1007/978-3-319-07458-0_22
   Ventura Jonathan., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, VRST '09, P151, DOI DOI 10.1145/1643928.1643963
   Wallergard, 2015, INT J VIRTUAL WORLDS, DOI [10.11159/vwhci.2015.003, DOI 10.11159/VWHCI.2015.003]
NR 25
TC 4
Z9 4
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 18
PY 2022
VL 3
AR 881318
DI 10.3389/frvir.2022.881318
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VR6
UT WOS:001019165000001
OA gold
DA 2024-07-18
ER

PT J
AU Moraga, FRG
   Tuente, SK
   Perrin, S
   Enebrink, P
   Sygel, K
   Veling, W
   Wallinius, M
AF Moraga, Fernando Renee Gonzalez
   Tuente, Stephanie Klein
   Perrin, Sean
   Enebrink, Pia
   Sygel, Kristina
   Veling, Wim
   Wallinius, Marta
TI New Developments in Virtual Reality-Assisted Treatment of Aggression in
   Forensic Settings: The Case of VRAPT
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE aggression; virtual reality; forensic settings; VRAPT; treatment of
   aggression; forensic psychiatry
ID PSYCHIATRIC-PATIENTS; HOSTILITY; BEHAVIOR; VIOLENCE; THERAPY
AB Aggression is a known problem in individuals being cared for in forensic settings, yet the evidence base for its treatment is scarce. Virtual Reality (VR) has been proposed as a promising addition to interventions in forensic settings, as it may increase the motivation among participants, bridge the gap between real life, therapeutic and laboratory experiences, and increase the ecological validity of psychological research. Recently, a new treatment for aggression using VR as the treatment environment, Virtual Reality Aggression Prevention Training (VRAPT), was developed to provide realistic and safe environments for participants to practice aggression management. In its current revised version, VRAPT is conceptualized as a form of cognitive behavioral therapy with its theoretical background in the General Aggression Model. Its purpose is to increase awareness of, and improve control over, one's own aggression and that of others through social interactions in individually tailored virtual environments. This manuscript describes how the lessons learned from the first randomized controlled trial of VRAPT have been applied to further develop the method and discusses challenges and future directions for VR-assisted treatment of aggression in forensic settings. VRAPT is a new psychological treatment for aggression and the coming years will provide expanded scientific evidence for further developments and adaptations.
C1 [Moraga, Fernando Renee Gonzalez; Tuente, Stephanie Klein; Sygel, Kristina; Wallinius, Marta] Reg Forens Psychiat Clin, Res Dept, Vaxjo, Sweden.
   [Moraga, Fernando Renee Gonzalez; Tuente, Stephanie Klein; Wallinius, Marta] Lund Univ, Dept Clin Sci Lund, Lund Clin Res Externalizing & Dev Psychopathol, Child & Adolescent Psychiat, Lund, Sweden.
   [Moraga, Fernando Renee Gonzalez; Tuente, Stephanie Klein; Sygel, Kristina; Wallinius, Marta] Univ Gothenburg, Inst Neurosci & Physiol, Ctr Eth Law & Mental Hlth, Sahlgrenska Acad, Gothenburg, Sweden.
   [Perrin, Sean] Lund Univ, Dept Psychol, Lund, Sweden.
   [Enebrink, Pia] Karolinska Inst, Dept Clin Neurosci, Div Psychol, Stockholm, Sweden.
   [Sygel, Kristina] Natl Board Forens Med, Dept Forens Psychiat, Stockholm, Sweden.
   [Veling, Wim] Univ Groningen, Univ Med Ctr Groningen, Dept Psychiat, Groningen, Netherlands.
C3 Lund University; University of Gothenburg; Lund University; Karolinska
   Institutet; Swedish National Board of Forensic Medicine; University of
   Groningen
RP Moraga, FRG (corresponding author), Reg Forens Psychiat Clin, Res Dept, Vaxjo, Sweden.; Moraga, FRG (corresponding author), Lund Univ, Dept Clin Sci Lund, Lund Clin Res Externalizing & Dev Psychopathol, Child & Adolescent Psychiat, Lund, Sweden.; Moraga, FRG (corresponding author), Univ Gothenburg, Inst Neurosci & Physiol, Ctr Eth Law & Mental Hlth, Sahlgrenska Acad, Gothenburg, Sweden.
EM fernando_renee.gonzalez_moraga@med.lu.se
RI Perrin, Sean/F-7723-2010
OI Perrin, Sean/0000-0002-5468-4706; Gonzalez Moraga, Fernando
   Renee/0000-0003-2439-334X
FU Swedish Research Council for Health, Working Life and Welfare
   [2018-01409]; Southern Healthcare Region in Sweden [933868]; Region
   Kronoberg [936434]
FX This work was supported by the Swedish Research Council for Health,
   Working Life and Welfare under Grant No. 2018-01409, by the Southern
   Healthcare Region in Sweden (No. 933868), and by Region Kronoberg (No.
   936434).
CR Anderson C. A., 2004, The social psychology of good and evil, P168
   Anderson CA, 2002, ANNU REV PSYCHOL, V53, P27, DOI 10.1146/annurev.psych.53.100901.135231
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   [Anonymous], 2011, BEHANDLINGSPROGRAMME
   Appelbaum PS, 2012, CLIN TRIALS, V9, P765, DOI 10.1177/1740774512464312
   Appelbaum PS, 2012, CLIN TRIALS, V9, P748, DOI 10.1177/1740774512456455
   Barlett CP, 2011, PERS SOC PSYCHOL B, V37, P1564, DOI 10.1177/0146167211423671
   Benbouriche M, 2014, P VIRT REAL INT C LA, P1
   Bogaerts S, 2012, J FORENSIC PSYCHOL P, V12, P147, DOI 10.1080/15228932.2012.650144
   Brännström L, 2016, AGGRESS VIOLENT BEH, V27, P30, DOI 10.1016/j.avb.2016.02.006
   Brunner F, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00142
   CRICK NR, 1994, PSYCHOL BULL, V115, P74, DOI 10.1037/0033-2909.115.1.74
   Dack C, 2013, ACTA PSYCHIAT SCAND, V127, P255, DOI 10.1111/acps.12053
   DeWall CN, 2011, PSYCHOL VIOLENCE, V1, P245, DOI 10.1037/a0023842
   Dixon LB, 2016, WORLD PSYCHIATRY, V15, P13, DOI 10.1002/wps.20306
   European Science Foundation and All European Academies, 2011, EUR COD COND RES INT
   Falk Ö, 2014, SOC PSYCH PSYCH EPID, V49, P559, DOI 10.1007/s00127-013-0783-y
   Filov Izabela, 2019, Open Access Maced J Med Sci, V7, P657, DOI 10.3889/oamjms.2019.146
   Fromberger P, 2014, NERVENARZT, V85, P298, DOI 10.1007/s00115-013-3904-7
   Fromberger P, 2018, BEHAV SCI LAW, V36, P235, DOI 10.1002/bsl.2332
   Goldstein A., 1998, Aggression Replacement Training: A comprehensive intervention for aggressive youth
   Griskevicius V, 2009, J PERS SOC PSYCHOL, V96, P980, DOI 10.1037/a0013907
   Hoeffler A, 2017, POLIT PHILOS ECON, V16, P422, DOI 10.1177/1470594X17714270
   Hoogsteder LM, 2014, INT J FORENSIC MENT, V13, P25, DOI 10.1080/14999013.2014.893711
   Hornsveld RHJ, 2008, PSYCHOL CRIME LAW, V14, P1, DOI 10.1080/10683160701340569
   Howner K, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00452
   Kip H, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00042
   Kisker J, 2021, CURR PSYCHOL, V40, P3190, DOI 10.1007/s12144-019-00257-2
   Lee AH, 2018, CURR OPIN PSYCHOL, V19, P65, DOI 10.1016/j.copsyc.2017.04.004
   Lewis M, 2019, J FORENSIC PSYCHI PS, V30, P496, DOI 10.1080/14789949.2019.1570541
   Lobbestael J, 2015, PSYCHIAT RES, V229, P155, DOI 10.1016/j.psychres.2015.07.052
   Mikton CR, 2016, AM J PREV MED, V50, P652, DOI 10.1016/j.amepre.2015.10.007
   Mooney JL, 2015, PSYCHOL CRIME LAW, V21, P314, DOI 10.1080/1068316X.2014.989163
   Moraga FRG, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00984
   Mundt AP, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00804
   Munthe C, 2010, BIOETHICS, V24, P35, DOI 10.1111/j.1467-8519.2009.01773.x
   Needham I, 2004, J Psychiatr Ment Health Nurs, V11, P595, DOI 10.1111/j.1365-2850.2004.00767.x
   Papalia N, 2019, CLIN PSYCHOL-SCI PR, V26, DOI 10.1111/cpsp.12282
   Renaud P, 2005, ANN REV CYBERTHERAPY, V3, P85
   Renaud P, 2014, VIRTUAL REAL-LONDON, V18, P37, DOI 10.1007/s10055-013-0235-8
   Rizzo A. S., 2019, Virtual reality for psychological and neurocognitive interventions
   Schippers EE, 2020, J FORENSIC SCI, V65, P2058, DOI 10.1111/1556-4029.14539
   Sestir M.A., 2007, Aggressive offenders' cognition: Theory, research and practice, P157
   Shapiro D.L., 2016, ETHICS MED PUBLIC HL, V2, P45, DOI DOI 10.1016/J.JEMEP.2016.01.015
   Smeijers D, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00083
   Smeijers D, 2018, INT J OFFENDER THER, V62, P3834, DOI 10.1177/0306624X17747052
   Sygel K, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.673089
   Tapscott JL, 2012, CRIM JUSTICE BEHAV, V39, P202, DOI 10.1177/0093854811429647
   Tuente SK, 2020, J CLIN MED, V9, DOI 10.3390/jcm9072258
   Tuente SK, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-018-1830-8
   Vllm B., 2016, ETHICS MED PUBLIC HL, V2, P36, DOI [10.1016/j.jemep.2016.01.005, DOI 10.1016/J.JEMEP.2016.01.005]
   Warburton W.A., 2015, INT ENCY SOCIAL BEHA, V1, P373, DOI [10.1016/B978-0-08-097086-8.24002-6, DOI 10.1016/B978-0-08-097086-8.24002-6]
   Watt B.D., 1999, LEGAL CRIMINOL PSYCH, V4, P285, DOI DOI 10.1348/135532599167914
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
NR 54
TC 5
Z9 5
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 11
PY 2022
VL 2
AR 675004
DI 10.3389/frvir.2021.675004
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2QD0
UT WOS:001021746600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Bui, J
   Luauté, J
   Farnè, A
AF Bui, Julie
   Luaute, Jacques
   Farne, Alessandro
TI Enhancing Upper Limb Rehabilitation of Stroke Patients With Virtual
   Reality: A Mini Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE stroke; upper limb; rehabilitation; virtual reality therapy;
   naturalistic
ID UPPER EXTREMITY FUNCTION; FUNCTIONAL RECOVERY; MOTOR RECOVERY
AB Upper limb motor impairment following stroke is a common condition that impacts significantly the independence and quality of life of stroke survivors. In recent years, scholars have massively turned to virtual reality (VR) to develop more effective rehabilitation approaches. VR systems are promising tools that can help patients engage in intensive, repetitive and task-oriented practice using new technologies to promote neuroplasticity and recovery. Multiple studies have found significant improvements in upper limb function for patients using VR in therapy, but the heterogeneity of methods and tools employed make the assessment of VR efficacy difficult. Here we aimed to assess the potential of VR as a therapy tool for upper limb motor impairment and to provide initial assessment of what is the added value of using VR to both patients and clinicians. Our mini-review focuses the work published since the Cochrane review (2017) and suggests that VR may be particularly effective when used in combination to conventional rehabilitation approaches. We also highlight key features integrated in VR systems that appear to influence rehabilitation and can help maximizing therapy outcomes, if exploited properly. We conclude that although promising results have already been gathered, more focused research is needed to determine the optimal conditions to implement VR in clinical settings in order to enhance therapy and to better define and leverage the true potential of VR. The rapid pace of technological development and increasing research interest toward VR-based therapy will help providing extensive knowledge and lead to rapid advancements in the near future.
C1 [Bui, Julie; Luaute, Jacques; Farne, Alessandro] INSERM, Lyon Neurosci Res Ctr, Integrat Multisensory Percept Act & Cognit Team I, CNRS,U5292,U1028, Lyon, France.
   [Bui, Julie; Luaute, Jacques; Farne, Alessandro] Univ Lyon, Univ UCBL Lyon 1, Lyon, France.
   [Bui, Julie; Luaute, Jacques; Farne, Alessandro] Hosp Civils Lyon, Neuroimmers Mouvement & Handicap, Lyon, France.
   [Bui, Julie; Luaute, Jacques] INSERM, U1028, U5292, Trajectoires,CNRS,Lyon Neurosci Res Ctr, Lyon, France.
   [Farne, Alessandro] Univ Trento, Ctr Mind Brain Sci CIMeC, Trento, Italy.
C3 Centre National de la Recherche Scientifique (CNRS); Institut National
   de la Sante et de la Recherche Medicale (Inserm); Universite Claude
   Bernard Lyon 1; Universite Jean Monnet; Universite Claude Bernard Lyon
   1; CHU Lyon; Centre National de la Recherche Scientifique (CNRS);
   Institut National de la Sante et de la Recherche Medicale (Inserm);
   Universite Claude Bernard Lyon 1; Universite Jean Monnet; University of
   Trento
RP Bui, J (corresponding author), INSERM, Lyon Neurosci Res Ctr, Integrat Multisensory Percept Act & Cognit Team I, CNRS,U5292,U1028, Lyon, France.; Bui, J (corresponding author), Univ Lyon, Univ UCBL Lyon 1, Lyon, France.; Bui, J (corresponding author), Hosp Civils Lyon, Neuroimmers Mouvement & Handicap, Lyon, France.; Bui, J (corresponding author), INSERM, U1028, U5292, Trajectoires,CNRS,Lyon Neurosci Res Ctr, Lyon, France.
EM buijulie15@gmail.com
CR Adams RJ, 2018, IEEE T NEUR SYS REH, V26, P252, DOI 10.1109/TNSRE.2017.2771272
   Afsar SI, 2018, J STROKE CEREBROVASC, V27, P3473, DOI 10.1016/j.jstrokecerebrovasdis.2018.08.007
   Ahmed N, 2020, J CENT NERV SYST DIS, V12, DOI 10.1177/1179573519899471
   Ul Ain Q, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9030242
   Allegue DR, 2020, JMIR RES PROTOC, V9, DOI 10.2196/14629
   Aminov A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0370-2
   Askin A, 2018, SOMATOSENS MOT RES, V35, P25, DOI 10.1080/08990220.2018.1444599
   Baniña MC, 2022, DISABIL REHABIL-ASSI, V17, P100, DOI 10.1080/17483107.2020.1765421
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Brunner I, 2017, NEUROLOGY, V89, P2413, DOI 10.1212/WNL.0000000000004744
   Burdea GC, 2020, TOP STROKE REHABIL, V27, P321, DOI 10.1080/10749357.2019.1701178
   Cameirao MS, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-48
   Cameirao MDS, 2011, RESTOR NEUROL NEUROS, V29, P287, DOI 10.3233/RNN-2011-0599
   Demers M, 2019, DISABIL REHABIL-ASSI, V14, P361, DOI 10.1080/17483107.2018.1449019
   Dromerick AW, 2009, NEUROLOGY, V73, P195, DOI 10.1212/WNL.0b013e3181ab2b27
   Duncan PW, 2005, STROKE, V36, pE100, DOI 10.1161/01.STR.0000180861.54180.FF
   Ekstrand E, 2016, BMC NEUROL, V16, DOI 10.1186/s12883-016-0733-x
   Feigin VL, 2017, CIRC RES, V120, P439, DOI 10.1161/CIRCRESAHA.116.308413
   Garrett B, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/10839
   Huang QQ, 2019, TRIALS, V20, DOI 10.1186/s13063-019-3177-y
   Hung JW, 2019, EUR J PHYS REHAB MED, V55, P542, DOI 10.23736/S1973-9087.19.05598-9
   Kilbride C, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2018-026620
   Kim WS, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011173
   Kiper P, 2018, ARCH PHYS MED REHAB, V99, P834, DOI 10.1016/j.apmr.2018.01.023
   Kleim JA, 2008, J SPEECH LANG HEAR R, V51, pS225, DOI 10.1044/1092-4388(2008/018)
   Klinger E., 2008, APPORTS REALIT VIRTU
   Lai SM, 2002, STROKE, V33, P1840, DOI 10.1161/01.STR.0000019289.15440.F2
   Laver KE, 2020, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010255.pub3
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee MM, 2018, MED SCI MONITOR, V24, P2590, DOI 10.12659/MSM.906451
   Lee SH, 2020, PM&R, V12, P257, DOI 10.1002/pmrj.12206
   Legg L, 2007, BMJ-BRIT MED J, V335, P922, DOI 10.1136/bmj.39343.466863.55
   Maier M, 2019, NEUROREHAB NEURAL RE, V33, P112, DOI 10.1177/1545968318820169
   Massetti T, 2018, J CENT NERV SYST DIS, V10, DOI 10.1177/1179573518813541
   Mekbib DB, 2020, NEUROTHERAPEUTICS, V17, P1919, DOI 10.1007/s13311-020-00882-x
   Merians AS, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.573642
   Mestre DR, 2015, PROC SPIE, V9392, DOI 10.1117/12.2075798
   Nichols-Larsen DS, 2005, STROKE, V36, P1480, DOI 10.1161/01.STR.0000170706.13595.4f
   Nijenhuis SM, 2017, CLIN REHABIL, V31, P207, DOI 10.1177/0269215516629722
   Norouzi-Gheidari N, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010113
   Ögün MN, 2019, ARQ NEURO-PSIQUIAT, V77, P681, DOI [10.1590/0004-282X20190129, 10.1590/0004-282x20190129]
   Pallesen H, 2018, REHABIL RES PRACT, V2018, DOI 10.1155/2018/4318678
   Perez-Marcos D, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0328-9
   Rogers JM, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0531-y
   Ballester BR, 2017, JMIR SERIOUS GAMES, V5, DOI 10.2196/games.6773
   Ballester BR, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0178-x
   Schuster-Amft C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204455
   Subramanian SK, 2022, DISABIL REHABIL-ASSI, V17, P107, DOI 10.1080/17483107.2020.1765422
   Thielbar KO, 2020, ARCH PHYS MED REHAB, V101, P196, DOI 10.1016/j.apmr.2019.10.182
   van der Vliet R, 2020, ANN NEUROL, V87, P383, DOI 10.1002/ana.25679
   Verdelet G, 2019, 2019 INTERNATIONAL CONFERENCE ON 3D IMMERSION (IC3D), DOI 10.1109/ic3d48390.2019.8975994
   WADE DT, 1983, J NEUROL NEUROSUR PS, V46, P521, DOI 10.1136/jnnp.46.6.521
   WADE DT, 1987, J NEUROL NEUROSUR PS, V50, P177, DOI 10.1136/jnnp.50.2.177
   Wang ZR, 2017, NEURAL REGEN RES, V12, P1823, DOI 10.4103/1673-5374.219043
   Warland A, 2019, DISABIL REHABIL, V41, P2119, DOI 10.1080/09638288.2018.1459881
   Weiss Patrice L, 2004, J Neuroeng Rehabil, V1, P12, DOI 10.1186/1743-0003-1-12
NR 56
TC 13
Z9 14
U1 6
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 8
PY 2021
VL 2
AR 595771
DI 10.3389/frvir.2021.595771
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VN1
UT WOS:001019160400001
OA gold
DA 2024-07-18
ER

PT J
AU van Veelen, N
   Boonekamp, RC
   Schoonderwoerd, TAJ
   van Emmerik, ML
   Nijdam, MJ
   Bruinsma, B
   Geuze, E
   Jones, C
   Vermetten, E
AF van Veelen, Nancy
   Boonekamp, Rudy C. C.
   Schoonderwoerd, Tjeerd A. J.
   van Emmerik, Martijn L. L.
   Nijdam, Mirjam J. J.
   Bruinsma, Bastiaan
   Geuze, Elbert
   Jones, Chelsea
   Vermetten, Eric
TI Tailored Immersion: Implementing Personalized Components Into Virtual
   Reality for Veterans With Post-Traumatic Stress Disorder
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE post-traumatic stress disorder; virtual reality; immersion; presence;
   veterans; user experiment; tailored therapy; exposure therapy
ID EXPOSURE THERAPY; PTSD; ENVIRONMENTS; EXPERIENCE; SYMPTOMS; EMOTION;
   IRAQ
AB With the application of virtual reality (VR), tailored interventions can be created that mirror the traumatic experiences of veterans with post-traumatic stress disorder (PTSD). Visual elements can be mimicked, and auditory and other senses stimulated. In doing so, the degree of immersion can be adjusted to optimize the therapeutic process. Objectively measuring the sensory immersion is key to keep subjects within their personal window of tolerance. Based on this information the therapist can decide manipulate the sensory stimulation embedded in the treatment. The objectives of this article are to explore the different immersive design aspects of VRET that can be modified to influence the experienced presence in veterans with PTSD, and to discuss possible methods of measuring the emotional response facilitated by immersive design aspects and experienced presence. Four design aspects are discussed: system, sensory cues, narrative and challenge. We also report on a user experiment in three veterans that informed on quality and depth of immersion. Believability of the neutral virtual environment was important for maintaining the veterans' presence within the VR experience. The immersive design aspects that were personalized and supportive in the narrative of the veteran such as music and self-selected images appeared to have a strong influence on recall and reliving of the traumatic events. Finally, in order to increase the therapeutic effect in veterans with PTSD, the highlighted design aspects should be recognized and tailored to maximize immersion in virtual reality exposure therapy.
C1 [van Veelen, Nancy; Jones, Chelsea; Vermetten, Eric] Leiden Univ Med Ctr LUMC, Psychiat, Leiden, Netherlands.
   [van Veelen, Nancy; Nijdam, Mirjam J. J.; Vermetten, Eric] ARQ Ctr 45, Oegstgeest, Netherlands.
   [Boonekamp, Rudy C. C.; Schoonderwoerd, Tjeerd A. J.; van Emmerik, Martijn L. L.] Netherlands Org Appl Sci Res TNO, Soesterberg, Netherlands.
   [Nijdam, Mirjam J. J.] Amsterdam Univ Med Ctr, Dept Psychiat, Amsterdam, Netherlands.
   [Bruinsma, Bastiaan; Geuze, Elbert] Minist Def, Brain Res & Innovat Ctr, Utrecht, Netherlands.
   [Geuze, Elbert] UMC Utrecht Brain Ctr, Dept Psychiat, Utrecht, Netherlands.
   [Jones, Chelsea] Canadian Forces Hlth Serv, Dept Natl Def, Ottawa, ON, Canada.
   [Vermetten, Eric] Minist Def, Mil Mental Hlth Care, Utrecht, Netherlands.
C3 Leiden University; Leiden University Medical Center (LUMC); Netherlands
   Organization Applied Science Research
RP van Veelen, N (corresponding author), Leiden Univ Med Ctr LUMC, Psychiat, Leiden, Netherlands.; van Veelen, N (corresponding author), ARQ Ctr 45, Oegstgeest, Netherlands.
EM n.van_veelen@lumc.nl
RI Bruinsma, Bastiaan/HNI-3926-2023
OI Jones, Chelsea/0000-0001-7713-4099; van Veelen,
   Nancy/0000-0002-3558-8065; Bruinsma, Bastiaan/0009-0009-1385-1123
CR [Anonymous], 2006, Fundamentals of Game Design
   Beck JG, 2007, BEHAV THER, V38, P39, DOI 10.1016/j.beth.2006.04.001
   Bisson JI, 2020, ACTA PSYCHIAT SCAND, V142, P141, DOI 10.1111/acps.13200
   Blase K L, 2016, Tijdschr Psychiatr, V58, P292
   Botella C, 2010, CYBERPSYCH BEH SOC N, V13, P67, DOI 10.1089/cyber.2009.0353
   Bradley M., 2000, SER AFFECTIVE SCI, P242, DOI 10.1093/oso/9780195118889.003.0011
   Chen Y., 2011, 2011 ANN INT C IEEE
   Corrigan FM, 2011, J PSYCHOPHARMACOL, V25, P17, DOI 10.1177/0269881109354930
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Daniels JK, 2016, EXP NEUROL, V284, P168, DOI 10.1016/j.expneurol.2016.08.001
   Dibbets P, 2020, J BEHAV THER EXP PSY, V67, DOI 10.1016/j.jbtep.2019.01.001
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Ermi F., 2005, Worlds in Play: International Perspectives on Digital Games Research, P15, DOI DOI 10.1080/10641260490479818
   Eshuis LV, 2021, J PSYCHIATR RES, V143, P516, DOI 10.1016/j.jpsychires.2020.11.030
   Feldman PJ, 2004, PSYCHOL HEALTH, V19, P353, DOI 10.1080/0887044042000193497
   Freeman D, 2005, J NERV MENT DIS, V193, P309, DOI 10.1097/01.nmd.0000161686.53245.70
   Gamito P, 2010, CYBERPSYCH BEH SOC N, V13, P43, DOI 10.1089/cyber.2009.0237
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Gromer D, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00372
   Grübel J, 2017, LECT NOTES ARTIF INT, V10523, P159, DOI 10.1007/978-3-319-68189-4_10
   Haagen JFG, 2015, CLIN PSYCHOL REV, V40, P184, DOI 10.1016/j.cpr.2015.06.008
   Jaycox LH, 1998, J CONSULT CLIN PSYCH, V66, P185, DOI 10.1037/0022-006X.66.1.185
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Johnson D, 2003, ERGONOMICS, V46, P1332, DOI 10.1080/00140130310001610865
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Lane RD, 2009, NEUROIMAGE, V44, P213, DOI 10.1016/j.neuroimage.2008.07.056
   McMahan A., 2013, The video game theory reader, P89
   Narciso D., 2019, 2019 INT C GRAPH INT
   Nijdam MJ, 2018, EUR J PSYCHOTRAUMATO, V9, DOI 10.1080/20008198.2018.1458568
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Philippot P, 2002, COGNITION EMOTION, V16, P605, DOI 10.1080/02699930143000392
   Picard L, 2017, INT J BEHAV DEV, V41, P211, DOI 10.1177/0165025415616198
   Ranasinghe N., 2013, P 2013 ACM INT WORKS
   Reijnen A, 2015, EUR PSYCHIAT, V30, DOI 10.1016/j.eurpsy.2014.05.003
   Richardson LK, 2010, AUST NZ J PSYCHIAT, V44, P4, DOI 10.3109/00048670903393597
   Riva G, 2004, CYBERPSYCHOL BEHAV, V7, P402, DOI 10.1089/cpb.2004.7.402
   Riva G, 2011, NEW IDEAS PSYCHOL, V29, P24, DOI 10.1016/j.newideapsych.2009.11.002
   Rizzo A, 2005, STUD HEALTH TECHNOL, V111, P407
   Rizzo A, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1414560
   Rothbaum BO, 2014, AM J PSYCHIAT, V171, P640, DOI 10.1176/appi.ajp.2014.13121625
   Rubin M, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7020016
   Schnyder U, 2015, EUR J PSYCHOTRAUMATO, V6, DOI 10.3402/ejpt.v6.28186
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Serrano B, 2016, COMPUT HUM BEHAV, V55, P1, DOI 10.1016/j.chb.2015.08.007
   Siegel DJ, 2020, DEVELOPING MIND, 3 EDITION
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Stoffregen TA, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P111, DOI 10.1201/9781410608888.ch6
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Tielman M., 2015, INT C INT VIRT AG DE
   Toet A, 2006, COMPUT HUM BEHAV, V22, P615, DOI 10.1016/j.chb.2005.12.010
   van Dooren M, 2012, PHYSIOL BEHAV, V106, P298, DOI 10.1016/j.physbeh.2012.01.020
   van Gelderen MJ, 2020, EUR J PSYCHOTRAUMATO, V11, DOI 10.1080/20008198.2020.1829400
   van Gelderen MJ, 2020, J PSYCHIATR RES, V130, P387, DOI 10.1016/j.jpsychires.2020.08.011
   van Gelderen MJ, 2020, PSYCHOTHER PSYCHOSOM, V89, P215, DOI 10.1159/000505977
   van Gelderen MJ, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00176
   vanOyen Witvliet C, 2001, PSYCHOL SCI, V12, P117, DOI 10.1111/1467-9280.00320
   Vermetten E, 2003, J CLIN PSYCHIAT, V64, P202, DOI 10.4088/JCP.v64n0214
   Vermetten E, 2013, STUD HEALTH TECHNOL, V191, P125, DOI 10.3233/978-1-61499-282-0-125
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Waterworth EL, 2001, CYBERPSYCHOL BEHAV, V4, P203, DOI 10.1089/109493101300117893
   Waterworth J. A., 2003, PRESENCE CONNECT, V3, P1
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 63
TC 1
Z9 1
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 30
PY 2021
VL 2
AR 740795
DI 10.3389/frvir.2021.740795
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8ZD6
UT WOS:001019256200001
OA gold
DA 2024-07-18
ER

PT J
AU Maneuvrier, A
   Decker, LM
   Renaud, P
   Ceyte, G
   Ceyte, H
AF Maneuvrier, A.
   Decker, L. M.
   Renaud, P.
   Ceyte, G.
   Ceyte, H.
TI Field (In)dependence Flexibility Following a Virtual Immersion Is
   Associated With Cybersickness and Sense of Presence
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE sensory re-weighting; virtual reality; cybersickness; sense of presence;
   field dependence; perceptive style; flexibility; multisensory
   integration
ID MOTION SICKNESS; POSTURAL CONTROL; COGNITIVE-STYLE; DEPENDENCE; MODEL;
   VR
AB Field dependence-independence (FDI) is a psychological construct determining an individual's approach of the perception-cognition coupling. In virtual reality (VR) context, several studies suggest that an individual's perceptive style is susceptible to shift toward a more FI mode through down-weighting of conflicting visual cues. The present study proposes to investigate the potential flexible nature of FDI following a virtual immersion and to assess if this flexibility might be associated with the subjective experience of VR. 86 participants explored a real-world-like virtual environment for approximately 10 min. FDI levels were measured before and after the VR exposure using the rod-and-frame test. Their subjective experience of VR was measured a posteriori (cybersickness and sense of presence) and used in order to build two experimental groups via a cluster analysis. The results showed that only participants with a poor subjective experience of VR (i.e., a low level of sense of presence associated with a high level of cybersickness) significantly shifted to a more FI mode, which is discussed as a sensory re-weighting mechanism. Pragmatical applications are discussed, and future studies are outlined, based on the conclusion that FDI might be more flexible than we thought, which could shed light on the psychophysiology of VR.
C1 [Maneuvrier, A.; Decker, L. M.] Normandie Univ, UNICAEN, CIREVE, Caen, France.
   [Decker, L. M.] Normandie Univ, UNICAEN, INSERM, COMETE,GIP Cyceron, Caen, France.
   [Renaud, P.] Univ Quebec Outaouais, Dept Psychol, Lab Cyberpsychol, Gatineau, PQ, Canada.
   [Ceyte, G.] Aix Marseille Univ, CNRS, ISM, Marseille, France.
   [Ceyte, H.] Univ Lorraine, DevAH, Nancy, France.
C3 Universite de Caen Normandie; Institut National de la Sante et de la
   Recherche Medicale (Inserm); Universite de Caen Normandie; University of
   Quebec; University Quebec Outaouais; Aix-Marseille Universite; Centre
   National de la Recherche Scientifique (CNRS); Universite de Lorraine
RP Maneuvrier, A (corresponding author), Normandie Univ, UNICAEN, CIREVE, Caen, France.
EM arthur.maneuvrier@protonmail.com
RI CEYTE, Hadrien/HGD-8921-2022; Maneuvrier, Arthur/IQW-0291-2023; Decker,
   Leslie Marion/IWU-7992-2023; Decker, Leslie/N-8923-2015
OI CEYTE, Hadrien/0000-0003-1746-5026; Maneuvrier,
   Arthur/0000-0002-1897-8643; Decker, Leslie/0000-0003-2929-0761
CR Andersen Richard A, 2003, Adv Neurol, V93, P159
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   [Anonymous], 1975, Motion sickness
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bouchard S., 2007, ANN REV CYBERTHERAPY, V5, P117
   Bray A, 2004, CURR BIOL, V14, pR609, DOI 10.1016/j.cub.2004.07.040
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Cian C, 2011, AVIAT SPACE ENVIR MD, V82, P959, DOI 10.3357/ASEM.3049.2011
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Di Cesare CS, 2015, GAIT POSTURE, V41, P198, DOI 10.1016/j.gaitpost.2014.09.027
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Draper JV, 1996, IEEE INT CONF ROBOT, P1030, DOI 10.1109/ROBOT.1996.506844
   Evans C, 2013, BRIT J EDUC PSYCHOL, V83, P210, DOI 10.1111/bjep.12015
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Gresty MA, 2009, ANN NY ACAD SCI, V1164, P263, DOI 10.1111/j.1749-6632.2008.03744.x
   Gutierrez-Maldonado J, 2010, STUD HEALTH TECHNOL, V154, P97, DOI 10.3233/978-1-60750-561-7-97
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hecht D, 2007, CYBERPSYCHOL BEHAV, V10, P243, DOI 10.1089/cpb.2006.9962
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   KENNEDY RS, 1975, AVIAT SPACE ENVIR MD, V46, P1349
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Mahboobin A, 2005, EXP BRAIN RES, V167, P260, DOI 10.1007/s00221-005-0053-7
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Medendorp WP, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00377
   Messick S., 1976, Individuality in learning, P4
   NAVON D, 1979, PSYCHOL REV, V86, P214, DOI 10.1037/0033-295X.86.3.214
   Nori R, 2023, CURR PSYCHOL, V42, P4567, DOI 10.1007/s12144-021-01788-3
   Ochs M, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P161, DOI 10.1145/3284432.3284452
   Oman CM, 2014, EXP BRAIN RES, V232, P2483, DOI 10.1007/s00221-014-3973-2
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Pavlou M, 2011, GAIT POSTURE, V33, P113, DOI 10.1016/j.gaitpost.2010.10.085
   Piccione J, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02583
   Pithers R., 2002, Journal of Vocational Education and Training, P117, DOI [DOI 10.1080/13636820200200191, 10.1080/13636820200200191]
   Pritchard SC, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01649
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Robillard G., 2002, 25E CONGRES ANNUEL S
   Rus-Calafell M, 2013, STUD HEALTH TECHNOL, V191, P141, DOI 10.3233/978-1-61499-282-0-141
   Shafer D. M., 2017, MEDIA PSYCHOL REV, V11, P1
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Tinajero C, 1998, EUR J PSYCHOL EDUC, V13, P227, DOI 10.1007/BF03173091
   Wallach HS, 2011, STUD COMPUT INTELL, V337, P129
   Weech S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00010
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   WITKIN H. A., 1962
   Witkin H.A., 1971, A manual for the embedded figures tests
   WITKIN HA, 1948, J EXP PSYCHOL, V38, P762, DOI 10.1037/h0053671
   Zhang LF, 2004, PERS INDIV DIFFER, V37, P1295, DOI 10.1016/j.paid.2003.12.015
NR 54
TC 5
Z9 5
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 28
PY 2021
VL 2
AR 706712
DI 10.3389/frvir.2021.706712
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TH6
UT WOS:001021829900001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Collingwoode-Williams, T
   O'Shea, Z
   Gillies, M
   Pan, XN
AF Collingwoode-Williams, Tara
   O'Shea, Zoe
   Gillies, Marco
   Pan, Xueni
TI The Impact of Self-Representation and Consistency in Collaborative
   Virtual Environments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; human computer interaction; collaborative virtual
   environment; avatar representation; embodied consistency
ID TRUST; AGENT
AB This paper explores the impact of self-representation (full body Self Avatar vs. Just Controllers) in a Collaborate Virtual Environment (CVE) and the consistency of self-representation between the users. We conducted two studies: Study 1 between a confederate and a participant, Study 2 between two participants. In both studies, participants were asked to play a collaborative game, and we investigated the effect on trust with a questionnaire, money invested in a trust game, and performance data. Study 1 suggested that having a Self Avatar made the participant give more positive marks to the confederate and that when the confederate was without an avatar, they received more trust (measured by money). Study 2 showed that consistency led to more trust and better productivity. Overall, results imply consistency improves trust only when in an equal social dynamic in CVE, and that the use of confederate could shift the social dynamics.
C1 [Collingwoode-Williams, Tara; O'Shea, Zoe; Gillies, Marco; Pan, Xueni] Goldsmiths Univ London, Dept Comp, London, England.
C3 University of London; Goldsmiths University London
RP Collingwoode-Williams, T (corresponding author), Goldsmiths Univ London, Dept Comp, London, England.
EM tc.williams@gold.ac.uk
FU EPSRC Centre for Doctoral Training in Intelligent Games amp; Games
   Intelligence (IGGI), UK [EP/L015846/1]
FX This work was supported by the EPSRC Centre for Doctoral Training in
   Intelligent Games & amp; Games Intelligence (IGGI), UK [EP/L015846/1].
CR [Anonymous], 1992, Rationality and Society, DOI DOI 10.1177/1043463192004001008
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Dey A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4045, DOI 10.1145/3025453.3026028
   Doyen S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029081
   Feng JJ, 2004, BEHAV INFORM TECHNOL, V23, P97, DOI 10.1080/01449290310001659240
   Garau M., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P309, DOI 10.1145/365024.365121
   George C, 2018, COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'18), DOI 10.1145/3180308.3180355
   Glaeser EL, 2000, Q J ECON, V115, P811, DOI 10.1162/003355300554926
   Gong L, 2007, HUM COMMUN RES, V33, P163, DOI 10.1111/j.1468-2958.2007.00295.x
   Hale J., 2017, THESIS U LONDON LOND
   IJsselsteijn Wijnand A, 2013, The Game Experience Questionnaire
   Johnson ND, 2011, J ECON PSYCHOL, V32, P865, DOI 10.1016/j.joep.2011.05.007
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim K, 2012, P SIGCHI C HUM FACT, P2531, DOI DOI 10.1145/2207676.2208640
   Kondo R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25951-2
   Kuhlen AK, 2013, PSYCHON B REV, V20, P54, DOI 10.3758/s13423-012-0341-8
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   MARTIN JD, 1970, SOCIOMETRY, V33, P178, DOI 10.2307/2786328
   Maxwell S.E., 2004, Designing experiments and analyzing data: A model comparison perspective, V2nd
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Murphy D, 2017, P IEEE VIRT REAL ANN, P265, DOI 10.1109/VR.2017.7892278
   Nguyen D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1465
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Pan X, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00001
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Rae Irene., 2013, P SIGCHI C HUMAN FAC, P1921, DOI 10.1145/2470654.2466253
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Regenbrecht Holger, 2006, Virtual Real., V10, P95
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steed A, 1999, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.1999.756941
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Verberne Frank M. F., 2013, Persuasive Technology. 8th International Conference, PERSUASIVE 2013. Proceedings, P234, DOI 10.1007/978-3-642-37157-8_28
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/vr.2019.8797719, 10.1109/VR.2019.8797719]
NR 40
TC 3
Z9 3
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 28
PY 2021
VL 2
AR 648601
DI 10.3389/frvir.2021.648601
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YS1
UT WOS:001023342900001
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Shaw, AJ
   Lubetzky, AV
AF Shaw, Alexa J.
   Lubetzky, Anat V.
TI A Short Bout of Exercise With and Without an Immersive Virtual Reality
   Game Can Reduce Stress and Anxiety in Adolescents: A Pilot Randomized
   Controlled Trial
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; exercise; head mounted display (HMD); high school;
   stress; anxiety
ID PHYSICAL-ACTIVITY; TRAIL; DEPRESSION; BENEFITS; TESTS
AB Anxiety and stress are prominent issues for the adolescent population. Physical activity is known to reduce symptoms of anxiety and stress; however, many adolescents lack the time or motivation to exercise regularly, particularly during stressful exam weeks. Virtual Reality (VR) has the potential to make exercise more enjoyable and more engaging than exercise alone. We aimed to investigate the immediate effect of a 10-min dodgeball exercise session, with and without a VR headset, on self-reported stress, anxiety and cognitive performance in adolescents during times known to induce stress in high school, such as exam weeks. Participants were randomly assigned to a VR group (n = 16) where participants were immersed in a virtual dodgeball environment (exergame), or a dodgeball group (n = 14) which played a simple game of one-on-one dodgeball. Executive function was measured using the Trail Making Test (TMT) Parts A and B. Anxiety was self-reported on the Pediatric Anxiety Short Form 8a (PASF). Stress was self-reported on the Psychological Stress Experiences-Short Form 8a (PSES). Both groups significantly improved their TMT A and B performance and reduced stress and anxiety scores with effect size ranging from 0.59 to 1.2 (main effect of time p < 0.001 for all outcomes). There were no significant differences between groups and no time by group interaction for any outcome. A short bout of exercise, with or without VR, during stressful high school exam weeks was shown to be effective for immediate reduction of stress and anxiety and enhancement of cognitive function in a small sample of high school students. High schools looking to apply interventions to help their students manage anxiety and stress should consider encouraging them to take a "time-out" to exercise and play. The cost-effectiveness of exergames inside the school settings and implications for academic success should be investigated in future research.
C1 [Shaw, Alexa J.] Ossining High Sch, Ossining, NY USA.
   [Lubetzky, Anat V.] NYU, Steinhardt Sch Culture Educ & Human Dev, Phys Therapy Dept, New York, NY 10012 USA.
C3 New York University
RP Lubetzky, AV (corresponding author), NYU, Steinhardt Sch Culture Educ & Human Dev, Phys Therapy Dept, New York, NY 10012 USA.
EM anat@nyu.edu
FU National Institutes of Health National Rehabilitation Research Resource
   to Enhance Clinical Trials (REACT) pilot award; Emerging Research Grant
   from Hearing Health Foundation
FX AL was funded by grants from the National Institutes of Health National
   Rehabilitation Research Resource to Enhance Clinical Trials (REACT)
   pilot award and an Emerging Research Grant from Hearing Health
   Foundation. The sponsors had no role in the study design, collection,
   analysis and interpretation of data; in the writing of the manuscript;
   or in the decision to submit the manuscript for publication. The content
   is solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health.
CR [Anonymous], Virtual Reality
   BAHRKE MS, 1978, COGNITIVE THER RES, V2, P323, DOI 10.1007/BF01172650
   Barmola K., 2010, BOOK HEALTHCARE MANA
   Basso JC, 2015, J INT NEUROPSYCH SOC, V21, P791, DOI 10.1017/S135561771500106X
   Bevans KB, 2013, J PEDIATR PSYCHOL, V38, P173, DOI 10.1093/jpepsy/jss107
   Breus MJ, 1998, MED SCI SPORT EXER, V30, P1107, DOI 10.1097/00005768-199807000-00013
   CDC, 2020, TARG HEART RAT EST M
   CORRIGAN JD, 1987, J CLIN PSYCHOL, V43, P402, DOI 10.1002/1097-4679(198707)43:4<402::AID-JCLP2270430411>3.0.CO;2-E
   CROCKER PRE, 1991, J SPORT MED PHYS FIT, V31, P277
   de Oliveira RS, 2014, EINSTEIN-SAO PAULO, V12, P149, DOI 10.1590/S1679-45082014AO2954
   Esch T, 2010, ARCH MED SCI, V6, P447, DOI 10.5114/aoms.2010.14269
   GAUDINO EA, 1995, J CLIN EXP NEUROPSYC, V17, P529, DOI 10.1080/01688639508405143
   Gorini A, 2010, STUD HEALTH TECHNOL, V154, P39, DOI 10.3233/978-1-60750-561-7-39
   Gregor A, 2005, SCHOOL PSYCHOL INT, V26, P617, DOI 10.1177/0143034305060802
   Hillman CH, 2008, NAT REV NEUROSCI, V9, P58, DOI 10.1038/nrn2298
   Jackson EM, 2013, ACSMS HEALTH FIT J, V17, P14, DOI 10.1249/FIT.0b013e31828cb1c9
   Lezak MD, 2004, Neuropsychological Assessment, DOI DOI 10.1017/S0033291718001599
   Lubetzky AV, 2019, MOTOR CONTROL, V23, P127, DOI 10.1123/mc.2018-0001
   Lubetzky AV, 2018, PM&R, V10, P1223, DOI 10.1016/j.pmrj.2018.07.001
   Nabetani Teru, 2001, Journal of Physiological Anthropology and Applied Human Science, V20, P233, DOI 10.2114/jpa.20.233
   National Poll on Children's Health, 2020, GAM TEENS VID GAM
   Nigg CR, 2003, PSYCHOL SPORT EXERC, V4, P57, DOI 10.1016/S1469-0292(02)00017-1
   NORRIS R, 1992, J PSYCHOSOM RES, V36, P55, DOI 10.1016/0022-3999(92)90114-H
   Nyongesa MK, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00311
   Pascoe MC, 2020, INT J ADOLESC YOUTH, V25, P104, DOI 10.1080/02673843.2019.1596823
   Pfaltz MC, 2010, J ANXIETY DISORD, V24, P792, DOI 10.1016/j.janxdis.2010.06.001
   Philippot A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01820
   Plante T. G., 2003, INT J STRESS MANAGE, V10, P203, DOI [DOI 10.1037/1072-5245.10.3.203, 10.1037/1072-5245.10.3.203, 10.1037/1072-5245.10.3.203https://dx.doi.org/10.1037/1072, DOI 10.1037/1072-5245.10.3.203HTTPS://DX.DOI.ORG/10.1037/1072]
   Plante T.G., 2006, International Journal of Stress Management, V13, P108, DOI [10.1037/1072-5245.13.1.108, DOI 10.1037/1072-5245.13.1.108]
   Plante TG, 2003, COMPUT HUM BEHAV, V19, P495, DOI 10.1016/S0747-5632(02)00074-2
   Quinn H, 2014, HEALTH QUAL LIFE OUT, V12, DOI 10.1186/s12955-014-0160-x
   Rose M, 2014, DIALOGUES CLIN NEURO, V16, P197
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Russoniello CarmenV., 2009, Journal of CyberTherapy Rehabilitation, V2, P53, DOI DOI 10.3389/CONF.NEURO.14.2009.06.091
   Salmon P, 2001, CLIN PSYCHOL REV, V21, P33, DOI 10.1016/S0272-7358(99)00032-X
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Staiano AE, 2011, CHILD DEV PERSPECT, V5, P93, DOI 10.1111/j.1750-8606.2011.00162.x
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Steinmayr R, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01994
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Wagner S, 2011, ARCH CLIN NEUROPSYCH, V26, P314, DOI 10.1093/arclin/acr024
   Warburton DER, 2017, CURR OPIN CARDIOL, V32, P541, DOI 10.1097/HCO.0000000000000437
   Zeng N, 2018, J CLIN MED, V7, DOI 10.3390/jcm7030042
   Zeng N, 2017, CYBERPSYCH BEH SOC N, V20, P453, DOI 10.1089/cyber.2017.0042
NR 44
TC 4
Z9 4
U1 3
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 26
PY 2021
VL 1
AR 598506
DI 10.3389/frvir.2020.598506
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L3EC9
UT WOS:001022115200001
OA gold
DA 2024-07-18
ER

PT J
AU Fujimoto, K
   Ashida, H
AF Fujimoto, Kanon
   Ashida, Hiroshi
TI Roles of the Retinotopic and Environmental Frames of Reference on
   Vection
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE vection; lower visual field; reference frame; gravity; posture; virtual
   reality
ID VISUAL-FIELD; PERIPHERAL-VISION; IN-DEPTH; PERCEPTION; ASYMMETRIES;
   SENSITIVITY; RESOLUTION; DIRECTION; POSITION; STIMULUS
AB Humans perceive self-motion using multisensory information, while vision has a dominant role as is utilized in virtual reality (VR) technologies. Previous studies reported that visual motion presented in the lower visual field (LoVF) induces stronger illusion of self-motion (vection) as compared with the upper visual field (UVF). However, it was still unknown whether the LoVF superiority in vection was based on the retinotopic frame, or rather related to the environmental frame of reference. Here, we investigated the influences of retinotopic and environmental frames on the LoVF superiority of vection. We presented a planer surface along the depth axis in one of four visual fields (upper, lower, right, or left). The texture on the surface moved forward or backward. Participants reported vection while observing the visual stimulus through a VR head mounted display (HMD) in the sitting posture or lateral recumbent position. Results showed that the visual motion induced stronger vection when presented in the LoVF compared with the UVF in both postures. Notably, the vection rating in LoVF was stronger in the sitting than in the recumbent. Moreover, recumbent participants reported stronger vection when the stimulus was presented in the gravitationally lower field than in the gravitationally upper field. These results demonstrate contribution of multiple spatial frames on self-motion perception and imply the importance of ground surface.
C1 [Fujimoto, Kanon; Ashida, Hiroshi] Kyoto Univ, Grad Sch Letters, Dept Psychol, Kyoto, Japan.
   [Fujimoto, Kanon] Japan Soc Promot Sci, Tokyo, Japan.
C3 Kyoto University; Japan Society for the Promotion of Science
RP Fujimoto, K (corresponding author), Kyoto Univ, Grad Sch Letters, Dept Psychol, Kyoto, Japan.; Fujimoto, K (corresponding author), Japan Soc Promot Sci, Tokyo, Japan.
EM fujimoto.kanon.63a@st.kyoto-u.ac.jp
OI Fujimoto, Kanon/0000-0003-3448-3808
FU JSPS [15H01984, 19K03367, 20J10183]; HAYAO NAKAYAMA Foundation for
   Science amp; Technology and Culture
FX This study was supported by a JSPS grant-in-aid for scientific research
   (15H01984 and 19K03367 to HA; 20J10183 to KF) and HAYAO NAKAYAMA
   Foundation for Science & amp; Technology and Culture.
CR Amenedo E, 2007, INT J PSYCHOPHYSIOL, V64, P184, DOI 10.1016/j.ijpsycho.2007.02.001
   Ash A, 2013, PERCEPTION, V42, P562, DOI 10.1068/p7449
   BERTHOZ A, 1975, EXP BRAIN RES, V23, P471
   Bilodeau L, 1997, VISION RES, V37, P2073, DOI 10.1016/S0042-6989(97)00012-6
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   Bubka A, 2008, PERCEPTION, V37, P704, DOI 10.1068/p5781
   Carrasco M, 1998, PERCEPTION, V27, P24
   Carrasco Marisa, 2002, J Vis, V2, P467, DOI 10.1167/2.6.4
   Chen HF, 2004, BRAIN TOPOGR, V17, P39, DOI 10.1023/B:BRAT.0000047335.00110.6a
   CURCIO CA, 1990, J COMP NEUROL, V300, P5, DOI 10.1002/cne.903000103
   Dakin CJ, 2018, HAND CLINIC, V159, P43, DOI 10.1016/B978-0-444-63916-5.00003-3
   DAvossa G, 1996, VISION RES, V36, P2915, DOI 10.1016/0042-6989(96)00010-7
   DeAngelis G.C., 2012, The Neural Bases of Multisensory Processes, P629
   Dyde RT, 2006, EXP BRAIN RES, V173, P612, DOI 10.1007/s00221-006-0405-y
   EDWARDS M, 1993, PERCEPTION, V22, P1013, DOI 10.1068/p221013
   FERNANDEZ C, 1976, J NEUROPHYSIOL, V39, P985, DOI 10.1152/jn.1976.39.5.985
   Fischer H. M., 1930, J PSYCHOL NEUROL, V41, P273
   FITZPATRICK R, 1994, J PHYSIOL-LONDON, V478, P173, DOI 10.1113/jphysiol.1994.sp020240
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Greenlee MW, 2016, MULTISENS RES, V29, P525, DOI 10.1163/22134808-00002527
   Guterman PS, 2012, J VESTIBUL RES-EQUIL, V22, P105, DOI 10.3233/VES-2012-0448
   He S, 1996, NATURE, V383, P334, DOI 10.1038/383334a0
   Howard IP, 2001, PERCEPTION, V30, P583, DOI 10.1068/p3106
   Jamali M, 2019, ELIFE, V8, DOI 10.7554/eLife.45573
   KANO C, 1991, Ecological Psychology, V3, P241, DOI 10.1207/s15326969eco0303_3
   Kremlácek J, 2004, VISION RES, V44, P2989, DOI 10.1016/j.visres.2004.07.002
   Lacquaniti F, 2015, MULTISENS RES, V28, P397, DOI 10.1163/22134808-00002471
   Lakha L, 2005, SPATIAL VISION, V18, P447, DOI 10.1163/1568568054389570
   Lepecq JC, 2006, J NEUROPHYSIOL, V95, P3199, DOI 10.1152/jn.00478.2005
   Lepecq JC, 1999, PERCEPTION, V28, P63, DOI 10.1068/p2749
   Liu TH, 2006, J VISION, V6, P1294, DOI 10.1167/6.11.12
   MITTELSTAEDT H, 1983, NATURWISSENSCHAFTEN, V70, P272, DOI 10.1007/BF00404833
   O'Connell C, 2016, NEUROREPORT, V27, P1225, DOI 10.1097/WNR.0000000000000682
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   PREVIC FH, 1990, BEHAV BRAIN SCI, V13, P519, DOI 10.1017/S0140525X00080018
   Previc FH, 1998, PSYCHOL BULL, V124, P123, DOI 10.1037/0033-2909.124.2.123
   Rezec AA, 2004, SPATIAL VISION, V17, P269, DOI 10.1163/1568568041920203
   Riecke B. E., 2010, VIRTUAL REAL-LONDON
   Sato T., 2007, P ASIAGRAPH 2007, P103
   Schmidtmann G, 2015, J VISION, V15, DOI 10.1167/15.5.18
   Seno T, 2015, EXP BRAIN RES, V233, P275, DOI 10.1007/s00221-014-4109-4
   Seno T, 2011, PERCEPTION, V40, P747, DOI 10.1068/p7018
   Skrandies W, 1987, PROGR SENSORY PHYSL, P1, DOI [DOI 10.1007/978-3-642-71060-5_1, 10.1007/978-3-642-71060-5_1]
   St George RJ, 2011, J PHYSIOL-LONDON, V589, P843, DOI 10.1113/jphysiol.2010.197053
   Talgar CP, 2002, PSYCHON B REV, V9, P714, DOI 10.3758/BF03196326
   Tamada Y, 2015, AEROSP MED HUM PERF, V86, P794, DOI 10.3357/AMHP.4206.2015
   Tanahashi S, 2012, I-PERCEPTION, V3, P804, DOI 10.1068/i0479
   TELFORD L, 1993, PERCEPT PSYCHOPHYS, V53, P682, DOI 10.3758/BF03211744
   Trutoiu LC, 2009, COMPUT GRAPH-UK, V33, P47, DOI 10.1016/j.cag.2008.11.008
   WAESPE W, 1977, EXP BRAIN RES, V27, P523
   WARREN WH, 1988, J EXP PSYCHOL HUMAN, V14, P646, DOI 10.1037/0096-1523.14.4.646
   Weech S, 2017, MULTISENS RES, V30, P65, DOI 10.1163/22134808-00002545
   ZACHARIAS GL, 1981, EXP BRAIN RES, V41, P159
   Zito GA, 2016, FRONT BEHAV NEUROSCI, V10, DOI 10.3389/fnbeh.2016.00128
NR 54
TC 2
Z9 2
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 24
PY 2020
VL 1
AR 581920
DI 10.3389/frvir.2020.581920
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L6TU4
UT WOS:001024574100001
OA gold
DA 2024-07-18
ER

PT J
AU Hinricher, N
   Koenig, S
   Schroeer, C
   Backhaus, C
AF Hinricher, Niels
   Koenig, Simon
   Schroeer, Chris
   Backhaus, Claus
TI Effects of virtual reality and test environment on user experience,
   usability, and mental workload in the evaluation of a blood pressure
   monitor
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual prototype; usability test; virtual reality (VR); user interface;
   humantechnology interaction
ID TECHNOLOGY; PROTOTYPES; PRODUCTS
AB User experience and user acceptance of a product are essential for the product's success. Virtual reality (VR) technology has the potential to assess these parameters early in the development process. However, research is scarce on whether the evaluation of the user experience and user acceptance of prototypes in VR, as well as the simulation of the usage environment, lead to comparable results to reality. To investigate this, a digital twin of a blood pressure monitor (BPM) was created using VR. In a 2 x 2 factorial between-subjects design, 48 participants tested the real or VR BPM. The tests were performed either in a low-detail room at a desk or in a detailed operating room (OR) environment. Participants executed three use scenarios with the BPM and rated their user experience and acceptance with standardized questionnaires. A test leader evaluated the performance of the participants' actions using a three-point scheme. The number of user interactions, task time, and perceived workload were assessed. The participants rated the user experience of the BPM significantly (p < .05) better in VR. User acceptance was significantly higher when the device was tested in VR and in a detailed OR environment. Participant performance and time on task did not significantly differ between VR and reality. However, there was significantly less interaction with the VR device (p < .001). Participants who tested the device in a detailed OR environment rated their performance significantly worse. In reality, the participants were able to haptically experience the device and thus better assess its quality. Overall, this study shows that user evaluations in VR should focus on objective criteria, such as user errors. Subjective criteria, such as user experience, are significantly biased by VR.
C1 [Hinricher, Niels; Koenig, Simon; Schroeer, Chris] FH Munster Univ Appl Sci, Ctr Ergon & Med Engn, Steinfurt, Germany.
   [Backhaus, Claus] Tech Univ, Inst Dept Psychol & Ergon, Berlin, Germany.
C3 University of Applied Sciences, Muenster; Technical University of Berlin
RP Hinricher, N (corresponding author), FH Munster Univ Appl Sci, Ctr Ergon & Med Engn, Steinfurt, Germany.
EM niels.hinricher@fh-muenster.de
CR Adwernat Stefan, 2020, Procedia CIRP, V91, P710, DOI 10.1016/j.procir.2020.03.115
   Ahmed Salman, 2019, Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. Human Body and Motion.10th International Conference, DHM 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11581), P3, DOI 10.1007/978-3-030-22216-1_1
   [Anonymous], 2009, P CHI 09 CHI C HUM F
   Anthes C., 2016, P 2016 IEEE AEROSPAC, P1
   Antonya Csaba, 2007, Virtual Reality, V11, P275, DOI 10.1007/s10055-007-0074-6
   Aromaa S, 2020, VIRTUAL REAL-LONDON, V24, P23, DOI 10.1007/s10055-019-00384-y
   Aromaa S, 2017, PROCEEDINGS OF THE 21ST INTERNATIONAL ACADEMIC MINDTREK CONFERENCE (ACADEMIC MINDTREK), P110, DOI 10.1145/3131085.3131087
   Aromaa S, 2016, APPL ERGON, V56, P11, DOI 10.1016/j.apergo.2016.02.015
   Backhaus Claus., 2010, USABILITY ENG MEDIZI
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Berg LP, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4034267
   Bergroth JD, 2018, NUCL TECHNOL, V202, P278, DOI 10.1080/00295450.2017.1420335
   Berkman M.I., 2019, ENCY COMPUTER GRAPHI, P1, DOI DOI 10.1007/978-3-319-08234-9_162-1
   Bolder A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281512
   Bordegoni M, 2013, VIRTUAL PHYS PROTOTY, V8, P51, DOI 10.1080/17452759.2012.762612
   Brade J, 2017, INT J HUM-COMPUT ST, V101, P76, DOI 10.1016/j.ijhcs.2017.01.004
   Brandt S., 2017, P 37 COMP INF ENG C
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Bruno F., 2010, P 30 COMP INF ENG C
   Bruno F, 2010, INT J HUM-COMPUT ST, V68, P254, DOI 10.1016/j.ijhcs.2009.12.004
   Busch M, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P117, DOI 10.1145/2639189.2639224
   Chen X., 2021, Procedia CIRP, V104, P464
   Choi S, 2015, CONCURRENT ENG-RES A, V23, P40, DOI 10.1177/1063293X14568814
   de Clerk M, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00013
   de Freitas FV, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031755
   Elor Aviv, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3396249
   Franzreb D., 2022, DEV DESIGN RES PRACT, P105
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Gaina MA, 2022, J CLIN MED, V11, DOI 10.3390/jcm11061670
   Garrett James J., 2011, The elements of user experience: User-centered design for the web
   Grandi F, 2020, INT J COMPUT INTEG M, V33, P377, DOI 10.1080/0951192X.2019.1599441
   Harms P, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3301423
   Harris D, 2020, VIRTUAL REAL-LONDON, V24, P557, DOI 10.1007/s10055-019-00422-9
   HART S G, 1988, P139
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   Holderied H., 2017, EVALUATION INTERACTI
   Kuliga SF, 2015, COMPUT ENVIRON URBAN, V54, P363, DOI 10.1016/j.compenvurbsys.2015.09.006
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Ma C, 2019, LECT NOTES COMPUT SC, V11596, P145, DOI 10.1007/978-3-030-22666-4_11
   Madathil KC, 2017, APPL ERGON, V65, P501, DOI 10.1016/j.apergo.2017.02.011
   Mania K., 2001, Proceedings AFRIGRAPH 2001. 1st International Conference on Computer Graphics, Virtual Reality and Visualisation, P119, DOI 10.1145/513867.513893
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   Metag S., 2008, P WORKSH RES GOALS S
   Novacek T, 2020, PRESENCE-VIRTUAL AUG, V29, P37, DOI 10.1162/pres_a_00356
   Oberhauser M, 2017, COGN TECHNOL WORK, V19, P263, DOI 10.1007/s10111-017-0421-7
   Pettersson I, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P463, DOI 10.1145/3322276.3322288
   Rauschenberger M., 2013, TAGUNGSBAND, V13, P72
   Rauschenberger M, 2013, INT J INTERACT MULTI, V2, P39, DOI 10.9781/ijimai.2013.215
   Rudd Jim, 1996, Interactions, V3, P76, DOI DOI 10.1145/223500.223514
   Salwasser M., 2019, VIRTUELLE TECHNOLOGI
   Sarodnick F., 2011, Methoden der Usability Evaluation, V2nd
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Seifert K., 2002, Evaluation multimodaler Computer-Systeme infriihen Entwicklungsphasen - Ein empirischer Ansatz zur Ableitung von Gestaltungshinweisen fiir multimodale Computer-Systeme
   Siebers S., 2020, K GESELLSCHAFT F R A
   Sivanathan A, 2017, J ENG DESIGN, V28, P681, DOI 10.1080/09544828.2017.1393655
   Unger N. R., 2020, P INT S HUM FACT ERG, V9, P142, DOI [10.1177/2327857920091058, DOI 10.1177/2327857920091058]
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vergara M, 2011, APPL ERGON, V42, P652, DOI 10.1016/j.apergo.2010.09.014
   Wang G. G., 2002, Transactions of the ASME. Journal of Computing and Information Science in Engineering, V2, P232, DOI 10.1115/1.1526508
   Winter D., 2015, MENSCH COMPUTER 2015, P33
   Wolfartsberger J, 2020, PROCEDIA MANUF, V42, P2, DOI 10.1016/j.promfg.2020.02.016
   Wolfartsberger J, 2019, AUTOMAT CONSTR, V104, P27, DOI 10.1016/j.autcon.2019.03.018
   Zhou XC, 2019, APPL ERGON, V80, P111, DOI 10.1016/j.apergo.2019.05.007
NR 63
TC 1
Z9 1
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 13
PY 2023
VL 4
AR 1151190
DI 10.3389/frvir.2023.1151190
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WM9
UT WOS:001023285500001
OA gold
DA 2024-07-18
ER

PT J
AU Li, C
   Yip, PY
AF Li, Chen
   Yip, Pui Yin
TI Remote arts therapy in collaborative virtual environment: A pilot case
   study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; collaborative virtual environment; arts therapy;
   teletherapy; mental wellbeing; COVID-19
ID SOCIAL PRESENCE; REALITY; BEHAVIOR; ANXIETY
AB Motivated by the unique experience of creating three-dimensional artworks in virtual reality (VR) and the need for teletherapy due to the global pandemic, we conducted this pilot case study to explore the feasibility and effectiveness of using a custom-designed collaborative virtual environment (CVE) to enable remote arts therapy. Three participants (two females and one male) experiencing moderate to high stress as measured by the Perceived Stress Scale (PSS) joined this study. Each participant had eight 45-minute one-on-one sessions with the therapist for eight consecutive weeks. These eight sessions covered eight art creation themes and were delivered following pre-designed protocols. The CVE was the only medium to facilitate the sessions, during which the therapist and the participants were physically separated into two rooms. The quantitative and qualitative results suggested that the CVE-enabled approach was generally feasible and was welcomed by both the participants and the therapist. However, more evidence of the approach's effectiveness in enhancing the participants' mental wellbeing is needed because the results of the pilot case study were affected by the pandemic. The advantages and disadvantages of this approach and the CVE were investigated from practicality and technological affordance perspectives. Potential improvements to the CVE are also proposed to better facilitate the practice of remote arts therapy in CVE. We encourage future studies to cautiously investigate CVE-enabled remote arts therapy in clinical settings and collect more evidence regarding its effectiveness in addressing clinically diagnosed mental disorders and other complications.
C1 [Li, Chen; Yip, Pui Yin] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Li, C (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
EM richard-chen.li@polyu.edu.hk
OI Li, Chen/0000-0002-3782-0737
FU Hong Kong Polytechnic University [P0035264]
FX Financial support was received from The Hong Kong Polytechnic University
   (project no: P0035264).
CR Benford S, 2001, COMMUN ACM, V44, P79, DOI 10.1145/379300.379322
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Biocca Frank, 2013, COMMUNICATION AGE VI
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chow Kevin, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359142
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   Dellazizzo L, 2020, J MED INTERNET RES, V22, DOI 10.2196/20889
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Ekman P., 1978, APA PsycTests, DOI DOI 10.1037/T27734-000
   Fodor LA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28113-6
   Freiwald JP, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555522
   Gallagher L.M., 2002, MUSIC THER PERSPECT, V20, P117, DOI DOI 10.1093/MTP/20.2.117
   Gumilar I, 2021, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR-Adjunct54149.2021.00021
   Gussak D.E., 2015, The Wiley handbook of art therapy
   Gutiérrez-Maldonado J, 2014, VIRTUAL REAL-LONDON, V18, P61, DOI 10.1007/s10055-013-0236-7
   Haeyen S, 2021, ART PSYCHOTHER, V76, DOI 10.1016/j.aip.2021.101855
   Herrera F, 2018, PRESENCE-VIRTUAL AUG, V27, P163, DOI 10.1162/PRES_a_00324
   Kaimal G, 2020, ART THER, V37, P16, DOI 10.1080/07421656.2019.1659662
   Malchiodi CA., 2011, Handbook of art therapy
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Pidel C, 2020, LECT NOTES COMPUT SC, V12242, P141, DOI 10.1007/978-3-030-58465-8_10
   RIGGIO RE, 1986, J PERS SOC PSYCHOL, V50, P421, DOI 10.1037/0022-3514.50.2.421
   Robledo Yamamoto F., 2021, P ACM HUM COMP INT, V5, P1, DOI [10.1145/3479508, DOI 10.1145/3479508]
   Rogers A., 1981, 3 WORLD C PAIN INT A, P319
   Rubin J., 2012, Approaches to Art Therapy: Theory Technique
   Scozzari S, 2011, STUD COMPUT INTELL, V337, P63
   Shella TA, 2018, ART PSYCHOTHER, V57, P59, DOI 10.1016/j.aip.2017.10.003
   Short J., 1976, The social psychology of telecommunications
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2002, COMP SUPP COMP W SER, P146
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sungchul Jung, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449146
   Tennant R, 2007, HEALTH QUAL LIFE OUT, V5, DOI 10.1186/1477-7525-5-63
   Wang CY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1215, DOI [10.1109/vr.2019.8797789, 10.1109/VR.2019.8797789]
   Won AS, 2014, J NONVERBAL BEHAV, V38, P389, DOI 10.1007/s10919-014-0186-0
   Zubala A, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.600070
NR 41
TC 0
Z9 0
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 12
PY 2023
VL 4
AR 1059278
DI 10.3389/frvir.2023.1059278
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WY6
UT WOS:001023297200001
OA gold
DA 2024-07-18
ER

PT J
AU Bonfert, M
   Reinschluessel, AV
   Putze, S
   Lai, YC
   Alexandrovsky, D
   Malaka, R
   Doering, T
AF Bonfert, Michael
   Reinschluessel, Anke V.
   Putze, Susanne
   Lai, Yenchin
   Alexandrovsky, Dmitry
   Malaka, Rainer
   Doering, Tanja
TI Seeing the faces is so important-Experiences from online team meetings
   on commercial virtual reality platforms
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE CSCW; virtual reality; social VR; remote collaboration; virtual
   meetings; video conferencing; autoethnography; case study
ID SOCIAL PRESENCE; COMMUNICATION; BEHAVIOR; COPRESENCE
AB During the COVID-19 pandemic, online meetings became common for daily teamwork in the home office. To understand the opportunities and challenges of meeting in virtual reality (VR) compared to videoconferences, we conducted the weekly team meetings of our human-computer interaction research lab on five off-the-shelf online meeting platforms over 4 months. After each of the 12 meetings, we asked the participants (N = 32) to share their experiences, resulting in 200 completed online questionnaires. We evaluated the ratings of the overall meeting experience and conducted an exploratory factor analysis of the quantitative data to compare VR meetings and video calls in terms of meeting involvement and co-presence. In addition, a thematic analysis of the qualitative data revealed genuine insights covering five themes: spatial aspects, meeting atmosphere, expression of emotions, meeting productivity, and user needs. We reflect on our findings gained under authentic working conditions, derive lessons learned for running successful team meetings in VR supporting different kinds of meeting formats, and discuss the team's long-term platform choice.
C1 [Bonfert, Michael; Reinschluessel, Anke V.; Putze, Susanne; Lai, Yenchin; Alexandrovsky, Dmitry; Malaka, Rainer; Doering, Tanja] Univ Bremen, Digital Media Lab, Bremen, Germany.
C3 University of Bremen
RP Bonfert, M (corresponding author), Univ Bremen, Digital Media Lab, Bremen, Germany.
EM bonfert@uni-bremen.de
RI Malaka, Rainer/IXD-3800-2023
OI Malaka, Rainer/0000-0001-6463-4828; Reinschluessel, Anke
   V./0000-0002-6389-6436; Bonfert, Michael/0000-0002-3605-6693
FU Klaus Tschira Stiftung; Staats-und Universitaetsbibliothek Bremen
FX This research was partially funded by the Klaus Tschira Stiftung by
   financing the scholarship of MB. The open access publication fees were
   covered by Staats-und Universitaetsbibliothek Bremen.
CR Abdullah Ahsan, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479597
   Ahn SJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.648575
   [Anonymous], 1997, VIDEO MEDIATED COMMU
   [Anonymous], 1997, Video-mediated communication
   Bailenson J. N., 2021, Technology, Mind, and Behavior, DOI [DOI 10.1037/TMB0000030, 10.1037/tmb0000030]
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Bailenson JN, 2004, PRESENCE-VIRTUAL AUG, V13, P428, DOI 10.1162/1054746041944803
   Barreda-Angeles M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107047
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Blackwell Lindsay, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359202
   Blackwell L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P854, DOI [10.1109/VR.2019.8798165, 10.1109/vr.2019.8798165]
   Bleakley A, 2022, HUM-COMPUT INTERACT, V37, P404, DOI 10.1080/07370024.2021.1994859
   Brucks MS, 2022, NATURE, V605, P108, DOI 10.1038/s41586-022-04643-y
   Burgoon JK, 1999, J MANAGE INFORM SYST, V16, P33, DOI 10.1080/07421222.1999.11518255
   Byun Byungki., 2011, 2011 IEEE INT C MULT, DOI [10.1109/ICME.2011.6011855., DOI 10.1109/ICME.2011.6011855]
   Cha HS, 2022, VIRTUAL REAL-LONDON, V26, P385, DOI 10.1007/s10055-021-00575-6
   Corda Stefano, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2210, 10.48550/arXiv.2210]
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   Dzardanova E, 2022, VIRTUAL REAL-LONDON, V26, P737, DOI 10.1007/s10055-021-00564-9
   Erickson T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P503
   Fagersten K., 2010, CASES ONLINE DISCUSS, P19
   Freeman Guo, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512932
   Galegher J., 1990, INTELLECTUAL TEAMWOR
   Gonzalez-Franco M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04201-x
   Hamedi M, 2018, IEEE T AFFECT COMPUT, V9, P102, DOI 10.1109/TAFFC.2016.2569098
   Hecht H, 2019, ACTA PSYCHOL, V193, P113, DOI 10.1016/j.actpsy.2018.12.009
   Hinds P.J., 1999, MEDIA PSYCHOL, V1, P283, DOI [DOI 10.1207/S1532785XMEP0104_1, https://doi.org/10.1207/s1532785xmep0104_1]
   Kang SH, 2013, COMPUT HUM BEHAV, V29, P1169, DOI 10.1016/j.chb.2012.10.010
   Kern AC, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00020
   Kirchner K., 2021, INNOVATIONS COMMUNIT, P123, DOI [10.1007/978-3-030-75004-6_9, DOI 10.1007/978-3-030-75004-6_9]
   Koseki Natsuki, 2020, 2020 9th International Congress on Advanced Applied Informatics (IIAI-AAI), P651, DOI 10.1109/IIAI-AAI50415.2020.00133
   Kramer A. D. I., 2006, Conference on Human Factors in Computing Systems. CHI2006, P913
   Kyrlitsias C, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.786665
   Lahlou S, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451579
   Liu QX, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.668181
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Luo WZ, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501946
   Mack K, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3471199
   Maloney D., 2020, PROC ACM HUM COMPUT, V4, P1, DOI DOI 10.1145/3415246
   McVeigh-Schultz J., 2021, 2021 CHI C HUM FACT, P1
   McVeigh-Schultz J, 2022, HUM-COMPUT INTERACT, V37, P433, DOI 10.1080/07370024.2021.1994860
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Microsoft, 2022, ANN REPORT
   Milgram S., 1974, Obedience to authority: An experiment view
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Nadler R., 2020, Computers and Composition, V58, DOI DOI 10.1016/J.COMPCOM.2020.102613
   NILLES JM, 1975, IEEE T COMMUN, V23, P1142, DOI 10.1109/TCOM.1975.1092687
   Nind Melanie, 2021, UOSIR
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Nowak Kristine., 2001, 2001 C PHIL PA US 20
   OCHSMAN RB, 1974, INT J MAN MACH STUD, V6, P579, DOI 10.1016/S0020-7373(74)80019-2
   Oculus, 2021, INTR HOR WORKR REM C
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Organisation for Economic Co-operation and Development (OECD), 2021, Teleworking in the COVID-19 pandemic: Trend and prospects, DOI [10.1787/72a416b6-en, DOI 10.1787/72A416B6-EN]
   Otte A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1729, DOI 10.1109/VR.2019.8797740
   Poeschl S, 2013, P IEEE VIRT REAL ANN, P129, DOI 10.1109/VR.2013.6549396
   Raghuram S, 2019, ACAD MANAG ANN, V13, P308, DOI 10.5465/annals.2017.0020
   Rogers B, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206569
   Roth D, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364269
   Roth D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P215, DOI 10.1109/VR.2018.8447550
   Rzeszewski M., 2020, ROZWOJ REGIONALNY PO, VRegionalna, P57, DOI DOI 10.14746/RRPR.2020.51.06
   Saatçi B, 2020, COMPUT SUPP COOP W J, V29, P769, DOI 10.1007/s10606-020-09385-x
   Samrose Samiha, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161186
   Samrose Samiha, 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764, 10.1145/3411764.3445615]
   Sarkar A, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451793
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Schwartz G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392493
   Shockley KM, 2021, J APPL PSYCHOL, V106, P1137, DOI 10.1037/apl0000948
   Short J., 1976, The social psychology of telecommunications
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Stahl O., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P164, DOI 10.1145/323663.323691
   Suh H, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3988, DOI 10.1145/2858036.2858448
   Sykownik P, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P546, DOI 10.1109/VR50410.2021.00079
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Torro O, 2021, COMMUN ACM, V64, P48, DOI 10.1145/3440868
   van Ginkel S, 2019, COMPUT EDUC, V134, P78, DOI 10.1016/j.compedu.2019.02.006
   Wigham CR, 2013, RECALL, V25, P63, DOI 10.1017/S0958344012000250
   Wilcox Laurie M., 2006, ACM Trans. on Perception, V3, P412, DOI [DOI 10.1145/1190036.1190041, 10.1145/1190036.1190041]
   Williams JK, 2022, PROTEINS, V90, P1044, DOI 10.1002/prot.26208
   Williamson JR, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517594
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
   Yoshimura A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.648619
   Zibrek K., 2019, Motion, interaction and games, P1, DOI [DOI 10.1145/3359566.3360064, 10.1145/3359566.3360064]
NR 85
TC 0
Z9 0
U1 8
U2 19
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 11
PY 2023
VL 3
AR 945791
DI 10.3389/frvir.2022.945791
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XM5
UT WOS:001023311100001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Fraser, AD
   Branson, I
   Hollett, RC
   Speelman, CP
   Rogers, SL
AF Fraser, A. D.
   Branson, I.
   Hollett, R. C.
   Speelman, C. P.
   Rogers, S. L.
TI Expressiveness of real-time motion captured avatars influences perceived
   animation realism and perceived quality of social interaction in virtual
   reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; avatar; animation realism; face realism; body realism;
   social interaction; motion capture; avatar expressiveness
ID FACE; PREFERENCE; BODY
AB Using motion capture to enhance the realism of social interaction in virtual reality (VR) is growing in popularity. However, the impact of different levels of avatar expressiveness on the user experience is not well understood. In the present study we manipulated levels of face and body expressiveness of avatars while investigating participant perceptions of animation realism and interaction quality when disclosing positive and negative experiences in VR. Moderate positive associations were observed between perceptions of animation realism and interaction quality. Post-experiment questions revealed that many of our participants (approximately 40%) indicated the avatar with the highest face and body expressiveness as having the most realistic face and body expressions. The same proportion also indicated the avatar with the highest face and body expressiveness as being the most comforting and enjoyable avatar to interact with. Our results suggest that higher levels of face and body expressiveness are important for enhancing perceptions of realism and interaction quality within a social interaction in VR using motion capture.
C1 [Fraser, A. D.; Branson, I.; Hollett, R. C.; Speelman, C. P.; Rogers, S. L.] Edith Cowan Univ, Expt Psychol Unit, Perth, WA, Australia.
C3 Edith Cowan University
RP Rogers, SL (corresponding author), Edith Cowan Univ, Expt Psychol Unit, Perth, WA, Australia.
EM shane.rogers@ecu.edu.au
CR Aburumman N, 2022, INT J HUM-COMPUT ST, V164, DOI 10.1016/j.ijhcs.2022.102819
   Arias S, 2021, FIRE MATER, V45, P462, DOI 10.1002/fam.2922
   Aseeri S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P581, DOI [10.1109/VRW50115.2020.0-134, 10.1109/VRW50115.2020.00141]
   Baccon LA, 2019, CYBERPSYCH BEH SOC N, V22, P158, DOI 10.1089/cyber.2018.0247
   Barreda-Angeles M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107047
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Cao QD, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P751, DOI [10.1109/VRW50115.2020.00226, 10.1109/VRW50115.2020.00-49]
   Capin TK, 1997, IEEE COMPUT GRAPH, V17, P42, DOI 10.1109/38.574680
   Felton WM, 2022, INT J HUM-COMPUT INT, V38, P1, DOI 10.1080/10447318.2021.1921368
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P281, DOI 10.1145/3267851.3267891
   Fink B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00220
   Foster ME, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES (CUI 2019), DOI 10.1145/3342775.3342810
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Grewe CM, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.619811
   Guye-Vuilleme A., 1999, Virtual Reality, V4, P49, DOI 10.1007/BF01434994
   Herrera F, 2018, PRESENCE-VIRTUAL AUG, V27, P163, DOI 10.1162/PRES_a_00324
   Higgins D, 2022, COMPUT GRAPH-UK, V104, P116, DOI 10.1016/j.cag.2022.03.009
   Jung SC, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.693327
   Kalra P, 1998, IEEE COMPUT GRAPH, V18, P42, DOI 10.1109/38.708560
   Kokkinara E., 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG'15, P221, DOI DOI 10.1145/2822013.2822035
   Kruzic CO, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76672-4
   Kyrlitsias C, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.786665
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lombard M, 2009, Measuring presence: the temple presence inventory, P1
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Maurel Walter., 1998, Biomechanical Models_for_Soft_Tissue_Simulation, DOI [DOI 10.1007/978-3-662-03589-4, 10.1007/ 978-3-662-03589-4]
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Owens ME, 2015, J PSYCHOPATHOL BEHAV, V37, P296, DOI 10.1007/s10862-014-9454-x
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Proverbio AM, 2018, SOC COGN AFFECT NEUR, V13, P590, DOI 10.1093/scan/nsy033
   Rogers SL, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.750729
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Sel A, 2015, SOC COGN AFFECT NEUR, V10, P1316, DOI 10.1093/scan/nsv009
   Seymour M, 2021, J ASSOC INF SYST, V22, P591, DOI 10.17705/1jais.00674
   Seymour M, 2018, J ASSOC INF SYST, V19, P953, DOI 10.17705/1jais.00515
   Shields K, 2012, COGNITION EMOTION, V26, P699, DOI 10.1080/02699931.2011.588691
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Solanas MP, 2018, SOC COGN AFFECT NEUR, V13, P135, DOI 10.1093/scan/nsx130
   Sterna R, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.705448
   Stuart J, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.864676
   Thomas S, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P11, DOI 10.1109/VR51125.2022.00018
   Willis ML, 2011, EMOTION, V11, P514, DOI 10.1037/a0022571
   Wu YJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.641296
NR 45
TC 3
Z9 3
U1 8
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 1
PY 2022
VL 3
AR 981400
DI 10.3389/frvir.2022.981400
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XZ9
UT WOS:001023324600001
OA gold
DA 2024-07-18
ER

PT J
AU Michels, FL
   Haefner, V
AF Michels, Felix Longge
   Haefner, Victor
TI Automating virtualization of machinery for enabling efficient virtual
   engineering methods
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual engineering; causal AI; tunnel boring machine;
   virtual twin; virtualization process; hardware in the loop; software in
   the Loop
ID MODEL GENERATION; SIMULATION; REALITY
AB Virtual engineering as a new working method in product development should make it much easier to validate the development progress and facilitate team communication. Work steps are brought forward and start with the virtual components instead of real ones. To validate mechanical and electrical CAD as well as programming, automated virtualization systems should create the virtual twin of the machine at the push of a button. For this purpose, generic intelligence is added to enable complex interactive virtual models that can be used for training, monitoring and many other applications. Advanced applications are for example training and support applications, especially in combination with augmented reality and remote collaboration. We propose a system that combines virtual reality, virtual engineering and artificial intelligence methods for the product development process. Geometry analysis algorithms are used to process mechanical CAD data and thus, for example, to automatically parameterize kinematic simulations. In combination with electrical CAD data and the simulations of electric circuits as well as the original machine program allow simulating the behavior of the machine and the user interaction with it. This article will describe the virtualization method in detail and present various use-cases in special machine construction. It will also propose a novel method to use causal discovery in complex machine simulations.
C1 [Michels, Felix Longge; Haefner, Victor] Karlsruhe Inst Technol, Inst Informat Management Engn, Dept Mech Engn, Smart Immers Environm, Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Haefner, V (corresponding author), Karlsruhe Inst Technol, Inst Informat Management Engn, Dept Mech Engn, Smart Immers Environm, Karlsruhe, Germany.
EM victor.haefner@kit.edu
RI Michels, Felix L./JED-4424-2023
FU Karlsruhe Institute of Technology; KIT-Publication Fund; Karlsruhe
   Institute of Technology; company Herrenknecht AG in Germany
FX The work presented in this paper was mostly funded by the Karlsruhe
   Institute of Technology. We acknowledge support by the KIT-Publication
   Fund of the Karlsruhe Institute of Technology. Some aspects were
   researched in the scope of various research, industry and student
   projects. The funding for the virtual tunnel boring simulation came
   partly from the company Herrenknecht AG in Germany.
CR AutomationML, 2022, AUT DESCR
   Bayart B, 2015, P IEEE VIRT REAL ANN, P395, DOI 10.1109/VR.2015.7223462
   Bönsch J, 2022, COMPUT IND ENG, V172, DOI 10.1016/j.cie.2022.108556
   Chang M, 2011, INT J PROD RES, V49, P4593, DOI 10.1080/00207543.2010.506893
   Cheng J, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P1038, DOI 10.1109/NISS.2009.31
   Coumans E., 2016, PYBULLET PYTHON MODU
   EPLAN, 2022, EPLAN DESCR
   Haefner Victor, 2014, EUROVR 2014 C EXHIBI, DOI [10.2312/eurovr.20141343, DOI 10.2312/EUROVR.20141343]
   Hafner V., 2014, POLYVR SOURCE
   Hafner V., 2020, WIRTSCH FABR, V115, P148, DOI [10.3139/104.112253, DOI 10.3139/104.112253]
   Hauf D, 2017, PROCEDIA MANUF, V11, P256, DOI 10.1016/j.promfg.2017.07.359
   Ko M, 2013, INT J PROD RES, V51, P1668, DOI 10.1080/00207543.2012.693964
   Kumar SPL, 2019, INT J PROD RES, V57, P4766, DOI 10.1080/00207543.2018.1424372
   Li G, 2011, ADV MATER RES-SWITZ, V139-141, P957, DOI 10.4028/www.scientific.net/AMR.139-141.957
   Li HY, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016651557
   Mao S., 2013, P 13 INT C CONSTR AP
   Moraffah R, 2021, KNOWL INF SYST, V63, P3041, DOI 10.1007/s10115-021-01621-0
   Ninic J, 2015, TUNN UNDERGR SP TECH, V45, P138, DOI 10.1016/j.tust.2014.09.013
   Park HT, 2010, INT J PROD RES, V48, P1517, DOI 10.1080/00207540802577961
   Reinhardt H, 2019, PROC CIRP, V81, P121, DOI 10.1016/j.procir.2019.03.022
   Schroeder GN, 2016, IFAC PAPERSONLINE, V49, P12, DOI 10.1016/j.ifacol.2016.11.115
   Sepasgozar SME, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134678
   Siemens, TIA PORT DESCR
   Siemens, 2022, SIEM SIM DESCR
   Thongnuch S, 2017, IEEE ASME INT C ADV, P1077, DOI 10.1109/AIM.2017.8014162
   Vukovic M, 2022, J MANUF MATER PROC, V6, DOI 10.3390/jmmp6010010
   Wolfartsberger J, 2019, AUTOMAT CONSTR, V104, P27, DOI 10.1016/j.autcon.2019.03.018
   Wu HY, 2022, INT J APPL EARTH OBS, V112, DOI 10.1016/j.jag.2022.102887
   Xu H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183715
NR 29
TC 0
Z9 0
U1 4
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 23
PY 2022
VL 3
AR 1034431
DI 10.3389/frvir.2022.1034431
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YW7
UT WOS:001023347500001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Lee, SY
   Yoon, SY
AF Lee, Seo-Young
   Yoon, So-Yeon
TI Effects of gender and personality on experience of small living spaces:
   Ceiling height and floor plan shape in virtual environment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE small living spaces; virtual environment; place attachment; ceiling
   height; floor plan shape; tiny home
ID ATTACHMENT; PERCEPTIONS; PROXIMITY; RESPONSES; PRIVACY
AB Virtual reality (VR) technology has been used as a design research tool to enable a virtual experience of space as a real-life-scale mock-up. In terms of user experience design research, VR is highly scalable and adjustable, meaning that designed virtual prototypes and environments can be tested on a diverse population without restrictions. In spatial design, VR has been applied in various contexts, often focusing on behavioral intentions and psychological perceptions. Small living spaces are gaining more popularity as an affordable housing solution and an environmentally sustainable lifestyle. Despite their growing demand, user experiences of small living spaces have not been empirically tested. Specifically, the impact of users' different characteristics on the psychological responses to small living spaces has rarely been studied. In this study, we used three-dimensional (3D) virtual mock-ups to test how subjects of different genders and personality types perceived different shapes of a small space. A 2 x 2 factorial design was used to test two different wall length-width combinations (short vs. long floor plan shape) with two different ceiling heights (low vs. high). Forty-eight participants were randomly assigned to watch one of the four small living spaces. After watching the virtual walkthrough video, participants filled out the questionnaires on their perceptions. The results show that floor plan shape had a significant impact on place attachment. Participants reported greater place attachment to the space with a shorter floor plan than the longer one. In addition, higher ceiling height is closely related to functional and goal-oriented connections. The impact of the floor plan shape of the space on place attachment differed according to gender, age, and personality. Participants with higher extrovert scores reported greater functional connections to higher ceiling height. Men reported significantly more affective ties with longer floor plans than shorter ones. The older age group perceived longer floor plans to be more functional than the shorter ones.
C1 [Lee, Seo-Young; Yoon, So-Yeon] Cornell Univ, Dept Human Ecol, Human Ctr Design, Ithaca, NY 14850 USA.
C3 Cornell University
RP Yoon, SY (corresponding author), Cornell Univ, Dept Human Ecol, Human Ctr Design, Ithaca, NY 14850 USA.
EM sy492@cornell.edu
CR ALLEN TJ, 1973, HUM FACTORS, V15, P487, DOI 10.1177/001872087301500505
   [Anonymous], 1993, CHILDRENS ENV
   [Anonymous], 1969, Proceedings of the Annual Convention of the American Psychological Association
   BARRICK MR, 1991, PERS PSYCHOL, V44, P1, DOI 10.1111/j.1744-6570.1991.tb00688.x
   Batistatou A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.819597
   BENSON C, 1973, PERCEPT PSYCHOPHYS, V13, P361, DOI 10.3758/BF03205786
   BROOKES MJ, 1972, HUM FACTORS, V14, P373, DOI 10.1177/001872087201400502
   DIGMAN JM, 1990, ANNU REV PSYCHOL, V41, P417, DOI 10.1146/annurev.psych.41.1.417
   Doggett R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.620503
   Evans GW, 2003, J SOC ISSUES, V59, P475, DOI 10.1111/1540-4560.00074
   Evans GW, 1996, J PERS SOC PSYCHOL, V70, P41
   Evans K, 2021, J PLAN EDUC RES, V41, P270, DOI 10.1177/0739456X18788938
   Evans Krista., 2018, Journal of Geography and Regional Planning, V11, P34
   Gifford R., 2007, Environmental psychology: Principles and practice, V4th
   Gifford R., 2011, IAAP Handbook of Applied Psychology, P440, DOI [DOI 10.1002/9781444395150.CH18, 10.1007/ SpringerReference_29557]
   Gifford R, 2014, ANNU REV PSYCHOL, V65, P541, DOI 10.1146/annurev-psych-010213-115048
   GORMLY J, 1983, PERS SOC PSYCHOL B, V9, P267, DOI 10.1177/0146167283092011
   Harrison XA, 2018, PEERJ, V6, DOI 10.7717/peerj.4794
   Hidalgo MC, 2001, J ENVIRON PSYCHOL, V21, P273, DOI 10.1006/jevp.2001.0221
   Hwang J, 2012, INT J CONTEMP HOSP M, V24, P224, DOI 10.1108/09596111211206150
   ICC, 2018, 2018 INT RES COD
   Jackson A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17020661
   Kaltenborn B. P., 1997, Norsk Geografisk Tidsskrift, V51, P187, DOI 10.1080/00291959708542842
   Kaya N, 2003, J ENVIRON PSYCHOL, V23, P301, DOI 10.1016/S0272-4944(02)00087-7
   Kyle G, 2004, J ENVIRON PSYCHOL, V24, P213, DOI 10.1016/j.jenvp.2003.12.006
   Li DM, 2021, J RETAIL CONSUM SERV, V59, DOI 10.1016/j.jretconser.2020.102355
   Li Z., 2018, ADV SOCIAL SCI, P176
   Magezi DA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00002
   Maher A, 2005, J ENVIRON PSYCHOL, V25, P219, DOI 10.1016/j.jenvp.2005.05.002
   Mangold S, 2019, SOC SCI-BASEL, V8, DOI 10.3390/socsci8010026
   Meagher BR, 2020, J ENVIRON PSYCHOL, V72, DOI 10.1016/j.jenvp.2020.101516
   Miller JR, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03927
   Neo JRJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.603750
   Olick D., 2018, TINY HOMES CAN MEAN
   Penfold H, 2018, AUST PLAN, V55, P164, DOI 10.1080/07293682.2019.1632360
   Pervin L. A., 1999, HDB PERSONALITY THEO, P738
   Portman ME, 2015, COMPUT ENVIRON URBAN, V54, P376, DOI 10.1016/j.compenvurbsys.2015.05.001
   Proshansky HM., 1983, Journal of environmental psychology, DOI [10.1016/S0272-4944(83)80021-8, DOI 10.1016/S0272-4944(83)80021-8]
   Raymond CM, 2010, J ENVIRON PSYCHOL, V30, P422, DOI 10.1016/j.jenvp.2010.08.002
   Rollings KA, 2019, ENVIRON BEHAV, V51, P590, DOI 10.1177/0013916518824631
   Scannell L, 2017, J ENVIRON PSYCHOL, V51, P256, DOI 10.1016/j.jenvp.2017.04.001
   Schreyer R., 1981, P APPL GEOGR C
   Shearer H., 2021, PREPRINT, DOI [10.1080/02673037.2021.1884203, DOI 10.1080/02673037.2021.1884203]
   Stamps AE, 2011, ENVIRON BEHAV, V43, P252, DOI 10.1177/0013916509354696
   Stokols Daniel., 1981, COGNITION SOC BEHAV, P441
   Wells M, 2002, ENVIRON BEHAV, V34, P300, DOI 10.1177/0013916502034003002
   Yadegari Zohre., 2020, Technium Social Sciences Journal, V3, P82, DOI [https://doi.org/10.47577/tssj.v3i1.80, DOI 10.47577/TSSJ.V3I1.80]
   Yildirim K, 2007, J ENVIRON PSYCHOL, V27, P154, DOI 10.1016/j.jenvp.2007.01.004
   Yoon S., 2010, Journal of Interior Design, V35, P33
   ZAHN GL, 1991, COMMUN RES, V18, P737, DOI 10.1177/009365091018006002
   Zerella S, 2017, J ENVIRON PSYCHOL, V54, P1, DOI 10.1016/j.jenvp.2017.08.004
NR 51
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 26
PY 2022
VL 3
AR 958829
DI 10.3389/frvir.2022.958829
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4SM7
UT WOS:001023180800001
OA gold
DA 2024-07-18
ER

PT J
AU Hayes, AT
   Hughes, CE
   Bailenson, J
AF Hayes, Aleshia Taylor
   Hughes, Charles E.
   Bailenson, Jeremy
TI Identifying and Coding Behavioral Indicators of Social Presence With a
   Social Presence Behavioral Coding System
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE mixed reality; human computer interaction; user experience evaluation;
   research methodology; social presence
ID VIRTUAL ENVIRONMENTS; RESPONSES; CONCEPTUALIZATION; PERSPECTIVE;
   ENGAGEMENT; NOVELTY; GAZE
AB Social presence, the sense of connection with another, is more important than ever as teachers, healthcare providers, and other professionals are using immersive tools to facilitate the social interaction for education, training, therapy and collaboration between geographically distributed humans and surrogates (avatars, agents, or robots). Leading researchers cite the subjective nature of the traditional self-report measures of social presence and the absence of a standardized approach to measuring social presence as a constraint to gaining deeper understanding of user's experiences of emerging and existing tools. This discourse highlights behavioral indicators of social presence that have been identified over decades across disciplines from psychology, communication, computer science, education, and engineering. The authors explicate the behavioral themes of social presence and describe a classification system grounded in exogenic and endogenic themes of social presence. This article goes on to describe the design of a social presence behavioral coding system (SPBCS) instrument that provides a structure to coding behaviors associated with a users' experience of social presence. The behavioral coding system described in this paper is the first step in creating a robust standardized approach to quantifying social presence through behavioral, physiological, and subjective indicators that ultimately may replace the current standard subjective approaches to describing the user's experience in all realities.
C1 [Hayes, Aleshia Taylor] Univ North Texas, Dept Learning Technol, SURGE XR Lab, Denton, TX 76205 USA.
   [Hughes, Charles E.] Univ Cent Florida, Ctr Res Educ Simulat Technol, Dept Comp Sci, Orlando, FL 32816 USA.
   [Bailenson, Jeremy] Stanford Univ, Dept Commun, Virtual Human Interact Lab, Stanford, CA USA.
C3 University of North Texas System; University of North Texas Denton;
   State University System of Florida; University of Central Florida;
   Stanford University
RP Hayes, AT (corresponding author), Univ North Texas, Dept Learning Technol, SURGE XR Lab, Denton, TX 76205 USA.; Hughes, CE (corresponding author), Univ Cent Florida, Ctr Res Educ Simulat Technol, Dept Comp Sci, Orlando, FL 32816 USA.
EM aleshia.prof@gmail.com; ceh@ucf.edu
FU Bill amp; Melinda Gates Foundation
FX We would like to acknowledge the principal investigators (PIs) of TLE
   TeachLivE, Lisa Dieker, and Michael Hynes who were not among the authors
   of this paper. We would like to acknowledge the Bill & Melinda Gates
   Foundation, whose gift in part supported the TeachLivE team and the
   execution of this study, and the National Science Foundation
   (CNS1051067) whose support contributed to the technical infrastructure.
CR Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2005, HUM COMMUN RES, V31, P511, DOI 10.1093/hcr/31.4.511
   Barreda-Angeles M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107047
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Biocca F., 2002, Criteria for a theory and measure of social presence
   Carretié L, 2014, COGN AFFECT BEHAV NE, V14, P1228, DOI 10.3758/s13415-014-0270-2
   Chih-Hsiung Tu, 2002, American Journal of Distance Education, V16, P131, DOI 10.1207/S15389286AJDE1603_2
   Chow Meyrick C M, 2012, NI 2012 (2012), V2012, P83
   Chuah JH, 2013, PRESENCE-VIRTUAL AUG, V22, P141, DOI 10.1162/PRES_a_00145
   Cunningham T, 2006, J ADVERTISING RES, V46, P369, DOI 10.2501/S0021849906060454
   Dawson MR, 2017, TEACH EDUC SPEC EDUC, V40, P26, DOI 10.1177/0888406416664184
   Gibson D., 2012, P SITE 2012 SOC INF
   Gunawardena C., 1995, International Journal of Educational Telecommunications, V1, P147, DOI DOI 10.1080/08923649709526970
   Gunawardena CN., 1997, American Journal of Distance Education, V11, P8, DOI [DOI 10.1080/08923649709526970, 10.1080/08923649709526970]
   Guoqiang C., 2013, Journal Of Educational Technology Development Exchange, V6, P13, DOI [10.18785/jetde.0601.02, DOI 10.18785/JETDE.0601.02]
   Hayes A., 2015, THESIS U CENTRAL FLO
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Holland NN, 2008, INTERDISCIPL SCI REV, V33, P312, DOI 10.1179/174327908X392870
   Jin SAA, 2009, CYBERPSYCHOL BEHAV, V12, P723, DOI 10.1089/cpb.2008.0289
   Kang SH, 2014, COMPUT HUM BEHAV, V34, P120, DOI 10.1016/j.chb.2014.01.006
   Li J. V., 2021, C HUM FACT COMP SYST
   Lombard M., 2009, P 12 ANN INT WORKSHO
   Lombard M., 2011, 2011 ANN C INT SOC P
   Lu BZ, 2016, COMPUT HUM BEHAV, V56, P225, DOI 10.1016/j.chb.2015.11.057
   McGreevy M.W., 1992, Presence: Teleoperators and Virtual Environments, V1, P375, DOI DOI 10.1162/PRES.1992.1.4.375
   Meehan M, 2005, APPL PSYCHOPHYS BIOF, V30, P239, DOI 10.1007/s10484-005-6381-3
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   MEHRABIAN A, 1967, J COMMUN, V17, P324
   Mennecke BE, 2011, DECISION SCI, V42, P413, DOI 10.1111/j.1540-5915.2011.00317.x
   Miller Mark Roman, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI [10.1145/3479518, 10.1145/3479544]
   Minsky Marvin, 1980, OMNI JUN, P48
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Mykota D., 2018, International Journal of E-Learning Distance Education, V33, P1
   Nam C., 2006, PRESENCE TECHNOLOGIC
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Parsons TD, 2009, STUD HEALTH TECHNOL, V142, P253, DOI 10.3233/978-1-58603-964-6-253
   Patel K., 2008, R EFFECTS FULLY IMME
   Puka L., 2011, INT ENCY STAT SCI, P713, DOI [DOI 10.1007/978-3-642-04898-2_324, 10.1007/978-3-642-04898-2_324]
   Richardson JC, 2017, COMPUT HUM BEHAV, V71, P402, DOI 10.1016/j.chb.2017.02.001
   Saldana J., 2021, ANAL INTERPRETING QU
   Schlogl A., 2002, PRESENCE RES EEG, V7
   Schultze U, 2010, INFORM SYST RES, V21, P810, DOI 10.1287/isre.1100.0321
   Sears A, 2009, HUM FACTORS ERGON, P1, DOI 10.1201/9781420088885
   Serby T, 2011, LIVERP LAW REV, V32, P181, DOI 10.1007/s10991-011-9095-z
   Shen KN, 2008, INT J HUM-COMPUT INT, V24, P722, DOI 10.1080/10447310802335789
   Skinner EA, 2009, EDUC PSYCHOL MEAS, V69, P493, DOI 10.1177/0013164408323233
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Slater M, 2009, ANU PSICOL, V40, P193
   Slattery DR, 2008, TECHNOETIC ARTS, V6, P3, DOI 10.1386/tear.6.1.3_1
   Steuer J, 1993, DEFINING VIRTUAL REA, V25
   Sun Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221803
   TAYLOR DA, 1973, MEM COGNITION, V1, P61, DOI 10.3758/BF03198069
   Thornson CA, 2009, INT J HUM-COMPUT ST, V67, P62, DOI 10.1016/j.ijhcs.2008.08.006
   Tokunaga RS, 2013, HUM COMMUN RES, V39, P365, DOI 10.1111/hcre.12008
   Waterworth JA, 2010, J CONSCIOUSNESS STUD, V17, P167
   Weston C., 2001, Qualitative Sociology, V24, P381, DOI [DOI 10.1023/A:1010690908200, 10.1023/A:1010690908200]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wood J. T., 2009, COMMUNICATION OUR LI, V5th ed., P15047060
   YANTIS S, 1993, J EXP PSYCHOL HUMAN, V19, P676, DOI 10.1037/0096-1523.19.3.676
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zimmer JC, 2010, INFORM MANAGE-AMSTER, V47, P115, DOI 10.1016/j.im.2009.12.003
NR 65
TC 2
Z9 2
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 23
PY 2022
VL 3
AR 773448
DI 10.3389/frvir.2022.773448
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OX1
UT WOS:001021714600001
OA gold
DA 2024-07-18
ER

PT J
AU Dengel, A
   Iqbal, MZ
   Grafe, S
   Mangina, E
AF Dengel, Andreas
   Iqbal, Muhammad Zahid
   Grafe, Silke
   Mangina, Eleni
TI A Review on Augmented Reality Authoring Toolkits for Education
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE Augmented reality; immersive learning; authoring toolkit;
   technology-enhanced learning; augmented reality learning
ID TOOLS; DESIGN
AB Creating pedagogically sound, interactive Augmented Reality (AR) experiences supporting situated and experiential learning remains a challenge to teachers without programming skills. To integrate AR in the everyday classroom, teachers need to be capable of designing their own immersive experiences for their students, which is why an analysis of existing authoring toolkits is necessary to identify suitable tools for educational application development and future research directions in terms of educational AR. We identified "easy access", "GUI-based design", and "interactive contents" as needs of teachers for designing AR content for the classroom. Based on these needs, we conducted a literature review of 835 documents. Of 80 relevant articles, we included 43 peer-reviewed articles from ACM Digital Library, DBLP, IEEExplore, Scopus, Web of Science, Google Scholar, and miscellaneous other sources in our analysis. We identified 69 different AR authoring toolkits and classified these with regard to their accessibility, their degree of required programming knowledge, and their interactivity. The results show a divergent research landscape with a lack of empirical evaluation. Of 26 openly accessible toolkits, we identified five toolkits addressing the defined needs of teachers for designing interactive AR experiences for the classroom without requiring extensive programming knowledge. We conclude that there are only few tools for the straightforward design of educational AR experiences addressing the needs of teachers and suggest using research-informed and evidence-based criteria for developing AR authoring toolkits for education.
C1 [Dengel, Andreas] Goethe Univ Frankfurt, Fac Comp Sci, Frankfurt, Germany.
   [Iqbal, Muhammad Zahid; Mangina, Eleni] Univ Coll Dublin, Coll Sci, Sch Comp Sci, Dublin, Ireland.
   [Grafe, Silke] Julius Maximilian Univ Wurzburg, Chair Sch Pedag, Wurzburg, Germany.
C3 Goethe University Frankfurt; University College Dublin; University of
   Wurzburg
RP Iqbal, MZ (corresponding author), Univ Coll Dublin, Coll Sci, Sch Comp Sci, Dublin, Ireland.
EM Muhammad-zahid.iqbal@ucdconnect.ie
RI Dengel, Andreas/AAE-8190-2019; Iqbal, Muhammad Zahid/AAU-4937-2020
OI Iqbal, Muhammad Zahid/0000-0002-2761-4163
FU European Union [856533]
FX & nbsp;The publication has been supported by European Union's Horizon
   2020 research and innovation program under grant agreement No 856533,
   project ARETE.
CR A-Frame, 2021, INSTALLATION A FRAME
   Adcock M, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P1, DOI 10.1109/ART.2003.1320415
   Alzahrani N. M., 2019, INT C HUMAN INTERACT, P282, DOI [10.1007/978-3-030-25629-6_44, DOI 10.1007/978-3-030-25629-6_44]
   [Anonymous], 1994, Bloom's taxonomy
   [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI DOI 10.1371/JOURNAL.PMED.1000097
   ARCore, 2021, ARCORE
   Areeka, 2021, ABOUT US
   Arete, 2021, ARETE HOME
   ARgent, 2020, AVRUPA BILIM TEKNOLO, P244
   ARKit, 2021, ARKIT OVERVIEW
   ARToolKit, 2021, ARTOOLKIT DOWNLOAD
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   AugmentedBook, 2019, AUGMENTEDBOOK COLLAB
   AuthorAR, 2013, AUTHORAR AUTHORING T
   AWE, 2021, CREAT WEB AW AUGM WE
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Balcisoy S., 2000, P ACM S VIRTUAL REAL, P61, DOI DOI 10.1145/502390.502403
   Barbadillo J, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P206
   Bauer M, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P45, DOI 10.1109/ISAR.2001.970514
   Bégout P, 2020, LECT NOTES COMPUT SC, V12243, P304, DOI 10.1007/978-3-030-58468-9_22
   Benbelkacem S, 2020, J KING SAUD UNIV-COM, V32, P433, DOI 10.1016/j.jksuci.2019.11.010
   Billinghurst M, 2001, COMPUT GRAPH-UK, V25, P745, DOI 10.1016/S0097-8493(01)00117-0
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Blippar, 2021, AUG REAL AR COMP VIS
   Blippbuilder, 2021, AUGM REAL CREAT TECH
   BlocklyXR, 2021, BLOCKL INT EXT REAL
   BOYKO A, 2014, P 27 ANN ACM S US IN, P33, DOI DOI 10.1145/2642918.2647418
   Buchner J, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P287
   Chang Y.J., 2011, 2011 IEEE INT C MULT, P1, DOI DOI 10.1109/ICME.2011.6012177
   Chaudhary V, 2006, INT CONF PARA PROC, P415
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Coma-Tatay I, 2019, MULTIMED TOOLS APPL, V78, P6093, DOI 10.1007/s11042-018-6395-5
   CoSpaces, 2021, COSP ED KID FRIENDL
   Crawford S., 2020, VIRTUAL REALITY SCEN
   da Silva V. C., 2011, 2011 XIII Symposium on Virtual Reality (SVR), P128, DOI 10.1109/SVR.2011.38
   Dag F, 2014, PROCD SOC BEHV, V116, P888, DOI 10.1016/j.sbspro.2014.01.316
   de Dinechin GD, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P857, DOI [10.1109/VRW50115.2020.00280, 10.1109/VRW50115.2020.00010]
   de Dinechin GD, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P801, DOI [10.1109/VRW50115.2020.00251, 10.1109/VRW50115.2020.00-24]
   Designar, 2021, DES BUILD AR EXP YOU
   Dias JMS, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P18, DOI 10.1109/ART.2003.1320420
   Dias M, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P54, DOI 10.1109/ART.2003.1320428
   Dinechin G. D. d., 2020, 2020 IEEE C VIRTUAL, P844, DOI [10.1109/VRW50115.2020.00273, DOI 10.1109/VRW50115.2020.00273]
   Dinechin GDd, 2020, 2020 IEEE C VIRTUAL, P348, DOI DOI 10.1109/VRW50115.2020.00076
   DiVerdi S, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P86, DOI 10.1109/ART.2003.1320436
   Dodds H. E., 2021, PRACTITIONERS GUIDE
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Dwarf, 2021, DWARF INST TUT
   Ediphy, 2020, EDIPH MOD EXT OP SOU
   Engine U, 2021, ABOUT US
   FI-AR, 2019, FI AR LEARN WEB BAS
   FitzGerald E., 2012, 11 WORLD C MOB CONT, V955955, P6262
   Freitas G, 2020, SYMP VIRTUAL AUGMENT, P199, DOI 10.1109/SVR51698.2020.00041
   Gandy M., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology - UIST '14, P627
   Gandy M., 2006, SUPPORTING EARLY DES, DOI [10.4018/9781599040660.ch008, DOI 10.4018/9781599040660.CH008]
   GooglePoly, 2021, POLY
   Grimm P., 2002, First IEEE International Augmented Reality Toolkit Workshop. Proceedings (Cat. No.02EX632), DOI 10.1109/ART.2002.1107008
   Guimaraes MDP, 2017, LECT NOTES COMPUT SC, V10404, P585, DOI 10.1007/978-3-319-62392-4_42
   Haller M., 2002, First IEEE International Augmented Reality Toolkit Workshop. Proceedings (Cat. No.02EX632), DOI 10.1109/ART.2002.1106978
   Henrysson A, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P27, DOI 10.1109/ART.2003.1320421
   Huang TC, 2016, COMPUT EDUC, V96, P72, DOI 10.1016/j.compedu.2016.02.008
   ImageTcl, 2021, IM MULT DEV SYST
   Inglobe Technologies, 2021, AR MED FEAT
   Inglobe Technologies, 2021, AR MED DOWNL
   InstantReality, 2021, ABOUT US
   Iqbal M, 2022, POLYM BULL, V79, P5019, DOI 10.1007/s00289-021-03763-1
   Jee H.-K., 2011, 2011 INT C INF SCI A, P1, DOI [10.1109/icisa.2011.5772399, DOI 10.1109/ICISA.2011.5772399]
   Jesionkowska J, 2020, EDUC SCI, V10, DOI 10.3390/educsci10080198
   Jinhyuk Choi, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P219, DOI 10.1109/ISMAR.2010.5643576
   Jinwook Shim, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P105, DOI 10.1007/978-3-642-22021-0_13
   Jo D, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174912
   Jung K, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031073
   Kampa A, 2017, LECT NOTES COMPUT SC, V10690, P372, DOI 10.1007/978-3-319-71027-3_46
   Kato H, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P77, DOI 10.1109/ART.2003.1320435
   Kato H, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P75, DOI 10.1109/ART.2003.1320434
   Kato H., 2007, 1 IEEE INT WORKSH AU
   Kim SL, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P21, DOI 10.1109/WF-IoT.2014.6803110
   Kljun M., 2020, Augmented reality in education, P3, DOI DOI 10.1007/978-3-030-42156-41
   Kosko K. W., 2021, Journal of Technology and Teacher Education, V29, P257
   Krauss V, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445335
   Lanham Micheal, 2018, Learn ARCore-Fundamentals of Google ARCore: Learn to build augmented reality apps for Android, Unity, and the web with Google ARCore 1.0
   Latoschik ME, 2014, WORK SOFTW ENG, P9, DOI 10.1109/SEARIS.2014.7152796
   Layar, 2021, SOL LAY
   Ledermann F., 2004, AUTHORING FRAMEWORK
   Lee B.-g., 2020, 2020 IEEE INT C CONS, P1, DOI [10.1109/icce-asia49877.2020.9276896, DOI 10.1109/ICCE-ASIA49877.2020.9276896]
   Lee GA, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P172, DOI 10.1109/ISMAR.2004.34
   Li Wenkai., 2017, Multimodal Technol Inter, V1, P17, DOI [DOI 10.3390/MTI1030017, 10.3390/mti1030017]
   Liao T, 2015, NEW MEDIA SOC, V17, P1418, DOI 10.1177/1461444814527734
   Looser J., 2010, MAKING AUGMENTED REA
   Looser J., 2006, OSGART A PRAGMATIC A
   López-Pernas S, 2020, INT CONF INTEL ENVIR, P119, DOI [10.1109/ie49459.2020.9154949, 10.1109/IE49459.2020.9154949]
   Lucrecia M, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P503
   MacIntyre B, 2005, ACM T GRAPHIC, V24, P932, DOI 10.1145/1073204.1073288
   MacIntyre B, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P329, DOI 10.1109/ISMAR.2003.1240744
   MagicBook, 2021, MAGICBOOK 4D AR LEAR
   MAGIS, 2019, MAG MOB AUGM REAL GA
   Metaio, 2021, MET CREAT FREE DOWNL
   Mirage XR, 2021, ABOUT US
   Moorhouse N., 2017, EREVIEW TOURISM RES, V8
   Mota J. M., 2016, VISUAL ENV DESIGNING
   Mota RC, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P164, DOI 10.1109/ISMAR.2015.47
   MRToolkit, 2021, GITH MICR MIX UN MIX
   Murray T., 2004, Educational Technology, V44, P10
   Murray T, 2016, INT J ARTIF INTELL E, V26, P37, DOI 10.1007/s40593-015-0076-6
   Nebeling M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P333, DOI 10.1109/ISMAR-Adjunct.2018.00098
   Nincarean D, 2013, PROCD SOC BEHV, V103, P657, DOI 10.1016/j.sbspro.2013.10.385
   OSGART, 2021, OSG ART OP
   Packer HS, 2017, LECT NOTES COMPUT SC, V10690, P63, DOI 10.1007/978-3-319-71027-3_6
   Pan Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P188, DOI [10.1109/VRW50115.2020.0-235, 10.1109/VRW50115.2020.00041]
   Pan Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P759, DOI [10.1109/VRW50115.2020.00-45, 10.1109/VRW50115.2020.00230]
   Park JS, 2011, MULTIMED TOOLS APPL, V55, P725, DOI 10.1007/s11042-010-0592-1
   Pessoa SA, 2012, COMPUT GRAPH-UK, V36, P50, DOI 10.1016/j.cag.2011.12.003
   Pintaric T, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P71, DOI 10.1109/ART.2003.1320431
   Poupyrev I., 2001, 2001 INTERACT 2001 C
   Radu I., 2009, Proceedings of the 8th International Conference on Interaction Design and Children, P210, DOI DOI 10.1145/1551788.1551831
   Read J. C., 2008, P 3 INT C DIG INT ME, P85, DOI [10.1145/1413634.1413654, DOI 10.1145/1413634.1413654]
   Reimann C, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P32, DOI 10.1109/ART.2003.1320423
   Reipschläger P, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P29, DOI 10.1145/3343055.3359718
   Roberto RA, 2016, LECT NOTES COMPUT SC, V9748, P237, DOI 10.1007/978-3-319-40406-6_22
   Roldán-Alvarez D, 2016, INT J HUM-COMPUT ST, V94, P18, DOI 10.1016/j.ijhcs.2016.04.011
   Sanders A., 2016, INTRO UNREAL ENGINE
   Santos P, 2007, LECT NOTES COMPUT SC, V4564, P435
   Sawasdee T., 2011, DEV AUGM REAL APPL A, DOI [10.1115/1.859926.paper24, DOI 10.1115/1.859926.PAPER24]
   Saykili A, 2019, PROC TEACH EDUCATION, P323, DOI 10.20472/TEC.2019.008.024
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Seichter H, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P42, DOI 10.1109/ART.2003.1320425
   Shibolet Y, 2018, LECT NOTES COMPUT SC, V11318, P523, DOI 10.1007/978-3-030-04028-4_61
   Simonetti Ibanez A., 2013, Vuforia v1. 5 sdk: Analysis and evaluation of capabilities
   Singh A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P713, DOI 10.1109/VR50410.2021.00098
   Snap Inc, 2021, DOWNL LENS STUD SNAP
   Spark A., 2019, STUDIO
   SparkAR, 2021, SPARK AR STUD
   Speicher M., 2015, INFORMATIK
   StoryCreatAR, 2021, STOR CREAT TOOLK SPA
   Studierstube, 2021, STUD DOWNL
   Sudwest M. F., 2018, KIM STUDIE 2020
   Sudwest M. F., 2020, JIM STUDIE 2020
   Takala TM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P859, DOI [10.1109/VRW50115.2020.00282, 10.1109/VRW50115.2020.00283]
   Unity, 2021, ABOUT US
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Vedils, 2021, VED VIS ENV DES INT
   Vert S, 2017, IEEE INT CONF ADV LE, P496, DOI 10.1109/ICALT.2017.129
   Vidal ECE, 2019, INTERACT LEARN ENVIR, V27, P895, DOI 10.1080/10494820.2018.1504305
   Villanueva A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376146
   Vuforia, 2021, VUF STUD AUGM REAL I
   Vuforia, 2021, Vuforia Developer Portal
   Wagner M, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P62, DOI 10.1109/ART.2003.1320429
   Wagner M. T., 2002, First IEEE International Augmented Reality Toolkit Workshop. Proceedings (Cat. No.02EX632), DOI 10.1109/ART.2002.1106970
   Wang MJ, 2010, IFIP ADV INF COMM TE, V332, P285
   Wang W., 2018, BEGINNING ARKIT IPHO
   WEKIT, 2021, D2 5 WEKIT1 FINAL PR
   Wheeler G, 2018, HEALTHC TECHNOL LETT, V5, P148, DOI 10.1049/htl.2018.5064
   Whitlock Matt, 2020, Virtual, Augmented and Mixed Reality. Design and Interaction. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12190), P235, DOI 10.1007/978-3-030-49695-1_16
   Wikitude, 2021, WORLD LEAD AUGM REAL
   Woolard A, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P69, DOI 10.1109/ART.2003.1320430
   Xiao F., 2003, P INT WORKSH SOFTW T, P537
   Yang KX, 2020, Arxiv, DOI arXiv:2010.13779
   Ying Li, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P187, DOI 10.1109/ICACTE.2010.5579661
   Yusoff RCM, 2019, ADV INTELL SYST COMP, V843, P1037, DOI 10.1007/978-3-319-99007-1_96
NR 158
TC 12
Z9 12
U1 3
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 27
PY 2022
VL 3
AR 798032
DI 10.3389/frvir.2022.798032
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4SX8
UT WOS:001023191900001
OA gold
DA 2024-07-18
ER

PT J
AU Smith, KL
   Wang, Y
   Colloca, L
AF Smith, Kathryn L.
   Wang, Yang
   Colloca, Luana
TI Impact of Virtual Reality Technology on Pain and Anxiety in Pediatric
   Burn Patients: A Systematic Review and Meta-Analysis
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE pediatrics; burn wound care; nonpharmacological intervention; acute pain
   management; distraction analgesia
ID YOUNG-CHILDREN
AB Introduction: Virtual reality (VR) has the potential to lessen pain and anxiety experienced by pediatric patients undergoing burn wound care procedures. Population-specific variables require novel technological application and thus, a systematic review among studies on its impact is warranted.Objective: The objective of this review was to evaluate the effectiveness of VR on pain in children with burn injuries undergoing wound care procedures.Methods: A systematic literature review was performed using PubMed and CINAHL databases from January 2010 to July 2021 with the keywords "pediatric," "burn," "virtual reality," and "pain." We included experimental studies of between- and within-subjects designs in which pediatric patients' exposure to virtual reality technology during burn wound care functioned as the intervention of interest. Two researchers independently performed the literature search, made judgements of inclusion/exclusion based on agreed-upon criteria, abstracted data, and assessed quality of evidence using a standardized appraisal tool. A meta-analysis was conducted to evaluate the effectiveness of the VR on burning procedural pain in pediatric population. Standardized mean difference (SMD) was used as an index of combined effect size, and a random effect model was used for meta-analysis.Results: Ten articles published between January 2010 and July 2021 passed the selection criteria: six randomized controlled trials and four randomized repeated-measures studies. Consistent results among the studies provided support for VR as effective in reducing pain and potentially pain related anxiety in children undergoing burn wound care through preprocedural preparation (n = 2) and procedural intervention (n = 8). A random effects meta-analysis model indicated a moderate and significant combined effect size (SMD = 0.60, 95% CI = 0.28-0.93, p = 0.0031) of VR effects on pain intensity ratings with no significant heterogeneity of VR intervention effects between studies. Only one study reported direct influence of VR intervention on pre-procedural situational anxiety with a moderate effect size (Cohen's d = 0.575, 95%CI = 0.11-1.04).Conclusion: Children's exposure to VR during burn care procedures was associated with lower levels of pain and pain related anxiety. Moderate to large effect sizes support the integration of VR into traditional pediatric burn pain protocols irrespective of innovative delivery methods and content required for use in burned pediatric patients.
C1 [Smith, Kathryn L.; Wang, Yang; Colloca, Luana] Univ Maryland, Sch Nursing, Dept Pain Translat Symptom Sci, Baltimore, MD 21201 USA.
   [Wang, Yang; Colloca, Luana] Univ Maryland, Ctr Adv Chron Pain Res, Baltimore, MD 21201 USA.
   [Colloca, Luana] Univ Maryland, Sch Med, Dept Anesthesiol & Psychiat, Baltimore, MD 21201 USA.
C3 University System of Maryland; University of Maryland Baltimore;
   University System of Maryland; University of Maryland Baltimore;
   University System of Maryland; University of Maryland Baltimore
RP Colloca, L (corresponding author), Univ Maryland, Sch Nursing, Dept Pain Translat Symptom Sci, Baltimore, MD 21201 USA.; Colloca, L (corresponding author), Univ Maryland, Ctr Adv Chron Pain Res, Baltimore, MD 21201 USA.; Colloca, L (corresponding author), Univ Maryland, Sch Med, Dept Anesthesiol & Psychiat, Baltimore, MD 21201 USA.
EM colloca@umaryland.edu
RI Colloca, Luana/S-1389-2018; Wang, Yang/HTP-8917-2023
OI Wang, Yang/0000-0002-6630-8425
FU National Center for Complementary and Integrative Medicine; MPowering
   the State Grants;  [NCCIH: 1R01AT010333];  [R01 AT011347-01A1]; National
   Center for Complementary and Integrative Health [R01AT011347,
   R01AT010333] Funding Source: NIH RePORTER; National Institute on Alcohol
   Abuse and Alcoholism [R13AA028424] Funding Source: NIH RePORTER
FX LC reported having received support for Invited Lectures outside the
   submitted work. This research is supported by National Center for
   Complementary and Integrative Medicine (NCCIH: 1R01AT010333, R01
   AT011347-01A1, LC) and the MPowering the State Grants (LC). The funding
   agencies have no roles in the study. The views expressed here are the
   authors' own and do not reflect the position or policy of the National
   Institutes of Health or any other part of the federal and state
   government.
CR Alnababtah K, 2016, PAEDIATR INT CHILD H, V36, P45, DOI 10.1179/2046905514Y.0000000157
   Borenstein M, 2010, RES SYNTH METHODS, V1, P97, DOI 10.1002/jrsm.12
   Brown NJ, 2014, BURNS, V40, P204, DOI 10.1016/j.burns.2013.11.024
   Cohen LL, 2008, J PEDIATR PSYCHOL, V33, P939, DOI 10.1093/jpepsy/jsm103
   Colloca L, 2020, PAIN, V161, P2010, DOI 10.1097/j.pain.0000000000001900
   Dahlquist LM, 2009, J PEDIATR PSYCHOL, V34, P574, DOI 10.1093/jpepsy/jsn023
   Darnall BD, 2020, JMIR FORM RES, V4, DOI 10.2196/17293
   de Jong AEE, 2014, BURNS, V40, P38, DOI 10.1016/j.burns.2013.09.017
   Dumoulin S, 2019, GAMES HEALTH J, V8, P285, DOI 10.1089/g4h.2018.0111
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   Gerçeker GÖ, 2021, EUR J ONCOL NURS, V50, DOI 10.1016/j.ejon.2020.101886
   Gutierrez-Martinez O, 2010, STUD HEALTH TECHNOL, V154, P155, DOI 10.3233/978-1-60750-561-7-155
   Higgins JPT, 2003, BMJ-BRIT MED J, V327, P557, DOI 10.1136/bmj.327.7414.557
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Hoffman HG, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.602299
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Honzel E, 2019, PAIN, V160, P1909, DOI 10.1097/j.pain.0000000000001539
   Jeffs D, 2014, J BURN CARE RES, V35, P395, DOI 10.1097/BCR.0000000000000019
   Justus Rachel, 2006, Pediatr Nurs, V32, P35
   Khadra C, 2020, BURNS, V46, P1571, DOI 10.1016/j.burns.2020.04.006
   Khadra C, 2018, J PAIN RES, V11, P343, DOI 10.2147/JPR.S151084
   Kipping B, 2012, BURNS, V38, P650, DOI 10.1016/j.burns.2011.11.010
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Le May S, 2021, PAIN MANAG NURS, V22, P191, DOI 10.1016/j.pmn.2020.10.002
   MANNE SL, 1992, PAIN, V48, P45, DOI 10.1016/0304-3959(92)90130-4
   McGarry S, 2014, BURNS, V40, P606, DOI 10.1016/j.burns.2013.08.031
   McMurtry C Meghan, 2015, Clin J Pain, V31, pS3, DOI 10.1097/AJP.0000000000000272
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   Miller K, 2011, BURNS, V37, P395, DOI 10.1016/j.burns.2010.12.008
   Newhouse R.P., 2007, Johns Hopkins Nursing - Evidence-Based Practice Model and Guidelines
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Sahiner NC, 2016, J CHILD HEALTH CARE, V20, P277, DOI 10.1177/1367493515587062
   Scapin S, 2018, BURNS, V44, P1403, DOI 10.1016/j.burns.2017.11.002
   Squires V L, 1995, Semin Perioper Nurs, V4, P80
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Won AS, 2017, CHILDREN-BASEL, V4, DOI 10.3390/children4070052
   Xiang H, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.12082
NR 38
TC 7
Z9 7
U1 4
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 6
PY 2022
VL 2
AR 751735
DI 10.3389/frvir.2021.751735
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L3EE1
UT WOS:001022116400001
PM 36247202
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Jeong, HS
   Oh, J
   Paik, M
   Kim, H
   Jang, S
   Kim, BS
   Kim, JJ
AF Jeong, Hyu Seok
   Oh, Jooyoung
   Paik, Minjeong
   Kim, Hyunji
   Jang, Sooah
   Kim, Beom Soo
   Kim, Jae-Jin
TI Development and Feasibility Assessment of Virtual Reality-Based
   Relaxation Self-Training Program
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; relaxation; self-training; diaphragmatic breathing;
   progressive muscle relaxation
ID PROGRESSIVE MUSCLE-RELAXATION; QUALITY-OF-LIFE; SOCIAL ANXIETY DISORDER;
   BEHAVIORAL TREATMENT; CANCER-PATIENTS; EXPOSURE; THERAPY; DEPRESSION;
   CHEMOTHERAPY; AGORAPHOBIA
AB Diaphragmatic breathing and progressive muscle relaxation (PMR) are an effective way for relaxation training and anxiety control, but their use is not common to the general public. Today, as the need for non-face-to-face contact increases, virtual reality (VR)-based self-training is gaining attention in public health. This study aimed to evaluate the feasibility of the newly developed VR-based relaxation training program. Both diaphragmatic breathing and PMR can be trained without an assistant using this VR application in three steps: 1) learning in a virtual clinic, 2) review in a comfortable virtual environment, and 3) practice in outdoor virtual environments. Self-training is recommended on a 3-weeks schedule with a total of 4-6 trials per day for 4 days a week. Thirty-one healthy volunteers were divided into the VR (n = 15) and worksheet (n = 16) groups, and participated in self-training under similar conditions as much as possible. Multiple evaluations were performed before, during, and after self-training. The change rates of all psychological and psychophysiological measures before and after self-training did not significantly differ between the two groups. The levels of tension after breathing practices showed no group difference, whereas those after PMR practices were significantly lower in the VR group than in the worksheet group. In the VR group, trials of outdoor practices tended to induce a decrease of the tension level, particularly after outdoor breathing trials. The VR group gave a practicable score of 70 points or more, average 43.5, and average 180.3 for usability, cybersickness, and presence of this program, respectively. These results suggest that the VR-based relaxation self-training program can be used by healthy people as a means of relaxation. In the use of this program, diaphragmatic breathing may be used more easily, but the benefit of using VR is higher in PMR. These findings provide justification for a randomized controlled study of whether this program can be used for stress relief in the general population and, furthermore, treatment of patients with anxiety disorders.
C1 [Jeong, Hyu Seok; Oh, Jooyoung; Kim, Jae-Jin] Yonsei Univ, Dept Psychiat, Coll Med, Seoul, South Korea.
   [Jeong, Hyu Seok; Oh, Jooyoung; Paik, Minjeong; Kim, Hyunji; Jang, Sooah; Kim, Beom Soo; Kim, Jae-Jin] Yonsei Univ, Inst Behav Sci Med, Coll Med, Seoul, South Korea.
C3 Yonsei University; Yonsei University Health System; Yonsei University;
   Yonsei University Health System
RP Kim, JJ (corresponding author), Yonsei Univ, Dept Psychiat, Coll Med, Seoul, South Korea.; Kim, JJ (corresponding author), Yonsei Univ, Inst Behav Sci Med, Coll Med, Seoul, South Korea.
EM jaejkim@yonsei.ac.kr
RI Jeong, Hyu seok/HOC-2008-2023
OI Jeong, Hyu seok/0000-0002-7382-9413; Oh, Jooyoung/0000-0001-6721-399X;
   Kim, Jae-Jin/0000-0002-1395-4562
FU National IT Industry Promotion Agency (NIPA); National Research
   Foundation of Korea (NRF) - Korea government (MSIP)
   [NRF-2021M3E5D9025019]
FX This work was supported by 2018 VR/AR/MR flagship project of the
   National IT Industry Promotion Agency (NIPA) and by the National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (MSIP) (No. NRF-2021M3E5D9025019).
CR Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Anderson PL, 2013, J CONSULT CLIN PSYCH, V81, P751, DOI 10.1037/a0033559
   BARLOW DH, 1989, BEHAV THER, V20, P261, DOI 10.1016/S0005-7894(89)80073-5
   Baxter AJ, 2013, PSYCHOL MED, V43, P897, DOI 10.1017/S003329171200147X
   Bouchard Stephane, 2006, Technol Health Care, V14, P19
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Cárdenas G, 2006, CYBERPSYCHOL BEHAV, V9, P248, DOI 10.1089/cpb.2006.9.248
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Charalambous A, 2015, EVID-BASED COMPL ALT, V2015, DOI 10.1155/2015/270876
   Chen YF, 2017, PERSPECT PSYCHIATR C, V53, P329, DOI 10.1111/ppc.12184
   Cheung YL, 2003, PSYCHO-ONCOLOGY, V12, P254, DOI 10.1002/pon.638
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   Conrad A, 2007, J ANXIETY DISORD, V21, P243, DOI 10.1016/j.janxdis.2006.08.001
   Dadashi M, 2015, BASIC CLIN NEUROSCI, V6, P14
   Emmelkamp PMG, 2001, CYBERPSYCHOL BEHAV, V4, P335, DOI 10.1089/109493101300210222
   Feldman G, 2010, BEHAV RES THER, V48, P1002, DOI 10.1016/j.brat.2010.06.006
   Fields JA, 2012, MIL MED, V177, P1492, DOI 10.7205/MILMED-D-12-00036
   Gálvez-García G, 2015, HUM FACTORS, V57, P649, DOI 10.1177/0018720814554948
   Grinberg AS, 2020, UROLOGY, V137, P26, DOI 10.1016/j.urology.2019.12.024
   Han JN, 1996, J PSYCHOSOM RES, V41, P481, DOI 10.1016/S0022-3999(96)00220-6
   HIBBERT GA, 1989, BRIT J PSYCHIAT, V154, P232, DOI 10.1192/bjp.154.2.232
   Hong YJ, 2017, CYBERPSYCH BEH SOC N, V20, P753, DOI 10.1089/cyber.2017.0085
   Jiménez-Rodríguez D, 2019, ENFERM CLIN, V29, P178, DOI 10.1016/j.enfcli.2018.07.005
   Kampmann IL, 2016, BEHAV RES THER, V77, P147, DOI 10.1016/j.brat.2015.12.016
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khan R, 2019, ENDOSCOPY, V51, P653, DOI 10.1055/a-0894-4400
   Kidwell KM, 2015, J HEALTH PSYCHOL, V20, P1377, DOI 10.1177/1359105313512352
   Kim HE, 2017, COMPUT HUM BEHAV, V73, P614, DOI 10.1016/j.chb.2017.04.017
   Kim SY, 2012, J CLIN PSYCHIAT, V73, P931, DOI 10.4088/JCP.11m07068
   Knight WEJ, 2001, J MUSIC THER, V38, P254, DOI 10.1093/jmt/38.4.254
   Kothgassner OD, 2019, EUR J PSYCHOTRAUMATO, V10, DOI 10.1080/20008198.2019.1654782
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   Lai Byron, 2016, JMIR Rehabil Assist Technol, V3, pe8, DOI 10.2196/rehab.5524
   Lee J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051493
   Ma X, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00874
   Malbos E, 2013, AUST NZ J PSYCHIAT, V47, P160, DOI 10.1177/0004867412453626
   Manzoni GM, 2008, BMC PSYCHIATRY, V8, DOI 10.1186/1471-244X-8-41
   Marco JH, 2013, PSYCHIAT RES, V209, P619, DOI 10.1016/j.psychres.2013.02.023
   Matsumoto M, 2001, J CLIN PSYCHOL, V57, P1551, DOI 10.1002/jclp.1117
   McKnight PE, 2016, CLIN PSYCHOL REV, V45, P115, DOI 10.1016/j.cpr.2015.10.005
   Migoya-Borja M, 2020, CYBERPSYCH BEH SOC N, V23, P246, DOI 10.1089/cyber.2019.0497
   Molassiotis A, 2002, SUPPORT CARE CANCER, V10, P237, DOI 10.1007/s00520-001-0329-9
   Moline J, 1997, ST HEAL T, V44, P3
   Moore J, 2009, J REHABIL MED, V41, P195, DOI 10.2340/16501977-0308
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Norton PJ, 2007, J NERV MENT DIS, V195, P521, DOI 10.1097/01.nmd.0000253843.70149.9a
   Özlü I, 2021, PERSPECT PSYCHIATR C, V57, P1791, DOI 10.1111/ppc.12750
   Palazzo C, 2016, ANN PHYS REHABIL MED, V59, P107, DOI 10.1016/j.rehab.2016.01.009
   Park KM, 2011, PSYCHIAT RES, V189, P166, DOI 10.1016/j.psychres.2011.04.003
   Pelekasis P, 2017, PALLIAT SUPPORT CARE, V15, P465, DOI 10.1017/S1478951516000870
   Piccione J, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02583
   Prisnie JC, 2018, GEN HOSP PSYCHIAT, V52, P58, DOI 10.1016/j.genhosppsych.2018.03.009
   Scalese RJ, 2008, J GEN INTERN MED, V23, P46, DOI 10.1007/s11606-007-0283-4
   Segawa T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01409
   Sheik-Ali Sharaf, 2019, Surg Technol Int, V35, P27
   Subbalakshmi NK, 2014, J DIABETES INVEST, V5, P456, DOI 10.1111/jdi.12163
   최아영, 2014, Korean Journal of Clinical Psychology, V33, P413
   Tortella-Feliu M, 2011, BEHAV MODIF, V35, P3, DOI 10.1177/0145445510390801
   Toussaint L, 2021, EVID-BASED COMPL ALT, V2021, DOI 10.1155/2021/5924040
   Veling W, 2021, J MED INTERNET RES, V23, DOI 10.2196/17233
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wibirama S, 2014, IEEE ENG MED BIO, P4803, DOI 10.1109/EMBC.2014.6944698
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Zhao LP, 2012, EUR J OBSTET GYN R B, V162, P211, DOI 10.1016/j.ejogrb.2012.02.029
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 68
TC 1
Z9 1
U1 3
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 5
PY 2022
VL 2
AR 722558
DI 10.3389/frvir.2021.722558
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TM1
UT WOS:001021834400001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Buck, L
   Paris, R
   Bodenheimer, B
AF Buck, Lauren
   Paris, Richard
   Bodenheimer, Bobby
TI Distance Compression in the HTC Vive Pro: A Quick Revisitation of
   Resolution
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; perception; distance compression; head-mounted
   displays; human-computer interaction
ID VIRTUAL ENVIRONMENTS; REAL; PERCEPTION; DISPLAYS
AB Spatial perception in immersive virtual environments, particularly regarding distance perception, is a well-studied topic in virtual reality literature. Distance compression, or the underestimation of distances, is and has been historically prevalent in all virtual reality systems. The problem of distance compression still remains open, but recent advancements have shown that as systems have developed, the level of distance compression has decreased. Here, we add evidence to this trend by beginning the assessment of distance compression in the HTC Vive Pro. To our knowledge, there are no archival results that report any findings about distance compression in this system. Using a familiar paradigm for studying distance compression in virtual reality hardware, we asked users to blind walk to a target object placed in a virtual environment and assessed their judgments based on those distances. We find that distance compression in the HTC Vive Pro mirrors that of the HTC Vive. Our results are not particularly surprising, considering the nature of the differences between the two systems, but they lend credence to the finding that resolution does not affect distance compression. More extensive study should be performed to reinforce these results.
C1 [Buck, Lauren; Bodenheimer, Bobby] Vanderbilt Univ, Dept Elect Engn & Comp Sci, Learning Virtual Environm Lab, Nashville, TN 37235 USA.
   [Paris, Richard] Verizon Wireless, Nashville, TN USA.
C3 Vanderbilt University
RP Buck, L (corresponding author), Vanderbilt Univ, Dept Elect Engn & Comp Sci, Learning Virtual Environm Lab, Nashville, TN 37235 USA.
EM lauren.e.buck.1@vanderbilt.edu
FU Office of Naval Research [N00014-18-1-2964]
FX Funding This work is supported under a grant issued by the Office of
   Naval Research (N00014-18-1-2964).
CR Buck LE, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3196885
   Creem-Regehr SH, 2015, PSYCHOL LEARN MOTIV, V62, P195, DOI 10.1016/bs.plm.2014.09.006
   Creem-Regehr SH, 2005, PERCEPTION, V34, P191, DOI 10.1068/p5144
   Feldstein IT, 2020, PERCEPTION, V49, P940, DOI 10.1177/0301006620951997
   Fidopiastis C, 2005, PRESENCE-TELEOP VIRT, V14, P550, DOI 10.1162/105474605774918697
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Gagnon HC, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3449067
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Jones JB, 2012, PLANT NUTRITION AND SOIL FERTILITY MANUAL, 2ND EDITION, P119
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Langbehn E, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P241, DOI 10.1145/2993369.2993379
   Li BC, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3165286
   Lin Q., 2011, P ACM SIGGRAPH S APP, P75, DOI DOI 10.1145/2077451.2077465
   Masnadi S, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P542, DOI 10.1109/VRW52623.2021.00153
   Mohler BJ, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P194
   Peer A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P219, DOI [10.1109/VRW50115.2020.0-229, 10.1109/VRW50115.2020.00047]
   Peer A, 2017, IEEE SYMP 3D USER, P83, DOI 10.1109/3DUI.2017.7893321
   Peillard E, 2020, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR50242.2020.00028
   Phillips L, 2010, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2010.5444802
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Sinai MJ, 1998, NATURE, V395, P497, DOI 10.1038/26747
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   Willemsen P, 2002, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2002.996536
   Willemsen P, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498702
   Witmer BG, 1998, HUM FACTORS, V40, P478, DOI 10.1518/001872098779591340
   Wright R. H., 1995, 1025 ARM RES I BEH S
   Wu B, 2004, NATURE, V428, P73, DOI 10.1038/nature02350
   Young M. K., 2014, P ACM S APPL PERCEPT, P83
   Zhang J., 2021, I-PERCEPTION, V12, DOI DOI 10.1177/20416695211023956
NR 31
TC 4
Z9 4
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 7
PY 2021
VL 2
AR 728667
DI 10.3389/frvir.2021.728667
PG 6
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WS4
UT WOS:001019191900001
OA gold
DA 2024-07-18
ER

PT J
AU Rawlins, CR
   Veigulis, Z
   Hebert, C
   Curtin, C
   Osborne, TF
AF Rawlins, Caitlin R.
   Veigulis, Zachary
   Hebert, Catherine
   Curtin, Catherine
   Osborne, Thomas F.
TI Effect of Immersive Virtual Reality on Pain and Anxiety at a Veterans
   Affairs Health Care Facility
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; pain; anxiety; veteran; distraction; acute pain;
   chronic pain; immersive
ID ADULTS; TECHNOLOGY; MUSIC; DISTRACTION; PERCEPTIONS; MANAGEMENT;
   REDUCTION; AGITATION; LEVEL
AB Objectives: The primary objective of this evaluation is to determine the impact of virtual reality (VR) distraction on acute and chronic pain in Veterans within the Veterans Affairs Health Care System (VA). A secondary objective is to determine the impact of VR on the experience of stress and anxiety in Veterans utilizing VR for the indication of pain. A third objective is to develop an understanding of the Veteran experience of using VR in a healthcare setting.Methods: This prospective, pretest-posttest mixed methods assessment was performed at a VA medical center from August 30, 2019 to November 23, 2020. VR experiences lasted between 10 and 30 min utilizing an immersive head-mounted display with multiple, autonomously chosen virtual environments. Qualitative data was collected concurrently to provide context to quantitative measures which included pain scores and stress/anxiety levels. Data from 79 participants was included in this analysis. Data included pre- and post-VR session Defense and Veterans Pain Rating Scale and stress/anxiety levels.Results: Results for the cohort demonstrated a statistically significant decrease in pain intensity (p <0 .001) with an average 12% decrease in pain levels and an 92% reduction in anxiety for those in concurrent pain.Conclusion: VR as a non-pharmacological adjunct or alternative modality, appears to be a viable option for improving pain management and reducing anxiety in Veteran populations across various age ranges, and levels of acuity and chronicity. VR was found to be an effective distraction from pain, a pleasurable experience for the majority, and opened the door to other non-pharmacological modalities in a Veteran population.
C1 [Rawlins, Caitlin R.; Hebert, Catherine] US Dept Vet Affairs, Western North Carolina Hlth Care Syst, Asheville, NC 11706 USA.
   [Veigulis, Zachary; Curtin, Catherine; Osborne, Thomas F.] US Dept Vet Affairs, Palo Alto Healthcare Syst, Palo Alto, CA USA.
   [Curtin, Catherine] Stanford Univ, Dept Surg, Sch Med, Stanford, CA USA.
   [Osborne, Thomas F.] Stanford Univ, Dept Radiol, Sch Med, Stanford, CA USA.
C3 US Department of Veterans Affairs; US Department of Veterans Affairs;
   Veterans Health Administration (VHA); VA Palo Alto Health Care System;
   Stanford University; Stanford University
RP Rawlins, CR (corresponding author), US Dept Vet Affairs, Western North Carolina Hlth Care Syst, Asheville, NC 11706 USA.
EM Caitlin.Rawlins@va.gov
OI Osborne, Thomas/0000-0002-8896-2487
FU Nursing Services of the WNC VA HCS; 2019 American Nurses Credentialing
   Center Pathway Award (R) by Cerner (R)
FX This project was funded in part by the Nursing Services of the WNC VA
   HCS. External funding included monies awarded for the 2019 American
   Nurses Credentialing Center Pathway Award (R) sponsored by Cerner (R)
   and financial support received as an investee of the VHA Innovators
   Network for Fiscal Year 2020.
CR ACKERMAN MD, 1989, J CLIN PSYCHOL, V45, P223, DOI 10.1002/1097-4679(198903)45:2<223::AID-JCLP2270450208>3.0.CO;2-Y
   Ahern MM, 2020, PAIN PRACT, V20, P656, DOI 10.1111/papr.12885
   Ahmad M, 2020, PAIN MANAG NURS, V21, P601, DOI 10.1016/j.pmn.2020.04.002
   Al-Ghamdi NA, 2020, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00467
   [Anonymous], 1998, Cyberpsychol Behav Soc Netw, DOI [10.1089/cpb.1998.1.195, DOI 10.1089/CPB.1998.1.195]
   Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Bakerjian D, 2020, J AM MED DIR ASSOC, V21, P1045, DOI 10.1016/j.jamda.2020.01.103
   BASIL MD, 1994, COMMUN RES, V21, P177, DOI 10.1177/009365094021002003
   Becker WC, 2017, BMC FAM PRACT, V18, DOI 10.1186/s12875-017-0608-2
   Bellini M, 2013, ANAESTH INTENSIVE TH, V45, P93, DOI 10.5603/AIT.2013.0021
   Benham S, 2019, OTJR-OCCUP PART HEAL, V39, P90, DOI 10.1177/1539449218817291
   Benyamin R, 2008, PAIN PHYSICIAN, V11, pS105
   Brown JA, 2019, GERONTOL GERIATR MED, V5, DOI 10.1177/2333721419885287
   Chan E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200987
   Chuan A, 2021, ANAESTHESIA, V76, P695, DOI 10.1111/anae.15202
   Clancy C., 2015, DEP VETERANS AFFAIRS
   Dascal Julieta, 2017, Innov Clin Neurosci, V14, P14
   Eccleston C, 1999, PSYCHOL BULL, V125, P356, DOI 10.1037/0033-2909.125.3.356
   Eccleston C, 2001, BRIT J ANAESTH, V87, P144, DOI 10.1093/bja/87.1.144
   Firoozabadi R, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.553492
   Fowler Christopher A, 2019, JMIR Form Res, V3, pe11266, DOI 10.2196/11266
   Gerdner LA, 2000, INT PSYCHOGERIATR, V12, P49, DOI 10.1017/S1041610200006190
   Goldberg DS, 2011, BMC PUBLIC HEALTH, V11, DOI 10.1186/1471-2458-11-770
   GUREJE OYE., Survey of Anesthesiology, DOI DOI 10.1097/00132586-199906000-00054
   Hawley-Hague H, 2014, INT J MED INFORM, V83, P416, DOI 10.1016/j.ijmedinf.2014.03.002
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Hoffman HG, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89526-4
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Hoffman HG, 2011, ANN BEHAV MED, V41, P183, DOI 10.1007/s12160-010-9248-7
   Honzel E, 2019, PAIN, V160, P1909, DOI 10.1097/j.pain.0000000000001539
   Huber A, 2021, ACT ADAPT AGING, V45, P70, DOI 10.1080/01924788.2020.1722348
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Indovina P, 2018, CLIN J PAIN, V34, P858, DOI 10.1097/AJP.0000000000000599
   Jones T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167523
   Jung JH., 2014, CURR PHYS MED REHAB, V2, P55
   Kahneman D., 1973, Attention and effort
   Keefe FJ, 2012, PAIN, V153, P2163, DOI 10.1016/j.pain.2012.05.030
   Kramer TL, 2013, CYBERPSYCH BEH SOC N, V16, P293, DOI 10.1089/cyber.2013.1504
   Lee M, 2016, J REHABIL RES DEV, V53, P239, DOI 10.1682/JRRD.2014.07.0164
   Li L, 2017, AM J TRANSL RES, V9, P3867
   Liberman JS, 2019, J AM HEART ASSOC, V8, DOI 10.1161/JAHA.118.010664
   Maani CV, 2011, J TRAUMA, V71, pS125, DOI 10.1097/TA.0b013e31822192e2
   Mallari B, 2019, J PAIN RES, V12, P2053, DOI 10.2147/JPR.S200498
   Maseda A, 2018, J ALZHEIMERS DIS, V63, P1415, DOI 10.3233/JAD-180109
   Miles M. B., 1984, Qualitative data analysis: An expanded sourcebook
   Nahin RL, 2015, J PAIN, V16, P769, DOI 10.1016/j.jpain.2015.05.002
   National Center for Complementary and Integrative Health, 2016, PAIN US MIL VET
   Norr AM, 2018, DEPRESS ANXIETY, V35, P523, DOI 10.1002/da.22751
   Ong Triton L, 2020, Crit Care Explor, V2, pe0122, DOI 10.1097/CCE.0000000000000122
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Piskorz J, 2018, J SPEC PEDIATR NURS, V23, DOI 10.1111/jspn.12201
   Polomano RC, 2016, PAIN MED, V17, P1505, DOI 10.1093/pm/pnw105
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Ridder HMO, 2013, AGING MENT HEALTH, V17, P667, DOI 10.1080/13607863.2013.790926
   Roberts AR, 2019, CLIN GERONTOLOGIST, V42, P27, DOI 10.1080/07317115.2018.1442380
   Shahrbanian S, 2009, STUD HEALTH TECHNOL, V144, P40, DOI 10.3233/978-1-60750-017-9-40
   Sheehan RC, 2021, MIL MED, V186, pE721, DOI 10.1093/milmed/usaa483
   Smith V, 2020, J MED INTERNET RES, V22, DOI 10.2196/17980
   Spiegel B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219115
   Sündermann O, 2018, SCAND J PAIN, V18, P379, DOI 10.1515/sjpain-2017-0163
   Sweta V R, 2019, Ann Maxillofac Surg, V9, P110, DOI 10.4103/ams.ams_263_18
   Syed-Abdul S, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1218-8
   Tack C, 2021, DISABIL REHABIL-ASSI, V16, P637, DOI 10.1080/17483107.2019.1688399
   Teater D., 2014, PSYCH PHYS SID EFF P
   Theunissen M, 2012, CLIN J PAIN, V28, P819, DOI 10.1097/AJP.0b013e31824549d6
   Trost Z, 2021, PAIN, V162, P325, DOI 10.1097/j.pain.0000000000002060
   U.S. Department of Veterans Affairs, 2018, VET POP
   U.S. Department of Veterans Affairs, 2017, PROF VET 2017 HIGHL
   U.S. Department of Veterans Affairs, 2020, VA RES PAIN MAN
   Walker MR, 2014, MIL MED, V179, P891, DOI 10.7205/MILMED-D-13-00343
   Webster LR, 2017, ANESTH ANALG, V125, P1741, DOI 10.1213/ANE.0000000000002496
   Williamson A, 2005, J CLIN NURS, V14, P798, DOI 10.1111/j.1365-2702.2005.01121.x
   Won AS, 2017, CHILDREN-BASEL, V4, DOI 10.3390/children4070052
NR 76
TC 4
Z9 5
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 5
PY 2021
VL 2
AR 719681
DI 10.3389/frvir.2021.719681
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L3JX6
UT WOS:001022267100001
OA gold
DA 2024-07-18
ER

PT J
AU Wang, YH
   Kopper, R
AF Wang, Yunhan
   Kopper, Regis
TI Efficient and Accurate Object 3D Selection With Eye Tracking-Based
   Progressive Refinement
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE selection; progressive refinement; eye tracking; 3D user interfaces;
   interaction
AB Selection by progressive refinement allows the accurate acquisition of targets with small visual sizes while keeping the required precision of the task low. Using the eyes as a means to perform 3D selections is naturally hindered by the low accuracy of eye movements. To account for this low accuracy, we propose to use the concept of progressive refinement to allow accurate 3D selection. We designed a novel eye tracking selection technique with progressive refinement-Eye-controlled Sphere-casting refined by QUAD-menu (EyeSQUAD). We propose an approximation method to stabilize the calculated point-of-regard and a space partitioning method to improve computation. We evaluated the performance of EyeSQUAD in comparison to two previous selection techniques-ray-casting and SQUAD-under different target size and distractor density conditions. Results show that EyeSQUAD outperforms previous eye tracking-based selection techniques, is more accurate and can achieve similar selection speed as ray-casting, and is less accurate and slower than SQUAD. We discuss implications of designing eye tracking-based progressive refinement interaction techniques and provide a potential solution for multimodal user interfaces with eye tracking.
C1 [Wang, Yunhan] Duke Univ, Dept Mech Engn & Mat Sci, Durham, NC USA.
   [Kopper, Regis] Univ N Carolina, Dept Comp Sci, Greensboro, NC 27412 USA.
C3 Duke University; University of North Carolina; University of North
   Carolina Greensboro
RP Kopper, R (corresponding author), Univ N Carolina, Dept Comp Sci, Greensboro, NC 27412 USA.
EM kopper@uncg.edu
CR [Anonymous], 2021, HTC VIVE PRO EYE
   Ashmore Michael., 2005, P GRAPHICS INTERFACE, P203, DOI DOI 10.1145/1089508.1089542
   Bacim F, 2013, INT J HUM-COMPUT ST, V71, P785, DOI 10.1016/j.ijhcs.2013.03.003
   Birch J, 1997, OPHTHAL PHYSL OPT, V17, P403, DOI 10.1111/j.1475-1313.1997.tb00072.x
   Cournia Nathan., 2003, CHI'03 extended abstracts on Human factors in computing systems, P772, DOI DOI 10.1145/765891.765982
   Creed C, 2016, P 30 INT BCS HUMAN C, P38
   Dalmaijer ES, 2014, BEHAV RES METHODS, V46, P913, DOI 10.3758/s13428-013-0422-2
   De Haan G., 2005, IPT EGVE, P201
   Deubel H, 1996, VISION RES, V36, P1827, DOI 10.1016/0042-6989(95)00294-4
   Dishart D., 1998, EYE GUIDANCE READING, P419
   Duchowski A. T., 2017, EYE TRACKING METHODO, DOI [10.1007/978-3-319-57883-5, DOI 10.1007/978-3-319-57883-5]
   Field A., 2013, DISCOVERING STAT USI
   FINDLAY JM, 1982, VISION RES, V22, P1033, DOI 10.1016/0042-6989(82)90040-2
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   FOVE Inc, 2018, EYE TRACK VIRT REAL
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Fuhl W, 2016, MACH VISION APPL, V27, P1275, DOI 10.1007/s00138-016-0776-4
   Goldberg JH, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P493, DOI 10.1016/B978-044451020-4/50027-X
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   IACONO WG, 1982, J ABNORM PSYCHOL, V91, P35, DOI 10.1037/0021-843X.91.1.35
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jeevithashree DV, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P319, DOI 10.1145/3197391.3205395
   Khamis M, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206522
   Khushaba RN, 2013, EXPERT SYST APPL, V40, P3803, DOI 10.1016/j.eswa.2012.12.095
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Kumar M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P421
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Majaranta P, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P357
   Mardanbegi D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P474, DOI [10.1109/vr.2019.8797988, 10.1109/VR.2019.8797988]
   Meagher D, 1980, OCTREE ENCODING NEW
   Meena YK, 2016, IEEE SYS MAN CYBERN, P3688, DOI 10.1109/SMC.2016.7844807
   Meena YK, 2017, IEEE ENG MED BIO, P905, DOI 10.1109/EMBC.2017.8036971
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Miniotas D., 2004, AALBORG DENMARK INF, V30
   Miniotas Darius., 2004, CHIOF EXTENDED ABSTR, P1255
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Pfeiffer T., 2008, VIRT ERW REAL FUNFT
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Pfeuffer Ken, 2020, 26 ACM S VIRT REAL S, DOI [10.1145/3385956.3418962, DOI 10.1145/3385956.3418962]
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Poole A., 2006, ENCY HUMAN COMPUTER, P211, DOI [DOI 10.4018/978-1-59140-562-7.CH034, 10.4018/978-1-59140-562-7]
   PORAC C, 1976, PSYCHOL BULL, V83, P880, DOI 10.1037/0033-2909.83.5.880
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Rivu R., 2020, ACM S EYE TRACKING R, P1, DOI DOI 10.1145/3379157
   ROBINSON DA, 1964, J PHYSIOL-LONDON, V174, P245, DOI 10.1113/jphysiol.1964.sp007485
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Smith J.D., 2006, P 2006 ACM SIGCHI IN, P20, DOI [10.1145/1178823.1178847, DOI 10.1145/1178823.1178847]
   Stellmach S., 2012, Proc. CHI, P2981, DOI DOI 10.1145/2207676.2208709
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   Tobacco, 2021, ABOUT US
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Wedel M., 2008, Review of Marketing Research, V4, P123, DOI 10.4324/9781351550932-5
   Zhai Shumin., 1999, Proceedings of CHI, P246, DOI [10.1145/302979.303053 10.1145/302979.303053, DOI 10.1145/302979.3030532, DOI 10.1145/302979.303053]
NR 56
TC 2
Z9 2
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 17
PY 2021
VL 2
AR 607165
DI 10.3389/frvir.2021.607165
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9BC5
UT WOS:001019307400001
OA gold
DA 2024-07-18
ER

PT J
AU Golding, JF
   Rafiq, A
   Keshavarz, B
AF Golding, John F.
   Rafiq, Aisha
   Keshavarz, Behrang
TI Predicting Individual Susceptibility to Visually Induced Motion Sickness
   by Questionnaire
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE motion sickness (simulator sickness); migraines; optokinetic; vection;
   personality; anxiety; syncope; sleep
ID VERTICAL AXIS ROTATION; SIMULATOR SICKNESS; DIZZINESS; MIGRAINE
AB Background: The introduction of new visual technologies increases the risk of visually induced motion sickness (VIMS). The aim was to evaluate the 6-item Visually Induced Motion Sickness Susceptibility Questionnaire (VIMSSQ; also known as the VIMSSQ-short) and other predictors for individual susceptibility to VIMS.
   Methods: Healthy participants (10M + 20F), mean age 22.9 (SD 5.0) years, viewed a 360 degrees panoramic city scene projected in the visual equivalent to the situation of rotating about an axis tilted from the vertical. The scene rotated at 0.2 Hz (72 degrees s(-1)), with a 'wobble' produced by superimposed 18 degrees tilt on the rotational axis, with a field of view of 83.5 degrees. Exposure was 10 min or until moderate nausea was reported. Simulator Sickness Questionnaire (SSQ) was the index of VIMS. Predictors/correlates were VIMSSQ, Motion Sickness Susceptibility Questionnaire (MSSQ), migraine (scale), syncope, Social & Work Impact of Dizziness (SWID), sleep quality/disturbance, personality ("Big Five" TIPI), a prior multisensory Stepping-Vection test, and vection during exposure.
   Results: The VIMSSQ had good scale reliability (Cronbach's alpha = 0.84) and correlated significantly with the SSQ (r = 0.58). Higher MSSQ, migraine, syncope, and SWID also correlated significantly with SSQ. Other variables had no significant relationships with SSQ. Regression models showed that the VIMSSQ predicted 34% of the individual variation of VIMS, increasing to 56% as MSSQ, migraine, syncope, and SWID were incorporated as additional predictors.
   Conclusion: The VIMSSQ is a useful adjunct to the MSSQ in predicting VIMS. Other predictors included migraine, syncope, and SWID. No significant relationship was observed between vection and VIMS.
C1 [Golding, John F.; Rafiq, Aisha] Univ Westminster, Sch Social Sci, Psychol, London, England.
   [Keshavarz, Behrang] Univ Hlth Network, KITE Toronto Rehabil Inst, Toronto, ON, Canada.
   [Keshavarz, Behrang] Ryerson Univ, Dept Psychol, Toronto, ON, Canada.
C3 University of Westminster; University of Greenwich; University of
   Toronto; University Health Network Toronto; Toronto Rehabilitation
   Institute; Toronto Metropolitan University
RP Golding, JF (corresponding author), Univ Westminster, Sch Social Sci, Psychol, London, England.
EM goldinj@westminster.ac.uk
RI Keshavarz, Behrang/AFQ-0294-2022
OI Keshavarz, Behrang/0000-0002-7763-5325; Golding,
   John/0000-0003-0971-9508
CR Besnard S., 2019, C MOT SICKN JUL 7 10
   Bijveld MMC, 2008, AVIAT SPACE ENVIR MD, V79, P661, DOI 10.3357/ASEM.2241.2008
   Bosser G, 2006, BRAIN RES BULL, V68, P217, DOI 10.1016/j.brainresbull.2005.05.031
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Bronstein A., 2013, OXFORD TXB VERTIGO I
   Bronstein AM, 2020, SEMIN NEUROL, V40, P116, DOI 10.1055/s-0040-1701653
   Bronstein AM, 2010, J NEUROL, V257, P183, DOI 10.1007/s00415-009-5287-z
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   CHEUNG BSK, 1991, AVIAT SPACE ENVIR MD, V62, P527
   Cohn JV, 2000, J NEUROPHYSIOL, V83, P3230, DOI 10.1152/jn.2000.83.6.3230
   Diels C, 2013, HUM FACTORS, V55, P595, DOI 10.1177/0018720812469046
   Drummond PD, 2005, HEADACHE, V45, P653, DOI 10.1111/j.1526-4610.2005.05132.x
   Flanagan MB, 2005, AVIAT SPACE ENVIR MD, V76, P642
   Golding J. F., 2017, 6 INT VIMS C TOR CAN
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Golding JF, 2017, ACTA OTO-LARYNGOL, V137, P495, DOI 10.1080/00016489.2016.1255775
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Golding JF, 2009, AVIAT SPACE ENVIR MD, V80, P516, DOI 10.3357/ASEM.2433.2009
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Hromatka BS, 2015, HUM MOL GENET, V24, P2700, DOI 10.1093/hmg/ddv028
   Johnson WH, 1999, J VESTIBUL RES-EQUIL, V9, P83
   Kaplan J, 2017, AUTON NEUROSCI-BASIC, V202, P86, DOI 10.1016/j.autneu.2016.08.019
   Kennedy R S, 1968, Acta Otolaryngol, V66, P533, DOI 10.3109/00016486809126317
   Kennedy R S., 1995, Safe Journal, V25, P69
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz Behrang, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P2267, DOI 10.1177/1071181319631216
   Keshavarz B, 2018, TRANSPORT RES F-TRAF, V54, P47, DOI 10.1016/j.trf.2018.01.007
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Klosterhalfen Sibylle, 2006, Gend Med, V3, P236, DOI 10.1016/S1550-8579(06)80211-1
   Kuiper OX, 2019, DISPLAYS, V58, P82, DOI 10.1016/j.displa.2018.10.001
   Láinez MJ, 2010, BMC NEUROL, V10, DOI 10.1186/1471-2377-10-39
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   LAWTHER A, 1988, AVIAT SPACE ENVIR MD, V59, P399
   Moss J. D., 2015, 86 ANN M AER MED ASS
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Oman CM, 2014, EXP BRAIN RES, V232, P2483, DOI 10.1007/s00221-014-3973-2
   Paillard AC, 2013, J VESTIBUL RES-EQUIL, V23, P203, DOI 10.3233/VES-130501
   Peverall L., 2017, 11 M BRIT SOC NEUR S
   Powell G, 2020, NEUROLOGY, V94, pE1929, DOI 10.1212/WNL.0000000000009373
   Reason J. T., MOTION SICKNESS
   Reavley CM, 2006, AVIAT SPACE ENVIR MD, V77, P1148
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Turner M, 1999, ERGONOMICS, V42, P444, DOI 10.1080/001401399185586
   Yu L, 2012, BEHAV SLEEP MED, V10, P6, DOI 10.1080/15402002.2012.636266
NR 45
TC 22
Z9 23
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 26
PY 2021
VL 2
AR 576871
DI 10.3389/frvir.2021.576871
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OW6
UT WOS:001021714100001
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Mouatt, B
   Smith, AE
   Mellow, ML
   Parfitt, G
   Smith, RT
   Stanton, TR
AF Mouatt, Brendan
   Smith, Ashleigh E.
   Mellow, Maddison L.
   Parfitt, Gaynor
   Smith, Ross T.
   Stanton, Tasha R.
TI The Use of Virtual Reality to Influence Motivation, Affect, Enjoyment,
   and Engagement During Exercise: A Scoping Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; immersion; avatar; engagement; enjoyment; motivation;
   affect; exercise
ID SELF-DETERMINATION THEORY; PHYSICAL-ACTIVITY; INTRINSIC MOTIVATION;
   PERFORMANCE; BENEFITS; FACILITATION; DISPLEASURE; COMPETITION;
   EXPERIENCE; ADHERENCE
AB Many adults are physically inactive. While the reasons are complex, inactivity is, in part, influenced by the presence of negative feelings and low enjoyment during exercise. While virtual reality (VR) has been proposed as a way to improve engagement with exercise (e.g., choosing to undertake exercise), how VR is currently used to influence experiences during exercise is largely unknown. Here we aimed to summarize the existing literature evaluating the use of VR to influence motivation, affect, enjoyment, and engagement during exercise. A Population (clinical, and healthy), Concept (the extent and nature of research about VR in exercise, including underpinning theories), and Context (any setting, demographic, social context) framework was used. A systematic search of Medline, Scopus, Embase, PsycINFO, and Google Scholar was completed by two independent reviewers. Of 970 studies identified, 25 unique studies were included (n = 994 participants), with most (68%) evaluating VR influences on motivation, affect, enjoyment, and engagement during exercise in healthy populations (n = 8 studies evaluating clinical populations). Two VR strategies were prominent - the use of immersion and the use of virtual avatars and agents/trainers. All studies but one used virtual agents/trainers, suggesting that we know little about the influence of virtual avatars on experiences during exercise. Generally, highly immersive VR had more beneficial effects than low immersive VR or exercise without VR. The interaction between VR strategy and the specific exercise outcome appeared important (e.g., virtual avatars/agents were more influential in positively changing motivation and engagement during exercise, whereas immersion more positively influenced enjoyment during exercise). Presently, the knowledge base is insufficient to provide definitive recommendations for use of specific VR strategies to target specific exercise outcomes, particularly given the numerous null findings. Regardless, these preliminary findings support the idea that VR may influence experiences during exercise via multiple mechanistic pathways. Understanding these underlying mechanisms may be important to heighten effects targeted to specific exercise outcomes during exercise. Future research requires purposeful integration of exercise-relevant theories into VR investigation, and careful consideration of VR definitions (including delineation between virtual avatars and virtual agents), software possibilities, and nuanced extension to clinical populations.
C1 [Mouatt, Brendan; Stanton, Tasha R.] Univ South Australia, IIMPACT Hlth, Allied Hlth & Human Performance, Adelaide, SA, Australia.
   [Smith, Ashleigh E.; Mellow, Maddison L.; Parfitt, Gaynor] Univ South Australia, Alliance Res Exercise Nutr & Act ARENA, Allied Hlth & Human Performance, Adelaide, SA, Australia.
   [Smith, Ross T.] Univ South Australia, Australian Ctr Interact & Virtual Environm, Wearable Comp Lab, Adelaide, SA, Australia.
   [Stanton, Tasha R.] Neurosci Res Australia, Sydney, NSW, Australia.
C3 University of South Australia; University of South Australia; University
   of South Australia; Neuroscience Research Australia
RP Stanton, TR (corresponding author), Univ South Australia, IIMPACT Hlth, Allied Hlth & Human Performance, Adelaide, SA, Australia.; Stanton, TR (corresponding author), Neurosci Res Australia, Sydney, NSW, Australia.
EM tasha.stanton@unisa.edu.au
RI Smith, Ross/L-4790-2016; Stanton, Tasha/F-4038-2013; Parfitt,
   Gaynor/G-7640-2012; Smith, Ashleigh/B-2397-2013
OI Smith, Ross/0000-0002-9044-9199; Stanton, Tasha/0000-0001-7106-4456;
   Mellow, Maddison/0000-0002-0514-8261; Parfitt,
   Gaynor/0000-0002-5547-5797; Smith, Ashleigh/0000-0001-6316-2259; Mouatt,
   Brendan/0000-0003-2422-1599
FU combined National Health & Medical Research Council of Australia;
   Australian Research Council (NHMRC-ARC) Dementia Research Development
   Fellowship [GNT1097397]; NHMRC Career Development Fellowship
   [ID1141735]; University of South Australia Research Themes Investment
   Scheme (RTIS); Dementia Australia Research Foundation PhD scholarship
FX AS was supported by a combined National Health & Medical Research
   Council of Australia and Australian Research Council (NHMRC-ARC)
   Dementia Research Development Fellowship (GNT1097397). TS was supported
   by an NHMRC Career Development Fellowship (ID1141735). This research
   project was supported by a University of South Australia Research Themes
   Investment Scheme (RTIS) grant awarded to TS, AS, GP, and RS. MM was
   supported by a Dementia Australia Research Foundation PhD scholarship.
   The funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Annesi JJ, 1997, PERCEPT MOTOR SKILL, V85, P835, DOI 10.2466/pms.1997.85.3.835
   [Anonymous], 2017, Global strategy on diet, physical activity, and health
   Aral S, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14753
   Bailenson J.N., 2004, Avatars. Encyclopedia of Human-Computer Interaction
   BANDURA A, 1989, AM PSYCHOL, V44, P1175, DOI 10.1037/0003-066X.44.9.1175
   Bandura A., 1997, SELF EFFICACY EXERCI
   Baños RM, 2016, CYBERPSYCH BEH SOC N, V19, P115, DOI 10.1089/cyber.2015.0283
   Barathi SC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173982
   Bird JM, 2019, SCAND J MED SCI SPOR, V29, P1161, DOI 10.1111/sms.13453
   Blair SN, 2009, BRIT J SPORT MED, V43, P1
   Booth ML, 2000, PREV MED, V31, P15, DOI 10.1006/pmed.2000.0661
   BROADBENT DE, 1957, PSYCHOL REV, V64, P205, DOI 10.1037/h0047313
   Bryanton C, 2006, CYBERPSYCHOL BEHAV, V9, P123, DOI 10.1089/cpb.2006.9.123
   Calogiuri G, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02321
   Casey D, 2010, DIABETIC MED, V27, P79, DOI 10.1111/j.1464-5491.2009.02873.x
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Corbett J, 2012, MED SCI SPORT EXER, V44, P509, DOI 10.1249/MSS.0b013e31823378b1
   Csikszentmihalyi M, 1992, Optimal Experience: Psychological Studies of Flow in Consciousness
   Deci E.L., 1980, ADV EXP SOC PSYCHOL, P39
   Ekkekakis P, 2005, J SPORT EXERCISE PSY, V27, P350, DOI 10.1123/jsep.27.3.350
   Ekkekakis P, 2003, COGNITION EMOTION, V17, P213, DOI 10.1080/02699930302292
   Ekkekakis P, 2011, SPORTS MED, V41, P641, DOI 10.2165/11590680-000000000-00000
   Farrow M, 2019, EUR J SPORT SCI, V19, P719, DOI 10.1080/17461391.2018.1542459
   Festinger L, 1954, HUM RELAT, V7, P117, DOI 10.1177/001872675400700202
   Finkelstein S, 2013, 2013 1ST WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P11, DOI 10.1109/VAAT.2013.6786186
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Garcia-Vergara S., 2015, INCREASING SUPER POP
   Garrett B, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/10839
   Giles-Corti B, 2002, SOC SCI MED, V54, P1793, DOI 10.1016/S0277-9536(01)00150-2
   Gillman AS, 2016, ANN BEHAV MED, V50, P157, DOI 10.1007/s12160-015-9730-3
   Glen K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186526
   Hamzeheinejad N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1421, DOI [10.1109/VR.2019.8797763, 10.1109/vr.2019.8797763]
   HARDY CJ, 1989, J SPORT EXERCISE PSY, V11, P304, DOI 10.1123/jsep.11.3.304
   Hossain MS, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON HAPTIC AUDIO-VISUAL ENVIRONMENTS AND GAMES (HAVE 2013), P7, DOI 10.1109/HAVE.2013.6679602
   Iso-Ahola SE, 2000, QUEST, V52, P131, DOI 10.1080/00336297.2000.10491706
   Jones L, 2019, J SPORT HEALTH SCI, V8, P325, DOI 10.1016/j.jshs.2019.03.003
   Joshi A., 2015, BRIT J APPL SCI TECH, V7, P396, DOI [10.9734/BJAST/2015/14975, DOI 10.9734/BJAST/2015/14975]
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Kaplan R., 1995, EXPERIENCE NATURE PS
   Kendzierski D, 1998, J SPORT EXERCISE PSY, V20, P176, DOI 10.1123/jsep.20.2.176
   Knaving K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2013, DOI 10.1145/2702123.2702542
   Lahart I, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16081352
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lewis BA, 2016, PSYCHOL HEALTH, V31, P456, DOI 10.1080/08870446.2015.1111372
   Lox C. L., 2000, Measurement in Physical Education and Exercise Science, V4, P79, DOI 10.1207/S15327841Mpee0402_4
   Marker AM, 2015, GAMES HEALTH J, V4, P25, DOI 10.1089/g4h.2014.0066
   Matthews G, 2002, EMOTION, V2, P315, DOI 10.1037//1528-3542.2.4.315
   Mestre DR, 2011, STUD HEALTH TECHNOL, V167, P122, DOI 10.3233/978-1-60750-766-6-122
   Mestre DR, 2011, PRESENCE-VIRTUAL AUG, V20, P1, DOI 10.1162/pres_a_00031
   Meyer Jochen., 2014, CHI 14 EXTENDED ABST, P95
   Meyer L. J., 2008, DISSERT ABSTRACTS IN, V69, P5008
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Monedero J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118470
   Murray EG, 2016, PSYCHOL SPORT EXERC, V22, P328, DOI 10.1016/j.psychsport.2015.09.007
   Neumann DL, 2018, SPORTS, V6, DOI 10.3390/sports6030071
   Nideffer R.M., 1976, INNER ATHLETE
   Nishigami T, 2019, MUSCULOSKEL SCI PRAC, V39, P178, DOI 10.1016/j.msksp.2018.07.002
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Parton BJ, 2019, PSYCHOL SPORT EXERC, V41, P191, DOI 10.1016/j.psychsport.2018.06.010
   Peters D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00797
   Peters MD., 2015, The Joanna Briggs Institute reviewers' manual 2015: methodology for JBI scoping reviews, DOI DOI 10.1017/CB09781107415324.004
   Plante T.G., 2006, International Journal of Stress Management, V13, P108, DOI [10.1037/1072-5245.13.1.108, DOI 10.1037/1072-5245.13.1.108]
   Plante TG, 2003, COMPUT HUM BEHAV, V19, P495, DOI 10.1016/S0747-5632(02)00074-2
   Radel R, 2018, PHYSIOL BEHAV, V195, P82, DOI 10.1016/j.physbeh.2018.07.028
   Raedeke TD, 2007, J APPL SPORT PSYCHOL, V19, P105, DOI 10.1080/10413200601113638
   Rajati F, 2014, ARYA ATHEROSCLER, V10, P319
   Rizzo AA, 2004, P ANN INT IEEE EMBS, V26, P4852
   Rizzo A, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1414560
   Rogers R, 2017, COMPUT HUM BEHAV, V73, P446, DOI 10.1016/j.chb.2017.03.048
   Russell WD, 2008, EDUC TECHNOL SOC, V11, P294
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Sarter M, 2001, BRAIN RES REV, V35, P146, DOI 10.1016/S0165-0173(01)00044-3
   Seinfeld S, 2021, HUM-COMPUT INTERACT, V36, P400, DOI 10.1080/07370024.2020.1724790
   Shaw L. A., 2017, P AUSTRALASIAN COMPU, P11, DOI [DOI 10.1145/3014812.3014823, DOI 10.1145/3014812.3014823PAGES#28, 10.1145/3014812.3014823pages#28]
   Shaw LA, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.92
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stroebe W., 1996, UNDERSTANDING GROUP, V2, P37
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   SVEBAK S, 1985, J PERS SOC PSYCHOL, V48, P107, DOI 10.1037/0022-3514.48.1.107
   Törnbom K, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209214
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Tsigilis N, 2003, PERCEPT MOTOR SKILL, V97, P271, DOI 10.2466/PMS.97.4.271-280
   van Berkel N., 2015, P 2015 ACM INT JOINT, P973
   Veritas Health Innovation, 2017, COV SYST REV SOFTW
   WANKEL LM, 1993, INT J SPORT PSYCHOL, V24, P151
   Warburton DER, 2006, CAN MED ASSOC J, V174, P801, DOI 10.1503/cmaj.051351
   Williams DM, 2008, PSYCHOL SPORT EXERC, V9, P231, DOI 10.1016/j.psychsport.2007.04.002
   Wininger S. R., 2010, Athletic Insight: The Online Journal of Sport Psychology, V12, punpaginated
   Yim Jeffrey., 2007, Proceedings of the 2007 conference on Future Play - Future Play '07, ACM Press, P166, DOI https://doi.org/10.1145/1328202.1328232
   ZAJONC RB, 1966, J EXP SOC PSYCHOL, V2, P160, DOI 10.1016/0022-1031(66)90077-1
   Zeng N, 2017, CYBERPSYCH BEH SOC N, V20, P453, DOI 10.1089/cyber.2017.0042
   Zimmerli L, 2013, ARCH PHYS MED REHAB, V94, P1737, DOI 10.1016/j.apmr.2013.01.029
NR 93
TC 45
Z9 50
U1 12
U2 25
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 23
PY 2020
VL 1
AR 564664
DI 10.3389/frvir.2020.564664
PG 23
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4VQ3
UT WOS:001023262600001
OA gold
DA 2024-07-18
ER

PT J
AU Stauffert, JP
   Niebling, F
   Latoschik, ME
AF Stauffert, Jan-Philipp
   Niebling, Florian
   Latoschik, Marc Erich
TI Latency and Cybersickness: Impact, Causes, and Measures. A Review
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE virtual reality; latency; cybersickness; jitter; simulator sickness
ID TO-END LATENCY; MOTION SICKNESS; VIRTUAL-REALITY; QUESTIONNAIRE;
   AMPLITUDE
AB Latency is a key characteristic inherent to any computer system. Motion-to-Photon (MTP) latency describes the time between the movement of a tracked object and its corresponding movement rendered and depicted by computer-generated images on a graphical output screen. High MTP latency can cause a loss of performance in interactive graphics applications and, even worse, can provoke cybersickness in Virtual Reality (VR) applications. Here, cybersickness can degrade VR experiences or may render the experiences completely unusable. It can confound research findings of an otherwise sound experiment. Latency as a contributing factor to cybersickness needs to be properly understood. Its effects need to be analyzed, its sources need to be identified, good measurement methods need to be developed, and proper counter measures need to be developed in order to reduce potentially harmful impacts of latency on the usability and safety of VR systems. Research shows that latency can exhibit intricate timing patterns with various spiking and periodic behavior. These timing behaviors may vary, yet most are found to provoke cybersickness. Overall, latency can differ drastically between different systems interfering with generalization of measurement results. This review article describes the causes and effects of latency with regard to cybersickness. We report on different existing approaches to measure and report latency. Hence, the article provides readers with the knowledge to understand and report latency for their own applications, evaluations, and experiments. It should also help to measure, identify, and finally control and counteract latency and hence gain confidence into the soundness of empirical data collected by VR exposures. Low latency increases the usability and safety of VR systems.
C1 [Stauffert, Jan-Philipp; Niebling, Florian; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
C3 University of Wurzburg
RP Stauffert, JP (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
EM jan-philipp.stauffert@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600
CR Adelstein B. D., 2003, P HUMAN FACTORS ERGO, V47, P2083, DOI [DOI 10.1177/1541931203047020, DOI 10.1177/154193120304702001]
   Ames SL, 2005, OPTOMETRY VISION SCI, V82, P168, DOI 10.1097/01.OPX.0000156307.95086.6
   [Anonymous], 1975, Motion sickness
   Antoine Axel, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P869, DOI 10.1145/3379337.3415833
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Attig C, 2017, LECT NOTES ARTIF INT, V10276, P3, DOI 10.1007/978-3-319-58475-1_1
   Becher A, 2018, Arxiv, DOI arXiv:1809.06320
   Billeter M, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P184, DOI [10.1109/ISMAR-Adjunct.2016.0072, 10.1109/ISMAR-Adjunct.2016.63]
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Carmack John, 2013, Latency mitigation strategies
   Caserman P, 2019, LECT NOTES COMPUT SC, V11863, P57, DOI 10.1007/978-3-030-34644-7_5
   Chang C.-M., 2016, PERFORMANCE MEASUREM, DOI [10.1145/2964284.2967303, DOI 10.1145/2964284.2967303]
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen Y.C., 2011, BIO Web of Conferences, V1, P00016, DOI DOI 10.1051/BIOCONF/20110100016
   Davis J, 2015, SCI REP-UK, V5, DOI 10.1038/srep07861
   Davis S., 2014, SYSTEMATIC REV CYBER, DOI [10.1145/2677758.2677780, DOI 10.1145/2677758.2677780]
   Di Luca M, 2010, PRESENCE-TELEOP VIRT, V19, P569, DOI 10.1162/pres_a_00023
   DiZio P., 2000, Motion Sickness Side Effects and Aftereffects of Immersive Virtual Environments Created with Helmet-Mounted Visual Displays
   Ellis S.R., 2004, Proceedings of the Human Factors and Ergonomics Society 48th annual meeting, P2632, DOI DOI 10.1177/154193120404802306
   Ellis SR, 1999, HUM FAC ERG SOC P, P1182
   Feldstein IT, 2021, IEEE T VIS COMPUT GR, V27, P3611, DOI 10.1109/TVCG.2020.2980527
   FRANK LH, 1988, HUM FACTORS, V30, P201, DOI 10.1177/001872088803000207
   Friston S, 2014, IEEE T VIS COMPUT GR, V20, P616, DOI 10.1109/TVCG.2014.30
   Gach E, 2019, VALVE UPDATES STEAM
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Gianaros PJ, 2001, AVIAT SPACE ENVIR MD, V72, P115
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   GRAYBIEL A, 1968, AEROSPACE MED, V39, P453
   Gruen R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P791, DOI [10.1109/VR46266.2020.000-1, 10.1109/VR46266.2020.1580498468656]
   He D., 2000, INT IMMERSIVE PROJEC
   Hsu R., 2015, WHO MOVED MY 99 PERC
   Jerald J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P211, DOI 10.1109/VR.2009.4811025
   Jung J.Y., 2000, Proc. Hum. Factors Ergon. Soc. Annu. Meet., V44, P499, DOI [10.1177/154193120004400504, DOI 10.1177/154193120004400504]
   Kamarainen T., 2017, Proceedings of the 18th International Workshop on Mobile Computing Systems and Applications, P61, DOI DOI 10.1145/3032970.3032985
   Kawamura S, 2016, P IEEE VIRT REAL ANN, P199, DOI 10.1109/VR.2016.7504722
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kijima R, 2016, P IEEE VIRT REAL ANN, P203, DOI 10.1109/VR.2016.7504724
   Kijima R, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P249, DOI 10.1109/3DUI.2016.7460064
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kinsella A, 2016, AEROSP MED HUM PERF, V87, P604, DOI 10.3357/AMHP.4351.2016
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lampton DR., 1994, Presence: Teleoperators and Virtual Environments, V3, P145
   Liang J., 1991, UIST Fourth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P19, DOI 10.1145/120782.120784
   Luu W., 2019, P SIGGRAPH AS SIGGRA, DOI [10.1145/3355056.3364590, DOI 10.1145/3355056.3364590]
   Mayer B., 2020, SPACEX LINUX RECHNER
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   McHugh N., 2019, Master's Thesis, DOI [10.26021/1316, DOI 10.26021/1316]
   McKenney P. E, 2008, OTTAWA LINUX S, P57
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Miller D, 2002, P SOC PHOTO-OPT INS, V4660, P458, DOI 10.1117/12.468062
   Mine MarkR., 1993, Characterization of end-to-end delays in head-mounted display systems
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Muth ER, 1996, J PSYCHOSOM RES, V40, P511, DOI 10.1016/0022-3999(95)00638-9
   Nancel M, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P271, DOI 10.1145/2984511.2984590
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Papadakis G, 2011, P 10 INT C VIRT REAL, P581, DOI [DOI 10.1145/2087756.2087869, 10.1145/2087756.2087869]
   Pape S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P234, DOI [10.1109/VRW50115.2020.0-226, 10.1109/VRW50115.2020.00050]
   Pierre MES, 2015, DISPLAYS, V36, P1, DOI 10.1016/j.displa.2014.10.005
   Raaen K, 2015, LECT NOTES COMPUT SC, V9353, P457, DOI 10.1007/978-3-319-24589-8_40
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Roberts D, 2009, IEEE ACM DIS SIM, P89, DOI 10.1109/DS-RT.2009.43
   Seo MW, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051112
   Sielhorst Tobias., 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR), P215, DOI [10.1109/ISMAR.2007.4538850, DOI 10.1109/ISMAR.2007.4538850]
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stauffert JP, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P636, DOI [10.1109/VR46266.2020.1581339481249, 10.1109/VR46266.2020.00086]
   Stauffert JP, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P707, DOI [10.1109/VRW50115.2020.00-71, 10.1109/VRW50115.2020.00204]
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Stauffert JP, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P47, DOI 10.1145/2993369.2993402
   Steed A., 2008, P 2008 ACM S VIRT RE, P123, DOI [10.1145/1450579.1450606, DOI 10.1145/1450579.1450606]
   Stone Ill W. B., 2017, PSYCHOMETRIC EVALUAT
   Swindells C., 2000, UIST. Proceedings of the 13th Annual ACM Symposium on User Interface Software and Technology, P161, DOI 10.1145/354401.354444
   Teather RJ, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P43, DOI 10.1109/3DUI.2009.4811204
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Tumanov A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P123
   van Waveren JMP, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P37, DOI 10.1145/2993369.2993375
   Viirre E, 1996, IEEE ENG MED BIOL, V15, P41, DOI 10.1109/51.486717
   Vulimiri A, 2013, Arxiv, DOI [arXiv:1306.3707, 10.1145/2535372.2535392, DOI 10.1145/2535372.2535392]
   Wu WX, 2013, PRESENCE-TELEOP VIRT, V22, P20, DOI 10.1162/PRES_a_00131
   Zhao JB, 2017, P IEEE VIRT REAL ANN, P313, DOI 10.1109/VR.2017.7892302
NR 85
TC 60
Z9 61
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 26
PY 2020
VL 1
AR 582204
DI 10.3389/frvir.2020.582204
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WD7
UT WOS:001023276200001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Maneuvrier, A
   Decker, LM
   Ceyte, H
   Fleury, P
   Renaud, P
AF Maneuvrier, Arthur
   Decker, Leslie Marion
   Ceyte, Hadrien
   Fleury, Philippe
   Renaud, Patrice
TI Presence Promotes Performance on a Virtual Spatial Cognition Task:
   Impact of Human Factors on Virtual Reality Assessment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE immersion; sense of presence; cybersickness; virtual environment (VE);
   human-computer interaction (HCI); head-mounted display (HMD); field
   dependence; spatial orientation and navigation
ID VIDEO GAME USE; SEX-DIFFERENCES; MOTION SICKNESS; GENDER-DIFFERENCES;
   NAVIGATION; EXPERIENCE; SENSE; ENVIRONMENTS; MEMORY; IMPAIRMENT
AB The use of virtual reality in spatial cognition evaluation has been growing rapidly, mainly because of its potential applications in the training and diagnosis of cognitive impairment and its ability to blend experimental control and ecological validity. However, there are still many gray areas on virtual reality, notably on the sense of presence and its complex relationship to task performance. Performance in VR is often suggested to be influenced by other human factors including, amongst others, cybersickness, gender, video game experience, and field dependence. Would an individual experiencing more presence systematically show better performance? This study aimed to be part of a framework of virtual reality as this question is fundamental for rigorous assessment and diagnostics, and particularly in the spatial cognition field. Forty-eight healthy young subjects were recruited to take part in a virtual spatial cognition evaluation. Spatial cognition performance, along with their level of presence, cybersickness, video game experience, gender and field dependence, were measured. Matrix correlations were used, along with linear regressions and mediation analysis. Results show that presence promoted performance on the spatial cognition evaluation, while cybersickness symptoms hindered it, notably among women. The presence-performance relationship was not mediated by other human factors. Video game experience significantly predicted both sense of presence and cybersickness, the latter two being negatively correlated. Even if women experienced more negative symptoms than men, gender appears less informative than cybersickness and video game experience. Field dependence was not associated with any other variable. Results are discussed by confronting two theories of cognition (representational vs. ecological), highlighting that virtual reality is not a simple transposition of reality but truly a new paradigm with its own biases favoring some individuals more than others, and that some human factors have to be controlled for rigorous uses of virtual environments, particularly for spatial cognition evaluation.
C1 [Maneuvrier, Arthur; Fleury, Philippe] Normandie Univ, UNICAEN, Erlis, Caen, France.
   [Decker, Leslie Marion] Normandie Univ, UNICAEN, COMETE, INSERM,GIP CYCERON, Caen, France.
   [Ceyte, Hadrien] Univ Lorraine, DevAH, Nancy, France.
   [Renaud, Patrice] Univ Quebec Outaouais, Dept Psychol, Lab Cyberpsychol, Gatineau, PQ, Canada.
C3 Universite de Caen Normandie; Institut National de la Sante et de la
   Recherche Medicale (Inserm); Universite de Caen Normandie; Universite de
   Lorraine; University of Quebec; University Quebec Outaouais
RP Maneuvrier, A (corresponding author), Normandie Univ, UNICAEN, Erlis, Caen, France.
EM arthur.maneuvrier@protonmail.com
RI Maneuvrier, Arthur/IQW-0291-2023; Decker, Leslie Marion/IWU-7992-2023;
   CEYTE, Hadrien/HGD-8921-2022; Decker, Leslie/N-8923-2015
OI Maneuvrier, Arthur/0000-0002-1897-8643; CEYTE,
   Hadrien/0000-0003-1746-5026; Decker, Leslie/0000-0003-2929-0761
CR Adams F, 2010, PHENOMENOL COGN SCI, V9, P619, DOI 10.1007/s11097-010-9175-x
   Allahyar M., 2003, INT J TEST, V3, P263, DOI [10.1207/S15327574IJT0303_5, DOI 10.1207/S15327574IJT03035]
   Allison SL, 2016, J ALZHEIMERS DIS, V52, P77, DOI 10.3233/JAD-150855
   Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   [Anonymous], 1975, Motion sickness
   Baniqued PL, 2013, ACTA PSYCHOL, V142, P74, DOI 10.1016/j.actpsy.2012.11.009
   Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Barfield W., 1995, Virtual Reality: Research, Developments, Applications, V1, P3, DOI [10.1007/BF02009709, DOI 10.1007/BF02009709]
   Behm-Morawitz E, 2009, SEX ROLES, V61, P808, DOI 10.1007/s11199-009-9683-8
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Boone AP, 2018, MEM COGNITION, V46, P909, DOI 10.3758/s13421-018-0811-y
   Boot WR, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00226
   Bos JE, 2005, AVIAT SPACE ENVIR MD, V76, P1111
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bosser AG, 2006, LECT NOTES COMPUT SC, V4161, P374
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Boyle EA, 2016, COMPUT EDUC, V94, P178, DOI 10.1016/j.compedu.2015.11.003
   Brake WG, 2018, CURR OPIN BEHAV SCI, V23, P176, DOI 10.1016/j.cobeha.2018.08.002
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   Breuer J, 2015, CYBERPSYCH BEH SOC N, V18, P197, DOI 10.1089/cyber.2014.0492
   Byagowi A, 2012, IEEE ENG MED BIO, P4812, DOI 10.1109/EMBC.2012.6347070
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Cameron EL, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00067
   Castelvecchi D, 2016, NATURE, V533, P153, DOI 10.1038/533153a
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Cipresso P, 2016, BMC MED INFORM DECIS, V16, DOI 10.1186/s12911-016-0276-5
   Clay F, 2020, J ALZHEIMERS DIS, V75, P23, DOI 10.3233/JAD-191218
   Clernes SA, 2005, J BIOL RHYTHM, V20, P71, DOI 10.1177/0748730404272567
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Coelho C, 2009, EMERG COMMUN-STUD NE, V9, P25
   Cogné M, 2017, ANN PHYS REHABIL MED, V60, P164, DOI 10.1016/j.rehab.2015.12.004
   Cogné M, 2018, NEUROPSYCHOLOGY, V32, P385, DOI 10.1037/neu0000435
   Coleman B, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01851
   Coluccia E, 2004, J ENVIRON PSYCHOL, V24, P329, DOI 10.1016/j.jenvp.2004.08.006
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   De Leo G, 2014, SIMUL HEALTHC, V9, P1, DOI 10.1097/SIH.0b013e3182a99dd9
   Diersch N, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.187252
   Ditton T., 1997, J COMPUTER MEDIATED, V3, pJCMC321, DOI [10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X]
   Draper J. V., 1996, P IEEE INT C ROB AUT
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Entertainment Software Association, 2019, 2019 SAL DEM US DAT
   Entertainment Software Association, 2019, ESS FACTS COMP VID G
   Epstein RA, 2017, NAT NEUROSCI, V20, P1504, DOI 10.1038/nn.4656
   Evans C, 2013, BRIT J EDUC PSYCHOL, V83, P210, DOI 10.1111/bjep.12015
   Felnhofer A., 2012, P INT SOC PRESENCE R
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   Foreman N., 2010, THEMES SCI TECHNOLOG, V2, P225
   Fox J, 2016, J INTERPERS VIOLENCE, V31, P1912, DOI 10.1177/0886260515570747
   Gamito P., 2008, Annual Review of CyberTherapy and Telemedicine: Changing the Face of Healthcare, P83
   Gamito P, 2010, STUD HEALTH TECHNOL, V154, P128, DOI 10.3233/978-1-60750-561-7-128
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Gibson J-J, 1977, Basic processes in reading: perception and comprehension, P155
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Grabarczyk P, 2016, AVANT, V7, P25, DOI 10.26913/70202016.0112.0002
   Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x
   Green CS, 2006, J EXP PSYCHOL HUMAN, V32, P1465, DOI 10.1037/0096-1523.32.6.1465
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Gregg L, 2007, SOC PSYCH PSYCH EPID, V42, P343, DOI 10.1007/s00127-007-0173-4
   Gresty MA, 2008, AVIAT SPACE ENVIR MD, V79, P105, DOI 10.3357/ASEM.2143.2008
   Gresty MA, 2009, ANN NY ACAD SCI, V1164, P263, DOI 10.1111/j.1749-6632.2008.03744.x
   Grön G, 2000, NAT NEUROSCI, V3, P404, DOI 10.1038/73980
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hecht D, 2007, CYBERPSYCHOL BEHAV, V10, P243, DOI 10.1089/cpb.2006.9962
   Hildebrandt J, 2018, LECT NOTES COMPUT SC, V10909, P82, DOI 10.1007/978-3-319-91581-4_7
   Hoeft F, 2008, J PSYCHIATR RES, V42, P253, DOI 10.1016/j.jpsychires.2007.11.010
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Ijaz K, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/13887
   Jones CM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00260
   Juul J., 2010, A Casual Revolution: Reinventing Video Games and Their Players
   Kapalo K.A., 2015, P HUMAN FACTORS ERGO, DOI DOI 10.1177/1541931215591261
   KENNEDY RS, 1975, AVIAT SPACE ENVIR MD, V46, P1349
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Knight M. M., 2006, RELATIONSHIP AGE OTH
   Kowert R., 2017, WOMEN ARE FARMVILLE
   Kuittinen J., 2007, P 2007 C FUT PLAY NE, P105, DOI 10.1145/1328202.1328221
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lachlan K, 2011, COMMUN RES REP, V28, P27, DOI 10.1080/08824096.2010.518924
   Lee AY, 1999, J CONSUM RES, V26, P115, DOI 10.1086/209554
   Levine SC, 2016, WIRES COGN SCI, V7, P127, DOI 10.1002/wcs.1380
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lobo L, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02228
   Ma RQ, 2006, INT J HUM-COMPUT ST, V64, P541, DOI 10.1016/j.ijhcs.2005.12.003
   Madl T, 2015, NEURAL NETWORKS, V65, P18, DOI 10.1016/j.neunet.2015.01.002
   Mahon BZ, 2015, LANG COGN NEUROSCI, V30, P420, DOI 10.1080/23273798.2014.987791
   Mantovani G, 1999, PRESENCE-TELEOP VIRT, V8, P540, DOI 10.1162/105474699566459
   Matsangas P, 2014, HUM FACTORS, V56, P1124, DOI 10.1177/0018720814522484
   Minderer M, 2016, NATURE, V533, P324, DOI 10.1038/nature17899
   Moffat SD, 1998, EVOL HUM BEHAV, V19, P73, DOI 10.1016/S1090-5138(97)00104-9
   Montello DR, 1999, ANN ASSOC AM GEOGR, V89, P515, DOI 10.1111/0004-5608.00160
   Moore JW, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01272
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Murias K, 2016, COMPUT HUM BEHAV, V58, P398, DOI 10.1016/j.chb.2016.01.020
   Nadler RT, 2010, PSYCHOL SCI, V21, P1770, DOI 10.1177/0956797610387441
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nash EB, 2000, INT J HUM-COMPUT INT, V12, P1, DOI 10.1207/S15327590IJHC1201_1
   NAVON D, 1979, PSYCHOL REV, V86, P214, DOI 10.1037/0033-295X.86.3.214
   North Max M., 2016, Australasian Journal of Information Systems, V20, P1
   Oliveira J, 2018, APPL NEUROPSYCH-ADUL, V25, P555, DOI 10.1080/23279095.2017.1349661
   Pallamin N, 2016, IFAC PAPERSONLINE, V49, P408, DOI 10.1016/j.ifacol.2016.10.600
   Pallavicini F, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02127
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   Parsons TD, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7040042
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Pithers R., 2002, Journal of Vocational Education and Training, P117, DOI [DOI 10.1080/13636820200200191, 10.1080/13636820200200191]
   Profet M., 1992, The adapted mind, P327
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rehbein F, 2016, COMPUT HUM BEHAV, V55, P729, DOI 10.1016/j.chb.2015.10.016
   Richardson AE, 2011, COMPUT HUM BEHAV, V27, P552, DOI 10.1016/j.chb.2010.10.003
   Riva G., 2003, Presence Connect
   Riva P. G., 2006, COMMUNICATION PRESEN
   Robillard G., 2002, 25E CONGRES ANNUEL S
   Rosa PJ, 2016, CYBERPSYCH BEH SOC N, V19, P209, DOI 10.1089/cyber.2015.0130
   Rowlands M., 2010, The New Science of the Mind: From Extended Mind to Embodied Phenomenology
   Saputra R., 2017, P 2017 4 INT C BIOM, P74, DOI [10.1145/3168776.3168797, DOI 10.1145/3168776.3168797]
   Saucier DM, 2002, BEHAV NEUROSCI, V116, P403, DOI 10.1037//0735-7044.116.3.403
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schultze U, 2010, J INF TECHNOL-UK, V25, P434, DOI 10.1057/jit.2010.25
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Scozzari S, 2011, STUD COMPUT INTELL, V337, P63
   Shafer D.-M., 2017, MED PSYCHOL REV
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Silverman I., 1992, ADAPTED MIND, P531
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Smith SM, 2001, PSYCHON B REV, V8, P203, DOI 10.3758/BF03196157
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Sullivan JV, 2018, PSYCHOL LEARN TEACH-, V17, P128, DOI 10.1177/1475725717752550
   Tarampi MR, 2016, PSYCHOL SCI, V27, P1507, DOI 10.1177/0956797616667459
   Thompson E., 2010, Mind in Life: Biology, Phenomenology and The Sciences of Mind
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   Welch RB, 1999, PRESENCE-TELEOP VIRT, V8, P574, DOI 10.1162/105474699566387
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witkin H.A., 1962, PSYCHOL DIFFERENTIAT
   Witmer B.G., 1994, MEASURING PRESENCE V
   Yee N., 2017, QUANTIC FOUNDRY
   Youngblut C, 2003, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2003.1191158
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
   Zhou YH, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01439
NR 156
TC 27
Z9 29
U1 6
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 29
PY 2020
VL 1
AR 571713
DI 10.3389/frvir.2020.571713
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L9FL1
UT WOS:001026248100001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Braun, N
   Berisha, A
   Anders, D
   Kannen, K
   Lux, S
   Philipsen, A
AF Braun, Niclas
   Berisha, Arbnor
   Anders, David
   Kannen, Kyra
   Lux, Silke
   Philipsen, Alexandra
TI Experimental Inducibility of Supernumerary Phantom Limbs: A Series of
   Virtual Reality Experiments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE supernumerary phantom limb; supernumerary limb illusion; virtual hand
   illusion; rubber hand illusion; EDA
ID RUBBER HAND; OWNERSHIP; ILLUSION; BODY; PERCEPTION; CORTEX; MOTOR; ARMS;
   OWN
AB Supernumerary phantom limb (SPL) is a rare neuropsychiatric syndrome, under which patients perceive more limbs than they anatomically possess (e.g., two instead of only one right arm). Remarkably, the concurrent limb percepts can thereby differ in respect to their primarily experienced modality, for instance, that one kinesthetic and one moving limb are experienced. Although SPLs are well-documented after various neuropsychiatric conditions, their neurocognitive pathomechanisms remain elusive. Therefore, an experimental paradigm by which such aberrant body misperceptions could be transiently induced and systematically investigated in healthy participants would be helpful. Inspired by the virtual hand illusion, we developed a virtual supernumerary limb illusion (SLI) version, in which two embodiable virtual hands are presented to the participant via a head-mounted display. One virtual hand is thereby presented medially and the other laterally aside the participant's hidden real hand. Using this general setup, we examined the inducibility of a SLI in three consecutive experiments: Experiment 1 explored by which induction type (visuotactile congruency, visuothermal congruency, and visuomotor congruency) SLI experiences can be induced most robustly, Experiment 2 explored whether SLIs can be induced by a combination of these induction types, and Experiment 3 explored how visuoproprioceptive congruency influences the inducibility of a SLI. Sense of ownership toward the virtual hands was systematically assessed by means of experience sampling and by an implicit electrodermal embodiment measure. Results reveal a robust effect of stronger sense of ownership toward the medially than laterally presented virtual hand, while only a subgroup of participants (on average, across experiments: similar to 25%) reported concomitant sense of ownership toward both virtual hands (i.e., a full-blown SLI experience). The highest SLI responder rate (similar to 63%) was observed for the combined application of visuotactile and visuothermal congruency, whereas a combined application of visuothermal and visuoproprioceptive congruency induced the lowest SLI responder rate (similar to 4%). In conclusion, our study demonstrates that although under specific experimental conditions, a majority of participants can be made to experience a SLI, under most conditions, sense of ownership is only experienced toward one virtual hand. This indicates that multiple type-identical limb percepts are avoided to be co-instantiated by our brain, wherever possible.
C1 [Braun, Niclas; Berisha, Arbnor; Anders, David; Kannen, Kyra; Lux, Silke; Philipsen, Alexandra] Univ Bonn, Dept Psychiat & Psychotherapy, Bonn, Germany.
C3 University of Bonn
RP Braun, N (corresponding author), Univ Bonn, Dept Psychiat & Psychotherapy, Bonn, Germany.
EM niclas.braun@ukbonn.de
RI Braun, Niclas/ITT-1944-2023
OI Anders, David/0000-0001-6843-3644; Kannen, Kyra/0000-0002-1524-6906
FU University of Bonn
FX This research article is a reworked excerpt from a non-published
   bachelor thesis by AB and was funded by budgets from the University of
   Bonn. No third party funding was involved. We acknowledge the support of
   Prof. Dr. Reinhard Klein.
CR Alimardani M, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00052
   Alimardani M, 2013, SCI REP-UK, V3, DOI 10.1038/srep02396
   Apps MAJ, 2014, NEUROSCI BIOBEHAV R, V41, P85, DOI 10.1016/j.neubiorev.2013.01.029
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   Braun N, 2016, SCI REP-UK, V6, DOI 10.1038/srep37696
   Braun N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111967
   Cipriani G, 2011, NEUROSCI BULL, V27, P359, DOI 10.1007/s12264-011-1737-6
   Curt A, 2011, SPINAL CORD, V49, P588, DOI 10.1038/sc.2010.143
   Dummer T, 2009, PERCEPTION, V38, P271, DOI 10.1068/p5921
   Ehrsson HH, 2009, PERCEPTION, V38, P310, DOI 10.1068/p6304
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Folegatti A, 2012, CONSCIOUS COGN, V21, P799, DOI 10.1016/j.concog.2012.02.008
   Guterstam A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017208
   Haans A, 2008, BODY IMAGE, V5, P389, DOI 10.1016/j.bodyim.2008.04.003
   HALLIGAN PW, 1993, J NEUROL NEUROSUR PS, V56, P159, DOI 10.1136/jnnp.56.2.159
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Kammers MPM, 2006, NEUROPSYCHOLOGIA, V44, P2430, DOI 10.1016/j.neuropsychologia.2006.04.009
   Khateb A, 2009, ANN NEUROL, V65, P698, DOI 10.1002/ana.21647
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Limanowski J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00946
   Limanowski J, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00547
   Lush P., 2019, PSYARXIV PREPRINT, DOI [10.31234/osf.io/82jav, DOI 10.31234/OSF.IO/82JAV]
   Lush P, 2020, COLLABRA-PSYCHOL, V6, DOI 10.1525/collabra.325
   MELZACK R, 1990, TRENDS NEUROSCI, V13, P88, DOI 10.1016/0166-2236(90)90179-E
   Millonig A, 2011, EPILEPSIA, V52, pE97, DOI 10.1111/j.1528-1167.2011.03156.x
   NEDERHOF AJ, 1985, EUR J SOC PSYCHOL, V15, P263, DOI 10.1002/ejsp.2420150303
   Newport R, 2010, EXP BRAIN RES, V204, P385, DOI 10.1007/s00221-009-2104-y
   Nickerson R. S., 1998, REV GEN PSYCHOL, V2, P175, DOI DOI 10.1037/1089-2680.2.2.175
   Ocklenburg S, 2011, LATERALITY, V16, P174, DOI 10.1080/13576500903483515
   Paulhus D. L., 1991, MEASURES PERSONALITY, V1, P17, DOI DOI 10.1016/B978-0-12-590241-0.50006-X
   Penfield W, 1937, BRAIN, V60, P389, DOI 10.1093/brain/60.4.389
   Riemer M, 2013, EXP BRAIN RES, V229, P383, DOI 10.1007/s00221-012-3374-3
   ROGERS M J C, 1992, Brain Injury, V6, P469, DOI 10.3109/02699059209008142
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Srivastava A, 2008, ACTA NEUROPSYCHIATR, V20, P256, DOI 10.1111/j.1601-5215.2008.00294.x
   Staub F, 2006, NEUROLOGY, V67, P2140, DOI 10.1212/01.wnl.0000249135.78905.75
   Synofzik M, 2008, CONSCIOUS COGN, V17, P411, DOI 10.1016/j.concog.2008.03.008
   Trojan J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29860-2
   Tsakiris M, 2017, Q J EXP PSYCHOL, V70, P597, DOI 10.1080/17470218.2016.1181768
   Tsakiris M, 2010, EXP BRAIN RES, V204, P343, DOI 10.1007/s00221-009-2039-3
   Yoo SD, 2011, J KOREAN MED SCI, V26, P844, DOI 10.3346/jkms.2011.26.6.844
NR 47
TC 3
Z9 3
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 16
PY 2020
VL 1
AR 12
DI 10.3389/frvir.2020.00012
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L7BN6
UT WOS:001024776200001
OA gold
DA 2024-07-18
ER

PT J
AU Ramousse, F
   Raimbaud, P
   Baert, P
   Helfenstein-Didier, C
   Gay, A
   Massoubre, C
   Galusca, B
   Lavoue, G
AF Ramousse, Florian
   Raimbaud, Pierre
   Baert, Patrick
   Helfenstein-Didier, Clementine
   Gay, Aurelia
   Massoubre, Catherine
   Galusca, Bogdan
   Lavoue, Guillaume
TI Does this virtual food make me hungry? effects of visual quality and
   food type in virtual reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE 3D graphics; visual quality; sensory evaluation; virtual reality; eating
   desire
ID SIGHT
AB Introduction: Studies into food-related behaviors and emotions are increasingly being explored with Virtual Reality (VR). Applications of VR technologies for food science include eating disorder therapies, eating behavior studies and sensory analyzes. These applications involve 3D food stimuli intended to elicit cravings, stress, and/or emotions. However, the visual quality (i.e., the realism) of used food stimuli is heterogeneous, and this factor's influence on the results has never been isolated and evaluated. In this context, this work aims to study how the visual quality of food stimuli, exposed in a virtual reality environment, influences the resulting desire to eat.Methods: 28 subjects without eating disorders were included in this protocol, who evaluated the desire to eat induced by 10 3D food stimuli, each duplicated in 7 quality levels (for a total of 70 stimuli).Results: Results show that visual quality influences the desire to eat, and this effect depends on the type of food and users' eating habits. We found two significant thresholds for visual quality: the first provides the minimal quality necessary to elicit a significant desire to eat, while the second provides the ceiling value above which increasing the quality does not improve further the desire to eat.Discussion: These results allow us to provide useful recommendations for the design of experiments involving food stimuli.
C1 [Ramousse, Florian; Raimbaud, Pierre; Baert, Patrick; Lavoue, Guillaume] Univ Claude Bernard Lyon 1, Univ Lyon, Ecole Natl Ingenieurs St Etienne, Ctr Natl Rech Sci,Cent Lyon,INSA Lyon,Lab InfoRmat, Ecully, France.
   [Helfenstein-Didier, Clementine] Univ Lyon, UMR Ctr Natl Rech Sci, Cent Lyon, Lab Tribol & Dynam Syst,UMR Ctr Natl Rech Sci, Ecully, France.
   [Gay, Aurelia; Galusca, Bogdan] Jean Monnet Univ, Univ Dept Psychiat, Addict & Extreme Bodyweight Res Grp TAPE, EA7423,CHU St Etienne,Eating Disorders, St Etienne, France.
   [Massoubre, Catherine] Jean Monnet Univ, Univ Dept Psychiat, Eating Disorders, CHU St Etienne, St Etienne, France.
   [Galusca, Bogdan] CHU St Etienne, Div Endocrinol Diabet Metab & Eating Disorders, St Etienne, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon; Ecole
   Centrale de Lyon; Centre National de la Recherche Scientifique (CNRS);
   Universite Claude Bernard Lyon 1; Ecole Centrale de Lyon; CHU de St
   Etienne; CHU de St Etienne; CHU de St Etienne
RP Ramousse, F (corresponding author), Univ Claude Bernard Lyon 1, Univ Lyon, Ecole Natl Ingenieurs St Etienne, Ctr Natl Rech Sci,Cent Lyon,INSA Lyon,Lab InfoRmat, Ecully, France.
EM florian.ramousse1@ec-lyon.fr
RI Raimbaud, Pierre/KDM-8260-2024
OI Raimbaud, Pierre/0000-0002-5584-8100; Helfenstein-Didier,
   Clementine/0000-0002-3197-601X
FU This work was funded by REHACOOR 42, Ecole Centrale of Lyon-ENISE, and
   the University Hospital Center (CHU) of Saint-Etienne.; Ecole Centrale
   of Lyon-ENISE; University Hospital Center (CHU) of Saint-Etienne
FX The authors also thank all the participants and Eliott Zimmermann,
   Pierre-Philippe Elst, Sophie Villenave and Charles Javerliat for
   technical supports and assistance.r This work was funded by REHACOOR 42,
   Ecole Centrale of Lyon-ENISE, and the University Hospital Center (CHU)
   of Saint-Etienne.
CR Alba-Martínez J, 2022, FOOD QUAL PREFER, V97, DOI 10.1016/j.foodqual.2021.104472
   Alexandrovsky D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376260
   Ammann J, 2020, FOOD QUAL PREFER, V86, DOI 10.1016/j.foodqual.2020.103998
   [Anonymous], 2019, GIMP
   Asp EH, 1999, FOOD POLICY, V24, P287, DOI 10.1016/S0306-9192(99)00024-X
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bi S, 2020, PROC CVPR IEEE, P5959, DOI 10.1109/CVPR42600.2020.00600
   Blechert J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00307
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Caine K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P981, DOI 10.1145/2858036.2858498
   Cheah CSL, 2020, APPETITE, V153, DOI 10.1016/j.appet.2020.104741
   Chen PJ, 2020, FOODS, V9, DOI 10.3390/foods9121898
   Chen Y, 2020, FOODS, V9, DOI 10.3390/foods9040465
   Cignoni P, 2008, ERCIM NEWS, P45
   Conner NO, 2022, Virtual Worlds, V1, P130, DOI DOI 10.3390/VIRTUALWORLDS1020008
   Crofton E, 2021, FOODS, V10, DOI 10.3390/foods10061154
   de Carvalho MR, 2017, BEHAV SCI-BASEL, V7, DOI 10.3390/bs7030043
   Delarue J, 2010, WOODHEAD PUBL FOOD S, P175, DOI 10.1533/9781845699970.2.175
   Flavián C, 2021, J BUS RES, V123, P289, DOI 10.1016/j.jbusres.2020.09.036
   Garland M, 1998, VISUALIZATION '98, PROCEEDINGS, P263, DOI 10.1109/VISUAL.1998.745312
   Gorini A, 2010, ANN GEN PSYCHIATR, V9, DOI 10.1186/1744-859X-9-30
   Gouton MA, 2021, FOOD QUAL PREFER, V87, DOI 10.1016/j.foodqual.2020.104016
   Hummel G, 2018, EAT BEHAV, V31, P60, DOI 10.1016/j.eatbeh.2018.08.002
   ISO 8589:2007, 2010, 85892007 ISO
   Javerliat C., 2022, P 28 ACM S VIRT REAL, P1
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91573-w
   Larson JS, 2014, J CONSUM PSYCHOL, V24, P188, DOI 10.1016/j.jcps.2013.09.001
   Machín L, 2019, FOOD QUAL PREFER, V77, P159, DOI 10.1016/j.foodqual.2019.05.012
   Marcum CS, 2018, ANN BEHAV MED, V52, P252, DOI 10.1093/abm/kax041
   Meiselman HL, 2006, FRONT NUTR SCI, P179, DOI 10.1079/9780851990323.0179
   Meiselman HL, 2000, APPETITE, V35, P231, DOI 10.1006/appe.2000.0360
   Muntoni Alessandro, 2021, PYMESHLAB
   Nehmé Y, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592786
   Paakki M, 2019, FOOD QUAL PREFER, V76, P81, DOI 10.1016/j.foodqual.2019.04.004
   Persky S, 2018, APPETITE, V123, P201, DOI 10.1016/j.appet.2017.12.007
   Picket B, 2019, FOODS, V8, DOI 10.3390/foods8020042
   ROLLS ET, 1983, PHYSIOL BEHAV, V30, P185, DOI 10.1016/0031-9384(83)90003-3
   ROLLS ET, 1976, BRAIN RES, V111, P53, DOI 10.1016/0006-8993(76)91048-9
   Schöniger MK, 2022, FOOD QUAL PREFER, V99, DOI 10.1016/j.foodqual.2021.104490
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   So BPH, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19105821
   Souchet AD, 2023, VIRTUAL REAL-LONDON, V27, P19, DOI 10.1007/s10055-022-00672-0
   Ung CY, 2018, FOOD QUAL PREFER, V63, P12, DOI 10.1016/j.foodqual.2017.07.007
   Waal NEV, 2021, FOOD QUAL PREFER, V90, DOI 10.1016/j.foodqual.2020.104167
   Wang QJ, 2021, FOOD RES INT, V145, DOI 10.1016/j.foodres.2021.110410
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Xu CY, 2021, TRENDS FOOD SCI TECH, V116, P533, DOI 10.1016/j.tifs.2021.07.015
NR 47
TC 1
Z9 1
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 14
PY 2023
VL 4
AR 1221651
DI 10.3389/frvir.2023.1221651
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA Q4EZ2
UT WOS:001057079000001
OA gold
DA 2024-07-18
ER

PT J
AU Lyu, Q
   Watanabe, K
   Umemura, H
   Murai, A
AF Lyu, Qiner
   Watanabe, Kentaro
   Umemura, Hiroyuki
   Murai, Akihiko
TI Design-thinking skill enhancement in virtual reality: A literature study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE design thinking; creative design; virtual design; virtual reality;
   virtual environment
ID ENVIRONMENTS; CREATIVITY; MANAGEMENT; SELF
AB As a methodology, design thinking involves practicing "a way of thinking" that non-designers can use as a source of inspiration instead being limited to a group of professional designers. This methodology has gained research attention because of the growing demands for social innovation and sustainability. The general public is expected to gain design-thinking skills through training or by applying design-thinking tools. Virtual reality (VR) is considered a potential tool to help accelerate augmenting design-thinking skills because it allows users to have embodied and immersive experiences. This study reviews existing literature on how VR has been used to enhance design-thinking skills. The general features of the publications such as the year of publication, design-thinking stages, VR types, targeted participants, and publication fields are analyzed for determining the latest trends and scenarios under this research topic. Further, a thematic analysis that follows creative enhancement structures is conducted to understand the role of VR in enhancing design-thinking skills, and future research directions are discussed based on the results. The review concludes that VR has the potential to enhance creativity in many aspects. Moreover, it highlights the need of gaining deeper understanding about 1) art, humanities, and societal perspectives; 2) cognition processes in VR; 3) emphasizing and defining stages in the design-thinking process; 4) technological improvements combined with the Metaverse; and 5) hybrid of the virtual and real worlds.
C1 [Lyu, Qiner] Univ Tokyo, Grad Sch Frontier Sci, Chiba, Japan.
   [Watanabe, Kentaro; Umemura, Hiroyuki; Murai, Akihiko] Natl Inst Adv Ind Sci & Technol, Human Augmentat Res Ctr, Chiba, Japan.
C3 University of Tokyo; National Institute of Advanced Industrial Science &
   Technology (AIST)
RP Lyu, Q (corresponding author), Univ Tokyo, Grad Sch Frontier Sci, Chiba, Japan.
EM 1199224946@edu.k.u-tokyo.ac.jp
RI Shamim, Nida/IXD-8527-2023; Murai, Akihiko/Q-5269-2016
FU International Graduate Program of Innovation for Intelligent World of
   the University of Tokyo
FX This study was funded by the International Graduate Program of
   Innovation for Intelligent World of the University of Tokyo.
CR Abdelhameed WA, 2014, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2014), P719
   Abhari M., 2021, HCI INT 2021 LATE BR
   Abrishami S., 2013, AEI 2013 BUILDING SO
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Alexiou A., 2004, 2004 24 INT C DISTR
   Aydin S, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.495468
   Bartosh A., 2019, EXPT APPL VIRTUAL RE
   Bastug E, 2017, IEEE COMMUN MAG, V55, P110, DOI 10.1109/MCOM.2017.1601089
   Bellalouna F, 2019, INT CONF COGN INFO, P41, DOI [10.1109/coginfocom47531.2019.9090002, 10.1109/CogInfoCom47531.2019.9090002]
   Berg LP, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4034267
   Bhattacharjee D, 2018, COMPUT ELECTR ENG, V65, P236, DOI 10.1016/j.compeleceng.2017.08.023
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brown T, 2011, J PROD INNOVAT MANAG, V28, P381, DOI 10.1111/j.1540-5885.2011.00806.x
   Buisine S, 2016, COGN TECHNOL WORK, V18, P583, DOI 10.1007/s10111-016-0378-y
   Bujdoso G., 2017, 2017 8 IEEE INT C CO
   Buruk O. T., 2021, 2021 ACM INT C PROCE
   Caputo F., 2017, 46 IT ASS FOR STRESS
   Chandrasekera T., 2015, P 2015 IEEE INT S MI
   Chang YS, 2023, INTERACT LEARN ENVIR, V31, P1142, DOI 10.1080/10494820.2020.1821717
   Chang YS, 2022, EDUC STUD-UK, V48, P341, DOI 10.1080/03055698.2020.1754767
   Charlton Patricia, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030034
   Chen YC, 2022, J COMPUT ASSIST LEAR, V38, P6, DOI 10.1111/jcal.12588
   Cindioglu HC, 2022, INT J TECHNOL DES ED, V32, P2775, DOI 10.1007/s10798-021-09707-0
   D'Souza N, 2011, DESIGN STUD, V32, P180, DOI 10.1016/j.destud.2010.07.002
   Dam R. F., 2021, WHAT IS EMPATHY WHY
   Dehn LB, 2018, COMPUT HUM BEHAV, V79, P40, DOI 10.1016/j.chb.2017.10.019
   Design Council, 2019, Framework for innovation: Design council's evolved double diamond
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Doring T., 2018, P 2018 ANN S COMP HU
   Dosi C., 2019, P INT C ENG DES ICED
   Dul J, 2011, ERGONOMICS, V54, P12, DOI 10.1080/00140139.2010.542833
   Dunne D, 2006, ACAD MANAG LEARN EDU, V5, P512, DOI 10.5465/AMLE.2006.23473212
   Earle AG, 2021, MANAGE LEARN, V52, P581, DOI 10.1177/1350507620974857
   Evans P., 2021, P 23 INT C ENG PROD
   Fan P. M., 2020, S SPAT US INT VIRT E
   Ferrara M., 2018, INT C INT HUM SYST I
   Fischer G, 2004, COMMUN ACM, V47, P33, DOI 10.1145/1015864.1015884
   Fogli D., 2017, CEUR WORKSHOP PROC
   Foster PP, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00117
   Georgiev GV, 2017, P IEEE VIRT REAL ANN, P243, DOI 10.1109/VR.2017.7892267
   Godin J J., 2019, Issues in Information Systems, V20, P104
   Gong ZY, 2022, DIGIT CREAT, V33, P96, DOI 10.1080/14626268.2022.2064879
   GORDON VS, 1995, IEEE SOFTWARE, V12, P85, DOI 10.1109/52.363162
   Gra&beta;ler I., 2017, 1 ANN SCI FICT PROT
   Gruber M, 2015, ACAD MANAGE J, V58, P1, DOI 10.5465/amj.2015.4001
   Gu N., 2010, DESIGN 2010 11 INT D
   Gül LF, 2014, J INF TECHNOL CONSTR, V19, P47
   Hanandeh A. E., 2016, 27 ANN C AUSTR ASS E
   Henriksen D., 2017, The STEAM Journal, V3, P1
   Hu X., 2020, P 6 INT C DES CREAT
   Huang X., 2018, LEARN AD PROT P 23 I
   IBM, 2018, DES THINK REENV MOD
   Jenek W., 2021, ACM INT C P SERIES
   Jensen C., 2017, Journal of Problem Based Learning in Higher Education, V5, P85, DOI [DOI 10.5278/OJS.JPBLHE.V0I0.1542, 10.5278/OJS.JPBLHE.V0I0.1542]
   Johansson-Sköldberg U, 2013, CREAT INNOV MANAG, V22, P121, DOI 10.1111/caim.12023
   Kan J. W., 2008, CAADRIA 2008 P 13 IN, P263
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   Keller I, 2001, CYBERPSYCHOL BEHAV, V4, P215, DOI 10.1089/109493101300117901
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Kurokawa T., 2013, Science Technology Trends Quarterly Review, V46, P50
   Lau KW, 2015, INTERACT LEARN ENVIR, V23, P3, DOI 10.1080/10494820.2012.745426
   Lee JH, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P604, DOI 10.1145/3325480.3326575
   Lee JH, 2021, DES J, V24, P503, DOI 10.1080/14606925.2021.1912902
   Lee L.-H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2110.05352
   Lee S., 2009, P 2009 ACM SIGCHI C
   Leung AKY, 2008, AM PSYCHOL, V63, P169, DOI 10.1037/0003-066X.63.3.169
   Liedtka J., 2011, STRATEGY LEADERSHIP, V39, P13, DOI [DOI 10.1108/10878571111161480, 10.1108/10878571111161480]
   Lin HC, 2020, THINK SKILLS CREAT, V37, DOI 10.1016/j.tsc.2020.100705
   Liu X., 2021, P DES SOC
   Lubart T, 2005, INT J HUM-COMPUT ST, V63, P365, DOI 10.1016/j.ijhcs.2005.04.002
   Manera V., 2017, FRONT AGING NEUROSCI, V9, P391
   Maurya S, 2019, INT J INTERACT DES M, V13, P163, DOI 10.1007/s12008-018-0499-z
   Merrick KE, 2011, J INF TECHNOL CONSTR, V16, P165
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Mueller-Roterberg Christian., 2018, Handbook Of Design Thinking-Tips Tools For How To Design Thinking, V1st
   Mulligan K, 2018, DISABIL HEALTH J, V11, P237, DOI 10.1016/j.dhjo.2017.08.009
   Nakazato Naoto, 2014, P 17 ACM C COMP SUPP
   Narumi T., 2021, P 9 INT C HUMAN AGEN
   Neroni MA, 2021, INT J DES CREAT INNO, V9, P139, DOI 10.1080/21650349.2021.1929500
   Nishino H., 2001, INT C INF NETW
   O'Dwyer DW, 2007, EUR J ENG EDUC, V32, P695, DOI 10.1080/03043790701520727
   Obeid S, 2023, INTERACT LEARN ENVIR, V31, P1841, DOI 10.1080/10494820.2020.1858116
   Olmos F., 2006, WIT T INFORM COMMUNI
   Page R., 2000, SIMTECT 2000 P, P1, DOI 2.5428&rep=rep1&type=pdf
   Panke S., 2019, OPEN ED STUDIES, V1, P281, DOI DOI 10.1515/EDU-2019-0022
   Petrykowski M., 2018, FUTURE TECHNOLOGIES
   Pham DT, 1998, INT J MACH TOOL MANU, V38, P1257, DOI 10.1016/S0890-6955(97)00137-5
   Plattner H, 2011, UNDERST INNOV, P1, DOI 10.1007/978-3-642-13757-0
   Qian D., 2021, 7 INT C ARTS DES CON
   Razzouk R, 2012, REV EDUC RES, V82, P330, DOI 10.3102/0034654312457429
   Ren W., 2021, J PHYS C SERIES
   Rieuf Vincent, 2015, Journal of Design Research, V13, P78, DOI 10.1504/JDR.2015.067233
   Rieuf V, 2017, DESIGN STUD, V48, P43, DOI 10.1016/j.destud.2016.11.001
   Ritter SM, 2012, J EXP SOC PSYCHOL, V48, P961, DOI 10.1016/j.jesp.2012.02.009
   Rive P., 2016, 11 EUR C INN ENTR EC
   Robbins P., 2018, J OPEN INNOVATION, V4, P57, DOI DOI 10.3390/JOITMC4040057
   Robertson A., 2021, WHAT IS METAVERSE DO
   Roupé M, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001935
   Samson S, 2017, COLL RES LIBR, V78, P459, DOI 10.5860/crl.78.4.459
   Sanders EBN, 2002, DESIGN AND THE SOCIAL SCIENCES: MAKING CONNECTIONS, P1
   Schaper Marie-Monique, 2018, International Journal of Child-Computer Interaction, V17, P5, DOI 10.1016/j.ijcci.2018.02.001
   Schkolne S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P261, DOI 10.1145/365024.365114
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Seidel Victor P., 2020, INFORMS Transactions on Education, V20, P73, DOI 10.1287/ited.2019.0220
   Shahrbanian S., 2012, EUR J EXP BIOL, V2, P1408
   Shih S. C., 2017, P 2017 IEEE INT C AP
   Siau K, 2010, J DATABASE MANAGE, V21, P1, DOI 10.4018/jdm.2010100101
   Skibina V., 2021, INT C INF SYST DES, P323
   Skrupskaya Y., 2021, INFORM SYSTEMS DESIG, P336
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slepian ML, 2010, J EXP SOC PSYCHOL, V46, P696, DOI 10.1016/j.jesp.2010.03.009
   Sopher H, 2019, BRIT J EDUC TECHNOL, V50, P2109, DOI 10.1111/bjet.12857
   Stark R, 2010, CIRP ANN-MANUF TECHN, V59, P179, DOI 10.1016/j.cirp.2010.03.102
   Sutherland IE, 1965, MULTIMEDIA WAGNER VI
   Tabrizian P., 2017, DISC DISR P CAT 37 A
   Takeuchi K., 2020, COMP 2020 ACM IEEE I
   Thornhill-Miller B, 2016, J COGN EDUC PSYCHOL, V15, P102, DOI 10.1891/1945-8959.15.1.102
   van Ginkel S, 2019, COMPUT EDUC, V134, P78, DOI 10.1016/j.compedu.2019.02.006
   Vosinakis S, 2013, VIRTUAL REAL-LONDON, V17, P59, DOI 10.1007/s10055-013-0221-1
   Warren T., 2021, MICROSOFT TEAMS ENTE
   Washida Y., 2020, T FORESIGH, V23, P17
   Whewell E, 2022, EDUC INF TECHNOL, V27, P6691, DOI 10.1007/s10639-022-10892-1
   Yamada K., 2017, P INT C ENG DES ICED
   Ye J, 2006, VIRTUAL PHYS PROTOTY, V1, P171, DOI 10.1080/17452750601017129
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yoshida S., 2000, INT ARCH PHOTOGRAMME
   Zhongcui Zhu, 2021, Journal of Physics: Conference Series, V1746, DOI 10.1088/1742-6596/1746/1/012063
   Zimmerer C., 2020, ICMI 2020 P 2020 INT
NR 128
TC 2
Z9 2
U1 5
U2 24
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 4
PY 2023
VL 4
AR 1137293
DI 10.3389/frvir.2023.1137293
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WD9
UT WOS:001023276400001
OA gold
DA 2024-07-18
ER

PT J
AU Ambron, E
   Goldstein, S
   Miller, A
   Hamilton, RH
   Coslett, HB
AF Ambron, Elisabetta
   Goldstein, Shayna
   Miller, Alexander
   Hamilton, Roy H.
   Coslett, H. Branch
TI From my skin to your skin: Virtual image of a hand of different skin
   color influences movement duration of the real hand in Black and White
   individuals and influences racial bias
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; racial biases; movement; implicit association task;
   rubber hand illusion
ID SELF-REPRESENTATION; IMPLICIT; EMPATHY; OWNERSHIP; ILLUSION; SIZE; FEEL
AB Virtual reality (VR) allows individuals to experience someone else's body, but the possible effects of this embodiment on attitudes and biases are not fully understood. Using a virtual reality (VR) task, we had previously shown that changes in the visual image of the hand influenced action: when the visual image of one's hand was spatially displaced, participants acted as if the virtual hand was theirs. Here we tested whether these effects vary depending on the match between the skin color of the individual and the virtual hand. Black and White participants performed reaching movements with dark or light hands of naturalistic skin tones, or purple hands. As in our previous work, the correspondence between the location of the real and virtual hands was systematically varied. Both Black and White participants showed changes in the temporal and spatial parameters of the movements with the virtual hand of different colors indicating that the hand had been embodied. A larger effect of the illusion was observed in Black as compared to White individuals when performing the action with a dark-skin virtual hand. Ownership of the virtual hand that matched the participants' skin color was associated with their explicit attitude towards their in-group in Black participants and with empathic abilities in White individuals. Importantly, performing the task with a dark-skin hand reduced the implicit racial bias of White individuals. These data show that body representation is malleable and influenced by online perceptual factors as well as attitudes and biases. Our findings raise the possibility that altering the representation of one's body may be used to change participants' perspectives regarding social issues.
C1 [Ambron, Elisabetta; Goldstein, Shayna; Miller, Alexander; Hamilton, Roy H.; Coslett, H. Branch] Univ Penn, Lab Cognit & Neural Stimulat, Perelman Sch Med, Philadelphia, PA 19104 USA.
   [Hamilton, Roy H.; Coslett, H. Branch] Univ Penn, Dept Neurol, Perelman Sch Med, Philadelphia, PA USA.
C3 University of Pennsylvania; University of Pennsylvania
RP Ambron, E (corresponding author), Univ Penn, Lab Cognit & Neural Stimulat, Perelman Sch Med, Philadelphia, PA 19104 USA.
EM eli.ambron@gmail.com
CR Ambron E, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66348-4
   Ambron E, 2018, NEUROPSYCHOLOGIA, V119, P373, DOI 10.1016/j.neuropsychologia.2018.08.029
   Ambron E, 2017, ACTA PSYCHOL, V180, P160, DOI 10.1016/j.actpsy.2017.09.011
   Asai T, 2011, CONSCIOUS COGN, V20, P1744, DOI 10.1016/j.concog.2011.02.005
   Avenanti A, 2005, NAT NEUROSCI, V8, P955, DOI 10.1038/nn1481
   Avenanti A, 2010, CURR BIOL, V20, P1018, DOI 10.1016/j.cub.2010.03.071
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bruneau EG, 2017, SOC PSYCHOL PERS SCI, V8, P934, DOI 10.1177/1948550617693064
   Caola B, 2018, PERCEPTION, V47, P477, DOI 10.1177/0301006618758211
   DAMASIO AR, 1994, SCI AM, V271, P144, DOI 10.1038/scientificamerican1094-144
   Davis M. H., 1980, INTERPERSONAL REACTI, DOI [https://doi.org/10.1037/t01093-000, DOI 10.1037/T01093-000]
   Farmer H, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01016
   Farmer H, 2012, CONSCIOUS COGN, V21, P1242, DOI 10.1016/j.concog.2012.04.011
   Fiedler K., 2006, EUROPEAN REV SOCIAL, V17, P74, DOI [10.1080/10463280600681248, DOI 10.1080/10463280600681248]
   Frank KA, 2013, EDUC EVAL POLICY AN, V35, P437, DOI 10.3102/0162373713493129
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Greenwald AG, 2003, J PERS SOC PSYCHOL, V85, P197, DOI 10.1037/0022-3514.85.2.197
   Groom V, 2009, SOC INFLUENCE, V4, P231, DOI 10.1080/15534510802643750
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Lai CK, 2014, J EXP PSYCHOL GEN, V143, P1765, DOI 10.1037/a0036260
   Lira M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16137-3
   Lopez S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300787
   Maister L., 2013, COGNITIONNEUROPSYCHO, V12848, P170645, DOI [10.1016/j.neuropsychologia.2009.08.017, DOI 10.1016/J.NEUROPSYCHOLOGIA.2009.08.017]
   Marino BFM, 2010, EXP BRAIN RES, V202, P499, DOI 10.1007/s00221-009-2143-4
   Medina J, 2016, COGN NEUROPSYCHOL, V33, P1, DOI 10.1080/02643294.2016.1197195
   Nosek BA, 2005, J EXP PSYCHOL GEN, V134, P565, DOI 10.1037/0096-3445.134.4.565
   Nosek BA, 2002, GROUP DYN-THEOR RES, V6, P101, DOI 10.1037//1089-2699.6.1.101
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Slater M, 2021, CURR DIR PSYCHOL SCI, V30, P503, DOI 10.1177/09637214211046954
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Xu XJ, 2009, J NEUROSCI, V29, P8525, DOI 10.1523/JNEUROSCI.2418-09.2009
   Yee N., 2006, P PRESENCE 2006 9 AN
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
NR 37
TC 0
Z9 0
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD DEC 15
PY 2022
VL 3
AR 884189
DI 10.3389/frvir.2022.884189
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4XQ6
UT WOS:001023315200001
OA gold
DA 2024-07-18
ER

PT J
AU Kondo, R
   Sugimoto, M
AF Kondo, Ryota
   Sugimoto, Maki
TI Split body: Extending self-location by splitting a body left and right
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE body ownership; sense of agency; self-location; embodiment; split body
ID RUBBER; OWNERSHIP; ILLUSION; TOUCH; LIMB
AB Is it possible to feel part of one's own body even when the body part is separated from the body? If so, we could exist in different locations by splitting the self-body and using our body in each location. In a study in which the illusion that two bodies are one's own body was induced using virtual reality (VR), the participants felt as if they were at two locations through the two bodies. However, this illusion was weak and reported only subjectively. We hypothesized that this was because two presented bodies moved synchronously with one participant's movement or the simultaneous stroking of one participant's body and two presented bodies switched their attention and weakened body ownership. In this study, we investigated whether splitting one body into left and right in VR could induce body ownership and extend the self-location while maintaining a one-to-one correspondence between the participant's body and the presented body. The results showed that weaker body ownership was induced in the split body than in the normal body and self-location was extended to the right side of the body. The participants did not report a sense of having more than one body but reported a sense of body spreading, suggesting that the split bodies were perceived as a single body extending to the right side.
C1 [Kondo, Ryota; Sugimoto, Maki] Keio Univ, Dept Informat & Comp Sci, Yokohama, Kanagawa, Japan.
C3 Keio University
RP Kondo, R (corresponding author), Keio Univ, Dept Informat & Comp Sci, Yokohama, Kanagawa, Japan.
EM ryota.kondo@keio.jp
FU JST ERATO (Inami JIZAI Body Project) [JPMJER1701]; JSPS KAKENHI
   [21J00345]; Grants-in-Aid for Scientific Research [22KJ2659] Funding
   Source: KAKEN
FX This research was supported by JST ERATO Grant Number JPMJER1701 (Inami
   JIZAI Body Project) and JSPS KAKENHI Grant Number 21J00345.
CR Abdulkarim Z, 2016, ATTEN PERCEPT PSYCHO, V78, P707, DOI 10.3758/s13414-015-1016-0
   Aymerich-Franch L, 2016, CONSCIOUS COGN, V46, P99, DOI 10.1016/j.concog.2016.09.017
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Carey M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39168-4
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Guterstam A, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201911
   Kalckert A, 2014, CONSCIOUS COGN, V30, P118, DOI 10.1016/j.concog.2014.08.022
   Keenaghan S, 2020, CONSCIOUS COGN, V78, DOI 10.1016/j.concog.2020.102882
   Kilteni K, 2016, FRONT HUM NEUROSCI, V10, DOI [10.3389/fnhum.2010.00145, 10.3389/fnhum.2016.00145]
   Kondo R., 2018, INT C ARTIFICIAL REA, P21
   Kondo R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62121-9
   Kondo R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25951-2
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   Lloyd DM, 2007, BRAIN COGNITION, V64, P104, DOI 10.1016/j.bandc.2006.09.013
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Matsumiya K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37375-z
   Miura R, 2022, FRONT COMP SCI-SWITZ, V4, DOI 10.3389/fcomp.2022.788014
   Nakul E, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63643-y
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Tieri G, 2015, EXP BRAIN RES, V233, P1247, DOI 10.1007/s00221-015-4202-3
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
NR 26
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 4
PY 2022
VL 3
AR 992803
DI 10.3389/frvir.2022.992803
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4WR0
UT WOS:001023289600001
OA gold
DA 2024-07-18
ER

PT J
AU Oliva, R
   Beacco, A
   Navarro, X
   Slater, M
AF Oliva, Ramon
   Beacco, Alejandro
   Navarro, Xavi
   Slater, Mel
TI QuickVR: A standard library for virtual embodiment in unity
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual environments; virtual reality software; virtual
   reality systems; embodiment; body ownership; avatar tracking; unity
ID REALITY; BODY; BEHAVIOR
AB In the last few years the field of Virtual Reality (VR) has experienced significant growth through the introduction of low-cost VR devices to the mass market. However, VR has been used for many years by researchers since it has proven to be a powerful tool across a vast array of research fields and applications. The key aspect of any VR experience is that it is completely immersive, which means that the virtual world totally surrounds the participant. Some game engines such as Unity already support VR out of the box and an application can be configured for VR in a matter of minutes. However, there is still the lack of a standard and easy to use tool in order to embody participants into a virtual human character that responds synchronously to their movements with corresponding virtual body movements. In this paper we introduce QuickVR, a library based on Unity which not only offers embodiment in a virtual character, but also provides a series of high level features that are necessary in any VR application, helping to dramatically reduce the production time. Our tool is easy to use by coding novices, but also easy extensible and customizable by more experienced programmers.
C1 [Oliva, Ramon; Beacco, Alejandro; Navarro, Xavi; Slater, Mel] Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.
   [Slater, Mel] Univ Barcelona, Inst Neurosci, Barcelona, Spain.
C3 University of Barcelona; University of Barcelona
RP Slater, M (corresponding author), Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.; Slater, M (corresponding author), Univ Barcelona, Inst Neurosci, Barcelona, Spain.
EM melslater@ub.edu
RI Navarro, Xavi/KEE-5474-2024
FU European Research Council Advanced grant Moments in Time in Immersive
   Virtual Environments (MoTIVE) [742989]
FX Funding This research is supported by the European Research Council
   Advanced grant Moments in Time in Immersive Virtual Environments
   (MoTIVE) grant number 742989.
CR Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Barberia I, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203358
   Bebko A. O., 2020, bmltux: Design and control of experiments in virtual reality and beyond, DOI [10.31234/osf.io/arvkf, DOI 10.31234/OSF.IO/ARVKF]
   Bourdin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169343
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Caserman P, 2019, IEEE INT CONF SERIOU, DOI 10.1109/segah.2019.8882429
   Coelho CM, 2006, CYBERPSYCHOL BEHAV, V9, P336, DOI 10.1089/cpb.2006.9.336
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Epic Games, 2021, UNR ENG
   Extend Reality Ltd, 2021, VRTK
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Matamala-Gomez M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020291
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   Neyret S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62932-w
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Ponton Jose Luis, 2022, P EUR 2022 SHORT PAP, P77, DOI [10.2312/egs20221037, DOI 10.2312/EGS20221037]
   Root Motion, 2021, FIN
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Slater M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00091
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   Unity, 2021, Unity
   Unity Technologies, 2021, AN RIGG PACK
   Unity Technologies, 2021, XR INT TOOLK
   Unity Technologies, 2021, XR PLUG FRAM
   Watson MR, 2019, bioRxiv, DOI [10.1101/434944, 10.1101/434944, DOI 10.1101/434944]
NR 33
TC 6
Z9 6
U1 2
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 15
PY 2022
VL 3
AR 937191
DI 10.3389/frvir.2022.937191
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L0IB5
UT WOS:001020165500001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Hopkins, T
   Weng, SCC
   Vanukuru, R
   Wenzel, EA
   Banic, A
   Gross, MD
   Do, EYL
AF Hopkins, Torin
   Weng, Suibi Che Chuan
   Vanukuru, Rishi
   Wenzel, Emma A.
   Banic, Amy
   Gross, Mark D.
   Do, Ellen Yi-Luen
TI AR Drum Circle: Real-Time Collaborative Drumming in AR
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE augmented reality; remote collaboration; network latency; drum circle;
   user studies
ID MUSIC
AB AR Drum Circle, is an augmented reality (AR) platform we developed to facilitate a collaborative remote drumming experience. We explore the effects of virtual avatars that are rendered in a player's view to provide the joy and sensation of co-present music creation. AR Drum Circle uses a head mounted AR display, providing players with visual effects to assist drummers in coordinating musical ideas while simultaneously using a latency-optimized remote collaboration service (JackTrip). AR Drum Circle helps overcome barriers in music collaboration introduced when using remote collaboration tools on their own, which typically do not support real-time video, lack spatial information, and volume control between players, all of which are important for in-person drum circles and music collaboration. This paper presents the results of several investigations: (1) analysis of an in-depth, free-form response survey of drumming communication provided by a small group of expert drummers, (2) observations and analysis of 20 videos of live drum circles, (3) a case study using the AR Drum Circle application in pairs of remotely located participants, and (4) a collaborative drumming case study using a popular networked conferencing application (Zoom). Findings suggest that substantial communicative information including facial expressions, hand-tracking, and eye-contact is lost when using AR alone. Findings also indicate that the AR Drum Circle application can make players less self-conscious and more willing to participate while playing drums improvisationally with others.
C1 [Hopkins, Torin; Weng, Suibi Che Chuan; Vanukuru, Rishi; Wenzel, Emma A.; Banic, Amy; Gross, Mark D.; Do, Ellen Yi-Luen] Univ Colorado Boulder, ATLAS Inst, Boulder, CO 80309 USA.
   [Banic, Amy] Univ Wyoming, Interact Real Lab, Laramie, WY USA.
C3 University of Colorado System; University of Colorado Boulder;
   University of Wyoming
RP Hopkins, T (corresponding author), Univ Colorado Boulder, ATLAS Inst, Boulder, CO 80309 USA.
EM torin.hopkins@colorado.edu
RI Do, Ellen Yi-Luen/B-3621-2009
OI Do, Ellen Yi-Luen/0000-0002-9948-6375; Banic, Amy/0000-0003-4803-1925
FU Ericsson Research
FX This study received funding from Ericsson Research. The funder was not
   involved in the study design, collection, analysis, interpretation of
   data, the writing of this article or the decision to submit it for
   publication.
CR [Anonymous], 2002, THESIS STANFORD U
   Beacco A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/VR50410.2021.00078
   Berry R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P338, DOI 10.1109/ISMAR.2003.1240749
   Billinghurst Mark., 2004, Tangible Augmented Reality
   Biocca F., 2002, DEF MEAS SOC PRES CO, P1
   Bishop L, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01285
   Cáceres JP, 2010, J NEW MUSIC RES, V39, P183, DOI 10.1080/09298215.2010.481361
   Chew E., 2005, P SOUND MUSIC COMPUT
   Drioli C., 2013, INT C INFORM TECHNOL, P240
   Eaves DL, 2020, MUSIC SCI, V24, P475, DOI 10.1177/1029864919825776
   Jo D., 2016, SIGGRAPH ASIA 2016 V, P1
   Jung Byungdae., 2000, Proceedings of the ACM symposium on Virtual reality software and technology, P206, DOI DOI 10.1145/502390.502429
   Kipp M., 2012, Multimedia Information Extraction: Advances in Video, Audio, and Imagery Analysis for Search, Data Mining, Surveillance, and Authoring, P351, DOI DOI 10.1002/9781118219546.CH21
   Kleimola J., 2006, Latency Issues in Distributed Musical Performance
   Kokotsaki D, 2011, MUSIC EDUC RES, V13, P149, DOI 10.1080/14613808.2011.577768
   Krueger J, 2011, CONSCIOUS COGN, V20, P643, DOI 10.1016/j.concog.2010.09.022
   Lee S, 2020, INT J HUM-COMPUT INT, V36, P930, DOI 10.1080/10447318.2019.1699748
   Lin G., 2021, Hotmobile 2021 - proceedings of the 22nd international workshop on mobile computing systems and applications, P132
   Mastnak W, 2020, ACTA PAEDIATR, V109, P1516, DOI 10.1111/apa.15346
   Nowacki Pawel, 2020, Engineering in Dependability of Computer Systems and Networks. Proceedings of the Fourteenth International Conference on Dependability of Computer Systems DepCoS-RELCOMEX. Advances in Intelligent Systems and Computing (AISC 987), P358, DOI 10.1007/978-3-030-19501-4_36
   Philippe RA, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05212
   Poupyrev I, 2000, SIGGRAPH 2000 EMERGI
   Signiant, 2021, VR AR ARE SURG COVID
   Simsek M, 2016, IEEE J SEL AREA COMM, V34, P460, DOI 10.1109/JSAC.2016.2525398
   Thompson WF, 2005, SEMIOTICA, V156, P203, DOI 10.1515/semi.2005.2005.156.203
   Vinnard Valerie., 2018, Delta_Kappa_Gamma_Bulletin, V85, P43
   Xu Chi., 2021, SPIE_AVR21_Industry_Talks II, V11764, page, P1176409, DOI DOI 10.1117/12.2597454
NR 27
TC 2
Z9 3
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 19
PY 2022
VL 3
AR 847284
DI 10.3389/frvir.2022.847284
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OS0
UT WOS:001021709500001
OA gold
DA 2024-07-18
ER

PT J
AU Hosono, S
   Miyake, T
   Miyake, S
   Tamaki, E
AF Hosono, Satoshi
   Miyake, Tamon
   Miyake, Shota
   Tamaki, Emi
TI Feedback Method of Force Controlled by Electrical Muscle Stimulation
   Based on Infrared Optical Sensing
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE infrared optical sensing; body sharing; electrical muscle stimulation;
   support vector regression model; augmented experience
ID PIANISTS
AB The goal of the study was to develop a system that can adjust the electrical muscle stimulation parameters for individuals when sharing experiences with stimulation by sensing the degree of muscle contraction during electrical stimulation. If we do not know the appropriate amount of current for stimulation for an individual, the muscles would not contract as we aimed, and we will not be able to share the experience as we expected. In this study, we presented a system estimating fingertip force as the output of electrical muscle stimulation by monitoring the muscle state based on infrared optical sensing for adjusting electrical muscle stimulation parameters for the individual. We developed a regression model based on support vector regression during electrical stimulation using an infrared optical sensor with seven people's data to estimate the pushing force. The coefficient of determination between the measured pushing force and estimated pushing force was greater than 0.8 and 0.9 for the index and middle fingers, respectively. The system can monitor a feedback value of electrical muscle stimulation fingertip control. The system showed the feasibility of infrared optical sensing for the closed-loop feedback control system of the electrical stimulation parameters for an individual.
C1 [Hosono, Satoshi; Tamaki, Emi] H2L Inc, Tokyo, Japan.
   [Miyake, Tamon] Waseda Univ, Future Robot Org, Tokyo, Japan.
   [Miyake, Shota] Waseda Univ, Creat Sci & Engn Fac, Tokyo, Japan.
   [Tamaki, Emi] Univ Ryukyus, Fac Engn, Nishihara, Okinawa, Japan.
C3 Waseda University; Waseda University; University of the Ryukyus
RP Hosono, S (corresponding author), H2L Inc, Tokyo, Japan.
EM satoshi.hosono@h2l.jp
OI Tamaki, Emi/0000-0003-1990-6219
CR Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CRAGO PE, 1980, IEEE T BIO-MED ENG, V27, P306, DOI 10.1109/TBME.1980.326738
   Fu TF, 2020, NEUROSCIENCE, V426, P179, DOI 10.1016/j.neuroscience.2019.10.052
   Hanagata S, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174951
   Hassan Mahmoud, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3053332
   Hassib M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6133, DOI 10.1145/3025453.3025953
   Kasahara S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445147
   Kasuya M, 2013, IEEE INT CONF ROBOT, P93, DOI 10.1109/ICRA.2013.6630561
   Kinoshita H, 2007, J ACOUST SOC AM, V121, P2959, DOI 10.1121/1.2717493
   Kruijff E., 2006, P ACM S VIRTUAL REAL, P316, DOI DOI 10.1145/1180495.1180558
   Kurosawa K, 2005, IEEE T NEUR SYS REH, V13, P359, DOI 10.1109/TNSRE.2005.847355
   LOPES P, 2013, P SIGCHI C HUM FACT, P2577, DOI DOI 10.1145/2470654.2481355
   Lopes P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174020
   Lopes P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1471, DOI 10.1145/3025453.3025600
   Lopes P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2515, DOI 10.1145/2702123.2702128
   Lopes P, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P207, DOI 10.1145/2984511.2984530
   Miyake Tamon, 2019, 2019 IEEE International Conference on Robotics and Biomimetics (ROBIO), P977, DOI 10.1109/ROBIO49542.2019.8961661
   Miyake T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041081
   Miyamoto N., 2015, AIR TAP SENSATION TA, P285, DOI [10.1007/978-4-431-55690-9_52, DOI 10.1007/978-4-431-55690-9_52]
   Miyamoto T, 2016, EUR J SPORT SCI, V16, P1104, DOI 10.1080/17461391.2016.1151944
   Nishida J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3316, DOI 10.1145/3025453.3025829
   Nith Romain, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P414, DOI 10.1145/3472749.3474759
   Parlitz D, 1998, J BIOMECH, V31, P1063, DOI 10.1016/S0021-9290(98)00113-4
   Pfeiffer M., 2014, P 5 AUGM HUM INT C, P1
   Pfeiffer M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2505, DOI 10.1145/2702123.2702190
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Takahashi A., 2021, C HUM FACT COMP SYST, V216, P1
   Tamaki E., 2010, Proceedings of the 1st augmented human international conference, P1
   Tamaki E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P543
   Yem V, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P89, DOI 10.1109/VR.2018.8446403
NR 31
TC 1
Z9 1
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 5
PY 2022
VL 3
AR 880238
DI 10.3389/frvir.2022.880238
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PD2
UT WOS:001021720700001
OA gold
DA 2024-07-18
ER

PT J
AU Kaji, Y
   Sato, A
   Miyashita, H
AF Kaji, Yoshinobu
   Sato, Ai
   Miyashita, Homei
TI Design of Electrical Stimulation Waveform for Enhancing Saltiness and
   Experiment on Low-Sodium Dieters
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE electric taste; galvanic tongue stimulation; electrical stimulation;
   taste enhancement; salt reduction
ID TASTE
AB Electric tastes can present various taste modulation effects using stimulation waveforms. Presenting and stopping cathodal stimulation or presenting anodal stimulation, for example, can enhance the saltiness of foods and drinks. If the taste of low-sodium foods improves because of these effects, it can provide low-sodium dieters with both mental satisfaction and nutritional health benefits. However, no studies on the effect of saltiness enhancement on electric taste in low-sodium dieters have been conducted. In this study, we first designed and investigated a stimulation waveform suitable for saltiness enhancement of low-sodium foods. This stimulation waveform combined the effects of presenting and stopping cathodal stimulation and presenting anodal stimulation and showed a saltier enhancement than the existing waveforms. Next, we conducted an experiment with individuals who were or had been on a low-sodium diet. In this experiment, the effect of saltiness enhancement on the proposed stimulation waveform was investigated using saltwater gel samples with the same saltiness as low-sodium and ordinary foods. The results suggest that presenting the proposed stimulation waveform when eating foods with a 30% reduction in salt content can present a saltiness equivalent to that of ordinary foods. Furthermore, the discomfort caused by electrical stimulation was not severe enough to be a problem for most participants. Finally, assuming the use of electric tastes in daily life, this study attempted to qualitatively analyze the changes in saltiness intensity and flavor of low-sodium miso soup.
C1 [Kaji, Yoshinobu; Miyashita, Homei] Meiji Univ, Grad Sch Adv Math Sci, Tokyo, Japan.
   [Sato, Ai] Kirin Holdings Co Ltd, Tokyo, Japan.
C3 Meiji University; Kirin Holdings Co Ltd
RP Kaji, Y; Miyashita, H (corresponding author), Meiji Univ, Grad Sch Adv Math Sci, Tokyo, Japan.
EM cs212004@meiji.ac.jp; homei@homei.com
FU Kirin Holdings Company, Limited
FX This study received funding from Kirin Holdings Company, Limited.
CR Aoyama K, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02112
   Aruga Yukika, 2015, P 6 AUGM HUM INT C, P191, DOI [10.1145/2735711.2735811, DOI 10.1145/2735711.2735811]
   Kaji Y., 2021, P S ENTERTAINMENT CO, P266
   Kaji Y., 2022, P INTERACTION 2022
   Makino N., 1998, ENBUN HAYAWAKARI ITS
   Matsuda Y., 2017, MITE WAKARU TEIBAN O
   Nakamura H., 2013, CHI'13 Extended Abstracts on Human Factors in Computing Systems, P3111, DOI [DOI 10.1145/2468356.2479623, 10.1145/2468356, DOI 10.1145/2468356]
   Nakamura H, 2021, J ROBOT MECHATRON, V33, P1128, DOI 10.20965/jrm.2021.p1128
   Nakamura Hiromi, 2013, P 5 INT WORKSH MULT, P9, DOI [DOI 10.1145/2506023.2506026, 10.1145/2506023.2506026]
   Ranasinghe N, 2019, FOOD RES INT, V117, P60, DOI 10.1016/j.foodres.2018.05.030
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1139, DOI 10.1145/3123266.3123440
   Ranasinghe N, 2012, IEEE INT SYM WRBL CO, P80, DOI 10.1109/ISWC.2012.16
   Sakurai K, 2017, Trans Virtual Real Soc Jpn, V22, P149, DOI [10.18974/tvrsj.22.2_149, DOI 10.18974/TVRSJ.22.2_149]
NR 13
TC 3
Z9 3
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 5
PY 2022
VL 3
AR 879784
DI 10.3389/frvir.2022.879784
PG 10
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PH0
UT WOS:001021724500001
OA gold
DA 2024-07-18
ER

PT J
AU Boban, L
   Pittet, D
   Herbelin, B
   Boulic, R
AF Boban, Loen
   Pittet, David
   Herbelin, Bruno
   Boulic, Ronan
TI Changing Finger Movement Perception: Influence of Active Haptics on
   Visual Dominance
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE multisensory integration; multisensory conflicts; virtual reality;
   haptics; sense of agency; sense of ownership; visual perception; motor
   perception
ID TOUCH; HAND; FEEL
AB The perception of one's own body is a complex mechanism that can be disturbed by conflicting sensory information and lead to illusory (mis-) perceptions. Prominent models of multisensory integration propose that sensory streams are integrated according to their reliability by approximating Bayesian inference. As such, when considering self-attribution of seen motor actions, previous works argue in favor of visual dominance over other sensations, and internal cues. In the present work, we use virtual reality and a haptic glove to investigate the influence of an active haptic feedback on one's visual and agency judgments over a performed finger action under experimentally manipulated visual and haptic feedbacks. Data overall confirm that vision dominates for agency judgment in conditions of multisensory conflict. Interestingly, we also show that participants' visual judgment over their finger action is sensitive to multisensory conflicts (vision, proprioception, motor afferent signals, and haptic perception), thus bringing an important nuance to the widely accepted view on a general visual dominance.
C1 [Boban, Loen; Pittet, David; Boulic, Ronan] Ecole Polytech Fed Lausanne EPFL, Sch Comp & Commun Sci, Immers Interact Grp IIG, Lausanne, Switzerland.
   [Boban, Loen; Herbelin, Bruno] Ecole Polytech Fed Lausanne EPFL, Sch Life Sci, Lab Cognit Neurosci LNCO, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne
RP Boban, L (corresponding author), Ecole Polytech Fed Lausanne EPFL, Sch Comp & Commun Sci, Immers Interact Grp IIG, Lausanne, Switzerland.; Boban, L (corresponding author), Ecole Polytech Fed Lausanne EPFL, Sch Life Sci, Lab Cognit Neurosci LNCO, Lausanne, Switzerland.
EM loen.boban@epfl.ch
FU SNFS project [200020-178790]; Swiss National Science Foundation (SNF)
   [200020_178790] Funding Source: Swiss National Science Foundation (SNF)
FX This work has been supported by the SNFS project "Immersive Embodied
   Interactions" grant 200020-178790.
CR Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bovet S, 2018, IEEE T VIS COMPUT GR, V24, P1428, DOI 10.1109/TVCG.2018.2794658
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Friston KJ, 2012, NEUROIMAGE, V62, P1230, DOI 10.1016/j.neuroimage.2011.10.004
   HAY JC, 1965, PSYCHON SCI, V2, P215, DOI 10.3758/BF03343413
   HELLER MA, 1983, PERCEPTION, V12, P607, DOI 10.1068/p120607
   Holmes NP, 2005, EXP BRAIN RES, V166, P489, DOI 10.1007/s00221-005-2389-4
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   Lee Y, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P19, DOI 10.1109/WHC.2015.7177685
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   Odermatt IA, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.678909
   POWER RP, 1980, PERCEPTION, V9, P457, DOI 10.1068/p090457
   Ramírez-Fernández C, 2015, INT CONF PER COMP, P280, DOI 10.4108/icst.pervasivehealth.2015.260242
   Salomon R, 2016, SCI REP-UK, V6, DOI 10.1038/srep25847
   Schwind V, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225158
   van Beers RJ, 2002, CURR BIOL, V12, P834, DOI 10.1016/S0960-9822(02)00836-9
NR 19
TC 2
Z9 2
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 27
PY 2022
VL 3
AR 860872
DI 10.3389/frvir.2022.860872
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SY2
UT WOS:001021820500001
OA gold
DA 2024-07-18
ER

PT J
AU Podder, A
   Gruchalla, K
   Brunhart-Lupo, N
   Pless, S
   Sica, M
   Lacchin, P
AF Podder, Ankur
   Gruchalla, Kenny
   Brunhart-Lupo, Nicholas
   Pless, Shanti
   Sica, Mauro
   Lacchin, Paolo
TI Immersive Industrialized Construction Environments for Energy Efficiency
   Construction Workforce
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE industrialized construction; industry 4; 0; construction automation;
   productivity; workforce; energy efficiency; digital twins; immersive
   environments
ID PRODUCTIVITY
AB The National Renewable Energy Laboratory is actively developing and testing Immersive Industrialized Construction Environments (IICE) for construction automation and worker-machine interaction to investigate possible solutions and increase workforce productivity. At full scope and matured functionality, IICE allows us to accelerate the development of and better explore industrialized construction approaches such as prefabrication. IICE also enables wider adoption of energy-efficient products and Industry 4.0 construction automation through worker-machine interaction pilots. Industry 4.0 and industrialized construction approaches can encourage workforce specialization in energy efficiency construction, address the lack of multi-skilled workers, and increase workforce productivity with construction automation. However, recent attempts to integrate these concepts with the industry have only been moderately successful. To address this, focusing the pedagogy on using a digital twin, its digital models, and virtual reality could make the experience of continuing education on construction automation more affordable, accessible, scalable, immersive, and safer, and could greatly improve the efficiency and robustness of the building and construction industry. IICE accurately represents the realities of construction uncertainties without having to create full scale physical prototypes of machines. In this paper, we address the following research question: How can a digital twin and its models in virtual reality enhance the learning experience and productivity of energy efficiency construction workers to gain the skills in operating Industry 4.0 components such as construction automation and handling energy-efficient products in industrialized construction factories and on-site? We introduce original research on developing IICE and present preliminary findings from time and motion pilot studies.
C1 [Podder, Ankur; Pless, Shanti] Natl Renewable Energy Lab, Community & Urban Sci Res Grp, Golden, CO 80401 USA.
   [Gruchalla, Kenny; Brunhart-Lupo, Nicholas] Natl Renewable Energy Lab, Computat Sci Ctr, Golden, CO USA.
   [Sica, Mauro] Pre Framing Corp, Berkeley, CA USA.
   [Lacchin, Paolo] SimFactory Automat SA, Stabio, Switzerland.
C3 United States Department of Energy (DOE); National Renewable Energy
   Laboratory - USA; United States Department of Energy (DOE); National
   Renewable Energy Laboratory - USA
RP Podder, A (corresponding author), Natl Renewable Energy Lab, Community & Urban Sci Res Grp, Golden, CO 80401 USA.
EM Ankur.Podder@nrel.gov
FU National Renewable Energy Laboratory; U.S. Department of Energy (DOE);
   Wells Fargo Foundation's Innovation Incubator (IN2); U.S. DOE's Office
   of Energy Efficiency and Renewable Energy at NREL; NREL; Pre Framing
   Corp; SimFactory Automation SA
FX This work was authored in part by the National Renewable Energy
   Laboratory, operated by Alliance for Sustainable Energy, LLC, for the
   U.S. Department of Energy (DOE). Majority of the funding to perform this
   preliminary research and develop early IICE capability at NREL was
   provided by the Wells Fargo Foundation's Innovation Incubator (IN2).
   This research was performed using computational resources sponsored by
   the U.S. DOE's Office of Energy Efficiency and Renewable Energy and
   located at NREL. The funded project was a collaboration between NREL,
   Pre Framing Corp, and SimFactory Automation SA. The views expressed in
   the article do not necessarily represent the views of the DOE or the
   U.S. Government. The U.S. Government retains and the publisher, by
   accepting the article for publication, acknowledges that the U.S.
   Government retains a nonexclusive, paid-up, irrevocable, worldwide
   license to publish or reproduce the published form of this work, or
   allow others to do so, for U.S. Government purposes.
CR [Anonymous], 2014, International Journal of Advanced Science and Technology, V73, P51, DOI [10.14257/ijast.2014.73.04, DOI 10.14257/IJAST.2014.73.04]
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Energy, 2019, EN EFF JOBS AM
   Fenner A.E., 2017, Proceedings of the 6th International Network of Tropical Architecture Conference, Tropical Storms as a Setting for Adaptive Development and Architecture, Gainesville, FL, USA, P1
   Filipe Barbosa JW., 2017, REINVENTING CONSTRUC
   Golabchi A, 2015, J CONSTR ENG M, V141, DOI 10.1061/(ASCE)CO.1943-7862.0000998
   Goulding J, 2012, ADV ENG INFORM, V26, P103, DOI 10.1016/j.aei.2011.09.004
   Gruchalla K., 2019, VR DEV GEMS, P383, DOI [10.1201/b21598-21, DOI 10.1201/B21598-21]
   Guo XC, 2016, INT CONF COMP INFO, P6
   Hajikazemi S, 2017, INT J PRODUCT PERFOR, V66, P539, DOI 10.1108/IJPPM-06-2016-0122
   Loera I, 2013, PROCEDIA ENGINEER, V63, P947, DOI 10.1016/j.proeng.2013.08.274
   Lui M., 2014, ENCY SCI ED, P1, DOI [10.1007/978-94-007-6165-0_39-1, DOI 10.1007/978-94-007-6165-0_39-1]
   Podder A., 2020, NRELCP550077259, P1
   Razkenari M. A., 2018, TRAINING MANUFACTURE
   Razkenari M, 2019, COMPUTING IN CIVIL ENGINEERING 2019: DATA, SENSING, AND ANALYTICS, P352
   Oesterreich TD, 2016, COMPUT IND, V83, P121, DOI 10.1016/j.compind.2016.09.006
   Truitt S., 2020, NRELCP550075497
   Vaughan N, 2016, COMPUT SCI REV, V22, P65, DOI 10.1016/j.cosrev.2016.09.001
NR 19
TC 1
Z9 2
U1 6
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 10
PY 2022
VL 3
AR 781170
DI 10.3389/frvir.2022.781170
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TX9
UT WOS:001021846200001
OA gold
DA 2024-07-18
ER

PT J
AU Kelly, JW
   Doty, TA
   Ambourn, M
   Cherep, LA
AF Kelly, Jonathan W.
   Doty, Taylor A.
   Ambourn, Morgan
   Cherep, Lucia A.
TI Distance Perception in the Oculus Quest and Oculus Quest 2
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE distance perception; depth perception; virtual reality; head mounted
   display; oculus quest; oculus quest 2; Blind walking; verbal report
ID IMMERSIVE VIRTUAL ENVIRONMENTS; REAL; TRANSFERS
AB Distances in virtual environments (VEs) viewed on a head-mounted display (HMD) are typically underperceived relative to the intended distance. This paper presents an experiment comparing perceived egocentric distance in a real environment with that in a matched VE presented in the Oculus Quest and Oculus Quest 2. Participants made verbal judgments and blind walking judgments to an object on the ground. Both the Quest and Quest 2 produced underperception. Verbal judgments in the VE were 82% and 75% of the object distance, in contrast with real world judgments that were 94% of the object distance. Blind walking judgments were 68% and 70% of object distance in the Quest and Quest 2, respectively, compared to 88% in the real world. This project shows that significant underperception of distance persists even in modern HMDs.
C1 [Kelly, Jonathan W.; Doty, Taylor A.; Ambourn, Morgan; Cherep, Lucia A.] Iowa State Univ, Dept Psychol, Ames, IA 50011 USA.
C3 Iowa State University
RP Kelly, JW (corresponding author), Iowa State Univ, Dept Psychol, Ames, IA 50011 USA.
EM jonkelly@iastate.edu
RI Kelly, Jonathan/A-4793-2013
OI Kelly, Jonathan/0000-0002-4317-273X
CR Adams H, 2022, IEEE T VIS COMPUT GR, V28, P4624, DOI 10.1109/TVCG.2021.3097978
   Ahn S, 2021, INT J HUM-COMPUT INT, V37, P36, DOI 10.1080/10447318.2020.1805875
   [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   [Anonymous], 2005, ACM Transactions on Applied Perception, DOI [DOI 10.1145/1077399.1077403, DOI 10.1145/1077399.10774032,3,9]
   Arora R., 2021, ARXIV
   Aseeri S, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00044
   Buck L, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.728667
   Buck LE, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3196885
   Creem-Regehr SH, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P47, DOI 10.1145/2804408.2804422
   Creem-Regehr SH, 2015, PSYCHOL LEARN MOTIV, V62, P195, DOI 10.1016/bs.plm.2014.09.006
   Ding F, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407929
   Feldstein IT, 2020, PERCEPTION, V49, P940, DOI 10.1177/0301006620951997
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Hu HH, 2000, IEEE VISUAL, P179, DOI 10.1109/VISUAL.2000.885692
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   Kelly JW, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3165285
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kelly JW, 2014, IEEE T VIS COMPUT GR, V20, P588, DOI 10.1109/TVCG.2014.36
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Leyrer M., 2011, P ACM SIGGRAPH S APP, DOI 10.1145/2077451.2077464
   Li BC, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P55, DOI 10.1145/2804408.2804427
   Madison C, 2001, PERCEPT PSYCHOPHYS, V63, P187, DOI 10.3758/BF03194461
   Maruhn P, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224651
   Masnadi S, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P542, DOI 10.1109/VRW52623.2021.00153
   Ooi TL, 2001, NATURE, V414, P197, DOI 10.1038/35102562
   Peer A, 2017, IEEE SYMP 3D USER, P83, DOI 10.1109/3DUI.2017.7893321
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Richardson AR, 2007, HUM FACTORS, V49, P507, DOI 10.1518/001872007X200139
   Sahm C. S., 2005, ACM Trans. Appl. Percept. (TAP), V2, P35, DOI DOI 10.1145/1048687.1048690
   Siegel ZD, 2017, J EXP PSYCHOL HUMAN, V43, P1805, DOI 10.1037/xhp0000401
   Siegel ZD, 2017, ATTEN PERCEPT PSYCHO, V79, P39, DOI 10.3758/s13414-016-1243-z
   Steinicke F., 2009, Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization, P19, DOI 10.1145/1620993.1620998
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   Ullah F, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093142
   Waller D, 2008, J EXP PSYCHOL-APPL, V14, P61, DOI 10.1037/1076-898X.14.1.61
   Willemsen P, 2002, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2002.996536
   Willemsen P, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498702
   Witmer BG, 1998, HUM FACTORS, V40, P478, DOI 10.1518/001872098779591340
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
   Zhang J., 2021, I-PERCEPTION, V12, DOI DOI 10.1177/20416695211023956
NR 40
TC 5
Z9 5
U1 5
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAR 7
PY 2022
VL 3
AR 850471
DI 10.3389/frvir.2022.850471
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VV9
UT WOS:001019169300001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Podkosova, I
   Reisinger, J
   Kaufmann, H
   Kovacic, I
AF Podkosova, Iana
   Reisinger, Julia
   Kaufmann, Hannes
   Kovacic, Iva
TI BIMFlexi-VR: A Virtual Reality Framework for Early-Stage Collaboration
   in Flexible Industrial Building Design
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; collaborative BIM; parametric modeling in VR; VR in
   AEC; VR in Industry 4; 0; collaborative VR
AB Integrated industrial building design is an interdisciplinary task, in which planning of flexible building structures requires effective communication and collaboration between all stakeholders already in early design stage. This paper presents BIMFlexi-VR, a collaborative framework which implements a real-time bidirectional link between a parametric modelling component created in Grasshopper for Rhinoceros that performs optimized structural calculations of an industrial building, and an immersive Virtual Reality environment in which the automatically calculated building is visualized. Users of BIMFlexi-VR are able to change parameters defining the outcome of the structural calculation directly inside the virtual environment and see the modified building design together with the associated fitness metrics in a matter of seconds. Providing an efficient and intuitive platform for early exploration of industrial building designs, BIMFlexi-VR enables collaborative decision making and facilitates the creation of more efficient and sustainable industrial constructions.
C1 [Podkosova, Iana; Kaufmann, Hannes] TU Wien, Inst Visual Comp & Human Ctr Technol, Fac Comp Sci, Vienna, Austria.
   [Reisinger, Julia; Kovacic, Iva] TU Wien, Inst Interdisciplinary Construct Proc Management, Fac Civil Engn, Vienna, Austria.
C3 Technische Universitat Wien; Technische Universitat Wien
RP Podkosova, I (corresponding author), TU Wien, Inst Visual Comp & Human Ctr Technol, Fac Comp Sci, Vienna, Austria.
EM yana.podkosova@tuwien.ac.at
OI Reisinger, Julia/0000-0002-2316-306X
FU Austrian funding institution FFG (OEsterreichische
   Forschungsfoerderungsgesellschaft) within the FFG BRIDGE program
   [877159]
FX The authors would like to acknowledge the support by the Austrian
   funding institution FFG (OEsterreichische
   Forschungsfoerderungsgesellschaft) for the research project "BIMFlexi"
   within the FFG BRIDGE program (30th call for tenders, Grant No. 877159).
   Open access publishing is funded by the TU Wien library.
CR Anderson Anne, 2014, Construction in a Global Network. 2014 Construction Research Congress. Proceedings, P179
   Anderson A, 2017, J INF TECHNOL CONSTR, V22, P287
   Boton C, 2018, AUTOMAT CONSTR, V96, P1, DOI 10.1016/j.autcon.2018.08.020
   Bouchlaghem D, 2005, AUTOMAT CONSTR, V14, P287, DOI 10.1016/j.autcon.2004.08.012
   Coppens A., 2018, PARAMETRIC MODELLING
   Coppens A, 2018, LECT NOTES COMPUT SC, V11151, P304, DOI 10.1007/978-3-030-00560-3_44
   Davidson J, 2020, FRONT ENG MANAG, V7, P396, DOI 10.1007/s42524-019-0039-y
   Du J, 2018, AUTOMAT CONSTR, V85, P51, DOI 10.1016/j.autcon.2017.10.009
   Du J, 2016, CONSTRUCTION RESEARCH CONGRESS 2016: OLD AND NEW CONSTRUCTION TECHNOLOGIES CONVERGE IN HISTORIC SAN JUAN, P2281
   Enscape G., 2019, ENSC ARCHT VIRT REAL
   Fernandes KJ, 2006, TECHNOVATION, V26, P111, DOI 10.1016/j.technovation.2004.07.013
   Horikawa J., 2019, RHINO COMPUTE UNITY3
   Johansson M, 2014, FUSION: DATA INTEGRATION AT ITS BEST, VOL 2, P261
   Kalloc Studios F., 2018, FUZOR VR COLLABORATI
   Kamari A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010249
   Kieferle J, 2015, ECAADE 2015: REAL TIME - EXTENDING THE REACH OF COMPUTATION, VOL 1, P69
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Michalos G, 2018, CIRP ANN-MANUF TECHN, V67, P141, DOI 10.1016/j.cirp.2018.04.120
   Mindesk, 2019, MIND RHIN LINK
   Mindesk, 2019, MIND MULT VR RHIN
   Moubile M., 2018, THESIS GHENT U GHENT
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Quinn G., 2018, P IASS ANN S, P1
   Reisinger J., 2020, P 37 INT S AUT ROB C, DOI [10.22260/isarc2020/0028, DOI 10.22260/ISARC2020/0028]
   Reisinger J., 2021, 2021 EUR C COMP CONS, V11
   Reisinger J, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131910627
   Robert McNill and Associates, 2019, COMP GUID
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sampaio A.Z., 2018, STATE ART VIRTUAL RE, P59
   Sidani A, 2021, J BUILD ENG, V42, DOI 10.1016/j.jobe.2021.102500
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Warwick K., 1993, VIRTUAL REALITY ENG
   Whyte J., 2003, Electronic Journal of Information Technology in Construction, V8
   Wolfartsberger J, 2018, IFAC PAPERSONLINE, V51, P637, DOI 10.1016/j.ifacol.2018.08.390
   Zaker Reza, 2018, Visualization in Engineering, V6, DOI 10.1186/s40327-018-0065-6
   Zhao T., 2003, J INFRASTRUCT SYST, V9, P89, DOI DOI 10.1061/(ASCE)1076-0342(2003)9:3(89)
NR 37
TC 2
Z9 2
U1 2
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 25
PY 2022
VL 3
AR 782169
DI 10.3389/frvir.2022.782169
PG 13
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PQ3
UT WOS:001021733800001
OA gold
DA 2024-07-18
ER

PT J
AU Oberdoerfer, S
   Schraudt, D
   Latoschik, ME
AF Oberdoerfer, Sebastian
   Schraudt, David
   Latoschik, Marc Erich
TI Embodied Gambling-Investigating the Influence of Level of Embodiment,
   Avatar Appearance, and Virtual Environment Design on an Online VR Slot
   Machine
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual environments; immersion; gambling; risks;
   embodiment; avatars
ID CONFIRMATORY FACTOR VALIDATION; POP-UP MESSAGES; ILLUSORY OWNERSHIP;
   SOCIAL-STATUS; REALITY; ILLUSION; SCALE; FLOW; DISSOCIATION; EXPERIENCES
AB Slot machines are one of the most played games by players suffering from gambling disorder. New technologies like immersive Virtual Reality (VR) offer more possibilities to exploit erroneous beliefs in the context of gambling. Recent research indicates a higher risk potential when playing a slot machine in VR than on desktop. To continue this investigation, we evaluate the effects of providing different degrees of embodiment, i.e., minimal and full embodiment. The avatars used for the full embodiment further differ in their appearance, i.e., they elicit a high or a low socio-economic status. The virtual environment (VE) design can cause a potential influence on the overall gambling behavior. Thus, we also embed the slot machine in two different VEs that differ in their emotional design: a colorful underwater playground environment and a virtual counterpart of our lab. These design considerations resulted in four different versions of the same VR slot machine: 1) full embodiment with high socio-economic status, 2) full embodiment with low socio-economic status, 3) minimal embodiment playground VE, and 4) minimal embodiment laboratory VE. Both full embodiment versions also used the playground VE. We determine the risk potential by logging gambling frequency as well as stake size, and measuring harm-inducing factors, i.e., dissociation, urge to gamble, dark flow, and illusion of control, using questionnaires. Following a between groups experimental design, 82 participants played for 20 game rounds one of the four versions. We recruited our sample from the students enrolled at the University of Wurzburg. Our safety protocol ensured that only participants without any recent gambling activity took part in the experiment. In this comparative user study, we found no effect of the embodiment nor VE design on neither the gambling frequency, stake sizes, nor risk potential. However, our results provide further support for the hypothesis of the higher visual angle on gambling stimuli and hence the increased emotional response being the true cause for the higher risk potential.
C1 [Oberdoerfer, Sebastian; Schraudt, David; Latoschik, Marc Erich] Univ Wurzburg, Chair Human Comp Interact, Wurzburg, Germany.
C3 University of Wurzburg
RP Oberdoerfer, S (corresponding author), Univ Wurzburg, Chair Human Comp Interact, Wurzburg, Germany.
EM sebastian.oberdoerfer@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600
CR Aardema F, 2010, CYBERPSYCH BEH SOC N, V13, P429, DOI 10.1089/cyber.2009.0164
   Abbott M., 2018, CONCEPTUAL FRAMEWORK, DOI [DOI 10.33684/CFHG3.EN, 10.33684/CFHG3.e]
   Adams E., 2012, Game Mechanics: Advanced Game Design
   Adler NE, 2000, HEALTH PSYCHOL, V19, P586, DOI 10.1037/0278-6133.19.6.586
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Armstrong T, 2017, J GAMBL STUD, V33, P735, DOI 10.1007/s10899-016-9644-4
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Banz M., 2017, BUNDESZENTRALE F R G, P1, DOI [10.17623/BZGA:225-GS-SY17-1.0, DOI 10.17623/BZGA:225-GS-SY17-1.0]
   Barcrest, 2015, MON BIG EV
   Baria C. G., 2022, CHARACTERS
   Bayern L. S. G., 2022, SELBSTTEST GLUCKSSPI
   BECHARA A, 1994, COGNITION, V50, P7, DOI 10.1016/0010-0277(94)90018-3
   Blaszczynski A, 2016, J GAMBL STUD, V32, P789, DOI 10.1007/s10899-015-9565-7
   Bouchard S, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P59, DOI 10.1109/HAVE.2004.1391882
   Bouchard S., 2014, The thousand faces of virtual reality, P3, DOI DOI 10.5772/59240
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bouchard S, 2017, FRONT PSYCHIATRY, V8, DOI 10.3389/fpsyt.2017.00027
   Bremner JD, 1998, J TRAUMA STRESS, V11, P125, DOI 10.1023/A:1024465317902
   Brevers D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00665
   Calado F, 2016, J BEHAV ADDICT, V5, P592, DOI 10.1556/2006.5.2016.073
   Caler K., 2016, CURR ADDICT REP, V3, P437, DOI DOI 10.1007/S40429-016-0118-7
   Charbonneau P., 2017, INT C VIRT REH ICVR, P1, DOI [DOI 10.1109/ICVR.2017.8007535, 10.1109/ICVR.2017.8007535]
   Cloutier M, 2006, J PSYCHOL, V140, P434, DOI 10.3200/JRLP.140.5.434-438
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, V721
   Diskin Katherine M., 1999, J Gambl Stud, V15, P17, DOI 10.1023/A:1023062912062
   Diskin KM, 2001, CAN J BEHAV SCI, V33, P58, DOI 10.1037/h0087128
   Dixon MJ, 2018, J GAMBL STUD, V34, P73, DOI 10.1007/s10899-017-9695-1
   Dixon MJ, 2018, J GAMBL STUD, V34, P161, DOI 10.1007/s10899-017-9699-x
   Finlay K, 2006, ENVIRON BEHAV, V38, P570, DOI 10.1177/0013916505283419
   Finlay K, 2010, ENVIRON BEHAV, V42, P524, DOI 10.1177/0013916509341791
   Folkvord F., 2019, Journal of Behavioral Economics for Policy, V3, P20
   Fox J, 2013, COMPUT HUM BEHAV, V29, P930, DOI 10.1016/j.chb.2012.12.027
   Freepik, 2017, SEAL
   Friedman Bill., 2000, Designing Casinos to Dominate the Competition
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gall D, 2020, COMPUT HUM BEHAV, V109, DOI 10.1016/j.chb.2020.106346
   Graydon C, 2017, INT GAMBL STUD, V17, P442, DOI 10.1080/14459795.2017.1355404
   Griffiths M., 1993, Journal of Gambling Studies, V9, P101, DOI [10.1007/BF01014863, DOI 10.1007/BF01014863]
   Griffiths M., 2017, Casino Gaming International, P51
   Griffiths M.D., 2006, CURRENT ISSUES RELAT, P27
   Griffiths MD, 2005, J GAMBLING ISSUES, P13, DOI DOI 10.4309/JGI.2005.13.8
   Gupta Rina, 1998, J Gambl Stud, V14, P319, DOI 10.1023/A:1023068925328
   Heidrich D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P793, DOI [10.1109/vr.2019.8798021, 10.1109/VR.2019.8798021]
   Hoebel J, 2015, BUNDESGESUNDHEITSBLA, V58, P749, DOI 10.1007/s00103-015-2166-x
   HTC Corporation, 2011, HTC VIVE
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Jacobs D., 1986, Journal of Gambling Studies, V2, P15, DOI [DOI 10.1007/BF01019931, 10.1007/BF01019931]
   Johansson A, 2009, J GAMBL STUD, V25, P67, DOI 10.1007/s10899-008-9088-6
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kranes D, 1995, J Gambl Stud, V11, P91, DOI 10.1007/BF02283207
   Kuley NB., 1988, J GAMBLING BEHAV, V4, P197, DOI DOI 10.1007/BF01018332
   Ladouceur R., 1987, J GAMBLING BEHAV, V3, P115, DOI [DOI 10.1007/BF01043450, 10.1007/bf01043450]
   LANGER EJ, 1975, J PERS SOC PSYCHOL, V32, P311, DOI 10.1037/0022-3514.32.2.311
   Lapuz J., 2010, Gambling Research, V22, P34
   Latoschik M. E., 2016, P ACM S VIRT REAL SO
   Latoschik ME, 2022, Arxiv, DOI arXiv:2104.04846
   Lavoie RV, 2019, J GAMBL ISSUES, P53, DOI 10.4309/jgi.2019.41.4
   Lugrin J.-L., 2015, ICAT EGVE 2015 INT C, P1, DOI DOI 10.2312/EGVE.20151303
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Meyer G., 2005, SPIELSUCHT URSACHEN
   Meyer G, 2011, INT GAMBL STUD, V11, P221, DOI 10.1080/14459795.2011.584890
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Murch WS, 2021, CURR ADDICT REP, V8, P214, DOI 10.1007/s40429-021-00371-x
   Nacke Lennart., 2009, Affective ludology: Scientific measurement of user experience in interactive entertainment
   NetEnt A. B., 2011, GONZ QUEST
   NetEnt A. B., 2018, GONZ QUEST VR
   Oberdörfer S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.679277
   Oberdorfer S., 2018, P 10 INT C VIRT WORL, DOI [10.1109/VS-Games.2018.8493425, DOI 10.1109/VS-GAMES.2018.8493425]
   Oberdorfer S., 2018, P 6 S SPAT US INT OC, P89, DOI [10.1145/3267782.3267787, DOI 10.1145/3267782.3267787]
   Oberdorfer S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P483, DOI [10.1109/VR46266.2020.00-35, 10.1109/VR46266.2020.1581410387205]
   Park CB, 2015, ADDICT BEHAV, V41, P61, DOI 10.1016/j.addbeh.2014.09.027
   Park CB, 2014, CYBERPSYCH BEH SOC N, V17, P262, DOI 10.1089/cyber.2013.0253
   Partington S, 2009, SPORT PSYCHOL, V23, P170, DOI 10.1123/tsp.23.2.170
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Raylu N, 2004, PSYCHOL ADDICT BEHAV, V18, P100, DOI 10.1037/0893-164X.18.2.100
   Raylu N, 2004, ADDICTION, V99, P757, DOI 10.1111/j.1360-0443.2004.00753.x
   Reinhard R, 2020, MEDIA PSYCHOL, V23, P293, DOI 10.1080/15213269.2019.1598435
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   RootMotion, 2014, FIN IK PLUG
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Schull ND, 2005, ANN AM ACAD POLIT SS, V597, P65, DOI 10.1177/0002716204270435
   Sharman S, 2015, INT GAMBL STUD, V15, P212, DOI 10.1080/14459795.2015.1020959
   Sharpe L, 2002, CLIN PSYCHOL REV, V22, P1, DOI 10.1016/S0272-7358(00)00087-8
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M., 2010, ACM T GRAPHIC, V29, DOI [DOI 10.1145/1833351.1778829, DOI 10.1145/1833349.1778829]
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   SlotsMillion.com, 2014, SLOTSMILLION VR
   Steenbergh TA, 2002, PSYCHOL ADDICT BEHAV, V16, P143, DOI 10.1037//0893-164X.16.2.143
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Stewart MJ, 2013, PSYCHOL ADDICT BEHAV, V27, P268, DOI 10.1037/a0029882
   TAYLOR SE, 1988, PSYCHOL BULL, V103, P193, DOI 10.1037/0033-2909.103.2.193
   Thompson SC, 1999, CURR DIR PSYCHOL SCI, V8, P187, DOI 10.1111/1467-8721.00044
   TURNER N, 2004, J GAMBLING ISSUES
   Unity, 2021, UN 2020
   Valve Coorperation, 2015, STEAMVR PLUG
   van den Biggelaar R., 2016, AQUARIUM
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wanner B, 2006, J GAMBL STUD, V22, P289, DOI 10.1007/s10899-006-9017-5
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   World Health Organization, 2018, ICD 11 MORT MORB STA
   World Health Organization-WHO, 1993, The ICD-10 Classification of Mental and Behavioural Disorders: Diagnostic Criteria for Research, DOI DOI 10.5664/JCSM.8986
   Xuan ZM, 2009, J GAMBL STUD, V25, P239, DOI 10.1007/s10899-009-9118-z
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Young MM, 2009, PSYCHOL ADDICT BEHAV, V23, P512, DOI 10.1037/a0015043
NR 111
TC 1
Z9 1
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD FEB 10
PY 2022
VL 3
AR 828553
DI 10.3389/frvir.2022.828553
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K9AP1
UT WOS:001019293900001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Bueckle, A
   Buehling, K
   Shih, PC
   Börner, K
AF Bueckle, Andreas
   Buehling, Kilian
   Shih, Patrick C. C.
   Borner, Katy
TI Optimizing Performance and Satisfaction in Matching and Movement Tasks
   in Virtual Reality with Interventions Using the Data Visualization
   Literacy Framework
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; data visualization; user study; human-computer
   interaction; performance improvement; interaction technique; navigation;
   information visualization
ID VISUAL LITERACY; TAXONOMY
AB Virtual reality (VR) has seen increased use for training and instruction. Designers can enable VR users to gain insights into their own performance by visualizing telemetry data from their actions in VR. Our ability to detect patterns and trends visually suggests the use of data visualization as a tool for users to identify strategies for improved performance. Typical tasks in VR training scenarios are manipulation of 3D objects (e.g., for learning how to maintain a jet engine) and navigation (e.g., to learn the geography of a building or landscape before traveling on-site). In this paper, we present the results of the RUI VR (84 subjects) and Luddy VR studies (68 subjects), where participants were divided into experiment and control cohorts. All subjects performed a series of tasks: 44 cube-matching tasks in RUI VR, and 48 navigation tasks through a virtual building in Luddy VR (all divided into two sets). All Luddy VR subjects used VR gear. RUI VR subjects were divided across three setups: 2D Desktop (with laptop and mouse), VR Tabletop (in VR, sitting at a table), and VR Standup (in VR, standing). In an intervention called "Reflective phase," the experiment cohorts were presented with data visualizations, designed with the Data Visualization Literacy Framework (DVL-FW), of the data they generated during the first set of tasks before continuing to the second part of the study. For Luddy VR, we found that experiment users had significantly faster completion times in their second trial (p = 0.014) while scoring higher in a mid-questionnaire about the virtual building (p = 0.009). For RUI VR, we found no significant differences for completion time and accuracy between the two cohorts in the VR setups. however, 2D Desktop subjects in the experiment cohort had significantly higher rotation accuracy as well as satisfaction (p(rotation) = 0.031, p(satisfaction) = 0.040). We conclude with suggestions for adjustments to the Reflective phase to boost user performance before generalizing our findings to performance improvement in VR with data visualizations.
C1 [Bueckle, Andreas; Borner, Katy] Indiana Univ, Luddy Sch Informat Comp & Engn, Dept Intelligent Syst Engn, Bloomington, IN 47405 USA.
   [Buehling, Kilian] Tech Univ, Fak Wirtschaftswissensch, Res Grp Knowledge & Technol Transfer, Dresden, Germany.
   [Shih, Patrick C. C.] Indiana Univ, Luddy Sch Informat Comp & Engn, Dept Informat, Bloomington, IN USA.
C3 Indiana University System; Indiana University Bloomington; Technische
   Universitat Dresden; Indiana University System; Indiana University
   Bloomington
RP Bueckle, A (corresponding author), Indiana Univ, Luddy Sch Informat Comp & Engn, Dept Intelligent Syst Engn, Bloomington, IN 47405 USA.
EM abueckle@iu.edu
RI Shih, Patrick C./AAG-9674-2019; BESCHI, SARA/JXH-4238-2024
OI Shih, Patrick C./0000-0003-2460-0468; Bueckle,
   Andreas/0000-0002-8977-498X; Buehling, Kilian/0000-0002-5244-7547
FU National Institutes of Health (NIH) [OT2OD026671]; National Institute of
   Diabetes and Digestive and Kidney Diseases (NIDDK) Kidney Precision
   Medicine Project [U2CDK114886]; Common Fund Data Ecosystem (CFDE) [OT2
   OD030545]; Federal funds from the National Institute of Allergy and
   Infectious Diseases (NIAID), National Institutes of Health, Department
   of Health and Human Services under BCBB Support Services
   [HHSN316201300006W/HHSN27200002]; Stifterverband fuer die Deutsche
   Wissenschaft
FX This research was partially funded by the National Institutes of Health
   (NIH) under grant OT2OD026671, the National Institute of Diabetes and
   Digestive and Kidney Diseases (NIDDK) Kidney Precision Medicine Project
   grant U2CDK114886, and the Common Fund Data Ecosystem (CFDE) OT2
   OD030545. This project has also been funded in part with Federal funds
   from the National Institute of Allergy and Infectious Diseases (NIAID),
   National Institutes of Health, Department of Health and Human Services
   under BCBB Support Services Contract HHSN316201300006W/HHSN27200002 to
   MSC, Inc. (for an acknowledged contributor who is not an author on this
   publication). The Stifterverband fuer die Deutsche Wissenschaft provided
   funding for Kilian Buehling's research visit at Indiana University,
   Bloomington, via its INNcentive grant, which we gratefully acknowledge.
   The views and conclusions contained in this document are those of the
   authors and should not be interpreted as representing the official
   policies, either expressed or implied, of the NIH.
CR Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   Anderson A, 1999, J MOL GRAPH MODEL, V17, P180, DOI 10.1016/S1093-3263(99)00029-7
   [Anonymous], 2013, PISA 2015 DRAFT MATH
   AUSBURN LJ, 1978, PROGRAM LEARN EDUC T, V15, P291, DOI 10.1080/0033039780150405
   Avgerinou M.D., 2007, Journal of Visual Literacy, V27, P29, DOI DOI 10.1080/23796529.2007.11674644
   Bach B, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P529, DOI 10.1145/2992154.2996365
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Borner K, 2015, ATLAS OF KNOWLEDGE: ANYONE CAN MAP, P1
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Borner Katy., 2014, VISUAL INSIGHTS PRAC
   Bowman D. A., 2003, P ACM S VIRT REAL SO, DOI DOI 10.1145/1008653.1008669
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Bryson S, 1996, COMMUN ACM, V39, P62, DOI 10.1145/229459.229467
   Bueckle A., 2021, PREPRINT
   Bueckle A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258103
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/ICSENS.2015.7370446, 10.1109/GLOCOM.2015.7417476]
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Cyberinfrastructure for Network Science Center, 2021, EXPL US INT
   DataCamp, 2021, COEFT INF EST COEFF
   DataCamp, 2021, LM FITT LIN MOD
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Few Stephen, 2012, SHOW ME NUMBERS DESI, Vsecond
   Fransecky RB., 1972, VISUAL LITERACY WAY
   Djorgovski SG, 2013, Arxiv, DOI arXiv:1301.6808
   Garcia-Hernandez R.J., 2016, 2016 IEEE Aerospace Conference, IEEE, P1, DOI DOI 10.1109/AERO.2016.7500608
   Hattwig D, 2013, PORTAL-LIBR ACAD, V13, P61, DOI 10.1353/pla.2013.0008
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Heer J, 2010, COMMUN ACM, V53, P59, DOI 10.1145/1743546.1743567
   Hothorn T., 2021, LMTEST TESTING LINEA
   Huang B, 2001, INT J GEOGR INF SCI, V15, P439, DOI 10.1080/13658810110046574
   Ibrahim Z, 2019, J BIOMED INFORM, V90, DOI 10.1016/j.jbi.2019.103102
   Jacob RobertJ.K., 2008, Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems-CHI '08, P201, DOI DOI 10.1145/1357054.1357089
   Kaiser PK, 2005, RASIM6: CONTROLLING SEISMIC RISK, P33
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Marriott K., 2018, IMMERSIVE ANAL
   McKinlay J, 2010, CHANDOS INF PROF SER, P1, DOI 10.1533/9781780630243
   Mendes D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139157
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Munzner T, 2014, VISUALIZATION ANAL D, DOI DOI 10.1201/B17511
   OECD, 2013, Pisa 2015 Draft Reading Literacy Framework March 2013
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Raja D., 2004, PROC IMMERSIVE PROJE, P61
   Reyna VF, 2009, PSYCHOL BULL, V135, P943, DOI 10.1037/a0017327
   Rosenbaum Rene, 2011, Advances in Visual Computing, P530, DOI DOI 10.1007/978-3-642-24028-7_49
   Roth RE, 2013, IEEE T VIS COMPUT GR, V19, P2356, DOI 10.1109/TVCG.2013.130
   Simpson M, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P99, DOI 10.1145/3009939.3009955
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Smets G., 1993, INTERACT 93 CHI 93 C, P11, DOI [DOI 10.1145/259964.259975, 10.1145/259964, DOI 10.1145/259964]
   Snyder MP, 2019, NATURE, V574, P187, DOI 10.1038/s41586-019-1629-x
   TechSmith, 2020, CAMT 2020
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Valve Corporation, 2021, SteamVR
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
NR 66
TC 1
Z9 2
U1 5
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 21
PY 2022
VL 2
AR 727344
DI 10.3389/frvir.2021.727344
PG 22
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2SV1
UT WOS:001021817400001
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Rogers, SL
   Broadbent, R
   Brown, J
   Fraser, A
   Speelman, CP
AF Rogers, Shane L.
   Broadbent, Rebecca
   Brown, Jemma
   Fraser, Alan
   Speelman, Craig P.
TI Realistic Motion Avatars are the Future for Social Interaction in
   Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; avatar; motion capture (Mocap); face-to-face (dyadic)
   communication; computer mediated communication (CMC); eye contact;
   self-disclosure; social interaction
ID FACE-TO-FACE; EYE CONTACT; COMMUNICATION; ONLINE; TECHNOLOGY; EVOLUTION;
   RICHNESS; LIKING; TEXT
AB This study evaluated participant self-reported appraisal of social interactions with another person in virtual reality (VR) where their conversational partner was represented by a realistic motion avatar. We use the term realistic motion avatar because: 1. The avatar was modelled to look like the conversational partner it represented, and 2. Full face and body motion capture was utilised so that the avatar mimicked the facial and body language of the conversational partner in real-time. We compared social interaction in VR with face-to-face interaction across two communicative contexts: 1. Getting acquainted conversation, and 2. A structured interview where the participant engaged in self-disclosure about positive and negative experiences. Overall, participants largely indicated they preferred face-to-face over VR communication. However, some participants did indicate a preference for VR communication. Additionally, an analysis of post-conversation ratings indicated no significant difference for rated enjoyment, understanding, self-disclosure, comfort, and awkwardness between communication modes. The only ratings where face-to-face was found to be superior was for perceived closeness across both types of communication, and for feeling understood specifically when disclosing negative experiences. Most participants perceived frequent eye contact in both face-to-face and VR interaction, but typically more eye contact when face-to-face. Eye contact was positively associated with rated enjoyment, closeness, and comfort. Overall, our findings suggest that harnessing full face and body motion capture can make social interaction in VR very similar to face-to-face interaction. We anticipate that VR social interaction is poised to become the next major technological evolution for human computer mediated communication and suggest avenues for further research.
C1 [Rogers, Shane L.; Broadbent, Rebecca; Brown, Jemma; Fraser, Alan; Speelman, Craig P.] Edith Cowan Univ, Cognit Res Grp, Perth, WA, Australia.
C3 Edith Cowan University
RP Rogers, SL (corresponding author), Edith Cowan Univ, Cognit Res Grp, Perth, WA, Australia.
EM shane.rogers@ecu.edu.au
FU Edith Cowan University Early Career Researcher Grant [G1004675]
FX Funding This research made possible by an Edith Cowan University Early
   Career Researcher Grant awarded to SLR (Ref: G1004675) "Assessing the
   utility of real-time virtual character puppetry for conducting
   interviews".
CR Akechi H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059312
   Attardo S, 2003, HUMOR, V16, P243, DOI 10.1515/humr.2003.012
   Baccon LA, 2019, CYBERPSYCH BEH SOC N, V22, P158, DOI 10.1089/cyber.2018.0247
   Bailenson J. N., 2021, Technology, Mind, and Behavior, DOI [DOI 10.1037/TMB0000030, 10.1037/tmb0000030]
   Baltes BB, 2002, ORGAN BEHAV HUM DEC, V87, P156, DOI 10.1006/obhd.2001.2961
   BaronCohen S, 1997, J CHILD PSYCHOL PSYC, V38, P813, DOI 10.1111/j.1469-7610.1997.tb01599.x
   Center P. R., 2015, PEW
   Cui DX, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2009
   de Siqueira A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647801
   Falconer CJ, 2019, CHILD ADOL MENT H-UK, V24, P283, DOI 10.1111/camh.12326
   Fernandez V, 2013, COMPUT EDUC, V62, P32, DOI 10.1016/j.compedu.2012.10.020
   Ferstl Y, 2021, PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA), P76, DOI 10.1145/3472306.3478338
   Field A., 2013, DISCOVERING STAT USI
   Freeman G., 2020, 2020 CHI C HUM FACT, DOI 10.1145/3334480.3382923
   Gentina E, 2019, INFORM MANAGE-AMSTER, V56, DOI 10.1016/j.im.2018.12.006
   Geraets CNW, 2021, CURR OPIN PSYCHOL, V41, P40, DOI 10.1016/j.copsyc.2021.02.004
   Gunkel S, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P233, DOI 10.1145/3210825.3213566
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Higgins D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.668499
   Ho S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136905
   Hu-Au E., 2017, INT J INNOVATION ED, V4, P215, DOI [DOI 10.1504/IJIIE.2017.10012691, 10.1504/ijiie.2017, DOI 10.1504/IJIIE.2017, https://doi.org/10.1504/IJIIE.2017.10012691]
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Jarick M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01262
   Karaaslan A, 2020, VIS COGN, V28, P605, DOI 10.1080/13506285.2020.1846649
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   Khojasteh N., 2021, FRONT VIRTUAL REAL, V2, DOI DOI 10.3389/FRVIR.2021.643331
   KLEINKE CL, 1986, PSYCHOL BULL, V100, P78, DOI 10.1037/0033-2909.100.1.78
   Kock N, 2005, IEEE T PROF COMMUN, V48, P117, DOI 10.1109/TPC.2005.849649
   Kong Saoane Thach, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P303, DOI 10.1145/3441000.3441003
   Kroczek LOH, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00561
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Lenhart Amanda., 2015, Teens, Technology and Friendships
   Liang H, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1727
   Liddle J, 2021, CLIN GERONTOLOGIST, V44, P406, DOI 10.1080/07317115.2020.1852638
   Maloney D., 2020, PROC ACM HUM COMPUT, V4, P1, DOI DOI 10.1145/3415246
   Meeren HKM, 2005, P NATL ACAD SCI USA, V102, P16518, DOI 10.1073/pnas.0507650102
   Meier JV, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.666655
   Mura P, 2017, INF TECHNOL TOUR, V17, P145, DOI 10.1007/s40558-016-0059-y
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Pedram S, 2020, COMPUT HUM BEHAV, V105, DOI 10.1016/j.chb.2019.106223
   Pettersson E, 2017, MIG'17: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON MOTION IN GAMES, DOI 10.1145/3136457.3136461
   Pfund GN, 2021, PERS INDIV DIFFER, V171, DOI 10.1016/j.paid.2020.110537
   Pimentel D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627059
   Rehm IC, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00186
   Rogers SL, 2021, PEERJ, V9, DOI 10.7717/peerj.11767
   Rogers SL, 2019, PERCEPTION, V48, P248, DOI 10.1177/0301006619827486
   Rogers SL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22726-7
   Sampaio M, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.576421
   Senju A, 2009, TRENDS COGN SCI, V13, P127, DOI 10.1016/j.tics.2008.11.009
   Seymour M, 2021, J ASSOC INF SYST, V22, P591, DOI 10.17705/1jais.00674
   Seymour M, 2018, J ASSOC INF SYST, V19, P953, DOI 10.17705/1jais.00515
   Shalom JG, 2015, COMPUT HUM BEHAV, V44, P202, DOI 10.1016/j.chb.2014.11.056
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Sprecher S, 2021, J SOC PERS RELAT, V38, P1452, DOI 10.1177/0265407521996055
   Sprecher S, 2017, COMMUN Q, V65, P333, DOI 10.1080/01463373.2016.1256334
   Sprecher S, 2016, COMPUT HUM BEHAV, V62, P423, DOI 10.1016/j.chb.2016.03.090
   Sprecher S, 2014, COMPUT HUM BEHAV, V31, P190, DOI 10.1016/j.chb.2013.10.029
   Suler JR, 2000, CYBERPSYCHOL BEHAV, V3, P151, DOI 10.1089/109493100315996
   Syrjämäki AH, 2020, COMPUT HUM BEHAV, V112, DOI 10.1016/j.chb.2020.106454
   Vesper C, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00168
   Vlahovic TA, 2012, J COMPUT-MEDIAT COMM, V17, P436, DOI 10.1111/j.1083-6101.2012.01584.x
   Wu YJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.641296
   Wu YJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364267
   Zibrek Katja, 2021, MIG '21: Motion, Interaction and Games, DOI 10.1145/3487983.3488296
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
NR 67
TC 14
Z9 14
U1 13
U2 16
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JAN 3
PY 2022
VL 2
AR 750729
DI 10.3389/frvir.2021.750729
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8VP3
UT WOS:001019162600001
OA gold, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Wienrich, C
   Komma, P
   Vogt, S
   Latoschik, ME
AF Wienrich, Carolin
   Komma, Philipp
   Vogt, Stephanie
   Latoschik, Marc E.
TI Spatial Presence in Mixed Realities-Considerations About the Concept,
   Measures, Design, and Experiments
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE mixed reality; virtual-reality-continuum; spatial presence;
   place-illusion; plausibility-illusion; transportation; realism
ID VIRTUAL ENVIRONMENTS; BEHAVIOR
AB Plenty of theories, models, measures, and investigations target the understanding of virtual presence, i.e., the sense of presence in immersive Virtual Reality (VR). Other varieties of the so-called eXtended Realities (XR), e.g., Augmented and Mixed Reality (AR and MR) incorporate immersive features to a lesser degree and continuously combine spatial cues from the real physical space and the simulated virtual space. This blurred separation questions the applicability of the accumulated knowledge about the similarities of virtual presence and presence occurring in other varieties of XR, and corresponding outcomes. The present work bridges this gap by analyzing the construct of presence in mixed realities (MR). To achieve this, the following presents (1) a short review of definitions, dimensions, and measurements of presence in VR, and (2) the state of the art views on MR. Additionally, we (3) derived a working definition of MR, extending the Milgram continuum. This definition is based on entities reaching from real to virtual manifestations at one time point. Entities possess different degrees of referential power, determining the selection of the frame of reference. Furthermore, we (4) identified three research desiderata, including research questions about the frame of reference, the corresponding dimension of transportation, and the dimension of realism in MR. Mainly the relationship between the main aspects of virtual presence of immersive VR, i.e., the place-illusion, and the plausibility-illusion, and of the referential power of MR entities are discussed regarding the concept, measures, and design of presence in MR. Finally, (5) we suggested an experimental setup to reveal the research heuristic behind experiments investigating presence in MR. The present work contributes to the theories and the meaning of and approaches to simulate and measure presence in MR. We hypothesize that research about essential underlying factors determining user experience (UX) in MR simulations and experiences is still in its infancy and hopes this article provides an encouraging starting point to tackle related questions.
C1 [Wienrich, Carolin; Komma, Philipp; Vogt, Stephanie] Julius Maximilian Univ Wurzburg, Human Technol Syst, Wurzburg, Germany.
   [Latoschik, Marc E.] Julius Maximilian Univ Wurzburg, Human Comp Interact, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Wienrich, C (corresponding author), Julius Maximilian Univ Wurzburg, Human Technol Syst, Wurzburg, Germany.
EM carolin.wienrich@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600
FU University of Wuerzburg
FX This publication was supported by the Open-Access Publication Fund of
   the University of Wuerzburg.
CR Alexander A.L., 2005, DARWARS Training Impact Group, V5, P1, DOI [DOI 10.1016/J.ATHORACSUR.2004.02.012, DOI 10.5171/2012.800962]
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Biocca, 2003, EU PRES RES C VEN IT, V12, P13, DOI DOI 10.1162/105474603322761270
   Brown S, 2003, LECT NOTES COMPUT SC, V2897, P102
   Ditton T., 1997, J COMPUTER MEDIATED, V3, pJCMC321, DOI [10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X]
   Druckman D., 1994, LEARNING REMEMBERING
   GIBSON JAMES J., 1966
   Hartson R., 2012, The UX Book: Process and Guidelines for Ensuring a Quality User Experience
   Hassenzahl M, 2010, INTERACT COMPUT, V22, P353, DOI 10.1016/j.intcom.2010.04.002
   Hillstead A., 2017, SIMULATING PSYCHEDEL
   Insko B., 2003, Measuring Presence: Subjective, Behavioral and Physiological Methods
   Latoschik M. E., 2021, ARXIV
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lee S., 2004, P 7 INT WORKSH PRES, P20
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   Maguire K. C., 2006, 9 INT WORKSH PRES
   Mann S., 1994, MEDIATED REALITY
   Mann S., 2002, MEDIATED REALITY IMP, P1
   Microsoft, 2020, WAS ITS MIXED REALIT
   Milgram P, 1999, MIXED REALITY, P5
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Minsky Marvin, 1980, OMNI Magazine, P1
   Nunez D., 2001, Proceedings AFRIGRAPH 2001. 1st International Conference on Computer Graphics, Virtual Reality and Visualisation, P115, DOI 10.1145/513867.513892
   Nunez D., 2007, A capacity limited cognitive constructionist model of virtual presence
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert T., 2016, Igroup Presence Questionnaire (IPQ)
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Skarbez R, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281530
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   SLATER M, 1993, COMPUT GRAPH, V17, P643, DOI 10.1016/0097-8493(93)90113-N
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Michael., 1999, INTELLIGENT PERSONS
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Van Schaik P, 2004, CYBERPSYCHOL BEHAV, V7, P540, DOI 10.1089/1094931042403145
   Varjo, 2019, UNM XR 1 FOOT
   Wagner I, 2009, PRESENCE-VIRTUAL AUG, V18, P249, DOI 10.1162/pres.18.4.249
   Wienrich Carolin, 2020, i-com: Journal of Interactive Media, V19, P103, DOI 10.1515/icom-2020-0008
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 50
TC 6
Z9 6
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 25
PY 2021
VL 2
AR 694315
DI 10.3389/frvir.2021.694315
PG 14
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2PP7
UT WOS:001021733200001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Heilemann, F
   Zimmermann, G
   Münster, P
AF Heilemann, Fiona
   Zimmermann, Gottfried
   Muenster, Patrick
TI Accessibility Guidelines for VR Games-A Comparison and Synthesis of a
   Comprehensive Set
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Review
DE guidelines; accessibility; VR; comparison; VR games
AB Increasing numbers of gamers worldwide have led to more attention being paid to accessibility in games. Virtual Reality offers new possibilities to enable people to play games but also comes with new challenges for accessibility. Guidelines provide help for developers to avoid barriers and include persons with disabilities in their games. As of today, there are only a few extensive collections of accessibility rules on video games. Especially new technologies like virtual reality are sparsely represented in current guidelines. In this work, we provide an overview of existing guidelines for games and VR applications. We examine the most relevant resources, and form a union set. From this, we derive a comprehensive set of guidelines. This set summarizes the rules that are relevant for accessible VR games. We discuss the state of guidelines and their implication on the development of educational games, and provide suggestions on how to improve the situation.
C1 [Heilemann, Fiona; Zimmermann, Gottfried; Muenster, Patrick] Stuttgart Media Univ, Respons Media Experience Res Grp, Stuttgart, Germany.
C3 University of Stuttgart
RP Heilemann, F (corresponding author), Stuttgart Media Univ, Respons Media Experience Res Grp, Stuttgart, Germany.
EM fiona.heilemann@web.de
CR AbleGamers, 2018, ACC PLAYER EXP APX
   AbleGamers, 2018, ABL CHAR
   Aguado-Delgado J., 2018, THESIS U ALCALA MADR
   [Anonymous], 2011, LANCET, V377, P1977, DOI 10.1016/S0140-6736(11)60844-1
   [Anonymous], 2004, GUID DEV ENT SOFTW P
   Bankhurst A., 2020, 3000000000 PEOPLE WO
   Barlet M C., 2012, Includification: A practical guide to game accessibility
   Beeston J, 2018, LECT NOTES COMPUT SC, V10896, P245, DOI 10.1007/978-3-319-94277-3_40
   Bertiz A, 2019, 5 VR GAMES CONSIDERA
   Bierre K., 2004, ACCESSIBILITY GAMES
   Cairns P., 2019, ENABLED PLAYERS VALU
   Cairns P, 2019, INT J HUM-COMPUT ST, V131, P64, DOI 10.1016/j.ijhcs.2019.06.010
   Chang HW, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P279, DOI 10.1145/3126594.3126617
   Ellis B., 2020, GAME ACCESSIBILITY G
   Essential Accessibility, 2019, 301549 EN ESS ACC
   European Telecommunications Standards Institute, 2019, 301549V311 ETSI EN
   Grammenos D., 2009, ACM COMPUTERS ENTERT, V7, P1, DOI [10.1145/1486508.1486516, DOI 10.1145/1486508.1486516]
   Hamilton Ian, 2018, Computer Games Journal, V7, P63, DOI 10.1007/s40869-018-0061-z
   Harada S, 2011, LECT NOTES COMPUT SC, V6946, P11, DOI 10.1007/978-3-642-23774-4_4
   IGDA GASIG, 2015, SIG TOP 10 IGDA GAM
   IGDA GASIG, 2020, IGDA GAM ACC SIG
   Kirkpatrick A., 2018, WEB CONTENT ACCESSIB
   Microsoft, 2019, XBOX ACC
   Miesenberger K, 2008, LECT NOTES COMPUT SC, V5298, P247, DOI 10.1007/978-3-540-89350-9_18
   Mott M, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P451, DOI 10.1109/ISMAR-Adjunct.2019.00122
   Normand A., 2019, ACCESSIBILITY VIRTUA
   Oculus, 2020, QUEST VIRT REAL CHEC
   PlayStation, 2020, LAST US 2
   Sears A., 2003, When computers fade ... Pervasive computing and situationally-induced impairments and disabilities
   Special Effect, 2021, HELP PEOPL DIS ENJ V
   T4, 2021, VR HEADS MARK SHAR
   W3C, 2020, XR ACC US REQ
   WalkinVR, 2020, WALKINVR VIRT REAL P
   Westin T, 2018, LECT NOTES COMPUT SC, V10896, P270, DOI 10.1007/978-3-319-94277-3_43
   XR Access, 2020, HOM XR ACC IN
   Yuan B, 2011, UNIVERSAL ACCESS INF, V10, P81, DOI 10.1007/s10209-010-0189-5
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
NR 37
TC 4
Z9 5
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 20
PY 2021
VL 2
AR 697504
DI 10.3389/frvir.2021.697504
PG 9
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2ST4
UT WOS:001021815700001
OA gold
DA 2024-07-18
ER

PT J
AU Amemiya, T
   Aoyama, K
   Hirose, M
AF Amemiya, Tomohiro
   Aoyama, Kazuma
   Hirose, Michitaka
TI TeleParallax: Low-Motion-Blur Stereoscopic System With Correct
   Interpupillary Distance for 3D Head Rotations
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE telepresence; binocular; omnidireciontal camera; interpupillary distance
   (IPD); motion blur
ID DEPTH MODULES; VISION; STEREOPSIS; TELEPRESENCE; INTEGRATION
AB Binocular parallax provides cues for depth information when a scene is viewed with both eyes. In visual telepresence systems, stereo cameras are commonly used to simulate human eyes. However, motion blur occurs when these cameras are rotated quickly. The use of omnidirectional cameras can reduce the motion blur, but does not provide the correct interpupillary distance (IPD) when viewers tilt or turn their heads sideways. We propose a method called TeleParallax, in which two omnidirectional cameras are separated by the IPD and the direction of the lenses are kept constant in world coordinates by robotic arms during three-dimensional head rotations. TeleParallax can suppress the increase in image buffering during head rotations because each camera can capture an omnidirectional image with the lens direction fixed. We conducted three user studies to evaluate the perceptual effect of head tilt, eye asynchrony, and delays in IPD correction for a particular rotation. The results indicate that TeleParallax can provide depth perception that is independent of the head movement with less visual discomfort. Although the results show that the users were sensitive to the asynchrony between their eyes and to camera motion during IPDs, they retained the feeling of depth perception within interocular delays of 70 ms and motion velocity of 75 & DEG;/s. These results imply that TeleParallax has remarkable potential for visual telepresence systems.
C1 [Amemiya, Tomohiro; Aoyama, Kazuma] Univ Tokyo, Virtual Real Educ Res Ctr, Tokyo, Japan.
   [Amemiya, Tomohiro] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
   [Aoyama, Kazuma; Hirose, Michitaka] Univ Tokyo, Res Ctr Adv Sci & Technol, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo; University of Tokyo
RP Amemiya, T (corresponding author), Univ Tokyo, Virtual Real Educ Res Ctr, Tokyo, Japan.; Amemiya, T (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
EM amemiya@vr.u-tokyo.ac.jp
OI Amemiya, Tomohiro/0000-0002-7079-9167
CR Aggarwal R, 2016, PROC CVPR IEEE, P3755, DOI 10.1109/CVPR.2016.408
   Amemiya T., 2021, STEREOSCOPIC SYSTEM, P26
   Anderson R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980257
   ANDREDESHAYS C, 1991, EXP BRAIN RES, V84, P359
   Aykut T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P201, DOI 10.1145/3126686.3126751
   Baier H, 2003, ADV ROBOTICS, V17, P219, DOI 10.1163/156855303764018477
   Bordas JC, 1996, P SOC PHOTO-OPT INS, V2653, P106, DOI 10.1117/12.237423
   BULTHOFF HH, 1988, J OPT SOC AM A, V5, P1749, DOI 10.1364/JOSAA.5.001749
   Cai TT, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172426
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   Darmohray D, 2009, PERCEPTION, V38, P1867, DOI 10.1068/p6572
   Dodgson NA, 2004, PROC SPIE, V5291, P36, DOI 10.1117/12.529999
   Fang Y, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121035
   Farajiparvar P, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.578805
   Freedman EG, 2008, EXP BRAIN RES, V190, P369, DOI 10.1007/s00221-008-1504-8
   Heesy CP, 2008, BRAIN BEHAV EVOLUT, V71, P54, DOI 10.1159/000108621
   Higuchi Keita., 2013, Proc. CHI'13 extended abstracts, P2029
   Ikei Y, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P431, DOI 10.1109/VR.2019.8797876
   JOHNSTON EB, 1993, VISION RES, V33, P813, DOI 10.1016/0042-6989(93)90200-G
   Kane D, 2012, PROC SPIE, V8288, DOI 10.1117/12.912204
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Lam Dawn Y S, 2008, Binocul Vis Strabismus Q, V23, P95
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lanir J., 2013, Proceedings of the ACM SIGCHI Annual Conference on Human Factors in Computing Systems (CHI), P2243
   Madder RD, 2020, CATHETER CARDIO INTE, V95, P914, DOI 10.1002/ccd.28425
   Matzen K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073645
   Nityananda V, 2017, J EXP BIOL, V220, P2502, DOI 10.1242/jeb.143883
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Svedman M., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3069
   Tashiro K., 2017, ACM SIGGRAPH 2017 EM, DOI DOI 10.1145/3084822.3084831
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   vanEe R, 1996, VISION RES, V36, P3827, DOI 10.1016/0042-6989(96)00103-4
   Vienne C, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516681308
   Vishwanath D, 2014, PSYCHOL REV, V121, P151, DOI 10.1037/a0035233
   Votanopoulos K, 2008, WORLD J SURG, V32, P110, DOI 10.1007/s00268-007-9253-6
   Watanabe K, 2008, ADV ROBOTICS, V22, P1053, DOI 10.1163/156855308X324767
   Wen MC, 2018, AUTOMAT CONSTR, V89, P199, DOI 10.1016/j.autcon.2018.01.008
   Yanagida Y., 2001, P ICAT 2001, P42
   Yem V, 2019, SIGGRAPH ASIA 2019 EMERGING TECHNOLOGIES, P53, DOI 10.1145/3355049.3360540
   Zhou CX, 2003, PROC CVPR IEEE, P351
NR 41
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD OCT 6
PY 2021
VL 2
AR 726285
DI 10.3389/frvir.2021.726285
PG 17
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WD9
UT WOS:001019177300001
OA gold
DA 2024-07-18
ER

PT J
AU Oyekoya, O
   Urbanski, J
   Shynkar, Y
   Baksh, A
   Etsaghara, M
AF Oyekoya, Oyewole
   Urbanski, Jan
   Shynkar, Yaroslava
   Baksh, Arifa
   Etsaghara, Margaret
TI Exploring First-Person Perspectives in Designing a Role-Playing VR
   Simulation for Bullying Prevention: A Focus Group Study
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE bullying; virtual reality; perspectives; focus group; simulation design
ID SCHOOL; VICTIMIZATION; INTERVENTION; PERCEPTIONS; BEHAVIOR
AB Bullying is a complex and abusive form of violence that has potentially serious social and mental health consequences for children and adolescents. With reference to the Olweus Bullying Circle, this project involves the development of a simulation that will allow students to view themselves in different roles played in bullying situations using a virtual reality setting. Interventions need to explore the perspective of the student who bullies and the student being bullied, as well as the bystander in order to model desirable intervention behavior. The expectation is that through role-playing, the students will explore different perspectives and learn how to respond to bullying situations. Two focus groups were conducted to allow experts to contribute to the design of the bullying prevention simulation and gather suggestions for improvements. Findings from the focus group studies suggest that to create effective bullying prevention, Virtual Reality simulations should consider focusing on role-playing, customization of the characters, environments, scenarios and a scoring/reward system.
C1 [Oyekoya, Oyewole; Shynkar, Yaroslava; Baksh, Arifa] CUNY Hunter Coll, Dept Comp Sci, Visualizat & Virtual Real Lab, New York, NY 10065 USA.
   [Urbanski, Jan] Clemson Univ, Inst Family & Neighborhood Life, Safe Sch, Clemson, SC USA.
   [Urbanski, Jan] Clemson Univ, Inst Family & Neighborhood Life, Humane Sch, Clemson, SC USA.
C3 City University of New York (CUNY) System; Hunter College (CUNY);
   Clemson University; Clemson University
RP Oyekoya, O (corresponding author), CUNY Hunter Coll, Dept Comp Sci, Visualizat & Virtual Real Lab, New York, NY 10065 USA.
EM oyewole.oyekoya@hunter.cuny.edu
CR Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   [Anonymous], 1998, Preventing bullying: A manual for schools and communities
   Archibald MM, 2019, INT J QUAL METH, V18, DOI 10.1177/1609406919874596
   Bagès C, 2021, J RES CHILD EDUC, V35, P631, DOI 10.1080/02568543.2020.1810834
   Borgwald K, 2013, SOC INFLUENCE, V8, P149, DOI 10.1080/15534510.2012.724030
   Bowers EP, 2015, J YOUTH DEV, V10, P46
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Buhs ES, 2006, J EDUC PSYCHOL, V98, P1, DOI 10.1037/0022-0663.98.1.1
   Calvo-Morata A, 2020, COMPUT EDUC, V157, DOI 10.1016/j.compedu.2020.103958
   Carter L, 2016, PROCEEDINGS OF THE 2016 ACM SIGMIS CONFERENCE ON COMPUTERS AND PEOPLE RESEARCH (SIGMIS-CPR'16), P141, DOI 10.1145/2890602.2890626
   Cohen J., 1999, ED MINDS HEARTS SOCI
   De La Rue L, 2017, REV EDUC RES, V87, P7, DOI 10.3102/0034654316632061
   Donohoe P., 2020, International Journal of Bullying Prevention, V2, P264, DOI [10.1007/s42380-019-00036-4, DOI 10.1007/S42380-019-00036-4]
   Eklund L., 2015, FOCUS GROUP INTERVIE
   EKSTROM RB, 1986, TEACH COLL REC, V87, P356
   Elias M.J., 1997, Promoting social and emotional learning
   Forsberg C, 2014, RES PAP EDUC, V29, P557, DOI 10.1080/02671522.2013.878375
   Fradkin C, 2017, J YOUTH ADOLESCENCE, V46, P1629, DOI 10.1007/s10964-017-0658-8
   Gaffney H., 2019, International Journal of Bullying Prevention, V1, P14, DOI [10.1007/s42380-019-0007-4, DOI 10.1007/S42380-019-0007-4]
   Gini G, 2008, J ADOLESCENCE, V31, P93, DOI 10.1016/j.adolescence.2007.05.002
   Griffiths M., 2002, Education and Health, V20, P47
   Guest G, 2017, FIELD METHOD, V29, P3, DOI 10.1177/1525822X16639015
   Henson B, 2020, VIOLENCE AGAINST WOM, V26, P505, DOI 10.1177/1077801219835050
   Hu XQ, 2016, 2016 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET), P53, DOI 10.1109/ISET.2016.15
   Jones LM, 2015, J YOUTH ADOLESCENCE, V44, P2308, DOI 10.1007/s10964-015-0342-9
   Juvonen J, 2014, ANNU REV PSYCHOL, V65, P159, DOI 10.1146/annurev-psych-010213-115030
   Kalyanaraman S, 2010, J NERV MENT DIS, V198, P437, DOI 10.1097/NMD.0b013e3181e07d66
   Kolic-Vehovec S., 2019, 16 EUR C PSYCH, P1567
   Luxenberg H., 2019, Bullying in U.S. schools 2019 status report
   McEvoy KA, 2016, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2016.7504737
   Nansel TR, 2001, JAMA-J AM MED ASSOC, V285, P2094, DOI 10.1001/jama.285.16.2094
   O'Connell P, 1999, J ADOLESCENCE, V22, P437, DOI 10.1006/jado.1999.0238
   OLWEUS D, 1994, J CHILD PSYCHOL PSYC, V35, P1171, DOI 10.1111/j.1469-7610.1994.tb01229.x
   Olweus D., 2007, Olweus bullying prevention program schoolwide guide
   Olweus D., 1993, BULLYING SCH
   Padgett S., 2013, UNIVERSAL J ED RES, V1, P33, DOI DOI 10.13189/UJER.2013.010201
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Poels K., 2007, P 2007 C FUT PLAY, P83, DOI [DOI 10.1145/1328202.1328218, 10.1145/1328202.1328218]
   Polanin JR, 2012, SCHOOL PSYCHOL REV, V41, P47
   Pronk J, 2016, J EARLY ADOLESCENCE, V36, P267, DOI 10.1177/0272431614562836
   Raminhos Catia, 2015, P 13 INT C ADV MOBIL, P63, DOI [10.1145/2837126.2837135, DOI 10.1145/2837126.2837135]
   Rivara F, 2016, PREVENTING BULLYING THROUGH SCIENCE, POLICY, AND PRACTICE, P1, DOI 10.17226/23482
   Rivers I, 2009, SCHOOL PSYCHOL QUART, V24, P211, DOI 10.1037/a0018164
   Rosen LH, 2017, J SCH VIOLENCE, V16, P119, DOI 10.1080/15388220.2015.1124340
   Sapouna M, 2010, J CHILD PSYCHOL PSYC, V51, P104, DOI 10.1111/j.1469-7610.2009.02137.x
   Siris K, 2004, PHI DELTA KAPPAN, V86, P288, DOI 10.1177/003172170408600409
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Tham J, 2018, IEEE T PROF COMMUN, V61, P178, DOI 10.1109/TPC.2018.2804238
   Underwood JM, 2020, MMWR-MORBID MORTAL W, V69, P1, DOI 10.15585/mmwr.su6901a1
   Vanhoutte K. K., 2020, BULLYING ABUSE POWER
   Wang J, 2009, J ADOLESCENT HEALTH, V45, P368, DOI 10.1016/j.jadohealth.2009.03.021
   Wang K., 2020, INDICATORS SCH CRIME
   Yee N., 2006, P PRESENCE 2006 9 AN
NR 54
TC 8
Z9 8
U1 9
U2 14
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 28
PY 2021
VL 2
AR 672003
DI 10.3389/frvir.2021.672003
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WE0
UT WOS:001019177400001
OA gold
DA 2024-07-18
ER

PT J
AU Furmanek, MP
   Mangalam, M
   Lockwood, K
   Smith, A
   Yarossi, M
   Tunik, E
AF Furmanek, Mariusz P.
   Mangalam, Madhur
   Lockwood, Kyle
   Smith, Andrea
   Yarossi, Mathew
   Tunik, Eugene
TI Effects of Sensory Feedback and Collider Size on Reach-to-Grasp
   Coordination in Haptic-Free Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE visual feedback; auditory feedback; haptic feedback; collision
   detection; prehension; virtual environment; virtual reality
ID PREHENSION MOVEMENTS; MECHANICAL PERTURBATION; SELECTIVE PERTURBATION;
   NATURAL PREHENSION; VISUAL FEEDBACK; CONTACT CUES; TRANSPORT;
   PERFORMANCE; CALIBRATION; SUBSTITUTE
AB Technological advancements and increased access have prompted the adoption of head- mounted display based virtual reality (VR) for neuroscientific research, manual skill training, and neurological rehabilitation. Applications that focus on manual interaction within the virtual environment (VE), especially haptic-free VR, critically depend on virtual hand-object collision detection. Knowledge about how multisensory integration related to hand-object collisions affects perception-action dynamics and reach-to-grasp coordination is needed to enhance the immersiveness of interactive VR. Here, we explored whether and to what extent sensory substitution for haptic feedback of hand-object collision (visual, audio, or audiovisual) and collider size (size of spherical pointers representing the fingertips) influences reach-to-grasp kinematics. In Study 1, visual, auditory, or combined feedback were compared as sensory substitutes to indicate the successful grasp of a virtual object during reach-to-grasp actions. In Study 2, participants reached to grasp virtual objects using spherical colliders of different diameters to test if virtual collider size impacts reach-to-grasp. Our data indicate that collider size but not sensory feedback modality significantly affected the kinematics of grasping. Larger colliders led to a smaller size-normalized peak aperture. We discuss this finding in the context of a possible influence of spherical collider size on the perception of the virtual object's size and hence effects on motor planning of reach-to-grasp. Critically, reach-to-grasp spatiotemporal coordination patterns were robust to manipulations of sensory feedback modality and spherical collider size, suggesting that the nervous system adjusted the reach (transport) component commensurately to the changes in the grasp (aperture) component. These results have important implications for research, commercial, industrial, and clinical applications of VR.
C1 [Furmanek, Mariusz P.; Mangalam, Madhur; Lockwood, Kyle; Smith, Andrea; Yarossi, Mathew; Tunik, Eugene] Northeastern Univ, Dept Phys Therapy Movement & Rehabil Sci, Boston, MA 02115 USA.
   [Furmanek, Mariusz P.] Acad Phys Educ, Inst Sport Sci, Katowice, Poland.
   [Lockwood, Kyle; Yarossi, Mathew; Tunik, Eugene] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA USA.
   [Smith, Andrea; Tunik, Eugene] Northeastern Univ, Dept Bioengn, Boston, MA USA.
C3 Northeastern University; Northeastern University; Northeastern
   University
RP Furmanek, MP (corresponding author), Northeastern Univ, Dept Phys Therapy Movement & Rehabil Sci, Boston, MA 02115 USA.; Furmanek, MP (corresponding author), Acad Phys Educ, Inst Sport Sci, Katowice, Poland.
EM m.furmanek@northeastern.edu
FU NIH [2R01NS085122, 2R01HD058301]; NSF-CBET [1804540, 1804550]; NSF-CMMI
   [M3X-1935337]
FX & nbsp;This work was supported in part by NIH-2R01NS085122 (ET),
   NIH-2R01HD058301 (ET), NSF-CBET-1804540 (ET), NSF-CBET-1804550 (ET), and
   NSF-CMMI-M3X-1935337 (ET, MY).
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Adamovich SV, 2005, PRESENCE-VIRTUAL AUG, V14, P161, DOI 10.1162/1054746053966996
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Barrett J., 2004, Side effects of virtual environments: A review of the literature
   Bates D, 2014, Arxiv, DOI [arXiv:1406.5823, 10.48550/arXiv.1406.5823, DOI 10.48550/ARXIV.1406.5823]
   Ben-Shachar M.S., 2021, Package 'effectsize'
   Bingham G, 2007, NEUROPSYCHOLOGIA, V45, P288, DOI 10.1016/j.neuropsychologia.2006.07.011
   Bingham GP, 2013, J NEUROPHYSIOL, V110, P2857, DOI 10.1152/jn.00112.2013
   Bozzacchi C, 2018, EXP BRAIN RES, V236, P985, DOI 10.1007/s00221-018-5186-6
   Bozzacchi C, 2016, EXP BRAIN RES, V234, P255, DOI 10.1007/s00221-015-4456-9
   Bozzacchi C, 2014, J NEUROPHYSIOL, V112, P3189, DOI 10.1152/jn.00439.2014
   Canales Ryan, 2020, MIG '20: Motion, Interaction and Games, DOI 10.1145/3424636.3426897
   Castiello U, 2005, NAT REV NEUROSCI, V6, P726, DOI 10.1038/nrn1744
   Castiello U, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012240
   Coats R, 2008, EXP BRAIN RES, V189, P211, DOI 10.1007/s00221-008-1418-5
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Culham JC, 2006, NEUROPSYCHOLOGIA, V44, P2668, DOI 10.1016/j.neuropsychologia.2005.11.003
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Dubrowski A, 2002, EXP BRAIN RES, V145, P365, DOI 10.1007/s00221-002-1120-y
   FELDMAN AG, 1986, J MOTOR BEHAV, V18, P17
   Foster R, 2011, ACTA PSYCHOL, V136, P300, DOI 10.1016/j.actpsy.2010.12.003
   Furmanek MP, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0525-9
   GENTILUCCI M, 1992, BEHAV BRAIN RES, V47, P71, DOI 10.1016/S0166-4328(05)80253-0
   GENTILUCCI M, 1995, EXP BRAIN RES, V105, P291
   Groen J, 1998, PRESENCE-TELEOP VIRT, V7, P429, DOI 10.1162/105474698565839
   Hagen ME, 2008, SURG ENDOSC, V22, P1505, DOI 10.1007/s00464-007-9683-0
   HAGGARD P, 1995, EXP BRAIN RES, V102, P483
   HAGGARD P, 1991, NEUROSCI LETT, V122, P103, DOI 10.1016/0304-3940(91)90204-7
   Hosang S, 2016, EXP BRAIN RES, V234, P945, DOI 10.1007/s00221-015-4521-4
   JEANNEROD M, 1984, J MOTOR BEHAV, V16, P235
   Jeannerod M, 1981, ATTENTION PERFORM, P153
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Linkenauger SA, 2011, J EXP PSYCHOL HUMAN, V37, P1432, DOI 10.1037/a0024248
   Liu HX, 2019, IEEE INT CONF ROBOT, P5180, DOI [10.1109/icra.2019.8794230, 10.1109/ICRA.2019.8794230]
   Lok B, 2003, PRESENCE-VIRTUAL AUG, V12, P615, DOI 10.1162/105474603322955914
   Luckett E.:., 2018, QUANTITATIVE EVALUAT
   Mangalam M, 2021, EXP BRAIN RES, V239, P1651, DOI 10.1007/s00221-021-06079-8
   Massetti T, 2018, J CENT NERV SYST DIS, V10, DOI 10.1177/1179573518813541
   Meccariello G, 2016, J ROBOT SURG, V10, P57, DOI 10.1007/s11701-015-0541-0
   Meulenbroek RGJ, 2001, EXP BRAIN RES, V138, P219, DOI 10.1007/s002210100690
   Mon-Williams M, 2007, J EXP PSYCHOL HUMAN, V33, P645, DOI 10.1037/0096-1523.33.3.645
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Ogawa N, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P647, DOI 10.1109/VR.2018.8446318
   Ogawa N, 2017, LECT NOTES COMPUT SC, V10273, P589, DOI 10.1007/978-3-319-58521-5_46
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   PAULIGNAN Y, 1991, EXP BRAIN RES, V87, P407
   PAULIGNAN Y, 1991, EXP BRAIN RES, V83, P502
   Pilon JF, 2007, EXP BRAIN RES, V181, P49, DOI 10.1007/s00221-007-0901-8
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Prachyabrued M., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P39, DOI 10.1109/3DUI.2012.6184182
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Prachyabrued M, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P11, DOI 10.1109/3DUI.2013.6550190
   Rand MK, 2008, EXP BRAIN RES, V188, P263, DOI 10.1007/s00221-008-1361-5
   Säfström D, 2005, LEARN MEMORY, V12, P67, DOI 10.1101/lm.83005
   Säfström D, 2004, LEARN MEMORY, V11, P356, DOI 10.1101/lm.71804
   Säfström D, 2008, EXP BRAIN RES, V190, P265, DOI 10.1007/s00221-008-1469-7
   Schettino LF, 2017, J NEUROPHYSIOL, V117, P2292, DOI 10.1152/jn.00642.2016
   Sedda A, 2011, EXP BRAIN RES, V209, P365, DOI 10.1007/s00221-011-2559-5
   Sikström E, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P355, DOI 10.1145/2993369.2996343
   Sivakumar P, 2021, EXP BRAIN RES, V239, P835, DOI 10.1007/s00221-020-06025-0
   Stanney K.M., 2002, Handbook of virtual environments: design, implementation and applications
   van Polanen V, 2019, J NEUROPHYSIOL, V121, P1398, DOI 10.1152/jn.00396.2018
   Vesia M, 2012, EXP BRAIN RES, V221, P1, DOI 10.1007/s00221-012-3158-9
   Volcic R, 2016, EXP BRAIN RES, V234, P2165, DOI 10.1007/s00221-016-4620-x
   Volcic R, 2014, EXP BRAIN RES, V232, P2997, DOI 10.1007/s00221-014-3978-x
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Weiss P, 1998, NEWS PHYSIOL SCI, V13, P70
   Whitwell RL, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00216
   Yang F, 2010, EXP BRAIN RES, V201, P75, DOI 10.1007/s00221-009-2012-1
   Zahariev MA, 2008, EXP BRAIN RES, V186, P619, DOI 10.1007/s00221-008-1269-0
   Zahariev MA, 2007, EXP BRAIN RES, V180, P69, DOI 10.1007/s00221-006-0845-4
   Zahariev Mihaela A., 2003, P 5 INT C MULT INT V, P273, DOI [DOI 10.1145/958481, 10.1145/958432.958481, DOI 10.1145/958432.958481, DOI 10.1145/958432]
NR 74
TC 2
Z9 3
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD AUG 19
PY 2021
VL 2
AR 648529
DI 10.3389/frvir.2021.648529
PG 16
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2OL2
UT WOS:001021702700001
OA gold
DA 2024-07-18
ER

PT J
AU Tavassoli, F
   Howell, DM
   Black, EW
   Lok, B
   Gilbert, JE
AF Tavassoli, Fatemeh
   Howell, Diane M.
   Black, Erik W.
   Lok, Benjamin
   Gilbert, Juan E.
TI JAYLA (Junior Agent to typifY Levels of Autism): A Virtual Training
   Platform to Teach Severity Levels of Autism
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual patient; pediatric virtual patient; training; simulation; autism
   spectrum disorder
ID SPECTRUM DISORDERS; CHILDREN; REALITY; ENVIRONMENT; SKILLS; SIZE;
   STUDENTS; ADULTS; GAME
AB This initial exploratory study's primary focus is to investigate the effectiveness of a virtual patient training platform to present a health condition with a range of symptoms and severity levels. The secondary goal is to examine visualization's role in better demonstrating variances of symptoms and severity levels to improve learning outcomes. We designed and developed a training platform with a four-year-old pediatric virtual patient named JAYLA to teach medical learners the spectrum of symptoms and severity levels of Autism Spectrum Disorder in young children. JAYLA presents three sets of verbal and nonverbal behaviors associated with age-appropriate, mild autism, and severe autism. To better distinguish the severity levels, we designed an innovative interface called the spectrum-view, displaying all three simulated severity levels side-by-side and within the eye span. We compared its effectiveness with a traditional single-view interface, displaying only one severity level at a time. We performed a user study with thirty-four pediatric trainees to evaluate JAYLA's effectiveness. Results suggest that training with JAYLA improved the trainees' performance in careful observation and accurate classification of real children's behaviors in video vignettes. However, we did not find any significant difference between the two interface conditions. The findings demonstrate the applicability of the JAYLA platform to enhance professional training for early detection of autism in young children, which is essential to improve the quality of life for affected individuals, their families, and society.
C1 [Tavassoli, Fatemeh; Lok, Benjamin; Gilbert, Juan E.] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
   [Howell, Diane M.; Black, Erik W.] Univ Florida, Dept Pediat, Gainesville, FL USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of Florida
RP Tavassoli, F (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
EM ftavassoli@ufl.edu
OI Lok, Benjamin/0000-0002-1190-3729; Gilbert, Juan/0000-0002-6801-2206
CR APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Bahrani AA, 2019, J NEUROSCI METH, V327, DOI 10.1016/j.jneumeth.2019.108391
   Baio J, 2018, MMWR SURVEILL SUMM, V67, P1, DOI 10.15585/mmwr.ss6706a1
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Baraka K, 2017, LECT NOTES ARTIF INT, V10652, P105, DOI 10.1007/978-3-319-70022-9_11
   Bellani M, 2011, EPIDEMIOL PSYCH SCI, V20, P235, DOI 10.1017/S2045796011000448
   Bente G, 2001, BEHAV RES METH INS C, V33, P303, DOI 10.3758/BF03195383
   Bente G., 2011, Face-to-Face Communication over the Internet: Issues, Research, Challenges, P176, DOI [DOI 10.1017/CBO9780511977589.010, 10.1017/CBO9780511977589.010]
   Bernardini S, 2014, INFORM SCIENCES, V264, P41, DOI 10.1016/j.ins.2013.10.027
   Best J., 2019, Utilizing asynchronous online modules to educate preservice teachers to address bullying behaviors for elementary students with autism spectrum disorder [Unpublished doctoral dissertation]. University of Central Florida
   Bloodworth T., 2010, INITIAL EVALUATION V
   Bousfield T., 2017, EXAMINATION NOVICE E
   Buescher AVS, 2014, JAMA PEDIATR, V168, P721, DOI 10.1001/jamapediatrics.2014.210
   Burke SL, 2018, J AUTISM DEV DISORD, V48, P905, DOI 10.1007/s10803-017-3374-z
   Busby R., 2012, Rural Educator, V33, P27, DOI DOI 10.35608/RURALED.V33I2.416
   Cassell J., 2000, Embodied Conversational Agents
   CASTIELLO U, 1990, ACTA PSYCHOL, V73, P195, DOI 10.1016/0001-6918(90)90022-8
   Cheng YF, 2012, RES DEV DISABIL, V33, P2141, DOI 10.1016/j.ridd.2012.05.023
   Cheng YF, 2010, COMPUT EDUC, V55, P1449, DOI 10.1016/j.compedu.2010.06.008
   Choi HH, 2014, EDUC PSYCHOL REV, V26, P225, DOI 10.1007/s10648-014-9262-6
   Dennen Vanessa Paz., 2004, Cognitive apprenticeship in educational practice: research on scaffolding, modeling, mentoring, and coaching as instructional strategies
   Didehbani N, 2016, COMPUT HUM BEHAV, V62, P703, DOI 10.1016/j.chb.2016.04.033
   Dukes LC, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P118, DOI 10.1109/ICHI.2016.20
   Dyck M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003628
   Faras H, 2010, ANN SAUDI MED, V30, P295, DOI 10.4103/0256-4947.65261
   Georgescu AL, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00807
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Golnik A, 2009, PEDIATRICS, V123, P966, DOI 10.1542/peds.2008-1321
   Hopkins IM, 2011, J AUTISM DEV DISORD, V41, P1543, DOI 10.1007/s10803-011-1179-z
   Hou JH, 2012, COMPUT HUM BEHAV, V28, P617, DOI 10.1016/j.chb.2011.11.007
   Hyman SL, 2020, PEDIATRICS, V145, DOI 10.1542/peds.2019-3448
   Issenberg SB, 2005, MED TEACH, V27, P10, DOI 10.1080/01421590500046924
   Johnsen K, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1049
   Khoo EJ, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-2795
   Kotranza A., 2010, J. Bioalgorithms Med-systems, V6, P25
   Lopreiato J.O., 2016, HEALTHCARE SIMULATIO
   Major Nili E, 2015, AMA J Ethics, V17, P318, DOI 10.1001/journalofethics.2015.17.4.medu1-1504
   Martin M., 2018, INSTRUCTOR CREDIBILI
   Mineo BA, 2009, J AUTISM DEV DISORD, V39, P172, DOI 10.1007/s10803-008-0616-0
   Mitchell P, 2007, J AUTISM DEV DISORD, V37, P589, DOI 10.1007/s10803-006-0189-8
   Mussap M, 2020, METABOLITES, V10, DOI 10.3390/metabo10110476
   Ni T, 2006, PROC GRAPH INTERF, P139
   Ousley O.Y., 2013, Beyond parental report: Findings from the rapid-abc, a new 4-minute interactive autism
   Parsons S, 2002, J INTELL DISABIL RES, V46, P430, DOI 10.1046/j.1365-2788.2002.00425.x
   Pence TB, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P209, DOI 10.1109/ICHI.2013.36
   Putnam C., 2008, ASSETS '08: Proceedings of the 10th International ACM SIGACCESS Conference on Computers and Accessibility, P3, DOI [10.1145/1414471.1414475, DOI 10.1145/1414471.1414475]
   Ramdoss S, 2012, DEV NEUROREHABIL, V15, P119, DOI 10.3109/17518423.2011.651655
   Rehg J., 2013, 2013 IEEE CVPR
   Roth D, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P115, DOI 10.1109/AIVR50618.2020.00029
   Sandler AD, 2001, PEDIATRICS, V107, P1221
   Schopler E., 2010, CARS-2: Childhood Autism Rating Scale-Second Edition
   Sheldrick RC, 2017, J AM ACAD CHILD PSY, V56, P313, DOI 10.1016/j.jaac.2017.01.012
   Smith MJ, 2014, J AUTISM DEV DISORD, V44, P2450, DOI 10.1007/s10803-014-2113-y
   Talbot T., 2019, Virtual reality for psychological and neurocognitive interventions, P387, DOI [10.1007/978-1-4939-9482-317, DOI 10.1007/978-1-4939-9482-317]
   Tartaro A., 2008, PLAYING VIRTUAL PEER
   Tsai TC, 2004, ARCH DIS CHILD, V89, P1117, DOI 10.1136/adc.2003.037325
   van de Pol J, 2010, EDUC PSYCHOL REV, V22, P271, DOI 10.1007/s10648-010-9127-6
   Verkuyl M, 2016, NURS EDUC TODAY, V46, P81, DOI 10.1016/j.nedt.2016.08.024
   Vogeley K, 2010, NEURAL NETWORKS, V23, P1077, DOI 10.1016/j.neunet.2010.06.003
   Ziv A, 2005, MED TEACH, V27, P193, DOI 10.1080/01421590500126718
NR 60
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUL 21
PY 2021
VL 2
AR 660690
DI 10.3389/frvir.2021.660690
PG 12
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L2TI8
UT WOS:001021831100001
OA gold
DA 2024-07-18
ER

PT J
AU Kern, F
   Kullmann, P
   Ganal, E
   Korwisi, K
   Stingl, R
   Niebling, F
   Latoschik, ME
AF Kern, Florian
   Kullmann, Peter
   Ganal, Elisabeth
   Korwisi, Kristof
   Stingl, Rene
   Niebling, Florian
   Latoschik, Marc Erich
TI Off-The-Shelf Stylus: Using XR Devices for Handwriting and Sketching on
   Physically Aligned Virtual Surfaces
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; augmented reality; handwriting; sketching; stylus; user
   interaction; usability evaluation; passive haptic feedback
ID CALIBRATION
AB This article introduces the Off-The-Shelf Stylus (OTSS), a framework for 2D interaction (in 3D) as well as for handwriting and sketching with digital pen, ink, and paper on physically aligned virtual surfaces in Virtual, Augmented, and Mixed Reality (VR, AR, MR: XR for short). OTSS supports self-made XR styluses based on consumer-grade six-degrees-of-freedom XR controllers and commercially available styluses. The framework provides separate modules for three basic but vital features: 1) The stylus module provides stylus construction and calibration features. 2) The surface module provides surface calibration and visual feedback features for virtual-physical 2D surface alignment using our so-called 3ViSuAl procedure, and surface interaction features. 3) The evaluation suite provides a comprehensive test bed combining technical measurements for precision, accuracy, and latency with extensive usability evaluations including handwriting and sketching tasks based on established visuomotor, graphomotor, and handwriting research. The framework's development is accompanied by an extensive open source reference implementation targeting the Unity game engine using an Oculus Rift S headset and Oculus Touch controllers. The development compares three low-cost and low-tech options to equip controllers with a tip and includes a web browser-based surface providing support for interacting, handwriting, and sketching. The evaluation of the reference implementation based on the OTSS framework identified an average stylus precision of 0.98 mm (SD = 0.54 mm) and an average surface accuracy of 0.60 mm (SD = 0.32 mm) in a seated VR environment. The time for displaying the stylus movement as digital ink on the web browser surface in VR was 79.40 ms on average (SD = 23.26 ms), including the physical controller's motion-to photon latency visualized by its virtual representation (M = 42.57 ms, SD = 15.70 ms). The usability evaluation (N = 10) revealed a low task load, high usability, and high user experience. Participants successfully reproduced given shapes and created legible handwriting, indicating that the OTSS and it's reference implementation is ready for everyday use. We provide source code access to our implementation, including stylus and surface calibration and surface interaction features, making it easy to reuse, extend, adapt and/ or replicate previous results (https://go.uniwue.de/hci-otss).
C1 [Kern, Florian; Kullmann, Peter; Ganal, Elisabeth; Korwisi, Kristof; Stingl, Rene; Niebling, Florian; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
C3 University of Wurzburg
RP Kern, F (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Informat, Wurzburg, Germany.
EM florian.kern@uni-wuerzburg.de
RI Latoschik, Marc Erich/HLG-5348-2023
OI Latoschik, Marc Erich/0000-0002-9340-9600; Korwisi,
   Kristof/0000-0002-4837-5157
FU German Federal Ministry of Education and Research (BMBF) [16DHB2111];
   University of Wuerzburg
FX & nbsp;This work was supported in part by a grant from the German
   Federal Ministry of Education and Research (BMBF) in the project ViLeArn
   (reference number: 16DHB2111). This publication was supported by the
   Open Access Publication Fund of the University of Wuerzburg.
CR Angus I. G., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), P59, DOI 10.1109/INFVIS.1995.528687
   ANGUS IG, 1995, P SOC PHOTO-OPT INS, V2409, P282, DOI 10.1117/12.205875
   [Anonymous], 2016, P 5 ANN C RES INFORM, DOI DOI 10.1145/2978178.2978186
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Arora Rahul., 2018, Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI'18, P1, DOI DOI 10.1145/3173574.3173759
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P23, DOI [10.1109/VRW50115.2020.00012, 10.1109/VRW50115.2020.0-264]
   Bauer P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051622
   Beery K.E., 1997, BEERY BUKTENICA DEV, V4th
   Billinghurst M., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P155, DOI 10.1145/261135.261163
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Bovet S, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P132, DOI 10.1109/GEM.2018.8516449
   Bowers B., 2021, 2021 IEEE C VIRTUAL, P6, DOI [10.1109/VRW52623.2021.00048, DOI 10.1109/VRW52623.2021.00048]
   Bowers B, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P1, DOI 10.1109/VRW50115.2020.0-268
   Bowman D., 2001, P HCI INT 2001, P629
   Chen YT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P172, DOI [10.1109/VR.2019.8798338, 10.1109/vr.2019.8798338]
   Clergeaud Damien, 2017, 2017 3DTV Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON), DOI 10.1109/3DTV.2017.8280398
   Drey T., 2020, P 2020 CHI C HUM FAC, P1, DOI [10.1145/3313831.3376628, DOI 10.1145/3313831.3376628]
   Elmgren R., 2017, HANDWRITING VR TEXT, P13
   Elsayed Hesham., 2020, Proceedings of the 26th ACM Symposium on Virtual Reality Software and Technology, P1, DOI DOI 10.1145/3385956.3418953
   Erhardt R., 1994, DEV HAND DYSFUNCTION
   Fiorentino M., 2005, P 13 INT C CENTRAL E, P131
   Fuhrmann AL, 2001, SPRING EUROGRAP, P219
   Gerth S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01308
   Gerth S, 2016, HUM MOVEMENT SCI, V48, P62, DOI 10.1016/j.humov.2016.04.006
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   He D., 2000, INT IMMERSIVE PROJEC
   Hoppe Adrian H, 2020, HCI INT 2020 POST, P30, DOI DOI 10.1007/978-3-030-50729-9_4
   Hsu CH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P635, DOI 10.1109/VR50410.2021.00089
   Jackson B, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P13, DOI 10.1109/VRW50115.2020.0-266
   Jetter HC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376652
   Jiang HY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P132, DOI 10.1109/ISMAR-Adjunct.2018.00051
   Jost TA, 2021, DISABIL REHABIL-ASSI, V16, P632, DOI 10.1080/17483107.2019.1688398
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Li NL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376698
   Lindeman RW, 1999, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.1999.756952
   Lyu R., 2015, SIGGRAPH ASIA 2015 E, P1, DOI [10.1145/2818466.2818475, DOI 10.1145/2818466.2818475]
   Mangen A., 2018, 1 MONDAY, DOI [10.5210/fm.v23i10.9419, DOI 10.5210/FM.V23I10.9419]
   Mueller PA, 2014, PSYCHOL SCI, V25, P1159, DOI 10.1177/0956797614524581
   Naumann A., 2010, Proceedings of the 12th international conference on Human computer interaction with mobile devices and services, P401, DOI [DOI 10.1145/1851600.1851685, https://doi.org/10.1145/1851600.1851685]
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Askvik EO, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01810
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364264
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Reisman J., 1999, MINNESOTA HANDWRITIN, DOI [10.1057/9780333982785, DOI 10.1057/9780333982785]
   Richardson Mark., 2020, P 33 ANN ACM S US IN, P686
   Romat H., 2021, IEEE C VIRT REAL 3D, V10, DOI [10.1109/VR50410.2021.00053s, DOI 10.1109/VR50410.2021.00053S]
   ROSENBLOOM L, 1971, DEV MED CHILD NEUROL, V13, P3, DOI 10.1111/j.1469-8749.1971.tb03025.x
   Selin A., 2003, Pencil grip: a descriptive model and four empirical studies
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Spitzley KA, 2019, J BIOMECH, V87, P172, DOI 10.1016/j.jbiomech.2019.02.015
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   TUCERYAN M, 1995, IEEE T VIS COMPUT GR, V1, P255, DOI 10.1109/2945.466720
   van der Meer ALH, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00706
   Viciana-Abad R, 2010, PRESENCE-TELEOP VIRT, V19, P197, DOI 10.1162/pres.19.3.197
   Wacker P., 2018, 2018 CHI C HUM FACT, P1, DOI [10.1145/3170427.3188493, DOI 10.1145/3170427.3188493]
   Wagner JA, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13430
   Wagner JA, 2019, IEEE COMPUT GRAPH, V39, P41, DOI 10.1109/MCG.2019.2898856
   Wang SX, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P156, DOI 10.1109/ISMAR-Adjunct.2019.00-58
   Wiese E., 2010, 7 SKETCH BASEDINTERF, P135
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376876
   Wu PC, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/3126594.3126664
   Wynn-Parry C. B., 1966, REHABILITATION HAND
   Xiao R, 2018, IEEE T VIS COMPUT GR, V24, P1653, DOI 10.1109/TVCG.2018.2794222
   Yun MH, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P331, DOI 10.1145/3038912.3052557
   Zielasko D, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809589
   Zielasko D, 2017, 2017 IEEE 3RD WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/WEVR.2017.7957707
NR 73
TC 15
Z9 15
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD JUN 4
PY 2021
VL 2
AR 684498
DI 10.3389/frvir.2021.684498
PG 20
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YV2
UT WOS:001023346000001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Higgins, D
   Fribourg, R
   McDonnell, R
AF Higgins, Darragh
   Fribourg, Rebecca
   McDonnell, Rachel
TI Remotely Perceived: Investigating the Influence of Valence on
   Self-Perception and Social Experience for Dyadic Video-Conferencing With
   Personalized Avatars
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; virtual characters; perception; remote working; facial
   tracking; embodiment; face ownership; motion capture
ID VIRTUAL BODY OWNERSHIP; ENFACEMENT ILLUSION; SENSE; IMMERSION;
   ENVIRONMENTS; COPRESENCE; EMBODIMENT; APPEARANCE; BEHAVIOR; EMOTION
AB Avatar use on video-conference platforms has found dual purpose in recent times as a potential method for ensuring privacy and improving subjective engagement with remote meeting, provided one can also ensure a minimal loss in the quality of social interaction and sense of personal presence. This work focuses on interactions of this sort through real-time motion captured 3D personalized virtual avatars in a 2D video-conferencing context. Our experiments were designed with the intention of exploring previously defined perceptual illusions that occur with avatar-use in Virtual and Augmented Reality settings, outside of the immersive technological domains where they are normally measured. The research described here was aimed at empirically evaluating three separate dimensions of human-avatar interaction. The first was humans-as-avatars, with experimental conditions that were designed to measure changes to subjective perceptions of self-face ownership and self-concept. The second focus was other-perception, with the unique design of the studies outlined below among the first to measure social presence in a video-call between two human-driven avatars. The third emphasis was on the experiential content involved in avatar use, as there were measurements for emotion induction, fatigue and behavior change included in the data collection. The results describe some evidence for face and body ownership, while participants also reported high levels of social presence with the other avatar, indicating that avatar cameras could be a favorable alternative to non-camera feeds in video conferencing. There were also some useful insights gained regarding emotion elicitation in non-video vs. avatar conditions, as well as avatar-induced behavior change.
C1 [Higgins, Darragh; Fribourg, Rebecca; McDonnell, Rachel] Trinity Coll Dublin, Sch Comp Sci & Stat, Graph Vis & Visualisat Grp, Dublin, Ireland.
C3 Trinity College Dublin
RP Higgins, D (corresponding author), Trinity Coll Dublin, Sch Comp Sci & Stat, Graph Vis & Visualisat Grp, Dublin, Ireland.
EM higgind3@tcd.ie
OI Fribourg, Rebecca/0000-0002-4572-477X
FU Science Foundation Ireland [18/CRT/6224]; Trinity College Dublin's
   RADICal Project [19/FFP/6409]; Science Foundation Ireland (SFI)
   [18/CRT/6224] Funding Source: Science Foundation Ireland (SFI)
FX Funding This work was funded by the Science Foundation Ireland (grant
   number 18/CRT/6224), and Trinity College Dublin's RADICal Project (grant
   number 19/FFP/6409).
CR Archibald MM, 2019, INT J QUAL METH, V18, DOI 10.1177/1609406919874596
   Aseeri S., 2020, EMBODIED REALISTIC A, DOI [10.1109/VRW50115.2020.0-134, DOI 10.1109/VRW50115.2020.0-134]
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Biocca F, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P12, DOI 10.1109/CT.1997.617676
   Biocca F., 2001, CRITERIA SCOPE CONDI
   Bufalari I, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00102
   Dewez D., 2019, ISMAR 2019 18 IEEE I, P1
   Eich E., 2007, COMBINING MUSIC THOU
   Ferrer RA, 2015, EMOTION, V15, P752, DOI 10.1037/emo0000035
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P281, DOI 10.1145/3267851.3267891
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fribourg R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P273, DOI 10.1109/VR.2018.8448293
   GERRARDSHESSE A, 1994, BRIT J PSYCHOL, V85, P55, DOI 10.1111/j.2044-8295.1994.tb02508.x
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gonzalez-Franco M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00392
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Hamilton AFD, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0080
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Ito TA, 1998, J PERS SOC PSYCHOL, V75, P887, DOI 10.1037/0022-3514.75.4.887
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Kahn JH, 2007, AM J PSYCHOL, V120, P263, DOI 10.2307/20445398
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Koda T., 2006, Proceedings. International Symposium on Applications and the Internet
   Koda T., 2019, ANAL EFFECTS APPEARA, V1, P232, DOI [10.5220/0007483502320237, DOI 10.5220/0007483502320237]
   Kokkinara E., 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG'15, P221, DOI DOI 10.1145/2822013.2822035
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kossaifi J., 2019, SEWA DB RICH DATABAS, DOI [10.1109/TPAMI.2019.2944808, DOI 10.1109/TPAMI.2019.2944808]
   Kuzminykh A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376546
   Ma K, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00604
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P349, DOI 10.1111/jcal.12335
   McCreery MP, 2012, COMPUT HUM BEHAV, V28, P976, DOI 10.1016/j.chb.2011.12.019
   Mennecke B.E., 2010, EMBODIED SOCIAL PRES, DOI DOI 10.1109/HICSS.2010.179
   Minio-Paluello I, 2020, CORTEX, V123, P113, DOI 10.1016/j.cortex.2019.10.001
   Minsky M., 1980, Omni, V2, P44
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Panagiotopoulou E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13345-9
   Parsons TD, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7040042
   Peña J, 2009, COMMUN RES, V36, P838, DOI 10.1177/0093650209346802
   Porciello G, 2018, CORTEX, V104, P261, DOI 10.1016/j.cortex.2018.01.007
   Ratan R., 2012, IGI GLOB, P321, DOI [10.4018/978-1-4666-2211-1.ch018, DOI 10.4018/978-1-4666-2211-1.CH018]
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Riva G, 2018, CORTEX, V104, P241, DOI 10.1016/j.cortex.2017.07.013
   Romano D, 2014, BEHAV BRAIN RES, V261, P275, DOI 10.1016/j.bbr.2013.12.049
   Roseman IJ, 1996, COGNITION EMOTION, V10, P241, DOI 10.1080/026999396380240
   Roth D., 2019, Proceedings of Mensch Und Computer 2019, P21, DOI DOI 10.1145/3340764.3340797
   Roth D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P215, DOI 10.1109/VR.2018.8447550
   Seyama J, 2007, PRESENCE-TELEOP VIRT, V16, P337, DOI 10.1162/pres.16.4.337
   Sforza A, 2010, SOC NEUROSCI-UK, V5, P148, DOI 10.1080/17470910903205503
   Shahid M., 2018, ASSESSING QUALITY VI, DOI [10.2352/ISSN.2470-1173.2018.12.IQSP-235, DOI 10.2352/ISSN.2470-1173.2018.12.IQSP-235]
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Steinicke Frank, 2020, SUI '20: Symposium on Spatial User Interaction, DOI 10.1145/3385959.3422699
   Suh KS, 2011, MIS QUART, V35, P711
   Tajadura-Jiménez A, 2012, CONSCIOUS COGN, V21, P1725, DOI 10.1016/j.concog.2012.10.004
   Van Der Heide B, 2013, COMMUN RES, V40, P838, DOI 10.1177/0093650212438097
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang TY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1221, DOI [10.1109/VR.2019.8798044, 10.1109/vr.2019.8798044]
   Weibel D, 2010, CYBERPSYCH BEH SOC N, V13, P251, DOI 10.1089/cyber.2009.0171
   Wienrich C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P207, DOI 10.1109/VR.2018.8446575
   Wisessing P, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3383195
   Yee N, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, MEDIA PSYCHOL, V12, P195, DOI 10.1080/15213260902849943
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/vr.2019.8797719, 10.1109/VR.2019.8797719]
   Zibrek K, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419985
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 73
TC 3
Z9 3
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 31
PY 2021
VL 2
AR 668499
DI 10.3389/frvir.2021.668499
PG 21
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA K8WA2
UT WOS:001019173600001
OA gold
DA 2024-07-18
ER

PT J
AU Lobachev, O
   Berthold, M
   Pfeffer, H
   Guthe, M
   Steiniger, BS
AF Lobachev, Oleg
   Berthold, Moritz
   Pfeffer, Henriette
   Guthe, Michael
   Steiniger, Birte S. S.
TI Inspection of Histological 3D Reconstructions in Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE anatomy; scientific visualization; 3D reconstruction; virtual reality;
   histological serial sections
ID AUGMENTED REALITY; NAVIGATION SYSTEM; VISUALIZATION; EDUCATION; ANATOMY
AB 3D reconstruction is a challenging current topic in medical research. We perform 3D reconstructions from serial sections stained by immunohistological methods. This paper presents an immersive visualization solution to quality control (QC), inspect, and analyze such reconstructions. QC is essential to establish correct digital processing methodologies. Visual analytics, such as annotation placement, mesh painting, and classification utility, facilitates medical research insights. We propose a visualization in virtual reality (VR) for these purposes. In this manner, we advance the microanatomical research of human bone marrow and spleen. Both 3D reconstructions and original data are available in VR. Data inspection is streamlined by subtle implementation details and general immersion in VR.
C1 [Lobachev, Oleg; Berthold, Moritz; Guthe, Michael] Univ Bayreuth, Fak Math Phys & Informat, Visual Comp, Angew Informat Graph Datenverarbeitung 5, Bayreuth, Germany.
   [Lobachev, Oleg] Hannover Med Sch, Inst Funct & Appl Anat, Hannover, Germany.
   [Lobachev, Oleg] Leibniz Fachhsch Sch Business, Fachbereich Tech, Hannover, Germany.
   [Berthold, Moritz] BCM Solut GmbH, Stuttgart, Germany.
   [Pfeffer, Henriette; Steiniger, Birte S. S.] Philipps Univ Marburg, Med Fac, Anat & Cell Biol, Marburg, Germany.
C3 University of Bayreuth; Hannover Medical School; Philipps University
   Marburg
RP Lobachev, O (corresponding author), Univ Bayreuth, Fak Math Phys & Informat, Visual Comp, Angew Informat Graph Datenverarbeitung 5, Bayreuth, Germany.; Lobachev, O (corresponding author), Hannover Med Sch, Inst Funct & Appl Anat, Hannover, Germany.; Lobachev, O (corresponding author), Leibniz Fachhsch Sch Business, Fachbereich Tech, Hannover, Germany.
EM oleg.lobachev@leibniz-fh.de
RI Lobachev, Oleg/F-2843-2012
OI Lobachev, Oleg/0000-0002-7193-6258
FU DFG [MU 3118/8-1]; Philipps-University Marburg
FX This work was partially supported by DFG grant MU 3118/8-1. Open Access
   publication was funded by a joint programme of of DFG and
   Philipps-University Marburg.
CR Ahrens J., 2005, Visualization Handbook, DOI DOI 10.1016/B978-012387582-2/50038-1.3S
   [Anonymous], 2017, P 33 SPRING C COMP G, DOI DOI 10.1145/3154353.3154366
   Apel Sven, 2013, Feature-Oriented Software Product Lines-Concepts and Implementation, DOI DOI 10.1007/978-3-642-37521-7
   Ayachit U., 2015, The ParaView Guide, A Parallel Visualization Application
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Bouaoud J, 2021, J STOMATOL ORAL MAXI, V122, P367, DOI 10.1016/j.jormas.2020.09.009
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Burns M., 2007, Proceedings of Eurographics / IEEE VGTC Symposium on Visualization (EuroVis 2007), P275
   Calì C, 2019, JOVE-J VIS EXP, DOI 10.3791/59444
   Calvert J, 2020, COMPUT EDUC, V159, DOI 10.1016/j.compedu.2020.104005
   Chan S, 2013, NEUROSURGERY, V72, pA154, DOI 10.1227/NEU.0b013e3182750d26
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen XJ, 2015, J BIOMED INFORM, V55, P124, DOI 10.1016/j.jbi.2015.04.003
   Choi KS, 2016, IEEE CONF TECHNOL ED, P184, DOI [10.1109/T4E.2016.046, 10.1109/T4E.2016.45]
   Cignoni P., 2008, EUR IT CHAPT C, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129-136]
   Daly C. J., 2019, TXB VASCULAR MED, P59, DOI [10.1007/978-3-030-16481-2_6, DOI 10.1007/978-3-030-16481-2_6]
   Daly C. J., 2019, INFOCUS MAG, V54, P51, DOI [10.22443/rms.inf.1, DOI 10.22443/RMS.INF.1]
   Daly C. J., 2018, PHYSL NEWS, V111, P43, DOI [10.36866/pn.111.43, DOI 10.36866/PN.111.43]
   Derzapf E, 2012, COMPUT GRAPH FORUM, V31, P2288, DOI 10.1111/j.1467-8659.2012.03154.x
   Dorweiler B, 2019, GEFASSCHIRURGIE, V24, P531, DOI 10.1007/s00772-019-00570-x
   Duarte M. L., 2020, Morphologie, V104, P254, DOI 10.1016/j.morpho.2020.08.004
   Egger J, 2021, PROC SPIE, V11315, DOI 10.1117/12.2559239
   Egger J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173972
   El Beheiry M, 2019, J MOL BIOL, V431, P1315, DOI 10.1016/j.jmb.2019.01.033
   Esfahlani SS, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00526
   Faludi B, 2019, LECT NOTES COMPUT SC, V11768, P29, DOI 10.1007/978-3-030-32254-0_4
   Forsberg AS, 2000, IEEE VISUAL, P457, DOI 10.1109/VISUAL.2000.885731
   Gsaxner C, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105854
   Guarda AFR, 2017, SIGNAL PROCESS-IMAGE, V59, P96, DOI 10.1016/j.image.2017.02.002
   Guthe S, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P53, DOI 10.1109/VISUAL.2002.1183757
   Guthe S., 2016, Vision, Modeling and Visualization, P77, DOI DOI 10.2312/VMV.20161345
   Gutiérrez J, 2018, SIGNAL PROCESS-IMAGE, V69, P35, DOI 10.1016/j.image.2018.05.003
   Hasselgren J., 2016, P HIGH PERF GRAPH, P23
   Inoue A., 2016, Proc. Mtgs. Acoust., V29, DOI [10.1121/2.0000381, DOI 10.1121/2.0000381]
   Knodel MM, 2018, COMPUT VIS SCI, V18, P203, DOI 10.1007/s00791-018-0292-3
   Liimatainen K, 2020, Arxiv, DOI arXiv:2003.11148
   Lobachev O., 2019, INSPECTING HUMAN 3D
   Lobachev O., 2018, THESIS U BAYREUTH BA
   Lobachev O, 2020, IEEE ACCESS, V8, P13489, DOI 10.1109/ACCESS.2020.2965885
   Lobachev O, 2017, MED IMAGE ANAL, V35, P288, DOI 10.1016/j.media.2016.07.010
   Chávez OL, 2020, INT J MED INFORM, V141, DOI 10.1016/j.ijmedinf.2020.104226
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Mann S., 2018, arXiv
   Mathur AS, 2015, P IEEE VIRT REAL ANN, P345, DOI 10.1109/VR.2015.7223437
   Mattausch O, 2008, COMPUT GRAPH FORUM, V27, P221, DOI 10.1111/j.1467-8659.2008.01119.x
   Misiak M, 2018, 2018 SIXTH IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P112, DOI 10.1109/VISSOFT.2018.00020
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Philippe S., 2020, VIRTUAL REALITY INTE, V2, P421, DOI [DOI 10.1016/J.VRIH.2020.07.008, 10.1016/j.vrih.2020.07.008]
   Pieper S, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P632
   Pieterse AD, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.577534
   Pinter C., 2020, SLICERVR MED INTERVE
   Preim B, 2018, COMPUT GRAPH-UK, V71, P132, DOI 10.1016/j.cag.2018.01.005
   Quam DJ, 2015, J BIOMECH ENG-T ASME, V137, DOI 10.1115/1.4029017
   Ritter F, 2011, IEEE PULSE, V2, P60, DOI 10.1109/MPUL.2011.942929
   Rizvi SMAER, 2019, EC SOC DEVELOP, P1
   Ron Kikinis, 2014, Intraoperative Imaging and Image-Guided Therapy, P277, DOI DOI 10.1007/978-1-4614-7657-319
   Schneider JP, 2021, HISTOCHEM CELL BIOL, V155, P241, DOI 10.1007/s00418-020-01916-3
   Scholl I., 2018, BILDVERARBEITUNG F R, P297, DOI [10.1007/978-3-662-56537-7_79, DOI 10.1007/978-3-662-56537-7_79]
   Schweigger-Seidel F., 1862, ARCH PATHOL ANAT PH, V23, P526, DOI [10.1007/BF01939038, DOI 10.1007/BF01939038]
   Shen R, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P63, DOI 10.1109/MediVis.2008.10
   Shimabukuro MH, 1998, IEEE INFOR VIS, P25, DOI 10.1109/IV.1998.694195
   Silva Samuel, 2009, 2009 Second International Conference in Visualisation (VIZ), P165, DOI 10.1109/VIZ.2009.40
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Stefani C, 2018, J MOL BIOL, V430, P4028, DOI 10.1016/j.jmb.2018.06.035
   Steiniger BS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34105-3
   Steiniger B, 2007, HISTOCHEM CELL BIOL, V128, P391, DOI 10.1007/s00418-007-0320-8
   Steiniger BS, 2021, HISTOCHEM CELL BIOL, V155, P341, DOI 10.1007/s00418-020-01924-3
   Steiniger BS, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191019
   Steiniger BS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168173
   Stets JD, 2017, SIGGRAPH ASIA 2017 POSTERS (SA'17), DOI 10.1145/3145690.3145729
   Stone JE, 2010, LECT NOTES COMPUT SC, V6454, P382, DOI 10.1007/978-3-642-17274-8_38
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   SUTHERLAND IE, 1970, SCI AM, V222, P57, DOI 10.1038/scientificamerican0670-56
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tang L, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115852
   Tomikawa M, 2010, J AM COLL SURGEONS, V210, P927, DOI 10.1016/j.jamcollsurg.2010.01.032
   Ulrich C., 2014, WSCG COMMUNICATIONS
   Uppot RN, 2019, RADIOLOGY, V291, P570, DOI 10.1148/radiol.2019182210
   Uruthiralingam U, 2020, ADV EXP MED BIOL, V1235, P89, DOI 10.1007/978-3-030-37639-0_5
   van Dam A, 2000, IEEE COMPUT GRAPH, V20, P26, DOI 10.1109/38.888006
   Walsh CM, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008237.pub2
   Williams J. K., 2019, THESIS IOWA STATE U
   Wissmann N, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P828, DOI [10.1109/VR46266.2020.1580932797283, 10.1109/VR46266.2020.00009]
   Xia PJ, 2013, VISUAL COMPUT, V29, P433, DOI 10.1007/s00371-012-0748-2
   Zoller EI, 2020, INT J COMPUT ASS RAD, V15, P1797, DOI 10.1007/s11548-020-02258-0
NR 85
TC 3
Z9 3
U1 3
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD MAY 3
PY 2021
VL 2
AR 628449
DI 10.3389/frvir.2021.628449
PG 19
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L5AJ9
UT WOS:001023386700001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Stradford, J
   Sakhare, A
   Ravichandran, R
   Schroeder, ET
   Michener, LA
   Pa, J
AF Stradford, Joy
   Sakhare, Ashwin
   Ravichandran, Roshan
   Schroeder, E. Todd
   Michener, Lori A.
   Pa, Judy
TI Conducting a VR Clinical Trial in the Era of COVID-19
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; video games; aging; COVID-19; brain health; physical
   activity
AB The outbreak of severe acute respiratory syndrome coronavirus 2, also known as Coronavirus Disease 2019 (COVID-19) sparked a global public health pandemic that has impacted every aspect of daily life. Medical research was affected, and many clinical trials were halted to minimize COVID-19 transmission risk and spread while the world navigated this novel virus. Here we describe the relaunch of our virtual reality (VR) pilot clinical trial that uses an in-lab brain and body training program to promote brain health in mid-to-late life older adults, in the era of COVID-19. This case series includes five healthy female participants between 51 and 76 years of age, a subset of a larger VR pilot clinical trial that started pre-pandemic. We developed a revised study protocol based on the Center for Disease Control and World Health Organization guidelines to help manage the spread of COVID-19. Since the limited resumption of clinical trials at our institution in August 2020, we successfully completed over 200 in-lab virtual reality training sessions using our revised protocol. During this time, none of the five participants or three study staff reported any COVID-19 symptoms or reported a positive COVID-19 test. More than 40 voluntary COVID-19 tests were completed by our study staff over the last 6 months. All participants rated our safety protocol as very satisfied or extremely satisfied and that they would be very likely or extremely likely to participate in a VR clinical trial during the pandemic. Based on these findings, we suggest that continued VR clinical trial research during the COVID-19 pandemic is achievable and can be safely resumed if specific safety protocols are in place to mitigate the risk of exposure and spread of COVID-19.
C1 [Stradford, Joy; Sakhare, Ashwin; Ravichandran, Roshan; Pa, Judy] Univ Southern Calif, Mark & Mary Stevens Neuroimaging & Informat Inst, Dept Neurol, Los Angeles, CA 90007 USA.
   [Sakhare, Ashwin; Pa, Judy] Univ Southern Calif, Viterbi Sch Engn, Dept Biomed Engn, Los Angeles, CA 90007 USA.
   [Schroeder, E. Todd; Michener, Lori A.; Pa, Judy] Univ Southern Calif, Div Biokinesiol & Phys Therapy, Los Angeles, CA 90007 USA.
   [Pa, Judy] Univ Southern Calif, Keck Sch Med, Dept Neurol, Alzheimers Dis Res Ctr, Los Angeles, CA 90007 USA.
C3 University of Southern California; University of Southern California;
   University of Southern California; University of Southern California
RP Pa, J (corresponding author), Univ Southern Calif, Mark & Mary Stevens Neuroimaging & Informat Inst, Dept Neurol, Los Angeles, CA 90007 USA.; Pa, J (corresponding author), Univ Southern Calif, Viterbi Sch Engn, Dept Biomed Engn, Los Angeles, CA 90007 USA.; Pa, J (corresponding author), Univ Southern Calif, Div Biokinesiol & Phys Therapy, Los Angeles, CA 90007 USA.; Pa, J (corresponding author), Univ Southern Calif, Keck Sch Med, Dept Neurol, Alzheimers Dis Res Ctr, Los Angeles, CA 90007 USA.
EM judypa@usc.edu
RI Michener, Lori/Q-7186-2018
OI Michener, Lori/0000-0001-9469-0732; Stradford, Joy/0000-0001-5445-4081
FU National Center for Advancing Translational Science [UL1TR001855,
   UL1TR000130]; National Institute on Aging of the U.S. National
   Institutes of Health [R01AG065356]
FX & nbsp;This work was supported by the National Center for Advancing
   Translational Science (UL1TR001855 and UL1TR000130) and the National
   Institute on Aging (R01AG065356) of the U.S. National Institutes of
   Health.
CR Ascione F, 2021, ENERG BUILDINGS, V230, DOI 10.1016/j.enbuild.2020.110533
   Atkinson J, 2009, NATURAL VENTILATION FOR INFECTION CONTROL IN HEALTH-CARE SETTINGS, P1
   Ayittey FK, 2020, J MED VIROL, V92, P473, DOI 10.1002/jmv.25706
   Casini B, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16193572
   Centers for Disease Control Prevention, 2019, CONS I HIGH ED CTR D
   Centers for Disease Control Prevention, 2017, DEF SIGNS SYMPT COND
   Chu DK, 2020, LANCET, V395, P1973, DOI 10.1016/S0140-6736(20)31142-9
   Climate Data, 2021, CLIM DAT
   Dhama K, 2020, CLIN MICROBIOL REV, V33, DOI 10.1128/CMR.00028-20
   Epstein D, 2021, SCAND J MED SCI SPOR, V31, P70, DOI 10.1111/sms.13832
   Ferreri F, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11643
   Ge ZY, 2020, J ZHEJIANG UNIV-SC B, V21, P361, DOI 10.1631/jzus.B2010010
   Juliano JM, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00678-2
   Kim A, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0584-y
   Kutter JS, 2018, CURR OPIN VIROL, V28, P142, DOI 10.1016/j.coviro.2018.01.001
   LA County COVID-9 Surveillance Dashboard, 2020, ABOUT US
   Laurencin CT, 2020, J RACIAL ETHN HEALTH, V7, P398, DOI 10.1007/s40615-020-00756-0
   Leung SO, 2011, J SOC SERV RES, V37, P412, DOI 10.1080/01488376.2011.580697
   Maples-Keller JL, 2017, NEUROTHERAPEUTICS, V14, P554, DOI 10.1007/s13311-017-0534-y
   Marin-Pardo O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133754
   Mayo Clinic, 2020, COVID 19 WHOS HIGH R
   Montana JI, 2019, J CLIN MED, V8, DOI 10.3390/jcm8101516
   Otter JA, 2020, WOODH PUBL SER BIOM, P323, DOI 10.1016/B978-0-08-102565-9.00015-7
   Park MJ, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00505
   Pompoli A, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011004.pub2
   Raj VAA, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102371
   Repetto C, 2013, PERS UBIQUIT COMPUT, V17, P253, DOI 10.1007/s00779-011-0467-0
   Rizzo Albert, 2012, Stud Health Technol Inform, V173, P379
   Rothan HA, 2020, J AUTOIMMUN, V109, DOI 10.1016/j.jaut.2020.102433
   Sathian B, 2020, NEPAL J EPIDEMIOL, V10, P878, DOI 10.3126/nje.v10i3.31622
   Stawicki SP, 2020, J GLOB INFECT DIS, V12, P47, DOI 10.4103/jgid.jgid_86_20
   Umscheid CA, 2011, POSTGRAD MED, V123, P194, DOI 10.3810/pgm.2011.09.2475
   VR Cover, 2019, VR HYG SOL OC QUEST
NR 33
TC 2
Z9 2
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2021
VL 2
AR 639478
DI 10.3389/frvir.2021.639478
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4YN0
UT WOS:001023337800001
PM 35928984
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Vindenes, J
   Wasson, B
AF Vindenes, Joakim
   Wasson, Barbara
TI A Postphenomenological Framework for Studying User Experience of
   Immersive Virtual Reality
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE user experience; virtual reality; postphenomenology; mediation theory;
   framework
ID SELF; BEHAVIOR; PERCEPTIONS; ENVIRONMENT; EMBODIMENT; SIMULATOR
AB Virtual Reality (VR) is a remarkably flexible technology for interventions as it allows the construction of virtual worlds with ontologies radically different from the real world. By embodying users in avatars situated in these virtual environments, researchers can effectively intervene and instill positive change in the form of therapy or education, as well as affect a variety of cognitive changes. Due to the capabilities of VR to mediate both the environments in which we are immersed, as well as our embodied, situated relation toward those environments, VR has become a powerful technology for "changing the self." As the virtually mediated experience is what renders these interventions effective, frameworks are needed for describing and analyzing the mediations brought by various virtual world designs. As a step toward a broader understanding of how VR mediates experience, we propose a post-phenomenological framework for describing VR mediation. Postphenomenology is a philosophy of technology concerned with empirical data that understand technologies as mediators of human-world relationships. By addressing how mediations occur within VR as a user-environment relation and outside VR as a human-world relation, the framework addresses the various constituents of the virtually mediated experience. We demonstrate the framework's capability for describing VR mediations by presenting the results of an analysis of a selected variety of studies that use various user-environment relations to mediate various human-world relations.
C1 [Vindenes, Joakim; Wasson, Barbara] Univ Bergen, Ctr Sci Learning & Technol SLATE, Bergen, Norway.
   [Vindenes, Joakim; Wasson, Barbara] Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway.
C3 University of Bergen; University of Bergen
RP Vindenes, J (corresponding author), Univ Bergen, Ctr Sci Learning & Technol SLATE, Bergen, Norway.; Vindenes, J (corresponding author), Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway.
EM joakim.vindenes@uib.no
OI Wasson, Barbara/0000-0003-4897-1394
FU Ph.D. stipend at the University of Bergen
FX This research was funded by a Ph.D. stipend at the University of Bergen.
CR Achterhuis Hans., 2001, American Philosophy of Technology: The Empirical Turn
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   Alaraj Ali, 2011, Surg Neurol Int, V2, P52, DOI 10.4103/2152-7806.80117
   Alexandrovsky D., 2021, CHI C HUM FACT COMP
   Amores J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3311770
   Ates H.C., 2015, P 9 INT C TANGIBLE E, P225, DOI [DOI 10.1145/2677199.2680551, 10.1145/2677199.2680551]
   Aydin C, 2019, Philosophy and Technology, V32, P321, DOI DOI 10.1007/S13347-018-0309-3
   Banakou D, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201848
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Bourdin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169343
   Çaliskan O, 2011, PROCD SOC BEHV, V15, P3239, DOI 10.1016/j.sbspro.2011.04.278
   de Mul Jos., 2010, Cyberspace Odyssey: Towards a Virtual Ontology and Anthropology
   Falconer CJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111933
   Flobak E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300799
   Fox J, 2013, COMPUT HUM BEHAV, V29, P930, DOI 10.1016/j.chb.2012.12.027
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Gonzalez-Franco M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209704
   Groom V, 2009, SOC INFLUENCE, V4, P231, DOI 10.1080/15534510802643750
   Gualeni S., 2020, Virtual Existentialism: Meaning and Subjectivity in Virtual Worlds
   Gualeni S, 2015, VIRTUAL WORLDS AS PHILOSOPHICAL TOOLS: HOW TO PHILOSOPHIZE WITH A DIGITAL HAMMER, pXIV
   Hamilton-Giachritsis C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21036-2
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Hauser S, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P459, DOI 10.1145/3196709.3196745
   Hershfield HE, 2011, J MARKETING RES, V48, pS23, DOI 10.1509/jmkr.48.SPL.S23
   Ihde D., 1990, Technology and the Lifeworld: From Garden to Earth, DOI DOI 10.5860/CHOICE.28-1535
   Ihde D., 2003, Postphenomenology-again
   Ihde Don., 2002, Bodies in Technology
   Ihde Don., 2012, EXPT PHENOMENOLOGY
   Introna L., 2017, STANFORD ENCY PHILOS
   Jones PR, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0242-6
   Kalyanaraman S, 2010, J NERV MENT DIS, V198, P437, DOI 10.1097/NMD.0b013e3181e07d66
   Kaposy C., 2017, POSTPHENOMENOLOGICAL, P191
   KAY A, 1977, COMPUTER, V10, P31, DOI 10.1109/C-M.1977.217672
   Lanier J., 2017, DAWN NEW EVERYTHING, V1st
   Leitner JB, 2017, SOC COGN AFFECT NEUR, V12, P534, DOI 10.1093/scan/nsw168
   Lindner P, 2019, J ANXIETY DISORD, V61, P45, DOI 10.1016/j.janxdis.2018.07.003
   Loomis JM, 2016, PRESENCE-TELEOP VIRT, V25, P169, DOI 10.1162/PRES_a_00255
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Maxhall M., 2004, Proceedings of the 5th International Conference on Disability, Virtual Reality and Associated Technologies, P225
   McCarthy John., 2004, TECHNOLOGY EXPERIENC
   Merleau-Ponty Maurice., 2005, PHENOMENOLOGY PERCEP
   Metzinger TK, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00101
   MILGRAM S, 1964, J ABNORM SOC PSYCH, V69, P137, DOI 10.1037/h0047759
   Moran S, 2016, PERS UBIQUIT COMPUT, V20, P261, DOI 10.1007/s00779-016-0910-3
   Morgan KimberlyJ., 2017, The Many Hands of the State: Theorizing Political Authority and Social Control
   Neyret S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62932-w
   Nyre L., 2020, IMMERSIVE JOURNALISM, P25
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Prpa M, 2016, COMM COM INF SC, V604, P34, DOI 10.1007/978-3-319-32270-4_4
   Roo JS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1459, DOI 10.1145/3025453.3025743
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Rosenberger R., 2015, Postphenomenological investigations: Essays on human-technology relations, P9
   Rua H, 2011, J ARCHAEOL SCI, V38, P3296, DOI 10.1016/j.jas.2011.07.015
   SATAVA RM, 1993, SURG ENDOSC-ULTRAS, V7, P203, DOI 10.1007/BF00594110
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Semertzidis N. A., 2019, P 2019 CHI C HUM FAC, P1
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2014, COMPUTER, V47, P24, DOI 10.1109/MC.2014.198
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stepanova ER, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P641, DOI 10.1145/3357236.3395532
   Suzuki K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16316-2
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Verbeek P., 2011, Moralizing technology: Understanding and designing the morality of things, DOI DOI 10.7208/CHICAGO/9780226852904.001.0001
   Verbeek P., 2005, What Things Do: Philosophical Reflections on Technology, Agency, and Design
   Verbeek P.-P., 2005, P AIAS C MEDIATED VI, P1
   Verbeek P.-P., 2015, The online manifesto: Being human in a 324 hyperconnected era, P217, DOI [DOI 10.1007/978-3-319-04093-6, DOI 10.1007/978-3-319-04093-621]
   Verbeek PP, 2008, PHENOMENOL COGN SCI, V7, P387, DOI 10.1007/s11097-008-9099-x
   Verbeek PeterPaul, 2015, INTERACTIONS ACM, V12, P26, DOI [10.1145/2751314, DOI 10.1145/2751314]
   Voordijk H, 2022, EUR J ENG EDUC, V47, P259, DOI 10.1080/03043797.2020.1795085
   Willis Anne-Marie, 2006, Design Philosophy Papers, V4, P69, DOI [10.2752/144871306x13966268131514, DOI 10.2752/144871306X13966268131514, 10.2752/144871306X13966268131514]
NR 77
TC 11
Z9 14
U1 5
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD APR 29
PY 2021
VL 2
AR 656423
DI 10.3389/frvir.2021.656423
PG 15
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L4RQ6
UT WOS:001023158600001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Laguna, B
   Livingston, K
   Brar, R
   Jagodzinski, J
   Pandya, N
   Sabatini, C
   Courtier, J
AF Laguna, Benjamin
   Livingston, Kristin
   Brar, Ravinder
   Jagodzinski, Jason
   Pandya, Nirav
   Sabatini, Coleen
   Courtier, Jesse
TI Assessing the Value of a Novel Augmented Reality Application for
   Presurgical Planning in Adolescent Elbow Fractures
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE Hololens; radiology; DICOM; Augmented Reality (AR); computed tomography
ID SUPRACONDYLAR HUMERUS FRACTURES; DISTAL HUMERUS; RECONSTRUCTION;
   ARTHROPLASTY; MANAGEMENT; ACCURACY; RADIOGRAPHY; NAVIGATION; TEMPLATE;
   CHILDREN
AB Objectives: We retrospectively assess the potential impact of a novel, investigational Augmented Reality (AR) software application, Radiology with Holographic Augmentation (RadHA), on pediatric orthopedic surgeon's confidence in surgical planning, hardware selection, hardware fit, and estimated potential intraoperative time savings in the setting of complex adolescent elbow fractures.
   Methods: After study selection, 12 individual cases of complex elbow fractures in adolescent pediatric patients were identified for review. AR models were generated for each case derived from the patient's CT. Five fellowship-trained pediatric orthopedic surgeons reviewed each case for a total of 60 separate observations. Surgeons reviewed clinical data, radiologic imaging, and AR models and then answered Likert Scale questions on measures of confidence in presurgical planning and projected potential time savings. These data were reviewed and analyzed using various statistical tools.
   Results: Surgeons reported high confidence in the quality of the AR models created. Additionally, surgeons reported increased confidence in their surgical plan, increased confidence in hardware selection, and increased confidence in hardware fit. Within the sub-analysis of complex (comminuted) fractures, surgeons reported greater expected increases in confidence of their surgical plan and hardware fit. Overall, surgeons estimated potential intraoperative time savings, averaging 17.3min for all fracture types and 17.6min for complex fractures.
   Conclusions: Preoperative planning using AR-based models can increase surgeon confidence in preoperative planning, hardware selection, and confidence in hardware fit.
C1 [Laguna, Benjamin] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA USA.
   [Livingston, Kristin; Pandya, Nirav] Univ Calif San Francisco, Benioff Childrens Hosp, Dept Orthoped Surg, Div Pediat Orthoped Surg, San Francisco, CA USA.
   [Brar, Ravinder; Jagodzinski, Jason; Sabatini, Coleen] Univ Calif San Francisco, Benioff Childrens Hosp Oakland, Dept Orthoped Surg, Div Pediat Orthoped Surg, Oakland, CA USA.
   [Courtier, Jesse] Univ Calif San Francisco, Benioff Childrens Hosp, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA.
C3 University of California System; University of California San Francisco;
   University of California System; University of California San Francisco;
   University of California System; University of California San Francisco;
   UCSF Medical Center; UCSF Benioff Children's Hospital Oakland;
   University of California System; University of California San Francisco
RP Courtier, J (corresponding author), Univ Calif San Francisco, Benioff Childrens Hosp, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA.
EM jesse.courtier@ucsf.edu
FU Clinical and Translational Science Institute (CTSI); UCSF Catalyst
   Program of Innovation Ventures Fund [5018, 2001449]
FX This work was funded by the Clinical and Translational Science Institute
   (CTSI) and UCSF Catalyst Program of Innovation Ventures Fund #5018,
   Project #2001449.
CR Abzug JM, 2012, J AM ACAD ORTHOP SUR, V20, P69, DOI 10.5435/JAAOS-20-02-069
   arrs, 2019, ORAL SCI ED ABSTRACT
   Atesok K, 2010, J AM ACAD ORTHOP SUR, V18, P247, DOI 10.5435/00124635-201005000-00001
   Childers CP, 2018, JAMA SURG, V153, DOI 10.1001/jamasurg.2017.6233
   Citak M, 2008, J ORTHOP RES, V26, P547, DOI 10.1002/jor.20517
   Elmi-Terander A, 2016, SPINE, V41, pE1303, DOI 10.1097/BRS.0000000000001830
   Fotouhi J, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021205
   Frankle MA, 2003, J ORTHOP TRAUMA, V17, P473, DOI 10.1097/00005131-200308000-00001
   Handelsman JE, 2006, J PEDIATR ORTHOP B, V15, P194, DOI 10.1097/01.bpb.0000194440.75378.97
   Hassani H, 2014, J ARTHROPLASTY, V29, P1273, DOI 10.1016/j.arth.2013.12.033
   Houshian S, 2001, J Orthop Sci, V6, P312, DOI 10.1007/s007760100024
   Howard A, 2012, J AM ACAD ORTHOP SUR, V20, P320, DOI 10.5435/JAAOS-20-05-320
   Hsu AR, 2012, ORTHOPEDICS, V35, pE1596, DOI 10.3928/01477447-20121023-15
   Jacobs Stephan, 2008, Interact Cardiovasc Thorac Surg, V7, P6, DOI 10.1510/icvts.2007.156588
   Koh KH, 2010, J PEDIATR ORTHOPED, V30, P425, DOI 10.1097/BPO.0b013e3181df1578
   Leet AI, 2002, J PEDIATR ORTHOPED, V22, P203, DOI 10.1097/00004694-200203000-00014
   Lethaus B, 2012, J CRANIO MAXILL SURG, V40, P43, DOI 10.1016/j.jcms.2011.01.007
   Macario A, 2010, J CLIN ANESTH, V22, P233, DOI 10.1016/j.jclinane.2010.02.003
   Mehlman CT, 2001, J BONE JOINT SURG AM, V83A, P323, DOI 10.2106/00004623-200103000-00002
   Oishi M, 2013, J NEUROSURG, V119, P94, DOI 10.3171/2013.3.JNS121109
   Park DY, 2017, J ORTHOP TRAUMA, V31, pE340, DOI 10.1097/BOT.0000000000000914
   Ramachandran M, 2008, J BONE JOINT SURG BR, V90B, P1228, DOI 10.1302/0301-620X.90B9.20728
   Sasso RC, 2007, J SPINAL DISORD TECH, V20, P118, DOI 10.1097/01.bsd.0000211263.13250.b1
   Schepers RH, 2016, J CRANIO MAXILL SURG, V44, P392, DOI 10.1016/j.jcms.2015.12.008
   Schepers RH, 2015, J CRANIO MAXILL SURG, V43, P649, DOI 10.1016/j.jcms.2015.03.015
   Shippert R., 2005, AM J COSMETIC SURG, V22, P25, DOI DOI 10.1177/074880680502200104
   Teber D, 2009, EUR UROL, V56, P332, DOI 10.1016/j.eururo.2009.05.017
   Vávra P, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4574172
   Wake N, 2020, UROLOGY, V143, P20, DOI 10.1016/j.urology.2020.03.066
   Wicky S, 2000, EUR RADIOL, V10, P1227, DOI 10.1007/s003300000326
   Yu AW, 2015, ADV ORTHOP, V2015, DOI 10.1155/2015/617046
   Zhang XR, 2017, IEEE T BIO-MED ENG, V64, P1815, DOI 10.1109/TBME.2016.2624632
   Zhang YZ, 2011, INT J MED ROBOT COMP, V7, P469, DOI 10.1002/rcs.423
NR 33
TC 4
Z9 4
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD NOV 26
PY 2020
VL 1
AR 528810
DI 10.3389/frvir.2020.528810
PG 11
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L9GD7
UT WOS:001026266800001
OA gold
DA 2024-07-18
ER

PT J
AU Persky, S
   Dolwick, AP
AF Persky, Susan
   Dolwick, Alexander P. P.
TI Olfactory Perception and Presence in a Virtual Reality Food Environment
SO FRONTIERS IN VIRTUAL REALITY
LA English
DT Article
DE virtual reality; olfaction; presence; food behavior; sensory input;
   scent
ID EXPOSURE; SENSE; ODORS; TECHNOLOGY; APPETITE; IMPACT
AB Virtual reality (VR)'s effectiveness as a medium for training, education, research, and entertainment, is based in large part on the fact that users can be deeply immersed and feel present within virtual environments. Olfaction has received less attention regarding its ability to add realism to VR environments. It is important to investigate under which circumstances olfactory stimuli are likely to add to user experience and help achieve the goals of VR applications. This study examined the role of scent in a VR-based buffet restaurant environment. French fry scented oil was administered while participants made a plate of food in the VR Buffet. Participants were asked afterwards to report on smells they perceived. Only 18% of participants perceived the olfactory stimulus, 78% of whom correctly identified it. Perceiving the olfactory stimulus was associated with higher levels of presence in the VR Buffet. Correctly identifying the olfactory stimulus was associated with heightened presence and increased likelihood of choosing french fries from the VR Buffet. These results demonstrate the potential for variability in scent perception and related user experience in VR. Additionally, this study highlights a need for future research into factors that underlie and moderate olfactory perception in VR environments.
C1 [Persky, Susan; Dolwick, Alexander P. P.] NHGRI, Social & Behav Res Branch, Bethesda, MD 20894 USA.
C3 National Institutes of Health (NIH) - USA; NIH National Human Genome
   Research Institute (NHGRI)
RP Persky, S (corresponding author), NHGRI, Social & Behav Res Branch, Bethesda, MD 20894 USA.
EM perskys@mail.nih.gov
FU Intramural Research Program of the National Human Genome Research
   Institute [z01-HG200384-08]
FX This study was supported by the Intramural Research Program of the
   National Human Genome Research Institute (z01-HG200384-08).
CR Baus O, 2019, BEHAV INFORM TECHNOL, V38, P1369, DOI 10.1080/0144929X.2019.1590458
   Baus O, 2017, VIRTUAL REAL-LONDON, V21, P59, DOI 10.1007/s10055-016-0299-3
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bradford KD, 2009, J BUS ETHICS, V90, P141, DOI 10.1007/s10551-010-0377-5
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   de Groot JHB, 2020, BEHAV RES METHODS, V52, P1657, DOI 10.3758/s13428-019-01341-y
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Egan D., 2017, P 2 INT WORKSH MULT, P15, DOI [https://doi.org/10.1145/3132361.3132363, DOI 10.1145/3132361.3132363]
   Ferriday D, 2008, BRIT J NUTR, V100, P1325, DOI 10.1017/S0007114508978296
   Forster S, 2018, PSYCHOL SCI, V29, P1642, DOI 10.1177/0956797618781325
   Fox J, 2009, PRESENCE-TELEOP VIRT, V18, P294, DOI 10.1162/pres.18.4.294
   Gaillet-Torrent M, 2014, APPETITE, V76, P17, DOI 10.1016/j.appet.2014.01.009
   Kober SE, 2012, INT J HUM-COMPUT ST, V70, P577, DOI 10.1016/j.ijhcs.2012.03.004
   Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959
   Li BJ, 2017, PRESENCE-TELEOP VIRT, V26, P337, DOI [10.1162/PRES_a_00300, 10.1162/pres_a_00300]
   Munyan BG, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157568
   Narciso D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3380903
   Parsons TD, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7040042
   Persky S., IN PRESS
   Persky S, 2019, TRANSL BEHAV MED, V9, P1040, DOI 10.1093/tbm/ibz068
   Persky S, 2018, APPETITE, V123, P201, DOI 10.1016/j.appet.2017.12.007
   Proserpio C, 2017, PHYSIOL BEHAV, V174, P35, DOI 10.1016/j.physbeh.2017.02.042
   Ramaekers MG, 2014, INT J OBESITY, V38, P650, DOI 10.1038/ijo.2013.143
   Ranasinghe N, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174151
   Schubert T., 1999, VISUAL REPRESENTATIO, P269, DOI [DOI 10.1007/978-1-4471-0563-3_30, 10.1007/978-1-4471-0563-3_30]
   Seo HS, 2010, APPETITE, V54, P544, DOI 10.1016/j.appet.2010.02.011
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Spence C, 2017, INT J HUM-COMPUT ST, V107, P62, DOI 10.1016/j.ijhcs.2017.06.003
   Willander J, 2007, MEM COGNITION, V35, P1659, DOI 10.3758/BF03193499
   Zoon HFA, 2016, FOODS, V5, DOI 10.3390/foods5010012
NR 31
TC 10
Z9 10
U1 4
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2673-4192
J9 FRONT VIRTUAL REAL
JI Front. Virtual Real.
PD SEP 28
PY 2020
VL 1
AR 571812
DI 10.3389/frvir.2020.571812
PG 8
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA L9FO8
UT WOS:001026251800001
PM 37635709
OA gold, Green Accepted
DA 2024-07-18
ER

EF