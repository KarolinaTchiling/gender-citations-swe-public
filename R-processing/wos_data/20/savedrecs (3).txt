FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Zhao, DY
   Li, M
   Liu, YS
AF Zhao, Dengyang
   Li, Ming
   Liu, Yusheng
TI A novel application framework for self-supporting topology optimization
SO VISUAL COMPUTER
LA English
DT Article
DE Self-supporting; Topology optimization; Explicit quadratic constraints;
   Additive manufacturing; Discrete convolution
AB This paper presents an application framework that provides a complete process to design an optimizedself-supporting structure, ready to be fabricated via additive manufacturing without the usage of additionalsupportstructures. Such supports in general have to be created during the fabricating process so that the primary object can be manufactured layer by layer without collapse; this process is very time-consuming and waste of material. The main approach resolves this issue by formulating the self-supporting requirements as an explicit quadratic continuous constraint in a topology optimization problem, or specifically, requiring the number of unsupported elements (in terms of the sum of squares of their densities) to be zero. Under the formulation, the required sensitivity of the self-supporting constraint with respect to the design density can be derived straightforward and is only linearly dependent on the density of the element itself. In addition, a novel discrete convolution operator is particularly designed to detect the unsupported elements. The approach works for cases of general overhang angles, and the produced optimized structures have close target compliance to those of the reference structures obtained without considering the self-supporting constraint, as demonstrated by various 2D and 3D benchmark examples.
C1 [Zhao, Dengyang; Li, Ming; Liu, Yusheng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Li, M (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM liming@cad.zju.edu.cn
FU NSF of China [61872320]; National Key Research and Development Program
   [2016YFC1101302]; MIST of China
FX The valuable comments and suggestions from the anonymous reviewers are
   greatly appreciated. The work described in this paper is partially
   supported by the NSF of China (No. 61872320) and the National Key
   Research and Development Program (No. 2016YFC1101302) from the MIST of
   China.
CR Allaire G, 2017, J COMPUT PHYS, V351, P295, DOI 10.1016/j.jcp.2017.09.041
   [Anonymous], 2014, 15 AIAAISSMO MULTIDI, DOI [10.2514/6.2014-2036, DOI 10.2514/6.2014-2036]
   Bendse M P., 1989, Struct. Optim., V1, P193, DOI DOI 10.1007/BF01650949
   BENDSOE MP, 1988, COMPUT METHOD APPL M, V71, P197, DOI 10.1016/0045-7825(88)90086-2
   Brackett D., 2011, P INT SOL FREEF FABR, P348, DOI DOI 10.1017/CBO9781107415324.004
   Dai CK, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201342
   Daniel T., 2009, DEV DESIGN RULES SEL
   Diaz A, 1995, STRUCT OPTIMIZATION, V10, P40, DOI 10.1007/BF01743693
   Dumas J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601153
   Garaigordobil A, 2018, STRUCT MULTIDISCIP O, V58, P2003, DOI 10.1007/s00158-018-2010-7
   Gaynor AT, 2016, STRUCT MULTIDISCIP O, V54, P1157, DOI 10.1007/s00158-016-1551-x
   Guest JK, 2004, INT J NUMER METH ENG, V61, P238, DOI 10.1002/nme.1064
   Guo X, 2014, COMPUT METHOD APPL M, V272, P354, DOI 10.1016/j.cma.2014.01.010
   Huang XD, 2010, STRUCT MULTIDISCIP O, V41, P671, DOI 10.1007/s00158-010-0487-9
   Hughes TJR, 2005, COMPUT METHOD APPL M, V194, P4135, DOI 10.1016/j.cma.2004.10.008
   Langelaar M, 2018, STRUCT MULTIDISCIP O, V57, P1985, DOI 10.1007/s00158-017-1877-z
   Langelaar M, 2017, STRUCT MULTIDISCIP O, V55, P871, DOI 10.1007/s00158-016-1522-2
   Langelaar M, 2016, ADDIT MANUF, V12, P60, DOI 10.1016/j.addma.2016.06.010
   Lee M, 2018, COMPUT AIDED DESIGN, V101, P23, DOI 10.1016/j.cad.2018.03.007
   Liu JK, 2016, ADV ENG SOFTW, V100, P161, DOI 10.1016/j.advengsoft.2016.07.017
   Majhi J, 1999, COMP GEOM-THEOR APPL, V12, P241, DOI 10.1016/S0925-7721(99)00003-6
   Mirzendehdel AM, 2016, COMPUT AIDED DESIGN, V81, P1, DOI 10.1016/j.cad.2016.08.006
   Qian XP, 2017, INT J NUMER METH ENG, V111, P247, DOI 10.1002/nme.5461
   Qian XP, 2013, COMPUT METHOD APPL M, V265, P15, DOI 10.1016/j.cma.2013.06.001
   Serphos MR, 2014, 2014011 EM DELFT U T
   Sigmund O, 2001, STRUCT MULTIDISCIP O, V21, P120, DOI 10.1007/s001580050176
   Sigmund O, 2006, TOPOLOGY OPTIMIZATIO, DOI 10.1007/1-4020-5370-3_497
   Sigmund O, 2013, STRUCT MULTIDISCIP O, V48, P1031, DOI 10.1007/s00158-013-0978-6
   van Dijk NP, 2013, STRUCT MULTIDISCIP O, V48, P437, DOI 10.1007/s00158-013-0912-y
   Wang MY, 2003, COMPUT METHOD APPL M, V192, P227, DOI 10.1016/S0045-7825(02)00559-5
   Wang WM, 2018, IEEE T VIS COMPUT GR, V24, P2787, DOI 10.1109/TVCG.2017.2764462
   Wang WM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508382
   Wu J, 2018, COMPUT AIDED DESIGN, V102, P72, DOI 10.1016/j.cad.2018.04.008
   Wu J, 2016, COMPUT AIDED DESIGN, V80, P32, DOI 10.1016/j.cad.2016.07.006
   XIE YM, 1993, COMPUT STRUCT, V49, P885, DOI 10.1016/0045-7949(93)90035-C
   Xie Y, 2017, VIS INFORM, V1, P9, DOI 10.1016/j.visinf.2017.01.002
NR 36
TC 13
Z9 14
U1 2
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2021
VL 37
IS 5
BP 1169
EP 1184
DI 10.1007/s00371-020-01860-2
EA JUN 2020
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV2QF
UT WOS:000542515600001
DA 2024-07-18
ER

PT J
AU Abbass, MY
   Kwon, KC
   Kim, N
   Abdelwahab, SA
   EI-Samie, FEA
   Khalaf, AAM
AF Abbass, Mohammed Y.
   Kwon, Ki-Chul
   Kim, Nam
   Abdelwahab, Safey A.
   EI-Samie, Fathi E. Abd
   Khalaf, Ashraf A. M.
TI A survey on online learning for visual tracking
SO VISUAL COMPUTER
LA English
DT Article
DE Object tracking; Convolutional neural networks; Online learning; Deep
   learning; Real-time computer vision; Particle filter
ID OBJECT TRACKING; ROBUST TRACKING; TENSOR SUBSPACE; RECOGNITION;
   NETWORKS; MODEL; SEGMENTATION; FEATURES
AB Visual object tracking has become one of the most active research topics in computer vision, which has been growing in commercial development as well as academic research. Many visual trackers have been proposed in the last two decades. Recent studies of computer vision for dynamic scenes include motion detection, object classification, environment modeling, tracking of moving objects, understanding of object behaviors, object identification, and data fusion from multiple sensors. This paper provides an in-depth overview of recent object tracking research. Object tracking tasks in realistic scenario often face challenging problems such as camera motion, occlusion, illumination effect, clutter, and similar appearance. A variety of tracker techniques have been published, which combine multiple techniques to solve multiple visual tracking sub-problems. This paper also reviews the latest research trend in object tracking based on convolutional neural networks, which is receiving growing attention. Finally, the paper discusses the future challenges and research directions for the object tracking problems that still need extensive studies in coming years.
C1 [Abbass, Mohammed Y.; Kwon, Ki-Chul; Kim, Nam] Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju 28644, South Korea.
   [Abbass, Mohammed Y.; Abdelwahab, Safey A.] Atom Energy Author, Engn Dept, Nucl Res Ctr, Cairo, Egypt.
   [EI-Samie, Fathi E. Abd] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Khalaf, Ashraf A. M.] Minia Univ, Fac Engn, Elect & Commun Dept, Al Minya, Egypt.
   [EI-Samie, Fathi E. Abd] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh, Saudi Arabia.
C3 Chungbuk National University; Egyptian Knowledge Bank (EKB); Egyptian
   Atomic Energy Authority (EAEA); Egyptian Knowledge Bank (EKB); Menofia
   University; Egyptian Knowledge Bank (EKB); Minia University; Princess
   Nourah bint Abdulrahman University
RP Kim, N (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju 28644, South Korea.
EM myehiaa@yahoo.com; kwon@osp.chungbuk.ac.kr; namkim@chungbuk.ac.kr;
   safeyash@yahoo.com; fathi_sayed@yahoo.com; ashkhalaf@yahoo.com
RI Khalaf, Ashraf ِA. M./X-8289-2018
OI Khalaf, Ashraf ِA. M./0000-0003-3344-5420
FU National Research Foundation of Korea (NRF) under the ITRC (Information
   Technology Research Center) support program - Korea Government
   [NRF-2018R1D1A3B07044041, IITP-2020-2015-0-00448]; National Research
   Foundation of Korea (NRF) under Industrial Technology Innovation Program
   - Korea Government [20002655]
FX This work was supported by the National Research Foundation of Korea
   (NRF) (No. NRF-2018R1D1A3B07044041), under the ITRC (Information
   Technology Research Center) support program supervised by the IITP
   (Institute for Information & communications Technology Promotion)
   (IITP-2020-2015-0-00448), and under Industrial Technology Innovation
   Program (No.20002655), grant funded by Korea Government.
CR Abbas Q, 2019, ARTIF INTELL REV, V52, P39, DOI 10.1007/s10462-018-9633-3
   ABBASS MY, 2020, VISUAL COMPUT 0418
   Ai-Qadi IL, 2008, TRANSPORT RES REC, P102, DOI 10.3141/2045-12
   [Anonymous], 2015, CORR
   [Anonymous], 2009, P BRIT MACH VIS C BM
   [Anonymous], 2015, Advances in neural information processing systems
   Avidan S, 2005, PROC CVPR IEEE, P494
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   BAHDANAU D, CLIN ORTHOPAEDICS RE
   BASU A, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, P3107, DOI 10.1109/ICSMC.1995.538259
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bora K, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010068
   Boult T., 1998, P DARPA IMAGE UNDERS, P305
   Chen F, 2011, IMAGE VISION COMPUT, V29, P787, DOI 10.1016/j.imavis.2011.08.006
   Chen K, 2017, INT J ADV MANUF TECH, V91, P1697, DOI 10.1007/s00170-016-9884-6
   Chiverton J, 2012, IEEE T IMAGE PROCESS, V21, P1231, DOI 10.1109/TIP.2011.2167343
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Foresti GL, 2005, LECT NOTES COMPUT SC, V3617, P1198, DOI 10.1007/11553595_147
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Fussenegger M, 2009, IMAGE VISION COMPUT, V27, P1157, DOI 10.1016/j.imavis.2008.10.014
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gordon D., 2017, Re3: Real-time recurrent regression networks for object tracking
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gress O, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P374, DOI 10.1109/ISBI.2012.6235562
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Han XL, 2016, WIL SER MASS SPECTR, P3
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Jepson AD, 2001, PROC CVPR IEEE, P415
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Zdenek, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1417, DOI 10.1109/ICCVW.2009.5457446
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Karasulu B, 2011, MULTIMED TOOLS APPL, V55, P677, DOI 10.1007/s11042-010-0591-2
   Kemeny SE, 1997, IEEE T CIRC SYST VID, V7, P575, DOI 10.1109/76.611169
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P122, DOI 10.1109/76.988659
   Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075
   Kuai YL, 2019, INFORM SCIENCES, V503, P169, DOI 10.1016/j.ins.2019.07.004
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KC, 2005, PROC CVPR IEEE, P852
   Leistner C., 2008, IEEE COMPUTER VISION, P1, DOI DOI 10.1109/CVPR.2008.4587629
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li GR, 2008, IEEE IMAGE PROC, P1568, DOI 10.1109/ICIP.2008.4712068
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li W, 2012, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2012.6247949
   LI X, 2017, LECT NOTES COMPUTER
   Li X, 2007, IEEE I CONF COMP VIS, P960
   Li XB, 2008, CAN J EDUC ADM POLIC, P1
   Li YF, 2007, CHEM COMMUN, P254, DOI 10.1039/b611256k
   Lim Jongwoo., 2005, Advances in Neural Information Processing Systems, P793
   LIN R., 2004, ADV NEURAL INFORM PR, P801
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu Q, 2014, IET COMPUT VIS, V8, P419, DOI 10.1049/iet-cvi.2013.0134
   Liu XB, 2011, IEEE T CIRC SYST VID, V21, P1588, DOI 10.1109/TCSVT.2011.2129410
   Lu G, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P29, DOI 10.1109/CW.2009.22
   Lu K, 2013, NEUROCOMPUTING, V120, P45, DOI 10.1016/j.neucom.2012.08.053
   Lu XQ, 2013, PATTERN RECOGN, V46, P1762, DOI 10.1016/j.patcog.2012.11.016
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   MIAN AS, 2008, DIGITAL IMAGE COMPUT
   NGHIEM A, 2007, IEEE INT C ADV VID S, DOI DOI 10.1109/AVSS.2007.4425357
   Nguyen HT, 2004, LECT NOTES COMPUT SC, V3022, P446
   Padmanabhan J, 2015, IETE TECH REV, V32, P240, DOI 10.1080/02564602.2015.1010611
   Ramírez-Quintana JA, 2012, ENG LET, V20, P68
   Ross D., 2004, Proceedings ofEuropean Conference on Computer Vision, V2, p p, P470
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   SIDLA O, 2006, IEEE INT C VID SIGN
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Stern H, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P249, DOI 10.1109/AFGR.2002.1004162
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tu JL, 2006, LECT NOTES COMPUT SC, V3851, P694
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang JY, 2005, PROC CVPR IEEE, P1037
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang XY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON AUTOMATICA (ICA-ACCA)
   Wang Y, 2000, 29TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P95, DOI 10.1109/AIPRW.2000.953609
   Wen J, 2009, IEEE SYS MAN CYBERN, P3688, DOI 10.1109/ICSMC.2009.5346874
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2009, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2009.5459369
   Wu ZZ, 2015, INT CONF ACOUST SPEE, P4460, DOI 10.1109/ICASSP.2015.7178814
   Xu YL, 2012, IEEE IMAGE PROC, P389, DOI 10.1109/ICIP.2012.6466877
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P830, DOI 10.1109/TMM.2020.2966830
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang HX, 2010, LECT NOTES COMPUT SC, V6454, P687, DOI 10.1007/978-3-642-17274-8_67
   Yin ZZ, 2009, PROC CVPR IEEE, P731, DOI 10.1109/CVPRW.2009.5206674
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang L, 2006, PROCEEDINGS OF THE 18TH IASTED INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING AND SYSTEMS, P698
   Zhang XQ, 2007, IEEE I CONF COMP VIS, P1602, DOI 10.1109/ICCV.2007.4409034
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
   Zhu G, 2016, IEEE COMPUT SOC CONF, P1265, DOI 10.1109/CVPRW.2016.160
   Zhu YK, 2007, J CHEM RES, P662, DOI 10.3184/030823407X266243
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
   Zu H, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1035, DOI 10.1109/WCICA.2014.7052859
NR 123
TC 45
Z9 47
U1 2
U2 54
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2021
VL 37
IS 5
BP 993
EP 1014
DI 10.1007/s00371-020-01848-y
EA MAY 2020
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV2QF
UT WOS:000533063400002
DA 2024-07-18
ER

PT J
AU Zhang, WC
   Du, YZ
   Chen, Z
   Deng, JH
   Liu, PZ
AF Zhang, Wancheng
   Du, Yongzhao
   Chen, Zhi
   Deng, Jianhua
   Liu, Peizhong
TI Robust adaptive learning with Siamese network architecture for visual
   tracking
SO VISUAL COMPUTER
LA English
DT Article
DE Visual tracking; Siamese network; Adaptive feature fusion; Model update
ID OBJECT TRACKING; FEATURES
AB Correlation filters and deep learning methods are the two main directions in the research field of visual object tracking. However, these trackers do not balance accuracy and speed very well at the same time. The application of the Siamese networks brings great improvement in accuracy and speed, and an increasing number of researchers are paying attention to this aspect. Therefore, based on the advantages of the Siamese networks model, we conduct feasibility research and improvement of current visual tracking algorithms to improve the tracking performance. In this paper, we propose a robust adaptive learning visual tracking algorithm. HOG features, CN features and deep convolution features are extracted from the template frame and search region frame, respectively, and we analyze the merits of each feature and perform feature adaptive fusion to improve the validity of feature representation. Then, we update the two branch models with two learning change factors and realize a more similar match to locate the target. Besides, we propose a model update strategy that employs the average peak-to-correlation energy (APCE) to determinate whether to update the learning change factors to improve the accuracy of tracking model and reduce the tracking drift in the case of tracking failure, deformation or background blur, etc. Extensive experiments on the benchmark datasets (OTB-50, OTB-100, VOT2016) demonstrate that the proposed visual tracking algorithm is superior to several state-of-the-art methods in terms of accuracy and robustness.
C1 [Zhang, Wancheng; Du, Yongzhao; Chen, Zhi; Liu, Peizhong] Huaqiao Univ, Coll Engn, Quanzhou 362021, Peoples R China.
   [Deng, Jianhua] ZhongfangHongye Informat Technol Corp, Quanzhou 362021, Peoples R China.
C3 Huaqiao University
RP Liu, PZ (corresponding author), Huaqiao Univ, Coll Engn, Quanzhou 362021, Peoples R China.
EM wancheng_z@126.com; yongzhaodu@126.com; marico2018@163.com;
   jh_deng@uestc.edu.cn; pzliu@hqu.edu.cn
OI Liu, Peizhong/0000-0001-8785-0195
FU Promotion Program for Young and Middle-aged Teacher in Science and
   Technology Research of Huaqiao University [ZQN-PY518]; National Natural
   Science Foundation of China [61605048]; Fujian Provincial Big Data
   Research Institute of Intelligent Manufacturing; Quanzhou scientific and
   technological planning projects [2017G024, 2018N072S, 2019C099R];
   Subsidized Project for Postgraduates' Innovative Fund in Scientific
   Research of Huaqiao University [17014084014]
FX This work was supported by Promotion Program for Young and Middle-aged
   Teacher in Science and Technology Research of Huaqiao University (No.
   ZQN-PY518), and the grants from National Natural Science Foundation of
   China (No. 61605048), in part by Fujian Provincial Big Data Research
   Institute of Intelligent Manufacturing, in part by the Quanzhou
   scientific and technological planning projects (Nos. 2017G024, 2018N072S
   and 2019C099R), and in part by the Subsidized Project for Postgraduates'
   Innovative Fund in Scientific Research of Huaqiao University under Grant
   17014084014.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   [Anonymous], 2018, IEEE T PATTERN ANAL
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen Z, 2018, INFORMATION, V9, DOI 10.3390/info9100241
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heinrich S, 2019, NEUROCOMPUTING, V342, P137, DOI 10.1016/j.neucom.2018.10.086
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Khan FS, 2013, INT J COMPUT VISION, V105, P205, DOI 10.1007/s11263-013-0633-0
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee KH, 2015, IEEE T MULTIMEDIA, V17, P1429, DOI 10.1109/TMM.2015.2455418
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin Luyue, 2019, NEUROCOMPUTING
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Makhura OJ, 2019, SIGNAL PROCESS-IMAGE, V74, P153, DOI 10.1016/j.image.2019.02.009
   Peters J, 2017, ADAPT COMPUT MACH LE
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2
   Sharma VK, 2019, DIGIT SIGNAL PROCESS, V95, DOI 10.1016/j.dsp.2019.08.002
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tang JP, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2953560
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tu B, 2019, J VIS COMMUN IMAGE R, V60, P64, DOI 10.1016/j.jvcir.2019.01.032
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang Q., 2017, arXiv preprint arXiv:1704.04057
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu H, 2017, IEEE INT C COMPUT, P740, DOI 10.1109/CSE-EUC.2017.145
   Yang TY, 2017, IEEE INT CONF COMP V, P2010, DOI 10.1109/ICCVW.2017.235
   Yip YNZ, 2017, 2017 18TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P1011, DOI 10.1109/ICEPT.2017.8046614
   Zhang SR, 2018, INT SYMP COMP CONS, P221, DOI 10.1109/IS3C.2018.00063
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang WC, 2019, ALGORITHMS, V12, DOI 10.3390/a12010008
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
   Zhu ZY, 2018, IEEE INT CONF COMM
NR 55
TC 17
Z9 18
U1 1
U2 33
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2021
VL 37
IS 5
BP 881
EP 894
DI 10.1007/s00371-020-01839-z
EA APR 2020
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV2QF
UT WOS:000523110400001
DA 2024-07-18
ER

PT J
AU Golec, K
   Palierne, JF
   Zara, F
   Nicolle, S
   Damiand, G
AF Golec, K.
   Palierne, J-F
   Zara, F.
   Nicolle, S.
   Damiand, G.
TI Hybrid 3D mass-spring system for simulation of isotropic materials with
   any Poisson's ratio
SO VISUAL COMPUTER
LA English
DT Article
DE Physical simulation; Mass-spring system; Isotropic material
ID ELASTICITY; MODELS
AB Mass-spring systems (MSS) simulating elastic materials obey constraints known in elasticity as the Cauchy relations, restricting the Poisson ratio of isotropic systems to be exactly nu=1/4. We remind that this limitation is intrinsic to centrosymmetric spring systems (where each node is a center of symmetry), forbidding them for instance to simulate incompressible materials (with nu=1/2). To overcome this restriction, we propose to supplement the spring deformation energy with an energy depending on the volume only, insensitive to change of shape, permitting MSS to simulate any real isotropic materials. In addition, the freedom in choosing the spring constants realizing a given elastic behavior allows to manage instabilities. The proposed hybrid model is evaluated by comparing its response to various deformation geometries with analytical model and/or finite element model. The results show that the hybrid MSS model allows to simulate any compressible isotropic elastic material and in particular the nearly incompressible (Poisson ratio nu similar or equal to 1/2) biological soft tissues to which it is dedicated.
C1 [Golec, K.; Zara, F.; Damiand, G.] Univ Lyon 1, Univ Lyon, CNRS, LIRIS,UMR5205, F-69622 Lyon, France.
   [Palierne, J-F] Univ Lyon 1, Univ Lyon, Ecole Normale Super Lyon, Lab Phys,CNRS,UMR5672, Lyon, France.
   [Nicolle, S.] Univ Claude Bernard Lyon 1, Univ Lyon, IFSTTAR, LBMC UMR T9406, F-69622 Lyon, France.
C3 Universite Claude Bernard Lyon 1; Centre National de la Recherche
   Scientifique (CNRS); Institut National des Sciences Appliquees de Lyon -
   INSA Lyon; Universite Claude Bernard Lyon 1; Universite Paris Cite;
   Centre National de la Recherche Scientifique (CNRS); CNRS - Institute of
   Physics (INP); Ecole Normale Superieure de Lyon (ENS de LYON);
   Universite Gustave-Eiffel; Universite Claude Bernard Lyon 1
RP Zara, F (corresponding author), Univ Lyon 1, Univ Lyon, CNRS, LIRIS,UMR5205, F-69622 Lyon, France.
EM florence.zara@univ-lyon1.fr
RI Nicolle, Stéphane/H-2908-2018; Damiand, Guillaume/IAM-8662-2023
OI Nicolle, Stéphane/0000-0001-9365-4027; Zara,
   Florence/0000-0002-0118-7204; Damiand, Guillaume/0000-0003-1580-5517
FU LABEX PRIMES of Universite de Lyon, within the program "Investissements
   d'Avenir" [ANR-11-LABX-0063, ANR-11-IDEX-0007]
FX This work was supported by the LABEX PRIMES (ANR-11-LABX-0063) of
   Universite de Lyon, within the program "Investissements d'Avenir"
   (ANR-11-IDEX-0007) operated by the French National Research Agency
   (ANR). The authors would like to thank for support of E. Flechon for
   providing the original version of TopoSim (software implementing the
   LCC+MSS model).
CR Arnab S, 2008, GEOMETRIC MODELING & IMAGING: MODERN TECHNIQUES AND APPLICATIONS, P21, DOI 10.1109/GMAI.2008.24
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Baudet V, 2009, WSCG 2009, FULL PAPERS PROCEEDINGS, P145
   Bender J., 2013, STAR P EUR
   Bourguignon D, 2000, SPRING COMP SCI, P113
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Cauchy A.L, 1828, EXERCICES MATH, V3, P1882
   Cauchy A.L., OEUVRES COMPLETES 2, P1882
   Chen Y, 1998, COMP ANIM CONF PROC, P154, DOI 10.1109/CA.1998.681920
   de Saint-Venant A.J.C.B, 1855, MEMOIRES PRESENTES D
   Diziol Raphael., 2011, Proceedings of the 2011 ACM SIGGRAPH/eurographics symposium on computer animation, P237, DOI DOI 10.1145/2019406.2019438
   Duan YP, 2016, IEEE J BIOMED HEALTH, V20, P268, DOI 10.1109/JBHI.2014.2370059
   Elcoro L, 2011, EUR J PHYS, V32, P25, DOI 10.1088/0143-0807/32/1/003
   Hallquist J.O., 2006, LS-DYNA theory manual, V3
   Huang K., 1954, DYNAMICAL THEORY CRY
   Jarrousse O, 2010, IMPLICIT TIME INTEGR, P876
   KEATING PN, 1966, PHYS REV, V152, P774, DOI 10.1103/PhysRev.152.774
   KEATING PN, 1966, PHYS REV, V145, P637, DOI 10.1103/PhysRev.145.637
   Kirkwood JG, 1939, J CHEM PHYS, V7, P506, DOI 10.1063/1.1750479
   Kot Maciej, 2015, Proceedings of the 10th International Conference on Computer Graphics Theory and Applications (GRAPP 2015), P138
   Kot M, 2017, VISUAL COMPUT, V33, P283, DOI 10.1007/s00371-015-1194-8
   Kot M, 2015, VISUAL COMPUT, V31, P1339, DOI 10.1007/s00371-014-1015-5
   Lifshitz E, 1986, THEORY ELASTICITY
   Lloyd BA, 2007, IEEE T VIS COMPUT GR, V13, P1081, DOI 10.1109/TVCG.2007.1055
   Marchal M., 2006, THESIS
   Mollemans W, 2003, TETRAHEDRAL MASS SPR, P145
   Natsupakpong S, 2010, GRAPH MODELS, V72, P61, DOI 10.1016/j.gmod.2010.10.001
   Niiranen J., 1999, 6th International Conference of Electromechanics, V1, P71, DOI [10.13140/2.1.4663.0080, DOI 10.13140/2.1.4663.0080]
   Ostoja-Starzewski M, 1996, COMP MATER SCI, V7, P82, DOI 10.1016/S0927-0256(96)00064-X
   SAHIMI M, 1993, PHYS REV B, V47, P703, DOI 10.1103/PhysRevB.47.703
   San-Vicente G, 2012, IEEE T VIS COMPUT GR, V18, P228, DOI 10.1109/TVCG.2011.32
   Terzopoulos D., 1991, Journal of Visualization and Computer Animation, V2, P68, DOI 10.1002/vis.4340020208
   Todhunter I, 2014, HIST THEORY ELASTICI
   Van Gelder A., 1998, Journal of Graphics Tools, V3, P21, DOI 10.1080/10867651.1998.10487490
   Vincente-Otamendi G.S.:, 2011, THESIS
NR 35
TC 14
Z9 14
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2020
VL 36
IS 4
BP 809
EP 825
DI 10.1007/s00371-019-01663-0
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KW0AL
UT WOS:000520835800012
DA 2024-07-18
ER

PT J
AU Zhu, XL
   Chen, ZJ
AF Zhu, Xiaoliang
   Chen, Zijian
TI Dual-modality spatiotemporal feature learning for spontaneous facial
   expression recognition in e-learning using hybrid deep neural network
SO VISUAL COMPUTER
LA English
DT Article
DE Facial expression recognition; Spatiotemporal feature; Deep learning;
   Deep neural network; E-learning
ID EMOTION RECOGNITION; ENGAGEMENT; FUSION
AB Automatic facial expression recognition (FER) plays a crucial role in realizing the adaptable and individualized tutoring in affective computer-based learning environment. Although many research efforts have been conducted to enhance a greater understanding of FER, a successful accurate recognition of the spontaneous facial expressions in real e-learning environment is still challenging due to its low change in intensity and short duration. In this paper, we propose a new dual-modality spatiotemporal feature representation learning for recognizing facial expression in e-learning using the hybrid deep neural network. Except facial expression class information, representative expression states (e.g., onset, apex, offset of expressions) are utilized for expression recognition in our study. Spatiotemporal geometrical feature representations and spatial-temporal appearance feature representations are learned with a hybrid deep neural network. The dual-modality feature fusion representations are used to recognize facial expressions. The comprehensive experiments have been conducted on two spontaneous micro-expression datasets (CAS(ME)2 and CASME II). The experimental results showed that the proposed method achieved higher recognition accuracy compared to the state-of-the-art methods. Moreover, multiple metrics were adopted to provide more insight into the performance of the proposed method.
C1 [Zhu, Xiaoliang; Chen, Zijian] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.
   [Chen, Zijian] Guizhou Univ Finance & Econ, Sch Informat, Guiyang, Peoples R China.
C3 Central China Normal University; Guizhou University of Finance &
   Economics
RP Chen, ZJ (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.; Chen, ZJ (corresponding author), Guizhou Univ Finance & Econ, Sch Informat, Guiyang, Peoples R China.
EM zhuxl@mail.ccnu.edu.cn; czjsopoor@163.com
RI chen, zijian/KIH-1090-2024
OI Zhu, Xiaoliang/0000-0002-8493-1931; chen, zijian/0000-0002-6130-429X
FU National Key RAMP;D Program of China [2018Y-FB1004504]; Research
   Foundation of Humanities and Social Sciences of Ministry of Education of
   China [18YJAZH152]; Special Funding for Basic Scientific Research of
   Chinese Central University [CCNU18TS005]; Research Foundation of Guizhou
   University of Finance and Economics [2018XYB09]
FX This research has been supported by National Key R&D Program of China
   under Grant No.2018Y-FB1004504; Research Foundation of Humanities and
   Social Sciences of Ministry of Education of China No.18YJAZH152; Special
   Funding for Basic Scientific Research of Chinese Central University
   under Grant No. CCNU18TS005; and Research Foundation of Guizhou
   University of Finance and Economics under Grant No.2018XYB09.
CR Ali S., 2007, PROC 15 ACM INT C MU, P357
   [Anonymous], 2013, MED IMAGE COMPUTING
   Ballabio D, 2018, CHEMOMETR INTELL LAB, V174, P33, DOI 10.1016/j.chemolab.2017.12.004
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   Brawner KW, 2016, THEOR ISS ERGON SCI, V17, P183, DOI 10.1080/1463922X.2015.1111463
   Burkhardt F, 2007, P ISCA WORKSH SPEECH, V52, P119
   Butko N. J., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P382, DOI 10.1109/FG.2011.5771430
   Chen JH, 2017, SIGNAL IMAGE VIDEO P, V11, P1485, DOI 10.1007/s11760-017-1111-x
   Chen JH, 2015, INT CONF AFFECT, P636, DOI 10.1109/ACII.2015.7344636
   Chen Xinyun, 2017, ARXIV171205526
   Chen Y., 2015, INT C ED DAT MIN EDM
   D'Mello S., 2013, CHI '13 Extended Abstracts on Human Factors in Computing Systems, P2287, DOI [DOI 10.1145/2468356.2468751, 10.1145/2468356.2468751]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ekman P, 1982, EMOT HUM FACE
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Gunes H, 2016, IMAGE VISION COMPUT, V55, P6, DOI 10.1016/j.imavis.2016.03.013
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Isen AM, 2013, POSITIVE AFFECT DECI
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Kaliouby RE, 2004, REAL TIME VISION HUM
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kim BK, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2818346.2830590
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Lee SH, 2016, PATTERN RECOGN, V54, P52, DOI 10.1016/j.patcog.2015.12.016
   Li K, 2020, VISUAL COMPUT, V36, P391, DOI 10.1007/s00371-019-01627-4
   Lin KC, 2013, LIBR HI TECH, V31, P294, DOI 10.1108/07378831311329068
   Liu K, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P163, DOI 10.1109/CW.2016.34
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu Weifeng, 2011, Computer Engineering and Applications, V47, P149, DOI 10.3778/j.issn.1002-8331.2011.02.046
   Liu WY, 2016, PR MACH LEARN RES, V48
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   McDaniel B., 2007, Proceedings of the annual meeting of the cognitive science society
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Picard RW, 1997, AFFECT COMPUT
   Polikovsky S, 2013, IEICE T INF SYST, VE96D, P81, DOI 10.1587/transinf.E96.D.81
   Pons G, 2018, IEEE T AFFECT COMPUT, V9, P343, DOI 10.1109/TAFFC.2017.2753235
   Qu FB, 2018, IEEE T AFFECT COMPUT, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Ray A, 2016, EDUC TECHNOL SOC, V19, P112
   Ren FJ, 2015, IEEJ T ELECTR ELECTR, V10, P713, DOI 10.1002/tee.22151
   Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Shan K, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P123, DOI 10.1109/SERA.2017.7965717
   Simonyan K., 2014, 14091556 ARXIV
   Sun YX, 2017, NEUROCOMPUTING, V230, P397, DOI 10.1016/j.neucom.2016.12.043
   Tarnowski P, 2017, PROCEDIA COMPUT SCI, V108, P1175, DOI 10.1016/j.procs.2017.05.025
   Wang J., 2014, INT J SIGNAL PROCESS, V7, P349
   Wang SF, 2015, MACH VISION APPL, V26, P219, DOI 10.1007/s00138-015-0657-2
   Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang Y, 2014, COMPUTER VISION ACCV
   Wang YD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124674
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Wu Tingfan., 2010, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P42
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao JF, 2018, VISUAL COMPUT, V34, P1461, DOI 10.1007/s00371-018-1477-y
NR 68
TC 16
Z9 16
U1 0
U2 51
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2020
VL 36
IS 4
BP 743
EP 755
DI 10.1007/s00371-019-01660-3
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA KW0AL
UT WOS:000520835800007
DA 2024-07-18
ER

PT J
AU Irmak, EC
   Sahillioglu, Y
AF Irmak, Erdem Can
   Sahillioglu, Yusuf
TI 3D indirect shape retrieval based on hand interaction
SO VISUAL COMPUTER
LA English
DT Article
DE Indirect shape analysis; 3D shape retrieval; Leap Motion;
   Interaction-based shape analysis; Data Glove
ID RECOGNITION; DESCRIPTOR
AB In this work, we present a novel 3D indirect shape analysis method which successfully retrieves 3D shapes based on hand-object interaction. To this end, the human hand information is first transferred to the virtual environment by the Leap Motion controller. Position-, angle- and intersection-based novel features of the hand and fingers are used for this part. In the guidance of these features that define the way humans grab objects, a support vector machine (SVM) classifier is trained. Experiments validate that SVM results are useful for retrieval of 3D shapes. We also compare the retrieval performance of our method with an interaction-based indirect method based on the Data Glove controller as well as a direct method based on 3D shape distribution histograms. These comparisons reveal different advantages of our method, which are (i) being lower-cost and more accurate compared to the Data Glove, and (ii) being more discriminative compared to a direct approach. We finally note that our algorithm is rigid-motion invariant and able to explore databases of arbitrarily represented 3D shapes.
C1 [Irmak, Erdem Can] Middle East Tech Univ, Game Technol Dept, Ankara, Turkey.
   [Sahillioglu, Yusuf] Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
C3 Middle East Technical University; Middle East Technical University
RP Irmak, EC (corresponding author), Middle East Tech Univ, Game Technol Dept, Ankara, Turkey.
EM erdem.can.irmak@gmail.com; ys@ceng.metu.edu.tr
OI Sahillioglu, Yusuf/0000-0002-7997-4232
CR 5DT, 5DT DAT GLOV ULTR US
   Abbasi A, 2019, VISUAL COMPUT, V35, P271, DOI 10.1007/s00371-018-1586-7
   Bai S, 2017, IEEE T MULTIMEDIA, V19, P1257, DOI 10.1109/TMM.2017.2652071
   BAR-AVIV E., 2006, BRIT MACH VIS C, V32, P1
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Canterakis N., 1999, PROC 11 SCANDINAVIAN, P85
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Fan Q, 2018, VISUAL COMPUT, V34, P1145, DOI 10.1007/s00371-018-1546-2
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y., 2010, P INT C MULT MM, P947
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gibson J.J., 1977, Perceiving Acting and Knowing, P127
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hu JX, 2009, VISUAL COMPUT, V25, P667, DOI 10.1007/s00371-009-0340-6
   Hu RZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766914
   Jain V, 2007, COMPUT AIDED DESIGN, V39, P398, DOI 10.1016/j.cad.2007.02.009
   Kim VG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601117
   Lavoué G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x
   Leifman G, 2005, VISUAL COMPUT, V21, P865, DOI 10.1007/s00371-005-0341-z
   Li CY, 2013, VISUAL COMPUT, V29, P513, DOI 10.1007/s00371-013-0815-3
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Liu ZB, 2015, COMPUT GRAPH-UK, V46, P110, DOI 10.1016/j.cag.2014.09.038
   Mémoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Passalis G, 2007, VISUAL COMPUT, V23, P5, DOI 10.1007/s00371-006-0037-z
   Pickup D, 2018, GRAPH MODELS, V97, P17, DOI 10.1016/j.gmod.2018.02.002
   Qiu XY, 2010, CHIN CONTR CONF, P2171
   Reuter M., 2005, P 2005 ACM S SOLID P, P101, DOI DOI 10.1145/1060244.1060256
   Sahillioglu Y, 2017, IEEE COMPUT GRAPH, V37, P88, DOI 10.1109/MCG.2017.4031063
   Sahillioglu Y, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2893477
   Sahillioglu Y, 2015, COMPUT GRAPH-UK, V53, P156, DOI 10.1016/j.cag.2015.10.003
   Sahillioglu Y, 2012, IEEE T PATTERN ANAL, V34, P2203, DOI 10.1109/TPAMI.2012.26
   Shilane P, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P108
   Sipiran I, 2014, VISUAL COMPUT, V30, P1293, DOI 10.1007/s00371-014-0937-2
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Toldo R, 2010, VISUAL COMPUT, V26, P1257, DOI 10.1007/s00371-010-0519-x
   Wang P., 2017, INT J ROBUST NONLIN, V4, P1
   Xie J, 2015, PROC CVPR IEEE, P1275, DOI 10.1109/CVPR.2015.7298732
   Zheng YT, 2009, VISUAL COMPUT, V25, P13, DOI 10.1007/s00371-008-0294-0
   Zhu YK, 2014, LECT NOTES COMPUT SC, V8690, P408, DOI 10.1007/978-3-319-10605-2_27
NR 45
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2020
VL 36
IS 1
BP 5
EP 17
DI 10.1007/s00371-018-1597-4
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KJ3OJ
UT WOS:000511966800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xi, PC
   Guan, HT
   Shu, C
   Borgeat, L
   Goubran, R
AF Xi, Pengcheng
   Guan, Haitao
   Shu, Chang
   Borgeat, Louis
   Goubran, Rafik
TI An integrated approach for medical abnormality detection using deep
   patch convolutional neural networks
SO VISUAL COMPUTER
LA English
DT Article
DE Medical abnormality detection; Deep convolutional neural networks; Class
   activation mapping; Region proposal networks
ID COMPUTER-AIDED DIAGNOSIS; MICROCALCIFICATION CLUSTERS; CLASSIFICATION;
   LESIONS; MASS; FILTER
AB Computer-aided detection of abnormalities in medical images has clinical significance but remains a challenging research topic. Unlike object detection in natural images, the detection of medical abnormalities is unique because they often locate in tiny local regions within a high-resolution medical image. Traditional machine learning approaches build sliding windowbased detectors with manual features and are therefore limited on both efficiency and accuracy. Recent advances in deep learning shed new light on this problem, but applying it to medical image analysis faces challenges including insufficient data. Training deep convolutional neural networks (CNNs) directly on high-resolution images requires image compression at the input layer, which leads to the loss of information that is essential for medical abnormality detection. Therefore, instead of training on full images, the proposed approach first fine-tunes the pre-trained deep CNNs on image patches centered at medical abnormalities and then integrates them with class activation mappings and region proposal networks for building abnormality detectors. The deep patch classifier has been tested on a mammogram data set and achieved an overall classification accuracy of 92.53%, compared to 81.55% by a traditional approach using manual features. The integrated detector has been tested on an ultrasound liver image data set for abnormality detection and achieved an average precision of 0.60, outperforming both the sliding window-based approach of 0.16 and a deep learning YOLO model of 0.51. These validations suggest that the integrated approach has great potential for assisting doctors in detecting abnormalities from medical images.
C1 [Xi, Pengcheng; Goubran, Rafik] Carleton Univ, 1125 Colonel Dr, Ottawa, ON K1S 5B6, Canada.
   [Xi, Pengcheng; Shu, Chang; Borgeat, Louis] Natl Res Council Canada, 1200 Montreal Rd, Ottawa, ON K1A 0R6, Canada.
   [Guan, Haitao] Nantong 3 Peoples Hosp, 99 Qingnian Middle Rd, Nantong 226006, Jiangsu, Peoples R China.
C3 Carleton University; National Research Council Canada
RP Xi, PC (corresponding author), Carleton Univ, 1125 Colonel Dr, Ottawa, ON K1S 5B6, Canada.; Xi, PC (corresponding author), Natl Res Council Canada, 1200 Montreal Rd, Ottawa, ON K1A 0R6, Canada.; Guan, HT (corresponding author), Nantong 3 Peoples Hosp, 99 Qingnian Middle Rd, Nantong 226006, Jiangsu, Peoples R China.
EM pengcheng.xi@nrc-cnrc.gc.ca; happyght@qq.com; chang.shu@nrc-cnrc.gc.ca;
   louis.borgeat@nrc-cnrc.gc.ca; goubran@sce.carleton.ca
RI Xi, Pengcheng/N-9404-2019
OI Xi, Pengcheng/0000-0003-3236-5234
CR Arancibia Hernandez P.L., 2016, Rev. Chil. Radiol., V22, P80, DOI [DOI 10.1016/J.RCHIRA.2016.06.004, 10.1016/j.rchira.2016.06.004]
   Cascio D, 2006, IEEE T NUCL SCI, V53, P2827, DOI 10.1109/TNS.2006.878003
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Ciresan D., 2012, NIPS, P2843
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   GIRSHICK RB, 2015, ARXIV150408083 CORR
   Han S, 2017, PHYS MED BIOL, V62, P7714, DOI 10.1088/1361-6560/aa82ec
   Harirchi F., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P269, DOI 10.1109/ICPR.2010.75
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Kavitha K., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P405, DOI 10.1109/IWSSIP.2007.4381127
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Li HL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25005-7
   LI Y, 2016, J HLTH MED INF
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   MAZUROWSKI MA, 2018, ARXIV180208717 CORR
   Nakayama R, 2006, IEEE T BIO-MED ENG, V53, P273, DOI 10.1109/TBME.2005.862536
   Oliver A, 2012, KNOWL-BASED SYST, V28, P68, DOI 10.1016/j.knosys.2011.11.021
   Pal NR, 2008, NEUROCOMPUTING, V71, P2625, DOI 10.1016/j.neucom.2007.06.015
   Petrick N, 1996, IEEE T MED IMAGING, V15, P59, DOI 10.1109/42.481441
   PETROSIAN A, 1994, PHYS MED BIOL, V39, P2273, DOI 10.1088/0031-9155/39/12/010
   RAJPURKAR P, 2017, ARXIV171206957V3
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sa R, 2016, IEEE ENG MED BIO, P1054, DOI 10.1109/EMBC.2016.7590884
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   WANG X, 2017, ARXIV170502315 CORR
   XI P, 2018, P INT C PATT REC ART
   Xi W, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION, ELECTRONICS AND ELECTRICAL ENGINEERING (AUTEEE), P1, DOI 10.1109/AUTEEE.2018.8720814
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Zhang XS, 2012, ENG APPL ARTIF INTEL, V25, P1062, DOI 10.1016/j.engappai.2012.04.003
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 42
TC 30
Z9 31
U1 2
U2 25
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2020
VL 36
IS 9
BP 1869
EP 1882
DI 10.1007/s00371-019-01775-7
EA DEC 2019
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NA2KY
UT WOS:000541644600002
DA 2024-07-18
ER

PT J
AU Wang, Y
   Hu, SQ
   Wu, SD
AF Wang, Yong
   Hu, Shiqiang
   Wu, Shandong
TI Object tracking based on Huber loss function
SO VISUAL COMPUTER
LA English
DT Article
DE Object tracking; Subspace learning; Huber loss function; Alternating
   direction method of multipliers; Multi-task sparse learning
ID VISUAL TRACKING; ROBUST
AB In this paper we present a novel visual tracking algorithm, in which object tracking is achieved by using subspace learning and Huber loss regularization in a particle filter framework. The changing appearance of tracked target is modeled by principle component analysis basis vectors and row group sparsity. This method takes advantage of the strengths of subspace representation and explicitly takes the underlying relationship between particle candidates into consideration in the tracker. The representation of each particle is learned via the multi-task sparse learning method. Huber loss function is employed to model the error between candidates and templates, yielding robust tracking. We utilize the alternating direction method of multipliers to solve the proposed representation model. In experiments we tested sixty representative video sequences that reflect the specific challenges of tracking and used both qualitative and quantitative metrics to evaluate the performance of our tracker. The experiment results demonstrated that the proposed tracking algorithm achieves superior performance compared to nine state-of-the-art tracking methods.
C1 [Wang, Yong] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
   [Hu, Shiqiang] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
   [Wu, Shandong] Univ Pittsburgh, Dept Radiol, Pittsburgh, PA 15260 USA.
   [Wu, Shandong] Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15206 USA.
   [Wu, Shandong] Univ Pittsburgh, Dept Bioengn, Pittsburgh, PA 15213 USA.
   [Wu, Shandong] Univ Pittsburgh, Dept Intelligent Syst Comp Sci, Pittsburgh, PA 15260 USA.
C3 University of Ottawa; Shanghai Jiao Tong University; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); University of
   Pittsburgh; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of
   Higher Education (PCSHE); University of Pittsburgh; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); University of
   Pittsburgh
RP Wu, SD (corresponding author), Univ Pittsburgh, Dept Radiol, Pittsburgh, PA 15260 USA.; Wu, SD (corresponding author), Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15206 USA.; Wu, SD (corresponding author), Univ Pittsburgh, Dept Bioengn, Pittsburgh, PA 15213 USA.; Wu, SD (corresponding author), Univ Pittsburgh, Dept Intelligent Syst Comp Sci, Pittsburgh, PA 15260 USA.
EM wus3@upmc.edu
RI Wang, Zejun/KBB-8454-2024; TIAN, YI/KHU-9704-2024; Wu,
   Shandong/JHU-6628-2023
FU National Natural Science Foundation of China [61374161]; China Aviation
   Science Foundation [20142057006]; National Institutes of Health
   (NIH)/National Cancer Institute (NCI) R01 Grant [1R01CA193603]
FX This work was jointly supported by the National Natural Science
   Foundation of China (No. 61374161) and China Aviation Science Foundation
   (No. 20142057006). This work was also partially supported by a National
   Institutes of Health (NIH)/National Cancer Institute (NCI) R01 Grant
   (#1R01CA193603).
CR Adler A, 2015, J SIGNAL PROCESS SYS, V79, P179, DOI 10.1007/s11265-014-0913-0
   [Anonymous], MACH VIS APPL
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], 2010, PASCAL VISUAL OBJECT
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai YC, 2014, IEEE SIGNAL PROC LET, V21, P909, DOI 10.1109/LSP.2014.2320291
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Gong Pinghua, 2012, KDD, V2012, P895
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jalali Ali, 2010, ADV NEURAL INFORM PR, P964
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154
   Mei X, 2013, IEEE T IMAGE PROCESS, V22, P2661, DOI 10.1109/TIP.2013.2255301
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Quattoni A., 2009, P 26 ANN INT C MACH, P857, DOI DOI 10.1145/1553374.1553484
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sun DL, 2014, INT CONF ACOUST SPEE
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang T., 2012, IEEE C COMPUTER VISI, P1
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
NR 38
TC 7
Z9 7
U1 0
U2 29
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD NOV
PY 2019
VL 35
IS 11
SI SI
BP 1641
EP 1654
DI 10.1007/s00371-018-1563-1
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JD5IZ
UT WOS:000490018000011
PM 31741545
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Machraoui, AN
   Diouani, MF
   Mouelhi, A
   Jaouadi, K
   Ghrab, J
   Abdelmelek, H
   Sayadi, M
AF Machraoui, Ahmed Nejmedine
   Diouani, Mohamed Fethi
   Mouelhi, Aymen
   Jaouadi, Kaouther
   Ghrab, Jamila
   Abdelmelek, Hafedh
   Sayadi, Mounir
TI Automatic identification and behavioral analysis of phlebotomine sand
   flies using trajectory features
SO VISUAL COMPUTER
LA English
DT Article
DE Sand fly; Object tracking; Features extraction; Motion analysis;
   Computer vision; Ecology
ID IMAGING-SYSTEM; CLASSIFICATION; TRACKING; INSECTS; FLIGHT; COLOR; FISH
AB The present paper reports an automated approach for the characterization and analysis of the behavioral of sand flies; the method used is based on Gaussian mixture model and Kalman filter for the detection and tracking of sand flies, and then the extraction of an optimized set of features from the trajectory of flight is performed for the classification process. So, we propose here two optimized sets of features; the first one is used to identify sand flies among other insects, and the second is employed for the characterization of the behavioral change in the sand flies in the presence of a repulsive odor. These features are tested on three different classifiers; artificial neural network, support vector machine and K-nearest neighbor (KNN), and the results show an important improvement in the classification accuracy and confirm the effectiveness of our approach; the accuracy rate of the proposed method reached 88.6% for the identification of sand flies and 93.4% for the detection of their behavior change. Instead of the excessive use of pesticides over wide areas, the presented investigation is a key pillar of the development of an ecological way for a statistical information gathering about sand flies in order to fight against disease carried by those insects especially leishmaniosis and pappataci fever.
C1 [Machraoui, Ahmed Nejmedine; Mouelhi, Aymen; Sayadi, Mounir] Univ Tunis, ENSIT, Lab Signal Image & Energy Mastery, Tunis, Tunisia.
   [Diouani, Mohamed Fethi] Inst Pasteur Tunis, Lab Epidemiol & Vet Microbiol, Tunis, Tunisia.
   [Jaouadi, Kaouther] Inst Pasteur Tunis, Dept Med Epidemiol, Lab Transmiss Control & Immunobiol Infect LR11IPT, Tunis, Tunisia.
   [Ghrab, Jamila] Inst Pasteur Tunis, Lab Med Parasitol Biotechnol & Biomol, Tunis, Tunisia.
   [Abdelmelek, Hafedh] Fac Sci Bizerte, Lab Integrat Physiol, Bizerte, Tunisia.
C3 Universite de Tunis; Pasteur Network; Universite de Tunis-El-Manar;
   Institut Pasteur Tunis; Pasteur Network; Universite de Tunis-El-Manar;
   Institut Pasteur Tunis; Pasteur Network; Universite de Tunis-El-Manar;
   Institut Pasteur Tunis; Universite de Carthage
RP Machraoui, AN (corresponding author), Univ Tunis, ENSIT, Lab Signal Image & Energy Mastery, Tunis, Tunisia.; Diouani, MF (corresponding author), Inst Pasteur Tunis, Lab Epidemiol & Vet Microbiol, Tunis, Tunisia.
EM ahmed.machraoui@gmail.com; fethi.diouani@pasteur.rns.tn;
   kaoutherj@gmail.com; jamila.ghrab@hotmail.fr; habdelmelek@yahoo.com;
   mounir.sayadi@esstt.rnu.tn
RI Diouani, mohamed fethi MF/A-7880-2015; Mouelhi, Aymen/AAG-4517-2020;
   Mouelhi, Aymen/ABC-9909-2020
OI Sayadi, Mounir/0000-0003-4270-421X; Mouelhi, Aymen/0000-0002-6642-2594
FU European Tropsense Project [645 758]
FX This work was supported by the European Tropsense Project, ref: 645 758,
   H2020-MSCA-2014 RISE Program.
CR [Anonymous], THESIS
   [Anonymous], 2006, 10 INT WORKSH FRONT
   [Anonymous], BMVC
   [Anonymous], IEEE IPAS 14
   [Anonymous], COMPUT ELECT AGR
   Bashir FI, 2006, MULTIMEDIA SYST, V12, P45, DOI 10.1007/s00530-006-0024-2
   Berbar MA, 2014, VISUAL COMPUT, V30, P19, DOI 10.1007/s00371-013-0774-8
   Chen C, 2012, COMPUT ELECTRON AGR, V89, P100, DOI 10.1016/j.compag.2012.08.006
   Cullinan VI, 2015, ECOL INFORM, V27, P55, DOI 10.1016/j.ecoinf.2015.03.004
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DUBE S, 1989, CAN J BOT, V67, P2085, DOI 10.1139/b89-264
   Dutta MK, 2016, LWT-FOOD SCI TECHNOL, V68, P408, DOI 10.1016/j.lwt.2015.11.059
   Feng LN, 2016, PATTERN RECOGN, V51, P225, DOI 10.1016/j.patcog.2015.09.012
   Fry SN, 2000, J NEUROSCI METH, V101, P59, DOI 10.1016/S0165-0270(00)00253-3
   Frye MA, 2003, J EXP BIOL, V206, P843, DOI 10.1242/jeb.00175
   Handoko Y, 2009, J BIONIC ENG, V6, P264, DOI 10.1016/S1672-6529(08)60120-1
   Jhuang H, 2010, NAT COMMUN, V1, DOI 10.1038/ncomms1064
   Kaya Y, 2014, VISUAL COMPUT, V30, P71, DOI 10.1007/s00371-013-0782-8
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Li F, 2018, VISUAL COMPUT, V34, P1525, DOI 10.1007/s00371-017-1426-1
   Müller P, 2002, BEHAV ECOL, V13, P598, DOI 10.1093/beheco/13.5.598
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Poiesi F, 2015, IEEE T CIRC SYST VID, V25, P623, DOI 10.1109/TCSVT.2014.2344509
   Potamitis I, 2014, ECOL INFORM, V21, P40, DOI 10.1016/j.ecoinf.2013.11.005
   Solis-Sánchez LO, 2009, J APPL ENTOMOL, V133, P546, DOI 10.1111/j.1439-0418.2009.01400.x
   Solis-Sánchez LO, 2011, COMPUT ELECTRON AGR, V75, P92, DOI 10.1016/j.compag.2010.10.001
   Tlig L, 2012, SIGNAL PROCESS-IMAGE, V27, P694, DOI 10.1016/j.image.2012.03.001
   Umerie SC, 1998, BIORESOURCE TECHNOL, V64, P237, DOI 10.1016/S0960-8524(97)00188-0
   Yao Q, 2012, J INTEGR AGR, V11, P978, DOI 10.1016/S2095-3119(12)60089-6
   Zanaty EA, 2012, EGYPT INFORM J, V13, P177, DOI 10.1016/j.eij.2012.08.002
   Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072
NR 32
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2019
VL 35
IS 5
BP 721
EP 738
DI 10.1007/s00371-018-1506-x
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HZ0IT
UT WOS:000468524900009
DA 2024-07-18
ER

PT J
AU Cao, GY
   Li, JW
   Chen, XW
   He, ZQ
AF Cao, Guangying
   Li, Jianwei
   Chen, Xiaowu
   He, Zhiqiang
TI Patch-based self-adaptive matting for high-resolution image and video
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 6th International Conference on Virtual Reality and Visualization
   (ICVRV)
CY SEP 24-26, 2016
CL Hangzhou, PEOPLES R CHINA
SP China Soc Image & Graph, China Comp Federat, China Syst Simulat Assoc, IEEE Comp Soc, Connected Universal Experiences Labs Inc, China Soc Image & Graph, VR Comm, China Comp Federat, VR & Visualizat Comm, China Syst Simulat Assoc, VR Comm, China Syst Simulat Assoc, Digital Entertainment Comm, China Syst Simulat Assoc, Surgery Simulat Comm
DE Matting; Patch division; High resolution
AB We propose an efficient patch-based self-adaptive matting approach to reduce memory consumption in processing high-resolution image and video. Most existing image matting techniques employ a global optimization over the whole set of image pixels, incurring a prohibitively high memory consumption, especially in high-resolution images. Inspired by divide-and-conquer, we divide the images into small patches in a self-adaptive way according to the distribution of unknown pixels and handle the small patches one by one. The alpha mattes in patch level are combined according to the weights. Relationships between patches are also considered by locally linear embedding to maintain consistency through the whole image. We also extend the framework to video matting with considering the temporal coherence of alpha mattes. A sampling method is applied to speed up the operation of video sampling. A multi-frame graph model is also proposed to enhance temporal and spatial consistency which can be solved efficiently by Random Walk. Experimental results show that the proposed method significantly reduces memory consumption while maintaining high-fidelity matting results on the benchmark dataset.
C1 [Cao, Guangying; Li, Jianwei; Chen, Xiaowu] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [He, Zhiqiang] Lenovo Res, Beijing, Peoples R China.
C3 Beihang University; Legend Holdings; Lenovo
RP Chen, XW (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM jianwei.li@buaa.edu.cn; chen@buaa.edu.cn
RI li, jian/GSE-0245-2022; l, j/HNC-5728-2023; Li, Jin/GYQ-5363-2022; LI,
   JIAN/GRY-2197-2022; LI, Jing/HNB-5575-2023; LI, JIAN/JAX-3092-2023; Li,
   Jing/GYU-5036-2022
FU NSFC [61532003, 61421003]; Lenovo Outstanding Young Scientists Program
FX We would like to thank the reviewers for their help in improving the
   paper. This work was partially supported by NSFC (61532003&61421003) and
   the Lenovo Outstanding Young Scientists Program.
CR [Anonymous], 2013, 2013 IEEE INT C MULT
   [Anonymous], ACCV
   [Anonymous], 2006, CVPR
   [Anonymous], 2008, P IEEE COMPUTER VISI
   [Anonymous], 2017, CVPR
   [Anonymous], BMVC
   [Anonymous], 2007, CVPR
   [Anonymous], MACH LEARN RES
   Cao GY, 2016, I C VIRTUAL REALITY, P24, DOI 10.1109/ICVRV.2016.13
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2014, PROC CVPR IEEE, pCP5, DOI 10.1109/CVPR.2014.365
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   Choi I, 2012, LECT NOTES COMPUT SC, V7577, P540, DOI 10.1007/978-3-642-33783-3_39
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423
   He B, 2013, IEEE IMAGE PROC, P4282, DOI 10.1109/ICIP.2013.6738882
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Johnson J, 2016, IEEE T IMAGE PROCESS, V25, P3032, DOI 10.1109/TIP.2016.2555705
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Karacan L, 2015, IEEE I CONF COMP VIS, P424, DOI 10.1109/ICCV.2015.56
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Lee SY, 2010, GRAPH MODELS, V72, P25, DOI 10.1016/j.gmod.2010.03.001
   Li DZY, 2013, IEEE I CONF COMP VIS, P3599, DOI 10.1109/ICCV.2013.447
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741
   Tang Z, 2012, VISUAL COMPUT, V28, P47, DOI 10.1007/s00371-011-0598-3
   Vatolin Dmitriy S, 2015, BMVC, P99
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Xu Ning., 2017, CVPR
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
   Zou DQ, 2015, IEEE I CONF COMP VIS, P1564, DOI 10.1109/ICCV.2015.183
NR 34
TC 5
Z9 6
U1 1
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2019
VL 35
IS 1
BP 133
EP 147
DI 10.1007/s00371-017-1424-3
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA HL6ZO
UT WOS:000458885900012
DA 2024-07-18
ER

PT J
AU Xie, L
   Xu, YH
   Zhang, XH
   Bao, W
   Tong, CP
   Shi, BX
AF Xie, Liang
   Xu, Yuhua
   Zhang, Xiaohu
   Bao, Wei
   Tong, Chenpeng
   Shi, Boxin
TI A self-calibrated photo-geometric depth camera
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 6th International Conference on Virtual Reality and Visualization
   (ICVRV)
CY SEP 24-26, 2016
CL Hangzhou, PEOPLES R CHINA
SP China Soc Image & Graph, China Comp Federat, China Syst Simulat Assoc, IEEE Comp Soc, Connected Universal Experiences Labs Inc, China Soc Image & Graph, VR Comm, China Comp Federat, VR & Visualizat Comm, China Syst Simulat Assoc, VR Comm, China Syst Simulat Assoc, Digital Entertainment Comm, China Syst Simulat Assoc, Surgery Simulat Comm
DE Photometric stereo; Stereo matching; Lighting calibration; Random
   speckle
ID SHAPE; NORMALS
AB Compared with geometric stereo vision based on triangulation principle, photometric stereo method has advantages in recovering per-pixel surface details. In this paper, we present a practical 3D imaging system by combining the near-light photometric stereo and the speckle-based stereo matching method. The system is compact in structure and suitable for multi-albedo targets. The parameters (including position and intensity) of the light sources can be self-calibrated. To realize the auto-calibration, we first use the distant lighting model to estimate the initial surface albedo map, and then with the estimated albedo map and the normal vector field fixed, the parameters of the near lighting model are optimized. Next, with the optimized lighting model, we use the near-light photometric stereo method to re-compute the surface normal and fuse it with the coarse depth map from stereo vision to achieve high-quality depth map. Experimental results show that our system can realize high-quality reconstruction in general indoor environments.
C1 [Xie, Liang; Xu, Yuhua] Natl Univ Def Technol, Coll Aerosp Sci & Engn, Changsha 410073, Hunan, Peoples R China.
   [Zhang, Xiaohu] Sun Yat Sen Univ, Sch Aeronaut & Astronaut, Guangzhou 510275, Guangdong, Peoples R China.
   [Bao, Wei] Hefei Univ Technol, Sch Elect Engn & Automat, Hefei 230009, Anhui, Peoples R China.
   [Tong, Chenpeng] DeepInTech, Shenzhen 518055, Guangdong, Peoples R China.
   [Shi, Boxin] Peking Univ, Inst Digital Media, Sch EECS, Beijing 100871, Peoples R China.
C3 National University of Defense Technology - China; Sun Yat Sen
   University; Hefei University of Technology; Peking University
RP Xu, YH (corresponding author), Natl Univ Def Technol, Coll Aerosp Sci & Engn, Changsha 410073, Hunan, Peoples R China.
EM xyh_nudt@163.com
RI Xie, Liang/HLQ-7998-2023
OI Xu, Yuhua/0000-0002-7427-0156
FU National Natural Science Foundation of China [61402489]
FX This research was supported by the National Natural Science Foundation
   of China (No. 61402489).
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P INT C 3D VIS 3DV
   [Anonymous], 2013, VMV
   Blais F, 2004, J ELECTRON IMAGING, V13, P231, DOI 10.1117/1.1631921
   Chatterjee A, 2015, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2015.7298695
   Han Y, 2013, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2013.204
   Higo T, 2009, IEEE I CONF COMP VIS, P1234, DOI 10.1109/ICCV.2009.5459331
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jiang CF, 2016, OPT EXPRESS, V24, P7337, DOI 10.1364/OE.24.007337
   Madsen K., 2004, INFORM MATH MODELING, p24C29
   Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Powell MW, 2001, IEEE T PATTERN ANAL, V23, P1022, DOI 10.1109/34.955114
   Quéau Y, 2016, PROC CVPR IEEE, P4359, DOI 10.1109/CVPR.2016.472
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang C., 2013, P INT SPEECH COMM AS, P2748
   Zhang S, 2010, OPT EXPRESS, V18, P9684, DOI 10.1364/OE.18.009684
   Zhou WD, 2002, P ANN INT IEEE EMBS, P206, DOI 10.1109/IEMBS.2002.1134458
NR 19
TC 4
Z9 4
U1 1
U2 24
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2019
VL 35
IS 1
BP 99
EP 108
DI 10.1007/s00371-018-1507-9
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA HL6ZO
UT WOS:000458885900009
DA 2024-07-18
ER

PT J
AU Averbuch-Elor, H
   Kopf, J
   Hazan, T
   Cohen-Or, D
AF Averbuch-Elor, Hadar
   Kopf, Johannes
   Hazan, Tamir
   Cohen-Or, Daniel
TI Co-segmentation for space-time co-located collections
SO VISUAL COMPUTER
LA English
DT Article
DE Image co-segmentation; Foreground extraction; Non-rigid and deformable
   motion analysis; Belief propagation
AB We present a co-segmentation technique for space-time co-located image collections. These prevalent collections capture various dynamic events, usually by multiple photographers, and may contain multiple co-occurring objects which are not necessarily part of the intended foreground object, resulting in ambiguities for traditional co-segmentation techniques. Thus, to disambiguate what the common foreground object is, we introduce a weakly supervised technique, where we assume only a small seed, given in the form of a single segmented image. We take a distributed approach, where local belief models are propagated and reinforced with similar images. Our technique progressively expands the foreground and background belief models across the entire collection. The technique exploits the power of the entire set of image without building a global model, and thus successfully overcomes large variability in appearance of the common foreground object. We demonstrate that our method outperforms previous co-segmentation techniques on challenging space-time co-located collections, including dense benchmark datasets which were adapted for our novel problem setting.
C1 [Averbuch-Elor, Hadar] Tel Aviv Univ, Sch Elect Engn, Tel Aviv, Israel.
   [Kopf, Johannes] Facebook, Seattle, WA USA.
   [Hazan, Tamir] Technion, Fac Ind Engn & Management, Haifa, Israel.
   [Cohen-Or, Daniel] Tel Aviv Univ, Sch Comp Sci, Tel Aviv, Israel.
C3 Tel Aviv University; Facebook Inc; Technion Israel Institute of
   Technology; Tel Aviv University
RP Averbuch-Elor, H (corresponding author), Tel Aviv Univ, Sch Elect Engn, Tel Aviv, Israel.
EM hadar.a.elor@gmail.com; jkopf@fb.com; tamir.hazan@technion.ac.il;
   dcor@tau.ac.il
RI Averbuch-Elor, Hadar/AAO-4246-2021
CR [Anonymous], 2016, COMPUTER VISION PATT
   [Anonymous], 2006, 2006 IEEE COMPUTER S
   Arpa A, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P422, DOI 10.1109/3DV.2013.62
   Basha T, 2012, LECT NOTES COMPUT SC, V7577, P654, DOI 10.1007/978-3-642-33783-3_47
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Campbell NDF, 2010, IMAGE VISION COMPUT, V28, P14, DOI 10.1016/j.imavis.2008.09.005
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Chiu WC, 2013, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.2013.48
   Djelouah A, 2016, INT CONF 3D VISION, P360, DOI 10.1109/3DV.2016.45
   Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164
   Fan QN, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818105
   FU HZ, 2015, PROC CVPR IEEE, P4428, DOI DOI 10.1109/CVPR.2015
   Gang Z., 2004, P AS C COMP VIS CIT
   HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965
   Heskes T, 2006, J ARTIF INTELL RES, V26, P153, DOI 10.1613/jair.1933
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kim G, 2013, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2013.86
   Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kuettel D, 2012, LECT NOTES COMPUT SC, V7578, P459, DOI 10.1007/978-3-642-33786-4_34
   Maerki N., 2016, IEEE C COMP VIS PATT
   Mustafa A., 2017, CVPR 2017 P
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P2313, DOI 10.1109/TIT.2005.850091
   Zhang D, 2014, LECT NOTES COMPUT SC, V8695, P551, DOI 10.1007/978-3-319-10584-0_36
NR 30
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2018
VL 34
IS 12
BP 1761
EP 1772
DI 10.1007/s00371-017-1467-5
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GY3WM
UT WOS:000448487400012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Deng, WX
   Zou, HX
   Guo, F
   Lei, L
   Zhou, SL
   Luo, TC
AF Deng, Wanxia
   Zou, Huanxin
   Guo, Fang
   Lei, Lin
   Zhou, Shilin
   Luo, Tiancheng
TI A robust non-rigid point set registration method based on inhomogeneous
   Gaussian mixture models
SO VISUAL COMPUTER
LA English
DT Article
DE Non-rigid point set registration; Inhomogeneous Gaussian mixture models
   (IGMM); Local shape context; Feature similarity; Expectation
   maximization (EM)
ID TRANSFORMATION
AB In this paper, we propose a novel robust non-rigid point set registration method adopting a new probability model called inhomogeneous Gaussian mixture models (IGMM), where we regard one point set as the centroids of a Gaussian mixture model and the other point set as the data. The IGMM is defined by applying local features and Gaussian mixture models. Considering the local relationship among neighboring points is stable, a neighborhood structural descriptor, named as local shape context, is first presented. On the basis of local descriptors, we can obtain a measure of compatibility between local features in the point sets. Then, the similarity of the local structure of point neighborhoods can be calculated on the basis of the matching scores. Each Gaussian mixture component is assigned a different weight depending on the feature similarity, which differs from the traditional Gaussian mixture model where each Gaussian mixture component has the same weight. The proposed IGMM makes point pairs with more similar features have bigger probability to formulate a match, while in algorithms based on GMMs, all point pairs have the same probability to construct correspondence points. Finally, we support our claims through regularization theory and formulate registration as a likelihood maximization problem, which is solved by updating transformation parameters and outlier ratios using the expectation maximization algorithm. Extensive comparison and evaluation experiments on synthetic point-sets datasets demonstrate that the proposed approach is robust and achieves superior performance in the presence of non-rigid deformation, noise, outliers and occlusion. In addition, a number of experiments on real images reveal that our proposed algorithm is more applicable than state-of-the-art algorithms.
C1 [Deng, Wanxia; Zou, Huanxin; Guo, Fang; Lei, Lin; Zhou, Shilin; Luo, Tiancheng] Natl Univ Def Technol, 109 Deya Rd,Yanwachi St, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Zou, HX (corresponding author), Natl Univ Def Technol, 109 Deya Rd,Yanwachi St, Changsha 410073, Hunan, Peoples R China.
EM hxzou2008@163.com
CR [Anonymous], INT C COMP VIS
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.626
   [Anonymous], P ACM INT C MULT
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chen J, 2015, SIGNAL PROCESS, V106, P62, DOI 10.1016/j.sigpro.2014.07.004
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Deng WX, 2018, VISUAL COMPUT, V34, P55, DOI 10.1007/s00371-016-1311-3
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   Gao Y, 2014, PATTERN ANAL APPL, V17, P379, DOI 10.1007/s10044-013-0324-z
   Jain AK, 2009, IEEE IMAGE PROC, P2745, DOI 10.1109/ICIP.2009.5414140
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Jian Zhao, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P508, DOI 10.1109/ICCRD.2011.5764185
   Kato T., 2002, P JOINT IAPR INT WOR, P505
   Kybic J, 2012, SIGNAL PROCESS, V92, P1302, DOI 10.1016/j.sigpro.2011.11.027
   Lee JH, 2011, IEEE T PATTERN ANAL, V33, P427, DOI 10.1109/TPAMI.2010.179
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Ma JY, 2013, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2013.279
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Oztireli AC, 2008, VISUAL COMPUT, V24, P679, DOI 10.1007/s00371-008-0248-6
   Sfikas K, 2012, VISUAL COMPUT, V28, P943, DOI 10.1007/s00371-012-0714-z
   Sun K., 2015, INF SCI, V295, P322
   Tao W., 2014, IEEE C COMP VIS PATT, P2977
   Tao WB, 2015, IEEE T IMAGE PROCESS, V24, P3754, DOI 10.1109/TIP.2015.2449559
   Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44
   Tsin Y., 2004, Proceedings of European Conference on Computer Vision, P558
   Wang G, 2015, COMPUT VIS IMAGE UND, V141, P67, DOI 10.1016/j.cviu.2015.05.014
   Wang G, 2015, LECT NOTES COMPUT SC, V9006, P433, DOI 10.1007/978-3-319-16817-3_28
   Wong A, 2009, SIGNAL PROCESS, V89, P724, DOI 10.1016/j.sigpro.2008.10.028
   Yan XW, 2013, J CENT SOUTH UNIV, V20, P3077, DOI 10.1007/s11771-013-1831-1
   Zhao J, 2011, PROC CVPR IEEE, P2977, DOI 10.1109/CVPR.2011.5995336
   Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81
NR 37
TC 3
Z9 3
U1 3
U2 27
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2018
VL 34
IS 10
BP 1399
EP 1414
DI 10.1007/s00371-017-1444-z
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GR0KK
UT WOS:000442204400010
DA 2024-07-18
ER

PT J
AU Wang, C
   Yang, JB
AF Wang, Cong
   Yang, Jianbin
TI Poisson noise removal of images on graphs using tight wavelet frames
SO VISUAL COMPUTER
LA English
DT Article
DE Images on graphs; Tight wavelet frames; Poisson noise; Mixed
   Poisson-Gaussian noise
ID RESTORATION; SURFACES
AB After many years of study, the subject of image denoising on the flat domain is well developed. However, many practical problems arising from different areas, such as computer vision, computer graphics, geometric modeling and medical imaging, involve images on the irregular domain sets such as graphs. In this paper, we consider Poisson and mixed Poisson-Gaussian noise removal of images on graphs. Based on the statistical characteristic of the observed noisy images, we propose a wavelet frame-based variational model to restore images on graphs. The model contains a weighted fidelity term and an -regularized term which makes additional use of the tight wavelet frame transform on graphs in order to preserve key features such as textures and edges of images. We then apply the popular alternating direction method of multipliers (ADMM) to solve the model. Finally, we provide supporting numerical experiments on graphs and compare with other denoising methods. The results on some image denoising tasks indicate the effectiveness of our method.
C1 [Wang, Cong; Yang, Jianbin] Hohai Univ, Coll Sci, Nanjing 211100, Jiangsu, Peoples R China.
C3 Hohai University
RP Yang, JB (corresponding author), Hohai Univ, Coll Sci, Nanjing 211100, Jiangsu, Peoples R China.
EM wangc0705@hhu.edu.cn; jbyang@hhu.edu.cn
RI Wang, Cong/JVP-1007-2024; YANG, Bin/C-7819-2011
OI Wang, Cong/0000-0001-8182-0243; YANG, Bin/0000-0002-5136-9743; Yang,
   Jianbin/0000-0002-6652-5905
CR [Anonymous], 2011, PROC INT C DISTRIB C, DOI DOI 10.1109/DCOSS.2011.5982158
   Belkin M, 2005, LECT NOTES COMPUT SC, V3559, P486, DOI 10.1007/11503415_33
   Benninghoff H, 2016, J MATH IMAGING VIS, V55, P105, DOI 10.1007/s10851-015-0616-6
   Bertero M, 2010, INVERSE PROBL, V26, DOI 10.1088/0266-5611/26/10/105004
   Botsch M., 2010, Polygon Mesh Processing
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Cai JF, 2012, J AM MATH SOC, V25, P1033, DOI 10.1090/S0894-0347-2012-00740-1
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Chan RH, 2007, INT J COMPUT MATH, V84, P1183, DOI 10.1080/00207160701450390
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   CSISZAR I, 1991, ANN STAT, V19, P2032, DOI 10.1214/aos/1176348385
   Dong B., 2010, IAS Lecture Notes Series, Summer Program on "The Mathematics of Image Processing, V19
   Dong B, 2017, APPL COMPUT HARMON A, V42, P452, DOI 10.1016/j.acha.2015.09.005
   Dong B, 2016, APPL COMPUT HARMON A, V41, P561, DOI 10.1016/j.acha.2015.03.005
   El Ouafdi AF, 2015, VISUAL COMPUT, V31, P295, DOI 10.1007/s00371-014-0922-9
   GINE E., 2006, Lecture Notes-Monograph Series, P238
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gong Z, 2014, MULTISCALE MODEL SIM, V12, P458, DOI 10.1137/130904533
   Hein M, 2005, LECT NOTES COMPUT SC, V3559, P470, DOI 10.1007/11503415_32
   Jain P, 2015, VISUAL COMPUT, V31, P657, DOI 10.1007/s00371-014-0993-7
   Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y
   Li J, 2015, INVERSE PROBL IMAG, V9, P875, DOI 10.3934/ipi.2015.9.875
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Mason J.C., 2002, CHEBYSHEV POLYNOMIAL
   Niyobuhungiro J., 2014, 2 INT C INTELLIGENT
   Ron A, 1997, J FUNCT ANAL, V148, P408, DOI 10.1006/jfan.1996.3079
   Ron A, 1998, MATH COMPUT, V67, P191, DOI 10.1090/S0025-5718-98-00898-9
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Sawatzky A, 2013, LECT NOTES MATH, V2090, P71, DOI 10.1007/978-3-319-01712-9_2
   Shepp L A, 1982, IEEE Trans Med Imaging, V1, P113, DOI 10.1109/TMI.1982.4307558
   Singer A, 2006, APPL COMPUT HARMON A, V21, P128, DOI 10.1016/j.acha.2006.03.004
   Staglianò A, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/12/125003
   Yang JB, 2017, INVERSE PROBL IMAG, V11, P783, DOI 10.3934/ipi.2017037
   Yang JB, 2017, APPL COMPUT HARMON A, V42, P480, DOI 10.1016/j.acha.2015.09.008
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P1093, DOI 10.1109/TIP.2008.924386
   Zhang HY, 2015, IEEE T VIS COMPUT GR, V21, P873, DOI 10.1109/TVCG.2015.2398432
   Zosso D, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P821, DOI 10.1109/ICDMW.2015.112
NR 38
TC 15
Z9 15
U1 3
U2 20
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2018
VL 34
IS 10
BP 1357
EP 1369
DI 10.1007/s00371-017-1418-1
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GR0KK
UT WOS:000442204400007
DA 2024-07-18
ER

PT J
AU Vasiou, E
   Shkurko, K
   Mallett, I
   Brunvand, E
   Yuksel, C
AF Vasiou, Elena
   Shkurko, Konstantin
   Mallett, Ian
   Brunvand, Erik
   Yuksel, Cem
TI A detailed study of ray tracing performance: render time and energy cost
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 35th Computer Graphics International conference (CGI)
CY JUN 11-14, 2018
CL INDONESIA
SP Comp Graph Soc, Nanyang Technol Univ
DE Ray tracing; Energy efficiency; Graphics processors; Memory timing
AB Optimizations for ray tracing have typically focused on decreasing the time taken to render each frame. However, in modern computer systems it may actually be more important to minimize the energy used, or some combination of energy and render time. Understanding the time and energy costs per ray can enable the user to make conscious trade-offs between image quality and time/energy budget in a complete system. To facilitate this, in this paper we present a detailed study of per-ray time and energy costs for ray tracing. Specifically, we use path tracing, broken down into distinct kernels, to carry out an extensive study of the fine-grained contributions in time and energy for each ray over multiple bounces. As expected, we have observed that both the time and energy costs are highly correlated with data movement. Especially in large scenes that do not mostly fit in on-chip caches, accesses to DRAM not only account for the majority of the energy use, but also the corresponding stalls dominate the render time.
C1 [Vasiou, Elena; Shkurko, Konstantin; Mallett, Ian; Brunvand, Erik; Yuksel, Cem] Univ Utah, 50 Cent Campus Dr, Salt Lake City, UT 84112 USA.
C3 Utah System of Higher Education; University of Utah
RP Vasiou, E (corresponding author), Univ Utah, 50 Cent Campus Dr, Salt Lake City, UT 84112 USA.
EM elvasiou@cs.utah.edu; kshkurko@cs.utah.edu; imallett@cs.utah.edu;
   elb@cs.utah.edu; cem@cemyuksel.com
OI Mallett, Ian/0000-0002-2505-3649
FU National Science Foundation [1409129]; Division Of Computer and Network
   Systems; Direct For Computer & Info Scie & Enginr [1409129] Funding
   Source: National Science Foundation
FX This material is supported in part by the National Science Foundation
   under Grant No. 1409129.
CR Aila T., 2010, P HPG
   Aila T., 2009, P HPG
   [Anonymous], 1986, P SIGGRAPH
   [Anonymous], 2009, ISPASS
   [Anonymous], 2007, MICRO
   Arnau J. M., 2014, P ISCA
   Barringer R., 2014, ACM T GRAPHIC, V33, P33
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Boulos S., 2007, P GRAPHICS INTERFACE
   Brunvand Erik, 2014, ACM SIGGRAPH 2014 CO
   Budge BrianC., 2009, OUT OF CORE DATA MAN
   Chatterjee N., 2017, HPCA
   Chatterjee N., 2012, UUCS1202 USIMM
   Christensen P. H., 2003, EUROGRAPHICS
   Dally B., 2013, CELSIUS LECT
   Gribble C., 2008, IRT
   Hapala M., 2011, SCCG
   HWRT, 2012, SIMTRAX CYCL ACC RAY
   Johnsson B., 2014, J COMPUT GR TECH JCG, V3, P60
   Johnsson B., 2012, HPG
   Karras T., 2013, P HPG
   Kopta D, 2015, COMPUT GRAPH FORUM, V34, P47, DOI 10.1111/cgf.12458
   Kopta D., 2013, P HPG
   Lee W. J., 2015, P HPG
   Liktor G., 2016, P HPG
   Mansson E., 2007, IRT
   Moon B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805972
   Navratil P., 2007, IRT
   Navratil P.A., 2006, An analysis of ray tracing bandwidth consumption
   Overbeck R., 2008, IRT
   Pool J., 2010, ICCD
   Pool J, 2012, THESIS
   Shkurko K., 2017, P HPG
   Smits B., 2005, SIGGRAPH COURSES SIG
   Spjut J., 2008, SASP
   Spjut J, 2009, IEEE T COMPUT AID D, V28, P1802, DOI 10.1109/TCAD.2009.2028981
   Tsakok J. A., 2009, P HPG
   Vogelsang T., 2010, MICRO 43
   Wang R, 2016, ACM T GRAPHIC, V35
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
NR 40
TC 8
Z9 10
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2018
VL 34
IS 6-8
SI SI
BP 875
EP 885
DI 10.1007/s00371-018-1532-8
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GH6MC
UT WOS:000433557400012
DA 2024-07-18
ER

PT J
AU Khmag, A
   Ramli, A
   Al-Haddad, SAR
   Kamarudin, N
AF Khmag, Asem
   Ramli, Abd Rahman
   Al-Haddad, S. A. R.
   Kamarudin, Noraziahtulhidayu
TI Natural image noise level estimation based on local statistics for blind
   noise reduction
SO VISUAL COMPUTER
LA English
DT Article
DE Gaussian noise; Noise estimation; Image denoising; Low-rank patches; PCA
ID WAVELET; DOMAIN
AB This study proposes an automatic noise estimation method based on local statistics for additive white Gaussian noise. Noise estimation is an important process in digital imaging systems. For example, the performance of an image denoising algorithm can be significantly degraded because of poor noise level estimation. Most of the literature on the subject tends to use the true noise level of a noisy image when suppressing noise artifacts. Moreover, even with the given true noise level, these denoising techniques still cannot attain the best result, particularly for images with complicated details. In this study, a patch-based estimation technique is used to estimate for noise level and applies it to the proposed blind image denoising algorithm. Our approach includes selecting low-rank sub-image with removing high-frequency components from the contaminated image. This selection is according to the gradients of patches with the same statistics. Consequently, we need to estimate the noise level from the selected patches using principal component analysis (PCA). For blind denoising applications, the proposed denoising algorithm integrates the undecimated wavelet-based denoising algorithms and PCA to develop the subjective and objective qualities of the observed image, which result from filtering processes. Experiment results depict that the suggested algorithm performs efficiently over a wide range of visual contents and noise conditions, as well as in additive noise. Associated with different conventional noise estimators, the proposed algorithm yields the best performance, higher-quality images, and faster running speed.
C1 [Khmag, Asem] Univ Zawia, Fac Engn, Zawiya, Libya.
   [Khmag, Asem; Ramli, Abd Rahman; Al-Haddad, S. A. R.; Kamarudin, Noraziahtulhidayu] Univ Putra Malaysia UPM, Fac Engn, Serdang, Malaysia.
C3 Universiti Putra Malaysia
RP Khmag, A (corresponding author), Univ Zawia, Fac Engn, Zawiya, Libya.; Khmag, A (corresponding author), Univ Putra Malaysia UPM, Fac Engn, Serdang, Malaysia.
EM khmaj2002@gmail.com; arr@upm.edu.my; sar@upm.edu.my;
   hidayu.kamarudin@gmail.com
RI Al-Haddad, S. A. R./AAM-6449-2020; Khmag, Asem/AAH-1051-2019; kamarudin,
   noraziahtulhidayu/AAQ-8508-2021
OI Khmag, Asem/0000-0002-1360-5346; Kamarudin,
   Noraziahtulhidayu/0000-0001-7467-4348
CR Aja-Fernández S, 2009, IMAGE VISION COMPUT, V27, P756, DOI 10.1016/j.imavis.2008.08.002
   Amer A, 2005, IEEE T CIRC SYST VID, V15, P113, DOI 10.1109/TCSVT.2004.837017
   Amer A., 2002, P 2002 INT C IM PROC
   [Anonymous], 2012, Technical report
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Bilcu R., 2005, NSIP 2005 ABSTRACTS
   Bishop C. M., 2006, MACH LEARN, V128, P1
   Chen G., 2015, P IEEE INT C COMP VI
   Corner BR, 2003, INT J REMOTE SENS, V24, P689, DOI 10.1080/01431160210164271
   Dabov K., 2008, P SIGN PROC AD SPARS, P1
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Ghazal M, 2011, IEEE T IMAGE PROCESS, V20, P1788, DOI 10.1109/TIP.2010.2097272
   Ghazel M, 2006, IEEE T IMAGE PROCESS, V15, P2669, DOI 10.1109/TIP.2006.877377
   Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2269, DOI 10.1109/TIP.2006.875248
   Gonzales R.C., 2002, Digital image processing
   Goossens B, 2009, IEEE T IMAGE PROCESS, V18, P1153, DOI 10.1109/TIP.2009.2017169
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Jain P, 2015, VISUAL COMPUT, V31, P657, DOI 10.1007/s00371-014-0993-7
   Jiang P, 2016, PATTERN RECOGN LETT, V78, P8, DOI 10.1016/j.patrec.2016.03.026
   Khalil H. H., 2008, 3 INT C GEOM MOD IM
   Khmag A., J MED IMAGING HLTH I, V5, P1261
   Khmag A., 2016, VISUAL COMPUT, V4, P1
   Khmag A, 2016, IEEJ T ELECTR ELECTR, V11, P339, DOI 10.1002/tee.22223
   Larson E. C., 2009, CATEGORICAL SUBJECTI
   Lee J., 1989, GEOSC REM SENS S 198
   Li C., 2009, IS T SPIE ELECT IMAG
   Liu W., 2014, IEEE WORKSH EL COMP
   Liu W, 2013, IEEE T IMAGE PROCESS, V22, P872, DOI 10.1109/TIP.2012.2219544
   OLSEN SI, 1993, CVGIP-GRAPH MODEL IM, V55, P319, DOI 10.1006/cgip.1993.1022
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rank K, 1999, IEE P-VIS IMAGE SIGN, V146, P80, DOI 10.1049/ip-vis:19990238
   Salmeri M., 2001, P 2001 INT C IM PROC
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Shao L, 2008, IEEE T IMAGE PROCESS, V17, P1772, DOI 10.1109/TIP.2008.2002162
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Shin DH, 2005, IEEE T CONSUM ELECTR, V51, P218, DOI 10.1109/TCE.2005.1405723
   Sun Y, 2012, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT (IEEE IC-NIDC 2012), P27, DOI 10.1109/ICNIDC.2012.6418705
   Yang SM, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3476329
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
   Zoran D., 2009, 2009 IEEE 12 INT C C
NR 44
TC 36
Z9 37
U1 2
U2 27
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2018
VL 34
IS 4
BP 575
EP 587
DI 10.1007/s00371-017-1362-0
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FY6BJ
UT WOS:000426924400010
DA 2024-07-18
ER

PT J
AU Song, CF
   Pang, ZQ
   Jing, XY
   Xiao, CX
AF Song, Chengfang
   Pang, Zhiqiang
   Jing, Xiaoyuan
   Xiao, Chunxia
TI Distance field guided -median skeleton extraction
SO VISUAL COMPUTER
LA English
DT Article
DE Skeleton extraction; Point cloud; Skeleton alignment; L-1-median;
   Distance Transform
ID SURFACE
AB We introduce a distance field guided -median method to extract topologically clean 1D curve skeleton from the point cloud model. We first voxelize the input point cloud, and compute the distance field for the point cloud. Then with the distance field, we extract the initial skeleton of the model using a multi-scale parameter controlled thinning method. Finally, we incorporate the initial skeleton into the -median optimization, and develop a distance field guided -median to effectively extract the complete skeleton from the point cloud. Our method exhibits the advantages of both the distance field based skeleton extraction methods and the -median skeleton extraction methods. Our skeleton extraction system is robust and effective, and can be applied to the raw scanned point cloud data.
C1 [Song, Chengfang; Pang, Zhiqiang; Jing, Xiaoyuan; Xiao, Chunxia] Wuhan Univ, Sch Comp, State Key Lab Software Engn, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp, State Key Lab Software Engn, Wuhan 430072, Peoples R China.
EM songchf@whu.edu.cn; 1035922601@qq.com; jingxy_2000@126.com;
   cxxiao@whu.edu.cn
RI He, Chen/JLM-5059-2023
FU NSFC [614 72288, 61672390, 41201404, U1536204]; NCET [NCET-13-0441];
   State Key Lab of Software Engineering [SKLSE-2015-A-05]
FX This work was partly supported by NSFC (No. 614 72288, No. 61672390, No.
   41201404, No. U1536204), NCET (NCET-13-0441) and the Key Grant Project
   of State Key Lab of Software Engineering (SKLSE-2015-A-05).
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Bitter I, 2001, IEEE T VIS COMPUT GR, V7, P195, DOI 10.1109/2945.942688
   Bouix S, 2000, LECT NOTES COMPUT SC, V1842, P603
   Bucksch A, 2010, VISUAL COMPUT, V26, P1283, DOI 10.1007/s00371-010-0520-4
   Cao J., 2010, SHAP MOD INT C SMI 2, P187, DOI [DOI 10.1109/SMI.2010.25, 10.1109/SMI.2010.25]
   Chuang JH, 2004, COMPUT GRAPH-UK, V28, P907, DOI 10.1016/j.cag.2004.08.004
   Chuang M, 2011, COMPUT GRAPH FORUM, V30, P1750, DOI 10.1111/j.1467-8659.2011.01899.x
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Dey T.K., 2006, S GEOM PROC, P143, DOI DOI 10.2312/SGP/SGP06/143-152
   Gagvani N, 1999, GRAPH MODEL IM PROC, V61, P149, DOI 10.1006/gmip.1999.0495
   Hassouna MS, 2005, PROC CVPR IEEE, P458
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Jalba AC, 2016, IEEE T PATTERN ANAL, V38, P30, DOI 10.1109/TPAMI.2015.2414420
   Jiang W, 2013, GRAPH MODELS, V75, P137, DOI 10.1016/j.gmod.2012.10.005
   Katz Sagi., 2003, Hierarchical mesh decomposition using fuzzy clustering and cuts, V22
   Kustra J, 2016, PATTERN RECOGN LETT, V76, P13, DOI 10.1016/j.patrec.2015.05.007
   Li G, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866178
   Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343
   Liao B, 2013, COMPUT AIDED DESIGN, V45, P861, DOI 10.1016/j.cad.2013.02.003
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276405
   Livny Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866177
   Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7
   Natali M, 2011, GRAPH MODELS, V73, P151, DOI 10.1016/j.gmod.2011.03.002
   Pang ZQ, 2015, COMPUT ANIMAT VIRT W, V26, P301, DOI 10.1002/cav.1658
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059
   Sharf A, 2007, COMPUT GRAPH FORUM, V26, P323, DOI 10.1111/j.1467-8659.2007.01054.x
   Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8
   SMALL CG, 1990, INT STAT REV, V58, P263, DOI 10.2307/1403809
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Verroust A, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P194, DOI 10.1109/SMA.1999.749340
   Zheng Q, 2015, COMPUT GRAPH FORUM, V34, P275, DOI 10.1111/cgf.12559
   Zhou Y, 1999, IEEE T VIS COMPUT GR, V5, P196, DOI 10.1109/2945.795212
NR 37
TC 18
Z9 22
U1 4
U2 45
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2018
VL 34
IS 2
BP 243
EP 255
DI 10.1007/s00371-016-1331-z
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU6ZO
UT WOS:000424001800008
DA 2024-07-18
ER

PT J
AU Suarez, J
   Belhadj, F
   Boyer, V
AF Suarez, Jordane
   Belhadj, Fares
   Boyer, Vincent
TI Real-time 3D rendering with hatching
SO VISUAL COMPUTER
LA English
DT Article
DE Stylized rendering and animation; Hatching; GPU; Real-time rendering
ID TEXTURE SYNTHESIS
AB We present an approach for real-time pen-and-ink hatching renderings on large scenes. Starting with 3D models including photorealistic textures and materials, we aim to propose a solution that produces hatched renderings. As we consider scene objects described as polygonal meshes with their own textures, we produce once hatching patterns at different tones and resolutions considering the material of each object. To achieve that, we create a flow direction map per texture pixel, using contour characteristics extracted from the original texture and then interpolated. Stroke trajectories are thus generated depending on the flow direction and using B-splines, providing tones from light-to-dark. Tones are then stored in a mutli-resolution tonal art map. Moreover, we aim to overcome the limitations of existing hatching rendering methods by introducing an illumination model, fully implemented on GPU and able to manage three shading types: regular shadow, soft/cast shadow and self-shadowing. Tones and hatching resolutions are, therefore, assigned according to local/global illumination supporting multiple light sources. Our model, both dedicated for 3D static model renderings and 3D model animation, supports model deformations and is also spatially and temporally coherent since it gives continuous hatching strokes during object animations and/or light displacements.
C1 [Suarez, Jordane; Belhadj, Fares; Boyer, Vincent] Univ Paris 08, LIASD, St Denis, Reunion, France.
C3 Universite Paris-VIII
RP Boyer, V (corresponding author), Univ Paris 08, LIASD, St Denis, Reunion, France.
EM suarez@ai.univ-paris8.fr; amsi@ai.univ-paris8.fr;
   boyer@ai.univ-paris8.fr
CR [Anonymous], P EUR
   Barla P, 2006, COMPUT GRAPH FORUM, V25, P663, DOI 10.1111/j.1467-8659.2006.00986.x
   Belhadj F, 2007, AFRIGRAPH 2007: 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, COMPUTER GRAPHICS, VISUALIZATION AND INTERACTION IN AFRICA, P197
   Breslav S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276402
   Chen JZ, 2013, COMPUT GRAPH FORUM, V32, P98, DOI 10.1111/cgf.12164
   Coconu L., 2006, International Symposium on Non-Photorealistic Animation and Rendering NPAR, P27
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   Deussen O, 2000, COMP GRAPH, P13, DOI 10.1145/344779.344792
   Deussen O, 2000, COMPUT GRAPH FORUM, V19, pC41, DOI 10.1111/1467-8659.00396
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Freeman WT, 2003, ACM T GRAPHIC, V22, P33, DOI 10.1145/588272.588277
   Freudenberg B, 2001, COMPUT GRAPH FORUM, V20, pC184, DOI 10.1111/1467-8659.00511
   Fung J, 2003, PROC GRAPH INTERF, P131
   Gerl M, 2013, COMPUT GRAPH-UK, V37, P65, DOI 10.1016/j.cag.2012.11.003
   Girshick Ahna., 2000, Proceedings of International Symposium on Non-Photorealistic Animation and Rendering 2000, P43, DOI DOI 10.1145/340916.340922
   Guptill L.A, 1997, RENDERING PEN INK
   Han JW, 2006, VISUAL COMPUT, V22, P918, DOI 10.1007/s00371-006-0078-3
   Hasenfratz JM, 2003, COMPUT GRAPH FORUM, V22, P753, DOI 10.1111/j.1467-8659.2003.00722.x
   Hertzman A., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P233
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Jodoin Pierre-Marc., 2002, PROC NPAR, P29
   Kalnins RD, 2002, ACM T GRAPHIC, V21, P755, DOI 10.1145/566570.566648
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Kim Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409109
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Lawonn K, 2013, COMPUT GRAPH FORUM, V32, P321, DOI 10.1111/cgf.12119
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921
   Lum EB, 2005, VISUAL COMPUT, V21, P811, DOI 10.1007/s00371-005-0342-y
   Martín D, 2011, COMPUT GRAPH-UK, V35, P160, DOI 10.1016/j.cag.2010.11.006
   Neyret F., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P147
   Paget R, 2004, IEEE T PATTERN ANAL, V26, P408, DOI 10.1109/TPAMI.2004.1262338
   Popat A.C., 1997, VISMOD
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Praun E, 2000, COMP GRAPH, P465, DOI 10.1145/344779.344987
   Roettger S, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P373
   Rössl C, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P87, DOI 10.1109/PCCGA.2000.883890
   Runions A, 2007, VISUAL COMPUT, V23, P945, DOI 10.1007/s00371-007-0153-4
   Salisbury M. P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P101, DOI 10.1145/192161.192185
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Soler C, 2002, ACM T GRAPHIC, V21, P673, DOI 10.1145/566570.566635
   Streit L, 1998, COMPUT GRAPH FORUM, V17, pC207, DOI 10.1111/1467-8659.00268
   Suarez J., 2013, WSCG, P101
   Tamas U, 2011, COMPUT GRAPH FORUM, V30, P533, DOI 10.1111/j.1467-8659.2011.01878.x
   TURK G, 1991, COMP GRAPH, V25, P289, DOI 10.1145/127719.122749
   Turk G, 2001, COMP GRAPH, P347, DOI 10.1145/383259.383297
   VAN WIJK J.J., 2003, VIS 03, P17
   Veryovka O, 2002, PROC GRAPH INTERF, P9
   Webb Matthew., 2002, Proceedings of the 2nd international symposium on Non- photorealistic animation and rendering, NPAR '02, P53, DOI DOI 10.1145/508530.508540
   Wei LY, 2001, COMP GRAPH, P355, DOI 10.1145/383259.383298
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Winkenbach G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P91, DOI 10.1145/192161.192184
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Ying LI, 2001, SPRING EUROGRAP, P301
   Zander J, 2004, COMPUT GRAPH FORUM, V23, P421, DOI 10.1111/j.1467-8659.2004.00773.x
   Zhang E, 2006, ACM T GRAPHIC, V25, P1294, DOI 10.1145/1183287.1183290
NR 56
TC 11
Z9 12
U1 1
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2017
VL 33
IS 10
BP 1319
EP 1334
DI 10.1007/s00371-016-1222-3
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FF8VN
UT WOS:000409296000009
DA 2024-07-18
ER

PT J
AU Han, PF
   Zhao, G
AF Han, Pengfei
   Zhao, Gang
TI Line-based initialization method for mobile augmented reality in
   aircraft assembly
SO VISUAL COMPUTER
LA English
DT Article
DE Line u Initialization; Mobile augmented reality; Aircraft assembly
AB A fast line-based initialization method for mobile augmented reality in aircraft assembly is proposed in this paper. The challenge of recognition and pose estimation of aircraft structural parts in monocular images on mobile devices is mainly addressed. Rather than local feature points, straight lines are extracted and utilized here since they are more suitable for aircraft structural parts, which usually have a solid color and lack textures to generate invariant descriptors. The geometric relationship between 3D world lines and their projections on the camera image are built to estimate the relative 6-DOF pose including rotation and translation, respectively. The inertial sensors of mobile devices are used to provide partial rotation information directly, and the rest is obtained through a voting process. To shrink the search space and, therefore, improve the speed and robustness of initialization, a color-based ROI mask and a vertical lines extraction method are proposed. To determine the translation, the color mask is first used to roughly approximate the real pose and then a possible-correspondence map of lines is built by parallelism alignment combined with the rotation already obtained. This paper describes the details of our method and also shows its effectiveness with experiments. Moreover, the proposed method is especially suitable for but not limited to the aircraft assembly field.
C1 [Han, Pengfei] Beihang Univ, Beijing Key Lab Aircraft Assembly & Robot Equipme, Beijing, Peoples R China.
   [Zhao, Gang] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Zhao, G (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM 163heanas@163.com; zhaog@buaa.edu.cn
RI Zhao, Gang/JMC-6248-2023
FU National Natural Science Foundation of China [2015AA7045038]
FX This research has been partly funded by the National Natural Science
   Foundation of China (2015AA7045038).
CR Alvarez H, 2013, COMPUT VIS IMAGE UND, V117, P1204, DOI 10.1016/j.cviu.2012.08.012
   [Anonymous], P IEEE ACM INT S MIX
   [Anonymous], 2015, METAIO EDGE BASED IN
   [Anonymous], 2014, VUFORIA SMART TERRAI
   [Anonymous], P BRIT MACH VIS C
   Azuma R, 2011, COMPUT GRAPH-UK, V35, pVII, DOI 10.1016/j.cag.2011.05.002
   Bay H., 2008, COMPUTER VISION IMAG, V110, P34659
   Bleser Gabriele., 2006, INT S MIXED AUGMENTE, P56
   Bunnun P, 2012, INT SYM MIX AUGMENT, P273, DOI 10.1109/ISMAR.2012.6402570
   Carmichael O, 2004, IEEE T PATTERN ANAL, V26, P1537, DOI 10.1109/TPAMI.2004.128
   David P, 2005, IEEE I CONF COMP VIS, P1581
   Han PF, 2015, COMPUT GRAPH-UK, V50, P36, DOI 10.1016/j.cag.2015.05.021
   Harris C., 1990, RAPID VIDEO RATE OBJ
   Horejsí P, 2015, PROCEDIA ENGINEER, V100, P699, DOI 10.1016/j.proeng.2015.01.422
   Kim G, 2008, LECT NOTES CONTR INF, V370, P255
   Kim K, 2014, VISUAL COMPUT, V30, P417, DOI 10.1007/s00371-013-0865-6
   Kurz D, 2012, COMPUT GRAPH-UK, V36, P866, DOI 10.1016/j.cag.2012.03.038
   Liarokapis F, 2009, VISUAL COMPUT, V25, P1109, DOI 10.1007/s00371-009-0388-3
   Lilian Zhang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P217, DOI 10.1007/978-3-642-37431-9_17
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Z., 2011, 3 INT C DIG IM PROC, P800
   Mirzaei MR, 2014, VISUAL COMPUT, V30, P245, DOI 10.1007/s00371-013-0841-1
   Qiu ZY, 2009, FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P460, DOI 10.1109/JCAI.2009.149
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Shahrokni A., 2002, P COMP AN, P6569
   Smith A.R., 1978, P 5 ANN C COMP GRAPH, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   Truong Hung Q., 2008, 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2008), P656, DOI 10.1109/MFI.2008.4648019
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
NR 28
TC 16
Z9 17
U1 1
U2 38
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2017
VL 33
IS 9
BP 1185
EP 1196
DI 10.1007/s00371-016-1281-5
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FD1CS
UT WOS:000407275600008
DA 2024-07-18
ER

PT J
AU Chen, Y
   Du, XM
   Yuan, XR
AF Chen, Yi
   Du, Xiaomin
   Yuan, Xiaoru
TI Ordered small multiple treemaps for visualizing time-varying
   hierarchical pesticide residue data
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 34th Conference on Computer Graphics International (CGI)
CY JUN 27-30, 2017
CL Yokohama, JAPAN
SP Keio Univ, Fac Sci & Technol
DE Information visualization; Time-varying hierarchical data; Treemap;
   Metrics; Pesticide residue
ID EVOLUTION; MODEL
AB Small multiples can visually enforce comparisons of changes or differences among objects, revealing potential patterns by providing different views. According to the analyzing requirements in food safety fields and characteristics of pesticide residue detection data, in this paper, we propose a novel visualization approach to explore and analyze the time-varying hierarchical data, which is called ordered small multiple treemaps (OSMT). Inspired by the thought of querying an array by rows or columns, OSMT makes it possible to locate a specific node in the treemap layout by using a unique location 2-tuple and keep a relative stable order of nodes in the layout while we detecting temporal patterns. This algorithm enables the visual representation of the node values varying with time, preserving the hierarchical relationships among nodes in the meanwhile. Based on some interaction techniques (filtering, selecting, highlighting and zooming, etc.), OSMT can help users find some specific changes more easily and thus make corresponding decisions with more efficiency. Besides, we also propose a new metric called TVA (Ability of tracking time-varying data in treemap) with a purpose of evaluating different kinds of treemap layout algorithms from the aspect of the difficulty level for tracking time-varying nodes in the overall layout. Finally, our technique's applicability is demonstrated on the pesticide residues detection results dataset in this study.
C1 [Chen, Yi; Du, Xiaomin] Beijing Technol & Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.
C3 Beijing Technology & Business University; Peking University
RP Chen, Y (corresponding author), Beijing Technol & Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.
EM chenyi@th.btbu.edu.cn
RI Yuan, Xiaoru/E-1798-2013
OI Yuan, Xiaoru/0000-0002-7233-980X; Chen, Yi/0000-0002-4141-0554
FU "Twelfth Five Year Plan" National Science and Technology Support Program
   [2012-BAD29B01-2]; open funding project of State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang University
   [BUAA-VR-17KF-07]; Basic Research Project of the Ministry of Science and
   Technology [2015FY111200]
FX This work is supported by "Twelfth Five Year Plan" National Science and
   Technology Support Program (No. 2012-BAD29B01-2), the open funding
   project of State Key Laboratory of Virtual Reality Technology and
   Systems, Beihang University (Grant No. BUAA-VR-17KF-07), and Basic
   Research Project of the Ministry of Science and Technology (Grand No.
   2015FY111200). The authors also would like to thank the conference of
   CGI 2017, which provides the exchange platform for us.
CR Anand A., 2015, IEEE T VIS COMPUT GR, V22, P1
   Balzer M, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P49, DOI 10.1109/INFVIS.2005.1532128
   Bederson B. B., 2003, CRAFT INFORM VISUALI, P257, DOI DOI 10.1016/B978-155860915-0/50033-0
   Bruls M, 2000, SPRING COMP SCI, P33
   Burch M., 2008, P WORK C ADV VIS INT, P75
   Card S.K., 2002, Proceedings of the 2002 Working Conference on Advanced Visual Interfaces, P231, DOI [DOI 10.1145/1556262.1556300, 10.1145/1556262.1556300]
   Card SK, 2006, IEEE CONF VIS ANAL, P3
   Chen Y, 2015, J VISUAL-JAPAN, V18, P237, DOI 10.1007/s12650-014-0269-3
   Chen Yi, 2013, Journal of Computer Aided Design & Computer Graphics, V25, P1623
   Chintalapani G., 2004, TEMPORAL TREEMAPS VI
   Claessen JHT, 2011, IEEE T VIS COMPUT GR, V17, P2310, DOI 10.1109/TVCG.2011.201
   de Bono B, 2014, LECT NOTES COMPUT SC, V8819, P72, DOI 10.1007/978-3-319-12571-8_7
   de Carvalho MB, 2016, IEEE INT CONF INF VI, P399, DOI 10.1109/IV.2016.65
   Duarte FSLG, 2014, IEEE T VIS COMPUT GR, V20, P2063, DOI 10.1109/TVCG.2014.2346276
   Fekete JD, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P117, DOI 10.1109/INFVIS.2002.1173156
   Fischer Fabian., 2012, PROC EUROVIS SHORT P, P97
   Fuchs J., 2013, P ACM SIGCHI C HUM F, P3237, DOI [10.1145/2470654.2466443, DOI 10.1145/2470654.2466443]
   Ghoniem M., P 18 HCIL S WORKSH T
   Gotz D., 2011, PHYS REV A, V30, P150, DOI 10.1109/TADVP.2007.896008
   Graham M, 2010, INFORM VISUAL, V9, P235, DOI 10.1057/ivs.2009.29
   Greilich M, 2009, COMPUT GRAPH FORUM, V28, P975, DOI 10.1111/j.1467-8659.2009.01451.x
   Guerra-Gomez J. A., 2012, INTERACTIVE VISUALIZ
   Guerra-Gómez JA, 2015, TRANSPORT RES C-EMER, V51, P167, DOI 10.1016/j.trc.2014.11.007
   Guerra-Gómez JA, 2013, TRANSPORT RES REC, P48, DOI 10.3141/2392-06
   Guerra-Gómez JA, 2013, IEEE T VIS COMPUT GR, V19, P2566, DOI 10.1109/TVCG.2013.231
   Hadlak S., 2010, WORKSH GEOSP VIS AN
   Hahn Sebastian, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P50
   Hu Haiyun, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P1703
   Jia Y., 2013, COMMUN COMPUT PHYS, V363, P154
   Johnson B., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P284, DOI 10.1109/VISUAL.1991.175815
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P2287, DOI 10.1109/TVCG.2013.122
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Kutz DO, 2004, IEEE INFOR VIS, P983, DOI 10.1109/IV.2004.1320261
   Lampe O D, 2010, 15 INT WORKSH VIS MO, P315
   Liang J, 2015, J VISUAL LANG COMPUT, V31, P104, DOI 10.1016/j.jvlc.2015.10.009
   Liu SX, 2014, VISUAL COMPUT, V30, P1373, DOI 10.1007/s00371-013-0892-3
   Oliveira EC, 2015, ADV INTELL SYST, V353, P57, DOI 10.1007/978-3-319-16486-1_6
   Plaisant C, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P57, DOI 10.1109/INFVIS.2002.1173148
   Rios-Berrios M, 2012, GOV INFORM Q, V29, P212, DOI 10.1016/j.giq.2011.07.004
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Shi CL, 2012, IEEE T VIS COMPUT GR, V18, P2669, DOI 10.1109/TVCG.2012.253
   Shneiderman B, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P73, DOI 10.1109/INFVIS.2001.963283
   Shneiderman Ben., TREEMAPS SPACE CONST
   Telea A, 2008, COMPUT GRAPH FORUM, V27, P831, DOI 10.1111/j.1467-8659.2008.01214.x
   Tu Y, 2007, IEEE T VIS COMPUT GR, V13, P1286, DOI 10.1109/TVCG.2007.70529
   Wang C., 2013, IS T SPIE ELECT IMAG
   Wittenhagen M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3522, DOI 10.1145/2858036.2858442
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
   Yu L, 2010, COMPUT GRAPH FORUM, V29, P2271, DOI 10.1111/j.1467-8659.2010.01816.x
   Zhang Xin, 2012, Journal of Computer Aided Design & Computer Graphics, V24, P1113
NR 53
TC 12
Z9 13
U1 2
U2 23
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2017
VL 33
IS 6-8
BP 1073
EP 1084
DI 10.1007/s00371-017-1373-x
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EX1EY
UT WOS:000402964800036
DA 2024-07-18
ER

PT J
AU Hu, MX
   Zhou, Y
   Li, XJ
AF Hu, Mingxiao
   Zhou, Yan
   Li, Xujie
TI Robust and accurate computation of geometric distance for Lipschitz
   continuous implicit curves
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 34th Conference on Computer Graphics International (CGI)
CY JUN 27-30, 2017
CL Yokohama, JAPAN
SP Keio Univ, Fac Sci & Technol
DE Geometric distance; Geometric processing; Implicit curve; Foot point;
   Minor arcs evolution; Lipschitz continuity; Circle double-and-bisect
ID SURFACE RECONSTRUCTION; CURVATURE; POINT; PLANAR
AB Computing the geometric distance between a point and an implicitly defined curve is widely used in implicit curve fitting and geometric processing. Iterative numerical methods are often used to compute the distance, which may give quite accurate solutions but are usually time-consuming and non-robust. In this paper, a circle double-and-bisect algorithm is proposed to reliably evaluate the accurate geometric distance of a point to an implicit curve. The method's prerequisite is merely the Lipschitz continuity of the implicit function. Moreover, by using gradient norm's upper bound estimation and minor arcs evolution, the efficiency can be improved apparently. Experimental results show that the evaluated distance can describe the fitting result with more fidelity and that some fitting algorithms (for example, the genetic algorithm) re-implemented with the proposed geometric distance converge much faster. Due to these contributions, the proposed method can be applied in diverse applications such as error evaluation, curve fitting and random point cloud generator.
C1 [Hu, Mingxiao; Zhou, Yan; Li, Xujie] Wenzhou Univ, Coll Phys & Elect Informat Engn, Wenzhou 325035, Zhejiang, Peoples R China.
C3 Wenzhou University
RP Hu, MX (corresponding author), Wenzhou Univ, Coll Phys & Elect Informat Engn, Wenzhou 325035, Zhejiang, Peoples R China.
EM jsj_hmx@wzu.edu.cn
FU Zhejiang Provincial Natural Science Foundation of China [LY14F020032]
FX This research was supported by Zhejiang Provincial Natural Science
   Foundation of China under Grant No. LY14F020032.
CR Ahn SJ, 2001, PATTERN RECOGN, V34, P2283, DOI 10.1016/S0031-3203(00)00152-7
   [Anonymous], 2004, LEAST SQUARES ORTHOG
   Bajaj CL, 1997, ALGORITHMICA, V19, P243, DOI 10.1007/PL00014418
   Bo PB, 2012, COMPUT GRAPH-UK, V36, P534, DOI 10.1016/j.cag.2012.03.036
   Cheng KSD, 2007, IEEE T VIS COMPUT GR, V13, P878, DOI 10.1109/TVCG.2007.1064
   De la Fraga LG, 2007, LECT NOTES COMPUT SC, V4448, P359
   Elber G., 2001, P 6 ACM S SOLID MODE, P1, DOI [10.1145/376957.376958, DOI 10.1145/376957.376958]
   Gotardo PFU, 2004, IEEE T SYST MAN CY B, V34, P2303, DOI 10.1109/TSMCB.2004.835082
   Hartmann E, 1999, COMPUT AIDED GEOM D, V16, P355, DOI 10.1016/S0167-8396(99)00003-5
   Hu MX, 2010, VISUAL COMPUT, V26, P801, DOI 10.1007/s00371-010-0476-4
   Hunyadi L, 2011, 2011 2ND EASTERN EUROPEAN REGIONAL CONFERENCE ON THE ENGINEERING OF COMPUTER BASED SYSTEMS (ECBS-EERC), P106, DOI 10.1109/ECBS-EERC.2011.24
   Jüttler B, 2002, ADV COMPUT MATH, V17, P135, DOI 10.1023/A:1015200504295
   Juttler B., 2005, P 21 SPRING C COMP G, P13
   Kanatani K, 2011, COMPUT STAT DATA AN, V55, P2197, DOI 10.1016/j.csda.2010.12.012
   Kanatani K, 2010, J MATH IMAGING VIS, V38, P1, DOI 10.1007/s10851-010-0206-6
   Li Yun-Xi, 2007, Journal of Software, V18, P2306, DOI 10.1360/jos182306
   Martin A., 2004, MATH METHODS CURVES, P1
   Mullen P, 2010, COMPUT GRAPH FORUM, V29, P1733, DOI 10.1111/j.1467-8659.2010.01782.x
   Nishita T., 1990, Computer Graphics, V24, P337, DOI 10.1145/97880.97916
   Redding NJ, 2000, IEEE T PATTERN ANAL, V22, P191, DOI 10.1109/34.825757
   Rouhani M, 2012, IEEE T IMAGE PROCESS, V21, P2089, DOI 10.1109/TIP.2011.2170080
   SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0
   Sappa AD, 2009, IEEE IMAGE PROC, P3521, DOI 10.1109/ICIP.2009.5414072
   Schulz T, 2011, APPL ALGEBR ENG COMM, V22, P265, DOI 10.1007/s00200-011-0149-1
   SHERBROOKE EC, 1993, COMPUT AIDED GEOM D, V10, P379, DOI 10.1016/0167-8396(93)90019-Y
   Song XH, 2009, COMPUT GRAPH-UK, V33, P321, DOI 10.1016/j.cag.2009.03.021
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Upreti K, 2017, COMPUT AIDED DESIGN, V82, P112, DOI 10.1016/j.cad.2016.09.006
   Upreti K, 2014, COMPUT METHOD APPL M, V280, P28, DOI 10.1016/j.cma.2014.07.012
   Wang WP, 2006, ACM T GRAPHIC, V25, P214, DOI 10.1145/1138450.1138453
   Xinghua Song, 2010, Proceedings of the Shape Modeling International (SMI 2010), P241, DOI 10.1109/SMI.2010.18
   Zagorchev LG, 2012, IEEE T VIS COMPUT GR, V18, P1460, DOI 10.1109/TVCG.2011.276
NR 32
TC 8
Z9 10
U1 3
U2 14
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2017
VL 33
IS 6-8
BP 937
EP 947
DI 10.1007/s00371-017-1370-0
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EX1EY
UT WOS:000402964800024
DA 2024-07-18
ER

PT J
AU Henz, B
   Oliveira, MM
AF Henz, Bernardo
   Oliveira, Manuel M.
TI Artistic relighting of paintings and drawings
SO VISUAL COMPUTER
LA English
DT Article
DE Image relighting; Painting relighting; Drawing relighting; Normal and
   depth map transfer
ID ILLUMINATION TRANSFER; COLOR; IMAGE; VIDEO; SHAPE
AB We present a practical solution to the problem of subject relighting in paintings and drawings. Our interactive technique uses 3-D shading proxies and can be applied to objects with arbitrary geometries. Given a user-provided guess for the shading of an object in a painting/drawing and its corresponding target shading, we refine them using shading-color correlation and a multi-scale scheme. These refined shadings are then used to create a multi-channel shading-ratio image to perform relighting, while taking into account the colors used by the artists to convey shading information. We demonstrate the effectiveness of our solution on a variety of artistic styles, including paintings with strong brush strokes and unconventional shading encodings, drawings, and other types of artwork. Our method is the first to perform relighting of paintings and drawings and, in addition to relighting, can transfer smooth normal and depth maps from 3-D proxies to images.
C1 [Henz, Bernardo; Oliveira, Manuel M.] Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Henz, B (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.
EM bhenz@inf.ufrgs.br; oliveira@inf.ufrgs.br
RI Henz, Bernardo/T-3523-2019; Li, Mengqi/AAG-6804-2021; Menezes de
   Oliveira Neto, Manuel/H-1508-2011
OI Henz, Bernardo/0000-0003-2123-0537; Menezes de Oliveira Neto,
   Manuel/0000-0003-4957-9984
FU CAPES; CNPq-Brazil [134134/2013-3, 306196/2014-0, 482271/2012-4]
FX This work was sponsored by CAPES and CNPq-Brazil (Grants 134134/2013-3,
   306196/2014-0, and 482271/2012-4). We would like to thank the artists
   for allowing us to use their art works.
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   Akers D., 2003, VIS 03, P46
   [Anonymous], NPAR 10
   [Anonymous], RENDERING TECHNIQUES
   [Anonymous], CRAZYBUMP DEMO VERSI
   [Anonymous], ACM TOG
   [Anonymous], 1998, THESIS
   [Anonymous], ANTHROPICS PORTRAITP
   [Anonymous], 2002, Proceedings of the Symposium on Non-photorealistic animation and rendering
   [Anonymous], ACM TOG
   [Anonymous], ACM SIGGRAPH 09
   [Anonymous], 2006, PROC PAC GRAPHICS
   Anrys F, 2004, P 4 IASTED INT C VIS, P1
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5
   Basso A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P1085, DOI 10.1109/ICIP.2001.958686
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Boivin S, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P268
   Chen T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508378
   Chen XW, 2012, COMPUT GRAPH FORUM, V31, P1425, DOI 10.1111/j.1467-8659.2012.03138.x
   Chen XW, 2011, PROC CVPR IEEE, P281, DOI 10.1109/CVPR.2011.5995473
   Costa AC, 1999, SPRING EUROGRAP, P317
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Hu KX, 2014, VISUAL COMPUT, V30, P685, DOI 10.1007/s00371-014-0962-1
   Kholgade N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601209
   Li GN, 2013, COMPUT GRAPH FORUM, V32, P275, DOI 10.1111/cgf.12047
   Li Q, 2010, VISUAL COMPUT, V26, P41, DOI 10.1007/s00371-009-0375-8
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Loscos C, 2000, IEEE T VIS COMPUT GR, V6, P289, DOI 10.1109/2945.895874
   Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320
   Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Shapira D, 2013, IEEE IMAGE PROC, P2269, DOI 10.1109/ICIP.2013.6738468
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shih YC, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601137
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Sykora D, 2010, COMPUT GRAPH FORUM, V29, P615, DOI 10.1111/j.1467-8659.2009.01631.x
   Sykora D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591011
   Tunwattanapong B., 2011, 2011 Conference for Visual Media Production, P138, DOI 10.1109/CVMP.2011.22
   Wang O, 2008, COMPUT GRAPH FORUM, V27, P271, DOI 10.1111/j.1467-8659.2008.01124.x
   Wang Yang., 2007, CVPR 07
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Wen Z, 2003, PROC CVPR IEEE, P158
   Wu CL, 2011, IEEE I CONF COMP VIS, P1108, DOI 10.1109/ICCV.2011.6126358
   Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388
   Wu TP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409072
NR 47
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2017
VL 33
IS 1
BP 33
EP 46
DI 10.1007/s00371-015-1150-7
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI2JM
UT WOS:000392313200005
DA 2024-07-18
ER

PT J
AU Das Dawn, D
   Shaikh, SH
AF Das Dawn, Debapratim
   Shaikh, Soharab Hossain
TI A comprehensive survey of human action recognition with spatio-temporal
   interest point (STIP) detector
SO VISUAL COMPUTER
LA English
DT Article
DE Human action recognition; Human activity recognition; Spatio-temporal
   interest point; STIP
AB Over the past two decades, human action recognition from video has been an important area of research in computer vision. Its applications include surveillance systems, human-computer interactions and various real-world applications where one of the actor is a human being. A number of review works have been done by several researchers in the context of human action recognition. However, it is found that there is a gap in literature when it comes to methodologies of STIP-based detector for human action recognition. This paper presents a comprehensive review on STIP-based methods for human action recognition. STIP-based detectors are robust in detecting interest points from video in spatio-temporal domain. This paper also summarizes related public datasets useful for comparing performances of various techniques.
C1 [Das Dawn, Debapratim; Shaikh, Soharab Hossain] Univ Calcutta, Kolkata, India.
C3 University of Calcutta
RP Das Dawn, D (corresponding author), Univ Calcutta, Kolkata, India.
EM debapratimdd@gmail.com; soharab.h.shaikh@ieee.org
RI Hossain Shaikh, Soharab/AAF-6303-2019
OI Hossain Shaikh, Soharab/0000-0003-3409-8467
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], PROC BRIT MACH VIS C, DOI DOI 10.5244/C.24.52.1
   [Anonymous], ISPRS INT WORKSH
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], VIS COMPUT
   [Anonymous], 2013, IEEE T CIRCUITS SYST, DOI DOI 10.1109/TCSVT.2013.2276856
   [Anonymous], 2004, INT WORKSHOP SPATIAL
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], INT J INNOV RES COMP
   [Anonymous], IEEE P NONR ART MOT
   [Anonymous], ECCV 02 WORKSH STAT
   [Anonymous], CMURITR8003 CARN MEL
   [Anonymous], P 5 INT C BIOM ENG I
   [Anonymous], CVPR 13
   Baumberg A, 1996, IMAGE VISION COMPUT, V14, P525, DOI 10.1016/0262-8856(96)01092-X
   Cao LL, 2010, IEEE INT CON MULTI, P340, DOI 10.1109/ICME.2010.5583562
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Chakraborty B, 2011, IEEE I CONF COMP VIS, P1776, DOI 10.1109/ICCV.2011.6126443
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Guan D, 2011, IETE TECH REV, V28, P418, DOI 10.4103/0256-4602.85975
   Harris C., 1988, ALVEY VISION C, P147151
   Hassner T, 2013, IEEE COMPUT SOC CONF, P245, DOI 10.1109/CVPRW.2013.43
   Iosifidis A, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P522, DOI 10.1109/IIH-MSP.2013.135
   Jiang XB, 2014, VISUAL COMPUT, V30, P1021, DOI 10.1007/s00371-014-0923-8
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kliper-Gross O, 2012, IEEE T PATTERN ANAL, V34, P615, DOI 10.1109/TPAMI.2011.209
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Krüger V, 2007, ADV ROBOTICS, V21, P1473
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2004, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2004.1334003
   Laptev I, 2003, LECT NOTES COMPUT SC, V2695, P372
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Matikainen P, 2010, LECT NOTES COMPUT SC, V6311, P508, DOI 10.1007/978-3-642-15549-9_37
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mukherjee S, 2011, IEEE T CIRC SYST VID, V21, P1228, DOI 10.1109/TCSVT.2011.2135290
   Munaro M, 2013, BIOL INSPIR COGN ARC, V5, P42, DOI 10.1016/j.bica.2013.05.008
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ramanathan M, 2014, IEEE T HUM-MACH SYST, V44, P650, DOI 10.1109/THMS.2014.2325871
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Singh VK, 2011, VISUAL COMPUT, V27, P1115, DOI 10.1007/s00371-011-0656-x
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang H, 2009, J OPTOELECTRON BIOME, V1, P1
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong S.-F., 2007, P 11 IEEE INT C COMP, P1
   Wu QX, 2013, IEEE T SYST MAN CY-S, V43, P875, DOI 10.1109/TSMCA.2012.2226575
   Xu X, 2013, SENSORS-BASEL, V13, P1635, DOI 10.3390/s130201635
   Yan XS, 2012, NEUROCOMPUTING, V87, P51, DOI 10.1016/j.neucom.2012.02.002
   Yu G., 2012, Acm international conference on multimedia, P1049
   Zhang H., 2011, P 2011 IEEE RSJ INT, P2044, DOI [DOI 10.1109/IROS.2011.6094489, 10.1109/IROS.2011.6094489]
NR 65
TC 122
Z9 133
U1 1
U2 54
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2016
VL 32
IS 3
BP 289
EP 306
DI 10.1007/s00371-015-1066-2
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF9FK
UT WOS:000371666200003
DA 2024-07-18
ER

PT J
AU De Magistris, G
   Micaelli, A
   Evrard, P
   Savin, J
AF De Magistris, Giovanni
   Micaelli, Alain
   Evrard, Paul
   Savin, Jonathan
TI A human-like learning control for digital human models in a
   physics-based virtual environment
SO VISUAL COMPUTER
LA English
DT Article
DE Digital human model; Motion control; Bio-inspired motor control; Virtual
   reality
ID MUSCLE-STIFFNESS; MOVEMENTS; DYNAMICS; ARM; COMPENSATION; INFORMATION;
   STABILITY; BALANCE; SYSTEM
AB This paper presents a new learning control framework for digital human models in a physics-based virtual environment. The novelty of our controller is that it combines multi-objective control based on human properties (combined feedforward and feedback controller) with a learning technique based on human learning properties (human-being's ability to learn novel task dynamics through the minimization of instability, error and effort). This controller performs multiple tasks simultaneously (balance, non-sliding contacts, manipulation) in real time and adapts feedforward force as well as impedance to counter environmental disturbances. It is very useful to deal with unstable manipulations, such as tool-use tasks, and to compensate for perturbations. An interesting property of our controller is that it is implemented in Cartesian space with joint stiffness, damping and torque learning in a multi-objective control framework. The relevance of the proposed control method to model human motor adaptation has been demonstrated by various simulations.
C1 [De Magistris, Giovanni; Micaelli, Alain; Evrard, Paul] CEA, LIST, LSI, F-91190 Gif Sur Yvette, France.
   [Savin, Jonathan] INRS, F-54519 Vand Oeuvre Les Nancy, France.
C3 Universite Paris Saclay; Institut Polytechnique de Paris; Ecole
   Polytechnique; CEA; Centre National de la Recherche Scientifique (CNRS)
RP De Magistris, G (corresponding author), CEA, LIST, LSI, Rue Noetzlin, F-91190 Gif Sur Yvette, France.
EM giovanni_demagistris@hotmail.it
CR Abe Y, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P249
   [Anonymous], 2000, DYNAMICS MODELLING C
   [Anonymous], J QUALITY TECHNOLOGY
   [Anonymous], ITERATIVE LEARNING C
   ASTROM KJ, 1977, AUTOMATICA, V13, P457, DOI 10.1016/0005-1098(77)90067-X
   Badler N, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P28, DOI 10.1109/NAMW.1997.609848
   Bretl T, 2008, IEEE T ROBOT, V24, P794, DOI 10.1109/TRO.2008.2001360
   Buchli J, 2011, INT J ROBOT RES, V30, P820, DOI 10.1177/0278364911402527
   Burdet E, 2006, BIOL CYBERN, V94, P20, DOI 10.1007/s00422-005-0025-9
   Burdet E, 2001, NATURE, V414, P446, DOI 10.1038/35106566
   Chaffin DB, 2007, HUM FACTOR ERGON MAN, V17, P475, DOI 10.1002/hfm.20087
   Cheah CC, 1998, IEEE T ROBOTIC AUTOM, V14, P452, DOI 10.1109/70.678454
   Commuri S, 1996, IEEE INT CONF ROBOT, P2604, DOI 10.1109/ROBOT.1996.506555
   De Magistris G., 2011, 1 INT S DIG HUM MOD
   De Magistris G, 2013, INT J IND ERGONOM, V43, P170, DOI 10.1016/j.ergon.2013.01.003
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985
   Franklin DW, 2008, J NEUROSCI, V28, P11165, DOI 10.1523/JNEUROSCI.3099-08.2008
   Ganesh G., 2010, IEEE INT C ROB AUT
   Gomi H, 1998, J NEUROSCI, V18, P8965
   Gribble PL, 1999, J NEUROPHYSIOL, V82, P2310, DOI 10.1152/jn.1999.82.5.2310
   Grossman T, 2004, P SIGCHI C HUM FACT, V6, P447, DOI [10.1145/985692.985749, DOI 10.1145/985692.985749]
   Haddadin S, 2009, INT J ROBOT RES, V28, P1507, DOI 10.1177/0278364909343970
   Hanavan EP., 1964, Amrl-Tr-64-102, P1
   Hogan N., 1990, Multiple muscle systems biomechanics and movement organization, P1
   Hovland GE, 1996, IEEE INT CONF ROBOT, P2706, DOI 10.1109/ROBOT.1996.506571
   HYMAN R, 1953, J EXP PSYCHOL, V45, P188, DOI 10.1037/h0056940
   Ioannou PetrosA., 1983, Lecture Notes in Control and Information Sciences, V47
   Jagannathan S., 2006, Neural Network Control of Nonlinear Discrete-Time Systems
   KAWATO M, 1992, BIOL CYBERN, V68, P95, DOI 10.1007/BF00201431
   KHATIB O., 2004, Int J Humanoid Robot, V01, P29, DOI [DOI 10.1142/S0219843604000058, 10.1142/S0219843604000058]
   KIRSCH RF, 1994, IEEE T BIO-MED ENG, V41, P758, DOI 10.1109/10.310091
   LACKNER JR, 1994, J NEUROPHYSIOL, V72, P299, DOI 10.1152/jn.1994.72.1.299
   Lämkull D, 2009, INT J IND ERGONOM, V39, P428, DOI 10.1016/j.ergon.2008.10.005
   Liu MX, 2011, IEEE INT CONF ROBOT, P1676, DOI 10.1109/ICRA.2011.5980078
   McIntyre J, 1996, EXP BRAIN RES, V110, P248
   Merlhiot X., 2009, P MULT DYN ECCOMAS T
   MILNER TE, 1993, EXP BRAIN RES, V94, P522
   MORASSO P, 1981, EXP BRAIN RES, V42, P223
   MORASSO P, 1982, BIOL CYBERN, V45, P131, DOI 10.1007/BF00335240
   Morasso PG, 2002, J NEUROPHYSIOL, V88, P2157, DOI 10.1152/jn.2002.88.4.2157
   Occhipinti E, 1998, ERGONOMICS, V41, P1290, DOI 10.1080/001401398186315
   Perreault EJ, 2004, EXP BRAIN RES, V157, P507, DOI 10.1007/s00221-004-1864-7
   Porter JM, 2004, INT J IND ERGONOM, V33, P249, DOI 10.1016/j.ergon.2003.08.002
   PRAKASH N, 1981, DIFFERENTIAL GEOMETR
   Pratt J, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P1219, DOI 10.1109/IROS.1996.568974
   Salini J., 2012, THESIS U PIERRE M CU
   Schaub K, 1997, HUM FACTORS ERGONOM, V7, P269, DOI 10.1002/(SICI)1520-6564(199723)7:4<269::AID-HFM2>3.0.CO;2-1
   SHADMEHR R, 1994, J NEUROSCI, V14, P3208
   Slotine J.-J. E., 1991, APPL NONLINEAR CONTR, V199
   Smith AM, 1996, BEHAV BRAIN SCI, V19, P399, DOI 10.1017/S0140525X00081498
   Tee KP, 2010, BIOL CYBERN, V102, P31, DOI 10.1007/s00422-009-0348-z
   UNO Y, 1989, BIOL CYBERN, V61, P89, DOI 10.1007/BF00204593
   Vignes RM, 2004, MODELING MUSCLE FATI
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2
   WON J, 1995, EXP BRAIN RES, V107, P125
   Yang CG, 2011, IEEE T ROBOT, V27, P918, DOI 10.1109/TRO.2011.2158251
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 71
TC 1
Z9 1
U1 0
U2 29
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2015
VL 31
IS 4
BP 423
EP 440
DI 10.1007/s00371-014-0939-0
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA CD2IW
UT WOS:000350901600005
DA 2024-07-18
ER

PT J
AU Lai, YK
   Rosin, PL
AF Lai, Yu-Kun
   Rosin, Paul L.
TI Artistic rendering enhancing global structure
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Computational Visual Media Conference
CY 2013
CL Geneva, SWITZERLAND
DE Non-photorealistic rendering; Global structure; Multiple support; Hough
   transform; Deformation; Snapping
ID IMAGE; ABSTRACTION
AB Non-photorealistic rendering techniques usually produce abstracted images. Most existing methods consider local rendering primitives, and global structures may be easily obscured. Inspired by artists, we propose a novel image abstraction method that considers preserving or even enhancing global structures in the input images. Linear structures are particularly considered due to their wide existence and the availability of techniques for their reliable detection. Based on various computer vision techniques, the algorithm is fully automatic. As demonstrated in the paper, artistic looking results are obtained for various types of images. The technique is orthogonal to many non-photorealistic rendering techniques and can be combined with them.
C1 [Lai, Yu-Kun; Rosin, Paul L.] Cardiff Univ, Sch Comp Sci & Informat, Cardiff, S Glam, Wales.
C3 Cardiff University
RP Lai, YK (corresponding author), Cardiff Univ, Sch Comp Sci & Informat, Cardiff, S Glam, Wales.
EM Yukun.Lai@cs.cardiff.ac.uk; Paul.Rosin@cs.cardiff.ac.uk
RI Lai, Yu-Kun/D-2343-2010
OI Rosin, Paul/0000-0002-4965-3884
CR [Anonymous], ACM T GRAPH
   Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   BISCHOF WF, 1988, COMPUT VISION GRAPH, V42, P192, DOI 10.1016/0734-189X(88)90163-6
   BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5
   Bousseau A., 2006, P NPAR, P141, DOI [DOI 10.1145/1124728.1124751, 10.1145/1124728.1124751]
   Bousseau A., 2013, ACM T GRAPHIC, V32, P18
   Boyer KL, 1999, COMPUT VIS IMAGE UND, V76, P1, DOI 10.1006/cviu.1999.0797
   Cao Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366160
   Child J., 2008, STUDIO PHOTOGRAPHY E
   Clarke L, 2011, IEEE T VIS COMPUT GR, V17, P808, DOI 10.1109/TVCG.2010.76
   Collomosse JP, 2005, IEEE T VIS COMPUT GR, V11, P540, DOI 10.1109/TVCG.2005.85
   Collomosse JP, 2003, IEEE T VIS COMPUT GR, V9, P443, DOI 10.1109/TVCG.2003.1260739
   Cong L, 2011, VISUAL COMPUT, V27, P187, DOI 10.1007/s00371-010-0522-2
   Cour T, 2005, PROC CVPR IEEE, P1124
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hiller S, 2003, COMPUT GRAPH FORUM, V22, P515, DOI 10.1111/1467-8659.00699
   Huang H, 2011, VISUAL COMPUT, V27, P861, DOI 10.1007/s00371-011-0596-5
   Jie Xu, 2007, Proceedings Graphics Interface 2007, P43
   Kang H, 2008, COMPUT GRAPH FORUM, V27, P1773, DOI 10.1111/j.1467-8659.2008.01322.x
   Kolesnikov A, 2005, PATTERN RECOGN, V38, P381, DOI 10.1016/j.patcog.2004.07.005
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   Li XY, 2013, IEEE T IMAGE PROCESS, V22, P1915, DOI 10.1109/TIP.2013.2237922
   LUTKENHONER B, 1991, ACTA OTO-LARYNGOL, P52
   Ma LQ, 2012, COMPUT GRAPH-UK, V36, P1005, DOI 10.1016/j.cag.2012.08.001
   Mould D., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P20
   Nan LL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024219
   ORZAN A, 2007, ACM S NONPH AN REND, P103
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Rosin PL, 2013, GRAPH MODELS, V75, P208, DOI 10.1016/j.gmod.2013.03.004
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Son M, 2011, GRAPH MODELS, V73, P74, DOI 10.1016/j.gmod.2010.12.001
   Song Y.-Z., 2008, CAE, P65, DOI [DOI 10.2312/COMPAESTH/COMPAESTH08/065-072, 10.2312/compaesth/compaesth08/065-072]
   Sonka M., 2007, Image Processing, Analysis, and Machine Vision
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Wen F., 2006, PROC INT S NONPHOTOR, P47
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Yang CK, 2008, VISUAL COMPUT, V24, P303, DOI 10.1007/s00371-007-0183-y
   Zhang JW, 2012, VISUAL COMPUT, V28, P877, DOI 10.1007/s00371-012-0702-3
   Zhang SH, 2011, IEEE T MULTIMEDIA, V13, P1286, DOI 10.1109/TMM.2011.2165052
NR 45
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2014
VL 30
IS 10
BP 1179
EP 1193
DI 10.1007/s00371-013-0898-x
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA AP6NF
UT WOS:000342193800011
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Morigi, S
   Rucci, M
AF Morigi, S.
   Rucci, M.
TI Multilevel mesh simplification
SO VISUAL COMPUTER
LA English
DT Article
DE Incremental decimation; p-Laplacian flow; Simplification;
   Multiresolution representation
ID DISCRETE REGULARIZATION; IRREGULAR MESHES; WEIGHTED GRAPHS; IMAGE;
   DIFFUSION; ALGORITHM
AB The goal of a multilevel simplification method is to produce different levels of refinement of a mesh, reducing the resolution (total number of faces), while preserving the original topology and a good approximation to the original geometry. A new approach to simplification based on the evolution of surfaces under p-Laplacian flow is presented. Such an evolution provides a natural geometric clustering process where the spatial effect of the p-Laplacian allows for identifying suitable regions that need to be simplified. The concrete scheme is a multiresolution framework composed, at each simplification level, of a spatial clustering diffusion flow to determine the potential candidates for deletion, followed by an incremental decimation process to update the mesh vertex locations in order to decrease the overall resolution. Numerical results show the effectiveness of our strategy in multilevel simplification of different models with different complexities, in particular for models characterized by sharp features and flat parts.
C1 [Morigi, S.; Rucci, M.] Univ Bologna, Dept Math, CIRAM, Bologna, Italy.
C3 University of Bologna
RP Morigi, S (corresponding author), Univ Bologna, Dept Math, CIRAM, Bologna, Italy.
EM serena.morigi@unibo.it; marco.rucci4@unibo.it
CR Ainsworth M, 1999, NUMER MATH, V82, P351, DOI 10.1007/s002110050423
   [Anonymous], 2003, Level of detail for 3D graphics
   [Anonymous], 1993, Modeling in Computer Graphics
   [Anonymous], 2008, MESHLAB OPEN SOURCE, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   Bae E, 2010, LECT NOTES COMPUT SC, V5862, P1, DOI 10.1007/978-3-642-11620-9_1
   Borouchaki H, 2005, COMPUT METHOD APPL M, V194, P4864, DOI 10.1016/j.cma.2004.11.016
   Botsch M., 2010, Polygon Mesh Processing
   Bougleux S, 2007, LECT NOTES COMPUT SC, V4485, P128
   Chan TF, 2006, MULTISCALE MODEL SIM, V5, P615, DOI 10.1137/050644999
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cignoni P, 1998, COMPUT GRAPH-UK, V22, P37, DOI 10.1016/S0097-8493(97)00082-4
   Cunderlík R, 2013, J GEODESY, V87, P143, DOI 10.1007/s00190-012-0587-y
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Elmoataz A, 2008, IEEE T IMAGE PROCESS, V17, P1047, DOI 10.1109/TIP.2008.924284
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577
   Hoppe H., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P59, DOI 10.1109/VISUAL.1999.809869
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Huang YQ, 2007, J SCI COMPUT, V32, P343, DOI 10.1007/s10915-007-9134-z
   Kim SJ, 2002, COMPUT GRAPH-UK, V26, P657, DOI 10.1016/S0097-8493(02)00121-8
   Li YY, 1996, IEEE T IMAGE PROCESS, V5, P987, DOI 10.1109/83.503914
   Liu W., 2002, SIAM J NUMER ANAL, V40, P1780
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Morigi S., 2011, LNCS, V6667, P38
   Ng MK, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/74585
   Oberman A., 2011, PREPRINT, P1
   Pinkall U., 1993, Exp. Math., V2, P15, DOI 10.1080/10586458.1993.10504266
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schneider R, 2001, COMPUT AIDED GEOM D, V18, P359, DOI 10.1016/S0167-8396(01)00036-X
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Zhou D., 2004, P ICML WORKSH STAT R, P132
   Zhou DY, 2005, LECT NOTES COMPUT SC, V3663, P361
NR 33
TC 8
Z9 12
U1 2
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2014
VL 30
IS 5
BP 479
EP 492
DI 10.1007/s00371-013-0873-6
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AF2AN
UT WOS:000334515100002
DA 2024-07-18
ER

PT J
AU Sahami, S
   Amirani, MC
AF Sahami, Sadid
   Amirani, Mehdi Chehel
TI Matrix based cyclic spectral estimator for fast and robust texture
   classification
SO VISUAL COMPUTER
LA English
DT Article
DE Texture classification; Cyclostationary analysis; Spectral correlation
   estimator; SSCA; FAM
ID LOCAL BINARY PATTERNS; FEATURES; DESCRIPTOR
AB Utilization of cyclostationarity is a fresh paradigm in texture classification. This paper employs the Strip Spectral Correlation Analyzer (SSCA) as the new and superior method of such a category. The SSCA has been much more computational efficient than the other spectral correlation estimators, such as the FFT-Accumulated Method (FAM) or Direct Frequency Smoothing (DFS). Further, for comparable efficacy of the cyclostationary based analyzers, two new algorithms for implementation of both SSCA and FAM are proposed. The algorithms are fast, parallel, and linear-algebraic based, which brings many advantages in computational competence, feature generation flexibility, simplicity, and hardware implementation. SSCA as the unused promising texture analyzer and the new FAM implementation are compared with other state of the art methods in the case of classification accuracy, noise resistance and feature efficiency.
C1 [Sahami, Sadid; Amirani, Mehdi Chehel] Urmia Univ, Dept Elect Engn, Orumiyeh, Iran.
   [Amirani, Mehdi Chehel] Urmia Univ, Orumiyeh, Iran.
C3 Urmia University; Urmia University
RP Sahami, S (corresponding author), Urmia Univ, Dept Elect Engn, Orumiyeh, Iran.
EM st_s.sahami@urmia.ac.ir; m.amirani@urmia.ac.ir
RI Chehel Amirani, Mehdi/AGL-1681-2022
OI Chehel Amirani, Mehdi/0000-0002-5179-9831
CR Abadi M., 2006, LEGENDRE SPECTRUM TE
   Abbadeni N, 2011, IEEE T IMAGE PROCESS, V20, P236, DOI 10.1109/TIP.2010.2060345
   Al Nadi D.A., 2008, INDEPENDENT COMPONEN, P1
   Amirani MC, 2009, FUND INFORM, V95, P245, DOI 10.3233/FI-2009-149
   [Anonymous], 2007, Computer Vision
   Cheng QA, 2011, IEEE T PATTERN ANAL, V33, P1217, DOI 10.1109/TPAMI.2010.195
   Coggins J. M, 1983, AAI8315444
   Dong YS, 2011, IEEE SIGNAL PROC LET, V18, P247, DOI 10.1109/LSP.2011.2111369
   Fu X., 2008, CENTRALIZED BINARY P
   Gardner W.A., 1986, Statistical spectral analysis: a nonprobabilistic theory
   GARDNER WA, 1988, IEEE T COMMUN, V36, P897, DOI 10.1109/26.3769
   Gardner WA, 1991, IEEE SIGNAL PROC MAG, V8, P8
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Iakovidis D. K, 2008, FUZZY LOCAL BINARY P
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Khellah FM, 2011, IEEE T IMAGE PROCESS, V20, P3270, DOI 10.1109/TIP.2011.2143422
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Li X, 2010, IEEE SIGNAL PROC LET, V17, P308, DOI 10.1109/LSP.2009.2036653
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Martens G, 2010, VISUAL COMPUT, V26, P915, DOI 10.1007/s00371-010-0455-9
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Ojala T., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P311
   Phil B., 1999, TEXTURES PHOTOGRAPHI
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Recio JAR, 2005, FIS TIERRA, V17, P47
   Roberts RS, 1991, IEEE SIGNAL PROC MAG, V8, P38, DOI 10.1109/79.81008
   Rosiles JG, 2008, INT CONF ACOUST SPEE, P1325, DOI 10.1109/ICASSP.2008.4517862
   Tou J.Y., 2009, RECENT TRENDS TEXTUR
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Van Loan CF, 2000, J COMPUT APPL MATH, V123, P85, DOI 10.1016/S0377-0427(00)00393-9
   Wang ZZ, 2008, IEEE T IMAGE PROCESS, V17, P1421, DOI 10.1109/TIP.2008.926150
   Xu Q, 2006, INT C PATT RECOG, P29
   Zhang B., 2010, LOCAL DERIVATIVE PAT
   Zhang H, 2005, INT J PATTERN RECOGN, V19, P183, DOI 10.1142/S0218001405003983
   Zhao YD, 2007, IEEE T GEOSCI REMOTE, V45, P1458, DOI 10.1109/TGRS.2007.892602
NR 38
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2013
VL 29
IS 12
BP 1245
EP 1257
DI 10.1007/s00371-012-0766-0
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 251LB
UT WOS:000326929200002
DA 2024-07-18
ER

PT J
AU Livesu, M
   Scateni, R
AF Livesu, Marco
   Scateni, Riccardo
TI Extracting curve-skeletons from digital shapes using occluding contours
SO VISUAL COMPUTER
LA English
DT Article
DE Curve-skeleton; Perceptual shape analysis
ID VOLUME INTERSECTION; RECONSTRUCTION
AB Curve-skeletons are compact and semantically relevant shape descriptors, able to summarise both topology and pose of a wide range of digital objects. Most of the state-of-the-art algorithms for their computation rely on the type of geometric primitives used and sampling frequency. In this paper, we introduce a formally sound and intuitive definition of a curve-skeleton, then we propose a novel method for skeleton extraction that relies on the visual appearance of the shapes. To achieve this result, we inspect the properties of occluding contours, showing how information about the symmetry axes of a 3D shape can be inferred from a small set of its planar projections. The proposed method is fast, insensitive to noise and resolution, capable of working with different shape representations, and easy to implement.
C1 [Livesu, Marco; Scateni, Riccardo] Univ Cagliari, Dipartimento Matemat & Informat, I-09124 Cagliari, Italy.
C3 University of Cagliari
RP Scateni, R (corresponding author), Univ Cagliari, Dipartimento Matemat & Informat, Via Osped 72, I-09124 Cagliari, Italy.
EM marco.livesu@unica.it; riccardo@unica.it
RI Scateni, Riccardo/H-7803-2015; Livesu, Marco/AAV-9100-2020
OI Scateni, Riccardo/0000-0002-0950-7372; Livesu, Marco/0000-0002-4688-7060
CR [Anonymous], 1975, Generating semantic descriptions from drawing of scenes with shadows
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Binford ThomasO., 1971, IEEE conference on Systems and Control, V261, P262
   BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302
   Bullitt E, 1997, MED PHYS, V24, P1671, DOI 10.1118/1.597952
   Cao J., 2010, SHAP MOD INT C SMI 2, P187, DOI [DOI 10.1109/SMI.2010.25, 10.1109/SMI.2010.25]
   Chuang M, 2011, COMPUT GRAPH FORUM, V30, P1750, DOI 10.1111/j.1467-8659.2011.01899.x
   Cornea ND, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P95
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Dey TK, 2006, S GEOMETRY PROCESSIN, P143
   Hassouna MS, 2005, PROC CVPR IEEE, P458
   Laurentini A, 1997, COMPUT VIS IMAGE UND, V67, P81, DOI 10.1006/cviu.1996.0508
   LAURENTINI A, 1995, IEEE T PATTERN ANAL, V17, P188, DOI 10.1109/34.368170
   Lee IK, 2000, COMPUT AIDED GEOM D, V17, P161, DOI 10.1016/S0167-8396(99)00044-8
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Liu L, 2010, COMPUT GRAPH FORUM, V29, P2253, DOI 10.1111/j.1467-8659.2010.01814.x
   Livesu M, 2012, IEEE T VIS COMPUT GR, V18, P1891, DOI 10.1109/TVCG.2012.71
   MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020
   MARR D, 1977, PROC R SOC SER B-BIO, V197, P441, DOI 10.1098/rspb.1977.0080
   Martin T, 2012, COMPUT GRAPH FORUM, V31, P805, DOI 10.1111/j.1467-8659.2012.03061.x
   Miklos B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778838
   PUJARI AK, 1993, SADHANA-ACAD P ENG S, V18, P325, DOI 10.1007/BF02742664
   Rao K, 1988, COMP SOC C P COMP VI, P276
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   SHANMUKH K, 1991, PATTERN RECOGN LETT, V12, P165, DOI 10.1016/0167-8655(91)90045-N
   Sharf A, 2007, COMPUT GRAPH FORUM, V26, P323, DOI 10.1111/j.1467-8659.2007.01054.x
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P926, DOI 10.1109/TVCG.2008.38
   Yoon SM, 2009, WSCG 2009, FULL PAPERS PROCEEDINGS, P177
NR 30
TC 17
Z9 20
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2013
VL 29
IS 9
BP 907
EP 916
DI 10.1007/s00371-013-0855-8
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 186CB
UT WOS:000322018100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jin, JH
   Shin, HJ
   Choi, JJ
AF Jin, Jung-Hwan
   Shin, Hyun Joon
   Choi, Jung-Ju
TI SPOID: a system to produce spot-the-difference puzzle images with
   difficulty
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Computer Graphics International (CGI) Conference
CY 2013
CL Hanover, GERMANY
DE Spot-the-difference; Difficulty; Saliency; Perceptual difference; Image
   editing
ID REAL-WORLD SCENES; VISUAL-ATTENTION; EYE-MOVEMENTS; GRAPH CUTS;
   SALIENCE; INSPECTION; AWARENESS; SEARCH; OVERT; NEED
AB Spot-the-difference is a type of puzzles, where users try to find the different parts of two perceptually similar but actually different images. We propose a semi-automatic system to produce various spot-the-difference puzzle images tagged with their difficulties from a single input image. First, we extract regions to modify from the input by our modified maximal similarity-based region merging algorithm with little user intervention and then apply a variety of image editing techniques for each region to create a modified image. We evaluate the difficulty of a pair of the input and the modified images by considering the saliency and the perceptual difference of the modified region. We provide an empirical model to estimate the time to solve a pair of the images with respect to its difficulty. We show our experimental results and quantitative user research results to evaluate the effectiveness of the proposed method.
C1 [Jin, Jung-Hwan] Ajou Univ, Dept Comp Sci & Engn, Suwon 443749, South Korea.
   [Shin, Hyun Joon; Choi, Jung-Ju] Ajou Univ, Dept Digital Media, Suwon 443749, South Korea.
C3 Ajou University; Ajou University
RP Choi, JJ (corresponding author), Ajou Univ, Dept Digital Media, San 5, Suwon 443749, South Korea.
EM jin1024@ajou.ac.kr; joony@ajou.ac.kr; jungju@ajou.ac.kr
OI Shin, Hyun Joon/0000-0002-7786-6908
FU National Research Foundation of Korea (NRF); Korean government (MEST)
   [2012R1A1A2007264]; Industry Strategic Technology Development Program
   [10041784]; Ministry of Knowledge Economy (MKE, Korea)
FX We are grateful to Neowiz Games for their valuable assistance to our
   experiments. This research is partially supported by the National
   Research Foundation of Korea (NRF) grant funded by the Korean government
   (MEST) (No. 2012R1A1A2007264) and partially supported by the Industry
   Strategic Technology Development Program (No. 10041784) funded by the
   Ministry of Knowledge Economy (MKE, Korea).
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BIEDERMA.I, 1972, SCIENCE, V177, P77, DOI 10.1126/science.177.4043.77
   BLOK HJ, 2000, THESIS U BRIT COLUMB
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daly Scott, 1993, P179
   de Brecht M, 2006, NEURAL NETWORKS, V19, P1467, DOI 10.1016/j.neunet.2005.12.004
   Foulsham T, 2007, PERCEPTION, V36, P1123, DOI 10.1068/p5659
   Henderson J., 2006, Eye Movement Research: Insights into Mind and Brain, chapter Visual Saliency does not account for Eye-Movements during Visual Search in Real-World Scenes
   Huang LQ, 2007, PSYCHOL REV, V114, P599, DOI 10.1037/0033-295X.114.3.599
   Huang L, 2007, SCIENCE, V317, P823, DOI 10.1126/science.1143515
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Kelley TA, 2003, J VISION, V3, P1, DOI 10.1167/3.1.1
   Liu JY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531375
   Liu S., 2011, P INT C EL INF CONTR, P993, DOI [10.1145/2072298.2071921, DOI 10.1145/2072298.2071921]
   Lu F, 2007, LECT NOTES COMPUT SC, V4844, P134
   Lubin J., 1995, MEMORY A MENENDEZ, P245
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Ramasubramanian M, 1999, COMP GRAPH, P73, DOI 10.1145/311535.311543
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Smith CN, 2006, J NEUROSCI, V26, P11304, DOI 10.1523/JNEUROSCI.3071-06.2006
   Stirk JA, 2007, J VISION, V7, DOI 10.1167/7.10.3
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Treue S, 2003, CURR OPIN NEUROBIOL, V13, P428, DOI 10.1016/S0959-4388(03)00105-3
   Triesch J, 2003, J VISION, V3, P86, DOI 10.1167/3.1.9
   Underwood G, 2006, EUR J COGN PSYCHOL, V18, P321, DOI 10.1080/09541440500236661
   Verma M, 2010, J VISION, V10, DOI 10.1167/10.6.3
   Verma M, 2009, VISION RES, V49, P374, DOI 10.1016/j.visres.2008.11.006
   Yee Y. H., 2004, ACM SIGGRAPH 2004 SK, P121, DOI [10.1145/1186223.1186374, DOI 10.1145/1186223.1186374]
   Yoon JC, 2008, COMPUT GRAPH FORUM, V27, P1869, DOI 10.1111/j.1467-8659.2008.01334.x
NR 32
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2013
VL 29
IS 6-8
BP 481
EP 489
DI 10.1007/s00371-013-0812-6
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 151RR
UT WOS:000319478400003
DA 2024-07-18
ER

PT J
AU Sun, G
   Wang, SH
   Liu, XH
   Huang, QM
   Chen, YY
   Wu, EH
AF Sun, Gang
   Wang, Shuhui
   Liu, Xuehui
   Huang, Qingming
   Chen, Yanyun
   Wu, Enhua
TI Accurate and efficient cross-domain visual matching leveraging multiple
   feature representations
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Computer Graphics International (CGI) Conference
CY 2013
CL Hanover, GERMANY
DE Visual matching; Cross-domain; Multiple features; Hyperplane hashing
ID IMAGE; SCALE; SHAPE
AB Cross-domain visual matching aims at finding visually similar images across a wide range of visual domains, and has shown a practical impact on a number of applications. Unfortunately, the state-of-the-art approach, which estimates the relative importance of the single feature dimensions still suffers from low matching accuracy and high time cost. To this end, this paper proposes a novel cross-domain visual matching framework leveraging multiple feature representations. To integrate the discriminative power of multiple features, we develop a data-driven, query specific feature fusion model, which estimates the relative importance of the individual feature dimensions as well as the weight vector among multiple features simultaneously. Moreover, to alleviate the computational burden of an exhaustive subimage search, we design a speedup scheme, which employs hyperplane hashing for rapidly collecting the hard-negatives. Extensive experiments carried out on various matching tasks demonstrate that the proposed approach outperforms the state-of-the-art in both accuracy and efficiency.
C1 [Sun, Gang; Liu, Xuehui; Chen, Yanyun; Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Sun, Gang; Huang, Qingming] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Shuhui; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Macau, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Chinese
   Academy of Sciences; Institute of Computing Technology, CAS; University
   of Macau
RP Sun, G (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
EM sung@ios.ac.cn
RI Lin, Fan/JZT-1441-2024; Huang, Qingming/GLR-3473-2022
OI Lin, Fan/0000-0002-7330-3833; Huang, Qingming/0000-0002-3025-7099
FU National Fundamental Research Grant 973 Program [2009CB320802]; NSFC
   [61272326, 61025011]; University of Macau
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions to improve the quality of the paper.
   This research is supported by National Fundamental Research Grant 973
   Program (2009CB320802), NSFC grant (61272326, 61025011), and Research
   Grant of University of Macau. Image credits: Andy Carvin, Bob Pejman,
   Leonid Afremov, Mariko Jesse, Risto-Jussi Isopahkala, Steven Allen,
   www.turbosquid.com.
CR [Anonymous], 3 INT IEEE WORKSH 3D
   [Anonymous], 2011, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2010.266
   [Anonymous], P INT C MACH LEARN
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], 2010, ADV NEURAL INFORM PR
   [Anonymous], 2010, ADV NEURAL INFORM PR
   [Anonymous], 2009, ACM T GRAPHIC, DOI DOI 10.1145/1618452.1618470
   [Anonymous], 2004, P 21 INT C MACH LEAR
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Chong HY, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360660
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Ha JY, 2008, NCM 2008 : 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 1, PROCEEDINGS, P652, DOI 10.1109/NCM.2008.220
   Hauagge DC, 2012, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2012.6247677
   Hays J, 2008, PROC CVPR IEEE, P3436
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Johnson MK, 2011, IEEE T VIS COMPUT GR, V17, P1273, DOI 10.1109/TVCG.2010.233
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Shrivastava A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024188
   Vadivel A, 2009, ONLINE INFORM REV, V33, P1169, DOI 10.1108/14684520911011061
   Wang SH, 2012, IEEE T MULTIMEDIA, V14, P1259, DOI 10.1109/TMM.2012.2193120
NR 30
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2013
VL 29
IS 6-8
BP 565
EP 575
DI 10.1007/s00371-013-0818-0
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 151RR
UT WOS:000319478400011
DA 2024-07-18
ER

PT J
AU Wang, P
   Cheng, ZQ
   Martin, R
   Liu, HH
   Cai, X
   Li, SK
AF Wang, Pan
   Cheng, Zhiquan
   Martin, Ralph
   Liu, Huahai
   Cai, Xun
   Li, Sikun
TI NUMA-aware image compositing on multi-GPU platform
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Computer Graphics International (CGI) Conference
CY 2013
CL Hanover, GERMANY
DE Multi-GPU System; Parallel rendering; Image compositing
ID COMMUNICATION
AB Sort-last parallel rendering is widely used. Recent GPU developments mean that a PC equipped with multiple GPUs is a viable alternative to a high-cost supercomputer: the Fermi architecture of a single GPU supports uniform virtual addressing, providing a foundation for non-uniform memory access (NUMA) on multi-GPU platforms. Such hardware changes require the user to reconsider the parallel rendering algorithms. In this paper, we thoroughly investigate the NUMA-aware image compositing problem, which is the key final stage in sort-last parallel rendering. Based on a proven radix-k strategy, we find one optimal compositing algorithm, which takes advantage of NUMA architecture on the multi-GPU platform. We quantitatively analyze different image compositing modes for practical image compositing, taking into account peer-to-peer communication costs between GPUs. Our experiments on various datasets show that our image compositing method is very fast, an image of a few megapixels can be composited in about 10 ms by eight GPUs.
C1 [Wang, Pan; Cheng, Zhiquan; Liu, Huahai; Cai, Xun; Li, Sikun] Natl Univ Def Technol, Sch Comp Sci, Changsha, Hunan, Peoples R China.
   [Martin, Ralph] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AX, S Glam, Wales.
C3 National University of Defense Technology - China; Cardiff University
RP Cheng, ZQ (corresponding author), Natl Univ Def Technol, Sch Comp Sci, Changsha, Hunan, Peoples R China.
EM weaponfire2005@gmail.com; cheng.zhiquan@gmail.com; ralph@cs.cf.ac.uk;
   colinliu.nudt@gmail.com; cx72838@163.com; lisikun@263.net.cn
RI Martin, Ralph R/D-2366-2010
OI Martin, Ralph/0000-0002-8495-8536
FU National Basic Research Program [2009CB723803]; National Science
   Foundation Program of China [61103084, 61272334, 61170157, 61272009];
   National University of Defense Technology
FX This work is supported by the National Basic Research Program (No.
   2009CB723803), National Science Foundation Program (Nos. 61103084,
   61272334, 61170157 and No. 61272009) of China and Research Funding
   Program of National University of Defense Technology.
CR Cavin X, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P111
   Cavin X., 2012, EGPGV 12, P129
   Chan E, 2007, CONCURR COMP-PRACT E, V19, P1749, DOI 10.1002/cpe.1206
   Eilemann S., 2008, ACM SIGGRAPH ASIA, P39
   Eilemann S., 2012, EUR S PAR GRAPH VIS, P109, DOI [10.2312/EGPGV/EGPGV12/109-117, DOI 10.2312/EGPGV/EGPGV12/109-117]
   Kendall W., 2010, Proceedings of the 10th Eurographics Conference on Parallel Graphics and Visualization, EG PGV'10, P101, DOI DOI 10.2312/EGPGV/EGPGV10/101-110
   MA KL, 1994, IEEE COMPUT GRAPH, V14, P59, DOI 10.1109/38.291532
   MARCHESIN S, 2008, P 8 EUR C PAR GRAPH, P1
   Moerschell A., 2006, ACM SIGGRAPHEUROGRAP, P31
   MOLNAR S, 1994, IEEE COMPUT GRAPH, V14, P23, DOI 10.1109/38.291528
   Moreland K., 2011, Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis, SC'11, (New York, NY, USA), p25:1
   NEUMANN U, 1994, IEEE COMPUT GRAPH, V14, P49, DOI 10.1109/38.291531
   NVIDIA, 2012, CUD TOOLK 4 0
   Peterka T, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Porter T., 1984, Computers & Graphics, V18, P253
   Schroeder Tim C, 2011, Peer-to-Peer & Unified Virtual Addressing
   Spafford K., 2011, P 4 WORKSH GEN PURP, P11
   Stompel Aleksander., 2003, P 2003 IEEE S PARALL, P6
   Yu H., 2008, ACM SIGGRAPH ASIA, P40
NR 19
TC 3
Z9 4
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2013
VL 29
IS 6-8
BP 639
EP 649
DI 10.1007/s00371-013-0803-7
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 151RR
UT WOS:000319478400018
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Xia, PJ
   Lopes, AM
   Restivo, MT
AF Xia, Pingjun
   Lopes, Antonio Mendes
   Restivo, Maria Teresa
TI Virtual reality and haptics for dental surgery: a personal review
SO VISUAL COMPUTER
LA English
DT Article
DE Virtual reality; Haptics; Dental surgery; Review
ID SIMULATION; DESIGN; SYSTEM
AB Virtual reality and haptics are novel human-machine interaction technologies which have shown a good application potential in many fields such as medical, entertainment, manufacturing, and education areas in the last 20 years. Especially for dental surgery simulation and training, they provide a new and low-cost approach whereby dentists can practice procedures as many times as they want at no incremental cost and training can take place anywhere. This paper provides a comprehensive survey of virtual reality and haptics for dental surgery simulation and training. Some new ideas and recent research progress are investigated, the major research efforts and their typical systems are introduced, and the involved major research issues are summarized, and finally future trends and conclusions are discussed.
C1 [Xia, Pingjun; Lopes, Antonio Mendes; Restivo, Maria Teresa] Univ Porto, Fac Engn, IDMEC Polo FEUP, P-4100 Oporto, Portugal.
C3 Universidade de Lisboa; Universidade do Porto
RP Xia, PJ (corresponding author), Univ Porto, Fac Engn, IDMEC Polo FEUP, Rua Campo Alegre 823, P-4100 Oporto, Portugal.
EM smallping@fe.up.pt
RI Restivo, Maria Teresa/AAD-5694-2020; Lopes, António M./A-2740-2016;
   Restivo, Maria Teresa/I-6477-2015
OI Lopes, António M./0000-0001-7359-4370; Restivo, Maria
   Teresa/0000-0003-1118-9331
CR Agus M, 2003, PRESENCE-TELEOP VIRT, V12, P110, DOI 10.1162/105474603763835378
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   Arbabtafti M, 2011, IEEE T HAPTICS, V4, P39, DOI [10.1109/TOH.2010.5, 10.1109/ToH.2010.5]
   Ben Gal G, 2011, J DENT EDUC, V75, P496
   Bogdan CM, 2011, INT J COMPUT COMMUN, V6, P45
   Guanyang Liu, 2008, Virtual Reality, V12, P99, DOI 10.1007/s10055-008-0094-x
   Kim K., 2009, VRST 2009 KYOT JAP 1
   Kim L, 2006, VISUAL COMPUT, V22, P90, DOI 10.1007/s00371-006-0369-8
   Kim L., 2008, INT J CAD CAM, V8, P41
   Laehyun Kim, 2005, Computer-Aided Design and Applications, V2, P591
   Luciano C, 2009, VIRTUAL REAL-LONDON, V13, P69, DOI 10.1007/s10055-009-0112-7
   Mauch S, 2000, TECHNICAL REPORT
   Noborio H, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P19, DOI 10.1109/HAVE.2008.4685292
   Petersik A, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P66, DOI 10.1109/HAPTIC.2002.998942
   Ranta J. F., 1999, 4 PHANT US GROUPS WO, P73
   Rhienmora P., 2010, AUGMENTED REALITY HA, P97
   Rhienmora P, 2011, ARTIF INTELL MED, V52, P115, DOI 10.1016/j.artmed.2011.04.003
   Sae-Kee B, 2004, STUD HEALTH TECHNOL, V98, P327
   Steinberg AD, 2007, J DENT EDUC, V71, P1574
   Tanaka A, 1998, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VRAIS.1998.658425
   Thomas G, 2001, COMPUT METH PROG BIO, V64, P53, DOI 10.1016/S0169-2607(00)00089-4
   Tse B, 2010, LECT NOTES COMPUT SC, V6192, P101, DOI 10.1007/978-3-642-14075-4_15
   Velho L, 1999, ACM T GRAPHIC, V18, P329, DOI 10.1145/337680.337717
   Wang D, 2005, IEEE T VIS COMPUT GR, V11, P671, DOI 10.1109/TVCG.2005.97
   Wang D., 2011, IEEE T HAPTICS, DOI [10.1109/TOH.2011.59, DOI 10.1109/T0H.2011.59.IEEE]
   Wu JD, 2009, TRANSL ONCOL, V2, P39, DOI 10.1593/tlo.08217
   Wu J, 2010, J COMPUT INF SCI ENG, V10, DOI 10.1115/1.3402759
   Yau H. T., 2006, Computer-Aided Design and Applications, V3, P415
   Zhou Wan-Lin, 2009, Chinese Journal of Computers, V92, P1560, DOI 10.3724/SP.J.1016.2009.01560
NR 29
TC 32
Z9 35
U1 0
U2 26
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2013
VL 29
IS 5
BP 433
EP 447
DI 10.1007/s00371-012-0748-2
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 127RD
UT WOS:000317715200010
DA 2024-07-18
ER

PT J
AU Brecheisen, R
   Platel, B
   Romeny, BMT
   Vilanova, A
AF Brecheisen, R.
   Platel, B.
   Romeny, B. M. ter Haar
   Vilanova, A.
TI Illustrative uncertainty visualization of DTI fiber pathways
SO VISUAL COMPUTER
LA English
DT Article
DE Diffusion tensor imaging; Fiber tracking; Uncertainty visualization;
   Illustrative rendering; Neurosurgery planning
ID WILD BOOTSTRAP; DIFFUSION; BRAIN; EXPLORATION; TRACKING
AB Diffusion Tensor Imaging (DTI) and fiber tracking provide unique insight into the 3D structure of fibrous tissues in the brain. However, the output of fiber tracking contains a significant amount of uncertainty accumulated in the various steps of the processing pipeline. Existing DTI visualization methods do not present these uncertainties to the end-user. This creates a false impression of precision and accuracy that can have serious consequences in applications that rely heavily on risk assessment and decision-making, such as neurosurgery. On the other hand, adding uncertainty to an already complex visualization can easily lead to information overload and visual clutter. In this work, we propose Illustrative Confidence Intervals to reduce the complexity of the visualization and present only those aspects of uncertainty that are of interest to the user. We look specifically at the uncertainty in fiber shape due to noise and modeling errors. To demonstrate the flexibility of our framework, we compute this uncertainty in two different ways, based on (1) fiber distance and (2) the probability of a fiber connection between two brain regions. We provide the user with interactive tools to define multiple confidence intervals, specify visual styles and explore the uncertainty with a Focus+Context approach. Finally, we have conducted a user evaluation with three neurosurgeons to evaluate the added value of our visualization.
C1 [Brecheisen, R.; Romeny, B. M. ter Haar; Vilanova, A.] Eindhoven Univ Technol, Eindhoven, Netherlands.
   [Platel, B.] Fraunhofer MEVIS, Bremen, Germany.
C3 Eindhoven University of Technology
RP Brecheisen, R (corresponding author), Eindhoven Univ Technol, Dolech 2, Eindhoven, Netherlands.
EM r.brecheisen@tue.nl
RI Vilanova, Anna/G-1752-2010; Platel, Bram/D-2132-2009; ter Haar Romenij,
   Bart M./A-5323-2013
OI Vilanova, Anna/0000-0001-7273-4597; ter Haar Romenij, Bart
   M./0000-0003-3442-3207
CR Basser PJ, 2000, MAGNET RESON MED, V44, P625, DOI 10.1002/1522-2594(200010)44:4<625::AID-MRM17>3.0.CO;2-O
   Behrens TEJ, 2003, MAGN RESON MED, V50, P1077, DOI 10.1002/mrm.10609
   Bermnan JI, 2008, NEUROIMAGE, V39, P215, DOI 10.1016/j.neuroimage.2007.08.021
   Born S., 2009, BILDVERARBEITUNG MED, P6, DOI [DOI 10.1007/978-3-540-93860-6_2, 10.1007/978-3-540-93860-6_2]
   Brecheisen R, 2009, IEEE T VIS COMPUT GR, V15, P1441, DOI 10.1109/TVCG.2009.170
   Chen W, 2008, COMPUT GRAPH FORUM, V27, P1071, DOI 10.1111/j.1467-8659.2008.01244.x
   Delmarcelle T., 2003, IEEE COMPUT GRAPH, V13, P25
   Enders F, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P51
   Everts MH, 2009, IEEE T VIS COMPUT GR, V15, P1299, DOI 10.1109/TVCG.2009.138
   Friman O, 2006, IEEE T MED IMAGING, V25, P965, DOI 10.1109/TMI.2006.877093
   i Bartroli A.Vilanova., 2004, VISSYM 04 S VISUALIZ, P173
   Jainek WM, 2008, COMPUT GRAPH FORUM, V27, P855, DOI 10.1111/j.1467-8659.2008.01217.x
   Jeurissen B, 2011, HUM BRAIN MAPP, V32, P461, DOI 10.1002/hbm.21032
   Jiao FX, 2010, LECT NOTES COMPUT SC, V6326, P179
   Jones DK, 2008, IEEE T MED IMAGING, V27, P1268, DOI 10.1109/TMI.2008.922191
   Klein J., 2006, P INT SOC MAGN RES M
   Lazar M, 2003, HUM BRAIN MAPP, V18, P306, DOI 10.1002/hbm.10102
   LIU RY, 1988, ANN STAT, V16, P1696, DOI 10.1214/aos/1176351062
   Lodha SK, 1996, IEEE VISUAL, P249, DOI 10.1109/VISUAL.1996.568116
   Merhof D, 2009, STEREOT FUNCT NEUROS, V87, P50, DOI 10.1159/000195720
   Moberts B, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P65
   Mori S, 1999, ANN NEUROL, V45, P265, DOI 10.1002/1531-8249(199902)45:2<265::AID-ANA21>3.0.CO;2-3
   O'Donnell LJ, 2009, NEUROIMAGE, V45, P832, DOI 10.1016/j.neuroimage.2008.12.023
   Otten R, 2010, COMPUT GRAPH FORUM, V29, P1013, DOI 10.1111/j.1467-8659.2009.01688.x
   Pajevic S, 2003, J MAGN RESON, V161, P1, DOI 10.1016/S1090-7807(02)00178-7
   Pang A., 2001, Proceedings of the Workshop on the Intersections between Geospatial Information and Information Technology, P1
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Pierpaoli C, 1996, MAGNET RESON MED, V36, P893, DOI 10.1002/mrm.1910360612
   Schultz T, 2008, COMPUT GRAPH FORUM, V27, P1063, DOI 10.1111/j.1467-8659.2008.01243.x
   Schultz T., 2011, Scientific Visualization: Interactions, Features, Metaphors, V2, P322
   Schultz T, 2007, IEEE T VIS COMPUT GR, V13, P1496, DOI 10.1109/TVCG.2007.70602
   Sherbondy AJ, 2008, J VISION, V8, DOI 10.1167/8.9.15
   Svetachov P, 2010, COMPUT GRAPH FORUM, V29, P1023, DOI 10.1111/j.1467-8659.2009.01692.x
   Vilanova A., 2004, INTRO VISUALIZATION, P121
   Weiler F., 2008, P 22 INT C EXH COMP
   Whitcher B, 2008, HUM BRAIN MAPP, V29, P346, DOI 10.1002/hbm.20395
   Wittenbrink CM, 1996, IEEE T VIS COMPUT GR, V2, P266, DOI 10.1109/2945.537309
NR 37
TC 17
Z9 19
U1 0
U2 16
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2013
VL 29
IS 4
SI SI
BP 297
EP 309
DI 10.1007/s00371-012-0733-9
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 115AM
UT WOS:000316784200007
OA hybrid
DA 2024-07-18
ER

PT J
AU Wu, EH
   Liu, FT
AF Wu, Enhua
   Liu, Feitong
TI Robust image metamorphosis immune from ghost and blur
SO VISUAL COMPUTER
LA English
DT Article
DE Image morphing; Warping; Animation; Graph cut
ID INTERPOLATION
AB In this paper, we propose a novel method for the metamorphosis between two different images. By the approach, the transition sequence is generated by stitching two forward and backward warped sequences in a three-dimensional space along transition surface. In contrast to the traditional methods by blending two warped images at each intermediate frame, we continuously warp images on opposite direction without blending until the two warped images match in a three-dimensional space leading to a better transition in quality. Furthermore, for each pixel, we make decision of choosing a given input image best suitable so as to produce plausible in-between images to prevent from ghost and blur. By our scheme, the transition surface is computed by minimizing an energy function in terms of graph-cut optimization. Depending on the transition surface, a warp function is proposed to create a smooth and clear transformation. We demonstrate the advantage of our framework by performing transformation test to various kinds of image couples.
C1 [Wu, Enhua; Liu, Feitong] Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Taipa, Peoples R China.
   [Wu, Enhua; Liu, Feitong] Chinese Acad Sci, State Key Lab Comp Sci, Inst Software, Beijing, Peoples R China.
C3 University of Macau; Chinese Academy of Sciences; Institute of Software,
   CAS
RP Liu, FT (corresponding author), Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Taipa, Peoples R China.
EM feiecm@qq.com
RI wang, xueting/JPY-2782-2023
FU National Fundamental S&T Research Grant 973 Program [2009CB320802,
   2011CB302801]; NSFC [60833007]; University of Macau
FX Support to the research has been from the National Fundamental S&T
   Research Grant 973 Program (2009CB320802, 2011CB302801), the NSFC grant
   (60833007), and the Research Grant of University of Macau.
CR [Anonymous], VISION MODELING VISU
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Bhat P., 2007, P ESRT GREN FRANC, P327
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Hu S. M., 1994, P ACM SMA 04, P309
   Karam H, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P555, DOI 10.1109/VSMM.2001.969712
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lee SY, 1996, J VISUAL COMP ANIMAT, V7, P3, DOI 10.1002/(SICI)1099-1778(199601)7:1<3::AID-VIS131>3.0.CO;2-U
   Lerios A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P449, DOI 10.1145/218380.218502
   Lipski C., 2010, SIGGRAPH 10 ACM SIGG, P67
   Litwinowicz P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P409, DOI 10.1145/192161.192270
   Mahajan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531348
   Nishita T., 1993, Proceedings of the First Pacific Conference on Computer Graphics and Applications, P162
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Seung-Yong Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P439
   Stich T., 2007, TECHNICAL REPORT
   Stich T, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870079
   Stich T, 2008, COMPUT GRAPH FORUM, V27, P1781, DOI 10.1111/j.1467-8659.2008.01323.x
   Szewczyk R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P273, DOI 10.1145/266180.266378
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Wolberg G., 1990, Digital image warping
   Zhang ZP, 2002, ACM T GRAPHIC, V21, P457, DOI 10.1145/566570.566602
NR 23
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2013
VL 29
IS 4
SI SI
BP 311
EP 321
DI 10.1007/s00371-012-0734-8
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 115AM
UT WOS:000316784200008
DA 2024-07-18
ER

PT J
AU Pantuwong, N
   Sugimoto, M
AF Pantuwong, Natapon
   Sugimoto, Masanori
TI Skeleton growing: an algorithm to extract a curve skeleton from a
   pseudonormal vector field
SO VISUAL COMPUTER
LA English
DT Article
DE Skeleton growing; Curve skeleton; Vector field; Curvature; Topology
AB A curve skeleton is used to represent a 3D object in many different applications. It is a 1D curve that captures topology of the 3D object. The proposed method extracts a curve skeleton from the vector field inside the 3D object. A vector at each voxel of the 3D object is calculated using a pseudonormal vector. By using such a calculation, the computation time is significantly reduced compared with using a typical potential field. A curve skeleton is then extracted from the pseudonormal vector field by using a skeleton-growing algorithm. The proposed algorithm uses high-curvature boundary voxels to search for a set of critical points and skeleton branches near high-curvature areas. The set of detected critical points is then used to grow a curve skeleton in the next step. All parameters of our algorithms are calculated from the 3D object itself, without user intervention. The effectiveness of our method is demonstrated in our experiments.
C1 [Pantuwong, Natapon] Univ Tokyo, Dept Elect Engn & Informat Syst, Tokyo, Japan.
   [Sugimoto, Masanori] Univ Tokyo, Dept Elect Engn & Informat Syst, Grad Sch Engn, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo
RP Pantuwong, N (corresponding author), Univ Tokyo, Dept Elect Engn & Informat Syst, Tokyo, Japan.
EM na@itl.t.u-tokyo.ac.jp; sugi@itl.t.u-tokyo.ac.jp
FU Microsoft Research Collaborative Research Projects (MSR CORE7)
FX The authors thank Dr. Yasuyuki Matsushita (Microsoft Research Asia) for
   his constructive duscussions and valuable suggestions. The research is
   sponsored by Microsoft Research Collaborative Research Projects (MSR
   CORE7).
CR Au O.K.C., PROJECT SKELETON EXT
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Aujay G, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P151
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Bouix S, 2000, LECT NOTES COMPUT SC, V1842, P603
   Cheng ZQ, 2007, LECT NOTES COMPUT SC, V4842, P671
   Chuang JH, 2000, IEEE T PATTERN ANAL, V22, P1241
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Demarsin K, 2008, COMPUTER AIDED DESIG, V5, P589
   Dey T.K., CURVE SKELETONS 3D S
   Dey TK, 2006, S GEOMETRY PROCESSIN, P143
   Globus A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P33, DOI 10.1109/VISUAL.1991.175773
   Globus A., 1991, VIS 91, P408
   Goh WB, 2008, COMPUT VIS IMAGE UND, V110, P326, DOI 10.1016/j.cviu.2007.09.013
   Hadwiger M., 2006, REAL TIME VOLUME GRA
   Hassouna MS, 2005, PROC CVPR IEEE, P458
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Liao D., 2010, SCCG 08, P113
   Lien J, 2006, P 2006 ACM S SOL PHY, P219
   Liu PC, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P409
   Ma CM, 2002, IEEE T PATTERN ANAL, V24, P1594, DOI 10.1109/TPAMI.2002.1114851
   MONGA O, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P852, DOI 10.1109/CVPR.1994.323912
   Ogniewicz R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P63, DOI 10.1109/CVPR.1992.223226
   Pantuwong N, 2010, VMV 10, P235
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239509
   Poirier M, 2009, Graphics interface, P103
   Schwarz M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866201
   She FH, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P14, DOI 10.1109/DICTA.2009.13
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Theisel Holger., 2003, P 14 IEEE VISUALIZAT, P30
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P926, DOI 10.1109/TVCG.2008.38
NR 33
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2013
VL 29
IS 3
BP 203
EP 216
DI 10.1007/s00371-012-0721-0
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 115AI
UT WOS:000316783800004
DA 2024-07-18
ER

PT J
AU Hua, W
   Wang, R
   Zeng, XS
   Tang, Y
   Wang, HM
   Bao, HJ
AF Hua, Wei
   Wang, Rui
   Zeng, Xusheng
   Tang, Ying
   Wang, Huamin
   Bao, Hujun
TI Compressing repeated content within large-scale remote sensing images
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Conference on the Computer Graphics International (CGI)
CY 2012
CL Bournemouth, ENGLAND
DE Texture compression; Image epitomes; Large-scale remote sensing image
ID TEXTURE SYNTHESIS
AB Large-scale remote sensing images, including both satellite and aerial photographs, are widely used to render terrain scenes in real-time geographic visualization systems. Such systems often require large memories in order to store fine terrain details and fast network speeds to transfer image data, if they are built as web applications. In this paper, we propose a progressive texture compression framework to reduce the memory and bandwidth cost by compressing repeated content within and among large-scale remote sensing images. Different from existing image factorization methods, our algorithm incrementally find similar regions in new images so that large-scale images can be more efficiently compressed over time. We further propose a descriptor, the Gray Split Rotate (GSR) descriptor, to accelerate the similarity search. The reconstruction quality is finally improved by compressing residual error maps using customized S3TC-like compression. Our experiment shows that even with the error maps, our system still has higher compression rate and higher compression quality than using S3TC alone, which is a typical compression solution in most existing visualization systems.
C1 [Hua, Wei; Wang, Rui; Zeng, Xusheng; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Tang, Ying] Zhejiang Univ, Dept Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
   [Wang, Huamin] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 Zhejiang University; Zhejiang University; University System of Ohio;
   Ohio State University
RP Wang, R (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310003, Zhejiang, Peoples R China.
EM rwang@cad.zju.edu.cn
RI Wang, Huamin/H-9630-2013; Wang, Huamin/D-2600-2012
OI Wang, Huamin/0000-0002-8153-2337
CR [Anonymous], 2003, HWWS'03: Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware
   [Anonymous], ACM T GRAPHICS
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beers A. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P373, DOI 10.1145/237170.237276
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   Inada Tetsugo., 2006, Proc. ACM SIGGRAPH/EUROGRAPHICS Symp. Graphics Hardware, P111
   Iourcha K., 1999, U.S. Patent, Patent No. 5956431
   Ivanov D, 2000, COMPUT GRAPH FORUM, V19, pC283, DOI 10.1111/1467-8659.00420
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Lai JZC, 2009, PATTERN RECOGN, V42, P2551, DOI 10.1016/j.patcog.2009.02.014
   Lefebvre S, 2005, ACM T GRAPHIC, V24, P777, DOI 10.1145/1073204.1073261
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921
   Levkovich-Maslyuk L., 2000, Proceedings ACM Multimedia 2000, P401, DOI 10.1145/354384.354545
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mount D.M., 2010, LIB APPR NEAR NEIGHB
   Pereberin A. V., 1999, P GRAPHICON 99, P195
   Skodras AN, 2001, PATTERN RECOGN LETT, V22, P1337, DOI 10.1016/S0167-8655(01)00079-4
   Wang HM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360613
   Wei L.-Y, 2004, ACM SIGGRAPH 2004 SK, DOI 10.1145/1186223.1186307
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
NR 22
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2012
VL 28
IS 6-8
BP 755
EP 764
DI 10.1007/s00371-012-0710-3
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 947EW
UT WOS:000304411500023
DA 2024-07-18
ER

PT J
AU Hahmann, S
   Bonneau, GP
   Barbier, S
   Elber, G
   Hagen, H
AF Hahmann, Stefanie
   Bonneau, Georges-Pierre
   Barbier, Sebastien
   Elber, Gershon
   Hagen, Hans
TI Volume-preserving FFD for programmable graphics hardware
SO VISUAL COMPUTER
LA English
DT Article
DE Free form deformations (FFD); Volume preservation; Graphics hardware;
   Direct manipulation
ID MAPS
AB Free-Form Deformation (FFD) is a well established technique for deforming arbitrary object shapes in space. Although more recent deformation techniques have been introduced, among them skeleton-based deformation and cage-based deformation, the simple and versatile nature of FFD is a strong advantage, and justifies its presence in nowadays leading commercial geometric modeling and animation software systems. Since its introduction in the late 1980s, many improvements have been proposed to the FFD paradigm, including control lattices of arbitrary topology, direct shape manipulation and GPU implementation. Several authors have addressed the problem of volume-preserving FFD. These previous approaches either make use of expensive nonlinear optimization techniques, or resort to first order approximation suitable only for small-scale deformations. In this paper we take advantage of the multi-linear nature of the volume constraint in order to derive a simple, exact and explicit solution to the problem of volume-preserving FFD. Two variants of the algorithm are given, without and with direct shape manipulation. Moreover, the linearity of our solution enables to implement it efficiently on GPU.
C1 [Hahmann, Stefanie; Bonneau, Georges-Pierre; Barbier, Sebastien] Univ Grenoble, INRIA Rhone Alpes, Lab Jean Kuntzmann, Grenoble, France.
   [Hahmann, Stefanie] INRIA Lab LJK, F-38334 Saint Ismier, France.
   [Elber, Gershon] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
   [Hagen, Hans] TU Kaiserslautern, FB Informat, D-67653 Kaiserslautern, Germany.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS); Inria; Technion Israel Institute of
   Technology; University of Kaiserslautern
RP Hahmann, S (corresponding author), Univ Grenoble, INRIA Rhone Alpes, Lab Jean Kuntzmann, Grenoble, France.
EM Stefanie.Hahmann@inria.fr; Georges-Pierre.Bonneau@inria.fr;
   gershon@cs.technion.ac.il; Hagen@informatik.uni-kl.de
OI Hahmann, Stefanie/0000-0001-8623-7225
FU DFG [IRTG 1131, INST 248/72-1]
FX This work was partially supported by the DFG (IRTG 1131, INST 248/72-1).
CR [Anonymous], 2008, NVR2008003 NVIDIA
   Aubert F, 1997, COMPUT GRAPH, V21, P625, DOI 10.1016/S0097-8493(97)00040-X
   Bell N., 2008, Efficient sparse matrix-vector multiplication on CUDA
   Ben-Chen M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531340
   Cohen E., 2001, Geometric modeling with splines: an introduction, V1st
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Faloutsos P, 1997, IEEE T VIS COMPUT GR, V3, P201, DOI 10.1109/2945.620488
   Farin G., 2002, CURVES SURFACES COMP
   Goodnight N., 2003, P ACM SIGGRAPHEUROGR, P102
   Hirota G., 1999, PROC ACM S SOLID MOD, P234
   HSU WM, 1992, COMP GRAPH, V26, P177, DOI 10.1145/142920.134036
   Hu SM, 2001, VISUAL COMPUT, V17, P370, DOI 10.1007/s003710100114
   Kavan L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P39
   Krüger J, 2003, ACM T GRAPHIC, V22, P908, DOI 10.1145/882262.882363
   Lasseter J., 1987, Proc. SIGGRAPH 87, V21, P35, DOI DOI 10.1145/37402.37407
   Lien S.-L., 1984, IEEE COMPUT GRAPH AP, V4
   MacCracken R., 1996, SIGGRAPH 96, P234
   Marinov M., 2007, Journal of Graphics Tools, V12, P27
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Rappoport A, 1996, IEEE T VIS COMPUT GR, V2, P19, DOI 10.1109/2945.489383
   Rhee T, 2006, COMPUT GRAPH FORUM, V25, P439, DOI 10.1111/j.1467-8659.2006.00963.x
   Schein S, 2005, VISUAL COMPUT, V21, P791, DOI 10.1007/s00371-005-0338-7
   Schein S, 2006, INT J SHAPE MODEL, V12, P179
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
NR 24
TC 11
Z9 11
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2012
VL 28
IS 3
BP 231
EP 245
DI 10.1007/s00371-011-0608-5
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 896QS
UT WOS:000300585400001
DA 2024-07-18
ER

PT J
AU Lee, H
   Lavoué, G
   Dupont, F
AF Lee, Ho
   Lavoue, Guillaume
   Dupont, Florent
TI Rate-distortion optimization for progressive compression of 3D mesh with
   color attributes
SO VISUAL COMPUTER
LA English
DT Article
DE 3D mesh; Progressive compression; Rate distortion optimization; Adaptive
   quantization; Color attributes
ID LOSSLESS COMPRESSION; BIT ALLOCATION; GEOMETRY; ERROR
AB We propose a new lossless progressive compression algorithm based on rate-distortion optimization for meshes with color attributes; the quantization precision of both the geometry and the color information is adapted to each intermediate mesh during the encoding/decoding process. This quantization precision can either be optimally determined with the use of a mesh distortion measure or quasi-optimally decided based on an analysis of the mesh complexity in order to reduce the calculation time. Furthermore, we propose a new metric which estimates the geometry and color importance of each vertex during the simplification in order to faithfully preserve the feature elements. Experimental results show that our method outperforms the state-of-the-art algorithm for colored meshes and competes with the most efficient algorithms for non-colored meshes.
C1 [Lee, Ho; Dupont, Florent] Univ Lyon 1, CNRS, LIRIS, UMR5205, F-69622 Lyon, France.
   [Lavoue, Guillaume] Univ Lyon, CNRS, LIRIS, INSA Lyon,UMR5205, F-69621 Lyon, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon; Centre
   National de la Recherche Scientifique (CNRS); Universite Claude Bernard
   Lyon 1; Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Centre National de la Recherche Scientifique (CNRS)
RP Lee, H (corresponding author), Univ Lyon 1, CNRS, LIRIS, UMR5205, F-69622 Lyon, France.
EM ho.lee@liris.cnrs.fr; guillaume.lavoue@liris.cnrs.fr;
   florent.dupont@liris.cnrs.fr
OI Dupont, Florent/0000-0001-6611-4420
FU French National Research Agency (ANR) through the COSINUS
   [ANR-08-COSI-003]
FX The authors thank the anonymous reviewers for their valuable comments
   which helped to improve the quality of the paper. This work has been
   supported by the French National Research Agency (ANR) through the
   COSINUS program (project COLLAVIZ no ANR-08-COSI-003). The GIST-Monkey
   and Nefertiti models are courtesy of GIST in South Korea. The authors
   thank Sebastien Valette, Jingliang Peng, and Khaled Mamou for sending us
   the intermediate models from their works.
CR Ahn JK, 2010, IEEE IMAGE PROC, P3417, DOI 10.1109/ICIP.2010.5653130
   Ahn JH, 2006, IEEE T CIRC SYST VID, V16, P291, DOI 10.1109/TCSVT.2005.861945
   Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   Alliez P, 2001, COMPUT GRAPH FORUM, V20, pC480, DOI 10.1111/1467-8659.00541
   Bajaj CL, 1999, IEEE DATA COMPR CONF, P247, DOI 10.1109/DCC.1999.755674
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cirio G., 2010, INT C COMP GRAPH THE
   Cohen-Or D., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P67
   Deering M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P13, DOI 10.1145/218380.218391
   Gandoin PM, 2002, ACM T GRAPHIC, V21, P372, DOI 10.1145/566570.566591
   Gumhold S., 1998, P SIGGRAPH, P140
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Hoppe H., 1996, Proc. ACM SIGGRAPH, P99
   Isenburg M, 2005, COMPUT AIDED DESIGN, V37, P869, DOI 10.1016/j.cad.2004.09.015
   Karni Z, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P347, DOI 10.1109/VISUAL.2002.1183794
   Khodakovsky A, 2004, MATH VISUAL, P189
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   King D, 1999, COMP GEOM-THEOR APPL, V14, P91, DOI 10.1016/S0925-7721(99)00025-5
   Lee H., 2009, P VIS MOD VIS WORKSH, P73
   Lee H, 2010, WSCG 2010: COMMUNICATION PAPERS PROCEEDINGS, P199
   Mamou K, 2010, IEEE IMAGE PROC, P3425, DOI 10.1109/ICIP.2010.5653218
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Payan F, 2005, COMPUT AIDED GEOM D, V22, P466, DOI 10.1016/j.cagd.2005.04.001
   Peng J., 2005, ACM T GRAPHIC, V24, P616
   Peng JL, 2010, COMPUT GRAPH FORUM, V29, P2029, DOI 10.1111/j.1467-8659.2010.01789.x
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Roy M., 2004, Int. J. Image Graphics, V4, P127, DOI DOI 10.1142/S0219467804001324
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   Taubin G., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P123, DOI 10.1145/280814.280834
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P123, DOI 10.1109/TVCG.2004.1260764
   Valette S, 2004, COMPUT GRAPH-UK, V28, P35, DOI 10.1016/j.cag.2003.10.017
   Valette S, 2009, COMPUT GRAPH FORUM, V28, P1301, DOI 10.1111/j.1467-8659.2009.01507.x
   Yoon YS, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P253, DOI 10.1109/ICME.2006.262430
NR 34
TC 38
Z9 47
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2012
VL 28
IS 2
BP 137
EP 153
DI 10.1007/s00371-011-0602-y
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 881SW
UT WOS:000299510100001
DA 2024-07-18
ER

PT J
AU Xian, CH
   Lin, HW
   Gao, SM
AF Xian, Chuhua
   Lin, Hongwei
   Gao, Shuming
TI Automatic cage generation by improved OBBs for mesh deformation
SO VISUAL COMPUTER
LA English
DT Article
DE Cage generation; Mesh deformation; Geometric design; Computer graphics
AB In cage-based deformation, the most tedious task is to construct the coarse cage bounding a model. Currently, the coarse cage is constructed mainly by hand, and the construction usually takes several hours, even longer. Therefore, it is important to develop a convenient method to generate the coarse cage bounding a model. In this paper, we devise a method to construct the coarse cage automatically using the improved OBB tree, while allowing the users to modify the cage easily. Firstly, the OBB tree bounding the model is generated, where we propose an improved OBB slicing rule to make the generated OBBs close to the model it contains. Secondly, the OBBs are adjusted and merged into a whole entity by the boolean union operation. Finally, the outer surface of the entity is extracted as the coarse cage. Empirical results demonstrate the effectiveness and efficiency of the automatic coarse cage-generation method.
C1 [Xian, Chuhua; Lin, Hongwei; Gao, Shuming] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Lin, HW (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM xianchuhua@cad.zju.edu.cn; hwlin@cad.zju.edu.cn; smgao@cad.zju.edu.cn
FU Natural Science Foundation of China [60970150, 60736019, 60933008];
   Zhejiang Provincial Natural Science Foundation of China [Y1090416]
FX We thank the reviewers for their helpful comments. This paper is
   supported by Natural Science Foundation of China (Nos. 60970150,
   60736019, 60933008), and Zhejiang Provincial Natural Science Foundation
   of China (No. Y1090416).
CR Floater MS, 2005, COMPUT AIDED GEOM D, V22, P623, DOI 10.1016/j.cagd.2005.06.004
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Hearn D., 1997, COMPUTER GRAPHICS C, V2nd
   HUANG J, 2008, P ACM S SOL PHYS MOD, P241
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Ju T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409075
   Ju T, 2009, J COMPUT SCI TECH-CH, V24, P19, DOI 10.1007/s11390-009-9206-7
   Landreneau E, 2009, COMPUT GRAPH FORUM, V28, P347, DOI 10.1111/j.1467-8659.2009.01374.x
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Magnenat-Thalmann N., 1989, P GRAPHICS INTERFACE, P26, DOI [10.5555/102313.102317, DOI 10.5555/102313.102317]
   SEDERBERG TW, 1986, P SIGGRAPH 1986
   Xian C., 2009, IEEE INT C SHAP MOD
NR 14
TC 26
Z9 31
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2012
VL 28
IS 1
BP 21
EP 33
DI 10.1007/s00371-011-0595-6
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874YQ
UT WOS:000298995000003
DA 2024-07-18
ER

PT J
AU Simon, G
   Berger, MO
AF Simon, Gilles
   Berger, Marie-Odile
TI Interactive building and augmentation of piecewise planar environments
   using the intersection lines
SO VISUAL COMPUTER
LA English
DT Article
DE Interactive building; Structure-from-motion; SLAM; Particle filtering;
   Camera tracking; Augmented reality
AB This paper describes a method for online interactive building of piecewise planar environments for immediate use in augmented reality. This system combines user interaction from a camera-mouse and automated tracking/reconstruction methods to recover planar structures of the scene that are relevant for the augmentation task. An important contribution of our algorithm is that the process of tracking and reconstructing planar structures is decomposed into three steps-tracking, computation of the intersection lines of the planes, reconstruction-that can each be visually assessed by the user, making the interactive modeling procedure really robust and accurate with intuitive interaction. Videos illustrating our system both on synthetic and long real-size experiments are available at http://www.loria.fr/similar to gsimon/vc.
C1 [Simon, Gilles] Nancy Univ, LORIA, F-54506 Vandoeuvre Les Nancy, France.
   [Berger, Marie-Odile] INRIA Nancy Grand Est, LORIA, F-54600 Villers Les Nancy, France.
C3 Universite de Lorraine; Universite de Lorraine
RP Simon, G (corresponding author), Nancy Univ, LORIA, Campus Sci,BP 239, F-54506 Vandoeuvre Les Nancy, France.
EM gsimon@loria.fr
CR [Anonymous], P 8 IEEE ACM INT S M
   [Anonymous], 5 INT S 3D DAT PROC
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bunnun P, 2008, INT SYM MIX AUGMENT, P61, DOI 10.1109/ISMAR.2008.4637325
   Chekhlov D., 2007, P 6 IEEE ACM INT S M, P153, DOI DOI 10.1109/ISMAR.2007.4538840
   CHEKHLOV D, 2006, 2 INT S VIS COMP NOV
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   FAUGERAS O, 1988, 856 INRIA
   FISCHLER MA, 1980, 213 ART INT CTR SRI
   FREEMAN R, 2006, P ACM VIRT REAL SOFT, P61, DOI DOI 10.1145/1180495.1180508
   Gee AP, 2008, IEEE T ROBOT, V24, P980, DOI 10.1109/TRO.2008.2004641
   Harris C., 1988, P 4 ALV C CAMBR AUG
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Huynh D.-N.T., 2009, Proceed- ings of the 2009 ACM SIGGRAPH Symposium on Video Games, Sandbox '09, P135, DOI [DOI 10.1145/1581073.1581095, 10.1145/1581073.1581095]
   Jin HL, 2003, VISUAL COMPUT, V19, P377, DOI 10.1007/s00371-003-0202-6
   JOHANSSON B, 1999, ICCV, P54
   Kato H., 1999, P 2 INT WORKSH AUGM
   KLEIN G, 2008, P EUR C COMP VIS ECC
   Klein G., 2007, 6 IEEE ACM INT S MIX
   Lepetit V, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P93, DOI 10.1109/ISMAR.2003.1240692
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   NOURY N, 2010, RR7246 INRIA
   Schmid C, 1997, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1997.609397
   SIMON G, 2008, 9 INT C PATT REC ICP, P1
   Sinha SN, 2009, IEEE I CONF COMP VIS, P1881, DOI 10.1109/ICCV.2009.5459417
   Thormahlen T., 2006, THESIS U HANNOVER
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Tomasi C, 1991, DETECTION TRACKING P
   van den Hengel A, 2009, INT SYM MIX AUGMENT, P107, DOI 10.1109/ISMAR.2009.5336482
   VIGUERAS F, 2003, VIS VID GRAPH VVG 03
   VINCENT E, 2001, 2 INT S IM SIGN PROC
   XU G, 2000, P IEEE C COMP VIS PA
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yohan SJ., 2000, NATO S INFORM PROCES, P9
   Zuliani M, 2005, IEEE IMAGE PROC, P2969
NR 35
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2011
VL 27
IS 9
BP 827
EP 841
DI 10.1007/s00371-011-0556-0
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 807TK
UT WOS:000293922400003
DA 2024-07-18
ER

PT J
AU Garanzha, K
   Premoze, S
   Bely, A
   Galaktionov, V
AF Garanzha, Kirill
   Premoze, Simon
   Bely, Alexander
   Galaktionov, Vladimir
TI Grid-based SAH BVH construction on a GPU
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Conference on the Computer Graphics International (CGI)
CY JUN 12-15, 2011
CL Ottawa, CANADA
DE GPU; Ray tracing; Acceleration structure; Triangle subdivision; SAH;
   Surface area heuristic; BVH; Bounding volume hierarchy
AB We present an efficient algorithm for building an adaptive bounding volume hierarchy (BVH) in linear time on commodity graphics hardware using CUDA. BVHs are widely used as an acceleration data structure to quickly ray trace animated polygonal scenes. We accelerate the construction process with auxiliary grids that help us build high quality BVHs with SAH in O(kaun). We partition scene triangles and build a temporary grid structure only once. We also handle non-uniformly tessellated and long/thin triangles that we split into several triangle references with tight bounding box approximations. We make no assumptions on the type of geometry or animation motion. However, our algorithm takes advantage of coherent geometry layout and coherent frame-by-frame motion. We demonstrate the performance and quality of resulting BVHs that are built quickly with good spatial partitioning.
C1 [Garanzha, Kirill; Galaktionov, Vladimir] MV Keldysh Appl Math Inst, Comp Graph Dept, Moscow 125047, Russia.
   [Garanzha, Kirill] NVIDIA, OptiX Grp, Moscow, Russia.
   [Bely, Alexander] Capital Res, Moscow, Russia.
   [Bely, Alexander] FUGU, Moscow, Russia.
C3 Russian Academy of Sciences; Keldysh Institute of Applied Mathematics
RP Garanzha, K (corresponding author), MV Keldysh Appl Math Inst, Comp Graph Dept, Moscow 125047, Russia.
EM kirill@garanzha.com; simon.premoze@gmail.com;
   a.bely@capital-research.ru; vlgal@gin.keldysh.ru
RI Galaktionov, Vladimir A./N-3333-2017
CR AILA T, 2009, P C HIGH PERF GRAPH, P145, DOI DOI 10.1145/1572769.1572792
   [Anonymous], P 2007 EUR S PAR GRA
   CHOI B, 2010, P HIGH PERF GRAPH
   FOLEY T., 2005, HWWS 05, P15
   Garanzha K, 2010, COMPUT GRAPH FORUM, V29, P289, DOI 10.1111/j.1467-8659.2009.01598.x
   GOLDSMITH J, 1987, IEEE COMPUT GRAPH, V7, P14, DOI 10.1109/MCG.1987.276983
   HAVRAN V, 2000, THESIS CZECH TU PRAG
   Kalojanov J., 2009, Proceedings of the 1st ACM conference on High Performance Graphics - HPG '09 (New York, New York, USA, 2009), P23
   Kalojanov J, 2011, COMPUT GRAPH FORUM, V30, P307, DOI 10.1111/j.1467-8659.2011.01862.x
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   PANTALEONI J., 2010, HIGH PERFORMANCE GRA
   Popov S, 2007, COMPUT GRAPH FORUM, V26, P415, DOI 10.1111/j.1467-8659.2007.01064.x
   Satish Nadathur, 2009, P 23 IEEE INT PAR DI
   Shevtsov M, 2007, COMPUT GRAPH FORUM, V26, P395, DOI 10.1111/j.1467-8659.2007.01062.x
   STICH M, 2009, P HIGH PERF GRAPH
   Wachter C., 2006, Proceedings of the Eurographics Symposium on Rendering, P139, DOI DOI 10.2312/EGWR/EGSR06/139-149
   WALD I, 2007, P 2007 EUR IEEE S IN
   Wald I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186650
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 20
TC 10
Z9 17
U1 2
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2011
VL 27
IS 6-8
BP 697
EP 706
DI 10.1007/s00371-011-0593-8
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 766FY
UT WOS:000290767600028
DA 2024-07-18
ER

PT J
AU Röttger, D
   Seib, V
   Müller, S
AF Roettger, Diana
   Seib, Viktor
   Mueller, Stefan
TI Distance-based tractography in high angular resolution diffusion MRI
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Conference on the Computer Graphics International (CGI)
CY JUN 12-15, 2011
CL Ottawa, CANADA
DE High angular resolution diffusion imaging; Diffusion weighted magnetic
   resonance imaging; Tractography; Tracking; White matter
ID VALIDATION; TENSOR
AB High angular resolution diffusion imaging (HARDI) is a magnetic resonance imaging (MRI) technique, determining the diffusion of water molecules in tissue in vivo. HARDI is advantageous over the well-known diffusion tensor imaging (DTI), since it is able to extract more than one fiber orientation within a voxel and can therefore resolve crossing, kissing or fanning fiber tracts. However, multiple orientations per voxel require more sophisticated tractography approaches. In this paper we introduce a new deterministic fiber tracking method using the complete orientation distribution function (ODF) reconstructed from Q-ball imaging to enable tractography in challenging regions. Anisotropy classifiers are used to differentiate intra-voxel fiber populations and adjust a curvature threshold for one and multiple fiber configurations, respectively. In addition, we determine the most appropriate propagation direction in complex white matter regions, using the course of the current tract. To ensure tractography running within fiber bundles, a distance-based approach is integrated, which aims to maintain the initial distance of the seed point to the white matter boundary through the whole tracking. We evaluated our method using a phantom dataset featuring crossing, kissing and fanning fiber configurations and a human brain dataset, reconstructing the fanning of the corpus callosum and considering the region of the centrum semiovale.
C1 [Roettger, Diana; Seib, Viktor; Mueller, Stefan] Univ Koblenz Landau, Comp Graph Res Grp, D-56070 Koblenz, Germany.
C3 University of Koblenz & Landau
RP Röttger, D (corresponding author), Univ Koblenz Landau, Comp Graph Res Grp, Univ Str 1, D-56070 Koblenz, Germany.
EM droettger@uni-koblenz.de; vseib@uni-koblenz.de; stefanm@uni-koblenz.de
CR AGANJ I, 2009, IEEE INT S BIOM IM N
   Assemlal H-E, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P133
   Basser PJ, 2000, MAGNET RESON MED, V44, P625, DOI 10.1002/1522-2594(200010)44:4<625::AID-MRM17>3.0.CO;2-O
   Behrens TEJ, 2007, NEUROIMAGE, V34, P144, DOI 10.1016/j.neuroimage.2006.09.018
   BERMAN JI, 2008, NEUROIMAGE, V39
   Campbell JSW, 2005, NEUROIMAGE, V27, P725, DOI 10.1016/j.neuroimage.2005.05.014
   Chao YP, 2008, MED ENG PHYS, V30, P989, DOI 10.1016/j.medengphy.2008.01.010
   Chen Y, 2004, PROC CVPR IEEE, P588
   DESCOTEAUX M, 2009, IEEE T MED IMAG, V28
   Descoteaux M, 2007, MAGN RESON MED, V58, P497, DOI 10.1002/mrm.21277
   FILLARD P, 2011, NEUROIMAGE IN PRESS
   Frank LR, 2002, MAGN RESON MED, V47, P1083, DOI 10.1002/mrm.10156
   GOH A, 2009, LNAO
   Gray H., 1918, GRAYS ANATOMY HUMAN
   JEURISSEN B, 2009, LNAO
   Lazar M, 2003, HUM BRAIN MAPP, V18, P306, DOI 10.1002/hbm.10102
   Merhof D, 2006, IEEE T VIS COMPUT GR, V12, P1181, DOI 10.1109/TVCG.2006.151
   MORI S, 1999, MAGN RESON IMAG, V45
   Özarslan E, 2006, NEUROIMAGE, V31, P1086, DOI 10.1016/j.neuroimage.2006.01.024
   PERRIN M, 2005, INFORM PROCESSING ME
   POUPON C, 2010, ISMRM
   POUPON C, 2006, 12 HBM NEUR FLOR IT, P646
   Poupon C, 2008, MAGN RESON MED, V60, P1276, DOI 10.1002/mrm.21789
   PRCKOVSKA V, 2010, ICT INN 2009, P345
   ROTTGER D, 2011, INF AKTUELL, P364, DOI DOI 10.1007/978-3-642-19335-4_75
   Savadjiev P, 2008, NEUROIMAGE, V41, P58, DOI 10.1016/j.neuroimage.2008.01.028
   Tournier JD, 2007, NEUROIMAGE, V35, P1459, DOI 10.1016/j.neuroimage.2007.02.016
   Tournier JD, 2004, NEUROIMAGE, V23, P1176, DOI 10.1016/j.neuroimage.2004.07.037
   Tuch D.S., 2002, Diffusion MRI of complex tissue structure
   Tuch DS, 2004, MAGN RESON MED, V52, P1358, DOI 10.1002/mrm.20279
   WEDEEN V, 2008, NEUROIMAGE, V41
   WEDEEN V, 2000, P INT SOT MAG RES ME, V8
   WEINSTEIN D, 1999, 10 IEEE VIS
   ZHUKOV L, 2002, IEEE VISUALIZATION
NR 34
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2011
VL 27
IS 6-8
BP 729
EP 738
DI 10.1007/s00371-011-0587-6
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 766FY
UT WOS:000290767600031
DA 2024-07-18
ER

PT J
AU Sharma, O
   Anton, F
AF Sharma, Ojaswa
   Anton, Francois
TI Homotopy-based surface reconstruction with application to acoustic
   signals
SO VISUAL COMPUTER
LA English
DT Article
DE Homotopy; Continuous deformations; Surface reconstruction; Shape
   preserving; Acoustic signal; Sonar
ID SHAPE RECONSTRUCTION
AB This work introduces a new algorithm for surface reconstruction in a"e(3) from spatially arranged one-dimensional cross sections embedded in a"e(3). This is generally the case with acoustic signals that pierce an object non-destructively. Continuous deformations (homotopies) that smoothly reconstruct information between any pair of successive cross sections are derived. The zero level set of the resulting homotopy field generates the desired surface. Four types of homotopies are suggested that are well suited to generate a smooth surface. We also provide derivation of necessary higher order homotopies that can generate a C (2) surface. An algorithm to generate surface from acoustic sonar signals is presented with results. Reconstruction accuracies of the homotopies are compared by means of simulations performed on basic geometric primitives.
C1 [Sharma, Ojaswa; Anton, Francois] Tech Univ Denmark, Dept Informat & Math Modeling, DK-2800 Lyngby, Denmark.
C3 Technical University of Denmark
RP Sharma, O (corresponding author), Tech Univ Denmark, Dept Informat & Math Modeling, DK-2800 Lyngby, Denmark.
EM os@imm.dtu.dk; fa@imm.dtu.dk
RI Anton, François/F-7373-2011; Castro, Francesc Antón i/AAS-3240-2020;
   Anton, François/A-7550-2015; Anton, Francois/P-7251-2015
OI Castro, Francesc Antón i/0000-0002-0417-9787; Sharma,
   Ojaswa/0000-0002-9902-1367; Anton, Francois/0000-0003-1558-4611
CR Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475
   [Anonymous], 1990, Numerical Continuation Methods
   Armstrong MA., 1983, BASIC TOPOLOGY
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Bajaj CL, 1996, GRAPH MODEL IM PROC, V58, P524, DOI 10.1006/gmip.1996.0044
   Beros I., 1999, Mathematical Communications, V4, P73
   Berzin D, 2002, VISUAL COMPUT, V18, P437, DOI 10.1007/s003710100163
   BOISSONNAT JD, 1988, COMPUT VISION GRAPH, V44, P1, DOI 10.1016/S0734-189X(88)80028-8
   BOISSONNAT JD, 2007, P 5 EUR S GEOM PROC, P98
   Carr J, 2001, P 28 ANN C COMP GRAP, P76
   COPPERSMITH D, 1990, J SYMB COMPUT, V9, P251, DOI 10.1016/S0747-7171(08)80013-2
   Costantini P., 1984, Calcolo, V21, P281, DOI 10.1007/BF02576538
   DEBOOR C, 1977, J APPROX THEORY, V21, P411, DOI 10.1016/0021-9045(77)90011-9
   FUCHS H, 1977, COMMUN ACM, V20, P693, DOI 10.1145/359842.359846
   Fujimura K, 1999, GRAPH MODEL IM PROC, V61, P127, DOI 10.1006/gmip.1999.0494
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   HYMAN JM, 1983, SIAM J SCI STAT COMP, V4, P645, DOI 10.1137/0904045
   KEPPEL E, 1975, IBM J RES DEV, V19, P2, DOI 10.1147/rd.191.0002
   Liu L, 2008, COMPUT GRAPH FORUM, V27, P155, DOI 10.1111/j.1467-8659.2008.01112.x
   Ona Egil, 2007, OCEANS 2007 - Europe, P1, DOI 10.1109/OCEANSE.2007.4302473
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   PRUESS S, 1978, COMPUTING, V19, P365, DOI 10.1007/BF02252033
   Shinagawa Y., 1991, Visual Computer, V7, P77, DOI 10.1007/BF01901178
   Simmonds J., 2005, FISHERIES ACOUSTICS, V2nd ed., DOI DOI 10.1002/9780470995303.CH8
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   SPATH H, 1969, COMPUTING, V4, P225, DOI 10.1007/BF02234771
   Wolberg G, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P188, DOI 10.1109/CGI.1999.777953
   Zhang Y, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P45, DOI 10.1109/VISUAL.2002.1183755
NR 29
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2011
VL 27
IS 5
BP 373
EP 386
DI 10.1007/s00371-011-0544-4
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 745ZI
UT WOS:000289209800004
DA 2024-07-18
ER

PT J
AU Islam, MT
   Nahiduzzaman, KM
   Why, YP
   Ashraf, G
AF Islam, M. Tanvirul
   Nahiduzzaman, Kaiser M.
   Why, Yong Peng
   Ashraf, Golam
TI Informed character pose and proportion design
SO VISUAL COMPUTER
LA English
DT Article
DE Shape learning; Shape psychology; Perception games; Design tutor
AB The use of pose and proportion to represent character traits is well established in art and psychology literature. However, there are no golden rules that quantify a generic design template for stylized character figure drawing. Given the wide variety of drawing styles and a large feature dimension space, it is a significant challenge to extract this information automatically from existing cartoon art. This paper outlines a game-inspired methodology for systematically collecting layman perception feedback, given a set of carefully chosen trait labels and character silhouette images. The rated labels were clustered and then mapped to the pose and proportion parameters of characters in the dataset. The trained model can be used to classify new drawings, providing valuable insight to artists who want to experiment with different poses and proportions in the draft stage. The proposed methodology was implemented as follows: (1) Over 200 full-body, front-facing character images were manually annotated to calculate pose and proportion; (2) A simplified silhouette was generated from the annotations to avoid copyright infringements and prevent users from identifying the source of our experimental figures; (3) An online casual role-playing puzzle game was developed to let players choose meaningful tags (role, physicality, and personality) for characters, where tags and silhouettes received equitable exposure; (4) Analysis on the generated data was done both in stereotype label space as well as character shape space; (5) Label filtering and clustering enabled dimension reduction of the large description space, and subsequently, a select set of design features were mapped to these clusters to train a neural network classifier; (6) Bayesian graphs were also mined to allow informed tweaks to the input feature set, in order to push the character toward a different label stereotype class. The mapping between the collected perception and shape data give us quantitative and qualitative insight into character design. It opens up applications for creative reuse of (and deviation from) existing character designs.
C1 [Islam, M. Tanvirul; Nahiduzzaman, Kaiser M.; Ashraf, Golam] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
   [Why, Yong Peng] Natl Univ Singapore, FASS Psychol, Singapore 117548, Singapore.
C3 National University of Singapore; National University of Singapore
RP Ashraf, G (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
EM tanvirulbd@gmail.com; kaisernahid@gmail.com; psywyp@nus.edu.sg;
   gashraf@nus.edu.sg
OI Why, Felix/0000-0002-2937-225X
CR [Anonymous], 1995, P NZ COMPUTER SCI RE
   Ashraf G, 2010, COMPUT GAME MULTIMED, P58
   Bancroft T., 2006, Creating characters with personality
   Beiman N., 2007, PREPARE BOARD CREATI
   Camara Sergi., 2006, BARRONS ED SERIES
   Di Fiore F, 2008, VISUAL COMPUT, V24, P105, DOI 10.1007/s00371-007-0189-5
   EDELMAN S, 1997, LEARNING EXTRACTION
   FUNGE J, 1999, P ACM SIGGRAPH
   Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45
   Gingold Y, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1616494, 10.1145/1618452.1618494]
   GOLDBERG LR, 1993, AM PSYCHOL, V48, P26, DOI 10.1037/0003-066X.48.1.26
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   GUTIERREZ MA, 2007, J VISUAL COMPUTING
   HART C, 2000, CARTOON COOL DRAW NE
   Hsu CH, 2005, INT J ADV MANUF TECH, V26, P669, DOI 10.1007/s00170-003-2032-0
   Islam MT, 2010, LECT NOTES ARTIF INT, V6171, P606, DOI 10.1007/978-3-642-14400-4_47
   ISLAM MT, 2010, CYBERWORLDS 2010
   KARSVALL A, 2002, P 2 NORD C HUM COMP
   LES Z, 2008, SHAPE UNDERSTANDING
   LIN HYS, 2005, P 7 IEEE INT S MULT
   LIU J, 2006, P 14 ANN ACM INT C M
   Malone TW., 1980, P 3 ACM SIGSMALL S 1, P162, DOI DOI 10.1145/800088.802839
   MARCHENKO Y, 2007, MMM, V1, P13
   Meyer M, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276469
   Pizlo Z, 2008, 3D SHAPE: ITS UNIQUE PLACE IN VISUAL PERCEPTION, pIX
   Shneiderman B., 2004, INTERACTIONS, V11, P48, DOI DOI 10.1145/1015530.1015552
   Sykora D, 2010, COMPUT GRAPH FORUM, V29, P615, DOI 10.1111/j.1467-8659.2009.01631.x
   SYKORA D, 2005, P EUR WORKSH SKETCH, P27
   Sykora Daniel, 2009, P 7 INT S NONPHOTORE, P25, DOI DOI 10.1145/1572614.1572619.3,7
   UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954
   Veselova Y, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P482
   VOGEL HL, 2000, ENTERTAINMENT IND EC
   VONAHN L, 2008, ACM, V51
   Wang RY, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239524, 10.1145/1276377.1276468]
   WEBSTER J, 1988, P ACM SIGCPR C MAN I, P78
NR 35
TC 3
Z9 4
U1 1
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2011
VL 27
IS 4
SI SI
BP 251
EP 261
DI 10.1007/s00371-011-0545-3
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 739IC
UT WOS:000288707700002
DA 2024-07-18
ER

PT J
AU Liao, IY
   Zaman, M
AF Liao, Iman Y.
   Zaman, Munir
TI Prior model evaluation from Null Space Compensation perspective with
   application to surface reconstruction from single images
SO VISUAL COMPUTER
LA English
DT Article
DE Null Space Compensation; Prior model; Surface reconstruction; Shape from
   shading
ID SHAPE
AB Prior model is widely applied in the area of computer vision and computer graphics. However, there is still a lack of a general theoretical scheme for evaluating the performance of the priors and a guidance for choosing suitable models. In this paper, a general scheme is proposed for linear singular problems based on the idea of Null Space Compensation. It is proved that for a linear prior model the principal directions obtained from the singular value decomposition of the model shall not be parallel to those of the system matrix determined by the problem. It is also suggested that for a nonlinear prior, higher correlation between the null space components of the estimate data based on the given prior and those of the ground truth or controlled data indicate the better suitability of the prior. The proposed evaluation scheme is demonstrated through an application to a linearized shape from shading problem, where surface shall be reconstructed from single 2D images. Both linear model and nonlinear constraints are evaluated with experiments on both synthetic images and real images. The results validate the proposed evaluation scheme and its capability for guiding in choosing a good prior model structure.
C1 [Liao, Iman Y.; Zaman, Munir] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
C3 Universiti Sains Malaysia
RP Liao, IY (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
EM iman@cs.usm.my; mzaman@cs.usm.my
RI Zaman, Munir/A-6914-2011; Liao, Iman/HOC-9644-2023
OI Liao, Iman/0000-0001-5165-4539
FU Universiti Sains Malaysia
FX This work was partly supported by the Universiti Sains Malaysia
   Incentive Grant, awarded in November 2009.
CR [Anonymous], P 2 INT C COMP VIS
   Blanz Volker., 1999, P 26 ANN C COMPUTER, P187, DOI DOI 10.1145/311535.311556
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Durá E, 2004, IEE P-RADAR SON NAV, V151, P114, DOI 10.1049/ip-rsn:20040262
   HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3
   HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771
   Huang R, 2002, INT C PATT RECOG, P29, DOI 10.1109/ICPR.2002.1047787
   IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0
   Johnson AP, 2005, J OPT SOC AM A, V22, P2050, DOI 10.1364/JOSAA.22.002050
   KUBE P, 1988, IEEE T PATTERN ANAL, V10, P704, DOI 10.1109/34.6779
   Liao IY, 2008, COMPUT VIS IMAGE UND, V109, P227, DOI 10.1016/j.cviu.2007.10.002
   Liao Y, 2006, LECT NOTES COMPUT SC, V4222, P714
   Liu HX, 2003, COMPUT GEOSCI-UK, V29, P1229, DOI 10.1016/S0098-3004(03)00138-9
   OKATANI T, 1997, LECT NOTES COMPUT SC, V1351, P48
   PAN TS, 1991, IEEE T MED IMAGING, V10, P572, DOI 10.1109/42.108592
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Prados E, 2005, PROC CVPR IEEE, P870
   SALZMANN M, 2008, ECCV2008, P1
   Salzmann M, 2007, IEEE T PATTERN ANAL, V29, P1481, DOI 10.1109/TPAMI.2007.1080
   Szeliski R., 1989, Computer Graphics, V23, P51, DOI 10.1145/74334.74338
   Turner M.J., 1998, FRACTAL GEOMETRY DIG
   Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247
NR 24
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 997
EP 1005
DI 10.1007/s00371-010-0433-2
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800059
DA 2024-07-18
ER

PT J
AU Ozaki, M
   Gobeawan, L
   Kitaoka, S
   Hamazaki, H
   Kitamura, Y
   Lindeman, RW
AF Ozaki, Maya
   Gobeawan, Like
   Kitaoka, Shinya
   Hamazaki, Hirofumi
   Kitamura, Yoshifumi
   Lindeman, Robert W.
TI Camera movement for chasing a subject with unknown behavior based on
   real-time viewpoint goodness evaluation
SO VISUAL COMPUTER
LA English
DT Article
DE Computer animation; 3D Virtual environment; Computer games; Camera
   control; Path planning; Viewpoint entropy
AB We propose a method that automatically generates a smooth chase camera movement to follow a subject, a user-controlled character or a character with unknown behaviors, in a 3D environment freely in real time. We consider three objectives in generating the smooth-camera movement: to avoid collisions with obstacles, to avoid subject occlusions, and to choose a good viewpoint for looking at the subject. We evaluate the goodness of viewpoints by using a viewpoint entropy map and choose the best viewpoint as the goal position of the camera in real time. Afterwards, we move the camera toward the goal position by following the shortest path, found by the A* algorithm, on a roadmap graph. The resulting camera movement has a high degree of freedom and fulfills the three objectives above. Our method is effective for third-person-view 3D applications in tracking the real-time movement of user-controlled characters in exploring a 3D environment.
C1 [Ozaki, Maya; Kitaoka, Shinya] Osaka Univ, Human Interface Engn Lab, Suita, Osaka 5650871, Japan.
   [Gobeawan, Like] Inst High Performance Comp, Singapore 138632, Singapore.
   [Hamazaki, Hirofumi] Sharp Co Ltd, Abeno Ku, Osaka 5458522, Japan.
   [Kitamura, Yoshifumi] Tohoku Univ, Elect Commun Res Inst, Aoba Ku, Sendai, Miyagi 9808577, Japan.
   [Lindeman, Robert W.] Worcester Polytech Inst, Worcester, MA 01609 USA.
C3 Osaka University; Agency for Science Technology & Research (A*STAR);
   A*STAR - Institute of High Performance Computing (IHPC); Hisense; Sharp
   Corporation; Tohoku University; Worcester Polytechnic Institute
RP Ozaki, M (corresponding author), Osaka Univ, Human Interface Engn Lab, 2-1 Yamadaoka, Suita, Osaka 5650871, Japan.
EM maya.ozaki@gmail.com; gobeawanl@ihpc.a-star.edu.sg; skitaoka@gmail.com;
   hamazaki.hirofumi@sharp.co.jp; kitamura@ist.osaka-u.ac.jp; gogo@wpi.edu
RI Gobeawan, Like/U-4198-2019; Lindeman, Rob/AAG-8857-2020
OI Gobeawan, Like/0000-0001-6501-6394; Lindeman, Rob/0000-0002-0637-7701;
   Kitamura, Yoshifumi/0000-0002-7047-627X
CR AMERSON D, 2001, AAAI SPRING S ART IN
   Andújar C, 2004, COMPUT GRAPH FORUM, V23, P499, DOI 10.1111/j.1467-8659.2004.00781.x
   [Anonymous], INVISIBLE LEARNING A
   BARRAL P, 2000, P EUR 00, V2, P4
   Christianson DB, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P148
   CHRISTIE M, 2005, P ANN EUR C, P247
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   HAMAZAKI H, 2008, P 2008 INT C ADV COM, P126
   Heidrich W, 1998, P ACM SIGGRAPH EUROG
   Kitamura Y., 1995, Proceedings. 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots (Cat. No.95CB35836), P474, DOI 10.1109/IROS.1995.526259
   Kuffner J. J., 2000, IEEE INT C ROB AUT, V2
   LaValle SM, 2004, INT J ROBOT RES, V23, P673, DOI 10.1177/0278364904045481
   Marchand É, 2002, VISUAL COMPUT, V18, P1, DOI 10.1007/s003710100122
   Roberts D. R., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P740
   Rosell J, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P15, DOI 10.1109/IROS.2007.4399167
   Vazquez P.-P., 2001, Proceedings of Vision Modeling and Visualization Conference, P273
   WARREN CW, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, pB662
NR 17
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 629
EP 638
DI 10.1007/s00371-010-0489-z
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800023
DA 2024-07-18
ER

PT J
AU Shi, KL
   Yong, JH
   Sun, JG
   Paul, JC
   Gu, HJ
AF Shi, Kan-Le
   Yong, Jun-Hai
   Sun, Jia-Guang
   Paul, Jean-Claude
   Gu, He-Jin
TI Filling n-sided regions with G <SUP>1</SUP> triangular Coons B-spline
   patches
SO VISUAL COMPUTER
LA English
DT Article
DE n-sided region filling; Triangular Coons B-spline surface; G(1)
   continuity; CAD
ID CONTINUITY
AB Filling n-sided regions is an essential operation in shape and surface modeling. Positional and tangential continuities are highly required in designing and manufacturing. We propose a method for filling n-sided regions with untrimmed triangular Coons B-spline patches, preserving G (1) continuity exactly. The algorithm first computes a central point, a central normal, the central, and the corner derivative vectors. Then the region is split into n triangular areas by connecting the central point to each corner of the boundary. These inner curves and all cross-boundary derivatives are computed fulfilling G (1) compatibility conditions. And finally, the triangular patches are generated in the Coons B-spline form, one boundary of which is regressed to the central vertex. Neither positional nor tangential error is introduced by this method. And only one degree elevation is needed.
C1 [Shi, Kan-Le; Yong, Jun-Hai; Sun, Jia-Guang; Paul, Jean-Claude] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Shi, Kan-Le] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Shi, Kan-Le; Yong, Jun-Hai; Sun, Jia-Guang; Paul, Jean-Claude] Minist Educ China, Key Lab Informat Syst Secur, Beijing 100084, Peoples R China.
   [Shi, Kan-Le; Yong, Jun-Hai; Sun, Jia-Guang; Paul, Jean-Claude] Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Paul, Jean-Claude] INRIA, Nancy, France.
   [Gu, He-Jin] Jiangxi Acad Sci, Nanchang 330029, Peoples R China.
C3 Tsinghua University; Tsinghua University; Tsinghua University; Inria;
   Jiangxi Academy of Sciences
RP Shi, KL (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
EM skl03@mails.tsinghua.edu.cn
FU Chinese 973 Program [2010CB328001]; National Science Foundation of China
   [60625202, 90715043]; Chinese 863 Program [2007AA040401]; Fok Ying Tung
   Education Foundation [111070]; ANR-NSFC [60911130368]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments, and also thank Jia-Ting Chen of Tsinghua University
   for his valuable suggestions. The research was supported by Chinese 973
   Program (2010CB328001), the National Science Foundation of China
   (60625202, 90715043), and Chinese 863 Program (2007AA040401). The second
   author was supported by the Fok Ying Tung Education Foundation (111070).
   The fourth author was supported by ANR-NSFC (60911130368).
CR GREGORY JA, 1994, COMPUT AIDED GEOM D, V11, P391, DOI 10.1016/0167-8396(94)90205-4
   GREGORY JA, 1989, COMPUTATION CURVES S
   HAHN J, 1989, THEORY PRACTICE GEOM
   Hosaka M., 1984, Computer-Aided Geometric Design, V1, P75, DOI 10.1016/0167-8396(84)90005-0
   Hwang WC, 2003, J INF SCI ENG, V19, P857
   KARCIAUSKAS K, 2009, ACM T GRAPH, V28
   KARCIAUSKAS K, 2006, P S GRAPH PROC SGP J, P173
   Karciauskas K, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289605
   Li GQ, 2002, J COMPUT SCI TECHNOL, V17, P498, DOI 10.1007/BF02943290
   LIANG XZ, 2004, P GEOM MOD PROC
   Piegl L, 1997, COMPUT AIDED DESIGN, V29, P361, DOI 10.1016/S0010-4485(96)00074-7
   Piegl L., 1997, The Nurbs Book, Vsecond
   Piegl LA, 1999, VISUAL COMPUT, V15, P77, DOI 10.1007/s003710050163
   PLOWMAN D, 1994, P 6 IMA C MATH SURF, P67
   SABIN M, 1983, P EUROGRAPHICS 83, P57
   Shi KL, 2010, COMPUT AIDED DESIGN, V42, P479, DOI 10.1016/j.cad.2009.11.009
   Yang YJ, 2006, COMPUT AIDED DESIGN, V38, P1166, DOI 10.1016/j.cad.2006.07.001
   Ye XZ, 1996, COMPUT AIDED GEOM D, V13, P549, DOI 10.1016/0167-8396(95)00044-5
   Ye XZ, 1996, COMPUT AIDED GEOM D, V13, P521, DOI 10.1016/0167-8396(95)00043-7
NR 19
TC 8
Z9 12
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 791
EP 800
DI 10.1007/s00371-010-0468-4
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800039
DA 2024-07-18
ER

PT J
AU Wang, SD
   Cai, KY
   Lu, JA
   Liu, XH
   Wu, EH
AF Wang, Shandong
   Cai, Kangying
   Lu, Jian
   Liu, Xuehui
   Wu, Enhua
TI Real-time coherent stylization for augmented reality
SO VISUAL COMPUTER
LA English
DT Article
DE Stylization; Augmented reality; Line drawing; Abstraction; Coherent;
   Real-time
AB This paper presents a new stylized augmented reality (AR) framework which can generate line drawing and abstracted shading styles. In comparison with the state-of-art work, our framework can significantly improve both the visual immersion of a single frame and the temporal coherence of augmented video streams in real time. In our framework, we first render virtual objects over the input camera images and then uniformly process the combined contents with stylization techniques. For generating line drawing stylization, we first propose a specially designed shading method to render the virtual objects, and then use an adapted Flow-based anisotropic Difference-of-Gaussion (FDoG) filter to yield the high-quality line drawing effect. For generating the abstracted stylization, a focus-guided diffusion filter and a soft color quantization operator are sequentially applied to the augmented image, and then the processed result is combined with the detected edges to produce the final abstraction effect. The presented algorithms are all sympathetic to highly parallel processing, allowing a real-time performance on contemporary graphics hardware.
C1 [Wang, Shandong; Lu, Jian; Liu, Xuehui; Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab CS, Beijing, Peoples R China.
   [Wang, Shandong] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
   [Cai, Kangying] Thomson CR, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Macau, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; University
   of Macau
RP Wang, SD (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab CS, Beijing, Peoples R China.
EM sdwang10@gmail.com; cai_kangying@hotmail.com; zzzdevil@gmail.com;
   lxh@ios.ac.cn; EHWu@umac.mo
RI Lin, Fan/JZT-1441-2024
OI Lin, Fan/0000-0002-7330-3833
FU National Fundamental Research Grant of Science and Technology (973
   Project) [2009CB320802]; Science and Technology Development 863 project
   [2008AA01Z301]; University of Macau
FX We would like to thank Weiliangn Meng and Kai Bao for their help in
   typesetting the paper draft. This research is supported by National
   Fundamental Research Grant of Science and Technology (973 Project:
   2009CB320802), Science and Technology Development 863 project
   (2008AA01Z301) and research grant of University of Macau.
CR Cabral B, 1993, SIGGRAPH 93, P263
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHEN J, 2008, VRST 08, P231
   CHEN J, 2007, SIGGRAPH 07, P103
   COLE F, 2009, SIGGRAPH 09, P1
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   DeCarlo D, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P63
   DeCarlo Doug., 2004, P INT S NONPHOTOREAL, P15, DOI DOI 10.1145/987657.987661
   Fischer J., 2005, VRST, P155
   FISCHER J, 2006, EUR S VIRT ENV EGVE, P53
   Fischer J., 2005, WSI200518 U TUB
   FISCHER J, 2005, VR 05, P195
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   HALLER M, 2004, VRCAI 04, P189
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Judd T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239470
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kolomenkin M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409110
   Lee Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239469
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   Orzan A, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P103
   Pham TQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P454, DOI 10.1109/ICME.2005.1521458
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   Son MJ, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P333, DOI 10.1109/PG.2007.63
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
   ZHU L, 2008, IEEE AS PAC C CIRC S, P610
NR 31
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 445
EP 455
DI 10.1007/s00371-010-0436-z
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800006
DA 2024-07-18
ER

PT J
AU Xiong, MZ
   Lees, M
   Cai, WT
   Zhou, SP
   Low, MYH
AF Xiong, Muzhou
   Lees, Michael
   Cai, Wentong
   Zhou, Suiping
   Low, Malcolm Yoke Hean
TI Analysis of an efficient rule-based motion planning system for
   simulating human crowds
SO VISUAL COMPUTER
LA English
DT Article
DE Collision avoidance; Collision response; Motion planning; Crowd
   simulation
AB This paper proposes a rule-based motion planning system for agent-based crowd simulation, consisting of sets of rules for both collision avoidance and collision response. In order to avoid an oncoming collision, a set of rules for velocity sampling and evaluation is proposed, which aims to choose a velocity with an expected time to collision larger than a predefined threshold. In order to improve the efficiency over existing methods, the sampling procedure terminates upon finding an appropriate velocity. Moreover, the proposed motion planning system does not guarantee a collision-free movement. In case of collision, another set of rules is also defined to direct the agent to make a corresponding response. The experiment results show that the proposed approach can be applied in different scenarios, while making the simulation execution efficient.
C1 [Xiong, Muzhou; Lees, Michael; Cai, Wentong; Zhou, Suiping; Low, Malcolm Yoke Hean] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Xiong, MZ (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM mzxiong@ntu.edu.sg
RI Low, Malcolm Yoke Hean/AAT-1030-2020; Cai, Wentong/A-3720-2011; Lees,
   Michael H/A-3714-2011
OI Low, Malcolm Yoke Hean/0000-0002-5371-0896; Cai,
   Wentong/0000-0002-0183-3835; Lees, Michael/0000-0002-5457-9180
FU Defence Science and Technology Agency (DSTA) [POD0613456]; Technical
   Support Working Group (TSWG)
FX This research is supported under Defence Science and Technology Agency
   (DSTA) grant POD0613456 and Technical Support Working Group (TSWG).
CR Abe Y, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1207, DOI 10.1109/IROS.2001.977147
   [Anonymous], P 1 INT WORKSH CROWD
   [Anonymous], 2000, THESIS U TOKYO
   [Anonymous], P ACM SIGGRAPH
   BORIS K, 2004, P 2004 IEEE INT C RO, P4172
   Chenney Stephen., 2004, Proceedings of the 2004 ACM SIGGRAPH/Euro- graphics symposium on Computer animation, P233, DOI [10.1145/1028523.1028553, DOI 10.1145/1028523.1028553.]
   Fiorini P, 1998, INT J ROBOT RES, V17, P23
   Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977
   Gayle R., 2002, INT J ROBOT RES, V21, P233
   Helbing D, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P21
   Hsu D, 2002, INT J ROBOT RES, V21, P233, DOI 10.1177/027836402320556421
   Hughes RL, 2002, TRANSPORT RES B-METH, V36, P507, DOI 10.1016/S0191-2615(01)00015-7
   Jaillet L., 2004, Proc. of IEEE/RSJ IROS, P1606
   Li Y, 2007, IEEE INT CONF ROBOT, P1009, DOI 10.1109/ROBOT.2007.363117
   Mazarakis GP, 2005, Proceedings of the Second European Workshop on Wireless Sensor Networks, P415, DOI 10.1109/EWSN.2005.1462036
   Nguyen Q.H., 2005, Proceedings of the 2005 Conference on Behavior Representation in Modeling and Simulation (BRIMS), P55
   Parisi D., 2007, Pedestrian and Evacuation Dynamics 2005, P341
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechano Nuria., 2008, Virtual Crowds: Methods, Simulation, and Control
   Shiller Z, 2001, IEEE INT CONF ROBOT, P3716, DOI 10.1109/ROBOT.2001.933196
   Sud A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P91
   Thalmann Daniel., 2007, CROWD SIMULATION
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2008, INT J ROBOT RES, V27, P1274, DOI 10.1177/0278364908097581
   van den Berg J, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P139
   Weng WG, 2007, PHYSICA A, V374, P821, DOI 10.1016/j.physa.2006.08.003
   Xiong MZ, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P88, DOI 10.1109/CW.2009.32
NR 27
TC 9
Z9 11
U1 1
U2 10
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2010
VL 26
IS 5
BP 367
EP 383
DI 10.1007/s00371-010-0421-6
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 587GS
UT WOS:000276978800007
DA 2024-07-18
ER

PT J
AU Málková, M
   Parus, J
   Kolingerová, I
   Benes, B
AF Malkova, Martina
   Parus, Jindrich
   Kolingerova, Ivana
   Benes, Bedrich
TI An intuitive polygon morphing
SO VISUAL COMPUTER
LA English
DT Article
DE Morphing; Vector data; Polygon intersection; Computer Graphics
AB We present a new algorithm for morphing simple polygons that is inspired by growing forms in nature. While previous algorithms require user-assisted definition of complicated correspondences between the morphing objects, our algorithm defines the correspondence by overlapping the input polygons. Once the morphing of one object into another is defined, very little or no user interaction is necessary to achieve intuitive results. Our algorithm is suitable namely for growth-like morphing. We present the basic algorithm and its three variations. One of them is suitable mainly for convex polygons, the other two are for more complex polygons, such as curved or spiral polygonal forms.
C1 [Malkova, Martina; Parus, Jindrich; Kolingerova, Ivana] Univ W Bohemia, Plzen 30614, Czech Republic.
   [Benes, Bedrich] Purdue Univ, W Lafayette, IN 47907 USA.
C3 University of West Bohemia Pilsen; Purdue University System; Purdue
   University
RP Málková, M (corresponding author), Univ W Bohemia, Plzen 30614, Czech Republic.
EM mmalkov@kiv.zcu.cz; jparus@kiv.zcu.cz; kolinger@kiv.zcu.cz;
   bbenes@purdue.edu
RI Benes, Bedrich/A-8150-2016
OI Benes, Bedrich/0000-0002-5293-2112; Kolingerova,
   Ivana/0000-0003-4556-2771
FU Grant Agency of the Czech Republic [201/09/0097]
FX This work was supported by Grant Agency of the Czech Republic-project
   No. 201/09/0097.
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211
   Carmel E, 1997, VISUAL COMPUT, V13, P465, DOI 10.1007/s003710050118
   Comninos P., 2006, MATH COMPUTER PROGRA, DOI DOI 10.1007/978-1-84628-292-8
   Gomes J., 1999, WARPING MORPHING GRA
   JOHNSTONE JK, 2002, 40 ANN SE ACM C
   KENT JR, 1992, COMP GRAPH, V26, P47, DOI 10.1145/142920.134007
   MALKOVA M, 2008, SIGRAD 2008, V34, P39
   Sederberg T. W., 1993, Computer Graphics Proceedings, P15, DOI 10.1145/166117.166118
   SEDERBERG TW, 1992, COMP GRAPH, V26, P25, DOI 10.1145/142920.134001
   SHAPIRA M, 1995, IEEE COMPUT GRAPH, V15, P44, DOI 10.1109/38.365005
   Surazhsky V., 2003, International Journal of Shape Modeling, V9, P191, DOI 10.1142/S0218654303000115
   Surazhsky V, 2001, ACM T GRAPHIC, V20, P203, DOI 10.1145/502783.502784
NR 13
TC 3
Z9 4
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2010
VL 26
IS 3
BP 205
EP 215
DI 10.1007/s00371-009-0396-3
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 558CW
UT WOS:000274719200004
DA 2024-07-18
ER

PT J
AU Xi, PC
   Shu, C
AF Xi, Pengcheng
   Shu, Chang
TI Consistent parameterization and statistical analysis of human head scans
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Workshop on 3D Physiological Human
CY DEC, 2008
CL Zermatt, SWITZERLAND
DE Consistent parameterization; 3D mesh deformation; Principal component
   analysis; Independent component analysis
ID SPACE
AB Statistical shape analysis of 3-D scanned human heads provides important information for many applications. Nevertheless, special geometry processing techniques have to be developed for consistently parameterizing scans due to the fact that different scanning projects vary in landmark definition, noise control and other factors. For consistent parameterization, fitting a generic model to each scan has proved to be an effective method. In this paper, improved techniques are presented to solve problems in parameterizing different data sets. Principal Component Analysis (PCA) is thus conducted on the consistently parameterized data sets, and shape variances along principal components are demonstrated. In addition, shape variations analyzed by Independent Component Analysis (ICA) are also presented.
C1 [Xi, Pengcheng; Shu, Chang] Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada.
C3 National Research Council Canada
RP Xi, PC (corresponding author), Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada.
EM pengcheng.xi@nrc-cnrc.gc.ca; chang.shu@nrc-cnrc.gc.ca
RI Xi, Pengcheng/N-9404-2019; Xi, Pengcheng/Q-4808-2018
OI Xi, Pengcheng/0000-0003-3236-5234; 
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], 1999, P 2 INT C 3 D DIG IM
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Ben Azouz Z, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P750
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bookstein F.L, 1991, MORPHOMETRIC TOOLS L, DOI [10.1017/CBO9780511573064, DOI 10.1017/CBO9780511573064]
   Cohen-Or D, 1998, ACM T GRAPHIC, V17, P116, DOI 10.1145/274363.274366
   DeCarlo D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P67, DOI 10.1145/280814.280823
   DEKKER L, 1999, P 2 INT C 3 D DIG IM, P388, DOI DOI 10.1109/IM.1999.805369
   Hammond P, 2004, AM J MED GENET A, V126A, P339, DOI 10.1002/ajmg.a.20665
   Hutton TJ, 2003, IEEE T MED IMAGING, V22, P747, DOI 10.1109/TMI.2003.814784
   Kalberer GA, 2002, VISION MODELING, AND VISUALIZATION 2002, PROCEEDINGS, P463
   MARSCHNER SR, 2000, P 11 EUR WORKSH REND, P231
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   RUSS T, 2006, COMPUTER VISION PATT, P1391
   Ruto A., 2006, P ICA RES NETW INT W
   Xi P., 2007, Graphics Interface Conference 2007, P19
NR 18
TC 16
Z9 16
U1 0
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2009
VL 25
IS 9
BP 863
EP 871
DI 10.1007/s00371-009-0316-6
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 478KA
UT WOS:000268585100006
DA 2024-07-18
ER

PT J
AU Eppstein, D
   Goodrich, MT
   Kim, E
   Tamstorf, R
AF Eppstein, David
   Goodrich, Michael T.
   Kim, Ethan
   Tamstorf, Rasmus
TI Approximate topological matching of quad meshes
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Shape Modeling and Applications
CY JUN 04-06, 2008
CL Stony Brook, NY
SP IEEE Comp Soc, VGTC, ACM SIGGRAPH, EUROGRAPHICS, Comp Graph Soc
DE Quad mesh; Topological matching; NP-hard; NP-complete; Lazy-greedy
   heuristic; Isomorphism
ID GRAPH EDIT DISTANCE
AB In this paper, we study the problem of approximate topological matching for quadrilateral meshes, that is, the problem of finding as large a set as possible of matching portions of two quadrilateral meshes. This study is motivated by applications in graphics that involve the modeling of different shapes that have results needing to be merged in order to produce a final unified representation of an object. We show that the problem of producing a maximum approximate topological match of two quad meshes is NP-hard and that its decision version is NP-complete. Given these results, which make an exact solution extremely unlikely, we show that the natural greedy algorithm derived from polynomial-time graph isomorphism can produce poor results, even when it is possible to find matches with only a few nonmatching quads. Nevertheless, we provide a "lazy-greedy" algorithm that is guaranteed to find good matches when mismatching portions of mesh are localized. Finally, we provide empirical evidence that this approach produces good matches between similar quad meshes.
C1 [Eppstein, David; Goodrich, Michael T.] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
   [Kim, Ethan] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada.
   [Tamstorf, Rasmus] Walt Disney Animat Studios, Burbank, CA 91521 USA.
C3 University of California System; University of California Irvine; McGill
   University; Walt Disney Company
RP Goodrich, MT (corresponding author), Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
EM goodrich@acm.org; ethan@cs.mcgill.ca; Rasmus.Tamstorf@disney.com
CR Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   [Anonymous], P 27 ANN ACM S THEOR
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   [Anonymous], 1980, P 12 ANN ACM S THEOR, DOI [DOI 10.1145/800141.804670, 10.1145/800141.804670]
   [Anonymous], 2006, PROC EUROGRAPHICS S
   [Anonymous], 1998, GRAPH DRAWING ALGORI
   [Anonymous], 1974, P 6 ANN ACM S THEORY
   [Anonymous], 2000, Computational Geometry Algorithms and Applications
   Armstrong C. G., 1995, NAFEMS, P415
   BAUMGART B.G., 1972, CSTR72320 STANF U
   Bern M, 2000, INT J COMPUT GEOM AP, V10, P347, DOI 10.1142/S0218195900000206
   Berretti S, 2004, LECT NOTES COMPUT SC, V3115, P464
   BLACKER TD, 1991, INT J NUMER METH ENG, V32, P811, DOI 10.1002/nme.1620320410
   Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3
   Chae S.-W., 1997, Proceedings, 6th International Meshing Roundtable, P281
   COHENOR D, 1999, P 10 IEEE VIS VIS 99, P11
   CORNEIL DG, 1970, J ACM, V17, P51, DOI 10.1145/321556.321562
   DEFRAYSSEIX H, 1988, STOC 88, P426, DOI [10.1145/62212.62254, DOI 10.1145/62212.62254]
   DONG S, 2006, SIGGRAPH 06, P1057
   Eppstein D, 2008, COMPUT GRAPH FORUM, V27, P1477, DOI 10.1111/j.1467-8659.2008.01288.x
   Eppstein D, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P83, DOI 10.1109/SMI.2008.4547954
   ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835
   Ferragina P, 2000, ANN IEEE SYMP FOUND, P390, DOI 10.1109/SFCS.2000.892127
   Garey M.R., 1979, COMPUTERS INTRACTABI
   GROHE M, 2000, STOC 00, P63
   GURNHOLD S, 1998, P 25 C COMP GRAPH IN, P133
   Khodavosky A, 2002, GRAPH MODELS, V64, P147, DOI 10.1006/gmod.2002.0575
   King D, 1999, GITGVU9936
   Marini S, 2005, LECT NOTES COMPUT SC, V3434, P263
   MILLER GL, 1977, STOC 77, P143
   Mohar B., 2001, JH STUD MATH SCI
   MULLERHANNEMANN M, 1997, P 6 INT MESH ROUNDT, P293
   Neuhaus M, 2007, INFORM SCIENCES, V177, P239, DOI 10.1016/j.ins.2006.02.013
   Nowottny D., 1997, Proc. 6th Int. Meshing Roundtable, P309
   Palacios J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276446, 10.1145/1239451.1239506]
   Ray N, 2006, ACM T GRAPHIC, V25, P1460, DOI 10.1145/1183287.1183297
   SCHNYDER W, 1990, PROCEEDINGS OF THE FIRST ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P138
   SCHONFELD T, 1991, NUMERICAL GRID GENERATION IN COMPUTATIONAL FLUID DYNAMICS AND RELATED FIELDS, P743
   SHIMADA K, 1998, P 7 INT MESH ROUNDT, P61
   SMITH BC, 1993, IEEE COMPUT GRAPH, V13, P34, DOI 10.1109/38.232097
   TALBERT JA, 1990, INT J NUMER METH ENG, V29, P1551, DOI 10.1002/nme.1620290712
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   Wood D.R., 2007, New York J. Math., V13, P117
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
NR 45
TC 2
Z9 4
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2009
VL 25
IS 8
BP 771
EP 783
DI 10.1007/s00371-009-0363-z
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 465NI
UT WOS:000267593700005
DA 2024-07-18
ER

PT J
AU Yeo, YI
   Ni, TY
   Myles, A
   Goel, V
   Peters, J
AF Yeo, Young In
   Ni, Tianyun
   Myles, Ashish
   Goel, Vineet
   Peters, Joerg
TI Parallel smoothing of quad meshes
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Shape Modeling and Applications
CY JUN 04-06, 2008
CL Stony Brook, NY
SP IEEE Comp Soc, VGTC, ACM SIGGRAPH, EUROGRAPHICS, Comp Graph Soc
DE Subdivision; GPU; Smooth surface; Quadrilateral mesh
ID SPLINE SURFACES
AB For use in real-time applications, we present a fast algorithm for converting a quad mesh to a smooth, piecewise polynomial surface on the Graphics Processing Unit (GPU). The surface has well-defined normals everywhere and closely mimics the shape of Catmull-Clark subdivision surfaces. It consists of bicubic splines wherever possible, and a new class of patches-c-patches-where a vertex has a valence different from 4. The algorithm fits well into parallel streams so that meshes with 12,000 input quads, of which 60% have one or more non-4-valent vertices, are converted, evaluated and rendered with 9x9 resolution per quad at 50 frames per second. The GPU computations are ordered so that evaluation avoids pixel dropout.
C1 [Yeo, Young In; Ni, Tianyun; Myles, Ashish; Peters, Joerg] Univ Florida, Gainesville, FL 32611 USA.
   [Goel, Vineet] Adv Micro Devices Inc, Sunnyvale, CA 94088 USA.
C3 State University System of Florida; University of Florida; Advanced
   Micro Devices
RP Yeo, YI (corresponding author), Univ Florida, Gainesville, FL 32611 USA.
EM yiyeo@cise.ufl.edu
OI Peters, JORG/0000-0002-2499-1529
CR Bolz J., 2002, WEB3D 02, P11
   BUNNELL M, 2005, GPU GEMS, V2, pCH7
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   Farin G., 1988, Curves and Surfaces for Computer Aided Geometric Design: A Practical Guide
   GONZALEZ C, 1999, ACM S INT 3D GRAPH, P7
   Guthe M, 2005, ACM T GRAPHIC, V24, P1016, DOI 10.1145/1073204.1073305
   Halstead M., 1993, P SIGGRAPH 93, P35
   Lee A, 2000, COMP GRAPH, P85, DOI 10.1145/344779.344829
   Lee M., 2006, NEXT GENERATION GRAP
   Loop C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330519
   Ni T, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P3, DOI 10.1109/SMI.2008.4547938
   NI T, 2008, GPU SMOOTHING QUAD M
   Peters J, 1997, ACM T GRAPHIC, V16, P420, DOI 10.1145/263834.263851
   Peters J, 2000, COMP GRAPH, P255, DOI 10.1145/344779.344908
   Peters J., 2008, 2008421 U FLOR DEP C
   PETERS J, 2001, 2001001 U FLOR DEP C
   Powell M. J. D., 1974, Software for Numerical Mathematics, P253
   Shiue LJ, 2005, ACM T GRAPHIC, V24, P1010, DOI 10.1145/1073204.1073304
   Stam J, 1998, SIGGRAPH 98, P395
   Velho L, 2001, COMPUT AIDED GEOM D, V18, P397, DOI 10.1016/S0167-8396(01)00039-5
   VLACHOS A, 2001, BIANNUAL C SERIES, P159
   ZWART PB, 1973, SIAM J NUMER ANAL, V10, P665, DOI 10.1137/0710058
NR 22
TC 1
Z9 2
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2009
VL 25
IS 8
BP 757
EP 769
DI 10.1007/s00371-009-0365-x
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 465NI
UT WOS:000267593700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Turkay, C
   Koc, E
   Balcisoy, S
AF Turkay, Cagatay
   Koc, Emre
   Balcisoy, Selim
TI An information theoretic approach to camera control for crowded scenes
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Computer Graphics International Conference 2009
CY MAY 26-29, 2009
CL Victoria, CANADA
DE Automatic camera control; Information Theory; Crowds
AB Navigation and monitoring of large and crowded virtual environments is a challenging task and requires intuitive camera control techniques to assist users. In this paper, we present a novel automatic camera control technique providing a scene analysis framework based on information theory. The developed framework contains a probabilistic model of the scene to build entropy and expectancy maps. These maps are utilized to find interest points which represent either characteristic behaviors of the crowd or novel events occurring in the scene. After an interest point is chosen, the camera is updated accordingly to display this point. We tested our model in a crowd simulation environment and it performed successfully. Our method can be integrated into existent camera control modules in computer games, crowd simulations and movie pre-visualization applications.
C1 [Turkay, Cagatay; Koc, Emre; Balcisoy, Selim] Sabanci Univ, Comp Graph Lab, Istanbul, Turkey.
C3 Sabanci University
RP Turkay, C (corresponding author), Sabanci Univ, Comp Graph Lab, Istanbul, Turkey.
EM turkay@su.sabanciuniv.edu; emrekoc@su.sabanciuniv.edu;
   balcisoy@sabanciuniv.edu
RI , Selim/Y-3196-2019; Turkay, Cagatay/AAA-3810-2020
OI Turkay, Cagatay/0000-0001-6788-251X; Balcisoy, Selim/0000-0002-6495-7341
CR [Anonymous], 1997, Information theory and statistics
   ARBEL T, 1999, COMPUT VIS IEEE INT, V1, P248
   BLINN J, 1988, IEEE COMPUT GRAPH, V8, P76, DOI 10.1109/38.7751
   CHRISTIE M, 2006, EUROGRAPHICS 2006 ST
   Cover T. M., 1991, ELEMENTS INFORM THEO
   GLEICHER M, 1992, COMP GRAPH, V26, P331, DOI 10.1145/142920.134088
   He LiWei., 1996, SIGGRAPH, P217
   Itti L, 2005, PROC CVPR IEEE, P631
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji GF, 2006, IEEE T VIS COMPUT GR, V12, P1109, DOI 10.1109/TVCG.2006.137
   KAMADA T, 1988, COMPUT VISION GRAPH, V41, P43, DOI 10.1016/0734-189X(88)90116-8
   Kwon JY, 2008, VISUAL COMPUT, V24, P475, DOI 10.1007/s00371-008-0228-x
   LEE CH, 2005, SIGGRAPH 05, P659, DOI DOI 10.1145/1073204.1073244
   Reynolds C., 2004, Opensteer, steering behaviors for autonomous characters
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shoemake K., 1985, SIGGRAPH COMPUT GRAP, V19, P245, DOI DOI 10.1145/325334.325242
   Singh S, 2004, IEEE T KNOWL DATA EN, V16, P396, DOI 10.1109/TKDE.2004.1269665
   STOEV SL, 2002, VIS 02
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Wolfe Jeremy M, 2010, Curr Biol, V20, pR346, DOI 10.1016/j.cub.2010.02.016
NR 21
TC 6
Z9 7
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2009
VL 25
IS 5-7
BP 451
EP 459
DI 10.1007/s00371-009-0337-1
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 438ES
UT WOS:000265539300009
DA 2024-07-18
ER

PT J
AU Preda, M
   Villegas, P
   Morán, F
   Lafruit, G
   Berretty, RP
AF Preda, Marius
   Villegas, Paulo
   Moran, Franciso
   Lafruit, Gauthier
   Berretty, Robert-Paul
TI A model for adapting 3D graphics based on scalable coding, real-time
   simplification and remote rendering
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds
CY OCT 24-27, 2007
CL Hannover, GERMANY
SP Welfenlab, Gottfried Wilhelm Leibniz Univ, EuroGraphics, ACM SIGWEB, ACM SIGART
DE 3D graphics compression and adaptation; on-line games
ID ADAPTATION
AB Most current multiplayer 3D games can only be played on dedicated platforms, requiring specifically designed content and communication over a predefined network. To overcome these limitations, the OLGA (On-Line GAming) consortium has devised a framework to develop distributive, multiplayer 3D games. Scalability at the level of content, platforms and networks is exploited to achieve the best trade-offs between complexity and quality.
C1 [Preda, Marius] ARTEMIS, TELECOM & Management SudParis, Inst TELECOM, Evry, France.
   [Villegas, Paulo] Telefon I D, Madrid, Spain.
   [Moran, Franciso] Univ Politecn Madrid, Madrid, Spain.
   [Lafruit, Gauthier] Interuniv Microelect Ctr, Leuven, Belgium.
   [Berretty, Robert-Paul] Philips Res, Eindhoven, Netherlands.
C3 IMT - Institut Mines-Telecom; IMT Atlantique; Institut Polytechnique de
   Paris; Telecom SudParis; Institut Mines-Telecom Business School;
   Telefonica SA; Universidad Politecnica de Madrid; Interuniversity
   Microelectronics Centre; Philips; Philips Research
RP Preda, M (corresponding author), ARTEMIS, TELECOM & Management SudParis, Inst TELECOM, Evry, France.
EM Marius.Preda@int-evry.fr; Paulo@tid.es; Francisco.Moran@upm.es;
   Gauthier.Lafruit@imec.be; Robert-Paul.Berretty@philips.com
RI Villegas, Paulo/C-3502-2014; Morán, Francisco/F-2552-2016; Preda,
   Marius/HDM-2040-2022
OI Villegas, Paulo/0000-0001-9293-8052; Morán,
   Francisco/0000-0003-3837-692X; Preda, Marius/0000-0003-2288-0291
CR Avilés M, 2005, LECT NOTES COMPUT SC, V3767, P61
   Berretty RPM, 2006, PROC SPIE, V6055, DOI 10.1117/12.642125
   Garland M., 1997, PROC 24 C COMPUTER G, P209, DOI DOI 10.1145/258734.258849
   Gioia P, 2004, IEEE T CIRC SYST VID, V14, P1009, DOI 10.1109/TCSVT.2004.830672
   *ISO IEC, 1996, JTCISC29WG11AKA IS 2
   *ISO IEC, 2004, JTC1SC29WG11 16
   Martínez JM, 2003, IEEE MULTIMEDIA, V10, P94, DOI 10.1109/MMUL.2003.1237555
   Preda M, 2005, LECT NOTES COMPUT SC, V3767, P49
   PREDA M, 2007, P 12 INT C 3D WEB TE, P181
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Tack N, 2006, IEEE T CONSUM ELECTR, V52, P559, DOI 10.1109/TCE.2006.1649680
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
NR 12
TC 12
Z9 13
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2008
VL 24
IS 10
BP 881
EP 888
DI 10.1007/s00371-008-0284-2
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 347IQ
UT WOS:000259134200004
DA 2024-07-18
ER

PT J
AU Ancuti, C
   Haber, T
   Mertens, T
   Bekaert, P
AF Ancuti, Cosmin
   Haber, Tom
   Mertens, Tom
   Bekaert, Philippe
TI Video enhancement using reference photographs
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 26th International Conference on Computer Graphics
CY JUN 09-11, 2008
CL Istanbul, TURKEY
DE picture/image generation; graphics utilities; applications
AB Digital video cameras are becoming commonplace in many households, but they still leave something to be desired in terms of image quality. Their poor light sensitivity make images noisy and blurry, and internal storage bandwidth limits the frame resolution. We present a technique for enhancing a low quality video sequence, using a set of high quality reference photographs, taken of the same scene. Our technique generates a high quality frame by copying information from the photographs in a patch-wise fashion. The copying is guided by a sparse set of reliable correspondences between the video frames and photographs. Our technique is purely image-based, and does not require depth estimation. A robust descriptor is employed for establishing valid matches between the video frames and the photographs. Then, the geometric transformation is estimated between every corresponding patch. With only a few reference photographs, we are able to reduce noise and motion blur, and more important, increase resolution by a factor of 6 (see Fig. 1).
C1 [Ancuti, Cosmin; Haber, Tom; Mertens, Tom; Bekaert, Philippe] Hasselt Univ tUL IBBT, Expertise Ctr Digital Media, B-3590 Diepenbeek, Belgium.
C3 Hasselt University
RP Ancuti, C (corresponding author), Hasselt Univ tUL IBBT, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM cosmin.ancuti@uhasselt.be; tom.haber@uhasselt.be;
   tom.mertens@uhasselt.be; philippe.bekaert@uhasselt.be
RI Mertens, Thomas M/E-9826-2013
CR ANCUTI C, 2007, C ABSTR APPL ACM SIG
   [Anonymous], 2001, Schooling for Tomorrow
   [Anonymous], P C REND TECHN
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Capel D, 2000, INT C PATT RECOG, P600, DOI 10.1109/ICPR.2000.905409
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   FATTAL R, 2007, ACM T GRAPH SIGGRAPH, V26
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   IRANI M, 1991, J COMPUT VIS GRAPH I, V55, P231
   JIANG Z, 2003, P IEEE COMP VID PATT
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   LIANG L, 2001, P ACM SIGGRAPH 2001
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MIKOLAJCZYK K, 2004, IEEE COMPUT VIS PATT, V30, P257
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Shechtman E, 2005, IEEE T PATTERN ANAL, V27, P531, DOI 10.1109/TPAMI.2005.85
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sun J, 2003, PROC CVPR IEEE, P729
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
NR 27
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2008
VL 24
IS 7-9
BP 709
EP 717
DI 10.1007/s00371-008-0251-y
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 322OI
UT WOS:000257384800026
DA 2024-07-18
ER

PT J
AU Cheng, YM
   Wang, CM
AF Cheng, Yu-Ming
   Wang, Chung-Ming
TI An adaptive steganographic algorithm for 3D polygonal meshes
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 25th Computer Graphics International Conference (CGI)
CY MAY 30-JUN 02, 2007
CL Petropolis, BRAZIL
DE 3D polygonal; meshes; human visual system; steganography
ID WATERMARKING
AB This paper presents a new adaptive digital steganographic technique for three-dimensional (3D) polygonal meshes. It is based on an adaptive substitutive blind procedure in the spatial domain. We use angle features to remove all restrictions of fixed embedding size in each vertex to provide larger embedding capacity and to minimize the distortion by minimum distortion distance estimation. This method exploits the correlation between neighboring polygons with respect to the human visual system to estimate the degree of smoothness or roughness properties. If the vertex is located on a rough surface, then it may tolerate larger position changes by embedding more messages than those on smooth surfaces. Our method provides an easy way to produce a more imperceptible result. In addition, a simple contagious diffusion technique is devoted to improving performance for polygonal meshes traversal. Experimental results show that the proposed technique is adaptive, simple, efficient, general, and secure. This technique has high capacity and low distortion, and it is robust against affine transformations. Our technique provides an adaptive method and has proven feasible in steganography.
C1 Natl Chung Hsing Univ, Inst Comp Sci, Taichung 40227, Taiwan.
C3 National Chung Hsing University
RP Cheng, YM (corresponding author), Natl Chung Hsing Univ, Inst Comp Sci, Taichung 40227, Taiwan.
EM ssmtt.cym@msa.hinet.net; cmwana@cs.nchu.edu.tw
CR [Anonymous], 2000, Digital Watermarking
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   CAYRE F, 2004, 5223 INRIA
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Clarenz U, 2000, IEEE VISUAL, P397, DOI 10.1109/VISUAL.2000.885721
   Cotting D, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P233, DOI 10.1109/SMI.2004.1314510
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   KANAI S, 1998, P 6 IFIP WG 5 2 GEO, P296
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Lin HYS, 2005, IEEE T MULTIMEDIA, V7, P997, DOI 10.1109/TMM.2005.858412
   Maret Y, 2004, P MULT SEC WORKSH, P68
   Ohbuchi R, 1998, IEEE J SEL AREA COMM, V16, P551, DOI 10.1109/49.668977
   Ohbuchi R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P261, DOI 10.1145/266180.266377
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Ohbuchi R., 2001, Graphics Interface, P9
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Praun E, 1999, COMP GRAPH, P49, DOI 10.1145/311535.311540
   Rencher CA., 2002, Methods of Multivariate Analysis, V2nd
   Wagner M. G., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P201, DOI 10.1109/GMAP.2000.838252
   Wang CM, 2006, COMPUT GRAPH-UK, V30, P244, DOI 10.1016/j.cag.2006.01.030
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   ZOLLNER JZ, 1998, P 2 INF HID WORKSH P, P345
NR 25
TC 22
Z9 27
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2007
VL 23
IS 9-11
SI SI
BP 721
EP 732
DI 10.1007/s00371-007-0147-2
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 206UE
UT WOS:000249207600012
DA 2024-07-18
ER

PT J
AU Wecker, L
   Sarnavati, F
   Gavrilova, M
AF Wecker, Lakin
   Sarnavati, Fararnarz
   Gavrilova, Marina
TI Contextual void patching for digital elevation models
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 25th Computer Graphics International Conference (CGI)
CY MAY 30-JUN 02, 2007
CL Petropolis, BRAZIL
DE multiresolution; terrain; void patching; context sensitive
ID IMAGE
AB Digital terrain models can be created by gathering a set of measurements from geometric objects. For various reasons, these models may be incomplete and thus fail to meet the requirements defined by their potential applications. In this work, we develop a novel multiresolution approach to repair the voids commonly found in digital elevation models (DEM). We use the overall shape and structure of the surrounding terrain to build a smooth patch for the void. Then, using a multiresolution approach obtained from reverse Chaikin subdivision, we extract the low-scale characteristics from the surrounding terrain and apply them to the smooth patch. The results demonstrate that our approach is effective in synthesizing models with realistic characteristics.
C1 Univ Calgary, Calgary, AB T2N 1N4, Canada.
C3 University of Calgary
RP Wecker, L (corresponding author), Univ Calgary, 2500 Univ Dr NW, Calgary, AB T2N 1N4, Canada.
EM weekerl@cpsc.ucalgary.ca; samavati@cpsc.ucalgary.ca;
   marina@cpsc.ucalgary.ca
RI Gavrilova, Marina/AHD-3605-2022
OI Gavrilova, Marina/0000-0002-5338-1834
CR [Anonymous], 1987, An Introduction to Splines for use in Computer Graphics Geometric Modeling
   [Anonymous], 2001, Schooling for Tomorrow
   [Anonymous], Shuttle Radar Topography Mission
   BAREQUET G, 1995, COMPUT AIDED GEOM D, V12, P207, DOI 10.1016/0167-8396(94)00011-G
   Bartels RH, 2000, J COMPUT APPL MATH, V119, P29, DOI 10.1016/S0377-0427(00)00370-8
   BONET JSD, 1997, COMPUTER GRAPHICS, P361
   BROSZ J, 2005, THESIS U CALGARY CAL
   BROSZ J, 2006, INT C COMP GRAPH THE, P122
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265
   Davis J, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P428, DOI 10.1109/TDPVT.2002.1024098
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   FOURNIER A, 1982, COMMUN ACM, V25, P371, DOI 10.1145/358523.358553
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Li BR, 2005, INT C COMP AID DES C, P531
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   Liepa P., 2003, Symposium on Geometry Processing, P200
   SAMAVATI FF, 2006, SYNTHESIS ANAL BIOME
   Sharf A, 2004, ACM T GRAPHIC, V23, P878, DOI 10.1145/1015706.1015814
   STOLLINITZ EJ, 1996, WAVELETS COMPUTER GR
   VERDERA J, 2003, P INT C IM PROC ICIP, V2
   VERDERA J, 2003, P INT C IM PROC ICIP, V3
   WECKER L, 2007, THESIS U CALGARY CAL
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Zelinka S, 2004, ACM T GRAPHIC, V23, P930, DOI 10.1145/1027411.1027413
NR 27
TC 7
Z9 11
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2007
VL 23
IS 9-11
SI SI
BP 881
EP 890
DI 10.1007/s00371-007-0148-1
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 206UE
UT WOS:000249207600028
DA 2024-07-18
ER

PT J
AU Chisnall, D
   Chen, M
   Hansen, C
AF Chisnall, David
   Chen, Min
   Hansen, Charles
TI Ray-driven dynamic working set rendering - For complex volume scene
   graphs involving large point clouds
SO VISUAL COMPUTER
LA English
DT Article
DE out-of-core; pctree; point-based graphics; ray tracing; volume scene
   graph
AB Ray tracing a volume scene graph composed of multiple point-based volume objects (PBVO) can produce high quality images with effects such as shadows and constructive operations. A naive approach, however, would demand an overwhelming amount of memory to accommodate all point datasets and their associated control structures such as octrees. This paper describes an out-of-core approach for rendering such a scene graph in a scalable manner. In order to address the difficulty in pre-determining the order of data caching, we introduce a technique based on a dynamic, in-core working set. We present a ray-driven algorithm for predicting the working set automatically. This allows both the data and the control structures required for ray tracing to be dynamically pre-fetched according to access patterns determined based on captured knowledge of ray-data intersection. We have conducted a series of experiments on the scalability of the technique using working sets and datasets of different sizes. With the aid of both qualitative and quantitative analysis, we demonstrate that this approach allows the rendering of multiple large PBVOs in a volume scene graph to be performed on desktop computers.
C1 Univ Coll Swansea, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
   Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
C3 Swansea University; Utah System of Higher Education; University of Utah
RP Chisnall, D (corresponding author), Univ Coll Swansea, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
EM csdavec@swansea.ac.uk; m.chen@swansea.ac.uk; hansen@cs.utah.edu
OI Chisnall, David/0000-0001-6060-0153
FU EPSRC [EP/D059674/1] Funding Source: UKRI
CR Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Bloomenthal J., 1988, Computer-Aided Geometric Design, V5, P341, DOI 10.1016/0167-8396(88)90013-1
   Chen M, 2000, COMPUT GRAPH FORUM, V19, P281, DOI 10.1111/1467-8659.00464
   CHEN M, 2005, P VOL GRAPH NEW YORK, P127
   Chiang YJ, 1998, VISUALIZATION '98, PROCEEDINGS, P167, DOI 10.1109/VISUAL.1998.745299
   Chiang YJ, 1997, VISUALIZATION '97 - PROCEEDINGS, P293, DOI 10.1109/VISUAL.1997.663895
   CHIANG YJ, 2003, P IEEE S PAR VIS GRA, P59
   Cignoni P, 1996, 1996 SYMPOSIUM ON VOLUME VISUALIZATION, PROCEEDINGS, P31, DOI 10.1109/SVV.1996.558040
   Crawfis R. A., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P261, DOI 10.1109/VISUAL.1993.398877
   DENNING PJ, 1968, COMMUN ACM, V11, P323, DOI 10.1145/363095.363141
   Farias R, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.933523
   GROSS M, 2005, KEYN SPEECH IEEE VIS
   Grossman J. P., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P181
   Hua J, 2004, IEEE T VIS COMPUT GR, V10, P574, DOI 10.1109/TVCG.2004.28
   Kalra D., 1989, Computer Graphics, V23, P297, DOI 10.1145/74334.74364
   KURE T, 2001, IEEE COMPUT GRAPH, V21, P24
   LEUTENEGGER P, 1999, DIMACS BOOK SERIES, V50
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Lindstrom P, 2002, IEEE T VIS COMPUT GR, V8, P239, DOI 10.1109/TVCG.2002.1021577
   Lindstrom P, 2000, COMP GRAPH, P259, DOI 10.1145/344779.344912
   Livnat Y, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P457, DOI 10.1109/VISUAL.2004.52
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Mueller K, 1996, IEEE VISUAL, P65, DOI 10.1109/VISUAL.1996.567608
   NIELSON GM, 1993, IEEE COMPUT GRAPH, V13, P60, DOI 10.1109/38.180119
   NISHIMURA H, 1985, COMPUT GRAPH J D, V68
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   PHARR M, 2007, COMPUTER GRAPHICS, P101
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Schaufler G, 2000, SPRING COMP SCI, P319
   Shen H.-W., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P371, DOI 10.1109/VISUAL.1999.809910
   Stamminger M, 2001, SPRING EUROGRAP, P151
   Sutton PM, 2000, IEEE T VIS COMPUT GR, V6, P98, DOI 10.1109/2945.856992
   Teller S., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P443, DOI 10.1145/192161.192279
   Ueng SK, 1997, IEEE T VIS COMPUT GR, V3, P370, DOI 10.1109/2945.646239
   Vitter JS, 2001, ACM COMPUT SURV, V33, P209, DOI 10.1145/384192.384193
   von Rymon-Lipinski B, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P441, DOI 10.1109/VISUAL.2004.29
   Wald I., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P9, DOI 10.1109/PBG.2005.194058
   Wald I, 2005, IEEE T VIS COMPUT GR, V11, P562, DOI 10.1109/TVCG.2005.79
   Westover L., 1990, Computer Graphics, V24, P367, DOI 10.1145/97880.97919
   Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346
   Zwicker M, 2001, IEEE VISUAL, P29, DOI 10.1109/VISUAL.2001.964490
NR 43
TC 1
Z9 2
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2007
VL 23
IS 3
BP 167
EP 179
DI 10.1007/s00371-006-0091-6
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 134PM
UT WOS:000244095300002
DA 2024-07-18
ER

PT J
AU Keng, SL
   Lee, WY
   Chuang, JH
AF Keng, Shih-Ling
   Lee, Wang-Yeh
   Chuang, Jung-Hong
TI An efficient caching-based rendering of translucent materials
SO VISUAL COMPUTER
LA English
DT Article
DE subsurface scattering; BSSRDF; light transport; diffusion theory;
   realistic image synthesis
ID MODEL
AB This paper presents an efficient caching-based rendering technique for translucent materials. The proposed caching scheme, inspired by the irradiance caching method, is integrated into a hierarchical rendering technique for translucent materials. We propose a split-disk model to determine the cache distribution and derive the subsurface illuminance gradient used for interpolation by reformulating the equation of dipole diffusion approximation as a 3D convolution process. Our experiments show that only a few caches are required to interpolate the entire image, while the visual difference is negligible. The speedup could be achieved up to one order of magnitude.
C1 Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lee, WY (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM kensl@csie.nctu.edu.tw; wylee@csie.nctu.edu.tw;
   jhchuang@csie.nctu.edu.tw
CR CARR N, 2003, GRAPHICS HARDWARE 20, P51
   CHIRSTENSEN PH, 2003, SIGGRAPH 2003
   Dachsbacher C., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P197
   Dorsey J, 1999, COMP GRAPH, P225, DOI 10.1145/311535.311560
   FARRELL TJ, 1992, MED PHYS, V19, P879, DOI 10.1118/1.596777
   Hanrahan P., 1993, Computer Graphics Proceedings, P165, DOI 10.1145/166117.166139
   HAO X, 2003, 2003 ACM S INT 3D GR, P75
   Hao XJ, 2004, ACM T GRAPHIC, V23, P120, DOI 10.1145/990002.990004
   Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319
   Jensen HW, 2002, ACM T GRAPHIC, V21, P576, DOI 10.1145/566570.566619
   Lensch HPA, 2003, COMPUT GRAPH FORUM, V22, P195, DOI 10.1111/1467-8659.00660
   Mertens T., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P130
   Pharr M, 2000, COMP GRAPH, P75, DOI 10.1145/344779.344824
   Stam J, 1995, SPRING COMP SCI, P41
   TURK G, 1992, COMPUTER GRAPHICS P, V26
   WARD GJ, 1988, COMPUTER GRAPHICS P, V22
   WARD GJ, 1992, 3 EUR WORKSH REND BR, P85
NR 17
TC 5
Z9 7
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2007
VL 23
IS 1
BP 59
EP 69
DI 10.1007/s00371-006-0082-7
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 113RB
UT WOS:000242613900006
DA 2024-07-18
ER

PT J
AU Plantinga, S
   Vegter, G
AF Plantinga, Simon
   Vegter, Gert
TI Isotopic meshing of implicit surfaces
SO VISUAL COMPUTER
LA English
DT Article
DE implicit surfaces; approximation; isotopy; meshing
AB Implicit surfaces are given as the zero set of a function F : R-3 --> R. Although several algorithms exist for generating piecewise linear approximations, most of these are based on a user-defined stepsize or bounds to indicate the precision, and therefore cannot guarantee topological correctness. Interval arithmetic provides a mechanism to determine global properties of the implicit function. In this paper we present an algorithm that uses these properties to generate a piecewise linear approximation of implicit curves and surfaces, that is isotopic to the curve or surface itself. The algorithm is simple and fast, and is among the first to guarantee isotopy for implicit surface meshing.
C1 Univ Groningen, Groningen, Netherlands.
C3 University of Groningen
RP Plantinga, S (corresponding author), Univ Groningen, Groningen, Netherlands.
EM simon@cs.rug.nl; gert@cs.rug.nl
CR Akkouche S, 2001, COMPUT GRAPH FORUM, V20, P67, DOI 10.1111/1467-8659.00479
   ALBERTI L, 2005, MATH METHODS CURVES, P11
   Bloomenthal J., 1988, Computer-Aided Geometric Design, V5, P341, DOI 10.1016/0167-8396(88)90013-1
   Boissonnat JD, 2005, GRAPH MODELS, V67, P405, DOI 10.1016/j.gmod.2005.01.004
   BOISSONNAT JD, 2006, SCG 06, P337
   BOTTINO A, 1996, P IMPL SURF, P55
   Bremer David., 1998, Implicit Surfaces, P155
   CHENG S.-W., 2004, SCG 04, P280
   Chernyaev E.V., 1995, 9517 CERN CN
   Hartmann K, 1998, Eur J Med Res, V3, P95
   LERCH M, 2005, FILIB INTERVAL LIB
   Lopes H, 2002, COMPUT GRAPH-UK, V26, P841, DOI 10.1016/S0097-8493(02)00173-5
   LORENSEN WE, 1987, P 14 ANN C COMP GRAP, P163, DOI DOI 10.1145/3740137422
   Plantinga S., 2004, SGP 04 EUROGRAPHICSA, P245, DOI DOI 10.1145/1057432.1057465
   Plantinga Simon., 2003, SM'03: Proceedings of the eighth ACM symposium on Solid modeling and applications, P23
   SNYDER JM, 1992, COMP GRAPH, V26, P121, DOI 10.1145/142920.134024
   Stander BT, 1997, Proc. SIGGRAPH, P279, DOI DOI 10.1145/258734.258868
   VANOVERVELD CWA, 1993, 9351419 U CALG
   [No title captured]
NR 19
TC 20
Z9 22
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2007
VL 23
IS 1
BP 45
EP 58
DI 10.1007/s00371-006-0083-6
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 113RB
UT WOS:000242613900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, R
   Zhou, K
   Snyder, J
   Liu, XG
   Bao, HJ
   Peng, QS
   Guo, BN
AF Wang, Rui
   Zhou, Kun
   Snyder, John
   Liu, Xinguo
   Bao, Hujun
   Peng, Qunsheng
   Guo, Baining
TI Variational sphere set approximation for solid objects
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 14th Pacific Conference on Computer Graphics and Applications
CY OCT 11-13, 2005
CL Taipei, TAIWAN
DE variational approximation; solid objects; shadow; collision detection
ID COLLISION DETECTION; TREE
AB We approximate a solid object represented as a triangle mesh by a bounding set of spheres having minimal summed volume outside the object. We show how outside volume for a single sphere can be computed using a simple integration over the object's triangles. We then minimize the total outside volume over all spheres in the set using a variant of iterative Lloyd clustering that splits the mesh points into sets and bounds each with an outside volume-minimizing sphere. The resulting sphere sets are tighter than those of previous methods. In experiments comparing against a state-of-the-art alternative (adaptive medial axis), our method often requires half as many spheres, or fewer, to obtain the same error, under a variety of error metrics including total outside volume, shadowing fidelity, and proximity measurement.
C1 Microsoft Res Asia, Graph Grp, Beijing, Peoples R China.
   Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   Microsoft Res, Redmond, WA USA.
C3 Microsoft; Microsoft Research Asia; Zhejiang University; Microsoft
RP Zhou, K (corresponding author), Microsoft Res Asia, Graph Grp, Beijing, Peoples R China.
EM rwang@cad.zju.edu.cn; kunzhou@microsoft.com; johnsny@microsoft.com;
   xgliu@cad.zju.edu.cn; bao@cad.zju.edu.cn; peng@cad.zju.edu.cn;
   bainguo@microsoft.com
RI Zhou, Kun/AAH-9290-2019; Zhou, Kun/ABF-4071-2020
OI Zhou, Kun/0000-0003-2320-3655
CR Amenta Nina, 2001, P 6 ACM S SOL MOD AP
   [Anonymous], 1995, P 11 ANN S COMP GEOM
   [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   Bradshaw G, 2004, ACM T GRAPHIC, V23, P1, DOI 10.1145/966131.966132
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   HUBBARD P, 1993, P 1993 IEEE S RES FR, V14, P24
   Hubbard PM, 1996, ACM T GRAPHIC, V15, P179, DOI 10.1145/231731.231732
   HUBBARD PM, 1995, THESIS BROWN U
   James DL, 2004, ACM T GRAPHIC, V23, P393, DOI 10.1145/1015706.1015735
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   KRISHNAN S, 1998, P 1998 WORKSH ALG FE, P121
   LIU Y, 1988, P IEEE INT WORKSH IN, P801
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   QUINLAN S, 1994, IEEE INT CONF ROBOT, P3324, DOI 10.1109/ROBOT.1994.351059
   Ren Z, 2006, ACM T GRAPHIC, V25, P977, DOI 10.1145/1141911.1141982
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Ruspini D. C., 1997, ANN C COMP GRAPH INT, P345, DOI DOI 10.1145/258734.258878
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Tam RC, 1998, VISUAL COMPUT, V14, P401, DOI 10.1007/s003710050151
   TAO J, 2005, ACM T GRAPHIC, V24, P561
   Turk G., 1990, GRAPHICS GEMS GENERA, P24
   Wu JH, 2005, COMPUT GRAPH FORUM, V24, P277, DOI 10.1111/j.1467-8659.2005.00852.x
NR 24
TC 31
Z9 39
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2006
VL 22
IS 9-11
BP 612
EP 621
DI 10.1007/s00371-006-0052-0
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 082IW
UT WOS:000240381000004
DA 2024-07-18
ER

PT J
AU Hu, GF
   Peng, QS
   Forrest, AR
AF Hu, GF
   Peng, QS
   Forrest, AR
TI Mean shift denoising of point-sampled surfaces
SO VISUAL COMPUTER
LA English
DT Article
DE point-sampled surface; denoising; mean shift filter; PCA; surface
   variation
ID DIFFUSION
AB This paper presents an anisotropic denoising/smoothing algorithm for point-sampled surfaces. Motivated by the impressive results of mean shift filtering on image denoising, we extend the concept to 3D surface smoothing by taking the vertex normal and the curvature as the range component and the vertex position as the spatial component. Then the local mode of each vertex on point-based surfaces is computed by a 3D mean shift procedure dependent on local neighborhoods that are adaptively obtained by a kdtree data structure. Clustering pieces of point-based surfaces of similar local mode provides a meaningful model segmentation. Based on the adaptively clustered neighbors, we finally apply a trilateral point filtering scheme that adjusts the position of sample points along their normal directions to successfully reduce noise from point-sampled surfaces while preserving geometric features.
C1 Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
   Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.
C3 Zhejiang University; University of East Anglia
RP GE Global Res, 1800 CaiLun Rd,Zhangjiang HiTech Pk, Shanghai 201203, Peoples R China.
EM guofei.hu@ge.com
CR Alexa M, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P51, DOI 10.1109/SMI.2002.1003528
   Alexander M, 2001, INTERNETWEEK, P21
   Amenta N, 2004, ACM T GRAPHIC, V23, P264, DOI 10.1145/1015706.1015713
   Bajaj CL, 2003, ACM T GRAPHIC, V22, P4, DOI 10.1145/588272.588276
   Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   CHOUDHURY P, 2003, P EUR S REND, P186
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Clarenz U, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P600, DOI 10.1109/CGI.2004.1309272
   Clarenz U, 2000, IEEE VISUAL, P397, DOI 10.1109/VISUAL.2000.885721
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Hoppe Hugues, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011
   HU G, 2005, INT C COMP SCI ITS A, P758
   HU G, 2004, J SOFTWARE, V15, P215
   Hu GF, 2004, J COMPUT SCI TECH-CH, V19, P521, DOI 10.1007/BF02944753
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Lange C, 2005, COMPUT AIDED GEOM D, V22, P680, DOI 10.1016/j.cagd.2005.06.010
   Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Pauly M, 2001, COMP GRAPH, P379, DOI 10.1145/383259.383301
   Peng JB, 2001, IEEE VISUAL, P107
   Pinkall U., 1993, Exp. Math., V2, P15, DOI 10.1080/10586458.1993.10504266
   Taubin G., 1995, P 22 ANN C COMP GRAP, P351, DOI DOI 10.1145/218380.218473
   Vollmer J, 1999, COMPUT GRAPH FORUM, V18, pC131, DOI 10.1111/1467-8659.00334
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Welch W., 1994, COMPUT GRAPH, V28, P247
NR 30
TC 29
Z9 38
U1 1
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2006
VL 22
IS 3
BP 147
EP 157
DI 10.1007/s00371-006-0372-0
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 028UP
UT WOS:000236514600001
DA 2024-07-18
ER

PT J
AU Magnenat-Thalmann, N
   Thalmann, D
AF Magnenat-Thalmann, N
   Thalmann, D
TI Virtual humans: thirty years of research, what next?
SO VISUAL COMPUTER
LA English
DT Article
DE Virtual Human; motion modeling; crowd modeling; cloth and hair
   simulation; believable behavior
ID ACTORS
AB In this paper, we present research results and future challenges in creating realistic and believable Virtual Humans. To realize these modeling goals, real-time realistic representation is essential, but we also need interactive and perceptive Virtual Humans to populate the Virtual Worlds. Three levels of modeling should be considered to create these believable Virtual Humans: 1) realistic appearance modeling, 2) realistic, smooth and flexible motion modeling, and 3) realistic high-level behaviors modeling. At first, the issues of creating virtual humans with better skeleton and realistic deformable bodies are illustrated. To give a level of believable behavior, challenges are laid on generating on the fly flexible motion and complex behaviours of Virtual Humans inside their environments using a realistic perception of the environment. Interactivity and group behaviours are also important parameters to create believable Virtual Humans which have challenges in creating believable relationship between real and virtual humans based on emotion and personality, and simulating realistic and believable behaviors of groups and crowds. Finally, issues in generating realistic virtual clothed and haired people are presented.
C1 Univ Geneva, MIRALab, Geneva, Switzerland.
   Ecole Polytech Fed Lausanne, Vrlab, CH-1015 Lausanne, Switzerland.
C3 University of Geneva; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne
RP Univ Geneva, MIRALab, Geneva, Switzerland.
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Daniel/A-4347-2008; Thalmann,
   Nadia/AAK-5195-2021
OI Thalmann, Daniel/0000-0002-0451-7491; Thalmann,
   Nadia/0000-0002-1459-5960
CR ANDERSON M, 2003, P ACM S COMP AN
   ANDRE E, 1999, P INT WORKSH AFF INT
   ANJYO K, 1992, COMP GRAPH, V26, P111, DOI 10.1145/142920.134021
   [Anonymous], P 1 INT JOINT C AUT
   [Anonymous], P SIGGRAPH 95
   [Anonymous], BRAZIL
   [Anonymous], 1990, Handbook of personality: Theory and research
   [Anonymous], P 22 ANN C COMP GRAP
   [Anonymous], 1991, MUSIC LANGUAGE SPEEC
   Aubel A, 2004, J COMPUT SCI TECH-CH, V19, P585, DOI 10.1007/BF02945584
   Aubel A, 2000, IEEE T CIRC SYST VID, V10, P207, DOI 10.1109/76.825720
   AUBEL A, 2001, P COMP AN SEOUL KOR
   BADLER NN, 1997, IEEE WORKSH NONR ART
   BALL G, 1998, P WORKSH EMB CONV CH, P83
   BARFF D, 1998, P ACM SIGGRAPH 1998, P43
   Berthoz Alain., 2002, The Brain's Sense of Movement
   Bindiganavale R, 1998, LECT NOTES ARTIF INT, V1537, P70
   BOULIC R, VISUAL COMPUTER, V6, P344
   BOULIC R, 1995, P EUROGRAPHICS 95, P337
   Bouvier E., 1996, proc: Eurographics Workshop on Virtual Environments and Scientific Visualization'96, P104
   BRAND M, 2000, P SIGGRAPH 00 NEW OR
   Breen D. E., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P365, DOI 10.1145/192161.192259
   Brogan DC, 1997, AUTON ROBOT, V4, P137, DOI 10.1023/A:1008867321648
   Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421
   CARIGNAN M, 1992, COMP GRAPH, V26, P99, DOI 10.1145/142920.134017
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Chittaro L, 2004, COMPUT ANIMAT VIRT W, V15, P319, DOI 10.1002/cav.35
   Conde T, 2004, COMPUT ANIMAT VIRT W, V15, P311, DOI 10.1002/cav.34
   CORDIER F, 2002, COMPUTER GRAPHICS FO, V21
   Costa P. T., 1992, PSYCHOL ASSESSMENT, V4, P5, DOI DOI 10.1037/1040-3590.4.1.5
   CREMER J, 1995, ACM T MODEL COMPUT S, V5, P42
   Daldegan A., 1993, Computer Graphics Forum, V12, pC211, DOI 10.1111/1467-8659.1230211
   DAVIDSON RJ, 1990, J PERS SOC PSYCHOL, V58, P330, DOI 10.1037/0022-3514.58.2.330
   Eberhardt B, 2000, SPRING COMP SCI, P137
   EBERHARDT B, 1996, COMPUTER GRAPHICS TE, P52
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   EGGES A, 2004, CAPTECH WORKSH ZERM, P13
   Eischen JW, 1996, IEEE COMPUT GRAPH, V16, P71, DOI 10.1109/38.536277
   Ekman P., 1984, APPROACHES EMOTION, V3, P319, DOI DOI 10.1017/CBO9781107415324.004
   Elfes A, 1990, 6 C UNC AI
   ELNASR M, 1999, P AUT AG 99
   Glardon P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P292, DOI 10.1109/CGI.2004.1309224
   GLEICHER M, 1998, SIGGRAPH 98 C P ANN
   GRZESCZCUK R, 1998, SIGGRAPH 98 C P ANN
   HADAP S, 1999, IEEE VISUALIZATION 9, P175
   HADAP S, 2001, COMPUTER GRAPHICS FO, V20
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HENNE M, 1990, THESIS U CALIFORNIA
   ISLA D, 2002, P INT JOINT C AUT AG
   JAMES DL, 2003, ACM T GRAPHIC, V22, P165
   JEHEE L, P SIGGRAPH 99 HELD L, P39
   JOHNS M, 2001, 10 C COMP GEN FORC
   Johnson W. L., 1997, SIGART Bulletin, V8, P16
   KALLMANN M, 1991, P COMP AN 99
   KALRA D, 1992, P EUR 92, P45
   Kang YM, 2002, COMP ANIM CONF PROC, P203, DOI 10.1109/CA.2002.1017538
   Kuffner JJ, 1999, COMP ANIM CONF PROC, P118, DOI 10.1109/CA.1999.781205
   LeDoux J.E., 1986, Mind and Brain: Dialogues in Cognitive Neuroscience
   LEE DW, 2000, P INT WORKSH HUM MOD, P11
   LEVISON L, 1996, THESIS U PENNSYLVANI
   LIN M, 1998, P IMA C MATH SURF, P33
   MAGNENATTHALMANN N, 1987, IEEE COMPUT GRAPH, V7, P9, DOI 10.1109/MCG.1987.276934
   MAGNETANTTHALMA.N, 2004, IN PRESS J COMPUT SC, V19
   MAGNETATHALMAN D, 2004, HDB VIRTUAL HUMANS
   McPhail C., 1992, Social Science Computer Review, V10, P1, DOI 10.1177/089443939201000101
   McPhail Clark., 1991, MYTH MADDENING CROWD
   Nedel LP, 2000, VISUAL COMPUT, V16, P306, DOI 10.1007/PL00007212
   Ng HN, 1995, LECT NOTES COMPUT SC, V1024, P124
   NOSER H, 1995, COMPUT GRAPH, V19, P7, DOI 10.1016/0097-8493(94)00117-H
   Ortony A., 1988, COGNITIVE STRUCTURE
   Papagiannakis G, 2005, COMPUT ANIMAT VIRT W, V16, P11, DOI 10.1002/cav.53
   PARKE FI, 1974, UTECSCS7504
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2650, P300
   POPOVIC Z, 2000, P SIGGRAPH 99 LOS AN, P11
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   ROSENBERG PS, 1993, SOAR PAPERS RES ARTI
   Rosenblum R. E., 1991, Journal of Visualization and Computer Animation, V2, P141, DOI 10.1002/vis.4340020410
   Scheepers F., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P163, DOI 10.1145/258734.258827
   SEO H, 2000, P DEF 2000, P120
   Shah JJ, 1995, Parametric and feature-based CAD/CAM: concepts, techniques, and applications
   SMID C, 2004, CASA 2004 17 INT C C, P259
   Still G., 2000, THESIS WARWICK U
   Tecchia F, 2000, SPRING COMP SCI, P83
   THALMANN D, 1996, COMP GRAPH INT 96 PO
   TU X, 1994, ACM COMP GRAPH P SIG
   Ulicny B, 2002, COMPUT GRAPH FORUM, V21, P767, DOI 10.1111/1467-8659.00634
   ULICNY B, 2001, P EUR WORKSH AN SIM
   Ulicny Branislav, 2004, SCA'04'- Proc. of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P243, DOI [DOI 10.2312/SCA/SCA04/243-252, 10.1145/1028523.1028555, DOI 10.1145/1028523.1028555]
   Volino P, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P109, DOI 10.1109/VSMM.1997.622337
   Volino P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P137, DOI 10.1145/218380.218432
   WEIL J, 1986, COMPUTER GRAPHICS, V24, P243
   Wilhelms J, 1997, IEEE COMPUT GRAPH, V17, P22, DOI 10.1109/38.586015
   Yoshimoto S., 1992, Journal of Visualization and Computer Animation, V3, P85, DOI 10.1002/vis.4340030204
NR 94
TC 40
Z9 46
U1 0
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2005
VL 21
IS 12
BP 997
EP 1015
DI 10.1007/s00371-005-0363-6
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 996AB
UT WOS:000234145700006
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Penta, SK
   Narayanan, PJ
AF Penta, SK
   Narayanan, PJ
TI Compression of multiple depth maps for IBR
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 13th Pacific Conference on Computer Graphics and Applications
CY OCT 12-14, 2005
CL Macao, PEOPLES R CHINA
DE image-based rendering; depth map; data compression
AB Image-based rendering techniques include those with geometry and those without. Geometric information in the form of a depth map aligned with the image holds a lot of promise for IBR due to the several methods available to capture it. It can improve the quality of generated views using a limited number of views. Compression of light fields or multiple images has attracted a lot of attention in the past. Compression of multiple depth maps of the same scene has not been explored much in the literature. We propose a method for compressing multiple depth maps in this paper using geometric proxy. Different quality of rendering and compression ratio can be achieved by varying different parameters. Experiments show the effectiveness of the compression technique on several model data.
C1 Int Inst Informat Technol, Ctr Visual Informat Technol, Hyderabad 500019, Andhra Pradesh, India.
C3 International Institute of Information Technology Hyderabad
RP Int Inst Informat Technol, Ctr Visual Informat Technol, Hyderabad 500019, Andhra Pradesh, India.
EM sashikumar@iiit.ac.in; pjn@iiit.ac.in
OI Narayanan, P J/0000-0002-7164-4917
CR Adelson Edward H, 1991, PLENOPTIC FUNCTION E
   [Anonymous], 1987, SIGGRAPH
   [Anonymous], SIGGRAPH
   [Anonymous], MSTRTR9709
   [Anonymous], SIGGRAPH
   BAKER H, 2002, INT WORKSH IMM TEL I
   Buehler C., 2001, SIGGRAPH
   Curless Brian, 1996, SIGGRAPH
   GIROD B, 2003, ICASSP
   Gortler Steven J, 1996, P ACM SIGGRAPH
   GOTZ D, 2002, MULTIMEDIA 02, P67
   HECKBERT PS, 1997, CMUCS95194
   IHM I, 1997, PACIFIC GRAPHICS
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   KRISHNAMURTHY R, 2001, INT C IM PROC
   Levoy Marc, 1996, SIGGRAPH
   Magnor M, 2001, PROC SPIE, V4310, P263
   Mark W. R., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P7, DOI 10.1145/253284.253292
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   McMillan Leonard, 1995, SIGGRAPH
   NARAYANAN PJ, 1998, P INT C COMP VIS
   NARAYANAN PJ, 2004, ICVGIP
   Seitz S.M., 1996, SIGGRAPH
   Shum Harry., 1999, SIGGRAPH
   Shum HY, 2004, ACM T GRAPHIC, V23, P143, DOI 10.1145/990002.990005
   Shum HY, 2003, IEEE T CIRC SYST VID, V13, P1020, DOI 10.1109/TCSVT.2003.817360
   TONG X, 2000, ICASSP IST TURK 9 JU
   Towles H., 2002, INT WORKSH IMM TEL J
   Wilson Andrew, 2001, PROC 9 ACM INT C MUL, P348
   YU J, 2002, PACIFIC GRAPHICS
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 31
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2005
VL 21
IS 8-10
SI SI
BP 611
EP 618
DI 10.1007/s00371-005-0337-8
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 964CX
UT WOS:000231857400013
DA 2024-07-18
ER

PT J
AU Seidel, HP
AF Seidel, HP
TI Computer graphics - more than beautiful images
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 13th Pacific Conference on Computer Graphics and Applications
CY OCT 12-14, 2005
CL Macao, PEOPLES R CHINA
AB Computers are being used more and more to model, simulate and render parts of the real or an imaginary world, and due to the importance of visual information for humans, computer graphics is at the very core of the technologies enabling the modern information society. New and emerging technologies such as multimedia, digital television, telecommunication and telepresence, virtual reality, or 3D Internet further indicate the tremendous potential of computer graphics in the years to come. Typical for the field is the coincidence of very large data sets with the demand for fast (if possible interactive) high-quality visual display of the results. Furthermore, the user should be able to interact with the environment in a natural and intuitive way.
C1 MPI Informat, Saarbrucken, Germany.
C3 Max Planck Society
RP Seidel, HP (corresponding author), MPI Informat, Saarbrucken, Germany.
EM hpseidel@mpi-sb.mpg.de
NR 0
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING STREET, NEW YORK, NY 10013 USA
SN 0178-2789
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2005
VL 21
IS 8-10
SI SI
BP 520
EP 521
DI 10.1007/s00371-005-0348-5
PG 2
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 964CX
UT WOS:000231857400003
DA 2024-07-18
ER

PT J
AU Yuan, XR
   Zhang, N
   Nguyen, MX
   Chen, BQ
AF Yuan, XR
   Zhang, N
   Nguyen, MX
   Chen, BQ
TI Volume cutout
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 13th Pacific Conference on Computer Graphics and Applications
CY OCT 12-14, 2005
CL Macao, PEOPLES R CHINA
DE segmentation; volume editing; visualization; volume rendering;
   interaction
AB We present a novel method for cutting out 3D volumetric structures based on simple strokes that are drawn directly on volume rendered images. The freehand strokes roughly mark out objects of interest and background. Our system then automatically segments the regions of interest and refines their boundaries in the rendered image. These 2D segmentation results provide constraints for 3D segmentation in the volume dataset. The objects of interest are then efficiently cut out from the volume via a combination of our novel two-pass graph cuts algorithm and the pre-computed over-segmentation. Our method improves traditional, fully automatic segmentation by involving human users in the process, yet minimizing user input and providing timely feedback. Our experiments show that our method extracts volumetric structures precisely and efficiently while requiring little skill or effort from the user.
C1 Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55414 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Univ Minnesota, Dept Comp Sci & Engn, 4-192 EE-CS Bldg,200 Union St SE, Minneapolis, MN 55414 USA.
EM xyuan@cs.umn.edu; nanzhang@cs.umn.edu; mnguyen@cs.umn.edu;
   baoquan@cs.umn.edu
RI Yuan, Xiaoru/E-1798-2013
OI Yuan, Xiaoru/0000-0002-7233-980X
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   [Anonymous], 2005, PROC S INTERACTIVE 3
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   EESE L, 1999, THESIS B YOUNG U PRO
   Fairfield J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P712, DOI 10.1109/ICPR.1990.118200
   Fujita I., 1999, P INT SORPT HEAT PUM, P367
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Hadwiger M, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P301, DOI 10.1109/VISUAL.2003.1250386
   Hastreiter P, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P78, DOI 10.1109/CGI.1998.694253
   Hauser H, 2001, IEEE T VIS COMPUT GR, V7, P242, DOI 10.1109/2945.942692
   HE T, 1997, P IEEE VISUALIZATIO, P227
   Huang RZ, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P355
   *INC, 2002, AD PHOT US GUID
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   MARKS J., 1997, INT C COMPUTER GRAPH, P389
   McGuffin MJ, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P401, DOI 10.1109/VISUAL.2003.1250400
   Mortensen E. N., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P452, DOI 10.1109/CVPR.1999.784720
   Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442
   Mortensen EN, 1999, COMPUT GRAPHICS-US, V33, P55, DOI 10.1145/345370.345410
   MORTENSEN EN, 2000, P IEEE COMPUTER VISI, V2, P776
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Takahashi S, 2004, GRAPH MODELS, V66, P24, DOI 10.1016/j.gmod.2003.08.002
   Tan KH, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P337, DOI 10.1109/ICCV.2001.937538
   Tzeng Fan-Yin., 2004, Proceedings of Eurographics-IEEE Technical Committee on Visualization and Graphics Symposium on Visualization, P17
   Tzeng FY, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P505, DOI 10.1109/VISUAL.2003.1250413
   Viola I, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P139, DOI 10.1109/VISUAL.2004.48
   Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233
   YAO X, 1991, SPIE P, V1607, P369
NR 30
TC 21
Z9 26
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2005
VL 21
IS 8-10
SI SI
BP 745
EP 754
DI 10.1007/s00371-005-0330-2
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 964CX
UT WOS:000231857400027
DA 2024-07-18
ER

PT J
AU Geyer, C
   Daniilidis, K
AF Geyer, C
   Daniilidis, K
TI Omnidirectional video
SO VISUAL COMPUTER
LA English
DT Article
AB Omnidirectional video enables direct surround immersive viewing of a scene by warping the original image into the correct perspective given a viewing direction. However, novel views from viewpoints off the camera path can only be obtained if we solve the three-dimensional motion and calibration problem. In this paper we address the case of a parabolic catadioptric camera a paraboloidal mirror in front of an orthographic lens - and we introduce a new representation, called the circle space, for points and lines in such images. In this circle space, we formulate an epipolar constraint involving a 4 x 4 fundamental matrix. We prove that the intrinsic parameters can be inferred in closed form from the two-dimensional subspace of the new fundamental matrix from two views if they are constant or from three views if they vary. Three-dimensional motion and structure can then be estimated from the decomposition of the fundamental matrix.
C1 Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA.
C3 University of Pennsylvania
RP Geyer, C (corresponding author), Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA.
EM cgeyer@seas.upenn.edu; kostas@seas.upenn.edu
OI Daniilidis, Kostas/0000-0003-0498-0758
CR Aliaga DG, 2001, COMP GRAPH, P443, DOI 10.1145/383259.383311
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 1993, SPRINGER SERIES INFO
   BARRETO J, 2002, HAWAII, V4, P422
   Benosman R., 2000, Panoramic vision
   BENOSMAN R, 2002, WORKSH OMN VIS COP
   Boult TE, 1998, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.1998.698724
   Bruckstein AM, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P79
   CHEN E, 1993, P ACM SIGGRAPH
   Daniilidis K, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P3, DOI 10.1109/OMNVIS.2002.1044483
   DANIILIDIS K, 2000, IEEE WORKSH ONM VIS
   Daniilidis K., 1996, Visual Navigation, P61
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Fermuller C, 1998, INT J COMPUT VISION, V28, P137, DOI 10.1023/A:1008063000586
   Geyer C, 2002, LECT NOTES COMPUT SC, V2351, P140
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   GEYER C, 2001, IEEE C COMP VIS PATT
   Gluckman J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P999, DOI 10.1109/ICCV.1998.710838
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362
   JEPSON AD, 1990, RBCVTR9036 U TOR
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Ma Y, 2000, INT J COMPUT VISION, V38, P219, DOI 10.1023/A:1008143307025
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   Mulligan J, 2002, INT J COMPUT VISION, V47, P51, DOI 10.1023/A:1014525320885
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   Pedoe D., 1970, GEOMETRY COMPREHENSI
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Rees D W, 1970, United States Patent, Patent No. 3505465
   Sturm P, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P37, DOI 10.1109/OMNVIS.2002.1044489
   Sturm Peter, 1999, BMVC
   SVOBODA T, 1998, P 5 EUR C COMP VIS, P218
   Taylor CJ, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P3, DOI 10.1109/OMNVIS.2000.853795
   YAGI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P11, DOI 10.1109/70.285581
NR 37
TC 19
Z9 22
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2003
VL 19
IS 6
BP 405
EP 416
DI 10.1007/s00371-003-0204-4
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 745PC
UT WOS:000186696200005
DA 2024-07-18
ER

PT J
AU Neumann, J
   Fermüller, C
AF Neumann, J
   Fermüller, C
TI Plenoptic video geometry
SO VISUAL COMPUTER
LA English
DT Article
DE multi-view geometry; spatiotemporal image analysis; camera design;
   structure from motion; polydioptric cameras
ID STEREO
AB More and more processing of visual information is nowadays done by computers, but the images captured by conventional cameras are still based on the pinhole principle inspired by our own eyes. This principle though is not necessarily the optimal image-formation principle for automated processing of visual information. Each camera samples the space of light rays according to some pattern. If we understand the structure of the space formed by the light rays passing through a volume of space, we can determine the camera, or in other words the sampling pattern of light rays, that is optimal with regard to a given task. In this work we analyze the differential structure of the space of time-varying light rays described by the plenoptic function and use this analysis to relate the rigid motion of an imaging device to the derivatives of the plenoptic function. The results can be used to define a hierarchy of camera models with respect to the structure from motion problem and formulate a linear, scene-independent estimation problem for the rigid motion of the sensor purely in terms of the captured images.
C1 Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.
EM jneumann@cfar.umd.edu; fer@cfar.umd.edu
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783
   [Anonymous], 1981, PHOTIC FIELD
   [Anonymous], P INT C PATT REC
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   CAMAHORT E, 1999, TR9935 U TEX AUST DE
   Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932
   Chai JX, 2000, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2000.854892
   Dawkins R., 1996, CLIMBING MOUNT IMPRO
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611
   Horn B.K.P, 1986, Robot Vision
   Koch R., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P585, DOI 10.1109/ICCV.1999.791277
   LEVOY M, 1996, P ACM SIGGRAPH, P161
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   Neumann J, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P19, DOI 10.1109/OMNVIS.2002.1044486
   Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520
   Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346
   Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871
   Richter J., 1970, NOTEBOOKS L DAVINCI, V1, P39
   SEITZ S, 2001, P INT C COMP VIS
   SHUM HY, 1999, P INT C COMP VIS
   Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859
NR 23
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2003
VL 19
IS 6
BP 395
EP 404
DI 10.1007/s00371-003-0203-5
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 745PC
UT WOS:000186696200004
DA 2024-07-18
ER

PT J
AU Chang, CC
   Shih, TK
   Lini, IC
AF Chang, CC
   Shih, TK
   Lini, IC
TI Guessing by neighbors: an efficient reconstruction method for
   transmitting image progressively
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Multimedia Modeling Conference (MMM2001)
CY NOV, 2001
CL DUTCH NATL CTR MATH & COMP SCI, AMSTERDAM, NETHERLANDS
HO DUTCH NATL CTR MATH & COMP SCI
DE progressive image transmission; web applications; bitmapped graphics
ID TRANSMISSION
AB Progressive image transmission (PIT) is useful in Web applications. When the network bandwidth is restricted, the user can preview a coarse version of the image to decide if the entire detail of a picture needs to be transmitted. We propose a newly developed mechanism for PIT. According to the continuity of image pixels, we introduce a guessing-by-neighbors strategy. Only half of the original pixels are transmitted, with additional pixels for error recovery from unsuccessful guessing. The proposed algorithms can be used for both gray-level and color pictures. Bandwidth is saved. The preliminary results show that the number of transmitted bits is reduced in the first few rounds. Additionally, the PSNR values in the first few rounds are much better than other PIT techniques.
C1 Natl Chung Chang Univ, Dept Comp Sci & Informat Engn, Chaiyi, Taiwan.
   Tamkang Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Chung Cheng University; Tamkang University
RP Chang, CC (corresponding author), Natl Chung Chang Univ, Dept Comp Sci & Informat Engn, Chaiyi, Taiwan.
RI Chang, Ching-Chun/JAN-6210-2023
CR Accame M, 1999, IEEE T CONSUM ELECTR, V45, P13, DOI 10.1109/30.754412
   Chang CC, 1998, IEEE T CONSUM ELECTR, V44, P1225, DOI 10.1109/30.735821
   CHANG CC, 2001, LECT NOTES COMPUTER, V2105
   CHANG CC, 1999, P 5 AS C COMM 4 OPT
   CHANG KC, 1994, OPT ENG, V33, P586
   CHEN TS, 1997, INFORMATION SYSTEMS
   JIANG JH, 1997, DIGITAL MEDIA INFORM
   Kim JH, 1996, IEE P-VIS IMAGE SIGN, V143, P132, DOI 10.1049/ip-vis:19960254
   TZOU KH, 1987, OPT ENG, V26, P581, DOI 10.1117/12.7974121
NR 9
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER-VERLAG
PI NEW YORK
PA 175 FIFTH AVE, NEW YORK, NY 10010 USA
SN 0178-2789
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2003
VL 19
IS 5
BP 342
EP 353
DI 10.1007/s00371-002-0186-7
PG 12
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 726KP
UT WOS:000185598500007
DA 2024-07-18
ER

PT J
AU Li, XH
   Li, GQ
   Li, TC
   Mitrouchev, P
AF Li, Xihang
   Li, Guiqin
   Li, Tiancai
   Mitrouchev, Peter
TI Human body construction based on combination of parametric and
   nonparametric reconstruction methods
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Nonparametric human reconstruction; Parametric human reconstruction;
   Mesh deformation; Non-rigid registration; Pose fitting
ID MODEL; SHAPE
AB Nowadays, 3D human models are widely used in the garment industry where it is important to reconstruct compliant human model from scan of the body under partial dress for privacy reasons. A new 3D human construction method based on the combination of parametric and nonparametric reconstruction is proposed here. Inputs to the method include the raw scan and partial anthropometric parameters. The scan is divided into exposed area and clothing occluded area for modeling separately. The information of the clothing occluded area is restored by semantic parametric human modeling and pose fitting. The information of the exposed area is restored by the method of non-rigid registration. Then, the two types of information are fused to reconstruct the final human model. The experiment divided the human scan into three common situations: naked, partially clothed and highly clothed body scanning. The results of the qualitative and quantitative analyses show that the method is able to fit the parametric human model to the exposed area scan while matching the user input on the anthropometric parameters in the clothing occluded area. It is worth pointing out that the connection between the two areas is smooth. The performance is also better than previous related methods. The proposed method reduces the dressing requirements for reconstructing the human body from 3D scan and also demonstrates the validity, accuracy and versatility of the method for reconstructing human model.
C1 [Li, Xihang; Li, Guiqin] Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
   [Li, Tiancai] Shanghai Araystar Co Ltd, Shanghai, Peoples R China.
   [Mitrouchev, Peter] Univ Grenoble Alpes, G SCOP, Grenoble, France.
C3 Shanghai University; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA);
   Centre National de la Recherche Scientifique (CNRS)
RP Li, GQ (corresponding author), Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
EM leeching@shu.edu.cn
CR Alldieck T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5441, DOI 10.1109/ICCV48922.2021.00541
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Bhatnagar B.L., 2020, COMPUTER VISION ECCV
   Blackwell S., 2002, Civilian American and European Surface Anthropometry Resource (CAESAR). Volume 2: Descriptions, V2
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen DY, 2023, VISUAL COMPUT, V39, P1893, DOI 10.1007/s00371-022-02453-x
   Chen G, 2016, COMPUT ANIMAT VIRT W, V27, P72, DOI 10.1002/cav.1632
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Choutas Vasileios, 2020, ECCV, P2
   Hasler N, 2009, COMPUT GRAPH-UK, V33, P211, DOI 10.1016/j.cag.2009.03.026
   Hu PP, 2018, INT J CLOTH SCI TECH, V30, P159, DOI 10.1108/IJCST-05-2017-0067
   Izadi S., 2011, ACM SIGGRAPH
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Lazova V, 2019, INT CONF 3D VISION, P643, DOI 10.1109/3DV.2019.00076
   Li XH, 2023, VISUAL COMPUT, V39, P6435, DOI 10.1007/s00371-022-02738-1
   Li XH, 2022, TEXT RES J, V92, P3750, DOI 10.1177/00405175221093663
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Osman Ahmed A. A., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P598, DOI 10.1007/978-3-030-58539-6_36
   Osman Ahmed A. A., 2021, P IEEE CVF C COMP VI
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Romero J., 2022, arXiv, DOI 10.1145/3130800.3130883
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Song, 2018, SEMANTIC PARAMETRIC
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Wang RZ, 2016, LECT NOTES COMPUT SC, V9911, P271, DOI 10.1007/978-3-319-46478-7_17
   Wang YZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480488
   Xie HY, 2020, TEXT RES J, V90, P937, DOI 10.1177/0040517519883957
   Xiu Y., 2022, 2022 IEEE CVF C COMP
   Yan S, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-019-01054-4
   Yang L., 2020, COMPUTER VISION ECCV
   Yang YP, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON 3D VISION, VOL. 2, P41, DOI 10.1109/3DV.2014.47
   Yao Yuan, 2020, P IEEE CVF C COMP VI
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Zeng Y., 2017, International Conference on Internet Multimedia Computing and Service, P96
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
   Zheng ZR, 2022, IEEE T PATTERN ANAL, V44, P3170, DOI 10.1109/TPAMI.2021.3050505
NR 43
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD 2023 NOV 1
PY 2023
DI 10.1007/s00371-023-03122-3
EA NOV 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA W5QT6
UT WOS:001092178200001
DA 2024-07-18
ER

PT J
AU Chen, ZH
   Zhang, Y
AF Chen, Zihan
   Zhang, Yi
TI CA-GAN: the synthesis of Chinese art paintings using generative
   adversarial networks
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Image synthesis; Generative adversarial networks (GAN)
AB With the advent of generative adversarial networks (GAN), an astonishing advancement has been made in the generation of art painting in recent years. However, existing methods still suffer problems such as color confusion or blurred details. In addition, most of those works centered around the generation of western art painting, while less attention was paid to Chinese traditional arts. Moreover, the lack of traditional Chinese painting datasets is also one of the reasons for the delayed development. To solve the above problems, our research focuses on the synthesis of multi-style traditional Chinese paintings. Firstly, we collect and sort out more than 1000 traditional Chinese paintings, including line drawings, meticulous paintings, ink paintings. Secondly, we propose a Chinese art generative adversarial network (abbreviated as CA-GAN) to decouple the latent vector based on attention mechanism. CA-GAN maps an image to content space and attribute space and fuses them to generate high-quality traditional Chinese art paintings. Meanwhile, a content discriminator is presented to check the consistency of mapping process based on cross-cycle consistency constraint. To make the generated images more artistic, MS-SSIM loss and Charbonnier loss functions are adopted to improve the performance of our model. Experiments have been conducted to verify the effectiveness and the generalization ability of our model. Compared with other state-of-the-art methods, the Chinese art paintings generated by CA-GAN are more vivid and realistic, and the resolutions of them are increased to \(280 \times 280\).
C1 [Chen, Zihan; Zhang, Yi] Sichuan Univ, Dept Comp Sci, Chengdu, Peoples R China.
C3 Sichuan University
RP Zhang, Y (corresponding author), Sichuan Univ, Dept Comp Sci, Chengdu, Peoples R China.
EM chentzuhan@stu.scu.edu.cn; yi.zhang@scu.edu.cn
CR [Anonymous], 2018, NIPS
   Arjovsky, 2017, ARXIV170104862
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Barratt S, 2018, Arxiv, DOI [arXiv:1801.01973, DOI 10.48550/ARXIV.1801.01973]
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Fu FF, 2021, IET IMAGE PROCESS, V15, P746, DOI 10.1049/ipr2.12059
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He B, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1172, DOI 10.1145/3240508.3240655
   Hensel M, 2017, ADV NEUR IN, V30
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang Yunyun, 2022, Artificial Intelligence in Data and Big Data Processing: Proceedings of ICABDE 2021. Lecture Notes on Data Engineering and Communications Technologies (124), P473, DOI 10.1007/978-3-030-97610-1_37
   Jiang Y, 2021, arXiv, DOI DOI 10.48550/ARXIV.2102.07074
   KIM J, 2020, 8 INT C LEARN REPR I
   Kingma D. P., 2014, arXiv
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li Z., 2021, P 2021 IEEE INT C DA, P38, DOI 10.1109/ICDSCA53499.2021.9650335
   Lin DY, 2018, ALGORITHMS, V11, DOI 10.3390/a11010004
   Liu MY, 2017, ADV NEUR IN, V30
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Nowozin S, 2016, ADV NEUR IN, V29
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tang H, 2023, IEEE T NEUR NET LEAR, V34, P1972, DOI 10.1109/TNNLS.2021.3105725
   Tang H, 2019, IEEE IJCNN
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu JH, 2003, J COMPUT SCI TECH-CH, V18, P22, DOI 10.1007/BF02946647
   Zhang H, 2019, 36 INT C MACHINE LEA, V97
   Zhang J, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.723325
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 36
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD 2023 OCT 16
PY 2023
DI 10.1007/s00371-023-03115-2
EA OCT 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U7OU3
UT WOS:001086670500001
DA 2024-07-18
ER

PT J
AU Bondzulic, B
   Pavlovic, B
   Stojanovic, N
   Petrovic, V
   Bujakovic, D
AF Bondzulic, Boban
   Pavlovic, Boban
   Stojanovic, Nenad
   Petrovic, Vladimir
   Bujakovic, Dimitrije
TI A simple and reliable approach to providing a visually lossless image
   compression
SO VISUAL COMPUTER
LA English
DT Article
DE JPEG compression; Just noticeable difference (JND); Peak signal-to-noise
   ratio (PSNR); Visually lossless quality; VVC compression
AB This paper presents an approach for providing the desired visually lossless quality of Joint Photographic Experts Group (JPEG) and Versatile Video Coding (VVC) compressed images. The desired quality is defined as the peak signal-to-noise ratio (PSNR) of the first just noticeable difference (JND) point, which represents the boundary between visually lossless and visually lossy image compression. The proposed approach is based on a piecewise linear interpolation of the PSNR as a function of the parameter that controls the degree of compression-the quality factor (QF) or the quantization parameter (QP). The desired quality is obtained by determining the PSNR value for only two or three values of the QF or QP. The accuracy of the proposed approach was investigated on three publicly available image databases with available results of subjective JND tests on nearly 300 high-resolution images. It has been shown that the maximum difference between the desired and provided quality of JPEG compressed images is 0.3 dB, while the maximum difference in images with VVC compression is slightly larger and is approximately 0.5 dB.
C1 [Bondzulic, Boban; Pavlovic, Boban; Stojanovic, Nenad; Bujakovic, Dimitrije] Univ Def Belgrade, Mil Acad, Veljka Lukica Kurjaka 33, Belgrade 11000, Serbia.
   [Petrovic, Vladimir] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
C3 University of Novi Sad
RP Bondzulic, B (corresponding author), Univ Def Belgrade, Mil Acad, Veljka Lukica Kurjaka 33, Belgrade 11000, Serbia.
EM bobanpav@yahoo.com; bobanpav@yahoo.com; nivzvk@hotmail.com;
   vladimir.petrovic@uns.ac.rs; dimitrijebujakovic@gmail.com
RI Bondzulic, Boban/K-5595-2013; Stojanovic, Nenad/AAB-6788-2022
OI Bondzulic, Boban/0000-0002-8850-9842; Stojanovic,
   Nenad/0000-0001-9328-5348; Petrovic, Vladimir/0000-0002-8299-8999;
   Bujakovic, Dimitrije/0000-0001-7058-9293; Pavlovic,
   Boban/0000-0002-5476-7894
NR 0
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2024
VL 40
IS 5
BP 3747
EP 3763
DI 10.1007/s00371-023-03062-y
EA SEP 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OC3D9
UT WOS:001057647900001
DA 2024-07-18
ER

PT J
AU Lin, TX
   Huang, GH
   Yuan, XC
   Zhong, G
   Huang, XC
   Pun, CM
AF Lin, Tongxu
   Huang, Guoheng
   Yuan, Xiaochen
   Zhong, Guo
   Huang, Xiaocong
   Pun, Chi-Man
TI SCDet: decoupling discriminative representation for dark object
   detection via supervised contrastive learning
SO VISUAL COMPUTER
LA English
DT Article
DE Low-light environment; Dark object detection; Supervised contrastive
   learning; Representation decoupling
ID HISTOGRAM EQUALIZATION; ENHANCEMENT
AB Despite the significant progress made in object detection algorithms, their potential to operate effectively under the low-light environment remains to be fully explored. Recent methods realize dark object detection on the entire representation of dark images; however, they do not further consider the potential entanglement between dark disturbance and discriminative information in dark images, and thus, the learned representation may be sub-optimal. Towards this issue, we propose supervised contrastive detection (SCDet), a novel unified framework to learn the potential composition of dark images, and decouple the discriminative component for facilitating dark object detection. Specifically, we introduce the dense decoupling contrastive (DDC) pretext task to investigate the feature consistency based on a dark transformation, allowing the learned representation to be independent of the potential entanglement to realize decoupling. Moreover, to further drive the decoupled representation to be discriminative instead of a collapse solution for dark object detection, we incorporate the supervision detection task as an extra optimization objective, resulting in the joint optimization pattern. The two tasks are complementary to each other: the DDC task regularizes the detection to learn more decoupling-friendly representation, while the supervision detection task guides the discriminative representation decoupling. As a result, the SCDet achieves dark object detection by decoding the decoupled discriminative representation of dark images. Extensive experiments on four datasets demonstrate the effectiveness of our method in both synthetic and real-world scenarios. Code is available at https://github.com/TxLin7/SCDet.
C1 [Lin, Tongxu] Guangdong Univ Technol, Sch Automat, Guangzhou, Peoples R China.
   [Huang, Guoheng] Guangdong Univ Technol, Comp Sci, Guangzhou, Peoples R China.
   [Huang, Xiaocong] Guangdong Univ Technol, Sch Comp Sci, Guangzhou, Peoples R China.
   [Yuan, Xiaochen] Macao Polytech Univ, Fac Appl Sci, Taipa, Macao, Peoples R China.
   [Zhong, Guo] Guangdong Univ Foreign Studies, Sch Informat Sci & Technol, Guangzhou, Peoples R China.
   [Pun, Chi-Man] Univ Macau, Fac Sci & Technol, Image Proc & Pattern Recognit Lab, Taipa, Macao, Peoples R China.
C3 Guangdong University of Technology; Guangdong University of Technology;
   Guangdong University of Technology; Macao Polytechnic University;
   Guangdong University of Foreign Studies; University of Macau
RP Huang, GH (corresponding author), Guangdong Univ Technol, Comp Sci, Guangzhou, Peoples R China.
EM kevinwong@gdut.edu.cn
RI Pun, Chi Man/GRJ-3703-2022
OI Huang, Guoheng/0000-0002-3640-3229
FU Key Areas Research and Development Program of Guangzhou [2023B01J0029];
   Science and technology research in key areas in Foshan [2020001006832];
   Key-Area Research and Development Program of Guangdong Province
   [2018B010109007, 2019B010153002]; Science and technology projects of
   Guangzhou [202007040006]; Guangdong Provincial Key Laboratory of
   Cyber-Physical System [2020B1212060069]; Guangdong Basic and Applied
   Basic Research Foundation [2023A1515012534]; National Statistical
   Science Research Project of China [2022LY096]
FX This work was supported in part by the Key Areas Research and
   Development Program of Guangzhou Grant 2023B01J0029, Science and
   technology research in key areas in Foshan under Grant 2020001006832,
   the Key-Area Research and Development Program of Guangdong Province
   under Grant 2018B010109007 and 2019B010153002, the Science and
   technology projects of Guangzhou under Grant 202007040006, the Guangdong
   Provincial Key Laboratory of Cyber-Physical System under Grant
   2020B1212060069, the Guangdong Basic and Applied Basic Research
   Foundation under Grant 2023A1515012534, and the National Statistical
   Science Research Project of China (No. 2022LY096).
CR Brooks T, 2019, PROC CVPR IEEE, P11028, DOI 10.1109/CVPR.2019.01129
   Caron M., 2020, Advances in neural information processing systems, V33, P9912
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Cui Z., 2021, P IEEECVF INT C COMP, P2553
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Grill J., 2020, ADV NEURAL INFORM PR, V33, P21271, DOI DOI 10.48550/ARXIV.2006.07733
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   HEIDE F, 2014, ACM T GRAPHIC, V33, P1, DOI DOI 10.1145/2661229.2661260
   Hong Y., 2021, BRIT MACH VIS C, V1, P3
   Hu WH, 2022, VISUAL COMPUT, V38, P3731, DOI 10.1007/s00371-021-02210-6
   Huang SC, 2021, IEEE T PATTERN ANAL, V43, P2623, DOI 10.1109/TPAMI.2020.2977911
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kim T, 2019, PROC CVPR IEEE, P12448, DOI 10.1109/CVPR.2019.01274
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2020, ARXIV
   Liu S, 2022, IEEE COMPUT SOC CONF, P1210, DOI 10.1109/CVPRW56347.2022.00128
   Liu T, 2020, IEEE INT VEH SYM, P1394, DOI 10.1109/IV47402.2020.9304613
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WY, 2022, AAAI CONF ARTIF INTE, P1792
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lv F., 2018, P BMVC, V220, P4
   Ma YD, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P743
   Morawski I., 2022, P IEEE CVF C COMP VI, P630
   Neumann L, 2019, LECT NOTES COMPUT SC, V11361, P691, DOI 10.1007/978-3-030-20887-5_43
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Punnappurath A., 2022, P IEEE C COMP VIS PA, P10769
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sasagawa Yukihiro, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P345, DOI 10.1007/978-3-030-58589-1_21
   Schwartz E, 2019, IEEE T IMAGE PROCESS, V28, P912, DOI 10.1109/TIP.2018.2872858
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Wang SK, 2022, VISUAL COMPUT, V38, P3073, DOI 10.1007/s00371-022-02560-9
   Wang XL, 2021, PROC CVPR IEEE, P3023, DOI 10.1109/CVPR46437.2021.00304
   Wei C, 2018, ARXIV
   Wei KX, 2022, IEEE T PATTERN ANAL, V44, P8520, DOI 10.1109/TPAMI.2021.3103114
   Xie EZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8372, DOI 10.1109/ICCV48922.2021.00828
   Xie ZD, 2021, PROC CVPR IEEE, P16679, DOI 10.1109/CVPR46437.2021.01641
   Yang CY, 2021, PROC CVPR IEEE, P3986, DOI 10.1109/CVPR46437.2021.00398
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Yang WH, 2020, IEEE T IMAGE PROCESS, V29, P5737, DOI 10.1109/TIP.2020.2981922
   Yu NN, 2023, VISUAL COMPUT, V39, P1251, DOI 10.1007/s00371-022-02402-8
   Zhang B, 2022, IEEE T CIRC SYST VID, V32, P1339, DOI 10.1109/TCSVT.2021.3069034
   Zhang JD, 2024, VISUAL COMPUT, V40, P427, DOI 10.1007/s00371-023-02791-4
   Zhang L., 2022, ARXIV
   Zhang Yi, 2021, P IEEE CVF INT C COM, P4593
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 64
TC 2
Z9 2
U1 8
U2 36
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2024
VL 40
IS 5
BP 3357
EP 3369
DI 10.1007/s00371-023-03039-x
EA AUG 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OC3D9
UT WOS:001047709300005
DA 2024-07-18
ER

PT J
AU Wang, HZ
   Hu, CH
   Qian, WJ
   Wang, Q
AF Wang, Hanzhao
   Hu, Chunhua
   Qian, Weijie
   Wang, Qian
TI RT-Deblur: real-time image deblurring for object detection
SO VISUAL COMPUTER
LA English
DT Article
DE Image deblurring; Object detection; Generative adversarial networks;
   Artificial intelligence; Image resolution
AB After a long period of research and development, 2D image object detection technology has been greatly improved in terms of efficiency and accuracy, but it is still a great challenge in dealing with motion blurred images. Most of the current deblurring algorithms are too computationally intensive to meet the demands of real-time tasks. To address this problem, a real-time deblur network (RT-Deblur) based on adversarial generative networks has been proposed. Specifically, a fast Fourier transform residual (FFTRes) block was designed to allow the model to achieve better performance while using fewer residual blocks, and to reduce the number of parameters to meet real-time requirements. In order to improve the deblurring performance and the accuracy of object detection after deblurring, a weighted loss function was developed, which includes the discriminator loss, MSE loss, multi-scale frequency reconstruction loss and perceptual YOLO loss. To validate the effectiveness of deblurring for object detection, we produced two blurred object detection datasets based on REDS and GoPro. A large number of comparative experiments on object detection before and after deblurring using YOLOv5s have been done, and the results show that our network achieves leading m AP scores. RT-Deblur improved the m AP scores from 0.486 to 0.566 and from 0.17 to 0.433 on the two blurred datasets, respectively.
C1 [Wang, Hanzhao; Hu, Chunhua; Qian, Weijie; Wang, Qian] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 21003, Jiangsu, Peoples R China.
C3 Nanjing Forestry University
RP Hu, CH (corresponding author), Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 21003, Jiangsu, Peoples R China.
EM 1121202776@qq.com; huchunhua@njfu.edu.cn; 845532592@qq.com;
   adwangqian@163.com
FU National Natural Science Foundation of China [62072246]
FX AcknowledgementsThis work was supported by National Natural Science
   Foundation of China (62072246).
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bai HR, 2021, IEEE COMPUT SOC CONF, P223, DOI 10.1109/CVPRW53098.2021.00031
   Batchuluun G, 2021, IEEE ACCESS, V9, P5951, DOI 10.1109/ACCESS.2020.3048437
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Blalock D., 2020, What is the state of neural network pruning?, P129
   Chan KCK, 2021, PROC CVPR IEEE, P4945, DOI 10.1109/CVPR46437.2021.00491
   Chen LY, 2022, LECT NOTES COMPUT SC, V13667, P17, DOI 10.1007/978-3-031-20071-7_2
   Cho SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4621, DOI 10.1109/ICCV48922.2021.00460
   Dean J., 2015, NIPS DEEP LEARNING R
   Dong JX, 2022, IEEE T PATTERN ANAL, V44, P9960, DOI 10.1109/TPAMI.2021.3138787
   Dong JX, 2017, SIGNAL PROCESS-IMAGE, V58, P134, DOI 10.1016/j.image.2017.07.004
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fortunato HE, 2014, VISUAL COMPUT, V30, P661, DOI 10.1007/s00371-014-0966-x
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim TH, 2015, PROC CVPR IEEE, P5426, DOI 10.1109/CVPR.2015.7299181
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Liu XZ, 2022, MAGN RESON IMAGING, V89, P77, DOI 10.1016/j.mri.2022.03.003
   Nah S, 2021, IEEE COMPUT SOC CONF, P149, DOI 10.1109/CVPRW53098.2021.00025
   Nah S, 2019, IEEE COMPUT SOC CONF, P1996, DOI 10.1109/CVPRW.2019.00251
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Nishiyama M, 2011, IEEE T PATTERN ANAL, V33, P838, DOI 10.1109/TPAMI.2010.203
   Truong NQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143918
   Pan JS, 2021, IEEE T PATTERN ANAL, V43, P2449, DOI 10.1109/TPAMI.2020.2969348
   Paszke A., 2019, 33rd conference neural information processing systems Vancouver, Canada, December 814
   Purohit K, 2020, AAAI CONF ARTIF INTE, V34, P11882
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Suin M, 2020, PROC CVPR IEEE, P3603, DOI 10.1109/CVPR42600.2020.00366
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu YL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6353, DOI 10.1109/ICCV48922.2021.00631
   Xie G, 2021, IEEE I C VI COM I PR, DOI 10.1109/VCIP53242.2021.9675437
   Xu RK, 2021, IEEE COMPUT SOC CONF, P414, DOI 10.1109/CVPRW53098.2021.00052
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhang KH, 2020, PROC CVPR IEEE, P2734, DOI 10.1109/CVPR42600.2020.00281
   Zhang ZC, 2023, VISUAL COMPUT, V39, P1375, DOI 10.1007/s00371-022-02415-3
   Zhou LH, 2020, IEEE T VEH TECHNOL, V69, P3604, DOI 10.1109/TVT.2020.2969427
   Zou WB, 2021, IEEE INT CONF COMP V, P1895, DOI 10.1109/ICCVW54120.2021.00216
NR 43
TC 2
Z9 2
U1 23
U2 39
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2024
VL 40
IS 4
BP 2873
EP 2887
DI 10.1007/s00371-023-02991-y
EA JUL 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MZ2U3
UT WOS:001026397800006
DA 2024-07-18
ER

PT J
AU Cheng, WF
   Wang, XY
   Mao, BG
AF Cheng, Wangfeng
   Wang, Xuanyao
   Mao, Bangguo
TI A multi-feature fusion algorithm for driver fatigue detection based on a
   lightweight convolutional neural network
SO VISUAL COMPUTER
LA English
DT Article
DE Fatigue detection; Lightweight convolutional neural network;
   Multi-feature fusion; Pre-warning system
AB The majority of the current widely used algorithms for fatigue detection rely on shallow learning to extract fatigue characteristics and use a single feature to determine the level of fatigue. The accuracy of detection is greatly affected by individual and environmental differences, and there are certain limitations in complex scenes. To improve the accuracy and real-time performance of the fatigue detection algorithm, a new driver fatigue detection algorithm based on multi-feature fusion is proposed. This paper employs two cameras to capture photos of the driver and the road, respectively, and a lightweight convolutional neural network to extract features from the driver's face, including the eyes, mouth, and head, as well as lane departure features from the road images. The four fatigue features are analyzed and fused to comprehensively detect the driver's fatigue state. The experimental results show that the multi-feature fusion-based driver fatigue detection algorithm can not only detect the driver's fatigue condition accurately but also classify the fatigue state according to the degree of fatigue, which is useful for making effective pre-warning system.
C1 [Cheng, Wangfeng; Wang, Xuanyao; Mao, Bangguo] Anhui Univ Sci & Technol, Sch Mech Engn, Huainan 232001, Peoples R China.
   [Wang, Xuanyao] Anhui Univ Sci & Technol, Inst Environm Friendly Mat & Occupat Hlth, Wuhu 241000, Peoples R China.
   [Wang, Xuanyao] Shaanxi Automobile Holding Grp Huainan Special Pur, Huainan, Peoples R China.
C3 Anhui University of Science & Technology; Anhui University of Science &
   Technology
RP Wang, XY (corresponding author), Anhui Univ Sci & Technol, Sch Mech Engn, Huainan 232001, Peoples R China.; Wang, XY (corresponding author), Anhui Univ Sci & Technol, Inst Environm Friendly Mat & Occupat Hlth, Wuhu 241000, Peoples R China.; Wang, XY (corresponding author), Shaanxi Automobile Holding Grp Huainan Special Pur, Huainan, Peoples R China.
EM xuanyaowang@126.com
FU Anhui Provincial Natural Science Foundation [1908085ME159]; Scientific
   Research Activities of Post-Doctoral Researchers in Anhui Province
   [2020B447]; Anhui University of Technology Research Institute of
   Environmentally Friendly Materials and Occupational Health (Wuhu) Ramp;D
   special funding project [ALW2021YF05]; Anhui University of Science and
   Technology Postgraduate Innovation Fund Project [2022CX2068]
FX & nbsp;This work was supported by the Anhui Provincial Natural Science
   Foundation under Grant (1908085ME159), and the Project funded by the
   Scientific Research Activities of Post-Doctoral Researchers in Anhui
   Province under Grant (2020B447), and Anhui University of Technology
   Research Institute of Environmentally Friendly Materials and
   Occupational Health (Wuhu) R & D special funding project (ALW2021YF05),
   and Anhui University of Science and Technology Postgraduate Innovation
   Fund Project (2022CX2068).
CR Abe E, 2014, ASIAPAC SIGN INFO PR
   Altomare C, 2015, CIRC-ARRHYTHMIA ELEC, V8, P1265, DOI 10.1161/CIRCEP.114.002572
   An FP, 2022, VISUAL COMPUT, V38, P541, DOI 10.1007/s00371-020-02033-x
   Baulk SD, 2008, ACCIDENT ANAL PREV, V40, P396, DOI 10.1016/j.aap.2007.07.008
   Biswas K, 2021, ARXIV
   Chen Y, 2022, VISUAL COMPUT
   Cheng WF, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020789
   Das DK, 2022, VISUAL COMPUT, V38, P3803, DOI 10.1007/s00371-021-02222-2
   Dehzangi O, 2018, INT C PATT RECOG, P3598, DOI 10.1109/ICPR.2018.8545427
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Gao ZK, 2019, IEEE T NEUR NET LEAR, V30, P2755, DOI 10.1109/TNNLS.2018.2886414
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2017, IEEE T VEH TECHNOL, V66, P6645, DOI 10.1109/TVT.2017.2660497
   Khan MQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112574
   Li HT, 2022, VISUAL COMPUT, V38, P1759, DOI 10.1007/s00371-021-02103-8
   Li LL, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P6058, DOI 10.1109/WCICA.2010.5554645
   Luo R., 2020, Extended abstracts of the 2020 CHI conference on human factors in computing systems, P1
   Ma CW, 2021, SENSOR MATER, V33, P4545, DOI 10.18494/SAM.2021.3544
   Ma DF, 2017, IEEE INTEL TRANSP SY, V9, P136, DOI 10.1109/MITS.2017.2709881
   Ma DF, 2017, IET INTELL TRANSP SY, V11, P222, DOI 10.1049/iet-its.2016.0233
   Ma JY, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108297
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Macchi MM, 2002, ACCIDENT ANAL PREV, V34, P825, DOI 10.1016/S0001-4575(01)00089-6
   Malik H, 2022, VISUAL COMPUT, P519
   Mandal B, 2017, IEEE T INTELL TRANSP, V18, P545, DOI 10.1109/TITS.2016.2582900
   MULDER G, 1973, ERGONOMICS, V16, P69, DOI 10.1080/00140137308924483
   Pandey NN, 2022, NEURAL COMPUT APPL, V34, P13883, DOI 10.1007/s00521-022-07209-1
   Ryou S, 2019, IEEE I CONF COMP VIS, P5991, DOI 10.1109/ICCV.2019.00609
   Seifoory H, 2011, INT P COMPUT SCI INF, V2011, P51
   Shi SY, 2017, ITM WEB CONF, V12, DOI 10.1051/itmconf/20171201019
   Sikander G, 2019, IEEE T INTELL TRANSP, V20, P2339, DOI 10.1109/TITS.2018.2868499
   Wan J, 2022, IEEE T NEUR NET LEAR, V33, P2181, DOI 10.1109/TNNLS.2020.3044078
   Wan J, 2021, IEEE T IMAGE PROCESS, V30, P121, DOI 10.1109/TIP.2020.3032029
   XIE Y, 2017, 2017 20 INT C INF FU, P1
   Yang S, 2021, VISUAL COMPUT
   Yingyu Ji, 2018, Journal of Electronic Imaging, V27, DOI 10.1117/1.JEI.27.5.051205
NR 38
TC 1
Z9 1
U1 10
U2 41
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2024
VL 40
IS 4
BP 2419
EP 2441
DI 10.1007/s00371-023-02927-6
EA JUN 2023
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MZ2U3
UT WOS:001018118800002
DA 2024-07-18
ER

PT J
AU Gao, S
   Tan, ZH
   Ning, JY
   Hou, BQ
   Li, L
AF Gao, Shuo
   Tan, Zhenhua
   Ning, Jingyu
   Hou, Bingqian
   Li, Li
TI ResGait: gait feature refinement based on residual structure for gait
   recognition
SO VISUAL COMPUTER
LA English
DT Article
DE Biometrics; Human identification; Gait recognition; Soft threshold;
   Residual structure
AB Gait recognition is a biometric recognition technology, where the goal is to identify the subject by the subject's walking posture at a distance. However, a lot of redundant information in gait sequence will affect the performance of gait recognition, and the most existing gait recognition models are overly complicated and parameterized, which leads to the low efficiency in model training. Consequently, how to reduce the complexity of the model and eliminate redundant information effectively in gait have become a challenging problem in the field of gait recognition. In this paper, we present a residual structure based gait recognition model, short for ResGait, to learn the most discriminative changes of gait patterns. To eliminate redundant information in gait, the soft thresholding is inserted into the deep architectures as a nonlinear transformation layer to improve gait feature learning capability from the noised gait feature map. Moreover, each sample owns unique set of thresholds, making the proposed model suitable for different gait sequences with different redundant information. Furthermore, residual link is introduced to reduce the learning difficulties and alleviate computational costs in model training. Here, we train the network in terms of various scenarios and walking conditions, and the effectiveness of the method is validated through abundant experiments with various types of redundant information in gait. In comparison to the previous state-of-the-art works, experimental results on the common datasets, CASIA-B and OUMVLP-Pose, show that ResGait has higher recognition accuracy under various walking conditions and scenarios.
C1 [Gao, Shuo; Ning, Jingyu; Hou, Bingqian; Li, Li] Northeastern Univ, Software Coll, Shenyang, Peoples R China.
   [Tan, Zhenhua] Northeastern Univ, Fac Software Coll, Shenyang, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Tan, ZH (corresponding author), Northeastern Univ, Fac Software Coll, Shenyang, Peoples R China.
EM tanzh@mail.neu.edu.cn
OI Gao, Shuo/0009-0007-6696-4186; Ning, Jingyu/0000-0002-6949-6636; Tan,
   Zhenhua/0000-0002-9870-8925
FU National Natural Science Foundation of China [61772125]; National Key
   Research and Development Program of China [2019YFB1405803]
FX This research was funded by the National Natural Science Foundation of
   China under Grants No. 61772125 and the National Key Research and
   Development Program of China under Grant No. 2019YFB1405803.
CR Bai S., 2018, An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling, DOI [10.48550/arXiv.1803.01271, DOI 10.48550/ARXIV.1803.01271]
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chao HQ, 2022, IEEE T PATTERN ANAL, V44, P3467, DOI 10.1109/TPAMI.2021.3057879
   Fan C., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2211.06597
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gao S, 2022, IET COMPUT VIS, V16, P111, DOI 10.1049/cvi2.12070
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu HM, 2022, IEEE IMAGE PROC, P2546, DOI 10.1109/ICIP46576.2022.9897409
   Huang XH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12889, DOI 10.1109/ICCV48922.2021.01267
   Kipf TN, 2017, INT C LEARN REPR
   Li N., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2005.08625
   Li X, 2021, IEEE INT CONF COMP V, P4089, DOI 10.1109/ICCVW54120.2021.00456
   Liang JH, 2022, LECT NOTES COMPUT SC, V13665, P375, DOI 10.1007/978-3-031-20065-6_22
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Lin B., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2110.13408
   Liu YQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2570, DOI 10.1109/ICASSP39728.2021.9413894
   Mogan JN, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157639
   Pan H., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2209.11577
   Peng Y., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2110.13408
   Rijun Liao, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P474, DOI 10.1007/978-3-319-69923-3_51
   Shen C., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2206.13732
   Shiraga Kohei, 2016, ICB, P1, DOI DOI 10.1109/ICB.2016.7550060
   Song YF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1625, DOI 10.1145/3394171.3413802
   Tang J, 2017, IEEE T IMAGE PROCESS, V26, P7, DOI 10.1109/TIP.2016.2612823
   Teepe T, 2022, IEEE COMPUT SOC CONF, P1568, DOI 10.1109/CVPRW56347.2022.00163
   Teepe T, 2021, IEEE IMAGE PROC, P2314, DOI 10.1109/ICIP42928.2021.9506717
   Weizhi An, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P421, DOI 10.1109/TBIOM.2020.3008862
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang C., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.03873
   Zhang YQ, 2020, IEEE T IMAGE PROCESS, V29, P1001, DOI 10.1109/TIP.2019.2926208
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
   Zhao MH, 2020, IEEE T IND INFORM, V16, P4681, DOI 10.1109/TII.2019.2943898
   Zhu Z., 2021, P IEEE C COMP VIS PA, P14789
NR 38
TC 0
Z9 0
U1 15
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2023
VL 39
IS 8
SI SI
BP 3455
EP 3466
DI 10.1007/s00371-023-02973-0
EA JUN 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P2DS6
UT WOS:001016490300005
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Cui, YJ
   Huo, YK
AF Zhang, Xiaoyan
   Cui, Yujie
   Huo, Yongkai
TI Deformable patch embedding-based shift module-enhanced transformer for
   panoramic action recognition
SO VISUAL COMPUTER
LA English
DT Article
DE Panoramic; Action recognition; Vision transformer; Temporal shift
AB 360(?) video action recognition is one of the most promising fields with the popularity of omnidirectional cameras. To obtain a more precise action understanding in panoramic scene, in this paper, we propose a deformable patch embedding-based temporal shift module-enhanced vision transformer model (DS-ViT), which aims to simultaneously eliminate the distortion effects caused by equirectangular projection (ERP) and construct temporal relationship among the video sequences. Panoramic action recognition is a practical but challenging domain for the lack of panoramic feature extraction methods. With deformable patch embedding, our scheme can adaptively learn the position offsets between different pixels, which effectively captures the distorted features. The temporal shift module facilitates temporal information exchanging by shifting part of the channels with zero parameters. Thanks to the powerful encoder, DS-ViT can efficiently learn the distorted features from the ERP inputs. Simulation results show that our proposed solution outperforms the state-of-the-art two-stream solution by an action accuracy of 9.29% and an activity accuracy of 8.18%, where the recent EgoK360 dataset is employed.
C1 [Zhang, Xiaoyan; Cui, Yujie; Huo, Yongkai] Shenzhen Univ, Sch Comp Sci & Software Engn, Natl Engn Lab Big Data Syst Comp Technol, Shenzhen 518060, Peoples R China.
   [Zhang, Xiaoyan; Cui, Yujie; Huo, Yongkai] Shenzhen Univ, Res Inst Future Media Comp, Sch Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
C3 Shenzhen University; Shenzhen University
RP Zhang, XY (corresponding author), Shenzhen Univ, Sch Comp Sci & Software Engn, Natl Engn Lab Big Data Syst Comp Technol, Shenzhen 518060, Peoples R China.; Zhang, XY (corresponding author), Shenzhen Univ, Res Inst Future Media Comp, Sch Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM xyzhang15@szu.edu.cn; cuiyujie2019@email.szu.edu.cn; ykhuo@hotmail.com
FU National Natural Science Foundation of China [61702335]; National
   Science Foundation of Guangdong Province of China [2021A1515011632];
   Shenzhen University [001203234]
FX This work is supported in part by the National Natural Science
   Foundation of China (No. 61702335), in part by the National Science
   Foundation of Guangdong Province of China (No. 2021A1515011632) and in
   part by the funding of Shenzhen University (001203234).
CR Abnar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4190
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Bhandari K, 2020, IEEE IMAGE PROC, P266, DOI 10.1109/ICIP40778.2020.9191256
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2899, DOI 10.1145/3474085.3475467
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dosovitskiy Alexey, 2021, ICLR
   Eder Marc, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12423, DOI 10.1109/CVPR42600.2020.01244
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Han R, 2022, LECT NOTES COMPUT SC, V13664, P244, DOI 10.1007/978-3-031-19772-7_15
   Jiang Chiyu, 2019, INT C LEARNING REPRE
   Lee Y, 2019, PROC CVPR IEEE, P9173, DOI 10.1109/CVPR.2019.00940
   Li D, 2021, LECT NOTES COMPUT SC, V13002, P178, DOI 10.1007/978-3-030-89029-2_14
   Li JN, 2020, IEEE WINT CONF APPL, P497, DOI 10.1109/WACV45572.2020.9093283
   Li YH, 2022, LECT NOTES COMPUT SC, V13695, P336, DOI 10.1007/978-3-031-19833-5_20
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Monroy R, 2018, SIGNAL PROCESS-IMAGE, V69, P26, DOI 10.1016/j.image.2018.05.005
   Sharir G., 2021, ARXIV
   Simonyan K, 2014, ADV NEUR IN, V27
   Snyder JP., 1993, FLATTENING EARTH 200
   Steiner A., 2022, T MACH LEARN RES
   Sudhakaran S, 2020, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR42600.2020.00118
   Sudhakaran S, 2019, PROC CVPR IEEE, P9946, DOI 10.1109/CVPR.2019.01019
   Tian L, 2020, IEEE T IMAGE PROCESS, V29, P8429, DOI 10.1109/TIP.2020.3013168
   Touvron H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P32, DOI 10.1109/ICCV48922.2021.00010
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Xia ZF, 2022, PROC CVPR IEEE, P4784, DOI 10.1109/CVPR52688.2022.00475
   Xie EZ, 2021, ADV NEUR IN, V34
   Yan FH, 2021, LECT NOTES COMPUT SC, V13002, P113, DOI 10.1007/978-3-030-89029-2_9
   Yun H, 2022, LECT NOTES COMPUT SC, V13695, P422, DOI 10.1007/978-3-031-19833-5_25
   Zhang H, 2022, LECT NOTES COMPUT SC, V13443, P145, DOI 10.1007/978-3-031-23473-6_12
   Zhang JM, 2022, PROC CVPR IEEE, P16896, DOI 10.1109/CVPR52688.2022.01641
   Zhang YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13557, DOI [10.1109/iccv48922.2021.01332, 10.1109/ICCV48922.2021.01332]
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhu X., 2021, INT C LEARNING REPRE
NR 44
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2023
VL 39
IS 8
SI SI
BP 3247
EP 3257
DI 10.1007/s00371-023-02959-y
EA JUN 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P2DS6
UT WOS:001019834000002
DA 2024-07-18
ER

PT J
AU Zhu, DK
   Wang, WM
   Xue, X
   Xie, HR
   Cheng, GRY
   Wang, FL
AF Zhu, Dingkun
   Wang, Weiming
   Xue, Xue
   Xie, Haoran
   Cheng, Gary
   Wang, Fu Lee
TI Structure-preserving image smoothing via contrastive learning
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Image smoothing; Structure preservation; Contrastive learning; Main
   interpreter; Edge map extractor
ID SPARSE
AB Image smoothing is an important processing operation that highlights low-frequency structural parts of an image and suppresses the noise and high-frequency textures. In the paper, we post an intriguing question of how to combine the paired unsmoothed/smoothed images and meaningful edge information to improve the performance of image smoothing. To this end, we propose a structure-preserving image smoothing network, which consists of a main interpreter (MI) and an edge map extractor (EME). The network is trained via contrastive learning on the extended BSD500 dataset. In addition, an edge-aware total variation loss function is utilized to distinguish between non-edge regions and edge maps via a pre-trained EME module, therefore improving the capability of structure preservation. In order to maintain the consistency in structure and background brightness, the outputs from MI are used as anchors for a ternary loss in 1:1 paired positive and negative samples. Experiments on different datasets show that our network outperforms state-of-the-art image smoothing methods in terms of SSIM and PSNR.
C1 [Zhu, Dingkun; Wang, Weiming; Wang, Fu Lee] Hong Kong Metropolitan Univ, Sch Sci & Technol, Kowloon, Hong Kong 999077, Peoples R China.
   [Xue, Xue] Nanchang Inst Technol, Smart City & IoT Res Inst, Nanchang 330044, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Dept Comp & Decis Sci, Tuen Mun, Hong Kong 999077, Peoples R China.
   [Cheng, Gary] Educ Univ Hong Kong, Dept Math & Informat Technol, Ting Kok, Hong Kong 999077, Peoples R China.
C3 Hong Kong Metropolitan University; Nanchang Institute Technology;
   Lingnan University; Education University of Hong Kong (EdUHK)
RP Wang, WM (corresponding author), Hong Kong Metropolitan Univ, Sch Sci & Technol, Kowloon, Hong Kong 999077, Peoples R China.
EM dingkun_zhu@163.com; wmwang@hkmu.edu.hk; isso.xuexue@gmail.com;
   hrxie@ln.edu.hk; chengks@eduhk.hk; pwang@hkmu.edu.hk
RI yang, zhou/KBB-6972-2024; Xie, Haoran/AFS-3515-2022; Wang, Fu
   Lee/AAD-9782-2021; JIANG, Peng/KGL-3427-2024; yan, su/KHT-1728-2024
OI Xie, Haoran/0000-0003-0965-3617; Wang, Fu Lee/0000-0002-3976-0053; Wang,
   Weiming/0000-0002-9068-0227
FU Hong Kong Metropolitan University Research Grant [RD/2021/09]
FX AcknowledgementsThe work described in this paper was supported by Hong
   Kong Metropolitan University Research Grant (No. RD/2021/09).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Cho H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601188
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fan QN, 2018, LECT NOTES COMPUT SC, V11217, P455, DOI 10.1007/978-3-030-01261-8_27
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Feng YD, 2022, IEEE T NEUR NET LEAR, V33, P7223, DOI 10.1109/TNNLS.2021.3084473
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Gutmann Michael, 2010, P MACHINE LEARNING R, P297, DOI DOI 10.1145/3292500.3330651
   Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou YK, 2020, IEEE T IMAGE PROCESS, V29, P5121, DOI 10.1109/TIP.2020.2980116
   Hua M, 2014, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2014.363
   Jeon J, 2016, COMPUT GRAPH FORUM, V35, P77, DOI 10.1111/cgf.13005
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Kass M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778837
   Li YJ, 2016, LECT NOTES COMPUT SC, V9908, P154, DOI 10.1007/978-3-319-46493-0_10
   Liang D., 2021, arXiv
   Liu SF, 2016, LECT NOTES COMPUT SC, V9908, P560, DOI 10.1007/978-3-319-46493-0_34
   Liu W, 2022, IEEE T PATTERN ANAL, V44, P6631, DOI 10.1109/TPAMI.2021.3097891
   Liu W, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3388887
   Liu W, 2017, IEEE I CONF COMP VIS, pCP32, DOI 10.1109/ICCV.2017.624
   Liu W, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2612826
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Lu KY, 2018, LECT NOTES COMPUT SC, V11208, P229, DOI 10.1007/978-3-030-01225-0_14
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Nguyen RMH, 2015, IEEE I CONF COMP VIS, P208, DOI 10.1109/ICCV.2015.32
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Park Taesung, 2020, EUR C COMP VIS, P319, DOI [DOI 10.1007/978-3-030-58545-719, DOI 10.1007/978-3-030-58545-7_19]
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Sermanet P, 2018, IEEE INT CONF ROBOT, P1134
   Shen XY, 2017, Arxiv, DOI arXiv:1704.02071
   Sohn K, 2016, ADV NEUR IN, V29
   Srinivas Aravind, 2019, ABS190509272 CORR
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang GY, 2006, ACM T GRAPHIC, V25, P1360, DOI 10.1145/1183287.1183292
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Weiss B, 2006, ACM T GRAPHIC, V25, P519, DOI 10.1145/1141911.1141918
   Wibisono JK, 2020, IEEE IMAGE PROC, P678, DOI 10.1109/ICIP40778.2020.9190982
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu J, 2021, IEEE T MULTIMEDIA, V23, P4065, DOI 10.1109/TMM.2020.3037535
   Xu J, 2018, LECT NOTES COMPUT SC, V11212, P21, DOI 10.1007/978-3-030-01237-3_2
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Xu L, 2015, PR MACH LEARN RES, V37, P1669
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu PP, 2019, IEEE T IMAGE PROCESS, V28, P4354, DOI 10.1109/TIP.2019.2904847
   Yang QX, 2016, PROC CVPR IEEE, P4517, DOI 10.1109/CVPR.2016.489
   Yonglong Tian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P776, DOI 10.1007/978-3-030-58621-8_45
   Zhang FH, 2015, IEEE I CONF COMP VIS, P361, DOI 10.1109/ICCV.2015.49
   Zhang H, 2018, IEEE T IMAGE PROCESS, V27, P2121, DOI 10.1109/TIP.2017.2786469
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhu FD, 2019, IEEE T IMAGE PROCESS, V28, P3556, DOI 10.1109/TIP.2019.2908778
   Zhu L, 2020, IEEE T VIS COMPUT GR, V26, P2471, DOI 10.1109/TVCG.2018.2889055
   Zhu L, 2016, COMPUT GRAPH FORUM, V35, P217, DOI 10.1111/cgf.13019
NR 72
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD 2023 MAY 30
PY 2023
DI 10.1007/s00371-023-02897-9
EA MAY 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H6XL6
UT WOS:000997367300001
DA 2024-07-18
ER

PT J
AU Zhang, JJ
   Li, D
   Jiang, HR
   Zeng, D
AF Zhang, Junjie
   Li, Ding
   Jiang, Haoran
   Zeng, Dan
TI Region-guided network with visual cues correction for infrared small
   target detection
SO VISUAL COMPUTER
LA English
DT Article
DE Infrared image; Small targets; Region-guided; Visual cues
ID MODEL; DIM
AB Infrared small target detection (IRSTD) has experienced fast developments in recent years and been widely applied in civilian and military fields. The long imaging distance and complex backgrounds of infrared images often make the interested targets present in small scales and lack of contour features, which poses great challenges for the detection. Though deep neural network-based methods have been thoroughly investigated in IRSTD, deep layers generally struggle to retain the visual details and positions of small targets, aggravating the miss detection and false alarms. To address the above issue, we propose a Region-Guided Network with visual cues correction (RGNet) for IRSTD. More specifically, we design a Region Guidance Module embedded in shallow layers to generate the foreground mask by leveraging rich visual details contained in low-level features. The obtained mask then guides the re-weighting of deep feature maps to highlight the targets for further localization. Considering noisy signals in backgrounds tend to increase the false alarms of small targets, we propose a Visual Cues Correction Module, which extracts the regional features from low-level features by referring to the predicted positions of initial results, and conducts a binary classification to rule out the negative detection. Since the open-sourced IRSTD datasets are limited, we utilize both public and collected data for the evaluation. Both multi-target and single-target cases are investigated, and comprehensive experimental results indicate that compared to state-of-art models, our method achieves the overall best performance in both scenarios.
C1 [Zhang, Junjie; Li, Ding; Jiang, Haoran; Zeng, Dan] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Key Lab Specialty Fiber Opt & Opt Access Networks, Joint Int Res Lab Specialty Fiber Opt & Adv Commun, Shangda Rd 99, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Zeng, D (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Key Lab Specialty Fiber Opt & Opt Access Networks, Joint Int Res Lab Specialty Fiber Opt & Adv Commun, Shangda Rd 99, Shanghai 200444, Peoples R China.
EM junjie_zhang@shu.edu.cn; liding@shu.edu.cn; jianghaoran@shu.edu.cn;
   dzeng@shu.edu.cn
FU National Natural Science Foundation of China [62202283]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 62202283.
CR Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen F, 2022, IEEE T AERO ELEC SYS, V58, P3979, DOI 10.1109/TAES.2022.3159308
   Corbane C, 2008, SENSORS-BASEL, V8, P2959, DOI 10.3390/s8052959
   Dai YM, 2021, IEEE T GEOSCI REMOTE, V59, P9813, DOI 10.1109/TGRS.2020.3044958
   Dai YM, 2021, IEEE WINT CONF APPL, P949, DOI 10.1109/WACV48630.2021.00099
   Dai YM, 2017, IEEE J-STARS, V10, P3752, DOI 10.1109/JSTARS.2017.2700023
   Dai YM, 2017, INFRARED PHYS TECHN, V81, P182, DOI 10.1016/j.infrared.2017.01.009
   Dai YM, 2016, INFRARED PHYS TECHN, V77, P421, DOI 10.1016/j.infrared.2016.06.021
   Deng H, 2016, IEEE T GEOSCI REMOTE, V54, P4204, DOI 10.1109/TGRS.2016.2538295
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Dhengre N, 2022, VISUAL COMPUT, V38, P837, DOI 10.1007/s00371-020-02054-6
   Ding LH, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102949
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Ge Z, ARXIV
   Huang SQ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010047
   [回丙伟 Hui Bingwei], 2020, [中国科学数据, China Scientific Data], V5, P1
   Ju MR, 2021, INFRARED PHYS TECHN, V114, DOI 10.1016/j.infrared.2021.103659
   Li B., 2021, ARXIV
   Li HY, 2021, IEEE T IMAGE PROCESS, V30, P2016, DOI 10.1109/TIP.2021.3049955
   Liu M, 2017, CURRENT TRENDS IN COMPUTER SCIENCE AND MECHANICAL AUTOMATION, VOL 1, P211
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu TY, 2023, OPT QUANT ELECTRON, V55, DOI 10.1007/s11082-022-04294-3
   Ma TL, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3140432
   McIntosh B, 2021, IEEE T AERO ELEC SYS, V57, P485, DOI 10.1109/TAES.2020.3024391
   Mo W., 2022, VISUAL COMPUTER, V2022, P1
   Nie JY, 2018, INFRARED PHYS TECHN, V90, P186, DOI 10.1016/j.infrared.2018.03.006
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rivest JF, 1996, OPT ENG, V35, P1886, DOI 10.1117/1.600620
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi MS, 2020, MOBILE NETW APPL, V25, P1469, DOI 10.1007/s11036-019-01377-6
   Song HT, 2021, VISUAL COMPUT, V37, P2285, DOI 10.1007/s00371-020-01986-3
   Sun Y, 2021, IEEE T GEOSCI REMOTE, V59, P3737, DOI 10.1109/TGRS.2020.3022069
   Tan A., 2022, VIS COMP, P1
   Wang CY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092168
   Wang G., 2022, VISUAL COMPUT, P1
   Wang H, 2019, IEEE I CONF COMP VIS, P8508, DOI 10.1109/ICCV.2019.00860
   Wang KX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3121806
   Wang XY, 2017, IEEE GEOSCI REMOTE S, V14, P1700, DOI 10.1109/LGRS.2017.2729512
   Wang XJ, 2023, VISUAL COMPUT, V39, P4801, DOI 10.1007/s00371-022-02628-6
   Wei YT, 2016, PATTERN RECOGN, V58, P216, DOI 10.1016/j.patcog.2016.04.002
   Wu W., 2021, PLOS ONE, V16, P0259283
   Yang MM, 2022, VISUAL COMPUT, V38, P2661, DOI 10.1007/s00371-021-02144-z
   YIN W, 2023, VISUAL COMPUT, P1
   Zhang JJ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14081790
   Zhang M., 2023, IEEE Trans. Geosci. Remote Sens, V61, P1
   Zhang MJ, 2022, PROC CVPR IEEE, P867, DOI 10.1109/CVPR52688.2022.00095
   Zhang T., 2021, arXiv
   Zhao K., 2004, OPTICS OPTOELECTRONI, V2, P9
   Zhou X, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124600
NR 50
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2024
VL 40
IS 3
BP 1915
EP 1930
DI 10.1007/s00371-023-02892-0
EA MAY 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY8O3
UT WOS:000994739900002
DA 2024-07-18
ER

PT J
AU Ma, JJ
   Wang, T
   Li, GJ
   Zhan, Q
   Wu, DD
   Chang, YP
   Xue, Y
   Zhang, Y
   Zuo, JC
AF Ma, Jiajun
   Wang, Teng
   Li, Guangjie
   Zhan, Qiang
   Wu, Dandan
   Chang, Yuanpei
   Xue, Ying
   Zhang, Yu
   Zuo, Jiancun
TI Concrete surface roughness measurement method based on edge detection
SO VISUAL COMPUTER
LA English
DT Article
DE Roughness measurement; Concrete surface; Edge detection; Least squares
   method; Edge frequency
AB The strength of the bond between concretes is attributed to surface roughness. Therefore, it is necessary to quantify the roughness of concrete surfaces. In the traditional method, concrete surface roughness is measured using the sand filling method, which is contacting, inefficient, and destructive. Accordingly, this paper proposes an edge detection-based method for measuring concrete surface roughness. By combining pixel and sub-pixel edge detection, aggregate edges are extracted and a relationship curve between edge frequency and concrete surface roughness is fitted using the least squares method to achieve a non-contact, stable and non-destructive measurement. Experimental outcomes indicate that the accuracy of the method for measuring concrete surface roughness can reach 94.7%. Additionally, a single-input, single-output neural network model based on calculated edge frequencies is constructed with a measurement accuracy of 95.4% for concrete surface roughness detection.
C1 [Ma, Jiajun; Li, Guangjie; Zhan, Qiang; Wu, Dandan; Chang, Yuanpei; Xue, Ying; Zhang, Yu] Shanghai Polytech Univ, Sch Resources & Environm Engn, Shanghai, Peoples R China.
   [Wang, Teng; Zuo, Jiancun] Shanghai Polytech Univ, Sch Comp & Informat Engn, Shanghai, Peoples R China.
C3 Shanghai Polytechnic University; Shanghai Polytechnic University
RP Zuo, JC (corresponding author), Shanghai Polytech Univ, Sch Comp & Informat Engn, Shanghai, Peoples R China.
EM majiajun236@163.com; wangteng@sspu.edu.cn; 871045375@qq.com;
   2264407262@qq.com; 542676820@qq.com; 1041877933@qq.com;
   1069222955@qq.com; jczuo@sspu.edu.cn
RI Wu, Dan/AAW-6234-2021
CR Cheng H., 2020, J CIRCUIT SYST COMP, V29, P205
   Ghosh S, 2019, IEEE IMAGE PROC, P205, DOI [10.1109/ICIP.2019.8802986, 10.1109/icip.2019.8802986]
   Ghosh S, 2018, IEEE SIGNAL PROC LET, V25, P1555, DOI 10.1109/LSP.2018.2866949
   Guoxin Y., 2010, CONCRETE, V2010, P25
   Hawley CJ, 2022, CONSTR BUILD MATER, V361, DOI 10.1016/j.conbuildmat.2022.129644
   Kaya Y, 2014, VISUAL COMPUT, V30, P71, DOI 10.1007/s00371-013-0782-8
   Lei G., 2022, CHIN CIVIL ENG J, V55, P57
   Li BW, 2022, VISUAL COMPUT, V38, P4437, DOI 10.1007/s00371-021-02307-y
   Lidan Li., 2011, J LIAONING U ENG TEC, V30, P202
   Liu Zhi-cheng, 2016, Transactions of Beijing Institute of Technology, V36, P191, DOI 10.15918/j.tbit1001-0645.2016.02.016
   Özcan B, 2021, MATERIALS, V14, DOI 10.3390/ma14010158
   Riad M, 2021, J TEST EVAL, V49, P1119, DOI 10.1520/JTE20180761
   Santos PMD, 2013, CONSTR BUILD MATER, V38, P912, DOI 10.1016/j.conbuildmat.2012.09.045
   Shuting Hu., 2020, CRYOGENIC BUILD TECH, V42, P30
   Valikhani A, 2021, COMPUT-AIDED CIV INF, V36, P213, DOI 10.1111/mice.12605
   Wang HD, 2022, VISUAL COMPUT, V38, P591, DOI 10.1007/s00371-020-02036-8
   Wenwen Hu., 2020, J ZHENGZHOU U NAT SC, V52, P37
   Xie X, 2020, J AMB INTEL HUM COMP, V11, P2061, DOI 10.1007/s12652-019-01232-2
   Yi C., 2018, EURASIP J IMAGE VIDE, V2018, P210
   Yunyan W., 2022, SPRINGERBRIEF MATH, V39, P153
   [张渤钰 Zhang Boyu], 2020, [建筑科学, Building Science], V36, P111
   Zhang M., 2022, IEEE Trans. Neural Netw. Learn. Syst.
   Zhang MJ, 2023, IEEE T CYBERNETICS, V53, P578, DOI 10.1109/TCYB.2022.3163294
   Zhang Mingjin, 2022, IEEE T NEURAL NETWOR, P1
   Zhixiang C., 2021, 2021 10 INT C IND TE, V2021, P1
NR 25
TC 3
Z9 3
U1 15
U2 34
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2024
VL 40
IS 3
BP 1553
EP 1564
DI 10.1007/s00371-023-02868-0
EA APR 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY8O3
UT WOS:000978495700001
DA 2024-07-18
ER

PT J
AU Sattler, F
   Carrillo-Perez, B
   Barnes, S
   Stebner, K
   Stephan, M
   Lux, G
AF Sattler, Felix
   Carrillo-Perez, Borja
   Barnes, Sarah
   Stebner, Karsten
   Stephan, Maurice
   Lux, Gregor
TI Embedded 3D reconstruction of dynamic objects in real time for maritime
   situational awareness pictures
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Situtational awareness; Dynamic 3D reconstruction; Real-time monitoring;
   Maritime safety and security
ID VISION
AB Assessing the security status of maritime infrastructures is a key factor for maritime safety and security. Facilities such as ports and harbors are highly active traffic zones with many different agents and infrastructures present, like containers, trucks or vessels. Conveying security-related information in a concise and easily understandable format can support the decision-making process of stakeholders, such as port authorities, law enforcement agencies and emergency services. In this work, we propose a novel real-time 3D reconstruction framework for enhancing maritime situational awareness pictures by joining temporal 2D video data into a single consistent display. We introduce and verify a pipeline prototype for dynamic 3D reconstruction of maritime objects using a static observer and stereoscopic cameras on an GPU-accelerated embedded device. A simulated dataset of a harbor basin was created and used for real-time processing. Usage of a simulated setup allowed verification against synthetic ground-truth data. The presented pipeline runs entirely on a remote, low-power embedded system with similar to 6 Hz. A Nvidia Jetson Xavier AGX module was used, featuring 512 CUDA-cores, 16 GB memory and an ARMv8 64-bit octa-core CPU.
C1 [Sattler, Felix; Carrillo-Perez, Borja; Barnes, Sarah; Stephan, Maurice] German Aerosp Ctr DLR, Inst Protect Maritime Infrastructures, Maritime Secur Technol, Fischkai 1, D-27572 Bremen, Germany.
   [Stebner, Karsten] German Aerosp Ctr DLR, Inst Opt Sensor Syst, Secur Res & Applicat, Rutherfordstr 2, D-12489 Berlin, Germany.
   [Lux, Gregor] Westphalian Univ Appl Sci, Dept Comp Sci, Neidenburger Str 43, D-45897 Gelsenkirchen, Nrw, Germany.
C3 Helmholtz Association; German Aerospace Centre (DLR); Helmholtz
   Association; German Aerospace Centre (DLR)
RP Sattler, F (corresponding author), German Aerosp Ctr DLR, Inst Protect Maritime Infrastructures, Maritime Secur Technol, Fischkai 1, D-27572 Bremen, Germany.
EM felix.sattler@dlr.de; borja.carrilloperez@dlr.de; sarah.barnes@dlr.de;
   karsten.stebner@dlr.de; maurice.stephan@dlr.de; gregor.lux@w-hs.de
RI Carrillo-Perez, Borja/JNS-5214-2023
OI /0009-0002-5495-5841; Sattler, Felix/0000-0001-8869-282X
FU  [MARESEC 2022]
FX AcknowledgementsAn earlier version of this work was published as part of
   the Proceedings of the second European Workshop on Maritime Systems
   Resilience and Security (MARESEC 2022) under the title "Real-time
   embedded reconstruction of dynamic objects for a 3D maritime situational
   awareness picture".
CR Bârsan IA, 2018, IEEE INT CONF ROBOT, P7510
   Blender Foundation, 2018, Technical Report
   Bullinger S., 2020, Ph.D. thesis, DOI [10.5445/KSP/1000105589, DOI 10.5445/KSP/1000105589]
   Carrillo-Perez B, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072713
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Denninger Maximilian, 2019, ARXIV191101911
   Diller C., 2018, KINECTFUSIONLIB
   Engelmann F, 2017, IEEE WINT CONF APPL, P400, DOI 10.1109/WACV.2017.51
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Grinvald M, 2021, IEEE INT CONF ROBOT, P14192, DOI 10.1109/ICRA48506.2021.9560923
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jocher Glenn, 2022, Zenodo
   Karoly Artur I., 2022, 2022 IEEE 20th Jubilee World Symposium on Applied Machine Intelligence and Informatics (SAMI)., P000329, DOI 10.1109/SAMI54271.2022.9780790
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Merrill D, 2022, CUB v1.16.0
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Paszke A, 2019, ADV NEUR IN, V32
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Qiu WC, 2016, LECT NOTES COMPUT SC, V9915, P909, DOI 10.1007/978-3-319-49409-8_75
   Ribeiro M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218090
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sirimanne S.N., 2020, Technical Report. Tech. Rep..
   Solano-Carrillo E, 2021, IEEE INT C INTELL TR, P2193, DOI 10.1109/ITSC48978.2021.9564675
   Strecke M, 2019, IEEE I CONF COMP VIS, P5864, DOI 10.1109/ICCV.2019.00596
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008
   Yang Y, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9111281
   Zhang H., 2022, 2022 IEEE INT C UNM, P653, DOI [10.1109/ICUS55513.2022.9986766, DOI 10.1109/ICUS55513.2022.9986766]
NR 35
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD 2023 MAR 10
PY 2023
DI 10.1007/s00371-023-02802-4
EA MAR 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9T3CC
UT WOS:000946907000003
OA hybrid
DA 2024-07-18
ER

PT J
AU Pradhan, K
   Patra, S
AF Pradhan, Kunal
   Patra, Swarnajyoti
TI Semantic-aware structure-preserving median morpho-filtering
SO VISUAL COMPUTER
LA English
DT Article
DE Morphological filters; Median filter; Texture smoothing;
   Structure-preserving filtering
AB According to the recent developments, the most challenging part of texture filtering is to filter out the irregular and varying scale texture while preserving the structural contents with minimum distortion. For better handling varying scale irregular textural patterns, here we propose a semantic-aware structure-preserving filtering technique. Our technique, first, generates an edge-map by using semantic information extracted from the global and local morphological gradient histograms. Then using the generated edge-map, an adaptive median morpho-filtering is proposed by defining a dynamic window that avoids overlapping of textural and structural contents of the image. The experimental results for a variety of images show the potentiality of the proposed technique compared to the several state-of-the-art methods.
C1 [Pradhan, Kunal; Patra, Swarnajyoti] Tezpur Univ, Dept Comp Sci & Engn, Napam 784028, Assam, India.
C3 Tezpur University
RP Patra, S (corresponding author), Tezpur Univ, Dept Comp Sci & Engn, Napam 784028, Assam, India.
EM swpatra@tezu.ernet.in
RI Pradhan, Kunal/JWP-2309-2024
OI Pradhan, Kunal/0000-0003-4959-1983; Patra,
   Swarnajyoti/0000-0003-4300-9307
FU Science and Engineering Research Board, Government of India
   [CRG/2020/003018]
FX This work is supported by Science and Engineering Research Board,
   Government of India, with Grant No. CRG/2020/003018.
CR Annaby MH, 2021, J SIGNAL PROCESS SYS, V93, P1301, DOI 10.1007/s11265-021-01707-6
   [Anonymous], INT C INF TECHN E SE, DOI 10.1109/ICITeS.2012.6216680
   Bao LC, 2014, IEEE T IMAGE PROCESS, V23, P555, DOI 10.1109/TIP.2013.2291328
   Ben Said A, 2019, J MATH IMAGING VIS, V61, P106, DOI 10.1007/s10851-018-0829-6
   Berkovich H, 2013, INT SYMP IMAGE SIG, P10
   Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908
   Cai BL, 2017, IEEE IMAGE PROC, P250, DOI 10.1109/ICIP.2017.8296281
   Chen LG, 2020, VISUAL COMPUT, V36, P2017, DOI 10.1007/s00371-020-01950-1
   Cho H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601188
   Diamantas S., 2017, INT C IMAGING SYSTEM, P1
   Du H, 2016, VISUAL COMPUT, V32, P1537, DOI 10.1007/s00371-015-1138-3
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gavaskar RG, 2019, IEEE T IMAGE PROCESS, V28, P779, DOI 10.1109/TIP.2018.2871597
   Green O, 2018, IEEE T IMAGE PROCESS, V27, P2217, DOI 10.1109/TIP.2017.2781375
   Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Jeon J, 2016, COMPUT GRAPH FORUM, V35, P77, DOI 10.1111/cgf.13005
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Lee H, 2017, COMPUT GRAPH FORUM, V36, P262, DOI 10.1111/cgf.12875
   Likforman-Sulem L, 2011, IMAGE VISION COMPUT, V29, P351, DOI 10.1016/j.imavis.2011.01.001
   Lin TH, 2016, COMPUT GRAPH FORUM, V35, P57, DOI 10.1111/cgf.13003
   Liu B., 2018, IEEE INT C MULTIMEDI, P1
   Liu CX, 2017, VISUAL COMPUT, V33, P769, DOI 10.1007/s00371-017-1380-y
   Liu W, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3388887
   Liu Y, 2020, IEEE ACCESS, V8, P43838, DOI 10.1109/ACCESS.2020.2977408
   Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731
   Ochotorena CN, 2020, IEEE T IMAGE PROCESS, V29, P1397, DOI 10.1109/TIP.2019.2941326
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rivest J.-F., 1993, Journal of Electronic Imaging, V2, P326, DOI 10.1117/12.159642
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Ruhela R, 2023, VISUAL COMPUT, V39, P2035, DOI 10.1007/s00371-022-02462-w
   Saian PON., 2018, Int. J. Inf. Technol. Bus, V1, P10
   Serra J., 1983, IMAGE ANAL MATH MORP
   Song J, 2018, IEEE T CIRC SYST VID, V28, P2164, DOI 10.1109/TCSVT.2017.2717542
   Su Z, 2013, VISUAL COMPUT, V29, P1011, DOI 10.1007/s00371-012-0753-5
   Sun YJ, 2018, IEEE T VIS COMPUT GR, V24, P2129, DOI 10.1109/TVCG.2017.2711614
   Sun ZG, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108089
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tsai D.-Y., 2011, Medical Imaging, IntechOpen
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang C., 2022, IEEE I CONF COMP VIS
   Wang H., 2015, COMPUT VIS MEDIA, V1, P27
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu PP, 2019, IEEE T IMAGE PROCESS, V28, P4354, DOI 10.1109/TIP.2019.2904847
   Xu PP, 2018, IEEE T IMAGE PROCESS, V27, P3621, DOI 10.1109/TIP.2018.2820427
   Yang GZ, 1996, IMAGE VISION COMPUT, V14, P135, DOI 10.1016/0262-8856(95)01047-5
   Yang QX, 2016, PROC CVPR IEEE, P4517, DOI 10.1109/CVPR.2016.489
   Ye W, 2017, IEEE IMAGE PROC, P2443, DOI 10.1109/ICIP.2017.8296721
   Yin H, 2019, SIGNAL PROCESS, V165, P315, DOI 10.1016/j.sigpro.2019.07.026
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang GY, 2018, J VIS COMMUN IMAGE R, V56, P150, DOI 10.1016/j.jvcir.2018.09.016
   Zhao HL, 2018, VISUAL COMPUT, V34, P83, DOI 10.1007/s00371-016-1315-z
   Zhou PC, 2023, VISUAL COMPUT, V39, P1533, DOI 10.1007/s00371-022-02427-z
   Zhu L, 2020, IEEE T VIS COMPUT GR, V26, P2471, DOI 10.1109/TVCG.2018.2889055
NR 60
TC 4
Z9 4
U1 2
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2024
VL 40
IS 2
BP 505
EP 521
DI 10.1007/s00371-023-02796-z
EA MAR 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GE6E8
UT WOS:000943676800001
DA 2024-07-18
ER

PT J
AU Li, YJ
   Zhang, M
   Jin, WB
   Deng, CY
AF Li, Yajuan
   Zhang, Meng
   Jin, Wenbiao
   Deng, Chongyang
TI Approximating Bezier curves with least square polygons
SO VISUAL COMPUTER
LA English
DT Article
DE Piecewise linear approximation; Bezier curve; Least square fitting
ID BOUNDS; SHARP; PIECE
AB Approximating Bezier curve by polygon is a traditional technique in computer-aided geometric design, and there are several methods for constructing such polygons. In this paper, we propose to approximate Bezier curve by the least square polygon (LSP). LSP was derived by least square fitting which minimizes the integral of approximating errors. We provide a closed formula for the vertices of LSP. Because of its optimization method, LSP has lower approximation errors than existing approximating polygons. This observation is verified by many numerical examples we tested and several typical examples are included in this paper.
C1 [Li, Yajuan; Jin, Wenbiao; Deng, Chongyang] Hangzhou Dianzi Univ, Sch Sci, Hangzhou 310018, Peoples R China.
   [Zhang, Meng] Hangzhou Dianzi Univ, Informat Engn Coll, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Deng, CY (corresponding author), Hangzhou Dianzi Univ, Sch Sci, Hangzhou 310018, Peoples R China.
EM liyajuan@hdu.edu.cn; dcy@hdu.edu.cn
RI Deng, Chongyang/E-4422-2017; Zhang, Meng/N-3262-2017
OI Li, Yajuan/0000-0003-4020-7463
FU NationalNatural Science Foundation ofChina (NSFC) [61872121]
FX The authors owe their gratitude to the anonymous referees for their
   valuable comments which have helped to improve the presentation of this
   manuscript. This work was supported by the NationalNatural Science
   Foundation ofChina (NSFC) under the project numbers 61872121.
CR Farin G., 2001, Curves and Surfaces for CAGD: A Practical Guide, Vfifth
   LANE JM, 1980, IEEE T PATTERN ANAL, V2, P35, DOI 10.1109/TPAMI.1980.4766968
   Lutterkort D, 2001, COMPUT AIDED GEOM D, V18, P851, DOI 10.1016/S0167-8396(01)00067-X
   Lutterkort D, 2001, NUMER MATH, V89, P735, DOI 10.1007/S002110100181
   Nairn D, 1999, COMPUT AIDED GEOM D, V16, P613, DOI 10.1016/S0167-8396(99)00026-6
   Peters J, 2003, LECT NOTES COMPUT SC, V2768, P297
   Reif U, 2000, COMPUT AIDED GEOM D, V17, P579, DOI 10.1016/S0167-8396(00)00014-5
   WANG GJ, 1991, CVGIP-GRAPH MODEL IM, V53, P93, DOI 10.1016/1049-9652(91)90023-D
   Zhang Ren-jiang, 2003, J Zhejiang Univ Sci, V4, P47, DOI 10.1631/jzus.2003.0047
   Zhang RJ, 2010, COMPUT AIDED GEOM D, V27, P382, DOI 10.1016/j.cagd.2010.02.005
   Zhang RJ, 2009, COMPUT AIDED GEOM D, V26, P336, DOI 10.1016/j.cagd.2008.08.002
   Zhang RJ, 2006, COMPUT AIDED GEOM D, V23, P1, DOI 10.1016/j.cagd.2005.04.010
NR 12
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2024
VL 40
IS 2
BP 637
EP 646
DI 10.1007/s00371-023-02806-0
EA MAR 2023
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GE6E8
UT WOS:000943086600001
DA 2024-07-18
ER

PT J
AU Lu, XB
   Xie, XP
   Ye, CL
   Xing, H
   Liu, ZC
   Cai, CC
AF Lu, Xinbiao
   Xie, Xupeng
   Ye, Chunlin
   Xing, Hao
   Liu, Zecheng
   Cai, Changchun
TI A lightweight generative adversarial network for single image
   super-resolution
SO VISUAL COMPUTER
LA English
DT Article
DE Super-resolution; Generative adversarial network; Model lightweight;
   Inception block
ID ALGORITHM; INTERPOLATION
AB Single image super-resolution is a digital image processing technique that can obtain a corresponding high-resolution image from a low-resolution image. The growth of deep convolutional neural networks in the field of computer vision has greatly benefited recent research on super-resolution. However, the convolutional neural networks often have a large number of parameters, which increases the model's computational cost and limits its application in practical situations. In order to solve the problem, we propose a lightweight generative adversarial network model using the inception block. According to extensive experimental results on image super-resolution using four widely used datasets, our model not only achieves high scores on the peak signal to noise ratio/structural similarity index matrix, but also enables faster computation compared to other image super-resolution models.
C1 [Lu, Xinbiao; Xie, Xupeng; Ye, Chunlin; Xing, Hao; Liu, Zecheng] Hohai Univ, Sch Energy & Elect Engn, Nanjing 211100, Peoples R China.
   [Lu, Xinbiao; Cai, Changchun] Hohai Univ, Jiangsu Key Lab Power Transmiss & Distribut Equipm, Nanjing 211100, Peoples R China.
C3 Hohai University; Hohai University
RP Xie, XP (corresponding author), Hohai Univ, Sch Energy & Elect Engn, Nanjing 211100, Peoples R China.
EM xinbiaolu@126.com; studentxupeng@163.com; yechunlinhhu@126.com;
   haoxing1997@126.com; 2314180985@qq.com; 20031690@hhu.edu.cn
OI , xxp/0000-0002-0041-8234
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Aràndiga F, 2016, APPL MATH COMPUT, V272, P100, DOI 10.1016/j.amc.2015.08.027
   BOOR CD, 1962, J MATH PHYS CAMB, V41, P212
   Chen WH, 2020, IEEE ACCESS, V8, P93608, DOI 10.1109/ACCESS.2020.2995175
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li XH, 2021, ISPRS J PHOTOGRAMM, V179, P14, DOI 10.1016/j.isprsjprs.2021.07.007
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lu ZY, 2022, SIGNAL IMAGE VIDEO P, V16, P1143, DOI 10.1007/s11760-021-02063-5
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Muhammad W, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161979
   Shi WL, 2021, VISUAL COMPUT, V37, P1569, DOI 10.1007/s00371-020-01903-8
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HT, 2021, VISUAL COMPUT, V37, P2285, DOI 10.1007/s00371-020-01986-3
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang F, 2023, VISUAL COMPUT, V39, P5069, DOI 10.1007/s00371-022-02646-4
   Wang X., 2020, ACCV
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Yang X, 2022, VISUAL COMPUT, V38, P4307, DOI 10.1007/s00371-021-02297-x
   Yang X, 2015, NEUROCOMPUTING, V162, P171, DOI 10.1016/j.neucom.2015.03.055
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 40
TC 3
Z9 3
U1 10
U2 37
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2024
VL 40
IS 1
BP 41
EP 52
DI 10.1007/s00371-022-02764-z
EA FEB 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IX5B8
UT WOS:000934682000001
DA 2024-07-18
ER

PT J
AU Baker, L
   Ventura, J
   Langlotz, T
   Gul, S
   Mills, S
   Zollmann, S
AF Baker, Lewis
   Ventura, Jonathan
   Langlotz, Tobias
   Gul, Shazia
   Mills, Steven
   Zollmann, Stefanie
TI Localization and tracking of stationary users for augmented reality
SO VISUAL COMPUTER
LA English
DT Article
DE Localization; Tracking; Augmented reality; Virtual reality
ID MONOCULAR SLAM; RECOGNITION; ANNOTATIONS
AB In augmented reality applications it is essential to know the position and orientation of the user to correctly register virtual 3D content in the user's field of view. For this purpose, visual tracking through simultaneous localization and mapping (SLAM) is often used. However, when applied to the commonly occurring situation where the users are mostly stationary, many methods presented in previous research have two key limitations. First, SLAM techniques alone do not address the problem of global localization with respect to prior models of the environment. Global localization is essential in many applications where multiple users are expected to track within a shared space, such as spectators at a sporting event. Secondly, these methods often assume significant translational movement to accurately reconstruct and track from a local model of the environment, causing challenges for many stationary applications. In this paper, we extend recent research on Spherical Localization and Tracking to support relocalization after tracking failure, as well as global localization in large shared environments, and optimize the method for operation on mobile hardware. We also evaluate various state-of-the-art localization approaches, the robustness of our visual tracking method, and demonstrate the effectiveness of our system in real-life scenarios.
C1 [Baker, Lewis; Langlotz, Tobias; Gul, Shazia; Mills, Steven; Zollmann, Stefanie] Univ Otago, Dept Comp Sci & Informat Sci, Dunedin, New Zealand.
   [Ventura, Jonathan] Cal Poly, San Luis Obispo, CA USA.
C3 University of Otago; California State University System; California
   Polytechnic State University San Luis Obispo
RP Zollmann, S (corresponding author), Univ Otago, Dept Comp Sci & Informat Sci, Dunedin, New Zealand.
EM stefanie.zollmann@otago.ac.nz
OI Mills, Steven/0000-0002-4933-7777; Ventura,
   Jonathan/0000-0003-1661-8529; Langlotz, Tobias/0000-0003-1275-2026;
   Zollmann, Stefanie/0000-0002-4690-5409
FU Animation Research Ltd; Highlanders, Otago Rugby (ORFU); School of
   Surveying at the University of Otago
FX We thank Animation Research Ltd, Forsyth Barr Stadium, the Highlanders,
   Otago Rugby (ORFU) and OptaPerform for their support. We also thank Mike
   Denham and Craig Tidey from the School of Surveying at the University of
   Otago for their support in surveying the stadium.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   Arth C, 2015, IEEE T VIS COMPUT GR, V21, P1309, DOI 10.1109/TVCG.2015.2459772
   AZUMA R, 1993, COMMUN ACM, V36, P50, DOI 10.1145/159544.159581
   Baker L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P809, DOI [10.1109/VR46266.2020.1581313017497, 10.1109/VR46266.2020.00006]
   Baker L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P782, DOI [10.1109/VR46266.2020.1581313146787, 10.1109/VR46266.2020.000-2]
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Brachmann E, 2019, IEEE I CONF COMP VIS, P7524, DOI 10.1109/ICCV.2019.00762
   Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489
   Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267
   David P, 2003, PROC CVPR IEEE, P424
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   DiVerdi S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P19
   Engels C., 2006, PHOTOGRAMCOMPUTVIS, V2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Grubert J., 2012, AUGMENTED REALITY BR
   Grupp M., 2017, EV PYTH PACK EV OD S
   Gul S., 2021, 2021 36 INT C IM VIS, P1
   Hadian M, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P185, DOI 10.1109/IranianMVIP.2015.7397533
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Karami E., 2017, arXiv
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Khan N.Y., 2012, INT ACM SIGACCESS C, P201
   Klein George, 2007, P1
   Langlotz T., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P318, DOI DOI 10.1145/2414536.2414588
   Langlotz T, 2014, P IEEE, V102, P155, DOI 10.1109/JPROC.2013.2294255
   Langlotz T, 2012, IEEE PERVAS COMPUT, V11, P56, DOI 10.1109/MPRV.2010.69
   Langlotz T, 2011, COMPUT GRAPH-UK, V35, P831, DOI 10.1016/j.cag.2011.04.004
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791
   Liu HM, 2016, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR.2016.24
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Muñoz-Salinas R, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107193
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nistér D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y
   Prince SJD, 2002, IEEE COMPUT GRAPH, V22, P39, DOI 10.1109/MCG.2002.1046627
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662
   Sattler T, 2012, LECT NOTES COMPUT SC, V7572, P752, DOI 10.1007/978-3-642-33718-5_54
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Sklansky J, 1982, PATTERN RECOGN LETT, V1, P79, DOI 10.1016/0167-8655(82)90016-2
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sweeney C., 2019, ARXIV
   Taketomi T, 2017, IPSJ Trans. Comput. Vis. Appl, V9, P1, DOI [10.1186/s41074-017-0027-2, DOI 10.1186/S41074-017-0027-2]
   Ventura J, 2016, LECT NOTES COMPUT SC, V9907, P53, DOI 10.1007/978-3-319-46487-9_4
   Ventura J, 2014, IEEE T VIS COMPUT GR, V20, P531, DOI 10.1109/TVCG.2014.27
   Wagner D, 2010, P IEEE VIRT REAL ANN, P211, DOI 10.1109/VR.2010.5444786
   Wagner D, 2008, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR.2008.4637337
   Zollmann S, 2019, SA'19: SIGGRAPH ASIA 2019 TECHNICAL BRIEFS, P75, DOI 10.1145/3355088.3365162
NR 55
TC 3
Z9 3
U1 2
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2024
VL 40
IS 1
BP 227
EP 244
DI 10.1007/s00371-023-02777-2
EA FEB 2023
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IX5B8
UT WOS:000924564400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, XM
   Wang, JL
   Kang, MY
   Feng, Z
   Zhou, X
   Liu, B
AF Wang, Xingmei
   Wang, Jinli
   Kang, Minyang
   Feng, Ze
   Zhou, Xuan
   Liu, Bo
TI LDGC-Net: learnable descriptor graph convolutional network for image
   retrieval
SO VISUAL COMPUTER
LA English
DT Article
DE Image retrieval; Graph convolutional network; Hard mining ability;
   Plug-and-play module
AB Image retrieval is a challenging task of searching images similar to the query one from a database. Previous learning-based methods adopt various ingenious designs to increase the representatively positive and negative sample pairs in training. Still, these methods are performance immanently limited by the size of the mini-batch. To this end, we here introduce the learnable descriptor graph convolutional network (LDGC-Net), which effectively enhances the hard mining ability of the model and clears the boundary between different categories. We present an analysis of why our LDGC-Net can aggregate relationships between original descriptors in a constrained size of the mini-batch. Also, we propose an innovative end-to-end training framework with the LDGC-Net for image retrieval to accelerate model convergence. In particular, our LDGC-Net can be conveniently integrated into other current methods as a plug-and-play module with inappreciable computational cost. Experimental results in three benchmark datasets show that the proposed LDGC-Net can improve performance compared with several state-of-the-art approaches.
C1 [Wang, Xingmei; Wang, Jinli; Feng, Ze; Zhou, Xuan] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Peoples R China.
   [Kang, Minyang; Liu, Bo] Key Lab Av Syst Integrated Technol, Shanghai, Peoples R China.
C3 Harbin Engineering University
RP Wang, XM (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Peoples R China.
EM wangxingmei@hrbeu.edu.cn; 894921255@hrbeu.edu.cn; 108696950@qq.com;
   csfengze@hrbeu.edu.cn; zhouxuan8930@hrbeu.edu.cn; liubogoogle@126.com
FU Key Laboratory of Avionics System Integrated Technology, Fundamental
   Research Funds for the Central Universities in China [3072022JC0601];
   National Natural Science Foundation of China [41876110]
FX This work is supported by a grant from Key Laboratory of Avionics System
   Integrated Technology, Fundamental Research Funds for the Central
   Universities in China, Grant No. 3072022JC0601, and the National Natural
   Science Foundation of China under Grant No. 41876110.
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Atwood J, 2016, ADV NEUR IN, V29
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brown Andrew, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P677, DOI 10.1007/978-3-030-58545-7_39
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Cakir F, 2019, PROC CVPR IEEE, P1861, DOI 10.1109/CVPR.2019.00196
   Defferrard M, 2016, ADV NEUR IN, V29
   Dong B., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2106.02351
   El-Nouby A., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2102.05644
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Hamilton W. L., 2017, B TECHNICAL COMMITTE, V40, P52
   Hausler S, 2021, PROC CVPR IEEE, P14136, DOI 10.1109/CVPR46437.2021.01392
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Henaff M., 2015, ARXIV, DOI DOI 10.48550/ARXIV.1506.05163
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Qin Q, 2020, P 58 ANN M ASS COMPU, P8161, DOI [10.18653/v1/2020.acl-main.726, DOI 10.18653/V1/2020.ACL-MAIN.726]
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Ramzi E, 2021, ADV NEUR IN, V34
   Revaud J, 2019, IEEE I CONF COMP VIS, P5106, DOI 10.1109/ICCV.2019.00521
   Rolinek Michal, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7617, DOI 10.1109/CVPR42600.2020.00764
   Roth K, 2019, IEEE I CONF COMP VIS, P7999, DOI 10.1109/ICCV.2019.00809
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Suh Y, 2019, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2019.00742
   Teh E.W., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.01113
   Tolias Giorgos, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P460, DOI 10.1007/978-3-030-58452-8_27
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Venkataramanan S., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2106.04990
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang X, 2020, PROC CVPR IEEE, P6387, DOI 10.1109/CVPR42600.2020.00642
   Weyand T, 2020, PROC CVPR IEEE, P2572, DOI 10.1109/CVPR42600.2020.00265
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Zhang BR, 2022, PROC CVPR IEEE, P7522, DOI 10.1109/CVPR52688.2022.00738
   Zhao W., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2108.05889
   Zheng W., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2108.10026
NR 47
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2023
VL 39
IS 12
BP 6639
EP 6653
DI 10.1007/s00371-022-02753-2
EA DEC 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X7HK1
UT WOS:000904857900001
DA 2024-07-18
ER

PT J
AU Li, XH
   Li, GQ
   Li, TC
   Lv, JP
   Mitrouchev, P
AF Li, Xihang
   Li, Guiqin
   Li, Tiancai
   Lv, Jianping
   Mitrouchev, Peter
TI Remodeling of mannequins based on automatic binding of mesh to
   anthropometric parameters
SO VISUAL COMPUTER
LA English
DT Article
DE Mannequin modeling; Semantic anthropometric parameters; Mesh
   deformation; XGBoost-RFECV; Constrained optimization
ID RECONSTRUCTION; REGRESSION
AB In order to improve the accuracy of semantic anthropometric parameters in expressing the body shape of the mannequin and simplify the manual pre-processing of the parameter to body shape mapping, a method for creating 3D mannequins based on automatic binding of mesh to anthropometric parameters is presented. For this purpose, 27 anthropometric parameters are used to accurately constrain the shape of the human body. The missing parameters are estimated by partial user input, which avoids complex input. A method based on eXtreme Gradient Boosting and Recursive Feature Elimination with Cross-Validation to automatically bind the most relevant anthropometric parameters for each mesh is proposed and 3D mannequin is created by local mapping. This makes it easier to add or subtract parameters to constrain the mannequin. An error-based approach for iterative optimization of mannequins is also proposed to ensure that the created mannequin matches the user input parameters and has good local deformation capability. Width and thickness parameters have been added for the torso position of the mannequin, which provides good scalability for creating a mannequin based on 2D anthropometric measurements. The accuracy, flexibility and reliability of the reconstructed method are analyzed through series of performed experiments. An innovative application of personalized mannequin customization under clothing combining Kinect and multi-sensor information acquisition system and a semantic parameter extension method for skinned multi-person linear model body type are proposed, which proves the practicality and scalability of the proposed method.
C1 [Li, Xihang; Li, Guiqin; Lv, Jianping] Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
   [Li, Tiancai] Shanghai Araystar Co Ltd, Shanghai, Peoples R China.
   [Mitrouchev, Peter] Univ Grenoble Alpes, G SCOP, Grenoble, France.
C3 Shanghai University; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA);
   Centre National de la Recherche Scientifique (CNRS)
RP Li, GQ (corresponding author), Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
EM leeching@shu.edu.cn
OI Li, Guiqing/0000-0003-3620-5895
CR Alhwarin, 2018, INT JOINT C BIOMEDIC
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Alldieck Thiemo, 2021, INT C COMP VIS
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   [Anonymous], 2011, ACM Transactions on Graphics, DOI DOI 10.1145/2010324.1964973
   Briceno L, 2019, ADV INTELL SYST, V822, P224, DOI 10.1007/978-3-319-96077-7_23
   Chen DY, 2023, VISUAL COMPUT, V39, P1893, DOI 10.1007/s00371-022-02453-x
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Choutas Vasileios, 2020, ECCV, P2
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Ding YY, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S2-S12
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Hartmann AK, 2020, J STAT MECH-THEORY E, V2020, DOI 10.1088/1742-5468/ab7c5f
   He QZ, 2018, IET COMPUT VIS, V12, P553, DOI 10.1049/iet-cvi.2017.0403
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hsiao SW, 2013, COMPUT AIDED DESIGN, V45, P1426, DOI 10.1016/j.cad.2013.06.012
   Hu PP, 2018, INT J CLOTH SCI TECH, V30, P159, DOI 10.1108/IJCST-05-2017-0067
   ISO, 2017, ISO 855
   Jain A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866174
   Jiang, 2022, P IEEECVF C COMPUTER
   Li XH, 2022, TEXT RES J, V92, P3750, DOI 10.1177/00405175221093663
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lu FX, 2018, VISUAL COMPUT, V34, P753, DOI 10.1007/s00371-018-1540-8
   Ma, 2021, 2021 4 INT C INFORM
   Osman A.A.A., 2020, ECCV
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Saito S., 2019, P IEEECVF INT C COMP
   Segal MR, 2004, Machine Learning Benchmarks and Random Forest Regression
   Seo Hyewon., 2003, Proceedings of the 2003 Symposium on Interactive 3D Graphics, P19, DOI [10.1145/641480.641487, DOI 10.1145/641480.641487]
   Song, 2018, SEMANTIC PARAMETRIC
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang SH, 2019, J PETROL SCI ENG, V174, P682, DOI 10.1016/j.petrol.2018.11.076
   Xie HY, 2020, TEXT RES J, V90, P937, DOI 10.1177/0040517519883957
   Xu, 2011, J TEXT APPAR TECHNOL, V2, P1
   Xu HY, 2020, PROC CVPR IEEE, P6183, DOI 10.1109/CVPR42600.2020.00622
   Yang YP, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON 3D VISION, VOL. 2, P41, DOI 10.1109/3DV.2014.47
   Zanfir Andrei, 2020, ECCV
   Zeng, 2018, 3D HUMAN BODY RESHAP
   Zhang, 2017, 2017 IEEE C COMPUTER
   Zhang YZ, 2015, VISUAL COMPUT, V31, P1615, DOI 10.1007/s00371-014-1043-1
   Zhao TH, 2019, IEEE T MULTIMEDIA, V21, P114, DOI 10.1109/TMM.2018.2844087
   Zhou SZ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778863
NR 43
TC 4
Z9 4
U1 2
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2023
VL 39
IS 12
BP 6435
EP 6458
DI 10.1007/s00371-022-02738-1
EA DEC 2022
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X7HK1
UT WOS:000896503900002
DA 2024-07-18
ER

PT J
AU Artuger, F
   Özkaynak, F
AF Artuger, Firat
   Ozkaynak, Fatih
TI Chaotic quantization based JPEG for effective compression of whole slide
   images
SO VISUAL COMPUTER
LA English
DT Article
DE Chaos; Compression; Digital pathology; JPEG; Whole slide image
ID PATHOLOGY; MICROSCOPY
AB In today's digital world, effectively transferring data from one point to another is an important problem. For this reason, the development of various new compression algorithms and making existing solutions more effective are examined in detail by researchers. In this study, a new method is proposed to improve the performance of JPEG algorithm. The proposed method includes an approach based on chaotic systems. Chaotic systems contain a strong entropy source. This powerful source of entropy has strong practical applications in obtaining statistically robust random values. In this study, a method is proposed to obtain quantization tables effectively by taking advantage of this potential of chaotic systems. The obtained results showed that the compression performance can be increased at the same quality factors. The proposed approach has been tested on the whole slide image (WSI) dataset. Looking at the analysis results, an average of 2.43% higher accuracy was achieved compared to the JPEG algorithm. It is thought that these results can provide an advantage especially in transferring high-dimensional images such as the DICOM standard, where the JPEG algorithm is used in practical applications.
C1 [Artuger, Firat] Munzur Univ, Dept Comp Engn, TR-62200 Tunceli, Turkey.
   [Ozkaynak, Fatih] Brat Univ, Dept Software Engn, TR-23119 Elazig, Turkey.
C3 Munzur University
RP Artuger, F (corresponding author), Munzur Univ, Dept Comp Engn, TR-62200 Tunceli, Turkey.
EM firatartuger@munzunedu.tr; ozkaynak@firat.edu.tr
RI artuğer, fırat/AET-3815-2022
FU Scientific and Technological Research Council of Turkey [122E337]
FX Fatih Ozkaynak was supported in part by the Scientific and Technological
   Research Council of Turkey under Grant 122E337.
CR Açikkapi MS, 2021, IEEE ACCESS, V9, P1482, DOI 10.1109/ACCESS.2020.3046470
   [Anonymous], WEBPAGE2
   [Anonymous], WEBPAGE1
   Aresta G, 2019, MED IMAGE ANAL, V56, P122, DOI 10.1016/j.media.2019.05.010
   Artuger F, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040571
   Aswolinskiy W, 2021, PRO BIOMED OPT IMAG, V11603, DOI 10.1117/12.2581943
   Barisoni L, 2016, MODERN PATHOL, V29, P671, DOI 10.1038/modpathol.2016.58
   Barker J, 2016, MED IMAGE ANAL, V30, P60, DOI 10.1016/j.media.2015.12.002
   Ben-Gal I, 2005, IEEE T RELIAB, V54, P381, DOI 10.1109/TR.2005.853280
   Bhatt AR, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.348
   Bug D., 2020, BILDVERARBEITUNG F R, P315
   Cagnazzo M., 2007, J IMAGE VIDEO PROCES, V2007, P19
   Dong YH, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P224, DOI 10.1109/BHI.2016.7455875
   Dov D, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101814
   Doyle S, 2010, I S BIOMED IMAGING, P1313, DOI 10.1109/ISBI.2010.5490238
   Farahani N, 2015, PATHOL LAB MED INT, V7, P23, DOI 10.2147/PLMI.S59826
   Ferreira R, 1997, J AM MED INFORM ASSN, P449
   Ginsburg SB, 2016, IEEE T MED IMAGING, V35, P76, DOI 10.1109/TMI.2015.2456188
   González-Conejero J, 2010, IEEE GEOSCI REMOTE S, V7, P251, DOI 10.1109/LGRS.2009.2032370
   Hacking S, 2020, PATHOL RES PRACT, V216, DOI 10.1016/j.prp.2020.153233
   Hamilton PW, 2012, APMIS, V120, P305, DOI 10.1111/j.1600-0463.2011.02869.x
   Helin Henrik, 2018, J Pathol Inform, V9, P20, DOI 10.4103/jpi.jpi_69_17
   Hernández-Cabronero M, 2019, IEEE T MED IMAGING, V38, P21, DOI 10.1109/TMI.2018.2852685
   Hernández-Cabronero M, 2016, IEEE IMAGE PROC, P2370, DOI 10.1109/ICIP.2016.7532783
   Holzinger A., 2020, Artificial Intelligence and Machine Learning for Digital Pathology: State-of-the-Art and Future Challenges
   Hosseini M, 2016, INFORMATION, V7, DOI 10.3390/info7040056
   Jeong GM., 2005, ADV MULTIMEDIA INFOR, P681
   Jiang YH, 2022, IEEE DATA COMPR CONF, P458, DOI 10.1109/DCC52660.2022.00069
   Jiang YB, 2011, CONF REC ASILOMAR C, P225, DOI 10.1109/ACSSC.2011.6189990
   Johnson JP, 2011, IEEE T MED IMAGING, V30, P306, DOI 10.1109/TMI.2010.2077308
   Kalinski T, 2008, AM J CLIN PATHOL, V130, P259, DOI 10.1309/QAM22Y85QCV5JM47
   Kalinski T, 2009, HUM PATHOL, V40, P998, DOI 10.1016/j.humpath.2008.12.010
   Kalra S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101757
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01905-z
   Kong J, 2009, PATTERN RECOGN, V42, P1080, DOI 10.1016/j.patcog.2008.10.035
   Kumar Balasubramanian Vinoth, 2015, International Journal of Advanced Intelligence Paradigms, V7, P111
   Li B, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101938
   Liu TL, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117643
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   Muhammad ZMZ, 2020, IEEE ACCESS, V8, P56581, DOI 10.1109/ACCESS.2020.2982827
   Mukhopadhyay S, 2018, AM J SURG PATHOL, V42, P39, DOI 10.1097/PAS.0000000000000948
   Niazi MKK, 2019, ARTIF INTELL MED, V95, P82, DOI 10.1016/j.artmed.2018.09.002
   Niazi MKK, 2016, PROC SPIE, V9791, DOI 10.1117/12.2216967
   Ozer AB, 2010, EXPERT SYST APPL, V37, P4632, DOI 10.1016/j.eswa.2009.12.045
   Pantanowitz Liron, 2018, J Pathol Inform, V9, P40, DOI 10.4103/jpi.jpi_69_18
   PETERSON HA, 1991, P SOC PHOTO-OPT INS, V1453, P210, DOI 10.1117/12.44357
   PetersonH A., 1992, SOC INFORM DISPLAY D
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P700, DOI 10.1109/83.334973
   Rodrigues VF, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105403
   Salomon D., 2008, A concise introduction to data compression, DOI [10.1007/978-1-84800-072-8, DOI 10.1007/978-1-84800-072-8]
   Sanchez V, 2015, INT CONF ACOUST SPEE, P1250, DOI 10.1109/ICASSP.2015.7178170
   Sharma A, 2012, ANAL CELL PATHOL, V35, P101, DOI [10.1155/2012/960684, 10.3233/ACP-2011-0035]
   Snead DRJ, 2016, HISTOPATHOLOGY, V68, P1063, DOI 10.1111/his.12879
   Sood RR, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101957
   Srinidhi CL, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101813
   Strogatz SH, 2001, NONLINEAR DYNAMICS C
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Taubman D., 2012, JPEG2000: image compression fundamentals, standards and practice, V642
   Tsuneki M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030768
   Unser M, 2003, IEEE T IMAGE PROCESS, V12, P1080, DOI 10.1109/TIP.2003.812329
   Vahadane A, 2016, IEEE T MED IMAGING, V35, P1962, DOI 10.1109/TMI.2016.2529665
   van Rijthoven M, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101890
   Veta M, 2019, MED IMAGE ANAL, V54, P111, DOI 10.1016/j.media.2019.02.012
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang CW, 2022, MED IMAGE ANAL, V75, DOI 10.1016/j.media.2021.102270
   Wang SJ, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101549
   Wang XY, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101914
   Watson A.B., 1993, SID INT S, V24, P946
   Xiang Y, 2021, ULTRAMICROSCOPY, V220, DOI 10.1016/j.ultramic.2020.113146
   Yao H, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102795
   Zarella MD, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.4.047502
   Zhang L, 2015, IEEE DATA COMPR CONF, P233, DOI 10.1109/DCC.2015.33
   Zheng YS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102308
NR 73
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD NOV
PY 2023
VL 39
IS 11
BP 5609
EP 5623
DI 10.1007/s00371-022-02684-y
EA OCT 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA W5SX6
UT WOS:000864059700003
DA 2024-07-18
ER

PT J
AU Beacco, A
   Gallego, J
   Slater, M
AF Beacco, Alejandro
   Gallego, Jaime
   Slater, Mel
TI 3D objects reconstruction from frontal images: an example with guitars
SO VISUAL COMPUTER
LA English
DT Article
DE 3D guitar reconstruction; Guitar segmentation; 3D objects reconstruction
AB This work deals with the automatic 3D reconstruction of objects from frontal RGB images. This aims at a better understanding of the reconstruction of 3D objects from RGB images and their use in immersive virtual environments. We propose a complete workflow that can be easily adapted to almost any other family of rigid objects. To explain and validate our method, we focus on guitars. First, we detect and segment the guitars present in the image using semantic segmentation methods based on convolutional neural networks. In a second step, we perform the final 3D reconstruction of the guitar by warping the rendered depth maps of a fitted 3D template in 2D image space to match the input silhouette. We validated our method by obtaining guitar reconstructions from real input images and renders of all guitar models available in the ShapeNet database. Numerical results for different object families were obtained by computing standard mesh evaluation metrics such as Intersection over Union, Chamfer Distance, and the F-score. The results of this study show that our method can automatically generate high-quality 3D object reconstructions from frontal images using various segmentation and 3D reconstruction techniques.
C1 [Beacco, Alejandro; Gallego, Jaime; Slater, Mel] Univ Barcelona, EventLab, Barcelona, Spain.
C3 University of Barcelona
RP Gallego, J (corresponding author), Univ Barcelona, EventLab, Barcelona, Spain.
EM abeacco@ub.edu; jgallego@ub.edu; melslater@ub.edu
RI Gallego, Jaime/AAC-3603-2021
OI Gallego, Jaime/0000-0003-3332-619X
FU European Research Council (ERC) Advanced Grant Moments in Time in
   Immersive Virtual Environments (MoTIVE) [742989]
FX This work is funded by the European Research Council (ERC) Advanced
   Grant Moments in Time in Immersive Virtual Environments (MoTIVE) Number
   742989.
CR Badrinarayanan V., ARXIV
   Beacco A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/VR50410.2021.00078
   Beacco A, 2020, IEEE IMAGE PROC, P2785, DOI 10.1109/ICIP40778.2020.9191091
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chang A., ARXIV
   Chen LJ, 2018, ADV NEUR IN, V31
   Chollet F., ARXIV
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Fan H., 2016, ARXIV
   FRASER AM, 1986, PHYS REV A, V33, P1134, DOI 10.1103/PhysRevA.33.1134
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Gkioxari G., 2020, ARXIV
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Groueix T., ARXIV
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   He Kaiming, 2016, arXiv
   Hepperle D, 2022, VISUAL COMPUT, V38, P1227, DOI 10.1007/s00371-021-02151-0
   Jiang Y, 2020, PROC CVPR IEEE, P1248, DOI 10.1109/CVPR42600.2020.00133
   Kato H., ARXIV
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kong C, 2017, PROC CVPR IEEE, P5603, DOI 10.1109/CVPR.2017.594
   Le Meur O, 2013, IEEE T IMAGE PROCESS, V22, P3779, DOI 10.1109/TIP.2013.2261308
   Li YY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818071
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Opara A., 2019, MORE THIS PLEASE TEX
   Pan JY, 2019, IEEE I CONF COMP VIS, P9963, DOI 10.1109/ICCV.2019.01006
   Pontes JK, 2017, INT CONF 3D VISION, P88, DOI 10.1109/3DV.2017.00020
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Richter S., ARXIV
   Ronneberger O., arXiv
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitzmann V., ARXIV
   Sun K., ARXIV
   Tatarchenko M., ARXIV
   Tatarchenko M., 2019, ARXIV
   Tono I, 2020, PROCEEDINGS OF 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL PROBLEMS OF ELECTRICAL ENGINEERING (CPEE), DOI 10.1109/cpee50798.2020.9238720
   Tulsiani S, 2017, IEEE T PATTERN ANAL, V39, P719, DOI 10.1109/TPAMI.2016.2574713
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wells W M 3rd, 1996, Med Image Anal, V1, P35
   Wen C, 2019, IEEE I CONF COMP VIS, P1042, DOI 10.1109/ICCV.2019.00113
   Weng CY, 2019, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR.2019.00606
   Wu JJ, 2016, ADV NEUR IN, V29
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
   Zou QF, 2021, VISUAL COMPUT, V37, P1743, DOI 10.1007/s00371-020-01935-0
NR 50
TC 2
Z9 2
U1 7
U2 39
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD NOV
PY 2023
VL 39
IS 11
BP 5421
EP 5436
DI 10.1007/s00371-022-02669-x
EA SEP 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA W5SX6
UT WOS:000854726000001
PM 37899958
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Luan, HP
   Toyoura, M
   Gu, RS
   Terada, T
   Wu, HY
   Funatomi, T
   Xu, G
AF Luan, Haipeng
   Toyoura, Masahiro
   Gu, Renshu
   Terada, Takamasa
   Wu, Haiyan
   Funatomi, Takuya
   Xu, Gang
TI Textile image recoloring by polarization observation
SO VISUAL COMPUTER
LA English
DT Article
DE Textile recoloring; Polarization; Image processing; Image segmentation
ID OPTIMIZATION
AB In this paper, a novel method for recoloring a textile image with polarization observation is proposed. By polarization image analysis, the proposed method can easily catch the specular reflection of yarns. Polarization image analysis also contributes to highly accurate region segmentation of warp and weft yarns. The conventional method using convex-hull assumes that an image is composed of at least four color elements. Our proposed method can overcome the limitations of too few textile colors. Our method can process textile images composed of only two color elements while existing methods struggle. In addition, we show how to generate images recolored both correctly and naturally through interactive alpha-matting, instead of aiming only at efficiency in recoloring, which sometimes results in unnatural images. A user study is performed to test the GUI indicators and the naturalness of the recoloring results. Extensive experiments show that the proposed method generates far better textile recoloring results compared to existing approaches.
C1 [Luan, Haipeng; Gu, Renshu; Wu, Haiyan; Xu, Gang] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Toyoura, Masahiro; Terada, Takamasa] Univ Yamanashi, Dept Comp Sci & Engn, Kofu, Yamanashi, Japan.
   [Funatomi, Takuya] Nara Inst Sci & Technol, Ikoma, Nara 6300192, Japan.
C3 Hangzhou Dianzi University; University of Yamanashi; Nara Institute of
   Science & Technology
RP Xu, G (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.; Toyoura, M (corresponding author), Univ Yamanashi, Dept Comp Sci & Engn, Kofu, Yamanashi, Japan.
EM mtoyoura@yamanashi.ac.jp; gxu@hdu.edu.cn
RI Funatomi, Takuya/K-5919-2018; wu, haiyan/KHX-9321-2024; Xu,
   Gang/C-9762-2013
OI Funatomi, Takuya/0000-0001-5588-5932; Wu, Haiyan/0000-0002-0084-0697;
   Xu, Gang/0000-0003-3557-9529; Toyoura, Masahiro/0000-0002-5897-7573
FU National Key Research and Development Program of China [2020YFB
   1709402]; NSFC-Zhejiang Joint Fund for the Integration of
   Industrialization and Informatization [U1909210]; Zhejiang Provincial
   Science and Technology Program in China [2021C01108, LQ22F020026]; China
   National Natural Science Foundation [61902099]; Zhejiang Laboratory
   Tianshu Open Source AI Platform; Fundamental Research Funds for the
   Provincial Universities of Zhejiang [GK219909299001-028]
FX The authors would like to thank the anonymous reviewers for providing
   constructive suggestions, that contributed to highly improve this work.
   This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFB 1709402; in part by the
   NSFC-Zhejiang Joint Fund for the Integration of Industrialization and
   Informatization under Grant U1909210; in part by the Zhejiang Provincial
   Science and Technology Program in China under Grant 2021C01108; in part
   by the China National Natural Science Foundation under Grant 61902099;
   in part by the Zhejiang Laboratory Tianshu Open Source AI Platform; in
   part by the Zhejiang Provincial Science and Technology Program in China
   under Grant LQ22F020026; in part by the Fundamental Research Funds for
   the Provincial Universities of Zhejiang under Grant GK219909299001-028.
CR Afifi M., 2019, EUROGRAPHICS SHORT P, P33
   Atkinson GA, 2007, IEEE T PATTERN ANAL, V29, P2001, DOI 10.1109/TPAMI.2007.1099
   Bueno B, 2020, BUILD ENVIRON, V184, DOI 10.1016/j.buildenv.2020.107227
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Dobashi Y, 2019, VISUAL COMPUT, V35, P175, DOI 10.1007/s00371-017-1455-9
   Du ZJ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459675
   GRANT L, 1987, ENVIRON EXP BOT, V27, P139, DOI 10.1016/0098-8472(87)90064-5
   He MM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3292482
   Huang YF, 2018, COMPUT GRAPH FORUM, V37, P421, DOI 10.1111/cgf.13579
   Jacques SL, 2002, J BIOMED OPT, V7, P329, DOI 10.1117/1.1484498
   Kang JM, 2018, IEEE IMAGE PROC, P2252, DOI 10.1109/ICIP.2018.8451526
   Kuo CFJ, 2012, TEXT RES J, V82, P571, DOI 10.1177/0040517511435012
   Leaf J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275105
   Li ZQ, 2018, APPL OPTICS, V57, P1011, DOI 10.1364/AO.57.001011
   Liu SG, 2015, TEXT RES J, V85, P1972, DOI 10.1177/0040517514561919
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Mokrzycki W.S., 2011, Machine Graphics and Vision, V20, P383
   Monzón MD, 2019, MATERIALS, V12, DOI 10.3390/ma12071134
   Musialski P, 2013, VISUAL COMPUT, V29, P1173, DOI 10.1007/s00371-012-0761-5
   Nguyen RMH, 2014, COMPUT GRAPH FORUM, V33, P319, DOI 10.1111/cgf.12500
   Pitie F., 2007, P IET 4 EUR C VIS ME VIS MEDIA PROD, P23
   Porter T., 1984, Computers & Graphics, V18, P253
   POSTLE R, 1989, TEXT RES J, V59, P448, DOI 10.1177/004051758905900803
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Somodi Z, 2010, TEXT RES J, V80, P1255, DOI 10.1177/0040517509357655
   Tan JC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275054
   Tsekouras GE, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082740
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Zhao S., 2016, ACM T GRAPHIC, V35, P1, DOI [DOI 10.1145/2897824.2925932, 10.1145/2897824.2925932]
   Zhu ZY, 2021, VISUAL COMPUT, V37, P2999, DOI 10.1007/s00371-021-02240-0
   Zou Z, 2017, COLOR RES APPL, V42, P115, DOI 10.1002/col.22023
NR 31
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2023
VL 39
IS 9
BP 4351
EP 4370
DI 10.1007/s00371-022-02595-y
EA AUG 2022
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8PV6
UT WOS:000836989800001
DA 2024-07-18
ER

PT J
AU Upadhyay, K
   Agrawal, M
   Vashist, P
AF Upadhyay, Kamini
   Agrawal, Monika
   Vashist, Praveen
TI Learning multi-scale deep fusion for retinal blood vessel extraction in
   fundus images
SO VISUAL COMPUTER
LA English
DT Article
DE Fundus; Multi-scale; Wavelet; Characteristic patches; U-net; Deep
   learning
ID MATCHED-FILTER; SEGMENTATION; MODEL
AB Segmentation of retinal blood vessels is crucial in the automated diagnosis of many retinal and cardiovascular diseases. The process of precise vessel extraction using fundus images is still a challenge due to spatially varying vessel-width and non-homogeneous retinal backgrounds. This work targets the challenges mentioned above with an adaptive multi-scale decomposition of the input image and a novel characteristic patch-based deep network training. In order to enhance vessels of different widths, we use the observed field of view of the input image to estimate the most significant scales for Gabor decomposition. Enhanced vessel maps corresponding to real, imaginary, and absolute coefficients at the estimated scales are linearly combined using a trainable 1 x 1 convolutional layer of U-net. Moreover, the 'characteristic patch-based training' uses 'random' and 'specific' patches to learn vessels in non-homogeneous retinal backgrounds. The proposed algorithm minimizes false negatives and extracts promising vessel maps in various challenging regions of the retina. The significant improvement in accuracy, sensitivity and AUC compared to other state-of-the-art values proves the proposed method's outstanding performance.
C1 [Upadhyay, Kamini; Agrawal, Monika] IIT Delhi, Ctr Appl Res Elect, New Delhi, India.
   [Vashist, Praveen] AIIMS, Dr RP Ctr Ophthalm Sci, Community Ophthalmol, New Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi; All India Institute of Medical Sciences
   (AIIMS) New Delhi; Dr. Rajendra Prasad Centre for Ophthalmic Sciences
RP Upadhyay, K (corresponding author), IIT Delhi, Ctr Appl Res Elect, New Delhi, India.
EM kaminiup23@gmail.com
CR Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Alom MZ, 2018, arXiv
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Chatziralli IP, 2012, OPEN OPHTHALMOL J, V6, P4, DOI 10.2174/1874364101206010004
   Delibasis KK, 2010, COMPUT METH PROG BIO, V100, P108, DOI 10.1016/j.cmpb.2010.03.004
   Fraz MM, 2013, J DIGIT IMAGING, V26, P274, DOI 10.1007/s10278-012-9513-3
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Guan S, 2020, IEEE J BIOMED HEALTH, V24, P568, DOI 10.1109/JBHI.2019.2912935
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Huang LY, 2022, VISUAL COMPUT, V38, P135, DOI 10.1007/s00371-020-02008-y
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Kim JU, 2017, IEEE ENG MED BIO, P685, DOI 10.1109/EMBC.2017.8036917
   Lahiri A, 2017, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2017.110
   Li LZ, 2020, IEEE WINT CONF APPL, P3645, DOI 10.1109/WACV45572.2020.9093621
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Lyu CZ, 2022, VISUAL COMPUT, V38, P345, DOI 10.1007/s00371-020-02018-w
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Nagashree N., 2021, 2021 3rd International Conference on Computer Communication and the Internet (ICCCI), P23, DOI 10.1109/ICCCI51764.2021.9486783
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Odstrcilik J, 2013, IET IMAGE PROCESS, V7, P373, DOI 10.1049/iet-ipr.2012.0455
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Remeseiro B, 2021, VISUAL COMPUT, V37, P1247, DOI 10.1007/s00371-020-01863-z
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roychowdhury S, 2015, IEEE T BIO-MED ENG, V62, P1738, DOI 10.1109/TBME.2015.2403295
   Saranya P, 2022, VISUAL COMPUT, V38, P977, DOI 10.1007/s00371-021-02062-0
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Sreejini KS, 2015, EGYPT INFORM J, V16, P253, DOI 10.1016/j.eij.2015.06.004
   Upadhyay K, 2021, EUR SIGNAL PR CONF, P1304, DOI 10.23919/Eusipco47968.2020.9287387
   Upadhyay K, 2020, IET IMAGE PROCESS, V14, P2616, DOI 10.1049/iet-ipr.2019.0969
   Upadhyay Kamini, 2020, 2020 INT C SIGNAL PR, P1, DOI DOI 10.1109/SPCOM50965.2020.9179575
   Wang D, 2021, VISUAL COMPUT, V37, P1101, DOI 10.1007/s00371-020-01855-z
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   Xue DX, 2016, J MED BIOL ENG, V36, P755, DOI 10.1007/s40846-016-0182-4
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhang YS, 2018, LECT NOTES COMPUT SC, V11071, P83, DOI 10.1007/978-3-030-00934-2_10
NR 39
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2023
VL 39
IS 10
BP 4445
EP 4457
AR s00371-022-02600-4
DI 10.1007/s00371-022-02600-4
EA JUL 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T1GK8
UT WOS:000832801400001
DA 2024-07-18
ER

PT J
AU Liu, H
   Yuan, MK
   Wang, T
   Ren, PR
   Yan, DM
AF Liu, Hang
   Yuan, Mengke
   Wang, Tong
   Ren, Peiran
   Yan, Dong-Ming
TI LIST: low illumination scene text detector with automatic feature
   enhancement
SO VISUAL COMPUTER
LA English
DT Article
DE Low illumination; Scene image text detection; Data synthesis; Feature
   enhancement
AB Low illumination, under which discriminative clues are buried in the captured images, is an under-investigated but noteworthy issue in wild scene text detection. Existing deep learning approaches suffer from the scarcity of training data and illumination-sensitive feature representation. To address these issues, we propose a Low Illumination Scene Text (LIST) Detector training with authentic synthetic data and integrating dedicated feature enhancement modules. Specifically, we adopt a lightweight and non-reference low-light scene text image synthesis network to acquire adequate training data through pixel-wisely adjusting the dynamic range curve of normal-light images. Moreover, illumination invariant feature representation is learned through dual path feature extraction stem with intensity adjusted inputs, and feature fusion branch with automatically designed fusion cell. In the end, the enhanced feature is fed into a segmentation-based layer to localize arbitrary shape text instances. We construct a labeled real-world scene text image dataset called "DarkText" and conduct extensive experiments to validate the advantages of our proposed framework over state-of-the-art competitors.
C1 [Liu, Hang; Wang, Tong] Minist Educ, Engn Res Ctr Digitized Text & Apparel Technol, Shanghai 201620, Peoples R China.
   [Liu, Hang; Wang, Tong] Donghua Univ, Coll Informat Sci & Technol, Shanghai 201620, Peoples R China.
   [Yuan, Mengke; Yan, Dong-Ming] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   [Yuan, Mengke; Yan, Dong-Ming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Ren, Peiran] Alibaba Grp, Hangzhou, Zhejiang, Peoples R China.
C3 Donghua University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS; Alibaba Group
RP Wang, T (corresponding author), Minist Educ, Engn Res Ctr Digitized Text & Apparel Technol, Shanghai 201620, Peoples R China.; Wang, T (corresponding author), Donghua Univ, Coll Informat Sci & Technol, Shanghai 201620, Peoples R China.
EM mengke.yuan@nlpr.ia.ac.cn; wangtong@dhu.edu.cn
OI Yuan, Mengke/0000-0001-9277-2654
FU National Key R&D Program of China [2019YFB2204104]; National Natural
   Science Foundation of China [62172415, 62102414, 52175493]; Alibaba
   Group through Alibaba Innovative Research Program
FX This work was supported in part by the National Key R&D Program of China
   (No.2019YFB2204104) and the National Natural Science Foundation of China
   (Nos. 62172415, 62102414, 52175493), and the Alibaba Group through
   Alibaba Innovative Research Program.
CR Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Liao MH, 2020, AAAI CONF ARTIF INTE, V34, P11474
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liu H., 2018, PROC INT C LEARN REP
   Liu JY, 2021, INT J COMPUT VISION, V129, P1153, DOI 10.1007/s11263-020-01418-8
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Raisi Z., 2020, ARXIV200604305
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Xiao YX, 2020, IEEE ACCESS, V8, P123075, DOI 10.1109/ACCESS.2020.3007610
   Xiong YY, 2021, PROC CVPR IEEE, P3824, DOI 10.1109/CVPR46437.2021.00382
   Xu JZ, 2023, COMPUT VIS MEDIA, V9, P335, DOI 10.1007/s41095-022-0277-5
   Xue ML, 2021, IEEE T MULTIMEDIA, V23, P2706, DOI 10.1109/TMM.2020.3015037
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yuan MK, 2019, J COMPUT SCI TECH-CH, V34, P550, DOI 10.1007/s11390-019-1926-8
   Yuliang L., 2017, ARXIV171202170
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu YQ, 2021, PROC CVPR IEEE, P3122, DOI 10.1109/CVPR46437.2021.00314
NR 37
TC 4
Z9 4
U1 3
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2022
VL 38
IS 9-10
SI SI
BP 3231
EP 3242
DI 10.1007/s00371-022-02570-7
EA JUL 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4N3NE
UT WOS:000826120500001
DA 2024-07-18
ER

PT J
AU Reimann, M
   Buchheim, B
   Semmo, A
   Döllner, J
   Trapp, M
AF Reimann, Max
   Buchheim, Benito
   Semmo, Amir
   Doellner, Juergen
   Trapp, Matthias
TI Controlling strokes in fast neural style transfer using content
   transforms
SO VISUAL COMPUTER
LA English
DT Article; Early Access
AB Fast style transfer methods have recently gained popularity in art-related applications as they make a generalized real-time stylization of images practicable. However, they are mostly limited to one-shot stylizations concerning the interactive adjustment of style elements. In particular, the expressive control over stroke sizes or stroke orientations remains an open challenge. To this end, we propose a novel stroke-adjustable fast style transfer network that enables simultaneous control over the stroke size and intensity, and allows a wider range of expressive editing than current approaches by utilizing the scale-variance of convolutional neural networks. Furthermore, we introduce a network-agnostic approach for style-element editing by applying reversible input transformations that can adjust strokes in the stylized output. At this, stroke orientations can be adjusted, and warping-based effects can be applied to stylistic elements, such as swirls or waves. To demonstrate the real-world applicability of our approach, we present StyleTune, a mobile app for interactive editing of neural style transfers at multiple levels of control. Our app allows stroke adjustments on a global and local level. It furthermore implements an on-device patch-based upsampling step that enables users to achieve results with high output fidelity and resolutions of more than 20 megapixels. Our approach allows users to art-direct their creations and achieve results that are not possible with current style transfer applications.
C1 [Reimann, Max; Buchheim, Benito; Doellner, Juergen; Trapp, Matthias] Univ Potsdam, Hasso Plattner Inst, Potsdam, Germany.
   [Semmo, Amir] DigitalMasterpieces GmbH, Potsdam, Germany.
C3 University of Potsdam
RP Reimann, M (corresponding author), Univ Potsdam, Hasso Plattner Inst, Potsdam, Germany.
EM max.reimann@hpi.uni-potsdam.de; amir.semmo@digitalmasterpieces.com
RI Trapp, Matthias/J-4456-2014; Reimann, Max/JDH-5860-2023; Semmo,
   Amir/KPA-5814-2024
OI Trapp, Matthias/0000-0003-3861-5759; Reimann, Max/0000-0003-2146-4229; 
FU German Federal Ministry of Education and Research (BMBF) [01IS18092,
   01IS19006]; Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. This work was
   partially funded by the German Federal Ministry of Education and
   Research (BMBF) through grants 01IS18092 ("mdViPro") and 01IS19006
   ("KI-LAB-ITSE").
CR Amato G., 2019, ARXIV PREPRINT ARXIV
   Babaeizadeh M., 2020, 8 INT C LEARNING REP
   Barnes C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766934
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Chen DD, 2018, PROC CVPR IEEE, P6654, DOI 10.1109/CVPR.2018.00696
   Dapkus D., How to transfer styles to images with Adobe Pho- toshop
   Dumoulin V.., 2017, P INT C LEARN REPR I
   Fiser J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925948
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gobbi DG, 2003, COMPUT MED IMAG GRAP, V27, P255, DOI 10.1016/S0895-6111(02)00091-5
   Gu SY, 2018, PROC CVPR IEEE, P8222, DOI 10.1109/CVPR.2018.00858
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isenberg T., 2016, PROC NPAR SER EXPRES, P8996
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kingma DP., 2014, ADAM METHOD STOCHAST
   Klingbeil M, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3132803
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Li YJ, 2017, ADV NEUR IN, V30
   Li YJ, 2016, LECT NOTES COMPUT SC, V9908, P154, DOI 10.1007/978-3-319-46493-0_10
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Marques O, 2020, SPRINGERBRIEF COMPUT, P29, DOI 10.1007/978-3-030-54032-6_4
   Mohanty S, 2012, J PHYS CONF SER, V368, DOI 10.1088/1742-6596/368/1/012024
   Moiseenkov A., 2021, PRISMA
   Pasewaldt S., 2016, SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications, P1
   Paszke A, 2019, ADV NEUR IN, V32
   Reimann M, 2019, VISUAL COMPUT, V35, P1531, DOI 10.1007/s00371-019-01654-1
   Reimann M, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P9, DOI 10.1109/CW.2018.00016
   Semmo Amir., 2017, Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, V5, P1, DOI DOI 10.1145/3092919.3092920
   Simonyan K, 2015, IEEE INT C ICLR
   Su H, 2019, PROC CVPR IEEE, P11158, DOI 10.1109/CVPR.2019.01142
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Wu H, 2019, NEUROCOMPUTING, V370, P39, DOI 10.1016/j.neucom.2019.08.075
   Wu HK, 2018, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2018.00197
   Yang LC, 2018, COMPUT GRAPH FORUM, V37, P97, DOI 10.1111/cgf.13551
   Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567
   Youssef V, 2017, RANDOM NUMBER GENERA
   Zhang H, 2019, LECT NOTES COMPUT SC, V11132, P349, DOI 10.1007/978-3-030-11018-5_32
   Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1
NR 47
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD 2022 JUN 8
PY 2022
DI 10.1007/s00371-077-07518-x
EA JUN 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1Y2JT
UT WOS:000807970000003
DA 2024-07-18
ER

PT J
AU Xia, SF
   Guo, ST
   Qu, Z
   Yang, YY
AF Xia, Shufang
   Guo, Songtao
   Qu, Zhong
   Yang, Yuanyuan
TI A coarse-to-fine ghost removal scheme for HDR imaging
SO VISUAL COMPUTER
LA English
DT Article
DE High dynamic range imaging; Deghosting; Registration; PatchMatch
ID QUALITY ASSESSMENT; FUSION; INFORMATION; IMAGES
AB Ghost removal in high dynamic range imaging is a challenging problem especially when relative camera or object motion exists. To solve the problem, an effective coarse-to-fine deghosting method combining registration and matching based on PatchMatch is proposed. Firstly, the coarse registration scheme based on Scale-Invariant Feature Transform is used to achieve the consistency of image scale space. Secondly, similarity measure of underlayer information is established by Mutual Information to realize fine registration. Thirdly, different from general distance measurement, structural similarity index measurement is employed to build the objective function to search for the best-matched patch in the fusion process. Experimental results demonstrate the algorithm can remove the ghost artifacts effectively. Furthermore, objective evaluations show that the algorithm accuracy has been improved comprehensively. Compared with the existing methods, the proposed algorithm can achieve a convincing result for dynamic senses, especially for large moving objects.
C1 [Xia, Shufang; Guo, Songtao] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
   [Xia, Shufang; Guo, Songtao; Qu, Zhong] Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
   [Guo, Songtao] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Yang, Yuanyuan] SUNY Stony Brook, Dept Elect Comp Engn, Stony Brook, NY 11794 USA.
C3 Southwest University - China; Chongqing University of Posts &
   Telecommunications; Chongqing University; State University of New York
   (SUNY) System; State University of New York (SUNY) Stony Brook
RP Guo, ST (corresponding author), Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
EM songtao_guo@163.com
RI yang, yuanyuan/HPG-2020-2023
OI Xia, Shufang/0000-0002-1372-3983; Yang, Yuanyuan
   Kara/0000-0001-7296-9222
FU National Natural Science Foundation of China [61772432, 61503309]
FX The work described in this paper was partially supported by the National
   Natural Science Foundation of China (61772432, 61503309).
CR [Anonymous], 2012, CAVAILABLE HDRPROCES
   Baroncini V., 2015, EUR SIGN PROC C NIC
   Gallo O., 2015, P IEEE C COMP VIS PA
   Heo YS, 2011, LECT NOTES COMPUT SC, V6495, P486, DOI 10.1007/978-3-642-19282-1_39
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Lee C, 2014, IEEE SIGNAL PROC LET, V21, P1045, DOI 10.1109/LSP.2014.2323404
   Lee S, 2018, LECT NOTES COMPUT SC, V11206, P613, DOI 10.1007/978-3-030-01216-8_37
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Niu YZ, 2021, IEEE T IMAGE PROCESS, V30, P3885, DOI 10.1109/TIP.2021.3064433
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Qin XM, 2015, IEEE T CYBERNETICS, V45, P1549, DOI 10.1109/TCYB.2014.2355140
   Rana A, 2020, IEEE T IMAGE PROCESS, V29, P1285, DOI 10.1109/TIP.2019.2936649
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Tursun OT, 2016, COMPUT GRAPH FORUM, V35, P139, DOI 10.1111/cgf.12818
   Wang L, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9958017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia XH, 2016, OPTIK, V127, P7762, DOI 10.1016/j.ijleo.2016.05.114
   Yan QS, 2019, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2019.00185
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Yin J., 2021, IEEE T PATTERN ANAL, V99, P1
   Zhang H, 2004, P SOC PHOTO-OPT INS, V5307, P38
NR 30
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2023
VL 39
IS 7
BP 2515
EP 2528
DI 10.1007/s00371-022-02475-5
EA MAY 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L4HX1
UT WOS:000797304800001
DA 2024-07-18
ER

PT J
AU Keshvarikhojasteh, H
   Mohammadzade, H
   Behroozi, H
AF Keshvarikhojasteh, Hassan
   Mohammadzade, Hoda
   Behroozi, Hamid
TI Temporal action localization using gated recurrent units
SO VISUAL COMPUTER
LA English
DT Article
DE Temporal action localization (TAL); Gated recurrent units (GRUs); Learn
   to rank (LTR)
AB Temporal action localization (TAL) task which is to predict the start and end of each action in a video along with the class label of the action has numerous applications in the real world. But due to the complexity of this task, acceptable accuracy rates have not been achieved yet, whereas this is not the case regarding the action recognition task. In this paper, we propose a new network based on gated recurrent unit (GRU) and two novel post-processing methods for TAL task. Specifically, we propose a new design for the output layer of the conventionally GRU resulting in the so-called GRU-Split network. Moreover, linear interpolation is used to generate the action proposals with precise start and end times. Finally, to rank the generated proposals appropriately, we use a Learn to Rank approach. We evaluated the performance of the proposed method on Thumos14 and ActivityNet-1.3 datasets. Results show the superiority of the performance of the proposed method compared to state of the art. Specifically in the mean Average Precision metric at Intersection over Union of 0.7 on Thumos14, we get 27.52% accuracy which is 5.12% better than that of state-of-the-art methods.
C1 [Keshvarikhojasteh, Hassan; Mohammadzade, Hoda; Behroozi, Hamid] Sharif Univ Technol, Tehran, Iran.
C3 Sharif University of Technology
RP Mohammadzade, H (corresponding author), Sharif Univ Technol, Tehran, Iran.
EM ha.keshvari@student.sharif.edu; hoda@sharif.edu; behroozi@sharif.edu
RI , Hoda/ABC-6387-2020
OI , Hoda/0000-0002-9852-5088; Behroozi, Hamid/0000-0001-9294-3134
CR [Anonymous], 2015, CORR
   Buch S., 2017, P IEEE C COMPUTER VI
   Burges C., 2005, P INT C MACHINE LEAR, P8996
   Caba Heilbron F., 2015, P IEEE C COMPUTER VI
   Cao Z., 2007, P INT C MACHINE LEAR
   Carreira J., 2017, P IEEE C COMPUTER VI
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen PH, 2020, IEEE T MULTIMEDIA, V22, P2723, DOI 10.1109/TMM.2019.2959977
   Chron G., 2015, P INT C COMPUTER VIS
   Devlin J., 2018, BERT PRE TRAINING DE
   Feichtenhofer C., 2016, P IEEE C COMPUTER VI
   Gao J., 2017, P INT C COMPUTER VIS
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao ZN, 2019, AAAI CONF ARTIF INTE, P8328
   Gong GQ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102850
   Gowda S.N., 2020, ARXIV PREPRINT ARXIV
   Herbrich R., 1999, P ICANN, P97102
   Huang J., 2018, P 32 AAAI C ARTIFICI
   Huang LJ, 2022, IEEE T IMAGE PROCESS, V31, P1504, DOI 10.1109/TIP.2021.3137649
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang Y.G., 2014, P EUROPEAN C COMPUTE
   Kalfaoglu M.E., 2008, ARXIV PREPRINT ARXIV
   Lejmi W., 2017, P INT C NATURAL COMP
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P4626
   Lin C., 2019, ARXIV PREPRINT ARXIV
   Lin T., 2019, P INT C COMPUTER VIS
   Lin T., 2018, P EUROPEAN C COMPUTE, P321
   Lin T., 2017, P ACM MULTIMEDIA C
   Liu J., 2016, P EUROPEAN C COMPUTE
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Liu Q., 2020, P 34 AAAI C ARTIFICI
   Liu S., 2020, P ASIAN C COMPUTER V
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Nallapati R., 2004, P SIGIR, P6471
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tran D., 2015, P INT C COMPUTER VIS
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang B., 2021, IEEE SIGNAL PROC LET, V28, P1, DOI [10.1109/LSP.2020.3037508, DOI 10.1109/LSP.2020.3037508]
   Wang B., 2021, IEEE T CIRC SYST VID
   Wang H., 2013, P IEEE C COMPUTER VI
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wang T., 2020, IEEE T CYBERNETICS, P112
   Xiong Y., 2017, CoRR
   Xu M., 2020, P IEEE C COMPUTER VI, P10156
   Yang L, 2020, IEEE T IMAGE PROCESS, V29, P8535, DOI 10.1109/TIP.2020.3016486
   Yao Y., 2017, P CVPR ACTIVITYNET C, P50
   Ye, 2018, P INT C MULTIMEDIA R
   Zeng R., 2019, P INT C COMPUTER VIS
   Zhao P., 2020, P EUROPEAN C COMPUTE
   Zhao Y., 2017, ARXIV PREPRINT ARXIV
   Zisserman, 2014, ADV NEURAL INFORM PR
NR 51
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2023
VL 39
IS 7
BP 2823
EP 2834
DI 10.1007/s00371-022-02495-1
EA MAY 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L4HX1
UT WOS:000796320900001
DA 2024-07-18
ER

PT J
AU Liu, CJ
   Liu, XQ
   Chen, C
   Wang, QK
AF Liu, Chaoji
   Liu, Xingqiao
   Chen, Chong
   Wang, Qiankun
TI Soft thresholding squeeze-and-excitation network for pose-invariant
   facial expression recognition
SO VISUAL COMPUTER
LA English
DT Article
DE Pose-invariant facial expression recognition; Squeeze-and-excitation
   (SE) block; Soft thresholding SE block; Deep residual networks
ID ATTENTION; MULTISCALE; CONTEXT
AB Pose-invariant facial expression recognition is one of the popular research directions within the field of computer vision, but pose variant usually change the facial appearance significantly, making the recognition results unstable from different perspectives. In this paper, a novel deep learning method, namely, soft thresholding squeeze-and-excitation (ST-SE) block, was proposed to extract salient features of different channels for pose-invariant FER. For the purpose of adapting to different pose-invariant facial images better, global average pooling (GAP) operation was adopted to compute the average value of each channel of the feature map. To enhance the representational power of the network, Squeeze-and-Excitation (SE) block was embedded into the nonlinear transformation layer to filter out the redundant feature information. To further shrink the significant features, the absolute values of GAP and SE were multiplied to calculate the threshold suitable for the current view. And the developed ST-SE block was inserted into ResNet50 for the evaluation of recognition performance. In this study, extensive experiments on four pose-invariant datasets were carried out, i.e., BU-3DFE, Multi-PIE, Pose-RAF-DB and Pose-AffectNet, and the influences of different environments, poses and intensities on expression recognition were specifically analyzed. The experimental results demonstrate the feasibility and effectiveness of our method.
C1 [Liu, Chaoji; Liu, Xingqiao; Chen, Chong; Wang, Qiankun] Jiangsu Univ, Coll Elect & Informat Engn, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Liu, XQ (corresponding author), Jiangsu Univ, Coll Elect & Informat Engn, Zhenjiang, Jiangsu, Peoples R China.
EM 1719618835@qq.com
RI chen, xian/KHW-2227-2024
FU National Natural Science Foundation of China [:31872399]; Advantage
   Discipline Construction Project (PAPD, No.6-2018) of Jiangsu University
FX National Natural Science Foundation of China (No:31872399), Advantage
   Discipline Construction Project (PAPD, No.6-2018) of Jiangsu University
CR Fan J., 2020, P INDIN, P573, DOI 10.1109/INDIN45582.2020.9442212
   Gera D, 2022, PATTERN RECOGN LETT, V155, P9, DOI 10.1016/j.patrec.2022.01.013
   Gera D, 2021, PATTERN RECOGN LETT, V145, P58, DOI 10.1016/j.patrec.2021.01.029
   Gogic I, 2020, VISUAL COMPUT, V36, P97, DOI 10.1007/s00371-018-1585-8
   Goh KM, 2020, VISUAL COMPUT, V36, P445, DOI 10.1007/s00371-018-1607-6
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu M, 2022, VISUAL COMPUT, V38, P2617, DOI 10.1007/s00371-021-02136-z
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jampour M., 2015, COMP VIS WINT WORKSH
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kumar S, 2021, VISUAL COMPUT, V37, P143, DOI 10.1007/s00371-019-01788-2
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Li YL, 2021, INT J PROD RES, V59, P3880, DOI 10.1080/00207543.2020.1753897
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu Y, 2021, NEUROCOMPUTING, V428, P92, DOI 10.1016/j.neucom.2020.11.022
   Liu YY, 2021, INFORM SCIENCES, V578, P195, DOI 10.1016/j.ins.2021.07.034
   Liu YY, 2018, IEEE INT CONF AUTOMA, P458, DOI 10.1109/FG.2018.00074
   Ma H, 2021, SIGNAL IMAGE VIDEO P, V15, P1507, DOI 10.1007/s11760-021-01883-9
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Shu X., 2021, EXPANSION SQUEEZE EX
   Shu XB, 2018, IEEE T PATTERN ANAL, V40, P905, DOI 10.1109/TPAMI.2017.2705122
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Wang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P238, DOI 10.1145/3343031.3350872
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang ZN, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107694
   Wu JL, 2017, NEUROCOMPUTING, V239, P143, DOI 10.1016/j.neucom.2017.02.012
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang FF, 2020, IEEE T IMAGE PROCESS, V29, P4445, DOI 10.1109/TIP.2020.2972114
   Zhang FF, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3176646
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
   Zhao ZQ, 2021, IEEE T IMAGE PROCESS, V30, P6544, DOI 10.1109/TIP.2021.3093397
   Zheng H, 2020, INFORM SCIENCES, V533, P60, DOI 10.1016/j.ins.2020.04.041
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
   Zhu XL, 2020, VISUAL COMPUT, V36, P743, DOI 10.1007/s00371-019-01660-3
NR 39
TC 4
Z9 4
U1 2
U2 39
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2023
VL 39
IS 7
BP 2637
EP 2652
DI 10.1007/s00371-022-02483-5
EA APR 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L4HX1
UT WOS:000787630500001
DA 2024-07-18
ER

PT J
AU Chandrasekaran, R
   Loganathan, B
AF Chandrasekaran, Raja
   Loganathan, Balaji
TI Retinopathy grading with deep learning and wavelet hyper-analytic
   activations
SO VISUAL COMPUTER
LA English
DT Article
DE Diabetic retinopathy; CNN; Wavelets; Spatial-wavelet inputs; Complex
   activations
ID SPECTRAL-SPATIAL CLASSIFICATION; DIABETIC-RETINOPATHY; NEURAL-NETWORK;
   TRANSFORM; DIAGNOSIS; ALGORITHM
AB Recent developments reveal the prominence of Diabetic Retinopathy (DR) grading. In the past few decades, Wavelet-based DR classification has shown successful impacts and the Deep Learning models, like Convolutional Neural Networks (CNN's), have evolved in offering the highest prediction accuracy. In this work, the features of the input image are enhanced with the integration of Multi-Resolution Analysis (MRA) and a CNN framework without costing more convolution filters. The bottleneck with conventional activation functions, used in CNN's, is the nullification of the feature maps that are negative in value. In this work, a novel Hyper-analytic Wavelet (HW) phase activation function is formulated with unique characteristics for the wavelet sub-bands. Instead of dismissal, the function transforms these negative coefficients that correspond to significant edge feature maps. The hyper-analytic wavelet phase forms the imaginary part of the complex activation. And the hyper-parameter of the activation function is selected such that the corresponding magnitude spectrum produces monotonic and effective activations. The performance of 3 CNN models (1 custom, shallow CNN, ResNet with Soft attention, Alex Net for DR) with spatial-Wavelet quilts is better. With the spatial-Wavelet quilts, the Alex Net for DR has an improvement with an 11% of accuracy level (from 87 to 98%). The highest accuracy level of 98% and the highest Sensitivity of 99% are attained through Modified Alex Net for DR. The proposal also illustrates the visualization of the negative edge preservation with assumed image patches. From this study, the researcher infers that models with spatial-Wavelet quilts, with the hyper-analytic activations, have better generalization ability. And the visualization of heat maps provides evidence of better learning of the feature maps from the wavelet sub-bands.
C1 [Chandrasekaran, Raja] Sri Sairam Coll Engn, Dept ECE, Bengaluru, India.
   [Loganathan, Balaji] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept ECE, Chennai 600062, Tamil Nadu, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Chandrasekaran, R (corresponding author), Sri Sairam Coll Engn, Dept ECE, Bengaluru, India.
EM rajachandru82@yahoo.co.in; maildhanabal@gmail.com
RI Balaji, L/W-3538-2019; Chandrasekaran, Dr. Raja/U-5024-2018
OI Balaji, L/0000-0001-9709-2578; Chandrasekaran, Dr.
   Raja/0000-0001-7351-3403
CR Acharya UR, 2017, COMPUT BIOL MED, V84, P59, DOI 10.1016/j.compbiomed.2017.03.016
   Adam I, 2007, I S INTELL SIG PR, P237, DOI 10.1109/WISP.2007.4447560
   Agrawal A, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P24, DOI 10.1109/ICISCON.2013.6524167
   Aiello LP, 1998, DIABETES CARE, V21, P143, DOI 10.2337/diacare.21.1.143
   Akgül T, 2011, IEEE SIGNAL PROC MAG, V28, P160, DOI 10.1109/MSP.2010.938777
   Arcadu F, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0172-3
   Bloomgarden ZT, 2007, AM J HEALTH-SYST PH, V64, pS8, DOI 10.2146/ajhp070331
   Çelik T, 2011, COMPUT ELECTR ENG, V37, P729, DOI 10.1016/j.compeleceng.2011.06.008
   Chaudhary PK, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3140437
   Chen WH, 2020, IEEE ACCESS, V8, P178552, DOI 10.1109/ACCESS.2020.3027794
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Dang P, 2011, IEEE T SIGNAL PROCES, V59, P4708, DOI 10.1109/TSP.2011.2160260
   Diaz, 2020, MED NEWS TODAY
   Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589
   Gayathri S, 2020, IEEE ACCESS, V8, P57497, DOI 10.1109/ACCESS.2020.2979753
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   Gondal WM, 2017, IEEE IMAGE PROC, P2069, DOI 10.1109/ICIP.2017.8296646
   Khan Z, 2021, IEEE ACCESS, V9, P61408, DOI 10.1109/ACCESS.2021.3074422
   Koetting C., 2019, 4 STAGES DIABETIC RE
   Kwasigroch Arkadiusz, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P111, DOI 10.1109/IIPHDW.2018.8388337
   Lin JH, 2020, IEEE ACCESS, V8, P98126, DOI 10.1109/ACCESS.2020.2996250
   Lin JH, 2019, IEEE ACCESS, V7, P116612, DOI 10.1109/ACCESS.2019.2936591
   Mateen M, 2020, IEEE ACCESS, V8, P48784, DOI 10.1109/ACCESS.2020.2980055
   Mookiah MRK, 2013, COMPUT BIOL MED, V43, P2136, DOI 10.1016/j.compbiomed.2013.10.007
   Nafornita C, 2008, PROC SPIE, V7000, DOI 10.1117/12.780845
   Obla S, 2020, IEEE ACCESS, V8, P153098, DOI 10.1109/ACCESS.2020.3017436
   Peterman, 2015, GRIS WORL HOM
   Qian S, 2018, NEUROCOMPUTING, V272, P204, DOI 10.1016/j.neucom.2017.06.070
   Qian T, 2009, MATH METHOD APPL SCI, V32, P253, DOI 10.1002/mma.1032
   Quellec G, 2008, IEEE T MED IMAGING, V27, P1230, DOI 10.1109/TMI.2008.920619
   Raja C, 2015, J ELECTR ENG TECHNOL, V10, P1899, DOI 10.5370/JEET.2015.10.4.1899
   Raja C., 2015, P 4 INT C SOFT COMP, V2, P329
   Raja C, 2015, COMPUT BIOL MED, V63, P196, DOI 10.1016/j.compbiomed.2015.05.018
   Rosebrock A., 2015, DIABETIC RETINOPATHY
   Saranya P, 2022, VISUAL COMPUT, V38, P977, DOI 10.1007/s00371-021-02062-0
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Shu L, 2018, IEEE T GEOSCI REMOTE, V56, P5975, DOI 10.1109/TGRS.2018.2829400
   Sun YL, 2019, IEEE ACCESS, V7, P69657, DOI 10.1109/ACCESS.2019.2916922
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Varadarajan AV, 2018, INVEST OPHTH VIS SCI, V59, P2861, DOI 10.1167/iovs.18-23887
   Varshney M, 2021, SIGNAL IMAGE VIDEO P, V15, P1323, DOI 10.1007/s11760-021-01863-z
   Vashist Praveen, 2011, Indian J Community Med, V36, P247, DOI 10.4103/0970-0218.91324
   Viswanath K, 2003, Community Eye Health, V16, P21
   Wang X, 2019, NEUROCOMPUTING, V363, P88, DOI 10.1016/j.neucom.2019.07.017
   Xi PC, 2020, VISUAL COMPUT, V36, P1869, DOI 10.1007/s00371-019-01775-7
   Yu YB, 2020, IEEE ACCESS, V8, P72727, DOI 10.1109/ACCESS.2020.2987829
   Zhu M, 2021, NEUROCOMPUTING, V429, P110, DOI 10.1016/j.neucom.2020.11.068
NR 48
TC 7
Z9 7
U1 3
U2 23
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2023
VL 39
IS 7
BP 2741
EP 2756
DI 10.1007/s00371-022-02489-z
EA APR 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L4HX1
UT WOS:000788031600001
PM 35493724
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Prakash, AJ
   Prakasam, P
AF Prakash, Achanta Jyothi
   Prakasam, P.
TI An intelligent fruits classification in precision agriculture using
   bilinear pooling convolutional neural networks
SO VISUAL COMPUTER
LA English
DT Article
DE Machine vision; Fruit classification; Convolutional neural network;
   Bilinear pooling; Confusion matrix
AB With an increase in the consumption of fruits day by day, the yielding and production around the world are also increasing at a steady rate. Meanwhile, the workforce in the field becomes more challenging, there arises a need for automated solutions to maintain consistent output and quality of the product. An accurate, competent and consistent approach to classifying fruits and other agricultural products in precision agriculture is the foundation for a machine vision system to be successful and cost-effective. In this research work, Convolutional Neural Network (CNN)-based intelligent fruits classification utilizing the bilinear pooling with heterogeneous streams is proposed. The fruits classification problem is viewed as a fine-grained visual classification (FGVC) and the heterogeneous bilinear network is developed and compared with the normal implementations. The proposed CNN network is initialized with ImageNet weights and the pre-trained networks are used as components in the Bilinear Pooling CNN (BP-CNN). The CNNs used in the bilinear network function as feature extractors are then combined using the bilinear pooling function. The proposed BP-CNN-based intelligent classifier is trained and tested with Fruits-360, Imagenet and VegFru which are used by many researchers recently. The performance of the proposed BP-CNN model is validated using various metrics and compared with other existing CNN models. It is found that it outperforms all other methods with a classification accuracy of 99.69% and an F1 score of 0.9968.
C1 [Prakash, Achanta Jyothi; Prakasam, P.] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Prakasam, P (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM jyothi.prakash2017@vitstudent.ac.in; prakasamp@gmail.com
RI P, Prakasam/B-3075-2016; p, p/JED-5004-2023
OI P, Prakasam/0000-0002-2471-6375; 
CR Abbas HMT, 2019, INT CONF INF COMMUN, P78, DOI [10.1109/icict47744.2019.9001971, 10.1109/ICICT47744.2019.9001971]
   Ahmadian N, 2022, VEHICLE SYST DYN, V60, P1742, DOI 10.1080/00423114.2021.1879390
   Alresheedi KM., 2018, INT J COMPUT APPL, V181, P17
   Altaheri H, 2019, IEEE ACCESS, V7, P117115, DOI 10.1109/ACCESS.2019.2936536
   Anupama M. A., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0143, DOI 10.1109/ICCSP.2019.8698043
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Bayoudh K, 2022, VISUAL COMPUT, V38, P2939, DOI 10.1007/s00371-021-02166-7
   Becherer N, 2019, NEURAL COMPUT APPL, V31, P3469, DOI 10.1007/s00521-017-3285-0
   Ben Fredj H, 2021, VISUAL COMPUT, V37, P217, DOI 10.1007/s00371-020-01794-9
   Chaudhari Dipali, 2022, ICCCE 2021: Proceedings of the 4th International Conference on Communications and Cyber Physical Engineering. Lecture Notes in Electrical Engineering (828), P775, DOI 10.1007/978-981-16-7985-8_81
   Chu B, 2016, LECT NOTES COMPUT SC, V9915, P435, DOI 10.1007/978-3-319-49409-8_34
   Cireundefinedan D.C., 2011, IJCAI INT JOINT C AR, VTwo, P1237, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-210
   Dai XH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020301
   Fan XY, 2020, TSINGHUA SCI TECHNOL, V25, P425, DOI 10.26599/TST.2019.9010029
   Gajjar R, 2022, VISUAL COMPUT, V38, P2923, DOI 10.1007/s00371-021-02164-9
   Garillos-Manliguez CA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041288
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   González-González MG, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10010128
   Hameed K, 2018, IMAGE VISION COMPUT, V80, P24, DOI 10.1016/j.imavis.2018.09.016
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MS, 2018, FUTURE GENER COMP SY, V88, P333, DOI 10.1016/j.future.2018.05.050
   Jia WK, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105380
   Junos MH, 2022, VISUAL COMPUT, V38, P2341, DOI 10.1007/s00371-021-02116-3
   Khan A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243243
   Khan M., 2020, P 29 ACM INT C INF K
   Khan Muhammad Jaleed, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1097, DOI 10.1109/ICDAR.2019.00178
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Lu SY, 2018, INT CONF DIGIT SIG
   Maity A, 2021, MULTIMED TOOLS APPL, V80, P29765, DOI 10.1007/s11042-021-11194-3
   Malhotra Sahil, 2021, Proceedings of the Second International Conference on Information Management and Machine Intelligence (ICIMMI 2020). Lecture Notes in Networks and Systems (LNNS 166), P129, DOI 10.1007/978-981-15-9689-6_15
   Mehta SS, 2014, COMPUT ELECTRON AGR, V102, P146, DOI 10.1016/j.compag.2014.01.003
   Perez RM, 2017, COMPUT ELECTRON AGR, V139, P231, DOI 10.1016/j.compag.2017.05.014
   Muresan H, 2018, ACTA U SAPIEN INFORM, V10, P26, DOI 10.2478/ausi-2018-0002
   Naranjo-Torres J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103443
   Nasirzadehdizaji R, 2019, INT CONF AGRO-GEOINF, DOI 10.1109/agro-geoinformatics.2019.8820604
   Peng YQ, 2020, IEEE ACCESS, V8, P3987, DOI 10.1109/ACCESS.2019.2961767
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spetale FE, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105382
   Steinbrener J, 2019, COMPUT ELECTRON AGR, V162, P364, DOI 10.1016/j.compag.2019.04.019
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vasumathi M. T., 2021, INDIAN J SCI TECHNOL, V14, P1310, DOI [10.17485/IJST/v14i16.432, DOI 10.17485/IJST/v14i16.432]
   Vijayalakshmi M., 2021, International Journal of Information Technology, V13, P27, DOI 10.1007/s41870-020-00554-1
   Wan SH, 2020, COMPUT NETW, V168, DOI 10.1016/j.comnet.2019.107036
   Wang SH, 2020, MULTIMED TOOLS APPL, V79, P15117, DOI 10.1007/s11042-018-6661-6
   Xu W, 2020, NEURAL PROCESS LETT, V52, P169, DOI 10.1007/s11063-020-10238-3
   Xue G, 2023, COMPLEX INTELL SYST, V9, P2209, DOI 10.1007/s40747-020-00192-x
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang HX, 2012, NEURAL PROCESS LETT, V36, P173, DOI 10.1007/s11063-012-9229-x
   Zhang L, 2019, IEEE ACCESS, V7, P56028, DOI 10.1109/ACCESS.2019.2899940
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
NR 54
TC 14
Z9 14
U1 5
U2 29
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2023
VL 39
IS 5
BP 1765
EP 1781
DI 10.1007/s00371-022-02443-z
EA MAR 2022
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7ZK3
UT WOS:000770721300001
DA 2024-07-18
ER

PT J
AU Fan, JW
   Yang, XG
   Lu, RT
   Li, WP
   Huang, YP
AF Fan, Jiwei
   Yang, Xiaogang
   Lu, Ruitao
   Li, Weipeng
   Huang, Yueping
TI Long-term visual tracking algorithm for UAVs based on kernel correlation
   filtering and SURF features
SO VISUAL COMPUTER
LA English
DT Article
DE Unmanned aerial vehicle; Target tracking; Kernel correlation filtering;
   SURF
ID APPEARANCE; MODEL
AB Long-term visual target tracking of unmanned aerial vehicles (UAVs) is a challenging and basic research topic. In recent years, many visual object tracking methods have been proposed based on the kernel correlation filtering algorithm and achieved good results. These algorithms have good performance in short-term tracking, but when the target is occluded or disappears from view, the original update strategy may lead to tracker drift. Based on these issues, this paper proposes a long-term kernel correlation filtering and speeded-up robust features (KCFSURF) target tracking algorithm for UAVs in the process of long-term target tracking due to target occlusion or loss. The algorithm takes the KCF target tracking algorithm as the framework, introduces the strategy of searching and locating the target after occlusion or loss, and uses the peak side lobe (PSR) ratio to determine whether the target is covered, blocked, or lost. When the target is occluded or lost, the SURF-random sample consensus (RANSAC) target retrieval matching strategy is introduced to rematch the target and select the box. The new samples are input into the KCF algorithm to continue tracking the target. To verify the superiority and feasibility of the proposed algorithm, the OTB100, UAV123, and Temple-color-128 dataset is selected to evaluate and analyze the algorithm quantitatively and qualitatively. The evaluation results show that KCFSURF can rediscover the target after it is blocked or lost, realizing long-term stable target tracking. Finally, the effectiveness of the KCFSURF algorithm is verified in an S500 UAV target tracking scene.
C1 [Fan, Jiwei; Yang, Xiaogang; Lu, Ruitao; Li, Weipeng; Huang, Yueping] Rocket Force Univ Engn, Xian 710025, Peoples R China.
C3 Rocket Force University of Engineering
RP Yang, XG (corresponding author), Rocket Force Univ Engn, Xian 710025, Peoples R China.
EM fjw19900619@163.com; doctoryxg@163.com; lrt19880220@163.com;
   williamli_pro@163.com; hypsc1990@163.com
OI Fan, Jiwei/0000-0002-3173-1282
FU National Natural Science Foundation of China [61806209]; Natural Science
   Foundation of Shaanxi Province [2020JQ-490]; Aeronautical Science Fund
   [201851U8012]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61806209, in part by the Natural Science
   Foundation of Shaanxi Province under Grant 2020JQ-490, and in part by
   the Aeronautical Science Fund under Grant 201851U8012. (Corresponding
   author: Xiaogang Yang.)
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boudjit K, 2015, ICIMCO 2015 PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL. 2, P223
   Chen JN, 2019, IET CONTROL THEORY A, V13, P3117, DOI 10.1049/iet-cta.2019.0032
   Chen Yunfang, 2020, Computer Engineering and Applications, V56, P10, DOI 10.3778/j.issn.1002-8331.1911-0127
   Cheng Shuai, 2015, Optics and Precision Engineering, V23, P1161, DOI 10.3788/OPE.20152304.1161
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   GORDON D, 2018, IEEE ROBOTICS AUTOM
   Gundogdu Erhan, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301290
   Haag Klaus., 2015, Innovations for Community Services (I4CS), 2015 15th International Conference on, P1, DOI DOI 10.1109/I4CS.2015.7294481
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang Y, 2019, AEROSP SCI TECHNOL, V92, P831, DOI 10.1016/j.ast.2019.06.027
   Huang ZH, 2022, VISUAL COMPUT, V38, P2739, DOI 10.1007/s00371-021-02150-1
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang CR, 2018, NEUROCOMPUTING, V275, P2892, DOI 10.1016/j.neucom.2017.10.043
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li R, 2016, IEEE COMPUT SOC CONF, P29, DOI 10.1109/CVPRW.2016.11
   Li WG, 2020, CHIN CONT DECIS CONF, P481, DOI 10.1109/CCDC49329.2020.9164874
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li YS, 2018, IEEE ACCESS, V6, P31065, DOI 10.1109/ACCESS.2018.2832290
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Liu XC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155064
   LU R, 2020, IEEE GEOSCI REMOTE S
   Lu RT, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3038784
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   MBELWA J, 2020, VISUAL COMPUT
   Mohamed N, 2020, TECHNOL FORECAST SOC, V153, DOI 10.1016/j.techfore.2018.05.004
   Moorthy S, 2020, NEUROCOMPUTING, V411, P78, DOI 10.1016/j.neucom.2020.06.016
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   Pelland NA, 2018, J ATMOS OCEAN TECH, V35, P2241, DOI 10.1175/JTECH-D-18-0126.1
   Pestana J, 2013, IEEE INT SYMP SAFE
   Pui S, 2018, LECT NOTES ELECTR EN, V488, P64, DOI 10.1007/978-981-10-8276-4_7
   Qi Naixin, 2018, Systems Engineering and Electronics, V40, P1109, DOI 10.3969/j.issn.1001-506X.2018.05.23
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Suju DA, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Tareen S.A.K., 2018, 2018 INT C COMPUTING, P1, DOI DOI 10.1109/ICOMET.2018.8346440
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q., 2017, ARXIV PREPRINT ARXIV
   Wang SJ, 2020, IEEE T INTELL TRANSP, V21, P3409, DOI 10.1109/TITS.2019.2927838
   Wu Q, 2018, 2018 4TH ANNUAL INTERNATIONAL CONFERENCE ON NETWORK AND INFORMATION SYSTEMS FOR COMPUTERS (ICNISC 2018), P171, DOI 10.1109/ICNISC.2018.00041
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xiao YC, 2020, T I MEAS CONTROL, V42, P2645, DOI 10.1177/0142331220923768
   Yang X, 2020, VISUAL COMPUT, V36, P1783, DOI 10.1007/s00371-019-01772-w
   Yangping W., 2019, 2019 7 INT C INF COM, P230, DOI [10.1109/ICICN.2019.8834947, DOI 10.1109/ICICN.2019.8834947]
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2017, PATTERN RECOGN, V69, P82, DOI 10.1016/j.patcog.2017.04.004
   Zhang SJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123474
   Zhang T, 2020, IEEE ACCESS, V8, P163637, DOI 10.1109/ACCESS.2020.3020808
   Zhang WC, 2021, VISUAL COMPUT, V37, P881, DOI 10.1007/s00371-020-01839-z
   Zhu Q., 2015, J INSTRUM INSTRUM, V36, P2451, DOI [10.3969/j.issn.0254-3087.2015.11.007, DOI 10.3969/J.ISSN.0254-3087.2015.11.007]
NR 64
TC 11
Z9 11
U1 4
U2 36
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2023
VL 39
IS 1
BP 319
EP 333
DI 10.1007/s00371-021-02331-y
EA JAN 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F6UJ1
UT WOS:000745592200002
DA 2024-07-18
ER

PT J
AU Rao, SN
   Wang, HZ
AF Rao, Sana
   Wang, Hanzi
TI Optical flow estimation via weighted guided filtering with non-local
   steering kernel
SO VISUAL COMPUTER
LA English
DT Article
DE Optical flow; Motion estimation; TV-L-1; Edge-preservation; Weighted
   guided image filter
AB The weighted median filter and the guided image filter are considered important methods for the recently popular variational and non-local total variational optical flow estimation. Their attractive advantages are that outlier reduction is attained, while motion boundaries are preserved. However, these methods still suffer from halo artifacts near edges caused by motion occlusion and illumination changes in adverse outdoor conditions. To overcome these drawbacks, we propose weighted guided filtering with a non-local steering kernel during the coarse-to-fine optical flow estimation. The weighted guided filtering can preserve the motion edges more efficiently by incorporating edge-aware weighting into the filtering process, and the non-local steering kernel can leverage the edge direction more sufficiently. First, we formulate weighted guided filtering with a non-local steering kernel to preserve the edges and improve the robustness of optical flow estimation. Second, we present a combination of median filtering and weighted guided filtering with a non-local steering kernel to optimize the optical flow estimation under the coarse-to-fine process. We compare the proposed method with several state-of-the-art methods using the Middlebury and MPI Sintel test datasets. The results indicate that the proposed method is robust for optical flow estimation and able to preserve motion boundaries.
C1 [Rao, Sana; Wang, Hanzi] Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Rao, SN (corresponding author), Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
EM rao.sana10@yahoo.com
RI Wang, Han/GPW-9809-2022; wang, hao/HSE-7975-2023; wang,
   handong/HLH-5739-2023; rao, sana/AAY-9797-2021
FU CSC; Fujian key Laboratory of Sensing and Computing for Smart City of
   Xiamen University, China
FX ;We acknowledge the support of the CSC and Fujian key Laboratory of
   Sensing and Computing for Smart City of Xiamen University, China.
CR Alvarez L., 1999, PROC CONGRESO ECUACI, P1349
   Belhachmi Z, 2016, J MATH IMAGING VIS, V54, P358, DOI 10.1007/s10851-015-0608-6
   Bengtsson T, 2017, IMAGE VISION COMPUT, V57, P78, DOI 10.1016/j.imavis.2016.11.003
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Dong C, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116143
   Gavaskar RG, 2019, IEEE T IMAGE PROCESS, V28, P779, DOI 10.1109/TIP.2018.2871597
   GUANCHENG C, VISUAL COMPUT
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu YL, 2016, PROC CVPR IEEE, P5704, DOI 10.1109/CVPR.2016.615
   Hur J., 2020, Model Hum Motion Hum Percept Robot Des, P119, DOI 10.1007/978-3-030-46732-67
   Ince S, 2008, IEEE T IMAGE PROCESS, V17, P1443, DOI 10.1109/TIP.2008.925381
   Kim YH, 2005, IMAGE VISION COMPUT, V23, P365, DOI 10.1016/j.imavis.2004.05.010
   Lai R, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030329
   Mahfouf Z, 2018, NEUROCOMPUTING, V283, P140, DOI 10.1016/j.neucom.2017.12.040
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y
   Ren X., 2008, 2008 IEEE C COMPUTER, P1
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sevilla-Lara L, 2016, PROC CVPR IEEE, P3889, DOI 10.1109/CVPR.2016.422
   Shen XY, 2015, IEEE I CONF COMP VIS, P3406, DOI 10.1109/ICCV.2015.389
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Sun ZG, 2020, IEEE T IMAGE PROCESS, V29, P500, DOI 10.1109/TIP.2019.2928631
   Tomasi C., 1992, P IEEE INT C COMP VI, P836
   Torres BS, 2018, VISUAL COMPUT, V34, P145, DOI 10.1007/s00371-016-1321-1
   Tu ZG, 2017, PATTERN RECOGN, V65, P11, DOI 10.1016/j.patcog.2016.10.027
   Wang HT, 2005, ICEMI 2005: CONFERENCE PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS, VOL 6, P111
   Wedel Andreas, 2009, Statistical and Geometrical Approaches to Visual Motion Analysis. International Dagstuhl Seminar. Revised Papers, P23, DOI 10.1007/978-3-642-03061-1_2
   Wulff J, 2014, LECT NOTES COMPUT SC, V8694, P236, DOI 10.1007/978-3-319-10599-4_16
   Zhai ML, 2019, NEUROCOMPUTING, V368, P124, DOI 10.1016/j.neucom.2019.08.040
   Zhang CX, 2020, IEEE T MULTIMEDIA, V22, P349, DOI 10.1109/TMM.2019.2929934
   Zhang CX, 2018, IEEE ACCESS, V6, P26958, DOI 10.1109/ACCESS.2018.2831920
   Zhang CX, 2017, IEEE T IMAGE PROCESS, V26, P4055, DOI 10.1109/TIP.2017.2712279
   Zhang YG, 2018, IEEE INT CONF BIG DA, P4658, DOI 10.1109/BigData.2018.8622420
NR 38
TC 3
Z9 3
U1 5
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2023
VL 39
IS 3
BP 835
EP 845
DI 10.1007/s00371-021-02349-2
EA JAN 2022
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9E6QG
UT WOS:000745817200001
DA 2024-07-18
ER

PT J
AU Qian, XX
   Quan, HY
   Wu, M
AF Qian, Xiaoxiao
   Quan, Hongyan
   Wu, Min
TI PRNet: polar regression network for medical image segmentation
SO VISUAL COMPUTER
LA English
DT Article
DE Semantic segmentation; Polar regression; Shape prior; Center-attention;
   Projection distance
ID ACTIVE CONTOURS DRIVEN; LEFT-VENTRICLE; FITTING ENERGY; REGION; MODEL
AB High-performance segmentation of medical images, though important for automatic clinical diagnosis, remains a challenging problem. In this paper, we propose a novel polar regression network (PRNet) for the segmentation of oval-shaped targets in medical images. Through polar representation, the segmentation problem is formulated and decomposed into two sub-problems of center map estimation and ray length regression. The center map estimation is supervised by the probability center map, which is pre-generated by the contour-based algorithm. The ray length regression further leverages the center-attention polar loss and projection distance loss, in order to emphasize pixels in high probability in the center mask and capitalize on the implicit shape information. Experimental results demonstrate the effectiveness of our approach on the segmentation of oval targets in medical images.
C1 [Qian, Xiaoxiao; Wu, Min] East China Normal Univ, Sch Software Engn, Shanghai 200062, Peoples R China.
   [Quan, Hongyan] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
C3 East China Normal University; East China Normal University
RP Quan, HY (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
EM hyquan@cs.ecnu.edu.cn
CR Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   Avendi MR, 2016, MED IMAGE ANAL, V30, P108, DOI 10.1016/j.media.2016.01.005
   Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502
   Bi L, 2018, VISUAL COMPUT, V34, P1043, DOI 10.1007/s00371-018-1519-5
   Chen J., ARXIV PREPRINT ARXIV
   Cheng Z., 2021, VISUAL COMPUT, P1
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Lei L, 2021, APPL INTELL, V51, P673, DOI 10.1007/s10489-020-01828-8
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Li YP, 2018, APPL INTELL, V48, P4855, DOI 10.1007/s10489-018-1243-x
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Nosrati MS., 2016, ARXIV PREPRINT ARXIV
   Oghli MG, 2017, IRAN J RADIOL, V14, DOI 10.5812/iranjradiol.42272
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Orlando JI, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101570
   Pohle R, 2001, PROC SPIE, V4322, P1337, DOI 10.1117/12.431013
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777
   Shunjie Dong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P98, DOI 10.1007/978-3-030-59719-1_10
   Simpson A.L., 2019, LARGE ANNOTATED MEDI
   Sun Jesse, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P797, DOI 10.1007/978-3-030-59719-1_77
   Tan LK, 2017, MED IMAGE ANAL, V39, P78, DOI 10.1016/j.media.2017.04.002
   Tang P, 2021, NEUROCOMPUTING, V435, P103, DOI 10.1016/j.neucom.2020.12.085
   Tani LK, 2016, IEEE EMBS CONF BIO, P490, DOI 10.1109/IECBES.2016.7843499
   Tian J, 2019, COMM COM INF SC, V1142, P598, DOI 10.1007/978-3-030-36808-1_65
   Tong HL, 2021, APPL INTELL, V51, P5146, DOI 10.1007/s10489-020-01966-z
   Wang D, 2021, VISUAL COMPUT, V37, P1101, DOI 10.1007/s00371-020-01855-z
   Xie EZ, 2022, IEEE T PATTERN ANAL, V44, P5385, DOI 10.1109/TPAMI.2021.3080324
   Yanda Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P190, DOI 10.1007/978-3-030-58598-3_12
   Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 33
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2023
VL 39
IS 1
BP 87
EP 98
DI 10.1007/s00371-021-02315-y
EA OCT 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F6UJ1
UT WOS:000712213600001
DA 2024-07-18
ER

PT J
AU Szirmay-Kalos, L
   Magdics, M
AF Szirmay-Kalos, Laszlo
   Magdics, Milan
TI Adapting Game Engines to Curved Spaces
SO VISUAL COMPUTER
LA English
DT Article
DE Hyperbolic geometry; Elliptic geometry; Transformations; Illumination
ID VISUALIZATION; BODY
AB Curved spaces are very un-intuitive to our eyes trained on Euclidean geometry. Games provide an interesting way to explore these strange worlds. Games are written with the help of modeling tools and game engines based on Euclidean geometry. This paper addresses the problem of adapting 3D game engines to the rules of curved spaces. We consider the conversion of Euclidean objects, geometric calculations, transformation pipeline, lighting and physical simulation. Finally, we identify where existing game engines should be modified.
C1 [Szirmay-Kalos, Laszlo; Magdics, Milan] Budapest Univ Technol & Econ, Dept Control Engn & Informat Technol, Budapest, Hungary.
C3 Budapest University of Technology & Economics
RP Szirmay-Kalos, L (corresponding author), Budapest Univ Technol & Econ, Dept Control Engn & Informat Technol, Budapest, Hungary.
EM szirmay@iit.bme.hu; magdics@iit.bme.hu
RI Szirmay-Kalos, Laszlo/H-3853-2012
OI Szirmay-Kalos, Laszlo/0000-0002-8523-2315
FU OTKA [K-124124]
FX This project has been supported by OTKA K-124124.
CR Amenta  N., 1995, P 11 ANN S COMP GEOM, P412, DOI DOI 10.1145/220279.220327
   Berger P, 2015, VISUAL COMPUT, V31, P93, DOI 10.1007/s00371-013-0913-2
   Blinn, 2002, J BLINNS CORNER NOTA
   Bond J.G., 2014, Introduction to Game Design, Prototyping, and Development: From Concept to Playable Game with Unity and C#
   Brinkmann P, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P123, DOI 10.1109/3DUI.2010.5444708
   Celinska-Kopczynska, 2020, REAL TIME VISUALIZAT
   GROLLER E, 1995, VISUAL COMPUT, V11, P263, DOI 10.1007/BF01901044
   Gunn, 2010, GRAVISMA, P17
   Kopczynski E., 2017, P BRIDG 2017 MATH AR, P9
   Lamping J, 1996, J VISUAL LANG COMPUT, V7, P33, DOI 10.1006/jvlc.1996.0003
   Loustau B., 2020, HYPERBOLIC GEOMETRY
   Martelli B., 2016, An Introduction to Geometric Topology
   Molnar E., 1997, Beitr. Alg. Geom., (Contr. Alg. Geom.), V38, P261
   Novello, 2020, P GRAPHICS INTERFACE, P423, DOI [10.20380/GI2020.42, DOI 10.20380/GI2020.42]
   Novello T, 2020, COMPUT GRAPH-UK, V93, P61, DOI 10.1016/j.cag.2020.09.014
   Novello T, 2020, COMPUT GRAPH-UK, V91, P219, DOI 10.1016/j.cag.2020.07.016
   Osudin D, 2019, LECT NOTES COMPUT SC, V11540, P543, DOI 10.1007/978-3-030-22750-0_49
   Phillips Mark., 1992, Proceedings of the 1992 Symposium on Interactive 3D Graphics I3D'92, P209, DOI DOI 10.1145/147156.147206
   Reach AM, 2019, IEEE T VIS COMPUT GR, V25, P1421, DOI 10.1109/TVCG.2018.2800013
   Salvai M, 2000, J GEOM PHYS, V36, P126, DOI 10.1016/S0393-0440(00)00017-6
   Segerman, 2017, NONEUCLIDEAN VIRTUAL
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Thielhelm H, 2015, VISUAL COMPUT, V31, P187, DOI 10.1007/s00371-014-1041-3
   Trettel S. J., 2020, RAY MARCHING THURSTO
   Velho, 2015, P SIBGRAPI
   Weeks J, 2002, IEEE COMPUT GRAPH, V22, P90, DOI 10.1109/MCG.2002.1046633
   Weeks J, 2021, COMPUT GRAPH-UK, V97, P28, DOI 10.1016/j.cag.2021.04.002
   Weiskopf D, 2006, IEEE T VIS COMPUT GR, V12, P522, DOI 10.1109/TVCG.2006.69
   Weiskopf D., 2001, THESIS U TUBINGEN GE
   Wimmer M., 2021, EUROGRAPHICS 2021, DOI [10.2312/egs.20211010, DOI 10.2312/EGS.20211010]
   Yayli Y., 2012, INT J PURE APPL MATH, V77, P01
   ZITTERBARTH J, 1991, DEMONSTR MATH, V24, P465, DOI DOI 10.1515/DEMA-1991-3-407
NR 32
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2022
VL 38
IS 12
BP 4383
EP 4395
DI 10.1007/s00371-021-02303-2
EA OCT 2021
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7B7SH
UT WOS:000706056900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Jagtap, NS
   Thepade, SD
AF Jagtap, Nalini Santosh
   Thepade, Sudeep D.
TI High-quality image multi-focus fusion to address ringing and blurring
   artifacts without loss of information
SO VISUAL COMPUTER
LA English
DT Article
DE Blurring artifact; Edge detection operator; Guided filtering; Image
   fusion; Low-rank representation; Ringing artifact; Weighted fusion
ID TRANSFORM
AB For many multi-focus image fusion methods, fused image visual and quantitative analysis is a challenging problem because of the presence of ringing and blurring artifacts. A high-quality image fusion framework to overcome the challenges of ringing and blurring artifacts in multi-focus image fusion while preserving the input image regions in the fused image proposed. The modified guided filtering proposed is called novel information preservation-based guided filtering (IPGF). Each input image has been decomposed, using IPGF, into a detail image (small-scale details) and base image (large-scale intensity variations) using the edge detection operator (EDO). The EDO has been used to generate the guidance image to overcome the loss of detail parts and smooth tiny details. Low-rank representation (LRR) was used to estimate the focus map and generate the detail parts fusion. The inherent property of removing artifacts using LRR helps to generate artifact-free detail image fusion. A simple but effective choose max-based fusion has been applied to fuse base images. The addition of base and detail images leads to the initial fusion result. The guided filtering was applied to a focus map, and then the outcome was used to generate the final fused image. Guided filtering is applied to suppress the ringing and blurring effects from the final fused image. The proposed method shows improved performance in terms of statistical, subjective, and objective analysis compared to recent methods.
C1 [Jagtap, Nalini Santosh; Thepade, Sudeep D.] Pimpri Chinchwad Coll Engn, Pune, Maharashtra, India.
   [Jagtap, Nalini Santosh] SPPU, Dr Patil Inst Engn Management & Res, Pune, Maharashtra, India.
C3 Savitribai Phule Pune University
RP Thepade, SD (corresponding author), Pimpri Chinchwad Coll Engn, Pune, Maharashtra, India.
EM nalinisjagtap@gmail.com; sudeepthepade@gmail.com
RI Jagtap, Nalini Santosh/AAC-9416-2022; THEPADE, SUDEEP/P-9054-2015
OI Jagtap, Nalini Santosh/0000-0002-8477-9300; THEPADE,
   SUDEEP/0000-0001-7809-4148
CR Abdelbaky A, 2021, VISUAL COMPUT, V37, P1821, DOI 10.1007/s00371-020-01940-3
   Amin-Naji M, 2020, J AMB INTEL HUM COMP, V11, P1749, DOI 10.1007/s12652-019-01199-0
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Asad M, 2021, VISUAL COMPUT, V37, P1415, DOI 10.1007/s00371-020-01878-6
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   Bhat S, 2021, ARTIF INTELL REV, V54, P5735, DOI 10.1007/s10462-021-09961-7
   Bieshaar M., 2020, CORR200104171
   Bouzos O, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922097
   Chen YB, 2018, IEEE T IMAGE PROCESS, V27, P1526, DOI 10.1109/TIP.2017.2779274
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Du CB, 2018, OPTIK, V157, P1003, DOI 10.1016/j.ijleo.2017.11.162
   Geng P, 2019, IND ROBOT, V46, P369, DOI 10.1108/IR-05-2018-0097
   Guo XP, 2018, NEURAL COMPUT, V30, P1775, DOI 10.1162/neco_a_01098
   Gupta K, 2021, VISUAL COMPUT, V37, P1401, DOI 10.1007/s00371-020-01873-x
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   He L, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0494-8
   Iqbal CMM, 2020, MULTIMED TOOLS APPL, V79, P12817, DOI 10.1007/s11042-020-08661-8
   Jian LH, 2018, FUTURE GENER COMP SY, V83, P310, DOI 10.1016/j.future.2018.01.039
   Jiang Q, 2018, IEEE SENS J, V18, P2494, DOI 10.1109/JSEN.2018.2791642
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Kong FY, 2020, MULTIMED TOOLS APPL, V79, P35195, DOI 10.1007/s11042-019-7614-4
   Kong LB, 2020, INT J EXTREME MANUF, V2, DOI 10.1088/2631-7990/ab7ae6
   Li H, 2018, MULTIFOCUS NOISY IMA
   Li H, 2017, LECT NOTES COMPUT SC, V10666, P675, DOI 10.1007/978-3-319-71607-7_59
   Li J, 2021, VISUAL COMPUT, V37, P619, DOI 10.1007/s00371-020-01828-2
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu SQ, 2019, IEEE ACCESS, V7, P152043, DOI 10.1109/ACCESS.2019.2947378
   Liu YC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204556
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu ZD, 2017, INFORM FUSION, V35, P102, DOI 10.1016/j.inffus.2016.09.007
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Mahajan HB., 2018, INT J ADV SCI TECHNO, V2018, P37
   Mahajan HB., 2019, J ADV RES DYNAMICAL, V11, P1276, DOI [10.5373/JARDCS/V11I9/20193162, DOI 10.5373/JARDCS/V11I9/20193162]
   Mahajan HB., 2020, INT J ADV SCI TECHNO, V29, P214
   Mahajan HB, 2021, WIRELESS PERS COMMUN, V121, P3125, DOI 10.1007/s11277-021-08866-6
   Mahajan HB, 2021, J AMB INTEL HUM COMP, V12, P7777, DOI 10.1007/s12652-020-02502-0
   Na Y, 2018, IET IMAGE PROCESS, V12, P138, DOI 10.1049/iet-ipr.2016.0920
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Petrosian, 2013, WAVELETS SIGNAL IMAG
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Rahman MA, 2017, DIGIT SIGNAL PROCESS, V60, P1, DOI 10.1016/j.dsp.2016.08.004
   Stathaki T, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P1
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Thepade S., 2020, INT J ADV SCI TECHNO, V29, P3945
   Upla KP, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.096025
   Vanmali AV, 2020, INFORM FUSION, V56, P39, DOI 10.1016/j.inffus.2019.10.003
   Wang CM, 2021, VISUAL COMPUT, V37, P1233, DOI 10.1007/s00371-021-02079-5
   Wang ZB, 2017, NEURAL PROCESS LETT, V45, P75, DOI 10.1007/s11063-016-9513-2
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang DS, 2018, J SYST ENG ELECTRON, V29, P415, DOI 10.21629/JSEE.2018.02.21
   Yang Y, 2017, IEEE ACCESS, V5, P14898, DOI 10.1109/ACCESS.2017.2698217
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhang YX, 2019, SIGNAL IMAGE VIDEO P, V13, P727, DOI 10.1007/s11760-018-1402-x
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhou FQ, 2019, IEEE ACCESS, V7, P50780, DOI 10.1109/ACCESS.2019.2909591
   Zhu J, 2018, INFRARED PHYS TECHN, V89, P8, DOI 10.1016/j.infrared.2017.12.003
NR 60
TC 7
Z9 7
U1 2
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2022
VL 38
IS 12
BP 4353
EP 4371
DI 10.1007/s00371-021-02300-5
EA OCT 2021
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7B7SH
UT WOS:000703800200001
DA 2024-07-18
ER

PT J
AU Lin, RJ
   Liu, JY
   Liu, RS
   Fan, X
AF Lin, Runjia
   Liu, Jinyuan
   Liu, Risheng
   Fan, Xin
TI Global structure-guided learning framework for underwater image
   enhancement
SO VISUAL COMPUTER
LA English
DT Article
DE Underwater image enhancement; Image processing; Computer vision; Deep
   learning
AB Underwater image enhancement (UIE), as an image processing technique, plays a vital role in computer vision. However, existing approaches treat the restoration process as a whole; thus, they cannot adequately handle the color distortion and low contrast in the enhanced images. In this paper, we propose a global-local-guided model for realizing UIE tasks in a coarse-to-fine manner to alleviate these issues. The proposed model is divided into two paths. The global path targets to estimate basic structure and color information, while the local path targets to remove the undesirable artifacts, e.g., noises over-exposure regions, and blurred edges. By integrating two neural networks into our model, we could recover the underwater images with clear textural details and vivid color. Besides, a learning-based weight map is introduced to make the global-local path on friendly terms, which can balance the pixel intensity distribution from both sides and remove redundant information to a certain degree. Qualitative and quantitative experimental results on various benchmarks demonstrate that our method can effectively tackle color distortion and blurred edges compared with several state-of-the-art methods by a large margin. Finally, we also conduct experiments to demonstrate that our method can be applied in various computer vision tasks, e.g., object detection, matching and edge detection.
C1 [Liu, Jinyuan] Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.
   [Lin, Runjia; Liu, Risheng; Fan, Xin] Dalian Univ Technol, Int Sch Informat Sci & Engn, Dalian, Peoples R China.
   [Liu, Jinyuan; Liu, Risheng; Fan, Xin] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology
RP Liu, RS (corresponding author), Dalian Univ Technol, Int Sch Informat Sci & Engn, Dalian, Peoples R China.; Liu, RS (corresponding author), Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian, Peoples R China.
EM rsliu@dlut.edu.cn
RI Liu, Jinyuan/GNP-2535-2022
OI Liu, Jinyuan/0000-0003-2085-2676; Liu, Risheng/0000-0002-9554-0565
FU National Natural Science Foundation of China [61922019, 62027826,
   61722105, 61672125]
FX The funding was provided by National Natural Science Foundation of China
   (Grant Nos. 61922019, 62027826, 61722105, 61672125).
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Anwar S., 2018, ARXIV180703528
   Asmare MH, 2015, SIGNAL IMAGE VIDEO P, V9, P1679, DOI 10.1007/s11760-014-0626-7
   Baiju P.S., VISUAL COMPUT, V4
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Dudhane A., 2020, IEEE SIGNAL PROC LET, V1, P04
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Gupta Ekta, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359320
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou MJ, 2018, IEEE IMAGE PROC, P4043, DOI 10.1109/ICIP.2018.8451209
   Hu W., VISUAL COMPUT, V6
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Gulrajani I, 2017, ADV NEUR IN, V30
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ju MY, 2017, VISUAL COMPUT, V33, P1613, DOI 10.1007/s00371-016-1305-1
   Khan A, 2016, 2016 IEEE 6TH INTERNATIONAL CONFERENCE ON UNDERWATER SYSTEM TECHNOLOGY: THEORY AND APPLICATIONS, P83, DOI 10.1109/USYS.2016.7893927
   Koschmieder H., 1924, Beitraege Phys. Atmosp., P33
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li H., 2019, ARXIV190606819
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lisin D, 2005, 2005 IEEE COMP SOC C, P47, DOI [10.1109/CVPR.2005.433, 10/c3854f, DOI 10.1109/CVPR.2005.433]
   Liu, 2020, IEEE T CIRC SYST VID, V1, P10
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   LIU YC, 1995, IEEE T CONSUM ELECTR, V41, P460, DOI 10.1109/30.468045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JY, 2019, OPT LASER TECHNOL, V110, P105, DOI 10.1016/j.optlastec.2018.05.048
   Odena A, 2017, PR MACH LEARN RES, V70
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Skinner KA, 2019, IEEE INT CONF ROBOT, P7947, DOI [10.1109/ICRA.2019.8794272, 10.1109/icra.2019.8794272]
   Sun X, 2019, IET IMAGE PROCESS, V13, P469, DOI 10.1049/iet-ipr.2018.5237
   Uplavikar P. M., 2019, P IEEE C COMP VIS PA, P1
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang C., VISUAL COMPUT, V37
   Wang Y, 2017, IEEE IMAGE PROC, P1382, DOI 10.1109/ICIP.2017.8296508
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhou Y, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P2771, DOI 10.1109/SSCI44817.2019.9003045
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 55
TC 12
Z9 12
U1 3
U2 32
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2022
VL 38
IS 12
BP 4419
EP 4434
DI 10.1007/s00371-021-02305-0
EA OCT 2021
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7B7SH
UT WOS:000703382200001
DA 2024-07-18
ER

PT J
AU Szucs, J
   Balázs, P
AF Szucs, Judit
   Balazs, Peter
TI Local Q-concavity histograms for binary image classification and
   reconstruction
SO VISUAL COMPUTER
LA English
DT Article
DE Quadrant-convexity; Local shape descriptor; Image classification; Binary
   tomography; Image reconstruction; Simulated annealing
ID CONVEXITY MEASURE; SETS
AB In this paper, we propose a novel vector-form image descriptor that measures the so-called Q-concavity of a binary image under all possible positions of a sliding window of fixed size. In this way, a local Q-concavity histogram (LQH) is created. We propose three techniques to speed up the process of obtaining such histograms. Then, we also present a strategy to determine the proper window size and the appropriate number of histogram bins to achieve the greatest classification power of the descriptor. To show another application of the descriptor, we also solve a binary image reconstruction problem using LQH as prior information. The reconstruction is formulated as a discrete global optimization problem, which is then solved by simulated annealing. We also conduct experiments to show the usefulness of this approach.
C1 [Szucs, Judit; Balazs, Peter] Univ Szeged, Dept Image Proc & Comp Graph, Arpad Ter 2, H-6720 Szeged, Hungary.
C3 Szeged University
RP Szucs, J (corresponding author), Univ Szeged, Dept Image Proc & Comp Graph, Arpad Ter 2, H-6720 Szeged, Hungary.
EM jszucs@inf.u-szeged.hu; pbalazs@inf.u-szeged.hu
RI ; Balazs, Peter/M-4393-2018
OI Szucs, Judit/0000-0002-9828-3322; Balazs, Peter/0000-0003-3406-9578
FU New National Excellence Program of the Ministry for Innovation and
   Technology from the Source of the National Research, Development and
   Innovation Fund [UNKP-20-4-SZTE-598]; project "Integrated program for
   training new generation of scientists in the fields of computer science"
   [EFOP-3.6.3-VEKOP-16-2017-00002]; European Union; European Social Fund;
   Ministry for Innovation and Technology, Hungary [NKFIH-1279-2/2020]
FX Judit Szcs was supported by the UNKP-20-4-SZTE-598 New National
   Excellence Program of the Ministry for Innovation and Technology from
   the Source of the National Research, Development and Innovation Fund.
   This research was supported by the project "Integrated program for
   training new generation of scientists in the fields of computer
   science", no. EFOP-3.6.3-VEKOP-16-2017-00002. The project has been
   supported by the European Union and co-funded by the European Social
   Fund. The authors thank Daniel Melkvi and Gabor Magyar for conducting
   preliminary experiments with vector-form Q-concavity descriptors. This
   research was supported by grant NKFIH-1279-2/2020 of the Ministry for
   Innovation and Technology, Hungary.
CR Alenius S, 1998, IEEE T NUCL SCI, V45, P3097, DOI 10.1109/23.737670
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Brunetti S, 2003, THEOR COMPUT SCI, V304, P35, DOI 10.1016/S0304-3975(03)00050-1
   Brunetti S, 2001, LINEAR ALGEBRA APPL, V339, P37, DOI 10.1016/S0024-3795(01)00435-9
   Brunetti S, 2008, THEOR COMPUT SCI, V406, P55, DOI 10.1016/j.tcs.2008.06.003
   Brunetti S, 2019, LECT NOTES COMPUT SC, V11414, P330, DOI 10.1007/978-3-030-14085-4_26
   Brunetti Sara., 2017, International Conference on Discrete Geometry for Computer Imagery, P219
   Chan C, 2009, PHYS MED BIOL, V54, P7379, DOI 10.1088/0031-9155/54/24/009
   Dai L., 2020, VISUAL COMPUT
   Gong K, 2019, IEEE T MED IMAGING, V38, P1655, DOI 10.1109/TMI.2018.2888491
   Gorelick L, 2017, IEEE T PATTERN ANAL, V39, P258, DOI 10.1109/TPAMI.2016.2547399
   Herman G.T., 1999, Discrete Tomography Foundations, DOI DOI 10.1007/978-1-4612-1568-4
   Herman GT, 2009, ADV PATTERN RECOGNIT, P1
   Herman GT, 2007, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-4543-4
   Kak A. C., 1988, Principles of computerized tomographic imaging, DOI 10.1118/1.1455742
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kiss Z., 2005, Electronic Notes in Discrete Mathematics, V20, P475, DOI DOI 10.1016/J.ENDM.2005.05.080
   Kylberg G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-17
   Li R, 2017, VISUAL COMPUT, V33, P903, DOI 10.1007/s00371-017-1385-6
   Liu XL, 2015, VISUAL COMPUT, V31, P1431, DOI 10.1007/s00371-014-1024-4
   Lukic T, 2022, VISUAL COMPUT, V38, P695, DOI 10.1007/s00371-020-02044-8
   Lukic T, 2016, PATTERN RECOGN LETT, V79, P18, DOI 10.1016/j.patrec.2016.04.010
   Lukic Tibor., 2011, Proceedings of the 8th Conference of the Hungarian Association for Image Processing and Pattern Recognition, P83
   Ma JH, 2012, PHYS MED BIOL, V57, P7519, DOI 10.1088/0031-9155/57/22/7519
   Nguyen TV, 2020, J NAT HIST, V54, P195, DOI 10.1080/00222933.2020.1728411
   Rahtu E, 2006, IEEE T PATTERN ANAL, V28, P1501, DOI 10.1109/TPAMI.2006.175
   Ryser H.J., 1957, Canad. J. Math., V9, P371
   Sonka M, 2014, CENGAGE LEARNING, DOI [DOI 10.1007/978-1-4899-3216-7, 10.1007/978-1-4899-3216-7]
   Szucs Judit, 2020, Combinatorial Image Analysis. 20th International Workshop, IWCIA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12148), P245, DOI 10.1007/978-3-030-51002-2_18
   Wang J, 2009, MED PHYS, V36, P252, DOI 10.1118/1.3036112
   Zunic J, 2004, IEEE T PATTERN ANAL, V26, P923, DOI 10.1109/TPAMI.2004.19
NR 31
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2022
VL 38
IS 12
BP 4221
EP 4234
DI 10.1007/s00371-021-02290-4
EA SEP 2021
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7B7SH
UT WOS:000695457400001
DA 2024-07-18
ER

PT J
AU Musse, SR
   Cassol, VJ
   Thalmann, D
AF Musse, Soraia Raupp
   Cassol, Vinicius Jurinic
   Thalmann, Daniel
TI A history of crowd simulation: the past, evolution, and new perspectives
SO VISUAL COMPUTER
LA English
DT Article
DE Crowd simulation; Virtual humans; Behavioral animation
ID VIRTUAL HUMANS; MODEL; DENSITY; MOTION; EVACUATION; PARAMETERS;
   BEHAVIORS
AB This paper aims to discuss the past, evolution, and new perspectives in crowd simulation. Many work have been produced and published in this area that was launched approximately 30 years ago. In this paper, we re-visited the main aspects of the area, presenting the periods and evolution we had in the past. In addition, we also discuss the present and possible trends for the future.
C1 [Musse, Soraia Raupp; Cassol, Vinicius Jurinic] Pontificia Univ Catolica Rio Grande do Sul, Porto Alegre, Brazil.
   [Cassol, Vinicius Jurinic] UniRitter, Porto Alegre, RS, Brazil.
   [Thalmann, Daniel] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
C3 Pontificia Universidade Catolica Do Rio Grande Do Sul; Swiss Federal
   Institutes of Technology Domain; Ecole Polytechnique Federale de
   Lausanne
RP Musse, SR (corresponding author), Pontificia Univ Catolica Rio Grande do Sul, Porto Alegre, Brazil.
EM soraia.musse@pucrs.br; vinicius.cassol@uniritter.edu.br;
   daniel.thalmann@epfl.ch
RI Thalmann, Daniel/AAL-1097-2020; Cassol, Vinícius/GVU-7369-2022; Musse,
   Soraia Raupp R/G-4801-2012; Musse, Soraia Raupp/AAS-3787-2021
OI Thalmann, Daniel/0000-0002-0451-7491; 
FU CNPq [305084/2016-0]; FAPERGS [20/2551-0000280-2]
FX Soraia R. Musse was funded by CNPq (Grant number: 305084/2016-0) and
   FAPERGS (Grant number: 20/2551-0000280-2), andViniciusCassolwas funded
   by FAPERGS (Grant number: 20/2551-0000280-2).
CR Amirian J, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P7, DOI 10.1145/3328756.3328769
   Anderson M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P286
   [Anonymous], 1997, MODEL HUMAN CROWD BE
   [Anonymous], 1999, P GAM DEV C
   [Anonymous], 2020, ACM SIGGRAPH C MOT G, P1
   Antonitsch AD, 2020, SIBGRAPI, P31, DOI 10.1109/SIBGRAPI51738.2020.00013
   Azahar MBM, 2008, LECT NOTES COMPUT SC, V5093, P573
   Bansod SD, 2020, VISUAL COMPUT, V36, P609, DOI 10.1007/s00371-019-01647-0
   Basak AE, 2018, COMPUT GRAPH-UK, V72, P70, DOI 10.1016/j.cag.2018.02.004
   Bera A, 2015, P 41 GRAPH INT C, P65
   Berseth Glen, 2013, P MOT GAM ACM NEW YO, P67
   Bicho AD, 2012, COMPUT GRAPH-UK, V36, P70, DOI 10.1016/j.cag.2011.12.004
   Bosse T., 2011, MODERN APPROACHES AP, P677
   Braun A, 2003, COMP ANIM CONF PROC, P143, DOI 10.1109/CASA.2003.1199317
   Cassol VJ., 2017, SIMULATING CROWDS EG, DOI [10.1007/978-3-319-65202-3, DOI 10.1007/978-3-319-65202-3]
   Charalambous P, 2010, LECT NOTES COMPUT SC, V6459, P35
   Charrier R., 2021, COMPLEX SYSTEMS SMAR, P187, DOI [10.1007/978-3-030-59302-5_10, DOI 10.1007/978-3-030-59302-5_10]
   Cho K, 2008, LECT NOTES COMPUT SC, V5208, P364
   Courty N, 2007, COMPUT ANIMAT VIRT W, V18, P361, DOI 10.1002/cav.199
   Da Silva Antonitsch A., 2019, ADV COMPUTER GRAPHIC
   Dal Bianco CM, 2017, COMPUT ENTERTAIN, V15, DOI 10.1145/2996202
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Dihl L, 2017, 2017 IEEE VIRTUAL HUMANS AND CROWDS FOR IMMERSIVE ENVIRONMENTS (VHCIE)
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Dutra T., 2014, P 27 C COMP AN SOC A, P1
   Farenc N, 2000, APPL ARTIF INTELL, V14, P69, DOI 10.1080/088395100117160
   Favaretto RM, 2016, IEEE IMAGE PROC, P2936, DOI 10.1109/ICIP.2016.7532897
   Flagg M, 2013, IEEE T VIS COMPUT GR, V19, P1935, DOI 10.1109/TVCG.2012.317
   Neto ABF, 2017, LECT NOTES ARTIF INT, V10498, P63, DOI 10.1007/978-3-319-67401-8_7
   Geraerts R, 2008, LECT NOTES COMPUT SC, V5277, P11
   Grillon H, 2009, COMPUT ANIMAT VIRT W, V20, P111, DOI 10.1002/cav.293
   Haworth B., 2015, P ACM SIGGRAPH EUR S, P113
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hernández-Orallo E, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010033
   Ho R.C., 2016, SIGGRAPH ASIA 2016 P, DOI [10.1145/3005274.3005278, DOI 10.1145/3005274.3005278]
   Huang WJ, 2020, IEEE T VIS COMPUT GR, V26, P1502, DOI 10.1109/TVCG.2018.2874050
   Huang ZM, 2021, IEEE T CYBERNETICS, V51, P5559, DOI 10.1109/TCYB.2020.3013271
   Hurst W., 2019, 2019 IEEE VIRT HUM C, P1, DOI [10.1109/VHCIE.2019.8714733, DOI 10.1109/VHCIE.2019.8714733]
   Ijaz K., 2015, P 2015 17 UKSIM AMSS
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Karamouzas I, 2012, IEEE T VIS COMPUT GR, V18, P394, DOI 10.1109/TVCG.2011.133
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kielar P., 2020, COLLECTIVE DYNAMICS, V5, P290
   Koilias A, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1963
   Kremer M, 2021, VISUAL COMPUT, V37, P107, DOI 10.1007/s00371-020-01969-4
   Krontiris A., 2016, 29 INT C COMP AN SOC
   Kyriakou M, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274509
   Lai Yu-Chi., 2005, SCA 2005: Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P281, DOI DOI 10.1145/1073368.1073409
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Li XL, 2020, IEEE T IMAGE PROCESS, V29, P5571, DOI 10.1109/TIP.2020.2985284
   Li Y, 2021, SIMUL MODEL PRACT TH, V107, DOI 10.1016/j.simpat.2020.102150
   Liu WN, 2017, MIG'17: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON MOTION IN GAMES, DOI 10.1145/3136457.3136474
   Liu WY, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1965
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Maïm J, 2009, IEEE COMPUT GRAPH, V29, P82, DOI 10.1109/MCG.2009.129
   Min Zhou, 2022, IEEE Transactions on Intelligent Transportation Systems, V23, P1492, DOI 10.1109/TITS.2020.3027542
   Mingliang Xu, 2021, IEEE Transactions on Intelligent Transportation Systems, V22, P6977, DOI 10.1109/TITS.2020.3000607
   Mirahadi F, 2021, J BUILD ENG, V34, DOI 10.1016/j.jobe.2020.101687
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Musse SR, 2007, COMPUT ANIMAT VIRT W, V18, P83, DOI 10.1002/cav.163
   Musse SR, 2012, COMPUT ANIMAT VIRT W, V23, P49, DOI 10.1002/cav.1423
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Nasirpouri F., 2015, 2015 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2015.7157712
   Oguz O, 2010, COMPUT GRAPH-UK, V34, P136, DOI 10.1016/j.cag.2009.12.004
   Okaya M., 2011, AGENTS PRINCIPLE AGE
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Paris S, 2009, LECT NOTES COMPUT SC, V5884, P13, DOI 10.1007/978-3-642-10347-6_2
   Pelechano J., 2005, 1 INT WORKSHOP CROWD, P21
   Pelechano Nuria, 2016, 2016 IEEE Virtual Humans and Crowds for Immersive Environments (VHCIE), P17, DOI 10.1109/VHCIE.2016.7563568
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechano N., 2008, Synthesis Lectures on Computer Graphics and Animation, V3, P1, DOI DOI 10.2200/S00123ED1V01Y200808CGR008
   Pelechano N, 2006, IEEE COMPUT GRAPH, V26, P80, DOI 10.1109/MCG.2006.133
   Pettré J, 2006, COMPUT ANIMAT VIRT W, V17, P445, DOI 10.1002/cav.147
   Ravichandran NB, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P307, DOI 10.1145/3267851.3267914
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Renault O., 1990, Journal of Visualization and Computer Animation, V1, P18, DOI 10.1002/vis.4340010106
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rodrigues RA, 2009, LECT NOTES ARTIF INT, V5773, P358, DOI 10.1007/978-3-642-04380-2_39
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Schaffer Diogo, 2020, MIG '20: Motion, Interaction and Games, DOI 10.1145/3424636.3426900
   Shi XM, 2021, PHYSICA A, V562, DOI 10.1016/j.physa.2020.125347
   Shoulson A., 2013, I3D, P9
   Stüvel SA, 2017, IEEE T VIS COMPUT GR, V23, P1823, DOI 10.1109/TVCG.2016.2545670
   Sun JK, 2022, IEEE T KNOWL DATA EN, V34, P2348, DOI 10.1109/TKDE.2020.3008774
   SUNG M., 2005, SCA 05, P291
   Swathi HY, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ELECTRONICS AND COMMUNICATION TECHNOLOGY (ICRAECT), P169, DOI 10.1109/ICRAECT.2017.66
   Testa E, 2019, VISUAL COMPUT, V35, P1119, DOI 10.1007/s00371-019-01684-9
   Thalmann Daniel., 2007, CROWD SIMULATION
   Mathew CDT, 2019, COMPUT GRAPH FORUM, V38, P455, DOI 10.1111/cgf.13585
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Tripathi Gaurav, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P969, DOI 10.1109/ICSSIT48917.2020.9214208
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   Weizi Li, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P132, DOI 10.1007/978-3-642-25090-3_12
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Wong KY, 2008, LECT NOTES COMPUT SC, V5277, P43
   Wong Saikeung, 2017, [Computational Visual Media, 计算可视媒体], V3, P243
   Xiaoyuan Tu, 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P43
   Xie W, 2021, SAFETY SCI, V133, DOI 10.1016/j.ssci.2020.105029
   Yang FK, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P313, DOI 10.1145/3267851.3267877
   Yersin B, 2008, VISUAL COMPUT, V24, P859, DOI 10.1007/s00371-008-0286-0
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang P, 2015, VISUAL COMPUT, V31, P5, DOI 10.1007/s00371-013-0900-7
   Zhang Z, 2021, APPL MATH MODEL, V90, P488, DOI 10.1016/j.apm.2020.08.075
   Zhao MB, 2013, IEEE ACM DIS SIM, P125, DOI 10.1109/DS-RT.2013.21
   Zhao RY, 2020, IEEE T INTELL TRANSP, V21, P4425, DOI 10.1109/TITS.2019.2953357
NR 114
TC 8
Z9 9
U1 1
U2 35
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2021
VL 37
IS 12
SI SI
BP 3077
EP 3092
DI 10.1007/s00371-021-02252-w
EA AUG 2021
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP1DP
UT WOS:000681531100002
PM 34376881
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ananthi, G
   Sekar, JR
   Arivazhagan, S
AF Ananthi, G.
   Sekar, J. Raja
   Arivazhagan, S.
TI Human palm vein authentication using curvelet multiresolution features
   and score level fusion
SO VISUAL COMPUTER
LA English
DT Article
DE Authentication; Bounding rectangle strategy; Difference of Gaussian
   (DoG); Curvelet transform; Weighted sum rule
ID RECOGNITION; PALMPRINT; IMAGES
AB Human authentication plays a crucial role in sensitive applications like ATM usage, entry into a secured area, attendance and many more. A novel human authentication system is proposed by extracting curvelet multiresolution features from the palm vein trait. The entire palm region is extracted by using an improved bounding rectangle strategy and is further enhanced using Difference of Gaussian (DoG) and Histogram Equalization (HE) methods in order to make the vein pattern, more prominent. Curvelet, a multiresolution transform which handles curve discontinuities well is applied with five scales and sixteen orientations over the enhanced palm vein region. Standard deviation and mean features are calculated from the obtained curvelet subbands. Two scores are computed from these individual features and finally fused using weighted sum rule. The experiments are conducted in publicly available CASIA and VERA palm vein databases which results with the recognition rate of 99.7% and 99.86%, respectively. The proposed system achieved the lowest equal error rate (EER) of 0.021% and 0.0207%, respectively, for CASIA and VERA palm vein database as compared with other state-of-the-art methods. The system performance measured in terms of computation time took a maximum of 0.09 s in identifying an individual.
C1 [Ananthi, G.; Sekar, J. Raja; Arivazhagan, S.] Mepco Schlenk Engn Coll, Sivakasi 626005, Tamil Nadu, India.
C3 Mepco Schlenk Engineering College
RP Ananthi, G (corresponding author), Mepco Schlenk Engn Coll, Sivakasi 626005, Tamil Nadu, India.
EM ananthi@mepcoeng.ac.in; jrsekar@mepcoeng.ac.in; sarivu@mepcoeng.ac.in
RI S, Arivazhagan/T-3033-2019; J, Raja Sekar/T-1985-2019; Alsaif,
   Amal/IUO-9428-2023; Jayaram, Raja Sekar/AAM-2606-2020; G,
   Ananthi/AAC-2482-2022
OI S, Arivazhagan/0000-0002-2579-501X; Alsaif, Amal/0000-0002-8204-0326;
   Jayaram, Raja Sekar/0000-0001-5688-0308; G, Ananthi/0000-0003-3227-2134
CR Abdulla W., 2013, 8 CHIN BIOM C JIN CH
   Ahmad F, 2020, IEEE T INF FOREN SEC, V15, P184, DOI 10.1109/TIFS.2019.2917156
   [Anonymous], 1999, Biometrics: Personal Identification in Networked Society
   Arivazhagan S, 2014, DEFENCE SCI J, V64, P106, DOI 10.14429/dsj.64.3469
   Babalola FO, 2021, SIGNAL IMAGE VIDEO P, V15, P459, DOI 10.1007/s11760-020-01765-6
   Ben Fredj H, 2021, VISUAL COMPUT, V37, P217, DOI 10.1007/s00371-020-01794-9
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès EJ, 1999, APPL COMPUT HARMON A, V6, P197, DOI 10.1006/acha.1998.0248
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Han WY, 2012, EXPERT SYST APPL, V39, P13225, DOI 10.1016/j.eswa.2012.05.079
   Hawkes P., 1993, Hand and Fingerprint Seminar at NPL, P230
   Hernández-García R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142805
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   JIANGANG W, 2007, IEEE COMPUT SOC C CO, V41, P1
   Joardar S, 2016, IEEE INSTRU MEAS MAG, V19, P13, DOI 10.1109/MIM.2016.7462787
   Kang WX, 2014, IEEE T INF FOREN SEC, V9, P1974, DOI 10.1109/TIFS.2014.2361020
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kumar A., 2009, 2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications, P1
   Kumar A, 2009, IEEE T IMAGE PROCESS, V18, P2127, DOI 10.1109/TIP.2009.2023153
   Lee JC, 2012, PATTERN RECOGN LETT, V33, P1520, DOI 10.1016/j.patrec.2012.04.007
   Li CC, 2015, VISUAL COMPUT, V31, P1419, DOI 10.1007/s00371-014-1023-5
   Li QA, 2010, CHIN OPT LETT, V8, P577, DOI 10.3788/COL20100806.0577
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin CL, 2004, IEEE T CIRC SYST VID, V14, P199, DOI 10.1109/TCSVT.2003.821975
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Ma X, 2017, IET BIOMETRICS, V6, P325, DOI 10.1049/iet-bmt.2016.0085
   MacGregor P., 1991, Adv. Imaging, V6, P52
   Majumdar A, 2007, J PATTERN RECOGNIT R, V2, P17, DOI 10.13176/11.27
   Marcel, 2015, INT C BIOM SPEC INT, P215
   Nigam A., 2018, IEEE 4 INT C ID SEC
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qiu YH, 2021, VISUAL COMPUT, V37, P2253, DOI 10.1007/s00371-020-01984-5
   Sayeed F, 2011, DEFENCE SCI J, V61, P431, DOI 10.14429/dsj.61.1178
   Sharma RP, 2019, VISUAL COMPUT, V35, P1393, DOI 10.1007/s00371-018-01618-x
   Smith C. L., 1995, IEEE 29 INT CARN C S
   Su CL, 2009, EXPERT SYST APPL, V36, P1082, DOI 10.1016/j.eswa.2007.11.001
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Wang HG, 2008, PATTERN RECOGN, V41, P1514, DOI 10.1016/j.patcog.2007.10.021
   Watanabe T., 2005, PICTURE BOOK ECOLOGY, P1
   Wu KS, 2013, J SYST SOFTWARE, V86, P2870, DOI 10.1016/j.jss.2013.06.065
   Wu W, 2019, IET BIOMETRICS, V8, P206, DOI 10.1049/iet-bmt.2018.5027
   Xu NY, 2021, VISUAL COMPUT, V37, P695, DOI 10.1007/s00371-020-01962-x
   Yan XK, 2015, NEUROCOMPUTING, V151, P798, DOI 10.1016/j.neucom.2014.10.019
   Yang JX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102822
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang JL, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P627
   Zhixian J., 2013, ADV MAT RES, V710, P655, DOI [10.4028/www.scientific.net/AMR.710.655, DOI 10.4028/WWW.SCIENTIFIC.NET/AMR.710.655]
   Zhou YB, 2011, IEEE T INF FOREN SEC, V6, P1259, DOI 10.1109/TIFS.2011.2158423
NR 52
TC 6
Z9 6
U1 0
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2022
VL 38
IS 6
BP 1901
EP 1914
DI 10.1007/s00371-021-02253-9
EA JUL 2021
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1C6YN
UT WOS:000675047800002
DA 2024-07-18
ER

PT J
AU Jiang, J
   Seah, HS
   Liew, HZ
AF Jiang, Jie
   Seah, Hock Soon
   Liew, Hong Ze
TI Handling gaps for vector graphics coloring
SO VISUAL COMPUTER
LA English
DT Article
DE Vector graphics coloring; Gap size independence; Minimum spanning
   tree-based clustering; Least energy function
AB In computer-assisted 2D vector drawing systems, due to the precision of stroke representation, a stroke endpoint may not precisely connect to another stroke or endpoint during drawing so that the stroke endpoints become dangling. We call such dangling endpoints, gap points. With the presence of gaps on the region boundaries, regions formed by strokes frequently cannot be correctly colored using the standard 'flood fill' algorithm. In this paper, we propose a stroke-based technique to handle gaps in a vector drawing. The main contribution of our work is automatic computation of gap sizes of gap points without a predefined gap size and using a least energy method to handle gap points by estimating their relationship with surrounding strokes. Our approach consists of two major steps. Firstly, we cluster gap points in a drawing using Minimum Spanning Tree. Secondly, for each endpoint cluster, we use a least energy method together with predefined gap handling priority to estimate the connection of gap points. We demonstrate the effectiveness of our approach by applying it to line drawings with unresolved gap points.
C1 [Jiang, Jie; Seah, Hock Soon] Nanyang Technol Univ NTU, Sch Comp Sci & Engn, Singapore, Singapore.
   [Liew, Hong Ze] CACANi Private Ltd, Singapore, Singapore.
C3 Nanyang Technological University
RP Jiang, J (corresponding author), Nanyang Technol Univ NTU, Sch Comp Sci & Engn, Singapore, Singapore.
EM JJIANG009@e.ntu.edu.sg
OI JIANG, JIE/0000-0002-5831-7268
CR Asente P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276415, 10.1145/1239451.1239481]
   Cani, 2020, EUR 2020 P
   Chen Q, 2006, COMPUT ANIMAT VIRT W, V17, P189, DOI 10.1002/cav.122
   Chua, 1997, INSIGHT COMPUT GRAPH, V1994, P62
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Dalstein B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601169
   Fekete, 1994, ACM SIGGRAPH, V94
   Fiser J, 2016, COMPUT GRAPH-UK, V56, P46, DOI 10.1016/j.cag.2016.02.003
   Fourey Sbastien, 2018, FAST EFFICIENT SEMIG
   Fu HB, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024167
   Hati Y., 2019, P EUR C VIS MED PROD, P1
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508373
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Liu SL, 2020, VISUAL COMPUT, V36, P2457, DOI 10.1007/s00371-020-01958-7
   Liu SG, 2012, PATTERN RECOGN LETT, V33, P1673, DOI 10.1016/j.patrec.2012.06.001
   Madeira JS, 1996, VISUAL COMPUT, V12, P1
   Mahdiraji AR, 2009, INT J KNOWL-BASED IN, V13, P39, DOI [10.3233/KES-2009-0168, 10.3233/JAD-2009-0168]
   Parakkat AD, 2018, COMPUT GRAPH-UK, V74, P191, DOI 10.1016/j.cag.2018.05.015
   Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419
   Sandhya B, 2009, 2009 THIRD ASIA INTERNATIONAL CONFERENCE ON MODELLING & SIMULATION, VOLS 1 AND 2, P309, DOI 10.1109/AMS.2009.25
   Sasaki K, 2018, VISUAL COMPUT, V34, P1077, DOI 10.1007/s00371-018-1528-4
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Wang SX, 2020, VISUAL COMPUT, V36, P291, DOI 10.1007/s00371-018-1608-5
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
NR 25
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2021
VL 37
IS 9-11
SI SI
BP 2473
EP 2484
DI 10.1007/s00371-021-02235-x
EA JUL 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UL2RI
UT WOS:000673882600001
DA 2024-07-18
ER

PT J
AU Wang, QR
   Laramee, RS
   Lacey, A
   Pickrell, WO
AF Wang, Qiru
   Laramee, Robert S.
   Lacey, Arron
   Pickrell, William Owen
TI LetterVis: a letter-space view of clinic letters
SO VISUAL COMPUTER
LA English
DT Article
DE Information Visualization; Electronic Health Records; Visual Analytics
ID HEALTH RECORD; VISUALIZATION; TRENDS
AB The number of electronic health records (EHRs) collected by healthcare providers is growing at an unprecedented pace. Clinicians often compose detailed clinic letters to record as much essential information during consultations as they can. This increases the workload of analyzing these letters, performing individual and collective analysis, and clinical decision making. This paper presents a novel visualization tool, LetterVis, to support the analysis of clinic letters through advanced interactive visual designs and queries. We describe a letter-space that facilities the visual exploration of content and patterns inside a letter. Letters are processed using natural language processing techniques and explored in multiple linked interactive views providing different levels of abstraction. The tool includes customized visual designs and views for visualizing antiepileptic drugs (AEDs). We provide a range of filtering and selection options to assist pattern finding and outlier detection. We demonstrate LetterVis with three case studies using anonymized clinic letters, revealing insight that is normally either time-consuming or impossible to observe. Domain expert partners from EHR analysis review the software and are involved in every phase from the initial design to evaluation.
C1 [Wang, Qiru; Laramee, Robert S.] Univ Nottingham, Dept Comp Sci, Nottingham NG8 1BB, England.
   [Lacey, Arron; Pickrell, William Owen] Swansea Univ, Inst Life Sci, Neurol & Mol Neurosci Grp, Swansea SA2 8PP, W Glam, Wales.
C3 University of Nottingham; Swansea University
RP Wang, QR (corresponding author), Univ Nottingham, Dept Comp Sci, Nottingham NG8 1BB, England.
EM qiru.wang@nottingham.ac.uk; robert.laramee@nottingham.ac.uk;
   a.s.lacey@swansea.ac.uk; w.o.pickrell@swansea.ac.uk
RI LI, QI/IUM-8577-2023; wang, qi/IAN-4150-2023; Yang, Bo/JTS-4309-2023;
   wang, qi/ITT-9652-2023; Pickrell, William Owen/F-7110-2014; wang,
   qi/HGV-1859-2022
OI wang, qi/0000-0002-2794-6897; Pickrell, William
   Owen/0000-0003-4396-5657; Wang, Qiru/0000-0003-3397-308X; Laramee,
   Robert S/0000-0002-3874-6145
FU EPSRC [EP/S010238/1, EP/S010238/2] Funding Source: UKRI
CR Aigner Wolfgang, 2011, Foundations and Trends in Human-Computer Interaction, V5, P207, DOI 10.1561/1100000039
   [Anonymous], 2016, MIT CRITICAL DATA 2, DOI [10.1007/978-3-319-43742-2, DOI 10.1007/978-3-319-43742-2]
   Bernard J., 2015, Proceedings of the 2015 Workshop on Visual Analytics in Healthcare - VAHC'15, P1, DOI [10.1145/2836034.2836035, DOI 10.1145/2836034.2836035]
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cunningham H, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002854
   Glueck M, 2018, IEEE T VIS COMPUT GR, V24, P371, DOI 10.1109/TVCG.2017.2745118
   Glueck M, 2017, IEEE T VIS COMPUT GR, V23, P191, DOI 10.1109/TVCG.2016.2598469
   Glueck M, 2016, IEEE T VIS COMPUT GR, V22, P101, DOI 10.1109/TVCG.2015.2467733
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Gunter TD, 2005, J MED INTERNET RES, V7, DOI 10.2196/jmir.7.1.e3
   Hogan T, 2016, IEEE T VIS COMPUT GR, V22, P2579, DOI 10.1109/TVCG.2015.2511718
   Iakovidis I, 1998, INT J MED INFORM, V52, P105, DOI 10.1016/S1386-5056(98)00129-4
   Koleck TA, 2019, J AM MED INFORM ASSN, V26, P364, DOI 10.1093/jamia/ocy173
   Lacey AS, 2018, J NEUROL NEUROSUR PS, V89, P736, DOI 10.1136/jnnp-2017-317515
   Liddy ED, 2001, Natural Language Processing
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Medicines and Healthcare products Regulatory Agency, 2018, NEW MEAS AV VALPR EX
   Neveol A, 2015, Yearb Med Inform, V10, P194, DOI 10.15265/IY-2015-035
   Pickrell WO, 2014, SEIZURE-EUR J EPILEP, V23, P77, DOI 10.1016/j.seizure.2013.09.007
   Rostamzadeh N, 2021, INFORMATICS-BASEL, V8, DOI 10.3390/informatics8010012
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sultanum N, 2019, IEEE T VIS COMPUT GR, V25, P142, DOI 10.1109/TVCG.2018.2864905
   The Apache Software Foundation, 2018, APACH CLIN TEXT AN K
   Trivedi G, 2018, J AM MED INFORM ASSN, V25, P81, DOI 10.1093/jamia/ocx070
   Vellido A, 2020, NEURAL COMPUT APPL, V32, P18069, DOI 10.1007/s00521-019-04051-w
   Vollmer S, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.l6927
   West VL, 2015, J AM MED INFORM ASSN, V22, P330, DOI 10.1136/amiajnl-2014-002955
   Zhang Z., 2011, PROC N AM POWER S NA, P1
NR 28
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2021
VL 37
IS 9-11
SI SI
BP 2643
EP 2656
DI 10.1007/s00371-021-02171-w
EA JUN 2021
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UL2RI
UT WOS:000660824900001
DA 2024-07-18
ER

PT J
AU Wang, J
   Chen, SH
   Lv, X
   Xu, XQ
   Hu, XL
AF Wang, Jian
   Chen, Shuhan
   Lv, Xiao
   Xu, Xiuqi
   Hu, Xuelong
TI Guided residual network for RGB-D salient object detection with
   efficient depth feature learning
SO VISUAL COMPUTER
LA English
DT Article
DE RGB-D salient object detection; Guided residual network; Efficient depth
   feature learning; Adaptive depth weight
AB RGB-D salient object detection aims at identifying the most attractive parts from a RGB image and its corresponding depth image, which has been widely applied in many computer vision tasks. However, there are still two challenges: (1) how to quickly and effectively integrate the cross-modal features from the RGB-D data; and (2) how to mitigate the negative impact from the low-quality depth map. The previous methods mostly employ a two-stream architecture which adopts two backbone network to process RGB-D data and ignore the quality of depth map. In this paper, we propose a guided residual network to address these two issues. On the one hand, we design a simpler and efficient depth branch only using one convolutional layer and three residual modules to extract depth features instead of employing a pre-trained backbone to handle the depth data, and fuse RGB features and depth features in a multi-scale manner for refinement with top-down guidance. On the other hand, we add adaptive weight to depth maps to control the fusion between them, which mitigates the negative influence of unreliable depth map. Experimental results compared with 13 state-of-the-art methods on 7 datasets demonstrate the validity of the proposed approach both quantitatively and qualitatively, especially in efficiency (102 FPS) and compactness (64.2 MB).
C1 [Wang, Jian; Chen, Shuhan; Xu, Xiuqi; Hu, Xuelong] Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Lv, Xiao] Chongqing Special Equipment Inspect & Res Inst, Chongqing, Peoples R China.
C3 Yangzhou University
RP Chen, SH (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
EM haixiaoqu@163.com; c.shuhan@gmail.com; lvxiao87@126.com;
   frequency.xu@foxmail.com; xlhu@yzu.edu.cn
OI Chen, Shuhan/0000-0002-0094-5157
FU Natural Science Foundation of China [61802336]; Jiangsu Province 7th
   Projects for Summit Talents in Six Main Industries, Electronic
   Information Industry [DZXX-149, 110]
FX This work was supported by the Natural Science Foundation of China (No.
   61802336), Jiangsu Province 7th Projects for Summit Talents in Six Main
   Industries, Electronic Information Industry (DZXX-149, No.110).
CR Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kingma D. P., 2014, arXiv
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu ZY, 2021, VISUAL COMPUT, V37, P529, DOI 10.1007/s00371-020-01821-9
   Máttyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Simonyan K, 2015, IEEE INT C ICLR
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Zeng Y., 2009, CVPR, P6074
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
   Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355
NR 46
TC 8
Z9 8
U1 1
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2022
VL 38
IS 5
BP 1803
EP 1814
DI 10.1007/s00371-021-02106-5
EA APR 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0M9JP
UT WOS:000640840600001
DA 2024-07-18
ER

PT J
AU Shingrakhia, H
   Patel, H
AF Shingrakhia, Hansa
   Patel, Hetal
TI SGRNN-AM and HRF-DBN: a hybrid machine learning model for cricket video
   summarization
SO VISUAL COMPUTER
LA English
DT Article
DE Summarization; Key events; Scorecard; Umpire gesture; Deep belief
   network
ID CLASSIFICATION
AB Summarization is important in sports video analysis; it gives a more compact and interesting representation of content. The automatic cricket video summarization is more challenging as it contains several rules and longer match duration. In this research, a hybrid machine learning approach is proposed to summarize cricket video. It analyzes the excitement, object, and event-based features for the detection of key events from the cricket video. First, the audio is analyzed for the extraction of the exciting clips by using an adaptive threshold, speech-to-text framework, and Stacked Gated Recurrent Neural Network with Attention Module (SGRNN-AM). Then, the scenes of each exciting clip are classified with a new Hybrid Rotation Forest Deep Belief Network (HRF-DBN). Next, the characters and action features are extracted from the scorecard region of each key frame and umpire frames of exciting clips. Finally, SGRNN-AM model is used to detect key events including fours, sixes, and wickets. The accuracy of the proposed SGRNN-AM video summarization model is increased with an attention module in the hidden outputs of Gated Recurrent Unit (GRU) for selecting the significant features. The performance of the suggested technique has been improved on various collections of cricket videos. It achieved a precision of 96.82 % and an accuracy of 96.32% that proves its effectiveness.
C1 [Shingrakhia, Hansa; Patel, Hetal] Gujarat Technol Univ, Ahmadabad, Gujarat, India.
   [Shingrakhia, Hansa] Indus Univ, ECE Dept, Ahmadabad, Gujarat, India.
   [Patel, Hetal] AD Patel Inst Technol & Engn, ECE Dept, New Vallabh Vidyanagar, Gujarat, India.
C3 Gujarat Technological University
RP Shingrakhia, H (corresponding author), Gujarat Technol Univ, Ahmadabad, Gujarat, India.; Shingrakhia, H (corresponding author), Indus Univ, ECE Dept, Ahmadabad, Gujarat, India.
EM hansa.shingrakhia.2013@ieee.org; ec.hetal.patel@adit.ac.in
RI Patel, Dr. Hetal/ACE-2852-2022
OI Patel, Dr. Hetal/0000-0002-9764-1861; Shingrakhia,
   Hansa/0000-0001-9820-5095
CR Abdel-Zaher AM, 2016, EXPERT SYST APPL, V46, P139, DOI 10.1016/j.eswa.2015.10.015
   [Anonymous], 2016, IEEE T IND INFORM
   Choros K, 2017, LECT NOTES ARTIF INT, V10191, P619, DOI 10.1007/978-3-319-54472-4_58
   Hari R, 2014, ANNU IEEE IND CONF
   Hassan MM, 2019, INFORM FUSION, V51, P10, DOI 10.1016/j.inffus.2018.10.009
   Javed AR, 2020, J AMB INTEL HUM COMP, DOI [10.1007/s12652-020-01770-0, 10.1007/s10723-019-09498-8]
   Javed A, 2019, APPL INTELL, V49, P2899, DOI 10.1007/s10489-019-01410-x
   Javed A, 2019, IET IMAGE PROCESS, V13, P615, DOI 10.1049/iet-ipr.2018.5589
   Javed A, 2016, IEEE SIGNAL PROC LET, V23, P954, DOI 10.1109/LSP.2016.2573042
   Ji Z, 2019, INFORM SCIENCES, V478, P152, DOI 10.1016/j.ins.2018.09.050
   Kastrati Z, 2019, INFORM PROCESS MANAG, V56, P1618, DOI 10.1016/j.ipm.2019.05.003
   Khanna A, 2022, NUTR NEUROSCI, V25, P1240, DOI 10.1080/1028415X.2020.1853410
   Kolekar MH, 2015, IEEE T BROADCAST, V61, P195, DOI 10.1109/TBC.2015.2424011
   Kolekar MH, 2010, MULTIMED TOOLS APPL, V47, P545, DOI 10.1007/s11042-009-0337-1
   Lin P, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18070251
   Lu W, 2018, IEEE ACCESS, V6, P40198, DOI 10.1109/ACCESS.2018.2851942
   Mahmood M., J IMAGE GR, V6
   McGinnity T., 2018, SCI INF C, P203
   Merler M, 2019, IEEE T MULTIMEDIA, V21, P1147, DOI 10.1109/TMM.2018.2876046
   Minhas RA, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030483
   Moodley T, 2020, LECT NOTES ELECTR EN, V621, P171, DOI 10.1007/978-981-15-1465-4_18
   Naghibi SA, 2019, ENVIRON MONIT ASSESS, V191, DOI 10.1007/s10661-019-7362-y
   Nandyal S, 2020, SCALABLE COMPUT-PRAC, V21, P173, DOI 10.12694/scpe.v21i2.1655
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Panagiotakis Costas, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P305, DOI 10.1007/978-3-030-45442-5_38
   Rafiq M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061702
   Rani S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102190
   Ravi A, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1396, DOI 10.1109/SSCI.2018.8628877
   Sheena CV, 2015, PROCEDIA COMPUT SCI, V70, P36, DOI 10.1016/j.procs.2015.10.021
   Shingrakhia H, 2020, MULTIMEDIA SYST, V26, P745, DOI 10.1007/s00530-020-00684-3
   Shukla P, 2018, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2018.00233
   Stahl N, 2020, INT C INF PROC MAN U, P556, DOI DOI 10.1007/978-3-030-50146-4_41
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Yang FR, 2017, IEEE SIGNAL PROC LET, V24, P1778, DOI 10.1109/LSP.2017.2718564
   Zhang N, 2018, NEUROCOMPUTING, V275, P1186, DOI 10.1016/j.neucom.2017.09.065
NR 35
TC 12
Z9 12
U1 1
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2022
VL 38
IS 7
BP 2285
EP 2301
DI 10.1007/s00371-021-02111-8
EA APR 2021
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2B0WL
UT WOS:000639372900001
DA 2024-07-18
ER

PT J
AU Yang, QN
   Shi, WM
   Chen, J
   Tang, Y
AF Yang, Qiaoning
   Shi, Weimin
   Chen, Juan
   Tang, Yang
TI Localization of hard joints in human pose estimation based on residual
   down-sampling and attention mechanism
SO VISUAL COMPUTER
LA English
DT Article
DE Residual down-sampling; Attention mechanisms; Deep learning; Hard
   joints; Pose estimation
AB Hard-joint localization in human pose estimation is a challenging task for some reasons, such as the disappearance of joint points caused by clothing and lighting, the shelter caused by complex environment and the destruction of dependence among each joint point. A majority of existing approaches for hard-joint pose estimation achieve high accuracy by obtaining more high-level feature information. However, most networks suffer from information loss, which is caused by down-sampling. This would result in the loss of joint location. The compensation of information loss introduces useless information to network learning, affecting the extraction of useful information associated with hard joints. Herein, a residual down-sampling module is proposed to replace the pooling layer for down-sampling and fuse high-level features with low-resolution feature maps. This module aims to address the information loss issue. A strategy to guide network learning based on the attention mechanism is proposed, which makes the network focus on useful feature information. A convolutional block attention module is combined with a residual module outside the basic sub-network. The network can learn more effective high-level features. An eight-stack hourglass is used as the basic network, and the proposed method is validated on the MPII and LSP Human Pose dataset. Compared with eight-stack hourglass and HRNet, the proposed method achieves higher accuracy for hard-joint localization. The experimental results show our proposed methods effective for hard-joint localization.
C1 [Yang, Qiaoning; Shi, Weimin; Chen, Juan; Tang, Yang] Beijing Univ Chem Technol, Coll Informat Sci, Fifteen North Third Ring Rd East, Beijing 100020, Peoples R China.
C3 Beijing University of Chemical Technology
RP Yang, QN (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci, Fifteen North Third Ring Rd East, Beijing 100020, Peoples R China.
EM yangqn@mail.buct.edu.cn
RI Shi, Weimin/AAL-5136-2020
OI Shi, Weimin/0000-0002-8744-395X
CR Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chu X., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1831, DOI DOI 10.1109/CVPR.2017.601
   Everingham M., 2010, BMVC, V2, P5
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang T, 2019, VISUAL COMPUT, V35, P1655, DOI 10.1007/s00371-018-1565-z
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Newell A., 2017, ADV NEUR IN, P2171
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30
   Su K, 2019, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2019.00582
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sypetkowski M, 2019, J UNIVERS COMPUT SCI, V25, P683
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang W, 2019, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2019.00120
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Vaswani A, 2017, ADV NEUR IN, V30
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Zhang F, 2019, PROC CVPR IEEE, P3512, DOI 10.1109/CVPR.2019.00363
NR 27
TC 11
Z9 11
U1 0
U2 17
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2022
VL 38
IS 7
BP 2447
EP 2459
DI 10.1007/s00371-021-02122-5
EA APR 2021
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2B0WL
UT WOS:000638818700002
DA 2024-07-18
ER

PT J
AU Ma, YD
   Sun, SY
   Wu, FJ
   Yang, YF
   Yang, X
   Xu, B
   Luo, ZJ
AF Ma, Yuandong
   Sun, Shouyu
   Wu, Fengjiao
   Yang, Yunfan
   Yang, Xin
   Xu, Bin
   Luo, Zijiang
TI Additive margin cosine loss for image registration
SO VISUAL COMPUTER
LA English
DT Article
DE Image registration; Cosine loss; Convolution neural network; Computer
   vision
AB In view of the multi-scale changes and the influence of light and angle in the image matching process, it is quite difficult to realize intelligent image registration by using convolutional neural network. The existing image matching algorithm has the following problems in the application process: the existing shallow feature extraction model has lost a lot of effective feature information and low recognition accuracy. Meanwhile, the image registration method based on deep learning is not robust and accurate enough. Therefore, an image registration method based on additive edge cosine loss was proposed in this paper. In the twin network architecture, cosine loss was used to convert Euclidean space into angular space, which eliminated the influence of characteristic intensity and improved the accuracy of registration. The matching cost was directly calculated by the included angle of two vectors in the embedded space, where the size of the angle edge could be quantitatively adjusted through parameter m. We further derived a specific m to quantitatively adjust the loss. In addition, anti-rotation attention mechanism was added to the network to enhance the ability of feature information extraction and adjust the position information of feature vectors to reduce the mismatching caused by image rotation.
C1 [Ma, Yuandong; Sun, Shouyu; Wu, Fengjiao; Yang, Yunfan; Yang, Xin; Luo, Zijiang] Guizhou Univ Finance & Econ, Sch Informat, Guiyang, Guizhou, Peoples R China.
   [Ma, Yuandong; Sun, Shouyu; Wu, Fengjiao; Xu, Bin] Beijing Interjoy Technol Co Ltd, Beijing, Peoples R China.
C3 Guizhou University of Finance & Economics
RP Luo, ZJ (corresponding author), Guizhou Univ Finance & Econ, Sch Informat, Guiyang, Guizhou, Peoples R China.
EM mayuandong@mail.gufe.edu.cn; luozijiang@mail.gufe.edu.cn
RI Ma, Yuandong/KHW-7910-2024
OI Ma, Yuandong/0000-0003-1891-7661; luo, zijiang/0000-0002-7907-0858
FU National Natural Science Foundation of China [11664005]; Science and
   technology planning project of Guizhou province [2020-1Y021];
   Postgraduate Education Innovation Plan of Guizhou Province [YJSCXJH
   2019-066]; School-level project of Guizhou University of Finance and
   Economics in 2020 [2020XJC03]
FX This research was funded by the National Natural Science Foundation of
   China, Grant Nos. 11664005; Science and technology planning project of
   Guizhou province, Grant No. 2020-1Y021; Postgraduate Education
   Innovation Plan of Guizhou Province, Grant No. YJSCXJH 2019-066;
   School-level project of Guizhou University of Finance and Economics in
   2020, No. 2020XJC03.
CR Altwaijry H, 2016, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2016.385
   [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   [Anonymous], 2016, J Comput Sci, DOI DOI 10.3844/JCSSP.2016.213.222
   Balakrishnan G, 2019, IEEE T MED IMAGING, V38, P1788, DOI 10.1109/TMI.2019.2897538
   Balakrishnan G, 2018, PROC CVPR IEEE, P9252, DOI 10.1109/CVPR.2018.00964
   Balntas V., 2016, ARXIV160105030
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bruzzone L, 1995, IEEE T GEOSCI REMOTE, V33, P1318, DOI 10.1109/36.477187
   Chen SH, 2021, IEEE T GEOSCI REMOTE, V59, P3244, DOI 10.1109/TGRS.2020.3008609
   Daniel D., 2018, IEEE C COMP VIS PATT, P1
   Darrell T., 2014, NIPS, P1056
   Dong XY, 2019, IEEE T IMAGE PROCESS, V28, P518, DOI 10.1109/TIP.2018.2867747
   Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Ebel P, 2019, IEEE I CONF COMP VIS, P253, DOI 10.1109/ICCV.2019.00034
   Eppenhof KAJ, 2020, IEEE T MED IMAGING, V39, P1594, DOI 10.1109/TMI.2019.2953788
   Fan B, 2012, PATTERN RECOGN, V45, P794, DOI 10.1016/j.patcog.2011.08.004
   Feng RT, 2019, ISPRS J PHOTOGRAMM, V151, P15, DOI 10.1016/j.isprsjprs.2019.03.002
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   He K., IEEE I CONF COMP VIS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Ke Y, 2004, PROC CVPR IEEE, P506
   Khan M. J., 2017, J SPACE TECHNOL, V7, P44, DOI DOI 10.3390/S22031147
   Khan MUD, 2018, ITAL J PURE APPL MAT, P1, DOI 10.1080/02692171.2018.1518411
   Khan MA, 2019, MATER RES FOUND, V50, P1, DOI 10.21741/9781644900239-1
   Khan MJ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053001
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   kumar V, 2016, IEEE C COMP VIS PATT, P1740
   Laguna AB., 2019, P 2019 IEEE CVF INT, P593
   LANCE GN, 1966, COMPUT J, V9, P60, DOI 10.1093/comjnl/9.1.60
   Lei Y, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab79c4
   Li C, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060895
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mishchuk A., 2017, P ADV NEURAL INFORM, P4826
   MooYi K., 2016, LEARNED INVARIANT FE, P319
   Noh H., 2017, LARGESCALE IMAGE RET, P1612
   Revaud J, 2019, ADV NEUR IN, V32
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Savinov N, 2017, PROC CVPR IEEE, P3929, DOI 10.1109/CVPR.2017.418
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sdika M, 2008, IEEE T MED IMAGING, V27, P271, DOI 10.1109/TMI.2007.905820
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Tian YR, 2019, PROC CVPR IEEE, P11008, DOI 10.1109/CVPR.2019.01127
   Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   Wen YD, 2019, INT J COMPUT VISION, V127, P668, DOI 10.1007/s11263-018-01142-4
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang M, 2017, NEUROCOMPUTING, V6, P132
   Yousaf A, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12503
   Yuki O., 2018, C WORKSH NEUR INF PR, P125
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang X, 2017, PROC CVPR IEEE, P4923, DOI 10.1109/CVPR.2017.523
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zhong DX, 2020, IEEE T CIRC SYST VID, V30, P1559, DOI 10.1109/TCSVT.2019.2904283
NR 65
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2022
VL 38
IS 5
BP 1787
EP 1802
DI 10.1007/s00371-021-02105-6
EA MAR 2021
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0M9JP
UT WOS:000630256700002
DA 2024-07-18
ER

PT J
AU Zhang, XW
   Gong, YS
   Qiao, C
   Jing, WF
AF Zhang, Xuewu
   Gong, Yansheng
   Qiao, Chen
   Jing, Wenfeng
TI Multiview deep learning based on tensor decomposition and its
   application in fault detection of overhead contact systems
SO VISUAL COMPUTER
LA English
DT Article
DE High-speed railway catenary; Fault detection; Faster R-CNN; Multiview
   feature fusion; Tensor decomposition
ID CNN
AB This article mainly focuses on the most common types of high-speed railways malfunctions in overhead contact systems, namely, unstressed droppers, foreign-body invasions, and pole number-plate malfunctions, to establish a deep-network detection model. By fusing the feature maps of the shallow and deep layers in the pretraining network, global and local features of the malfunction area are combined to enhance the network's ability of identifying small objects. Further, in order to share the fully connected layers of the pretraining network and reduce the complexity of the model, Tucker tensor decomposition is used to extract features from the fused-feature map. The operation greatly reduces training time. Through the detection of images collected on the Lanxin railway line, experiments result show that the proposed multiview Faster R-CNN based on tensor decomposition had lower miss probability and higher detection accuracy for the three types faults. Compared with object-detection methods YOLOv3, SSD, and the original Faster R-CNN, the average miss probability of the improved Faster R-CNN model in this paper is decreased by 37.83%, 51.27%, and 43.79%, respectively, and average detection accuracy is increased by 3.6%, 9.75%, and 5.9%, respectively.
C1 [Zhang, Xuewu; Gong, Yansheng] China Railway First Survey & Design Inst Grp Co L, Xian 710043, Peoples R China.
   [Qiao, Chen; Jing, Wenfeng] Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Jing, WF (corresponding author), Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian 710049, Peoples R China.
EM wfjing@xjtu.edu.cn
RI Zhang, Xuewu/HGB-5196-2022; Gong, YanSheng/C-9849-2011
OI Wenfeng, Jing/0000-0003-0362-8728
FU China Railway Construction Corporation [18-A02]; Science and Technology
   Program of Xi'an [201809164CX5J6C6, 2019421315KYPT004 JC006]
FX This paper is supported by Major Special Project (18-A02) of China
   Railway Construction Corporation in 2018 and Science and Technology
   Program (201809164CX5J6C6, 2019421315KYPT004 JC006) of Xi'an.
CR CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Guo QF, 2020, IEEE ACCESS, V8, P105622, DOI 10.1109/ACCESS.2020.3000506
   HARSHMAN RA, 1994, COMPUT STAT DATA AN, V18, P39, DOI 10.1016/0167-9473(94)90132-5
   [蒋欣兰 Jiang Xinlan], 2019, [计算机工程与应用, Computer Engineering and Application], V55, P250
   Karakose E, 2017, IEEE T IND INFORM, V13, P635, DOI 10.1109/TII.2016.2628042
   Li, 2016, CHINA EMERG MANAG, V06, P24
   Li, 2012, GUIDE SCI TECH MAG, V02, P182
   Liu WQ, 2020, IEEE ACCESS, V8, P17049, DOI 10.1109/ACCESS.2020.2967831
   Petitjean C, 2009, LECT NOTES COMPUT SC, V5524, P225, DOI 10.1007/978-3-642-02172-5_30
   Qu ZJ, 2019, IEEE ACCESS, V7, P23210, DOI 10.1109/ACCESS.2019.2899074
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wu Jingfeng, 2019, Computer Engineering and Applications, V55, P193, DOI 10.3778/j.issn.1002-8331.1802-0156
   XU YB, 2018, APPL IMAGE PROCESSIN
   Yang, 2018, GENERATIVE ADVERSARI
   Zhong JP, 2019, IEEE T INSTRUM MEAS, V68, P2849, DOI 10.1109/TIM.2018.2871353
NR 16
TC 5
Z9 5
U1 3
U2 31
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2022
VL 38
IS 4
SI SI
BP 1457
EP 1467
DI 10.1007/s00371-021-02080-y
EA FEB 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0D9DX
UT WOS:000619384200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kuanar, S
   Mahapatra, D
   Bilas, M
   Rao, KR
AF Kuanar, Shiba
   Mahapatra, Dwarikanath
   Bilas, Monalisa
   Rao, K. R.
TI Multi-path dilated convolution network for haze and glow removal in
   nighttime images
SO VISUAL COMPUTER
LA English
DT Article
DE CNN; DeGlow; DeHaze; Depth; Dilated convolution
AB In this paper, we address the single-image haze removal problem in nighttime scenes. The night haze removal is a severely ill-posed problem due to the presence of various visible night light sources with varying colors and non-uniform illumination. These light sources are of different shapes and introduce a noticeable amount of glow in the night scenes. To overcome these effects, we introduce a deep learning-based DeGlow-DeHaze iterative model which accounts for varying colors and glows. The proposed model is a linear combination of three terms: the direct transmission attenuation, airlight and glow. First, a multi-path dilated convolution DeGlow network is introduced to interactively learn the local features with different reception fields and reduce the glow effect. The glow term is estimated by a binary mask that informs the location of the illumination source. As a result, the nighttime image is only left with only direct transmission and airlight terms. Finally, a separate post-processing DeHaze network is included to remove the haze effect from the reduced glow image. For our model training, we collected the night hazy images from internal and external resources, synthesized transmission maps from the NYU depth datasets, and consequently restored the haze-free images. The quantitative and qualitative evaluations show the effectiveness of our model on several real and synthetic images and compare our results with existing night haze models. The experimental results demonstrate that our multi-path CNN model outperforms other state-of-the-art methods in terms of PSNR (19.25 dB), SSIM (0.9958) evaluation parameters and computation time.
C1 [Kuanar, Shiba; Rao, K. R.] Univ Texas Arlington, Elect Engn, Arlington, TX 76019 USA.
   [Mahapatra, Dwarikanath] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.
   [Bilas, Monalisa] Univ Texas Dallas, Informat Syst, Richardson, TX 75083 USA.
C3 University of Texas System; University of Texas Arlington; University of
   Texas System; University of Texas Dallas
RP Kuanar, S (corresponding author), Univ Texas Arlington, Elect Engn, Arlington, TX 76019 USA.
EM shiba.kuanar@mavs.uta.edu
OI KUANAR, SHIBA/0000-0002-8670-6957
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2020, IEEE T IMAGE PROCESS, V29, P6264, DOI 10.1109/TIP.2020.2988203
   [Anonymous], 1952, VISION ATMOSPHERE
   [Anonymous], 2016, P ICLR
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Caraffa L, 2013, IEEE INT VEH SYM, P994, DOI 10.1109/IVS.2013.6629596
   Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Koschmieder H., 1925, Theorie der horizontalen Sichtweite: Kontrast und Sichtweite
   Kuanar S., 2019, ARXIV190200855
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lombardi S, 2016, IEEE T PATTERN ANAL, V38, P129, DOI 10.1109/TPAMI.2015.2430318
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mutimbu L, 2016, IEEE T IMAGE PROCESS, V25, P5383, DOI 10.1109/TIP.2016.2605003
   Narasimhan SG, 2003, PROC CVPR IEEE, P665
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Scharst D., 2007, IEEE CVPR, V31, P1582
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Shih YC, 2015, PROC CVPR IEEE, P3193, DOI 10.1109/CVPR.2015.7298939
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang J, 2017, PROC CVPR IEEE, P7016, DOI 10.1109/CVPR.2017.742
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 37
TC 24
Z9 25
U1 5
U2 45
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2022
VL 38
IS 3
BP 1121
EP 1134
DI 10.1007/s00371-021-02071-z
EA FEB 2021
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZQ8YX
UT WOS:000618571000001
OA Bronze
DA 2024-07-18
ER

PT J
AU Qin, ZX
   Yin, MX
   Lin, ZF
   Yang, F
   Zhong, C
AF Qin, Zixuan
   Yin, Mengxiao
   Lin, Zhenfeng
   Yang, Feng
   Zhong, Cheng
TI Three-view generation based on a single front view image for car
SO VISUAL COMPUTER
LA English
DT Article
DE Deep learning; Orthographic views; Front view; Point cloud shell
AB The multi-view of an object can be used for 3D reconstruction. The method proposed in this paper generates the left and the top view of a target car through deep learning. The input of the method is only a front view of a 3D car and it isn't necessary for the depth of the 3D car. Firstly, a rough orthographic views of the 3D car is gotten from an information constraint network which is constructed by considering the structural relation between one view and the other two views. And then the rough orthographic views is transformed into large-pixel block rough view through the nearest interpolation, at the same time, the large-pixel blocks are also migrated to improve the quality of the rough orthographic views. Finally, the generative adversarial network with perception loss is used to enhance the large-pixel block view. In addition, the three views generated by the network can be used to synthesize a 3D point cloud shell.
C1 [Qin, Zixuan; Yin, Mengxiao; Lin, Zhenfeng; Yang, Feng; Zhong, Cheng] Guangxi Univ, Sch Comp & Elect Informat, Nanning, Peoples R China.
   [Yin, Mengxiao; Yang, Feng; Zhong, Cheng] Guangxi Key Lab Multimedia Commun & Network Techn, Nanning, Peoples R China.
C3 Guangxi University
RP Yin, MX (corresponding author), Guangxi Univ, Sch Comp & Elect Informat, Nanning, Peoples R China.; Yin, MX (corresponding author), Guangxi Key Lab Multimedia Commun & Network Techn, Nanning, Peoples R China.
EM ymdfx@qq.com
FU Natural Science Foundation of China [61762007, 61861004]; Natural
   Science Foundation of Guangxi Province, China [2017GXNSFAA198269,
   2017GXNSFAA198267]
FX This work is partially supported by the Natural Science Foundation of
   China (Nos. 61762007 and 61861004), Natural Science Foundation of
   Guangxi Province, China (Nos. 2017GXNSFAA198269 and 2017GXNSFAA198267).
CR Agarwal G, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010055
   Chang Angel X., 2015, arXiv
   Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grigorev Artur, 2018, ARXIV181111459
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   Idesawa M., 1973, Bulletin of the Japan Society of Mechanical Engineers, V16, P216, DOI 10.1299/jsme1958.16.216
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaderberg M., 2014, CORR
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kholgade Natasha, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601209
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, ARXIV13126114
   Koch Sebastian, 2019, P IEEE C COMP VIS PA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JX, 2019, INT SYMPOS COMPUT NE, P37, DOI 10.1109/CANDAR.2019.00013
   Liu JC, 2019, VISUAL COMPUT, V35, P909, DOI 10.1007/s00371-019-01679-6
   Liu Shi-Xia, 2000, Chinese Journal of Computers, V23, P141
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luciano L, 2019, VISUAL COMPUT, V35, P1171, DOI 10.1007/s00371-019-01668-9
   Lucic M, 2019, PR MACH LEARN RES, V97
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Olszewski K, 2019, IEEE I CONF COMP VIS, P7647, DOI 10.1109/ICCV.2019.00774
   Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82
   Razavi A, 2019, ADV NEUR IN, V32
   Rematas K, 2017, IEEE T PATTERN ANAL, V39, P1576, DOI 10.1109/TPAMI.2016.2601093
   Shu ZY, 2020, IEEE T VIS COMPUT GR, V26, P2671, DOI 10.1109/TVCG.2019.2892076
   Shu ZY, 2019, IEEE T VIS COMPUT GR, V25, P2583, DOI 10.1109/TVCG.2018.2848628
   Shu ZY, 2016, COMPUT AIDED GEOM D, V43, P39, DOI 10.1016/j.cagd.2016.02.015
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitzmann V, 2019, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2019.00254
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sun YH, 2017, IEEE ICC
   Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20
   Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang J., 2015, Advances in Neural Information Processing Systems, P1099
   Zhang SY, 2019, VISUAL COMPUT, V35, P1157, DOI 10.1007/s00371-019-01691-w
   Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18
NR 41
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2021
VL 37
IS 8
BP 2195
EP 2205
DI 10.1007/s00371-020-01979-2
EA SEP 2020
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TT5FX
UT WOS:000572037900001
DA 2024-07-18
ER

PT J
AU Shimamura, R
   Feng, Q
   Koyama, Y
   Nakatsuka, T
   Fukayama, S
   Hamasaki, M
   Goto, M
   Morishima, S
AF Shimamura, Ryo
   Feng, Qi
   Koyama, Yuki
   Nakatsuka, Takayuki
   Fukayama, Satoru
   Hamasaki, Masahiro
   Goto, Masataka
   Morishima, Shigeo
TI Audio-visual object removal in 360-degree videos
SO VISUAL COMPUTER
LA English
DT Article
DE Audio-visual object removal; 360-degree video; Human perception; Signal
   processing; Virtual reality
ID SOUND; SEPARATION
AB We present a novel conceptaudio-visual object removalin 360-degree videos, in which a target object in a 360-degree video is removed in both the visual and auditory domains synchronously. Previous methods have solely focused on the visual aspect of object removal using video inpainting techniques, resulting in videos with unreasonable remaining sounds corresponding to the removed objects. We propose a solution which incorporates direction acquired during the video inpainting process into the audio removal process. More specifically, our method identifies the sound corresponding to the visually tracked target object and then synthesizes a three-dimensional sound field by subtracting the identified sound from the input 360-degree video. We conducted a user study showing that our multi-modal object removal supporting both visual and auditory domains could significantly improve the virtual reality experience, and our method could generate sufficiently synchronous, natural and satisfactory 360-degree videos.
C1 [Shimamura, Ryo; Feng, Qi; Nakatsuka, Takayuki] Waseda Univ, Tokyo, Japan.
   [Koyama, Yuki; Fukayama, Satoru; Hamasaki, Masahiro; Goto, Masataka] Natl Inst Adv Ind Sci & Technol, Tsukuba, Ibaraki, Japan.
   [Morishima, Shigeo] Waseda Res Inst Sci & Engn, Tokyo, Japan.
C3 Waseda University; National Institute of Advanced Industrial Science &
   Technology (AIST); Waseda University
RP Shimamura, R (corresponding author), Waseda Univ, Tokyo, Japan.
EM s-ryo@akane.waseda.jp; shigeo@waseda.jp
RI Nakatsuka, Takayuki/AAK-8819-2021; Hamasaki, Masahiro/AAS-1222-2021;
   FENG, Qi/ABC-6684-2020; Fukayama, Satoru/H-7863-2016
OI Nakatsuka, Takayuki/0000-0003-3181-4894; Hamasaki,
   Masahiro/0000-0003-3085-7446; FENG, Qi/0000-0002-6892-3122; Morishima,
   Shigeo/0000-0001-8859-6539; Shimamura, Ryo/0000-0002-8219-7470
FU JST ACCEL Grant, Japan [JPM-JAC1602]; JSPS KAKENHI Grant, Japan
   [JP19H01129]; JST-Mirai Program Grant, Japan [JPMJMI19B2]
FX This work was supported by JST ACCEL Grant No. JPM-JAC1602, JST-Mirai
   Program Grant Number JPMJMI19B2 and JSPS KAKENHI Grant No. JP19H01129,
   Japan.
CR Akyazi P, 2018, EUR SIGNAL PR CONF, P867, DOI 10.23919/EUSIPCO.2018.8553205
   Bertalmio M, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P33, DOI 10.1007/0-387-28831-7_3
   Bertalmio M., 2001, PROC CVPR IEEE, V1, P1, DOI DOI 10.1109/CVPR.2001.990497
   Feng WJ, 2017, IEEE IJCNN, P681, DOI 10.1109/IJCNN.2017.7965918
   GERZON MA, 1973, J AUDIO ENG SOC, V21, P2
   Hershey J, 2002, ADV NEUR IN, V14, P1173
   Kim D, 2019, PROC CVPR IEEE, P5785, DOI 10.1109/CVPR.2019.00594
   Korman S, 2016, IEEE T PATTERN ANAL, V38, P1099, DOI 10.1109/TPAMI.2015.2477814
   Kowalczyk K, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2014.2369531
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3401, DOI 10.1109/ICIP.2011.6116441
   Morgado Pedro, 2018, Advances in Neural Information Processing Systems, P362
   Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347
   Nair AA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1107, DOI 10.1145/3343031.3351010
   Paredes Daniel, 2013, 2013 IEEE International Symposium on Robotic and Sensors Environments (ROSE 2013), P67, DOI 10.1109/ROSE.2013.6698420
   Pulkki V, 2007, J AUDIO ENG SOC, V55, P503
   Ricoh Company Ltd., 360 DEGR CAM RICOH T
   Rivet B, 2014, IEEE SIGNAL PROC MAG, V31, P125, DOI 10.1109/MSP.2013.2296173
   Upenik E, 2019, INT CONF ACOUST SPEE, P2487, DOI 10.1109/ICASSP.2019.8683346
   Van Veen B. D., 1988, IEEE ASSP Magazine, V5, P4, DOI 10.1109/53.665
   Vilkamo J, 2009, J AUDIO ENG SOC, V57, P709
   Wang QZ, 2019, PROC CVPR IEEE, P4190, DOI 10.1109/CVPR.2019.00432
   Wang RC, 2014, IEEE I C NETW INFRAS, P338, DOI 10.1109/ICNIDC.2014.7000321
   Xu R, 2019, PROC CVPR IEEE, P3718, DOI 10.1109/CVPR.2019.00384
   Yang WY, 2018, INT C PATT RECOG, P2190, DOI 10.1109/ICPR.2018.8546070
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
NR 26
TC 6
Z9 6
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2020
VL 36
IS 10-12
BP 2117
EP 2128
DI 10.1007/s00371-020-01918-1
EA JUL 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NW1CX
UT WOS:000557083200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, CX
   Zhang, HY
   Liu, LG
AF Wang, Chunxue
   Zhang, Huayan
   Liu, Ligang
TI Total generalized variation-based Retinex image decomposition
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Retinex theory; Image decomposition; Total generalized variation
   regularization; Alternating minimization scheme
ID TOTAL VARIATION MODEL; IMPLEMENTATION; ILLUMINATION; LIGHTNESS;
   ALGORITHM
AB Human visual system (HVS) can perceive color under varying illumination conditions, and Retinex theory is precisely aimed to simulate and explain how the HVS perceives reflectance regardless of different illumination conditions. In this paper, we introduce a reflectance and illumination decomposition model for the Retinex problem via total generalized variation regularization and H-1 decomposition. The total generalized variation regularization ameliorates the staircasing artifacts that appear in the reflectance component of existing total variation-based models and H-1 norm guarantees smoother illumination. We analyze the existence and uniqueness of the proposed model and employ an alternating minimization scheme based on split Bregman iteration. We present numerous numerical experiments on both grayscale and color images to make comparisons with several state-of-the-art methods and demonstrate that our method is comparable both quantitatively and qualitatively.
C1 [Wang, Chunxue] Dunhuang Acad, Cultural Heritage Digitizat Inst, Dunhuang, Gansu, Peoples R China.
   [Zhang, Huayan] Tiangong Univ, Sch Comp Sci & Software Engn, Tianjin, Peoples R China.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei, Anhui, Peoples R China.
C3 Tiangong University; Chinese Academy of Sciences; University of Science
   & Technology of China, CAS
RP Wang, CX (corresponding author), Dunhuang Acad, Cultural Heritage Digitizat Inst, Dunhuang, Gansu, Peoples R China.
EM chunxuewang2019@163.com
RI chen, minghui/KFR-8832-2024
FU NationalNatural Science Foundation of China [61802279, 61602341];
   National Natural Science Foundation of Tianjin [18JCQNJC00100,
   17JCQNJC00600]
FX We would like to thank Michael K. Ng [51], Jingwei Liang [38], Xueyang
   Fu [14] and ChenWei [70] for sharing their code and the reviewers of
   this manuscript for their helpful comments and suggestions. Thiswork is
   supported by the NationalNatural Science Foundation of China (61802279,
   61602341) and the National Natural Science Foundation of Tianjin
   (18JCQNJC00100, 17JCQNJC00600).
CR [Anonymous], 2018, P BRIT MACH VIS C
   Berthold KP, 1974, Comput. Graph. Image Process., V3, P277, DOI [DOI 10.1016/0146-664X(74)90022-7, 10.1016/0146-664X(74)90022-7]
   BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4
   Bredies K, 2013, J MATH ANAL APPL, V398, P438, DOI 10.1016/j.jmaa.2012.08.053
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chang HB, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.1.013107
   Cheng MH, 2019, APPL MATH MODEL, V66, P305, DOI 10.1016/j.apm.2018.09.022
   Choi D.H., 2008 16 EUROPEAN SIG, P1
   Choi DH, 2007, IEEE INT SYMP CIRC S, P3948, DOI 10.1109/ISCAS.2007.378664
   Ciurea F., 2004, J ELECTRON IMAGING, V13, P48
   Cooper TJ, 2004, J ELECTRON IMAGING, V13, P85, DOI 10.1117/1.1636182
   Dahifale BS, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2010, VOL 5, PTS A AND B, P1
   Duan JM, 2015, J GLOBAL OPTIM, V62, P853, DOI 10.1007/s10898-015-0290-7
   Duan JM, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-7
   Frankle J. A., 1983, US Patent, Patent No. [4 384 336, 4384336, US, 4384336]
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Funt B, 2000, EIGHTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P112
   FUNT BV, 1992, LECT NOTES COMPUT SC, V588, P124
   Gao YY, 2018, IEEE T MULTIMEDIA, V20, P335, DOI 10.1109/TMM.2017.2740025
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gu SH, 2017, IEEE I CONF COMP VIS, P1717, DOI 10.1109/ICCV.2017.189
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Guojia Hou, 2017, IAENG International Journal of Computer Science, V44, P445
   Jiang B, 2015, J REAL-TIME IMAGE PR, V10, P239, DOI 10.1007/s11554-014-0399-9
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Juha K., 2017, SOBOLEV SPACES
   Kang M, 2017, J SCI COMPUT, V72, P172, DOI 10.1007/s10915-017-0357-3
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Land E.H, 1986, ALTERNATIVE TECHNIQU, P3078
   Land E.H., 1983, RECENT ADV RETINEX T, P5163
   Land Edwin H., 1985, Wenner-gren center international symposium series, P5
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2012, IEEE IMAGE PROC, P965, DOI 10.1109/ICIP.2012.6467022
   Lei Ling, 2007, Journal of Electronics (China), V24, P696, DOI 10.1007/s11767-006-0222-2
   Li HF, 2012, IEEE T GEOSCI REMOTE, V50, P3053, DOI 10.1109/TGRS.2011.2178075
   Liang JW, 2015, J MATH IMAGING VIS, V52, P345, DOI 10.1007/s10851-015-0568-x
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lu WQ, 2016, MATH METHOD APPL SCI, V39, P4208, DOI 10.1002/mma.3858
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Ma WY, 2012, INVERSE PROBL IMAG, V6, P697, DOI 10.3934/ipi.2012.6.697
   Ma WY, 2011, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2011.5995422
   Ma Y., 2017, INT C IM GRAPH, P626
   Marini D, 2000, IMAGE VISION COMPUT, V18, P1005, DOI 10.1016/S0262-8856(00)00037-8
   Maz'ya V., 2013, SOBOLEV SPACES
   McCann J, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P1
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Morel J.M., 2009, P COL IM 14 DISPL PR, V7241
   Morel JM, 2010, IEEE T IMAGE PROCESS, V19, P2825, DOI 10.1109/TIP.2010.2049239
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Pallara L. A. -N. F. -D., 2000, FUNCTIONS BOUNDED VA
   Park S, 2018, IEEE ACCESS, V6, P22084, DOI 10.1109/ACCESS.2018.2812809
   Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613
   Provenzi E, 2007, IEEE T IMAGE PROCESS, V16, P162, DOI 10.1109/TIP.2006.884946
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Shen L., 2017, ARXIV PREPRINT ARXIV, P171102488
   Shi W, 2016, LECT NOTES COMPUT SC, V9908, P371, DOI 10.1007/978-3-319-46493-0_23
   Shi Y., 2019, ARXIV190606027
   Wali S, 2019, J VIS COMMUN IMAGE R, V59, P39, DOI 10.1016/j.jvcir.2018.12.047
   Wang LQ, 2014, IEEE T IMAGE PROCESS, V23, P3381, DOI 10.1109/TIP.2014.2324813
   Wang QH, 2016, IEEE IMAGE PROC, P4077, DOI 10.1109/ICIP.2016.7533126
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang W, 2015, SIAM J IMAGING SCI, V8, P1955, DOI 10.1137/15M1006908
   Wang W, 2014, NUMER MATH-THEORY ME, V7, P334, DOI 10.4208/nmtma.2014.1326nm
   Wang W, 2008, INT C WAVEL ANAL PAT, P80, DOI 10.1109/ICWAPR.2008.4635754
   Zhang X.M., 1996, Society of Information Display Symposium Technical Digest, V27, P731
   Zosso D, 2013, PROC SPIE, V8657, DOI 10.1117/12.2008839
NR 71
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD 2020 JUL 9
PY 2020
DI 10.1007/s00371-070-01888-4
EA JUL 2020
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MH6PQ
UT WOS:000546849000001
DA 2024-07-18
ER

PT J
AU Zhang, H
   Liu, H
AF Zhang, Hui
   Liu, Huan
TI Relaxing topological surfaces in four dimensions
SO VISUAL COMPUTER
LA English
DT Article
DE Visual mathematics; Relaxation; Optimization; Knot theory; Four
   dimensions
ID KNOT
AB In this paper, we show the use of visualization and topological relaxation methods to analyze and understand the underlying structure of mathematical surfaces embedded in 4D. When projected from 4D to 3D space, mathematical surfaces often twist, turn, and fold back on themselves, leaving their underlying structures behind their 3D figures. Our approach combines computer graphics, relaxation algorithm, and simulation to facilitate the modeling and depiction of 4D surfaces, and their deformation toward the simplified representations. For our principal test case of surfaces in 4D, this for the first time permits us to visualize a set of well-known topological phenomena beyond 3D that otherwise could only exist in the mathematician's mind. Understanding a fairly long mathematical deformation sequence can be aided by visual analysis and comparison over the identified "key moments" where only critical changes occur in the sequence. Our interface is designed to summarize the deformation sequence with a significantly reduced number of visual frames. All these combine to allow a much cleaner exploratory interface for us to analyze and study mathematical surfaces and their deformation in topological space.
C1 [Zhang, Hui] Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
   [Liu, Huan] Univ Louisville, Louisville, KY 40292 USA.
C3 University of Louisville; University of Louisville
RP Zhang, H (corresponding author), Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
EM h0zhan22@louisville.edu
FU National Science Foundation [1651581]; ORAU's Ralph E. Powe Junior
   Faculty Enhancement grant; Div Of Information & Intelligent Systems;
   Direct For Computer & Info Scie & Enginr [1651581] Funding Source:
   National Science Foundation
FX This work was supported in part by National Science Foundation Grant
   #1651581 and the 2016 ORAU's Ralph E. Powe Junior Faculty Enhancement
   grant.
CR Abbott E.A., 1952, FLATLAND
   Annas J., 1981, INTRO PLATOS REPUBLI
   Artin E., 1925, Abh. Math. Sem. Univ. Hamburg, V4, P174, DOI DOI 10.1007/BF02950724
   Brown R, 1999, VISUAL REPRESENTATIO, P32
   Bruss I, 1996, LECT NOTES COMPUT SC, V1027, P99, DOI 10.1007/BFb0021794
   Carter J, 1995, K E SERIES KNOTS EV
   Carter J. S., 2012, REIDEMEISTER ROSEMAN
   Carter J.S., 1995, PITMAN RES NOTES MAT, V4, P112
   Carter M, 1998, KNOTTED SURFACES THE
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   DIBATTISTA G, 1994, COMP GEOM-THEOR APPL, V4, P235, DOI 10.1016/0925-7721(94)00014-X
   Dutagaci H., 2010, P ACM WORKSH 3D OBJ, P45, DOI DOI 10.1145/1877808.1877819
   Eberly D., 2006, 3D GAME ENGINE DESIG
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   Fox R. H., 1962, Topology of 3-Manifolds
   Francis GeorgeK., 1987, TOPOLOGICAL PICTUREB
   Friedman G, 2005, HANDBOOK OF KNOT THEORY, P187, DOI 10.1016/B978-044451452-3/50005-8
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   HANSON AJ, 1994, COMPUTER, V27, P73, DOI 10.1109/2.299415
   Hass J, 1999, J ACM, V46, P185, DOI 10.1145/301970.301971
   Jordan KE, 2008, THEOR COMPUT SCI, V405, P41, DOI 10.1016/j.tcs.2008.06.023
   Kawauchi A., 2012, SURVEY KNOT THEORY
   Kobourov S. G., 2012, Spring embedders and force directed graph drawing algorithms
   Kumar A., 1994, CS947
   Li C., 2013, P 6 INT S VIS INF CO, P107
   Livingston C., 1993, CARUS MATH MONOGRAPH
   Paton R, 2012, VISUAL REPRESENTATIO
   Ranicki A, 2013, HIGH DIMENSIONAL KNO
   Roseman D., 1993, TWISTING TURNING 4 D
   Scharein R. G., 1998, THESIS
   Simmons G F, 1963, Introduction to Topology and Modern Analysis
   Simon J.K., 1994, J. Knot Theory Ramif, V3, P299, DOI 10.1142/S021821659400023X
   Sorkine O., 2009, TECHNICAL NOTES, V120, P3
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Vizquez PP, 2003, LECT NOTES COMPUT SC, V2669, P295
   Wu Y., MD KNOT ENERGY MINIM
   Zhang H., 2011, P SOC PHOTO-OPT INS, V786807, P1
   Zhang H, 2006, LECT NOTES COMPUT SC, V4291, P232
   Zhang H, 2007, IEEE T VIS COMPUT GR, V13, P1688, DOI 10.1109/TVCG.2007.70593
   Zhang H, 2012, IEEE T VIS COMPUT GR, V18, P2051, DOI 10.1109/TVCG.2012.242
NR 40
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2020
VL 36
IS 10-12
BP 2341
EP 2353
DI 10.1007/s00371-020-01895-5
EA JUL 2020
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NW1CX
UT WOS:000545293900002
OA Bronze
DA 2024-07-18
ER

PT J
AU Singh, VK
   Kumar, N
AF Singh, Vivek Kumar
   Kumar, Nitin
TI Saliency bagging: a novel framework for robust salient object detection
SO VISUAL COMPUTER
LA English
DT Article
DE Ensemble learning; Bagging; Majority voting; Aggregation; Saliency map
ID AGGREGATION; INTEGRATION; ATTENTION; CONTRAST
AB Salient object detection is a challenging task, and several methods have been proposed for the same in the literature. The problem lies in that most of the methods perform good on a particular set of images but fail when exposed to a variety of different set of images. Here, we address this problem by proposing a novel framework called saliency bagging for detecting salient object(s) in digital images across a variety of images in a robust manner. The proposed framework generates the saliency map of an image in three phases: (i) Selection of existing saliency detection models and generation of initial saliency maps (ii) Generation of integrated binary map from the initial saliency maps by applying adaptive thresholding and majority voting (iii) Computation of final saliency map using integrated binary map and initial saliency maps by applying proposed integration logic. Extensive experiments on six publicly available datasets viz. MSRA10K, DUT-OMRON, ECSSD, PASCAL-S, SED2, and THUR15K have been performed to determine the effectiveness of the proposed method. The performance of the proposed method is measured in terms of Precision, Recall, F-Measure, Mean Absolute Error (MAE) and Receiver Operating Characteristic (ROC) curve and compared with 25 state-of-the-art methods including 17 classic best-performing methods of the last decade, five existing selected, and three aggregation saliency methods. The proposed method outperforms all the compared classic and existing selected methods in terms of Precision, F-Measure, and MAE, while it is comparable to the best-performing methods in terms of Recall and ROC curve across all the six datasets. The proposed framework is computationally very fast than all compared aggregation methods, while performance is almost same on all datasets that support its superiority.
C1 [Singh, Vivek Kumar; Kumar, Nitin] Natl Inst Technol Uttarakhand, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Singh, VK (corresponding author), Natl Inst Technol Uttarakhand, Srinagar, Uttarakhand, India.
EM singh.vivekrajput@gamil.com; nitin@nituk.ac.in
RI Kumar, Nitin/AAT-9454-2020
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, PROC CVPR IEEE, P359
   [Anonymous], P AS C COMP VIS
   [Anonymous], 2012, P AS C COMP VIS
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li RH, 2017, VISUAL COMPUT, V33, P1155, DOI 10.1007/s00371-016-1278-0
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu GH, 2019, IEEE T IMAGE PROCESS, V28, P6, DOI 10.1109/TIP.2018.2847422
   Liu H, 2012, VISUAL COMPUT, V28, P279, DOI 10.1007/s00371-011-0638-z
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Lu Y, 2020, J COMPUT BIOL, V27, P769, DOI 10.1089/cmb.2019.0172
   MAI L, 2013, PROC CVPR IEEE, P1131, DOI DOI 10.1109/CVPR.2013.150
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Ninassi A, 2007, IEEE IMAGE PROC, P733
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2018, INT J COMPUT VISION, V126, P751, DOI 10.1007/s11263-017-1062-2
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang L, 2018, IEEE IPCCC
   WEI Y, 2012, ECCV, P29
   Xu YY, 2019, IEEE T MULTIMEDIA, V21, P98, DOI 10.1109/TMM.2018.2856126
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Yuan YC, 2018, IEEE T IMAGE PROCESS, V27, P1311, DOI 10.1109/TIP.2017.2762422
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 61
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2020
VL 36
IS 7
BP 1423
EP 1441
DI 10.1007/s00371-019-01750-2
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LO1PW
UT WOS:000533401000010
DA 2024-07-18
ER

PT J
AU Xue, LX
   Jiang, D
   Wang, RG
   Yang, J
   Hu, M
AF Xue, Lixia
   Jiang, Di
   Wang, Ronggui
   Yang, Juan
   Hu, Min
TI Learning semantic dependencies with channel correlation for multi-label
   classification
SO VISUAL COMPUTER
LA English
DT Article
DE Multi-label image classification; Attention; Convolutional neural
   network; Label correlation
ID IMAGE CLASSIFICATION; GRADIENTS
AB Multi-label image classification is a fundamental and challenging task in computer vision. Although remarkable success has been achieved by applying CNN-RNN pattern, such method has a slow convergence rate due to the existence of RNN module. Instead of utilizing the RNN modules, this paper proposes a novel channel correlation network which is fully based on convolutional neural network (CNN) to model the label correlations with high training efficiency. By creating a new attention module, the image features obtained by CNN are further convoluted to obtain the correspondence between the label and the channel-wise feature map. Then we use the SE and the convolution operation alternately to eliminate the irrelevant information to better explore the label correlation. Experiments on PASCAL VOC 2007 and MIRFlickr25k show that our model can effectively exploit the dependencies between multiple tags to achieve better performance.
C1 [Xue, Lixia; Jiang, Di; Wang, Ronggui; Yang, Juan; Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei 230601, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230601, Peoples R China.
EM xlxzzm@163.com; 505185657@qq.com; wangrgui@foxmail.com;
   yangjuan6985@163.com; jsjxhumin@hfut.edu.cn
RI Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]; State Key
   Program of NSFC-Shenzhen Joint Foundation [U1613217]
FX We express our sincere thanks to the anonymous reviewers for their
   helpful comments and suggestions to raise the standard of our paper.
   This work is partly supported by the National Natural Science Foundation
   of China under Grant No. 61672202 and State Key Program of NSFC-Shenzhen
   Joint Foundation under Grant No. U1613217.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.37
   [Anonymous], 2014, ICLR
   Ba J., 2015, P ICLR, P1, DOI DOI 10.1016/J.JCYT.2014.02.008
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1467, DOI 10.1109/ICISCE.2017.306
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong Xingping, 2018, EUR C COMP VIS
   Dong XW, 2018, IEEE CONF COMPUT
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guo Y, 2011, IN C IND ENG ENG MAN, P1300, DOI 10.1109/IEEM.2011.6118126
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu Jie, 2018, COMPUTER VISION PATT
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Hu XW, 2017, LECT NOTES COMPUT SC, V10553, P186, DOI 10.1007/978-3-319-67558-9_22
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Gao, 2018, INT C LEARN REPR
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mnih V, 2014, ADV NEUR IN, V27
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Srivastava Neelam., 2012, The Postcolonial Gramsci, P1
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang RG, 2017, J VIS COMMUN IMAGE R, V49, P213, DOI 10.1016/j.jvcir.2017.07.004
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Y, 2018, LECT NOTES COMPUT SC, V11073, P523, DOI 10.1007/978-3-030-00937-3_60
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue XY, 2011, IEEE I CONF COMP VIS, P651, DOI 10.1109/ICCV.2011.6126300
   Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8
NR 47
TC 5
Z9 6
U1 3
U2 21
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2020
VL 36
IS 7
BP 1325
EP 1335
DI 10.1007/s00371-019-01731-5
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LO1PW
UT WOS:000533401000003
DA 2024-07-18
ER

PT J
AU Imran, J
   Raman, B
AF Imran, Javed
   Raman, Balasubramanian
TI Deep motion templates and extreme learning machine for sign language
   recognition
SO VISUAL COMPUTER
LA English
DT Article
DE Sign language recognition; Extreme learning machine; Convolutional
   neural network; Motion history image; Dynamic image; Late fusion
AB Sign language is a visual language used by persons with hearing and speech impairment to communicate through fingerspellings and body gestures. This paper proposes a framework for automatic sign language recognition without the need of hand segmentation. The proposed method first generates three different types of motion templates: motion history image, dynamic image and our proposed RGB motion image. These motion templates are used to fine-tune three ConvNets trained on ImageNet dataset. Fine-tuning avoids learning all the parameters from scratch, leading to faster network convergence even with a small number of training samples. For combining the output of three ConvNets, we propose a fusion technique based on Kernel-based extreme learning machine (KELM). The features extracted from the last fully connected layer of trained ConvNets are used to train three KELMs, and the final class label is predicted by averaging their scores. The proposed approach is validated on a number of publicly available sign language as well as human action recognition datasets, and state-of-the-art results are achieved. Finally, an Indian sign language dataset is also collected using a thermal camera. The experimental results obtained show that our ConvNet-based deep features along with proposed KELM-based fusion are robust for any type of human motion recognition.
C1 [Imran, Javed; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Imran, J (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM jimran@cs.iitr.ac.in; balarfcs@iitr.ac.in
FU SMILE Project, IIT Roorkee
FX This project was funded by SMILE Project, IIT Roorkee.
CR Ahad MAR, 2012, MACH VISION APPL, V23, P255, DOI 10.1007/s00138-010-0298-4
   [Anonymous], 2014, P 2 INT C HUM AG INT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], VIS COMPUT
   [Anonymous], 2009, PROC CVPR IEEE
   [Anonymous], MULTIMED TOOLS APPL
   Baraldi L, 2014, IEEE COMPUT SOC CONF, P702, DOI 10.1109/CVPRW.2014.107
   Bauer B, 2002, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2002.1048332
   Bi L, 2018, VISUAL COMPUT, V34, P1043, DOI 10.1007/s00371-018-1519-5
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Cirujeda Pol, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P657, DOI 10.1109/3DV.2014.10
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dreuw P., 2006, ECCV WORKSHOP STAT M, P7
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan J., 2016, arXiv
   Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Gao Z, 2014, KSII T INTERNET INF, V8, P483, DOI 10.3837/tiis.2014.02.009
   Geng LB, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1457, DOI 10.1109/WCICA.2014.7052933
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gogic I, 2020, VISUAL COMPUT, V36, P97, DOI 10.1007/s00371-018-1585-8
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GL, 2017, IEEE ICC
   Imran J, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P144, DOI 10.1109/ICACCI.2016.7732038
   Jiang T, 2019, VISUAL COMPUT, V35, P1655, DOI 10.1007/s00371-018-1565-z
   Li XJ, 2020, VISUAL COMPUT, V36, P39, DOI 10.1007/s00371-018-1582-y
   Lin Y.C., 2012, P 20 ACM INT C MULT, P1053
   Liu H, 2015, IEEE IMAGE PROC, P4674, DOI 10.1109/ICIP.2015.7351693
   Liu L., 2013, 23 INT JOINT C ART I
   Liu MY, 2016, NEUROCOMPUTING, V175, P747, DOI 10.1016/j.neucom.2015.11.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma CY, 2018, VISUAL COMPUT, V34, P1053, DOI 10.1007/s00371-018-1556-0
   Nishida N, 2016, LECT NOTES COMPUT SC, V9431, P682, DOI 10.1007/978-3-319-29451-3_54
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Ronchetti F., 2016, P 22 C ARG CIENC COM
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tung PT, 2014, P 5 S INF COMM TECHN, P186
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang PC, 2016, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2016.7899599
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Yu Z, 2017, VISUAL COMPUT, V34, P1
   Zheng JQ, 2017, MULTIMED TOOLS APPL, V76, P20525, DOI 10.1007/s11042-016-3988-8
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
NR 60
TC 36
Z9 37
U1 1
U2 23
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2020
VL 36
IS 6
BP 1233
EP 1246
DI 10.1007/s00371-019-01725-3
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LI0TO
UT WOS:000529199400011
DA 2024-07-18
ER

PT J
AU Chanu, OB
   Neelima, A
AF Chanu, Oinam Bidyapati
   Neelima, Arambam
TI A new multi-secret image sharing scheme based on DCT
SO VISUAL COMPUTER
LA English
DT Article
DE Secret image sharing scheme; Discrete Cosine Transform (DCT);
   Two-variable one-way function; Inverse Discrete Cosine Transform (IDCT);
   Frequency domain
ID CELLULAR-AUTOMATA; STEGANOGRAPHY; AUTHENTICATION
AB Multi-secret image sharing scheme (MSIS) is a technique to share multiple secret images over the internet. Normally, most of the secret image sharing schemes can share only a single secret image. However, due to the rapid development of internet technology, the necessity of sharing multiple images arises. An (n, n) MSIS is employed to share n images to n authorized participants. All the n participants are required to submit their respective shares to recover the original secret images. If the number of the participants is less than n, then reconstruction of the secret images is impossible. Most of the existing schemes which are in the frequency domain do not have the capability to handle multiple secret images. In this paper, a MSIS that uses the Discrete Cosine Transform is proposed to overcome the limitation present in the existing schemes. Moreover, the proposed scheme requires less computational time than the existing schemes. Security of the proposed scheme is analyzed and shows that the proposed scheme is computationally secure. Also, the proposed scheme can recover the same original secret images.
C1 [Chanu, Oinam Bidyapati; Neelima, Arambam] NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland
RP Chanu, OB (corresponding author), NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
EM obidyapatichanu@gmail.com; neelimaarambam@yahoo.co.in
OI CHANU, OINAM BIDYAPATI/0000-0002-3536-5435; Neelima,
   Arambam/0009-0003-2106-7757
CR [Anonymous], 2015, ARXIV150207469
   [Anonymous], 2013, INT C INN ENG TECHN
   [Anonymous], 2015, P 2015 INT C ADV RES
   [Anonymous], 2012, INT J SCI ENG RES
   [Anonymous], ARXIV12080950
   [Anonymous], 2014, J APPL MATH PHYS
   Bhattacharjee T, 2017, MICROSYST TECHNOL, V23, P4263, DOI 10.1007/s00542-016-3104-z
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chanu OB, 2019, INT J MULTIMED INF R, V8, P195, DOI 10.1007/s13735-018-0161-3
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen CC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013008
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Fang WP, 2006, INT J COMPUT SCI NET, V6, P228
   Fang WP, 2011, INT J COMPUT SCI NET, V11, P20
   Fathimal PM, 2017, MULTIMED TOOLS APPL, V76, P5489, DOI 10.1007/s11042-016-4074-y
   Guo C, 2014, MULTIMED TOOLS APPL, V72, P2195, DOI 10.1007/s11042-013-1510-0
   Koga H, 2006, DESIGN CODE CRYPTOGR, V40, P81, DOI 10.1007/s10623-005-6700-y
   Latha SB, 2017, IEEE INT ADV COMPUT, P619, DOI [10.1109/IACC.2017.122, 10.1109/IACC.2017.0131]
   Li GD, 2019, VISUAL COMPUT, V35, P1267, DOI 10.1007/s00371-018-1574-y
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Paillier P., 1997, P 5 INT WORKSHOP SEC, P207
   Rajput M, 2016, PROCEDIA COMPUT SCI, V89, P677, DOI 10.1016/j.procs.2016.06.034
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Singh P, 2017, SIGNAL PROCESS-IMAGE, V57, P46, DOI 10.1016/j.image.2017.04.012
   Surekha B., 2012, Int. J. Comput. Sci. Issues, V9, P312
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ting-Yi Chang, 2005, Operating Systems Review, V39, P48, DOI 10.1145/1044552.1044557
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang XF, 2017, CRYPTOGR COMMUN, V9, P625, DOI 10.1007/s12095-016-0205-6
   Wu CC, 2009, IMAGING SCI J, V57, P140, DOI 10.1179/174313109X459887
   Wu XT, 2013, J SYST SOFTWARE, V86, P1068, DOI 10.1016/j.jss.2012.11.021
   Xie D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168674
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
NR 39
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2020
VL 36
IS 5
BP 939
EP 950
DI 10.1007/s00371-019-01703-9
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LJ3BL
UT WOS:000530043100006
DA 2024-07-18
ER

PT J
AU Goh, KM
   Ng, CH
   Lim, LL
   Sheikh, UU
AF Goh, Kam Meng
   Ng, Chee How
   Lim, Li Li
   Sheikh, U. U.
TI Micro-expression recognition: an updated review of current trends,
   challenges and solutions
SO VISUAL COMPUTER
LA English
DT Review
DE Classification; Dataset; Feature extraction; Micro-expression;
   Pre-processing; Spotting
ID SUPERVISED DESCENT METHOD; LOCAL BINARY PATTERNS; FACE DETECTION;
   OPTICAL-FLOW; IMAGE; MOTION; MODEL; DECEPTION; EMOTIONS; SYSTEM
AB Micro-expression (ME) recognition has attracted numerous interests within the computer vision circle in different contexts particularly, localization, magnification, and recognition. Challenges in these areas remain relevant due to the nature of ME's split-second transition with minute intensity levels. In this paper, a comprehensive state-of-the-art analysis of ME recognition and detection challenges are provided. Contemporary solutions are categorized into low-level, mid-level, and high-level solutions with a review of their characteristics and performances. This paper also provides possible extensions to basic methods, highlight, and predict emerging trends. A thorough analysis of mainstream ME datasets is also provided by elucidating each of their advantages and limitations. This survey gives readers an understanding of ME recognition and an appreciation of future research direction in ME recognition systems.
C1 [Goh, Kam Meng; Ng, Chee How; Lim, Li Li] Tunku Abdul Rahman Univ Coll, Fac Engn & Technol, Dept Elect & Elect Engn, Jalan Genting Kelang, Kuala Lumpur 53300, Malaysia.
   [Sheikh, U. U.] Univ Teknol Malaysia, Fac Elect Engn, Skudai 81310, Johor, Malaysia.
C3 Tunku Abdul Rahman University College (TAR UC); Universiti Teknologi
   Malaysia
RP Goh, KM (corresponding author), Tunku Abdul Rahman Univ Coll, Fac Engn & Technol, Dept Elect & Elect Engn, Jalan Genting Kelang, Kuala Lumpur 53300, Malaysia.
EM gohkm@tarc.edu.my; C.How_93@hotmail.com; lllim@tarc.edu.my;
   usman@fke.utm.my
RI Sheikh, Usman Ullah/GRO-0863-2022; Lim, Li Li/ABI-1588-2020; Goh, Kam
   Meng/AAE-3941-2020
OI Goh, Kam Meng/0000-0003-0378-7390; Ullah Sheikh,
   Usman/0000-0001-9054-093X
FU Ministry of Higher Education (MOHE), Malaysia, under Fundamental
   Research Grant Scheme (FRGS) [FRGS/1/2016/TK04/TARUC/02/1]
FX This work is supported by Ministry of Higher Education (MOHE), Malaysia,
   under Fundamental Research Grant Scheme (FRGS) (Reference code:
   FRGS/1/2016/TK04/TARUC/02/1).
CR Adegun IP, 2016, 2016 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH)
   Ngo ACL, 2016, INT CONF ACOUST SPEE, P1243, DOI 10.1109/ICASSP.2016.7471875
   [Anonymous], 1998, ISIS TECH REP
   [Anonymous], 2017, IEEE T AFFECTIVE COM
   [Anonymous], 2017, J PHYS CONF SER
   [Anonymous], 2016, 2016 INT C ADV COMP
   [Anonymous], 2013, 2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG), DOI [DOI 10.1109/FG.2013.6553799, DOI 10.1109/FG.2013.6553799.IEEE]
   [Anonymous], 2017, 2017 INT C DIG IM
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010
   Ben XY, 2016, NEURAL COMPUT APPL, V27, P2629, DOI 10.1007/s00521-015-2031-8
   Bi L, 2017, VISUAL COMPUT, V33, P1061, DOI 10.1007/s00371-017-1379-4
   Bian P, 2018, SIGNAL IMAGE VIDEO P, V12, P17, DOI 10.1007/s11760-017-1125-4
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Chatfield K., 2014, ABS14053531 CORR
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen D., CHAM 2014 COMPUTER V, P109
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Davison A.K., 2016, ABS161205038 CORR
   Davison AK, 2015, IEEE SYS MAN CYBERN, P1864, DOI 10.1109/SMC.2015.326
   Davison AK, 2016, IEEE T AFFECT COMPUT, VPP, P1
   Deng WH, 2018, NEUROCOMPUTING, V273, P222, DOI 10.1016/j.neucom.2017.07.052
   Duque C., 2018, WACV 2018
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   Ekman P., 2003, Micro expression training tool
   Ekman P, 1978, FACIAL ACTION CODING
   Evangelidis GD, 2008, IEEE T PATTERN ANAL, V30, P1858, DOI 10.1109/TPAMI.2008.113
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Frank M., 2009, ANN M INT COMM ASS S
   Gines Hidalgo Z.C., 2017, OPENPOSE LIB
   Guo YJ, 2014, IEEE IJCNN, P3473, DOI 10.1109/IJCNN.2014.6889620
   Guo YC, 2015, OPTIK, V126, P4446, DOI 10.1016/j.ijleo.2015.08.167
   Happy SL, 2019, IEEE T AFFECT COMPUT, V10, P394, DOI 10.1109/TAFFC.2017.2723386
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   Hong X., 2017, ABS171002820 CORR
   House C., 2015, PREPROCESSING DESCRI
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10
   Huang X, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ARTIFICIAL INTELLIGENCE (CSAI 2017), P1, DOI 10.1145/3168390.3168392
   Izenman AJ, 2008, SPRINGER TEXTS STAT, P237, DOI 10.1007/978-0-387-78189-1_8
   Kamarol SKA, 2016, IET IMAGE PROCESS, V10, P534, DOI 10.1049/iet-ipr.2015.0519
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   Kumar S, 2011, IEEE T IMAGE PROCESS, V20, P3406, DOI 10.1109/TIP.2011.2156420
   Le Ngo A.C., CHAM 2015 COMPUTER V, P33
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li XH, 2016, INT CONF SIGN PROCES, P1130, DOI 10.1109/ICSP.2016.7878004
   Li XC, 2017, INT J REMOTE SENS, V38, P6030, DOI 10.1080/01431161.2016.1274451
   Liao Shengcai, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Lim C.H., 2017, AS PAS SIGN INF PROC
   Lim CH, 2014, IEEE T FUZZY SYST, V22, P1541, DOI 10.1109/TFUZZ.2014.2298233
   Liong S.-T., CHAM 2015, P644
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liong ST, 2016, SIGNAL PROCESS-IMAGE, V47, P170, DOI 10.1016/j.image.2016.06.004
   Liong ST, 2014, I S INTELL SIG PROC, P180, DOI 10.1109/ISPACS.2014.7024448
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu HH, 2009, INT J APPROX REASON, V51, P71, DOI 10.1016/j.ijar.2009.07.003
   Liu QS, 2016, IEEE T IMAGE PROCESS, V25, P700, DOI 10.1109/TIP.2015.2502485
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lu H, 2017, J. WSCG, V25, P87
   Lu Z., CHAM 2015, P698
   Lucas B.D., 1985, GEN IMAGE MATCHING M
   Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1
   Moilanen A, 2014, INT C PATT RECOG, P1722, DOI 10.1109/ICPR.2014.303
   Oh YH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1237, DOI 10.1109/ICDSP.2015.7252078
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pan W, 2009, IEEE T PATTERN ANAL, V31, P400, DOI 10.1109/TPAMI.2008.83
   Parkinson C, 2017, EMOTION, V17, P459, DOI 10.1037/emo0000194
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Pei LS, 2016, VISUAL COMPUT, V32, P1395, DOI 10.1007/s00371-015-1090-2
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Polikovsky S, 2013, IEICE T INF SYST, VE96D, P81, DOI 10.1587/transinf.E96.D.81
   Porter S, 2008, PSYCHOL SCI, V19, P508, DOI 10.1111/j.1467-9280.2008.02116.x
   Qu FB, 2018, IEEE T AFFECT COMPUT, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ro Y.M., 2013, 10 IEEE INT C WORKSH, P1
   Ruiz Ruiz Jorge Carlos, 2013, ISRN Biotechnol, V2013, P341974, DOI 10.5402/2013/341974
   Sariyanidi E, 2017, IEEE T IMAGE PROCESS, V26, P1965, DOI 10.1109/TIP.2017.2662237
   Sariyanidi E, 2017, IEEE T IMAGE PROCESS, V26, P1708, DOI 10.1109/TIP.2016.2639448
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   SHEN Q, 1993, IEEE T SYST MAN CYB, V23, P1038, DOI 10.1109/21.247887
   Shenoi S, 2015, INT J CRIT INFR PROT, V8, P1, DOI [10.1016/j.ijcip.2014.12.003, 10.1080/17538947.2014.927538]
   Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451
   SHREVE M., 2009, 2009 WORKSH APPL COM, P1, DOI [10.1109/WACV.2009.5403044, DOI 10.1109/WACV.2009.5403044]
   Shreve M, 2014, IMAGE VISION COMPUT, V32, P476, DOI 10.1016/j.imavis.2014.04.010
   Sikka K., BERLIN HEIDELBERG 20, P250
   Simon T., CVPR 2017, P4
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tran T.-K., CHAM 2017 ADV CONCEP, P542
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Tzimiropoulos G, 2011, IEEE I CONF COMP VIS, P1847, DOI 10.1109/ICCV.2011.6126452
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang S.-J., CHAM 2015, P325
   Wang SJ, 2017, NEUROCOMPUTING, V230, P382, DOI 10.1016/j.neucom.2016.12.034
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2015, LECT NOTES COMPUT SC, V8925, P325, DOI 10.1007/978-3-319-16178-5_23
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   Wang Y., CHAM 2015 COMPUTER V, P525
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Warren G, 2009, J NONVERBAL BEHAV, V33, P59, DOI 10.1007/s10919-008-0057-7
   Wu H, 2017, VISUAL COMPUT, V33, P113, DOI 10.1007/s00371-015-1156-1
   Wu Q, 2011, LECT NOTES COMPUT SC, V6975, P152, DOI 10.1007/978-3-642-24571-8_16
   Xia ZQ, 2016, COMPUT VIS IMAGE UND, V147, P87, DOI 10.1016/j.cviu.2015.12.006
   Xiong X, 2014, IEEE T IMAGE PROCESS, V23, P4311, DOI 10.1109/TIP.2014.2341932
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004
   Yan W.-J., CHAM 2015, P296
   Yan WJ, 2014, NEUROCOMPUTING, V136, P82, DOI 10.1016/j.neucom.2014.01.029
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Yu Z, 2017, VISUAL COMPUT, V34, P1
   Zhang M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095018
   Zhang WP, 2013, DYNAM SYST APPL, V22, P1
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng H., CHAM 2016 PRICAI 201, P692
   Zheng H, 2017, INT J MACH LEARN CYB, V8, P2043, DOI 10.1007/s13042-017-0684-6
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 123
TC 52
Z9 55
U1 6
U2 117
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2020
VL 36
IS 3
BP 445
EP 468
DI 10.1007/s00371-018-1607-6
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA KL4EO
UT WOS:000513378500002
DA 2024-07-18
ER

PT J
AU Rehman, B
   Ong, WH
   Tan, ACH
   Ngo, TD
AF Rehman, Bacha
   Ong, Wee Hong
   Tan, Abby Chee Hong
   Ngo, Trung Dung
TI Face detection and tracking using hybrid margin-based ROI techniques
SO VISUAL COMPUTER
LA English
DT Article
DE Face detection; Joint cascade; Convolutional neural network; Haar
   cascade; Template matching; Region of interest; Hybrid model; Dynamic
   margin; Face tracking; Processing time
ID ROBUST OBJECT TRACKING; RECOGNITION
AB This study is to solve the problem of low accuracy and slow processing speed for real-time face detection and tracking systems. A margin-based region of interest approach with fixed and dynamic margin concepts is proposed to speed up the processing time. In addition, a hybrid system is developed to boost the accuracy and overcome the deficiency of the main detection algorithm. This approach consists of two routines, i.e., main and escape routines. Three algorithms are used independently as the main routine to evaluate the effectiveness of the proposed hybrid approach. These algorithms are Haar cascade, Joint cascade, and multitask convolutional neural networks. The escape routine based on template matching algorithm is designed to evaluate the effectiveness of the proposed hybrid approach and improve detection accuracy. Two RGB video datasets with diversity and variations in face poses, video backgrounds, illuminations, video resolutions, expressions, over exposed faces, and occlusions of people within various unseen environments have been used for experiments and evaluation. The experiment results confirm that the hybrid approach is capable of detecting and tracking faces in non-frontal orientation with better accuracy and faster processing speed, i.e., four times faster than the conventional full frame scanning techniques.
C1 [Rehman, Bacha] Univ Brunei Darussalam, Fac Sci, Comp Sci, Bandar Seri Begawan, Brunei.
   [Ong, Wee Hong] Univ Brunei Darussalam, Fac Sci, Bandar Seri Begawan, Brunei.
   [Tan, Abby Chee Hong] Univ Brunei Darussalam, Fac Sci, Math, Bandar Seri Begawan, Brunei.
   [Ngo, Trung Dung] Univ Prince Edward Isl, More Than Robot Lab 1, Charlottetown, PE, Canada.
C3 University Brunei Darussalam; University Brunei Darussalam; University
   Brunei Darussalam; University of Prince Edward Island
RP Rehman, B (corresponding author), Univ Brunei Darussalam, Fac Sci, Comp Sci, Bandar Seri Begawan, Brunei.
EM bachapk@gmail.com; weehong.ong@ubd.edu.bn; abby.tan@ubd.edu.bn;
   dungnt@ieee.org
RI Rehman, Bacha/JAC-2503-2023; Ngo, Trung/ITU-2233-2023
OI Ngo, Trung/0000-0002-4528-0259; Ong, Wee Hong/0000-0003-2667-1980;
   Rehman, Bacha/0000-0003-2081-5728
CR [Anonymous], LECT NOTES COMPUTER
   [Anonymous], ACM SIGGRAPH 2011 PA
   [Anonymous], ARXIV170408068
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], DATA CODE SECTION
   [Anonymous], INT J ROB RES
   [Anonymous], INT J COMPUT APPL
   [Anonymous], P 2 INT C IM SIGN PR
   [Anonymous], RELATIONSHIP SUM SQU
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bradski G, 2000, DR DOBBS J, V25, P120
   Bulbul A, 2010, VISUAL COMPUT, V26, P311, DOI 10.1007/s00371-010-0419-0
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Chua TS, 2002, VISUAL COMPUT, V18, P121, DOI 10.1007/s003710100137
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gerónimo D, 2010, COMPUT VIS IMAGE UND, V114, P583, DOI 10.1016/j.cviu.2009.07.008
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Kalal Z, 2010, IEEE IMAGE PROC, P3789, DOI 10.1109/ICIP.2010.5653525
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Laurentini A, 2014, COMPUT VIS IMAGE UND, V125, P184, DOI 10.1016/j.cviu.2014.04.006
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Park JK, 2019, VISUAL COMPUT, V35, P1615, DOI 10.1007/s00371-018-1561-3
   Quan W, 2015, VISUAL COMPUT, V31, P1307, DOI 10.1007/s00371-014-1012-8
   Quan W, 2014, VISUAL COMPUT, V30, P351, DOI 10.1007/s00371-013-0860-y
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Ruder S, 2017, arXiv preprint arXiv:1706.05098
   Salam H, 2018, VISUAL COMPUT, V34, P289, DOI 10.1007/s00371-016-1332-y
   Singh C, 2012, VISUAL COMPUT, V28, P1085, DOI 10.1007/s00371-011-0659-7
   Tan T.K., 2006, INT C IMAGE PROCESSI, P1
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang R, 2016, VISUAL COMPUT, V32, P1379, DOI 10.1007/s00371-015-1206-8
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244
   Wang Y, 2019, VISUAL COMPUT, V35, P1641, DOI 10.1007/s00371-018-1563-1
   Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Xiao J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P163, DOI 10.1109/AFGR.2002.1004149
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang ChunYing Zhang ChunYing, 2010, Cotton Science, V22, P17
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 50
TC 11
Z9 11
U1 0
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2020
VL 36
IS 3
BP 633
EP 647
DI 10.1007/s00371-019-01649-y
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KL4EO
UT WOS:000513378500014
DA 2024-07-18
ER

PT J
AU Zhao, X
   Su, ZQ
   Komura, T
   Yang, XY
AF Zhao, Xi
   Su, Zhenqiang
   Komura, Taku
   Yang, Xinyu
TI Building hierarchical structures for 3D scenes with repeated elements
SO VISUAL COMPUTER
LA English
DT Article
DE 3D scene; Scene analysis; Hierarchy; Repeated patterns
AB We propose a novel hierarchy construction algorithm for 3D scenes with repeated elements, such as classrooms with multiple desk-chair pairs. Most existing algorithms focus on scenes such as bedrooms or living rooms, which rarely contain repeated patterns. Consequently, such methods may not recognize repeated patterns, which are vital for understanding the structure and context of scenes such as classrooms. Therefore, we propose a new global optimization algorithm for recognizing repeated patterns and building hierarchical structures based on repeated patterns. First, we find a repeated template by calculating the coverage ratios and frequencies of many substructures in a scene. Once the repeated template has been determined, a minimum cost maximum flow problem can be solved to find all instances (repetitions) of it in the scene and then group objects accordingly. Second, we group objects in the region outside the repeated elements according to their adjacency. Finally, based on these two sets of results, we build the hierarchy of the entire scene. We test this hierarchy construction algorithm on the Princeton and SceneNN databases and show that our algorithm can correctly find repeated patterns and construct a hierarchy that is more similar to the ground truth than the results of previous methods.
C1 [Zhao, Xi; Yang, Xinyu] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
   [Su, Zhenqiang] Xi An Jiao Tong Univ, Sch Software Engn, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
   [Komura, Taku] Univ Edinburgh, Sch Informat, Inst Percept Act & Behav, 10 Crichton St, Edinburgh, Midlothian, Scotland.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; University of
   Edinburgh
RP Yang, XY (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
EM xi.zhao@mail.xjtu.edu.cn; xyyang@mail.xjtu.edu.cn
FU National Natural Science Foundation of China [61602366]; China
   Postdoctoral Science Foundation [2015M582664]
FX This study was funded by the National Natural Science Foundation of
   China (61602366) and the China Postdoctoral Science Foundation
   (2015M582664).
CR Ahuja N, 2007, IEEE I CONF COMP VIS, P770
   Alhashim I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601102
   [Anonymous], 3 CAN C COMP ROB VIS
   [Anonymous], 2014, PROC ACM SIGGRAPH CO
   [Anonymous], SIGGRAPH ASIA 2014 I
   [Anonymous], ARXIV161005883CS
   Bokeloh M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778841
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cormen T.H., 2009, INTRO ALGORITHMS
   Sappa AD, 2007, VISUAL COMPUT, V23, P143, DOI 10.1007/s00371-006-0089-0
   Fisher M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964929
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Golovinskiy A, 2009, COMPUT GRAPH-UK, V33, P262, DOI 10.1016/j.cag.2009.03.010
   Hu RZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766914
   Huang H, 2011, COMPUT GRAPH FORUM, V30, P2059, DOI 10.1111/j.1467-8659.2011.02044.x
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Liu SL, 2007, LECT NOTES COMPUT SC, V4647, P290
   Liu TQ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661243
   Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332
   Moulin M, 2019, VISUAL COMPUT, V35, P1809, DOI 10.1007/s00371-018-1575-x
   Paraboschi L., 2007, Eurographics Italian Chapter, Trento (Italy), P87
   Sidi O, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024160
   Wang Y, 2011, COMPUT GRAPH FORUM, V30, P287, DOI 10.1111/j.1467-8659.2011.01885.x
   Xu K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601109
   Zhang FL, 2012, IEEE T VIS COMPUT GR, V18, P1849, DOI 10.1109/TVCG.2012.68
   Zhao X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982410
   Zhao X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2574860
NR 28
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2020
VL 36
IS 2
BP 361
EP 374
DI 10.1007/s00371-018-01625-y
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KJ2TH
UT WOS:000511910300010
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Mao, Y
   Li, ZN
   Li, YJ
   He, W
AF Mao, Yan
   Li, Zuning
   Li, Yongjian
   He, Wu
TI Emotion-based diversity crowd behavior simulation in public emergency
SO VISUAL COMPUTER
LA English
DT Article
DE Crowd simulation; Emotional contagion; Diversity behavior; Public
   emergency
ID MODEL; FRAMEWORK
AB Computer simulations of crowd behaviors in public emergency have become a hot research field, as they are able to provide rich valuable data for public safety analysis and disaster-preparedness measures. In most of the existing crowd escape simulation systems, human behaviors are often limited to taking flight or running away. However, due to the personality and the current emotion of each individual, they may behave in various ways, such as Samaritan or giving up on life et al. In order to simulate such like diversity crowd behavior, this paper presents an emotion-based diversity behavior model, by adopting the OCEAN personality model and the OCC emotion model, while being enriched with the incorporation of CA-SIRS emotion contagion model. We also consider the effects of Yerkes-Dodson Law on individuals' behaviors, which allows individuals to make authentic behaviors under stressful circumstances. The proposed model can provide more diverse individual behaviors compared to the existing emotion-based escape simulation models. The psychology-based individual modeling enables our model to be applied in various scenarios with slightly parameter adjustments.
C1 [Mao, Yan; Li, Yongjian] Southwest JiaoTong Univ, Sch Econ & Management, Chengdu, Sichuan, Peoples R China.
   [Li, Zuning; He, Wu] Sichuan Normal Univ, Coll Movie & Media, Chengdu, Sichuan, Peoples R China.
C3 Southwest Jiaotong University; Sichuan Normal University
RP Li, YJ (corresponding author), Southwest JiaoTong Univ, Sch Econ & Management, Chengdu, Sichuan, Peoples R China.
EM mr.lyj124@outlook.com
FU Humanities and Social Sciences projects of the Ministry of Education
   [17YJC630036]
FX This work was supported by Humanities and Social Sciences projects of
   the Ministry of Education (Grant No.17YJC630036).
CR Bosse T, 2009, LECT NOTES ARTIF INT, V5925, P48, DOI 10.1007/978-3-642-11161-7_4
   Charalambous P, 2014, PAG CROWD GRAPH BASE
   Che XD, 2015, VISUAL COMPUT, V31, P853, DOI 10.1007/s00371-015-1119-6
   Costa P. T., 1992, PSYCHOL ASSESSMENT, V4, P5, DOI DOI 10.1037/1040-3590.4.1.5
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Eysenck H. J., 1994, NORMALITY ABNORMALIT
   Neto ABF, 2017, LECT NOTES ARTIF INT, V10498, P63, DOI 10.1007/978-3-319-67401-8_7
   Fu LB, 2014, PHYSICA A, V405, P380, DOI 10.1016/j.physa.2014.03.043
   Fu YW, 2014, I C VIRTUAL REALITY, P103, DOI 10.1109/ICVRV.2014.52
   Gomez N.P., 2013, 1 INT WORKSH CROWD S, P21
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Helbing D., 1992, Complex Systems, V6, P391
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kalogeiton VS, 2015, INT J GEN SYST, V44, P354, DOI 10.1080/03081079.2014.997527
   Karbovskii V, 2015, PROCEDIA COMPUT SCI, V51, P2367, DOI 10.1016/j.procs.2015.05.407
   Kim S., 2012, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2159616.2159626, 10.1145/2159616.2159626]
   Minh LV, 2012, LECT NOTES ARTIF INT, V7057, P604
   Li W, 2010, 2010 2ND IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND FINANCIAL ENGINEERING (ICIFE), P83, DOI 10.1109/ICIFE.2010.5609257
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Ortony A., 1990, The Cognitive Structure of Emotion, V18, DOI DOI 10.2307/2074241
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pidd M, 1996, EUR J OPER RES, V90, P413, DOI 10.1016/0377-2217(95)00112-3
   Pimenta LCA, 2013, IEEE T ROBOT, V29, P383, DOI 10.1109/TRO.2012.2234294
   Proulx G, 2011, P 9 INT FIR PROT S M, P219
   RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473
   Rojas F, 2016, VISUAL COMPUT, V32, P335, DOI 10.1007/s00371-015-1187-7
   Sakuma T, 2010, COMPUT ANIMAT VIRT W, V16, P343
   Wang XM, 2016, KNOWL-BASED SYST, V109, P35, DOI 10.1016/j.knosys.2016.06.022
   Yu QX, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P119
   Zhang JZ, 2015, DISCRETE DYN NAT SOC, V2008, P473
   Zhao CM, 2009, FIRE TECHNOL, V45, P71, DOI 10.1007/s10694-007-0040-6
   Zoumpoulaki A, 2010, LECT NOTES ARTIF INT, V6040, P423, DOI 10.1007/978-3-642-12842-4_54
NR 32
TC 25
Z9 27
U1 4
U2 68
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2019
VL 35
IS 12
BP 1725
EP 1739
DI 10.1007/s00371-018-1568-9
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KI6XQ
UT WOS:000511494300004
DA 2024-07-18
ER

PT J
AU Umer, S
   Dhara, BC
   Chanda, B
AF Umer, Saiyed
   Dhara, Bibhas Chandra
   Chanda, Bhabatosh
TI NIR and VW iris image recognition using ensemble of patch statistics
   features
SO VISUAL COMPUTER
LA English
DT Article
DE Near-infrared; Visible wavelength; Iris recognition; Ensemble of patch
   statistic; Identification
ID IDENTIFICATION
AB A novel iris recognition system is proposed in this paper. The proposed system is able to handle various challenging issues which may occur during image acquisition in near-infrared and/or visible wavelength lights under constrained and less-constrained environments. The proposed system demonstrates great perseverance for recognizing subjects in both stable and adverse situations. During recognition, the system performs image preprocessing, feature extraction, and classification tasks. During preprocessing, an annular iris portion is segmented out from an input eyeball image, and for this, two different segmentation approaches: one for near-infrared images and another for visible wavelength images, have been proposed. A novel patch-based histogram-type feature (ensemble of patch statistics) which adopts a statistical approach of texture analysis is employed during feature extraction. For the proposed system, the extensive experimental results have been demonstrated using ten benchmark iris databases, namely MMU1, UPOL, IITD, UBIRIS.v1, CASIA-Interval-v3, CASIA-Iris-Twins, CASIA-Iris-Thousand, CASIA-Iris-Distance, CASIA-Iris-Syn, and UBIRIS.v2. The performance of the proposed system is compared with the state-of-the-art methods on these databases and the comparisons show significant out-performance on the competing methods.
C1 [Umer, Saiyed] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Dhara, Bibhas Chandra] Jadavpur Univ, Dept Informat Technol, Kolkata, India.
   [Chanda, Bhabatosh] Indian Stat Inst, Elect & Commun Sci Unit, Kolkata, India.
C3 Aliah University; Jadavpur University; Indian Statistical Institute;
   Indian Statistical Institute Kolkata
RP Umer, S (corresponding author), Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
EM saiyedumer@gmail.com
RI Dhara, Bibhas Chandra/ABF-9007-2020; umer, saiyed/ABD-1070-2021
OI umer, saiyed/0000-0002-1476-041X
CR Ahamed A, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P548, DOI 10.1109/ICIEV.2012.6317442
   Alvarez S, 2012, PATTERN RECOGN, V45, P4312, DOI 10.1016/j.patcog.2012.04.032
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], MATLAB SOURCE CODE B
   [Anonymous], IRIS IMAGE CLASSIFIC
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], ADV INF SECUR
   [Anonymous], 2014, ARXIV14091556
   [Anonymous], 2012 IEEE COMP SOC C
   [Anonymous], 2007, IRIS DATABASE
   [Anonymous], PATTERN ANAL APPL
   [Anonymous], IEEE T INFORM FORENS
   Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48
   Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832
   da Costa RM, 2012, IEEE T SYST MAN CY B, V42, P1072, DOI 10.1109/TSMCB.2012.2186125
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Dey S, 2012, IEEE T INF FOREN SEC, V7, P1192, DOI 10.1109/TIFS.2012.2196515
   Dong WB, 2011, IEEE T PATTERN ANAL, V33, P1744, DOI 10.1109/TPAMI.2010.227
   Eleyan A, 2008, IEEE INT SYMP SIGNAL, P7, DOI 10.1109/ISSPIT.2008.4775675
   Elgamal M, 2013, Int J Comput Inf Technol, V2, P521
   Erbilek M, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P604
   Llano EG, 2015, INT CONF BIOMETR, P17, DOI 10.1109/ICB.2015.7139042
   Harjoko A., 2009, WORLD ACAD SCI ENG T, V56, P126, DOI DOI 10.5281/ZENODO.1079934
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Hofbauer H, 2014, INT C PATT RECOG, P527, DOI 10.1109/ICPR.2014.101
   Hollingsworth KP, 2009, IEEE T PATTERN ANAL, V31, P964, DOI 10.1109/TPAMI.2008.185
   Ignat A, 2013, E-HEALTH BIOENG CONF, DOI 10.1109/EHB.2013.6707294
   IMAI H, 1985, SIAM J COMPUT, V14, P93, DOI 10.1137/0214006
   Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141
   Kumar A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P303, DOI 10.1109/ICB.2012.6199824
   Kumar A., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P59, DOI DOI 10.1109/CVPRW.2012.6239216
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee CP, 2013, NEURAL COMPUT, V25, P1302, DOI 10.1162/NECO_a_00434
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Masood K, 2007, THIRD INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES 2007, PROCEEDINGS, P253
   Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Nabti M., 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P238
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Proença H, 2015, IEEE T INF FOREN SEC, V10, P321, DOI 10.1109/TIFS.2014.2371691
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1502, DOI 10.1109/TPAMI.2009.140
   Rahulkar AD, 2012, IEEE T INF FOREN SEC, V7, P230, DOI 10.1109/TIFS.2011.2166069
   Rathgeb C, 2011, IET COMPUT VIS, V5, P389, DOI 10.1049/iet-cvi.2010.0176
   Rathgeb C, 2010, LECT NOTES COMPUT SC, V6112, P266, DOI 10.1007/978-3-642-13775-4_27
   Reyes-López J, 2012, P INT C CHIL COMPUT, P283, DOI 10.1109/SCCC.2011.36
   Ross A., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P30, DOI DOI 10.1109/CVPRW.2010.5543234
   Santos G, 2012, PATTERN RECOGN LETT, V33, P984, DOI 10.1016/j.patrec.2011.08.017
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Tan CW, 2012, INT C PATT RECOG, P553
   Tan CW, 2014, IEEE T IMAGE PROCESS, V23, P3962, DOI 10.1109/TIP.2014.2337714
   Tan CW, 2013, IEEE T IMAGE PROCESS, V22, P3751, DOI 10.1109/TIP.2013.2260165
   Tan TN, 2012, PATTERN RECOGN LETT, V33, P970, DOI 10.1016/j.patrec.2011.08.009
   Tsai CC, 2012, IEEE T SYST MAN CY B, V42, P150, DOI 10.1109/TSMCB.2011.2163817
   Uhl A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P283, DOI 10.1109/ICB.2012.6199821
   Umer S, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P97
   Umer S, 2015, PATTERN RECOGN LETT, V65, P67, DOI 10.1016/j.patrec.2015.07.008
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang KZ, 2016, PROC CVPR IEEE, P2138, DOI 10.1109/CVPR.2016.235
   Woodard Damon L., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P201, DOI 10.1109/ICPR.2010.58
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang H, 2011, LECT NOTES COMPUT SC, V7098, P82, DOI 10.1007/978-3-642-25449-9_11
   Zhang M, 2012, IET BIOMETRICS, V1, P37, DOI 10.1049/iet-bmt.2012.0002
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 69
TC 9
Z9 9
U1 1
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2019
VL 35
IS 9
BP 1327
EP 1344
DI 10.1007/s00371-018-1544-4
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IQ2JJ
UT WOS:000480574500011
DA 2024-07-18
ER

PT J
AU Xin, ZH
   Fu, S
AF Xin, Zhihong
   Fu, Shuang
TI User-centric QoE model of visual perception for mobile videos
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 36th Computer Graphics International Conference (CGI)
CY JUN 17-20, 2019
CL Calgary, CANADA
DE Quality of experience (QoE); Visual perception; Mobile video; User
   interest; User centric; Support vector machine (SVM)
ID QUALITY ASSESSMENT; EXPERIENCE
AB It is crucial for service providers to improve user's quality of visual perception for mobile users. Quality of experience (QoE) is an important perceptual visual metric. In this paper, we propose a user-centric QoE assessment model by joint considering technological-aware and psychology-aware parameters in the QoE communication ecosystem. For technological parameters, video encoding features are extracted from the video stream, and video content feature is estimated by video analysis. Moreover, user interests are also quantitatively collected as psychology parameters. Then, QoE model is developed by using support vector machine (SVM). Subjective tests have been performed. The collected data from subjective tests are used for training and validation of the proposed model. The experiment results show that the proposed user-centric QoE assessment model performs better in terms of high Pearson correlation coefficient (PCC) and low root-mean-square error (RMSE) compared with the conventional models.
C1 [Xin, Zhihong] Xian Med Univ, Xian 710021, Shaanxi, Peoples R China.
   [Fu, Shuang] Xi An Jiao Tong Univ, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Medical University; Xi'an Jiaotong University
RP Xin, ZH (corresponding author), Xian Med Univ, Xian 710021, Shaanxi, Peoples R China.
EM xinzhihong@xiyi.edu.cn
CR [Anonymous], P 21 INT C RAD BRN C
   [Anonymous], BT50011 INT TEL UN
   [Anonymous], EUROPEAN NETWORK QUA
   [Anonymous], METH SUBJ ASS VID QU
   [Anonymous], 2007, OPINION MODEL VIDEO
   Chen ZB, 2016, IEEE T CIRC SYST VID, V26, P1029, DOI 10.1109/TCSVT.2015.2441432
   Garcia MN, 2008, INT CONF ACOUST SPEE, P757, DOI 10.1109/ICASSP.2008.4517720
   Hamblen M., 2011, COMPUTER WORLD
   Hu SM, 2013, VISUAL COMPUT, V29, P393, DOI 10.1007/s00371-013-0792-6
   Hulusic V, 2013, VISUAL COMPUT, V29, P1159, DOI 10.1007/s00371-012-0760-6
   Khan A, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/608138
   Kilkki K, 2008, J UNIVERS COMPUT SCI, V14, P615
   Kim HL, 2010, INT CONF ADV COMMUN, P1377
   Kim HJ, 2008, NCM 2008: 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 2, PROCEEDINGS, P719, DOI 10.1109/NCM.2008.202
   Laghari KUR, 2012, IEEE COMMUN MAG, V50, P58, DOI 10.1109/MCOM.2012.6178834
   Li F, 2018, IEEE T MULTIMEDIA, V20, P1154, DOI 10.1109/TMM.2017.2764329
   Molnar A, 2012, CONSUM COMM NETWORK, P265, DOI 10.1109/CCNC.2012.6181099
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Seshadrinathan K., 2009, SPIE PROCESSING  FEB
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Vapnik VN, 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   YANG RL, 1994, PROCEEDINGS OF THE 1994 AMERICAN CONTROL CONFERENCE, VOLS 1-3, P1379
   Zargari Farzad, 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P489, DOI 10.1109/CBMI.2008.4564987
   Zargari F, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P831
NR 27
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2019
VL 35
IS 9
BP 1245
EP 1254
DI 10.1007/s00371-018-1590-y
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IQ2JJ
UT WOS:000480574500005
DA 2024-07-18
ER

PT J
AU Liu, XX
   Xu, QY
   Wang, N
AF Liu, Xiaoxiao
   Xu, Qingyang
   Wang, Ning
TI A survey on deep neural network-based image captioning
SO VISUAL COMPUTER
LA English
DT Article
DE Image captioning; Image understanding; Object detection; Language model;
   Attention mechanism; Dense captioning
AB Image captioning is a hot topic of image understanding, and it is composed of two natural parts (look and language expression) which correspond to the two most important fields of artificial intelligence (machine vision and natural language processing). With the development of deep neural networks and better labeling database, the image captioning techniques have developed quickly. In this survey, the image captioning approaches and improvements based on deep neural network are introduced, including the characteristics of the specific techniques. The early image captioning approach based on deep neural network is the retrieval-based method. The retrieval method makes use of a searching technique to find an appropriate image description. The template-based method separates the image captioning process into object detection and sentence generation. Recently, end-to-end learning-based image captioning method has been verified effective at image captioning. The end-to-end learning techniques can generate more flexible and fluent sentence. In this survey, the image captioning methods are reviewed in detail. Furthermore, some remaining challenges are discussed.
C1 [Liu, Xiaoxiao; Xu, Qingyang] Shandong Univ, Sch Mech Elect & Informat Engn, Weihai 264209, Peoples R China.
   [Wang, Ning] Dalian Maritime Univ, Marine Engn Coll, Dalian 116026, Peoples R China.
C3 Shandong University; Dalian Maritime University
RP Xu, QY (corresponding author), Shandong Univ, Sch Mech Elect & Informat Engn, Weihai 264209, Peoples R China.; Wang, N (corresponding author), Dalian Maritime Univ, Marine Engn Coll, Dalian 116026, Peoples R China.
EM sdulxx@163.com; qingyangxu@sdu.edu.cn; n.wang.dmu.cn@gmail.com
RI xu, qingyang/C-1808-2012; Wang, Ning/B-2777-2012; Liu,
   Xiaoxiao/HNI-6180-2023
OI Wang, Ning/0000-0003-1745-1425; Xu, Qingyang/0000-0003-3870-5551
FU National Nature Science Foundation of China [61603214, 61573213,
   51009017, 51379002]; Shandong Provincial Key Research and Development
   Plan [2018GGX101039]; Shandong Provincial Natural Science Foundation
   [ZR2015PF009, 2016ZRE2703]; Fund for Dalian Distinguished Young Scholars
   [2016RJ10]; Innovation Support Plan for Dalian High-level Talents
   [2015R065]; Fundamental Research Funds for the Central Universities
   [3132016314, 3132018126]
FX The authors would like to thank the two anonymous reviewers and the
   editor-in-chief for their comment to improve the paper. This work is
   supported by National Nature Science Foundation of China (under Grants
   61603214, 61573213, 51009017 and 51379002), Shandong Provincial Key
   Research and Development Plan (2018GGX101039), Shandong Provincial
   Natural Science Foundation (ZR2015PF009, 2016ZRE2703), the Fund for
   Dalian Distinguished Young Scholars (under Grant 2016RJ10), the
   Innovation Support Plan for Dalian High-level Talents (under Grant
   2015R065), and the Fundamental Research Funds for the Central
   Universities (under Grant 3132016314 and 3132018126).
CR Aker A., 2013, M ASS COMP LING ASS, P1250
   Aloimonos Y., 2016, ACM COMPUT SURV, V49, P71
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], 2016, POINTER SENTINEL MIX
   [Anonymous], 2014, EFFECTIVE USE WORD O
   [Anonymous], 2013, P 2013 C EMP METH NA
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], ARXIV161106607
   [Anonymous], 2005, Proc._Neural_Information_Processing_System
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2014, ARXIV14124729
   [Anonymous], 2014, ARXIV14128419
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Channarukul S., 2003, C N AM CHAPT ASS COM
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen W., 2016, ARXIV161105321V1
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Chisholm M., 2002, Proceeding 2002 International Conference Machine Learning, P75
   Cho K., 2014, ARXIV14061078
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Chung Junyoung, 2014, ARXIV14123555
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Donahue B, 2015, 2015 IEEE AEROSPACE CONFERENCE
   Dong YP, 2017, PROC CVPR IEEE, P975, DOI 10.1109/CVPR.2017.110
   Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522
   Er MJ, 2016, INFORM SCIENCES, V373, P388, DOI 10.1016/j.ins.2016.08.084
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Graff David., 2007, ENGLISH GIGAWORD, VThird
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A., 2015, ARXIV150602078
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Kuznetsova P., 2012, Long Papers, P359
   Li J., 2015, HIERARCHICAL NEURAL, P1057
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin Rui, 2015, EMNLP, P899
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu J., 2016, arXiv1612.01887
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Mao JH, 2015, IEEE I CONF COMP VIS, P2533, DOI 10.1109/ICCV.2015.291
   Mao Junhua., 2014, Explain images with multimodal recurrent neural networks
   Maron O, 1998, ADV NEUR IN, V10, P570
   Mikolov T., 2013, 27 ANN C NEUR INF PR, V26
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Mnih V, 2014, ADV NEUR IN, V27
   Norouzi M., 2014, P INT C LEARN REPR
   Ordonez V, 2012, ADV NEURAL INFORM PR, V25, P1143
   Oriol V, 2015, IEEE T PATTERN ANAL, V39, P652
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pascanu R., 2014, ICLR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Song HO, 2014, PR MACH LEARN RES, V32, P1611
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Sutskever Ilya, 2011, P 28 INT C MACH LEAR, P1017
   Tanti M., 2017, ARXIV170309137
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Verma Y, 2013, IEEE COMPUT SOC CONF, P288, DOI 10.1109/CVPRW.2013.50
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   White M, 2002, P WORKSH AUT SUMM IN, V4, P9
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
   Yang LJ, 2017, PROC CVPR IEEE, P1978, DOI 10.1109/CVPR.2017.214
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zaremba W., 2014, RECURRENT NEURAL NET, P1, DOI DOI 10.1016/S0893-6080(96)00073-1
   Zhou B., 2014, CORR, V1412, P6856
   Zhou Liang, 2004, Text Summarization Branches Out, P56
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 98
TC 50
Z9 53
U1 2
U2 50
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2019
VL 35
IS 3
BP 445
EP 470
DI 10.1007/s00371-018-1566-y
PG 26
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HP0MR
UT WOS:000461360600011
DA 2024-07-18
ER

PT J
AU Krösl, K
   Bauer, D
   Schwärzler, M
   Fuchs, H
   Suter, G
   Wimmer, M
AF Kroesl, Katharina
   Bauer, Dominik
   Schwaerzler, Michael
   Fuchs, Henry
   Suter, Georg
   Wimmer, Michael
TI A VR-based user study on the effects of vision impairments on
   recognition distances of escape-route signs in buildings
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 35th Computer Graphics International conference (CGI)
CY JUN 11-14, 2018
CL INDONESIA
SP Comp Graph Soc, Nanyang Technol Univ
DE Virtual reality; Vision impairment simulation; User study; Wheelchair
   simulation
ID VIRTUAL-REALITY
AB In workplaces or publicly accessible buildings, escape routes are signposted according to official norms or international standards that specify distances, angles and areas of interest for the positioning of escape-route signs. In homes for the elderly, in which the residents commonly have degraded mobility and suffer from vision impairments caused by age or eye diseases, the specifications of current norms and standards may be insufficient. Quantifying the effect of symptoms of vision impairments like reduced visual acuity on recognition distances is challenging, as it is cumbersome to find a large number of user study participants who suffer from exactly the same form of vision impairments. Hence, we propose a new methodology for such user studies: By conducting a user study in virtual reality (VR), we are able to use participants with normal or corrected sight and simulate vision impairments graphically. The use of standardized medical eyesight tests in VR allows us to calibrate the visual acuity of all our participants to the same level, taking their respective visual acuity into account. Since we primarily focus on homes for the elderly, we accounted for their often limited mobility by implementing a wheelchair simulation for our VR application.
C1 [Kroesl, Katharina] TU Wien, Comp Graph Res Div, Vienna, Austria.
   [Bauer, Dominik] TU Wien, Vienna, Austria.
   [Suter, Georg] TU Wien, Fac Architecture & Planning, Vienna, Austria.
   [Wimmer, Michael] TU Wien, Inst Comp Graph & Algorithms, Vienna, Austria.
   [Kroesl, Katharina; Schwaerzler, Michael] VRVis Res Ctr, Vienna, Austria.
   [Fuchs, Henry] Univ North Carolina Chapel Hill, Comp Sci, Chapel Hill, NC USA.
   [Fuchs, Henry] Univ North Carolina Chapel Hill, Biomed Engn, Chapel Hill, NC USA.
C3 Technische Universitat Wien; Technische Universitat Wien; Technische
   Universitat Wien; Technische Universitat Wien; University of North
   Carolina School of Medicine; University of North Carolina; University of
   North Carolina Chapel Hill; University of North Carolina; University of
   North Carolina Chapel Hill; University of North Carolina School of
   Medicine
RP Krösl, K (corresponding author), TU Wien, Comp Graph Res Div, Vienna, Austria.
EM kkroesl@cg.tuwien.ac.at
OI Bauer, Dominik/0000-0002-1260-1319; Wimmer, Michael/0000-0002-9370-2663;
   Krosl, Katharina/0000-0002-9939-0517
FU BMVIT, Styria; BMWFW, Styria; SFG; Vienna Business Agency in the scope
   of COMET-Competence Centers for Excellent Technologies [854174]
FX This work was enabled by the Doctoral College Computational Design,
   Center for Geometry and Computational Design, TU Wien and the Competence
   Centre VRVis. VRVis is funded by BMVIT, BMWFW, Styria, SFG and Vienna
   Business Agency in the scope of COMET-Competence Centers for Excellent
   Technologies (854174)-which is managed by FFG.
CR Almeida J.E., 2014, 9th Iberian Conference on Information Systems and Technologies (CISTI), P1, DOI DOI 10.1109/CISTI.2014.6876951
   [Anonymous], 386412011 ISO
   [Anonymous], 2002, INT COUNC OPHTH 29 I
   [Anonymous], 2011, INVESTIGATION INTERA
   Ates H.C., 2015, P 9 INT C TANGIBLE E, P225, DOI [DOI 10.1145/2677199.2680551, 10.1145/2677199.2680551]
   Chowdhury Tanvir Irfan., 2017, Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology, page, P37
   Cosma G, 2016, J TRANSP SAF SECUR, V8, P101, DOI 10.1080/19439962.2015.1046621
   DIN German Institute for Standardization, 2013, 18382013 DIN EN
   European Committee for Standardization, 2012, 70102011 ISO EUR COM
   Hogervorst M. A., 2006, Gerontechnology, V5, P208, DOI 10.4017/gt.2006.05.04.003.00
   International Organization for Standardization, 2009, 85932009 ISO
   Jin B, 2005, P ANN INT IEEE EMBS, P5128
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lewis J., 2012, P 9 INT C DIS VIRT R
   Lewis James., 2011, 2011 IEEE 1 INT C SE, P1, DOI DOI 10.1109/SEGAH.2011.6165430
   Luksch C., 2013, ACM SIGGRAPH Symp. on Interactive 3D Graphics and Games, P87
   Luksch C, 2014, VISUAL COMPUT, V30, P717, DOI 10.1007/s00371-014-0958-x
   NEI Office of Science Communications, PREV AD VIS IMP AG R
   Nybakke A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P27, DOI 10.1109/3DUI.2012.6184180
   Snellen H., 1862, Optotypi ad visum determinandum (letterproeven tot bepaling der gezichtsscherpte; probebuchstaben zur bestimmung der sehschaerfe)
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Suma EA, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P27, DOI 10.1109/3DUI.2010.5444726
   Vasylevska K., 2015, The Visual Language of Technique, P81
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Väyrynen J, 2016, 15TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2016), P69, DOI 10.1145/3012709.3012714
   Vincent G.K., 2010, NEXT 4 DECADES OLDER, P1138
   Wood J, 2010, OPTOMETRY VISION SCI, V87, P379, DOI 10.1097/OPX.0b013e3181d95b0d
   Xie H, 2007, J FIRE PROT ENG, V17, P41, DOI 10.1177/1042391507064025
   ZAGAR M, 2010, AM J PHARM EDUC, V74
NR 31
TC 22
Z9 22
U1 2
U2 22
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2018
VL 34
IS 6-8
SI SI
BP 911
EP 923
DI 10.1007/s00371-018-1517-7
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GH6MC
UT WOS:000433557400015
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Xia, PJ
AF Xia, Pingjun
TI New advances for haptic rendering: state of the art
SO VISUAL COMPUTER
LA English
DT Article
DE Haptics; Haptic rendering; Survey
ID REAL-TIME SIMULATION; SOFT-TISSUES; CONTACT; SURFACES; TEXTURES;
   DISPLAY; DESIGN; FORCES; MODEL
AB During the last decade, haptics has been a new emerged and interesting subject for many researchers, which can be classified into three topics such as human haptics, machine haptics and computer haptics. Haptic rendering is the most important technology for computer haptics, which means the process of calculating the force or tactile feedback to give the user a sense of touch or interaction with the virtual object. This paper provides a detailed and comprehensive survey of the methods and technologies for haptic rendering in the past 5 years, mainly from 2010-2015, including haptic rendering for rigid-rigid interaction, haptic rendering for rigid-deformable interaction, haptic rendering for rigid-fluid interaction, haptic rendering for image- and video-based interaction, and texture and tactile rendering. The main research efforts and the typical algorithms are discussed, and the new ideas and research progresses are investigated, then the conclusions and future directions are summarized.
C1 [Xia, Pingjun] Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Xia, PJ (corresponding author), Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.
EM smallping_hit@aliyun.com
CR Adams RJ, 1999, IEEE T ROBOTIC AUTOM, V15, P465, DOI 10.1109/70.768179
   Ahmaniemi T, 2010, IEEE T HAPTICS, V3, P245, DOI 10.1109/ToH.2010.22
   Altinsoy ME, 2012, IEEE T HAPTICS, V5, P6, DOI [10.1109/TOH.2011.56, 10.1109/ToH.2011.56]
   Altomonte M., 2008, IEEE RSJ INT C INT R, P3359
   [Anonymous], 2008, HAPTIC RENDERING FDN
   Appleyard MN, 2000, GASTROINTEST ENDOSC, V52, P237, DOI 10.1067/mge.2000.107218
   Barbic J, 2008, IEEE T HAPTICS, V1, P39, DOI [10.1109/TOH.2008.1, 10.1109/ToH.2008.1]
   Baxter W, 2004, PROC GRAPH INTERF, P81
   Bordegoni M, 2011, IEEE T HAPTICS, V4, P111, DOI [10.1109/TOH.2011.1, 10.1109/ToH.2011.1]
   Bordegoni M, 2008, J COMPUT INF SCI ENG, V8, DOI 10.1115/1.2988383
   Cirio G, 2013, IEEE T HAPTICS, V6, P117, DOI 10.1109/TOH.2012.34
   Cirio G, 2011, IEEE T VIS COMPUT GR, V17, P1714, DOI 10.1109/TVCG.2010.271
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Cugini U, 2007, VISUAL COMPUT, V23, P233, DOI 10.1007/s00371-007-0105-z
   Culbertson H, 2014, IEEE T HAPTICS, V7, P381, DOI 10.1109/TOH.2014.2316797
   Culbertson H, 2014, IEEE HAPTICS SYM, P319, DOI 10.1109/HAPTICS.2014.6775475
   Dobashi Y., 2006, Proceedings of ACM VRST'06, P91
   Gao Z, 2006, COMPUT AIDED DESIGN, V38, P661, DOI 10.1016/j.cad.2006.02.004
   Garcia-Hernandez N, 2011, IEEE T HAPTICS, V4, P100, DOI 10.1109/ToH.2010.59
   González D, 2015, COMPUT METHOD APPL M, V283, P210, DOI 10.1016/j.cma.2014.09.029
   He XJ, 2015, MULTIMED TOOLS APPL, V74, P1823, DOI 10.1007/s11042-013-1720-5
   Hirota K., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P211, DOI 10.1109/VRAIS.1995.512498
   Höver R, 2009, IEEE T HAPTICS, V2, P15, DOI 10.1109/ToH.2009.2
   Hoshi T, 2010, IEEE T HAPTICS, V3, P155, DOI [10.1109/ToH.2010.4, 10.1109/TOH.2010.4]
   Hou XY, 2013, VISUAL COMPUT, V29, P1063, DOI 10.1007/s00371-013-0838-9
   Jialu Li, 2010, Proceedings 2010 3rd International Symposium on Computational Intelligence and Design (ISCID 2010), P7, DOI 10.1109/ISCID.2010.9
   Kim L, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2943, DOI 10.1109/IRDS.2002.1041719
   Kim SY, 2009, IEICE ELECTRON EXPR, V6, P382, DOI 10.1587/elex.6.382
   Kim YJ, 2003, PRESENCE-VIRTUAL AUG, V12, P277, DOI 10.1162/105474603765879530
   Knott TC, 2016, COMPUT GRAPH-UK, V57, P68, DOI 10.1016/j.cag.2016.03.007
   Lang JC, 2011, IEEE T VIS COMPUT GR, V17, P380, DOI 10.1109/TVCG.2010.52
   Li Y, 2016, SIGNAL PROCESS, V120, P714, DOI 10.1016/j.sigpro.2014.12.004
   Li Y, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P289, DOI 10.1109/WHC.2013.6548423
   Li ZH, 2014, THESIS
   Mafi R, 2010, IEEE T HAPTICS, V3, P211, DOI [10.1109/TOH.2009.50, 10.1109/ToH.2009.50]
   Mirtich B., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P181, DOI 10.1145/199404.199436
   Moustakas K, 2016, MULTIMED TOOLS APPL, V75, P4543, DOI 10.1007/s11042-015-2490-z
   Neubauer A, 2013, COMPUT ANIMAT VIRT W, V24, P127, DOI 10.1002/cav.1489
   Niroomandi S, 2013, INT J NUMER METH BIO, V29, P586, DOI 10.1002/cnm.2544
   Ortega M, 2007, IEEE T VIS COMPUT GR, V13, P458, DOI 10.1109/TVCG.2007.1028
   OTADUY M.A., 2004, P 1 S APPL PERCEPTIO, V1, P123
   Peterlík I, 2011, IEEE T HAPTICS, V4, P175, DOI [10.1109/TOH.2011.41, 10.1109/ToH.2011.41]
   Rasool S., 2011, SIGGRAPH ASIA SKETCH, P1
   Rasool S, 2013, P 19 ACM S VIRT REAL, P17
   Rasool S, 2013, VISUAL COMPUT, V29, P333, DOI 10.1007/s00371-012-0736-6
   Rydén F, 2013, IEEE INT CONF ROBOT, P2353, DOI 10.1109/ICRA.2013.6630896
   Rydén F, 2013, IEEE T HAPTICS, V6, P257, DOI 10.1109/TOH.2013.20
   Sarakoglou I, 2012, IEEE T HAPTICS, V5, P252, DOI 10.1109/TOH.2012.20
   Siira J, 1996, IEEE INT CONF ROBOT, P557, DOI 10.1109/ROBOT.1996.503834
   Talvas A, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2013.6550206
   Venugopal K., 2012, INT J COMPUT SCI ISS, V9, P234
   Wang DX, 2014, IEEE T HAPTICS, V7, P48, DOI 10.1109/TOH.2014.2304734
   Wang DX, 2013, IEEE T HAPTICS, V6, P167, DOI [10.1109/ToH.2012.63, 10.1109/TOH.2012.63]
   Wang Q, 2012, IEEE T HAPTICS, V5, P344, DOI [10.1109/ToH.2011.69, 10.1109/TOH.2011.69]
   Wang Z, 2014, LECT NOTES COMPUT SC, V8579, P808, DOI 10.1007/978-3-319-09144-0_56
   Wu J, 2010, J COMPUT INF SCI ENG, V10, DOI 10.1115/1.3402759
   Wu XL, 2001, COMPUT GRAPH FORUM, V20, pC349
   Xia P, 2012, P 11 ACM SIGGRAPH IN, P25, DOI [10.1145/2407516.2407523, DOI 10.1145/2407516.2407523]
   Yang M., 2009, SIGGRAPH ASIA SKETCH, P182
   Yoo YH, 2010, IEICE ELECTRON EXPR, V7, P170, DOI 10.1587/elex.7.170
   Yuan Tian, 2014, 2014 IEEE 4th Workshop on Mining Unstructured Data (MUD), P1, DOI 10.1109/MUD.2014.14
   Zhang XR, 2014, ARTIF INTELL REV, V41, P49, DOI 10.1007/s10462-011-9297-8
   Zhang XZ, 2015, COMPUT ANIMAT VIRT W, V26, P311, DOI 10.1002/cav.1643
   Zilles C., 1995, INT C INTELLIGENT RO, P3146
NR 64
TC 11
Z9 11
U1 1
U2 22
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2018
VL 34
IS 2
BP 271
EP 287
DI 10.1007/s00371-016-1324-y
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU6ZO
UT WOS:000424001800010
DA 2024-07-18
ER

PT J
AU Ahmad, S
   Khan, MF
AF Ahmad, Sahar
   Khan, Muhammad Faisal
TI Multimodal non-rigid image registration based on elastodynamics
SO VISUAL COMPUTER
LA English
DT Article
DE Elastodynamics; Multimodal; Image registration; Mutual information
ID INFORMATION
AB In this paper, we present a new multimodal image registration technique established on elastodynamics notion. The main idea behind this concept is the progression of waves on an elastic body as soon as it is disturbed from its initial rest state. We propose to solve the multimodal registration problem by modeling the non-linear deformations as elastic waves and iteratively solving the elastodynamics wave equation to estimate the transformation. The inertial force in elastodynamics model is computed as the gradient of mutual information which considers the statistical relationship between the intensities of the images acquired using different imaging modalities. We tested our method on T1-T2 weighted MR brain image pairs and MR-CT brain image pairs. The proposed registration technique was compared against a variant of demons method proposed for multimodal images. The registration results were analyzed by examining the overlay images and by computing the normalized mutual information. The qualitative and quantitative analysis proved that our proposed method registers the images better than the compared method.
C1 [Ahmad, Sahar; Khan, Muhammad Faisal] NUST, Mil Coll Signals, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Ahmad, S (corresponding author), NUST, Mil Coll Signals, Islamabad, Pakistan.
EM 07311134@mcs.edu.pk
RI Ahmad, Sahar/AAE-1358-2020
OI Ahmad, Sahar/0000-0001-7243-9977
CR Ahmad S, 2015, MACH VISION APPL, V26, P689, DOI 10.1007/s00138-015-0690-1
   [Anonymous], SOLID MECH ITS APPL
   Barber J.R, 2010, Elasticity, DOI DOI 10.1007/978-90-481-3809-8
   D'Agostino E, 2003, MED IMAGE ANAL, V7, P565, DOI 10.1016/S1361-8415(03)00039-2
   Fernandez-De-Manuel L, 2014, MED IMAGE ANAL, V18, P22, DOI 10.1016/j.media.2013.09.002
   Hermosillo G, 2002, INT J COMPUT VISION, V50, P329, DOI 10.1023/A:1020830525823
   Khader M, 2012, EXPERT SYST APPL, V39, P5548, DOI 10.1016/j.eswa.2011.11.064
   Kroon DJ, 2009, I S BIOMED IMAGING, P963, DOI 10.1109/ISBI.2009.5193214
   Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072
   Leibfarth S, 2013, ACTA ONCOL, V52, P1353, DOI 10.3109/0284186X.2013.813964
   Lu H, 2010, I S BIOMED IMAGING, P372, DOI 10.1109/ISBI.2010.5490333
   Lu HX, 2013, COMPUT MED IMAG GRAP, V37, P234, DOI 10.1016/j.compmedimag.2013.03.004
   Martin S, 2004, ELECTRON LETT, V40, P595, DOI 10.1049/el:20040375
   Modat M., 2010, P SPIE, V7623
   Mutic S, 2001, INT J RADIAT ONCOL, V51, P255, DOI 10.1016/S0360-3016(01)01659-5
   Orchard J, 2008, MED IMAGE ANAL, V12, P385, DOI 10.1016/j.media.2007.12.002
   Piccinelli M, 2013, J BIOMED RES, V27, P439, DOI 10.7555/JBR.27.20130138
   Poruchikov B., 1993, METHODS CLASSICAL TH
   Reducindo I, 2012, IEEE ENG MED BIO, P1133, DOI 10.1109/EMBC.2012.6346135
   Sabuncu M., IEEE T IMAGE PROCESS, V17, P788
   Spiclin Z., 2011, LECT NOTES COMPUTER, V7012
   Vegh V, 2010, IEEE IMAGE PROC, P4385, DOI 10.1109/ICIP.2010.5653395
NR 22
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2018
VL 34
IS 1
BP 21
EP 27
DI 10.1007/s00371-016-1307-z
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FR5XF
UT WOS:000419139200004
DA 2024-07-18
ER

PT J
AU Zhang, HY
   Liu, GX
AF Zhang, Haoyang
   Liu, Guixi
TI Coupled-layer based visual tracking via adaptive kernelized correlation
   filters
SO VISUAL COMPUTER
LA English
DT Article
DE Coupled-layer visual model; Reliable patches; Kernelized correlation
   filters; Visual tracking
ID OBJECT TRACKING
AB Part-based visual model is particularly useful when the target appearance undergoes partial occlusion or deformation. The existing reliable patches tracking (RPT) method has achieved better result by identifying and exploiting the reliable patches that can be tracked correctly, yet it tends to fail in some challenging scenes since it ignores the holistic information of target completely, while, in fact, the target's holistic appearance provides more discriminative features than local patches with low resolution. Based on the existing RPT and kernelized correlation filters tracking method, in this paper, we propose a coupled-layer visual model based tracker by combining the target's global and local appearance in a coupled way. The global layer provides the holistic information and is treated as an approximation of the target. The local layer is composed of multiple small patches that are randomly initialized in the first frame. During tracking, the global tracker detects the target itself; its detection result is employed in the local layer to exploit the reliable patches and to estimate the target position corresponding to each patch. The exploited reliable patches are employed to estimate the target scale and to vote the current target location. Finally, both global and local models are updated with carefully designed updating mechanisms. Experiments conducted on 80 challenging benchmark sequences clearly show that our tracker improves the RPT tracker significantly both in overall and individual performance yet without obvious speed cost. Also, our tracker outperforms all the state-of-the-art trackers in overall datasets and eight independent datasets.
C1 [Zhang, Haoyang; Liu, Guixi] Xidian Univ, Sch Electromech Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Liu, GX (corresponding author), Xidian Univ, Sch Electromech Engn, Xian 710071, Shaanxi, Peoples R China.
EM zhanghy_xd@163.com; gxliu@xidian.edu.cn
RI Zhang, Yuyao/KEH-7175-2024
FU Preliminary Research Foundation of National Defence Science and
   Technology [90406150007]; Fundamental Research Funds for the Central
   Universities [NSIY191414]
FX This work is supported by the Preliminary Research Foundation of
   National Defence Science and Technology under Grant 90406150007, and the
   Fundamental Research Funds for the Central Universities under Grant
   NSIY191414.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cehovin L, 2011, IEEE I CONF COMP VIS, P1363, DOI 10.1109/ICCV.2011.6126390
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Doucet A, 2001, STAT ENG IN, P3
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao J., 2014, EUROPEAN C COMPUTER
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li Y, IEEE C COMP VIS PATT, P353
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nebehay G, 2014, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2014.6836013
   Nejhum S.M. Shahed., 2008, Proceedings IEEE Conference on Computer Vision and Pattern Recognition, P1
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu YL, 2016, IEEE SIGNAL PROC LET, V23, P40, DOI 10.1109/LSP.2015.2479360
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zeisl B, 2010, PROC CVPR IEEE, P1879, DOI 10.1109/CVPR.2010.5539860
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 39
TC 11
Z9 11
U1 1
U2 37
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2018
VL 34
IS 1
BP 41
EP 54
DI 10.1007/s00371-016-1310-4
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FR5XF
UT WOS:000419139200006
DA 2024-07-18
ER

PT J
AU Wilson, J
   Sterling, A
   Rewkowski, N
   Lin, MC
AF Wilson, Justin
   Sterling, Auston
   Rewkowski, Nicholas
   Lin, Ming C.
TI Glass half full: sound synthesis for fluid-structure coupling using
   added mass operator
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 34th International Conference on Computer Graphics (CGI)
CY JUN 27-30, 2017
CL Yokohama, JAPAN
SP Keio Univ, Fac Sci & Technol
DE Sound synthesis; Wave modes; Elasto-acoustic system; Fluid-structure;
   Added mass operator
AB We present a fast and practical method for simulating the sound of non-empty objects containing fluids. The method is designed and demonstrated for use in interactive 3D systems, where live sound synthesis is important. The key contribution of this work is to enhance the sound synthesis equation in the rigid-body audio pipeline to account for the fluid force on an object at the fluid-structure boundary. Additions include pre-processing steps to identify the mesh nodes of a tetrahedralized object that are in contact with the liquid and to apply an added mass operator to those structural boundary nodes and adjacent solid domain nodes by increasing their corresponding elements in the mass matrix proportional to the liquid's density, which may vary with temperature and/or type of fluids. Our technique generalizes to any impermeable tetrahedral mesh representing the rigid objects and inviscid liquids.
C1 [Wilson, Justin; Sterling, Auston; Rewkowski, Nicholas; Lin, Ming C.] Univ North Carolina Chapel Hill, Chapel Hill, NC 27599 USA.
C3 University of North Carolina School of Medicine; University of North
   Carolina; University of North Carolina Chapel Hill
RP Wilson, J (corresponding author), Univ North Carolina Chapel Hill, Chapel Hill, NC 27599 USA.
EM wilson@cs.unc.edu
FU Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [1320644, 1840864] Funding Source: National Science
   Foundation
CR Adrien J.-M., 1991, Representations on musical signals, P269
   [Anonymous], 2003, PRESENCE TELEOPERATI
   [Anonymous], 2006, EUR C COMP FLUID DYN
   Basic J., 2012, ANAL NUMERICAL COMPU
   Bazilevs Y, 2013, Computational Fluid structure interaction (Methods and Applications), DOI [DOI 10.1002/9781118483565, 10.1002/9781118483565]
   Boyd J. P., 2001, CHEBYSHEV FOURIER SP
   Brebbia C.A., 1991, BOUNDARY ELEMENT MET
   Brennen C.E., 1982, REV ADDED MASS FLUID
   CAL POLY POMONA MECHANICAL ENGINEERING DEPARTMENT, 2016, FLUID MECH TOP 4 3 H
   Chadwick JN, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964979
   Cummings J.J., 2012, IMMERSIVE IS ENOUGH
   Dobashi Y, 2003, ACM T GRAPHIC, V22, P732, DOI 10.1145/882262.882339
   Flemisch B., 2000, INT J NUMER METHODS
   Gottschalk S., 1996, OBBTREE HIERARCHICAL
   James D.L., 2016, PHYSICALLY BASED SOU
   James D.L., 2006, PRECOMPUTED ACOUSTIC
   Kosslyn SM, 2005, COGN NEUROPSYCHOL, V22, P333, DOI 10.1080/02643290442000130
   Lin M.C., 1998, PROC IMA C MATH SURF, P37
   Mehra R, 2015, IEEE T VIS COMPUT GR, V21, P434, DOI 10.1109/TVCG.2015.2391858
   Moss W., 2010, ACM T GRAPH TOG
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M., 2002, STABLE REAL TIME DEF
   Newman J. N., 1977, Marine Hydrodynamics
   OBrien J.F., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation, P175
   Raghuvanshi N., 2006, P ACM I3D
   Raghuvanshi N., 2010, ACM T GRAPH SIGGRAPH
   Raghuvanshi N, 2009, IEEE T VIS COMPUT GR, V15, P789, DOI [10.1109/TVCG.2009.27, 10.1109/TVCG.2009.28]
   Ren Z., 2012, ACM SIGGRAPH S INT 3
   Ren ZM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421637
   Rocchesso D., 2003, COMPUT MEDIA AESTHET
   Rungta A., 2016, IEEE TVCG
   Sakamoto S., 2006, J Acoust Soc Am, V120, P3008
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   SEK A, 1995, J ACOUST SOC AM, V97, P2479, DOI 10.1121/1.411968
   Shabana A., 1997, Vibration of discrete and continuous systems
   Sterling A., 2016, ACM SIGGRAPH S INT 3
   Thompson LL, 2006, J ACOUST SOC AM, V119, P1315, DOI 10.1121/1.2164987
   Tong Z., 2006, J SOUND VIB
   Tsingos N, 2004, ACM T GRAPHIC, V23, P249, DOI 10.1145/1015706.1015710
   van den Doel K, 2001, COMP GRAPH, P537, DOI 10.1145/383259.383322
   Van den Doel K., 1996, PRESENCE, V7, P382
   VanBrummelen E, 2009, DELFT AEROSP COMPUT
   Zheng CX, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778806
   Zheng CX, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964933
NR 44
TC 1
Z9 3
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2017
VL 33
IS 6-8
BP 1039
EP 1048
DI 10.1007/s00371-017-1383-8
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EX1EY
UT WOS:000402964800033
DA 2024-07-18
ER

PT J
AU Balducci, F
   Grana, C
   Cucchiara, R
AF Balducci, Fabrizio
   Grana, Costantino
   Cucchiara, Rita
TI Affective level design for a role-playing videogame evaluated by a
   brain-computer interface and machine learning methods
SO VISUAL COMPUTER
LA English
DT Article
DE Affective design; Role-playing games; Brain-computer interface
ID CIRCUMPLEX MODEL; EXPERIENCE
AB Game science has become a research field, which attracts industry attention due to a worldwide rich sell-market. To understand the player experience, concepts like flow or boredom mental states require formalization and empirical investigation, taking advantage of the objective data that psychophysiological methods like electroencephalography (EEG) can provide. This work studies the affective ludology and shows two different game levels for Neverwinter Nights 2 developed with the aim to manipulate emotions; two sets of affective design guidelines are presented, with a rigorous formalization that considers the characteristics of role-playing genre and its specific gameplay. An empirical investigation with a brain-computer interface headset has been conducted: by extracting numerical data features, machine learning techniques classify the different activities of the gaming sessions (task and events) to verify if their design differentiation coincides with the affective one. The observed results, also supported by subjective questionnaires data, confirm the goodness of the proposed guidelines, suggesting that this evaluation methodology could be extended to other evaluation tasks.
C1 [Balducci, Fabrizio; Grana, Costantino; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Via Vivarelli 10, I-41125 Modena, MO, Italy.
C3 Universita di Modena e Reggio Emilia
RP Grana, C (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Via Vivarelli 10, I-41125 Modena, MO, Italy.
EM fabrizio.balducci@unimore.it; costantino.grana@unimore.it;
   rita.cucchiara@unimore.it
RI Grana, Costantino/B-4555-2012; Cucchiara, Rita/L-3006-2015; Balducci,
   Fabrizio/K-5023-2019
OI Grana, Costantino/0000-0002-4792-2358; Balducci,
   Fabrizio/0000-0003-1174-4323
CR Aarnoutse Floor., 2014, Games Media Entertainment (GEM), 2014 IEEE, P1
   Andreassi J. L., 2000, Psychophysiology human behavior and physiological response, V4th
   [Anonymous], P 2014 C FDN DIG GAM
   [Anonymous], GAM VIRT WORLDS SER
   [Anonymous], P 2003 DIGRA INT C
   [Anonymous], 2012, P 16 INT AC MINDTREK
   [Anonymous], 2009, P 13 INT MINDTREK C
   [Anonymous], AAAI C ART INT INT D
   [Anonymous], NEVERWINTER NIGHTS E
   [Anonymous], P INT C MAK SENS CON
   [Anonymous], 2013, P 8 INT C FDN DIG GA
   [Anonymous], C P FDN DIG GAM CHAI
   [Anonymous], MINIGUIDES SERIES RO
   [Anonymous], SPACE INVADERS VERA
   [Anonymous], P 26 ANN SIGCHI C HU
   [Anonymous], 2000, BOREDOM ANXIETY
   [Anonymous], P 2008 C FUT PLAY RE
   [Anonymous], GAM VIRT WORLDS SER
   [Anonymous], AAAI C ART INT INT D
   [Anonymous], GAMES MEDIA ENTERTAI
   [Anonymous], IEEE T COMPUTATIONAL
   [Anonymous], P 8 INT C FDN DIG GA
   [Anonymous], 2010, P 14 INT AC MINDTREK, DOI DOI 10.1145/1930488.1930518
   [Anonymous], AAAI C ART INT INT D
   [Anonymous], GAMES MEDIA ENTERTAI
   [Anonymous], 2009, THESIS BLEKINGE I TE
   [Anonymous], P INT C MAK SENS CON
   [Anonymous], 2013, FDG
   [Anonymous], P 1 INT WORKSH INT U
   [Anonymous], 2015, 7 INT C GAM VIRT WOR, DOI DOI 10.1109/VSGAMES.2015.7295766
   [Anonymous], 2003, GAME TAXONOMIES HIGH
   [Anonymous], 2005 INT C CHANG VIE
   Ardito C, 2007, VL/HCC 2007: IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P81, DOI 10.1109/VLHCC.2007.54
   Baldwin A, 2013, INT IEEE CONSUM ELEC, P16, DOI 10.1109/IGIC.2013.6659150
   Bayliss J., 2008, Proceedings of the 3rd international conference on Game development in computer science education, P6
   Bergervoet EJ, 2013, VISUAL COMPUT, V29, P99, DOI 10.1007/s00371-012-0720-1
   Broin D. O., 2011, Proceedings of the 2011 3rd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2011), P63, DOI 10.1109/VS-GAMES.2011.15
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Burke JW, 2009, VISUAL COMPUT, V25, P1085, DOI 10.1007/s00371-009-0387-4
   Calleja Gordon., 2011, In-Game: From Immersion to Incorporation
   Carter Marcus., 2014, Proceedings of CHIPlay '14, P27
   Chalmers A, 2009, VISUAL COMPUT, V25, P1101, DOI 10.1007/s00371-009-0389-2
   Chen J, 2007, COMMUN ACM, V50, P31, DOI 10.1145/1232743.1232769
   Cheung GiffordK., 2014, P 1 ACM SIGCHI ANN S, P57, DOI DOI 10.1145/2658537.2658540
   Choo A., 2014, GAMES MEDIA ENTERTAI, P1
   Coulton Paul., 2011, Proceedings of the 15th International Academic Mindtrek Conference: Envisioning Future Media Environments, P37, DOI DOI 10.1145/2181037.2181045
   Craveirinha R., 2010, P 3 INT C FUN GAMES, P8, DOI DOI 10.1145/1823818.1823819
   CSIKSZENTMIHALYI M, 1982, BEHAV BRAIN SCI, V5, P160, DOI 10.1017/S0140525X00010980
   Dollard J., 1993, Frustration and aggression
   FISHER CD, 1993, HUM RELAT, V46, P395, DOI 10.1177/001872679304600305
   Frasca G., 2003, VIDEO GAME THEORY RE, P221
   Gee JamesPaul., 2008, The Ecology of Games: Connecting Youth, Games, and Learning
   Groenegress C, 2010, VISUAL COMPUT, V26, P649, DOI 10.1007/s00371-010-0471-9
   Horsfall M., 2011, Proceedings of the 2011 16th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES 2011), P63, DOI 10.1109/CGAMES.2011.6000361
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Juul J., 2010, Proceedings of the Fifth International Conference on the Foundations of Digital Games. FDG'10, P86, DOI DOI 10.1145/1822348.1822360
   Kang KK, 2009, VISUAL COMPUT, V25, P1073, DOI 10.1007/s00371-009-0385-6
   Lewis Chris, 2010, Proceedings of the 5th International Conference on the Foundations of Digital Games FDG, P108
   Lotte F., 2011, Proceedings of the 6th International Conference on Foundations of Digital Games, FDG'11, P325, DOI DOI 10.1145/2159365.2159427
   Machado M. C., 2011, Proceedings of the 2011 16th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES 2011), P50, DOI 10.1109/CGAMES.2011.6000359
   Mandryk R. L., 2004, Computer Supported Cooperative Work Conference Proceedings, P102, DOI 10.1145/1031607.1031625
   McGill M., 2008, Proceedings of the 2008 Conference on Future Play, P89
   Milam D., 2010, P 5 INT C FDN DIGITA, P139
   Moura Dinara, 2011, P 2011 ACM SIGGRAPH, P1, DOI DOI 10.1145/2018556.2018559
   MYERS D, 1990, PLAY CULTURE, V3, P286
   Nacke LE, 2011, SIMULAT GAMING, V42, P632, DOI 10.1177/1046878110378140
   Nakamura J., 2002, Handbook of Positive Psychology, DOI DOI 10.1007/978-94-017-9088-8_16
   Noah J.A., 2011, Proceedings of the 6th International Conference on Foundations of Digital Games - FDG'11, P280, DOI [10.1145/2159365.2159412, DOI 10.1145/2159365.2159412]
   Obbink M., 2012, P 4 INT ICST C INT T, V78, P183, DOI DOI 10.1007/978-3-642-30214-520
   Paavilainen J., 2010, P INT ACAD C FUTURE, P56, DOI DOI 10.1145/1920778.1920787
   Park JY, 2010, VISUAL COMPUT, V26, P595, DOI 10.1007/s00371-010-0482-6
   Picard R.W., 1995, Tech. Rep. 321
   Pinelle D., 2008, ACM FUT PLAY 2008 IN, P129, DOI [10.1145/1496984.1497006, DOI 10.1145/1496984.1497006]
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Potanin R., 2009, P 3 INT C FUN GAMES, P135, DOI DOI 10.1145/1823818.1823833
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Snowdon J., 2011, Proceedings of the 2011 16th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES 2011), P101, DOI 10.1109/CGAMES.2011.6000323
   Tatum William O, 2014, Neurodiagn J, V54, P3
   Tychsen A., 2008, Proceedings of the 2008 Conference on Future Play: Research, Play, Share, P57, DOI DOI 10.1145/1496984.1496995
   Vachiratamporn V, 2014, IEEE CONF COMPU INTE
   Vanhatupa J.M., 2011, Proceedings of the 6th International Conference on Foundations of Digital Games, P46
   Vourvopoulos A., 2011, Proceedings of the 2011 3rd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2011), P140, DOI 10.1109/VS-GAMES.2011.27
   Wilcox-Netepczuk Daniel, 2013, 2013 18th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES), P92, DOI 10.1109/CGames.2013.6632613
   Zagal J P., 2009, Proceedings of the 4th International Conference on Foundations of Digital Games, P215, DOI DOI 10.1145/1536513.1536553
   Zagalo N, 2008, VISUAL COMPUT, V24, P981, DOI 10.1007/s00371-008-0272-6
NR 85
TC 17
Z9 18
U1 5
U2 44
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2017
VL 33
IS 4
BP 413
EP 427
DI 10.1007/s00371-016-1320-2
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA ER4JZ
UT WOS:000398767100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wong, SK
   Chang, TC
   Ho, TC
   Chuang, JH
AF Wong, Sai-Keung
   Chang, Tse-Ching
   Ho, Tan-Chi
   Chuang, Jung-Hong
TI Fire synthesis using basis fires and design
SO VISUAL COMPUTER
LA English
DT Article
DE Fire synthesis; Design; Animation
ID ANIMATION
AB In this paper, we present an approach to use basis fires to design and synthesize fires in desired shapes and motions. In the preprocessing stage, each basis fire is simulated based on a physics-based fire simulator with a specific simulation configuration. The pathlines and temperatures of the basis fires are stored in a database. In the fire design stage, a user inputs a sequence of curves which represent the desired shapes of fires. In the fire synthesis stage, we use a least-square fitting method to fit the curves using the pathlines and temperatures of the basis fires. In the fire animation stage, we adopt a modified motion graph for animating the synthesized fires. We have applied our approach to synthesize fires with different shapes and motions. Experimental results show that our approach is easy to use and it can produce fires with desired shapes in an intuitive manner. The synthesized fire can be animated at real-time rates.
C1 [Wong, Sai-Keung; Chang, Tse-Ching; Ho, Tan-Chi; Chuang, Jung-Hong] Natl Chiao Tung Univ, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Hsinchu, Taiwan.
EM cswingo@cs.nctu.edu.tw
FU Ministry of Science and Technology of ROC (Taiwan) [MOST
   103-2221-E-009-127, MOST 103-2221-E-009-122-MY3]
FX We would like to thank the anonymous reviewers for their invaluable
   comments. This work was supported in part by Ministry of Science and
   Technology of ROC (Taiwan) grants under MOST 103-2221-E-009-127 and MOST
   103-2221-E-009-122-MY3.
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Dobashi Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360693
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Goswami P., 2010, P 2010 ACM SIGGRAPHE, P55
   Harris M.J., 2003, Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware, Eurographics Association, P92
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Hong Y, 2010, VISUAL COMPUT, V26, P1217, DOI 10.1007/s00371-009-0403-8
   Huang Ruoguan., 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'11, P177, DOI DOI 10.1145/2019406.2019430
   Kim Y., 2006, P 2006 ACM SIGGRAPHE, P33
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lever J, 2012, VISUAL COMPUT, V28, P691, DOI 10.1007/s00371-012-0684-1
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Sato S., 2012, Proceedings of the digital production symposium, P37
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Thürey N, 2009, GRAPH MODELS, V71, P221, DOI 10.1016/j.gmod.2008.12.007
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Treuille A, 2006, ACM T GRAPHIC, V25, P826, DOI 10.1145/1141911.1141962
   Wong S.-K., 2014, PACIFIC GRAPHICS SHO
   Yi Zhang, 2011, 2011 IEEE Electrical Power & Energy Conference (EPEC), P187, DOI 10.1109/EPEC.2011.6070193
   Yuan Z, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024170
   Zhang L, 2007, COMPUT ANIMAT VIRT W, V18, P371, DOI 10.1002/cav.205
   Zhang Y, 2013, J MATER CHEM B, V1, P132, DOI 10.1039/c2tb00071g
NR 26
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2017
VL 33
IS 3
BP 343
EP 354
DI 10.1007/s00371-015-1204-x
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EL1KM
UT WOS:000394379300008
DA 2024-07-18
ER

PT J
AU Lazunin, V
   Savchenko, V
AF Lazunin, Vladimir
   Savchenko, Vladimir
TI Interactive visualization of multi-layered clothing
SO VISUAL COMPUTER
LA English
DT Article
DE Garment rendering; Ray tracing; Surface deformation
ID COLLISION
AB We present a non-iterative approach to visually plausible rendering of multi-layered clothes, aimed mainly at human figures dressed in multiple garments. The problems we address are cloth interference and z-fighting. Our approach is based on numbering layers of clothing and then using recursive ray tracing to keep them in order. Instead of developing a new physically based technique, such as collision detection/response schemes or particle systems, we develop a visualization technique to complement existing physically based methods, greatly reducing the required precision and, thus, the computational cost.
C1 [Lazunin, Vladimir; Savchenko, Vladimir] Hosei Univ, 3-7-2 Kajino Cho, Koganei, Tokyo 1848584, Japan.
C3 Hosei University
RP Lazunin, V (corresponding author), Hosei Univ, 3-7-2 Kajino Cho, Koganei, Tokyo 1848584, Japan.
EM lazunin@gmail.com; vsavchen@k.hosei.ac.jp
CR [Anonymous], 2010, ACM T GRAPHICS TOG, DOI DOI 10.1145/1778765.1778843
   Garanzha K., 2011, P ACM SIGGRAPH S HIG, P59, DOI DOI 10.1145/2018323.2018333
   Guan Peng, 2012, P 11 ACM SIGGRAPHEUR, P295
   Hermann E, 2008, GRAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P293
   Karras Tero., 2013, Proceedings of the 5th High-Performance Graphics Conference, P89, DOI DOI 10.1145/2492045.2492055
   Kavan L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964988
   Knott D, 2003, PROC GRAPH INTERF, P73
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P506, DOI 10.1007/s00371-005-0347-6
   Rodriguez-Navarro J., 2005, 26 ANN C EUR ASS COM, P85
   Shinya M., 1991, J VISUAL COMP ANIMAT, V2, P132
   Umetani N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964985
   Vassilev T, 2001, COMPUT GRAPH FORUM, V20, pC260, DOI 10.1111/1467-8659.00518
   Vassilev TI, 2012, WSCG'2012, CONFERENCE PROCEEDINGS, PTS I & II, P19
   Vassilev TI, 2012, INT J INF TECHNOL SE, V4, P3
   Volino P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P137, DOI 10.1145/218380.218432
   Volino P, 2006, ACM T GRAPHIC, V25, P1154, DOI 10.1145/1141911.1142007
   Yasseen Z, 2013, COMPUT AIDED DESIGN, V45, P562, DOI 10.1016/j.cad.2012.10.041
NR 17
TC 1
Z9 2
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2017
VL 33
IS 1
BP 75
EP 84
DI 10.1007/s00371-015-1153-4
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI2JM
UT WOS:000392313200008
DA 2024-07-18
ER

PT J
AU Jeon, J
   Jung, Y
   Kim, H
   Lee, S
AF Jeon, Junho
   Jung, Yeongyu
   Kim, Haejoon
   Lee, Seungyong
TI Texture map generation for 3D reconstructed scenes
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 33rd Conference on Computer Graphics International (CGI)
CY JUN 28-JUL 01, 2016
CL Heraklion, GREECE
SP Fdn Res Technol
DE 3D reconstruction; Texture mapping; RGB-D images; Photometric
   consistency optimization
AB We present a novel method for generating texture maps for 3D geometric models reconstructed using consumer RGB-D sensors. Our method generates a texture map for a simplified 3D mesh of the reconstructed scene using spatially and temporally sub-sampled key frames of the input RGB stream. We acquire an accurate texture map by optimizing the texture coordinates of the 3D model to maximize the photometric consistency among multiple key frames. We show that the optimization can be performed efficiently using GPU by exploiting the locality of texture coordinate manipulation. Experimental results demonstrate that our method can generate a texture map in a few tens of seconds for a large 3D model, such as a whole room.
C1 [Jeon, Junho; Jung, Yeongyu; Kim, Haejoon; Lee, Seungyong] POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Lee, S (corresponding author), POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.
EM leesy@postech.ac.kr
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   [Anonymous], MITCSAILTR2012031
   Cignoni P, 2008, ERCIM NEWS, V73, P6
   Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626
   Crete-Roffet F., 2007, SPIE EL IM S C HUM V, V12
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Nikulin M., 1994, ENCY MATH
   Roth H, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.112
   Smith J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766947
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919
   Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134
NR 16
TC 22
Z9 25
U1 1
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2016
VL 32
IS 6-8
BP 955
EP 965
DI 10.1007/s00371-016-1249-5
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DP8ET
UT WOS:000378731600027
DA 2024-07-18
ER

PT J
AU Kim, Y
   Seo, W
   Kim, Y
   Lim, Y
   Nah, JH
   Ihm, I
AF Kim, Youngwook
   Seo, Woong
   Kim, Yongho
   Lim, Yeongkyu
   Nah, Jae-Ho
   Ihm, Insung
TI Adaptive undersampling for efficient mobile ray tracing
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 33rd Conference on Computer Graphics International (CGI)
CY JUN 28-JUL 01, 2016
CL Heraklion, GREECE
SP Fdn Res Technol
DE Ray tracing; Mobile platform; Adaptive undersampling; Postcorrection;
   GPU algorithm
AB Aiming to develop an efficient ray tracer for a mobile platform, we present an adaptive undersampling method that enhances the rendering speed by effectively replacing expensive ray-tracing operations with cheap interpolation whenever possible. Our method explores both object- and image-space information gathered during ray tracing to detect possibly problematic pixels. Rays are fired only for these pixels. We also present a postcorrection algorithm that minimizes annoying artifacts inevitably caused by undersampling. Our implementation on a mobile GPU demonstrates that this method can speed up the rendering computation significantly, while retaining almost the same visual quality of the rendering.
C1 [Kim, Youngwook; Seo, Woong; Ihm, Insung] Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Kim, Yongho] NCSOFT, Songnam, South Korea.
   [Lim, Yeongkyu; Nah, Jae-Ho] LG Elect, Seoul, South Korea.
C3 Sogang University; LG Electronics
RP Ihm, I (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM ihm@sogang.ac.kr
OI Nah, Jae-Ho/0000-0001-7805-5333
CR Akimoto T., 1991, Systems and Computers in Japan, V22, P57, DOI 10.1002/scj.4690220406
   [Anonymous], 1987, P 14 ANN C COMP GRAP, DOI [DOI 10.1145/37401.37410, DOI 10.1145/37402.37410]
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   Dippe M. A. Z., 1985, Computer Graphics, V19, P69, DOI 10.1145/325165.325182
   Formella A., 1994, Proceedings of Computer Animation '94, P184, DOI 10.1109/CA.1994.323992
   Genetti J, 1998, COMPUT GRAPH FORUM, V17, P29, DOI 10.1111/1467-8659.00214
   Hachisuka T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360632
   He Y., 2014, ACM T GRAPHIC, V33
   Jin B., 2009, P C HIGH PERFORMANCE, P117
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Lee M. E., 1985, Computer Graphics, V19, P61, DOI 10.1145/325165.325179
   Levoy M., 1990, Visual Computer, V6, P2, DOI 10.1007/BF01902624
   Murakami K., 1990, Eurographics Workshop on Photosimulation, Realism and Physics in Computer Graphics. Conference Proceedings, P15
   Ohta M., 1990, Visual Computer, V6, P125, DOI 10.1007/BF01911004
   Painter J., 1989, Computer Graphics, V23, P281, DOI 10.1145/74334.74362
   Rigau J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P260
   Sengupta S., 2011, SCI COMPUTING MULTIC, P413, DOI [DOI 10.1201/B10376, 10.1201/b10376, DOI 10.1201/B10376-29]
   Thomas D., 1989, Computer Graphics Forum, V8, P325, DOI 10.1111/j.1467-8659.1989.tb00514.x
   Vaidyanathan K., 2014, P HIGH PERF GRAPH, P9, DOI DOI 10.2312/HPG.20141089
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
NR 20
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2016
VL 32
IS 6-8
BP 801
EP 811
DI 10.1007/s00371-016-1251-y
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DP8ET
UT WOS:000378731600013
DA 2024-07-18
ER

PT J
AU Ling, ZG
   Li, ST
   Wang, YN
   Shen, H
   Lu, X
AF Ling, Zhigang
   Li, Shutao
   Wang, Yaonan
   Shen, He
   Lu, Xiao
TI Adaptive transmission compensation via human visual system for efficient
   single image dehazing
SO VISUAL COMPUTER
LA English
DT Article
DE Single image dehazing; Human visual system; Just-noticeable distortion;
   Dark channel prior
ID ENHANCEMENT; VISIBILITY; VISION
AB Dark channel prior has been used widely in single image haze removal because of its simple implementation and satisfactory performance. However, it often results in halo artifacts, noise amplification, over-darking, and/or over-saturation for some images containing heavy fog or large sky patches where dark channel prior is not established. To resolve this issue, this paper proposes an efficient single dehazing algorithm via adaptive transmission compensation based on human visual system (HVS). The key contributions of this paper are made as follows: firstly, two boundary constraints on transmission are deduced to preserve the intensity of the defogged image and suppress halo artifacts or noise via the minimum intensity constraint and the just-noticeable distortion model, respectively. Secondly, an improved HVS segmentation algorithm is employed to detect the saturation areas in the input image. Finally, an adaptive transmission compensation strategy is presented to remove the haze and simultaneously suppress the halo artifacts or noise in the saturation areas. Experimental results indicate that this proposed method can efficiently improve the visibility of the foggy images in the challenging condition.
C1 [Ling, Zhigang; Li, Shutao; Wang, Yaonan; Lu, Xiao] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
   [Shen, He] Univ Cent Florida, Dept Mech & Aerosp Engn, Orlando, FL 32817 USA.
C3 Hunan University; State University System of Florida; University of
   Central Florida
RP Ling, ZG (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
EM zgling_hunan@126.com; shutao_li@hnu.edu.cn; yaonan@hnu.edu.cn;
   shenhe@knights.ucf.edu; xlu_hnu@163.com
RI Li, Shutao/Y-3102-2019; lu, xiao/AAS-2542-2020; Shen, He/AGR-4428-2022
OI Li, Shutao/0000-0002-0585-9848; Shen, He/0000-0001-7282-316X
FU National High Technology Research and Development Program of China (863
   Program) [2012AA112312]; National Natural Science Foundation of China
   [61471166, 61175075]; Science and Technique Project of Ministry of
   Transport of the People's Republic of China [201231849A70]; Hunan
   Provincial Natural Science Foundation of China [14JJ2052]
FX This work was supported by the National High Technology Research and
   Development Program of China (863 Program, Grant No. 2012AA112312),
   National Natural Science Foundation of China (Grant No. 61471166 and
   61175075), the Science and Technique Project of Ministry of Transport of
   the People's Republic of China (Grant No. 201231849A70) and Hunan
   Provincial Natural Science Foundation of China (14JJ2052).
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], PHYSICAE FREIBERGER
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Lee CH, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033007
   Li WJ, 2012, IET IMAGE PROCESS, V6, P589, DOI 10.1049/iet-ipr.2010.0574
   McCartney E.J., 1976, OPTICS ATMOSPHERE
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Panetta KA, 2008, IEEE T SYST MAN CY B, V38, P174, DOI 10.1109/TSMCB.2007.909440
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Sun W., 2013, OPT ENG, V52
   Tan R.T., 2008, IEEE INT C COMP VIS, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IET IMAGE PROCESS, V6, P966, DOI 10.1049/iet-ipr.2011.0472
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xie B, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.101703
   Yan Q., 2013, SIGGRAPH ASIA 2013 T
   Yan Wang, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P789, DOI 10.1109/ICICISYS.2010.5658614
   Yoon I, 2012, IEEE T CONSUM ELECTR, V58, P111, DOI 10.1109/TCE.2012.6170062
   Zhang JW, 2011, VISUAL COMPUT, V27, P749, DOI 10.1007/s00371-011-0569-8
NR 27
TC 6
Z9 9
U1 0
U2 35
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2016
VL 32
IS 5
BP 653
EP 662
DI 10.1007/s00371-015-1081-3
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DK5UI
UT WOS:000374985800010
DA 2024-07-18
ER

PT J
AU Zhao, SH
   Ooi, WT
AF Zhao, Shanghong
   Ooi, Wei Tsang
TI Modeling 3D synthetic view dissimilarity
SO VISUAL COMPUTER
LA English
DT Article
DE View dissimilarity; View similarity; Viewpoint selection; Perceptual
   cost
ID MENTAL ROTATION; HEURISTICS
AB We model the dissimilarity among 3D synthetic views and measure the novelty of a view by its dissimilarity to other view(s). Two views are dissimilar if they have different viewing content or viewing orientations. The model evaluates the perceptual cost of mentally reconstructing one view from other view(s). Higher perceptual cost means more dissimilarity. Perceptual cost is related to reaction time of rotation and completion of human mental images. Visual comparisons among dissimilarity measures suggest that our model can better determine how dissimilar one view is to other view(s).
C1 [Zhao, Shanghong; Ooi, Wei Tsang] Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
C3 National University of Singapore
RP Zhao, SH (corresponding author), Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
EM shzhao17@comp.nus.edu.sg; ooiwt@comp.nus.edu.sg
RI Ooi, Wei Tsang/AAE-7810-2019; Ooi, Wei Tsang/HLW-5142-2023
OI Ooi, Wei Tsang/0000-0001-8994-1736; Ooi, Wei Tsang/0000-0001-8994-1736
CR [Anonymous], 2010, ACM SIGGRAPH 2010 papers
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2019, The stanford encyclopedia of philosophy
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Chen XB, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185525
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Cheung OS, 2009, COGNITION, V113, P128, DOI 10.1016/j.cognition.2009.07.008
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   Glover F, 2001, EUR J OPER RES, V129, P555, DOI 10.1016/S0377-2217(99)00468-3
   Hlavac V., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P526, DOI 10.1007/BFb0015563
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   McMillan L, 1997, IMAGE BASED APPROACH
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Ponto K, 2012, IEEE T VIS COMPUT GR, V18, P607, DOI 10.1109/TVCG.2012.41
   Rosenkrantz D. H., 1977, SIAM Journal on Computing, V6, P563, DOI 10.1137/0206041
   Shepard R.N., 1982, MENTAL IMAGES THEIR
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Shore DI, 1997, J EXP PSYCHOL HUMAN, V23, P980
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Viola I, 2006, IEEE T VIS COMPUT GR, V12, P933, DOI 10.1109/TVCG.2006.152
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuksel C, 2011, COMPUT AIDED DESIGN, V43, P747, DOI 10.1016/j.cad.2010.08.008
   Zhao S., 2013, P 4 ACM MULT SYST C, P178
   Zhao SH, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2537854
   Zhu Minhui, 2011, P 19 ACM INT C MULT, P183, DOI DOI 10.1145/2072298.2072324
NR 29
TC 2
Z9 4
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2016
VL 32
IS 4
BP 429
EP 443
DI 10.1007/s00371-015-1069-z
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA DI6YD
UT WOS:000373645200003
DA 2024-07-18
ER

PT J
AU Bailey, SW
   Echevarria, JI
   Bodenheimer, B
   Gutierrez, D
AF Bailey, Stephen W.
   Echevarria, Jose I.
   Bodenheimer, Bobby
   Gutierrez, Diego
TI Fast depth from defocus from focal stacks
SO VISUAL COMPUTER
LA English
DT Article
DE Depth from defocus; Shape from defocus
ID SHAPE; FOCUS
AB We present a new depth from defocus method based on the assumption that a per pixel blur estimate (related with the circle of confusion), while ambiguous for a single image, behaves in a consistent way when applied over a focal stack of two or more images. This allows us to fit a simple analytical description of the circle of confusion to the different per pixel measures to obtain approximate depth values up to a scale. Our results are comparable to previous work while offering a faster and flexible pipeline.
C1 [Bailey, Stephen W.] Univ Calif Berkeley, Visual Comp Lab, Berkeley, CA 94720 USA.
   [Echevarria, Jose I.; Gutierrez, Diego] Univ Zaragoza, Graph & Imaging Lab, Zaragoza, Spain.
   [Bodenheimer, Bobby] Vanderbilt Univ, Nashville, TN 37235 USA.
C3 University of California System; University of California Berkeley;
   University of Zaragoza; Vanderbilt University
RP Echevarria, JI (corresponding author), Univ Zaragoza, Zaragoza, Spain.
EM stephen.w.bailey@berkeley.edu; jiecheva@unizar.es;
   bobby.bodenheimer@vanderbilt.edu; diegog@unizar.es
OI Gutierrez Perez, Diego/0000-0002-7503-7022
FU European Union [251415, 288914]; Gobierno de Aragon through the TAMA
   project; National Science Foundation [0705863, 1116988]; Direct For
   Computer & Info Scie & Enginr; Div Of Information & Intelligent Systems
   [1116988] Funding Source: National Science Foundation; Div Of
   Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [0705863] Funding Source: National Science Foundation
FX The authors thank T. S. Choi and Paolo Favaro for sharing their data
   sets. This work has been supported by the European Union through the
   projects GOLEM (grant agreement no.: 251415) and VERVE (grant agreement
   no.: 288914), as well as by the Gobierno de Aragon through the TAMA
   project. This material is based upon work supported by the National
   Science Foundation under Grant Nos. 0705863 and 1116988.
CR [Anonymous], 2009, 2009 IEEE INT C COMP
   [Anonymous], ADDISON WESLEY WORLD
   [Anonymous], IM SYST TECHN IST 20
   [Anonymous], IEEE WORKSH APPL COM
   [Anonymous], ACM SIGGRAPH 2007 PA
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Bauszat P, 2011, COMPUT GRAPH FORUM, V30, P1361, DOI 10.1111/j.1467-8659.2011.01996.x
   Calderero F, 2013, INT J COMPUT VISION, V104, P38, DOI 10.1007/s11263-013-0613-4
   Cao Y, 2013, IEEE T IMAGE PROCESS, V22, P3703, DOI 10.1109/TIP.2013.2270086
   Favaro P., 2006, 3 D SHAPE ESTIMATION
   Favaro P, 2008, IEEE T PATTERN ANAL, V30, P518, DOI 10.1109/TPAMI.2007.1175
   Favaro P, 2010, PROC CVPR IEEE, P1133, DOI 10.1109/CVPR.2010.5540089
   Flannery B. P., 1992, NUMERICAL RECIPES C, DOI DOI 10.2277/052143064X
   Hasinoff S, 2009, INT J COMPUT VISION, V81, P82, DOI 10.1007/s11263-008-0164-2
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hu H, 2007, LECT NOTES COMPUT SC, V4678, P461
   Knutsson H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P515, DOI 10.1109/CVPR.1993.341081
   Lee IH, 2013, OPT LASER ENG, V51, P520, DOI 10.1016/j.optlaseng.2012.11.003
   Levin A., 2007, ACM T GRAPH SIGGRAPH
   Li C, 2013, PROC CVPR IEEE, P217, DOI 10.1109/CVPR.2013.35
   Lin X, 2013, IEEE INT CONF COMPUT
   Mahmood MT, 2012, IEEE T IMAGE PROCESS, V21, P2866, DOI 10.1109/TIP.2012.2186144
   Namboodiri V., 2008, COMPUTER VISION PATT, P1
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Shim SO, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P321, DOI 10.1109/ICCE.2012.6161887
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438
   Yang Cao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P168, DOI 10.1109/ICIG.2011.35
   Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
   Zhuo SJ, 2009, LECT NOTES COMPUT SC, V5702, P889, DOI 10.1007/978-3-642-03767-2_108
NR 34
TC 12
Z9 17
U1 0
U2 26
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2015
VL 31
IS 12
BP 1697
EP 1708
DI 10.1007/s00371-014-1050-2
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CV2ZD
UT WOS:000364126900009
DA 2024-07-18
ER

PT J
AU Wang, XP
   Zhang, WZ
   Huang, X
AF Wang, Xiaoping
   Zhang, Weizhong
   Huang, Xiang
TI Computation of point inversion and ray-surface intersection through
   tracing along the base surface
SO VISUAL COMPUTER
LA English
DT Article
DE Point inversion; Central projection; Parallel projection; Orthogonal
   projection; Ray-surface intersection; Newton iteration
ID ORTHOGONAL PROJECTION; CURVES; DESIGN; FORM
AB This paper addresses new methods to solve point inversion problem for parametric surface. As a by-product a new method for ray-surface intersection is also developed. After further analysis, we reduce finding the corresponding parameters of a given point on a surface to the following steps: (1) construct a line segment with the given point as its one end and an arbitrarily selected point on the surface as its other end point, (2) project the line segment onto the surface orthogonally or along a vector or through a central point, or compute the intersection curve segment of a specially created plane and the surface, (3) trace the parameters along the projected curve or intersection curve with the linear convergence or the second-order convergence. As a matter of fact, we formulate some related systems of first-order or second-order ordinary differential equations met by the corresponding projection curve segment of the line segment or by the intersection curve segment. Using the parameters of the selected point as initial values, we trace the desired parameter on surface along the line segment from its one end to another or along the intersection curve segment. In this method, there is no need to consider the sensitivity to the choice of starting points, iteration convergence and so on, which several existing methods must face. The method is simpler than existing methods for it merely concerns first-order information of the surface, if we only ask for linear convergence, and has better error control mechanism, if we seek for second-order convergence. Implementation examples are also given to demonstrate its validity.
C1 [Wang, Xiaoping; Huang, Xiang] Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Jiangsu, Peoples R China.
   [Zhang, Weizhong] Qingdao Univ, Coll Informat Engn, Qingdao 266071, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Qingdao University
RP Wang, XP (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Jiangsu, Peoples R China.
EM levine@nuaa.edu.cn; zhangwz_01@aliyun.com; xhuang@nuaa.edu.cn
RI Wang, Xiao-Ping/G-7394-2011
FU National Natural Science Foundation of China [51075206]; China
   Scholarship Council Foundation [201406835014]
FX The authors are deeply thankful to the anonymous referees for their
   valuable comments and suggestions. The work reported in this paper was
   supported by National Natural Science Foundation of China under grant
   No. 51075206 and by China Scholarship Council Foundation under grant No.
   201406835014 during the first author's visit to ASU.
CR Abert O., 2006, P 2006 IEEE S INT RA
   [Anonymous], 1996, Springer Series in Computational Mathematics
   Dixon AL, 1908, P LOND MATH SOC, V6, P468
   Farin G., 2002, HDB COMPUTER AIDED G
   Hairer E., 2008, Solving ordinary differential equations. I: Nonstiff problems, V2nd
   Hairer E., 2002, GEOMETRIC NUMERICAL
   Hartmann E, 1999, COMPUT AIDED GEOM D, V16, P355, DOI 10.1016/S0167-8396(99)00003-5
   HOFFMANN CM, 1993, IEEE COMPUT GRAPH, V13, P79, DOI 10.1109/38.180121
   Hoschek J., 1993, FUNDAMENTALS COMPUTE
   Hu SM, 2005, COMPUT AIDED GEOM D, V22, P251, DOI 10.1016/j.cagd.2004.12.001
   Hughes J. F., 1999, Journal of Graphics Tools, V4, P33, DOI 10.1080/10867651.1999.10487513
   Kajiya J. T., 1982, Computer Graphics, V16, P245, DOI 10.1145/965145.801287
   Liu XM, 2009, COMPUT AIDED GEOM D, V26, P593, DOI 10.1016/j.cagd.2009.01.004
   Ma YL, 2003, COMPUT AIDED GEOM D, V20, P79, DOI 10.1016/S0167-8396(03)00021-9
   *MATH WORKS INC, 2000, US MATLAB VERS 6
   Park T, 2013, COMPUT AIDED GEOM D, V30, P795, DOI 10.1016/j.cagd.2013.07.001
   Pegna J, 1996, J MECH DESIGN, V118, P45, DOI 10.1115/1.2826855
   Petcu D., 2001, LECT NOTES COMPUTER, V1988, P341
   Piegl LA, 2001, COMPUT AIDED DESIGN, V33, P593, DOI 10.1016/S0010-4485(00)00103-2
   Press W. H., 1999, NUMERICAL RECIPES C
   Qin KH, 1997, COMPUT GRAPH-UK, V21, P577, DOI 10.1016/S0097-8493(97)87263-9
   SEDERBERG TW, 1986, IEEE COMPUT GRAPH, V6, P52, DOI 10.1109/MCG.1986.276742
   SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3
   Singh JM, 2010, IEEE T VIS COMPUT GR, V16, P261, DOI 10.1109/TVCG.2009.41
   Toth D. L., 1985, Computer Graphics, V19, P171, DOI 10.1145/325165.325233
   Wang SW, 2002, J INF SCI ENG, V18, P541
   Xu JT, 2009, FRONT COMPUT SCI CHI, V3, P472, DOI 10.1007/s11704-009-0034-2
NR 27
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD NOV
PY 2015
VL 31
IS 11
BP 1487
EP 1500
DI 10.1007/s00371-014-1028-0
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CT3BJ
UT WOS:000362680600005
DA 2024-07-18
ER

PT J
AU Dearden, J
   Jones, MW
   Wilson, A
AF Dearden, J.
   Jones, M. W.
   Wilson, A.
TI DynaMoVis: visualization of dynamic models for urban modeling
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 32nd Computer Graphics International CGI 15 Conference
CY JUN 24-26, 2015
CL INSA Strasbourg Univ Strasbourg, Strasbourg, FRANCE
SP CNRS, iCUBE, Univ Strasbourg, CGS, Springer, Acm Incooperation, IGG, ACMSIGGRAPH, KIST Europe, Region Alsace, Visteon
HO INSA Strasbourg Univ Strasbourg
DE Dynamic models; Urban modeling; Visualization
ID VISUAL ANALYSIS; BIFURCATIONS; EXPLORATION; UNCERTAINTY
AB In association with Urban modelers, we have created DynaMoVis, a system for the visualization of dynamic models. The prediction of the evolution of urban and ecological systems is difficult because they are complex nonlinear systems that exhibit self-organization, emergence, and path dependence. Without a good understanding of the dynamics, interventions might have unintended side-effects. This study aims to make progress in the understanding of dynamic models in the application areas of urban modeling. Analyzing these simulations is challenging due to the large amount of data generated and the high-dimensional nature of the system. We present a visualization system for exploring the behavior of a simulation from many different points of view. The system contains a number of different modes which allow exploration of the simulation parameter space, the introduction and effect of noise on the simulation and the basins of attraction in the phase space of the simulation. Through the use of this system, it has been possible to develop a deeper understanding of the inter-dependencies in the models, their parameter spaces, and corresponding phase spaces.
C1 [Dearden, J.; Jones, M. W.] Swansea Univ, Visual Comp Grp, Swansea, W Glam, Wales.
   [Wilson, A.] UCL, Ctr Adv Spatial Anal, London, England.
C3 Swansea University; University of London; University College London
RP Jones, MW (corresponding author), Swansea Univ, Visual Comp Grp, Swansea, W Glam, Wales.
EM M.W.Jones@Swansea.ac.uk
RI ; Jones, Mark W./F-1114-2015
OI Wilson, Alan/0000-0002-7495-6617; Jones, Mark W./0000-0001-8991-1190
CR Berger W, 2011, COMPUT GRAPH FORUM, V30, P911, DOI 10.1111/j.1467-8659.2011.01940.x
   Bergner S, 2013, IEEE T VIS COMPUT GR, V19, P1499, DOI 10.1109/TVCG.2013.61
   Bischi GI, 2001, NONLINEAR ANAL-THEOR, V47, P5325, DOI 10.1016/S0362-546X(01)00638-1
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Boyandin I, 2011, COMPUT GRAPH FORUM, V30, P971, DOI 10.1111/j.1467-8659.2011.01946.x
   Chang R, 2007, IEEE T VIS COMPUT GR, V13, P1169, DOI 10.1109/TVCG.2007.70574
   Dearden J., 2015, EXPLORATIONS URBAN R
   Dykes J, 2007, IEEE T VIS COMPUT GR, V13, P1161, DOI 10.1109/TVCG.2007.70558
   Graham M, 2003, IEEE INFOR VIS, P10, DOI 10.1109/IV.2003.1217950
   Gröller E, 1999, FUTURE GENER COMP SY, V15, P75, DOI 10.1016/S0167-739X(98)00054-5
   Guo DS, 2009, IEEE T VIS COMPUT GR, V15, P1041, DOI 10.1109/TVCG.2009.143
   Heinrich Julian, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P594
   Heinrich J, 2009, IEEE T VIS COMPUT GR, V15, P1531, DOI 10.1109/TVCG.2009.131
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Liu SX, 2014, VISUAL COMPUT, V30, P1373, DOI 10.1007/s00371-013-0892-3
   Matkovic K, 2010, IEEE T VIS COMPUT GR, V16, P1449, DOI 10.1109/TVCG.2010.171
   Orrell D, 2003, INT J BIFURCAT CHAOS, V13, P3015, DOI 10.1142/S0218127403008387
   Pinnel LD, 2000, SPRING COMP SCI, P199
   Pitzer E., 2010, P 2010 UK WORKSH COM, P1, DOI DOI 10.1109/UKCI.2010.5625595
   Pueyo O, 2014, VISUAL COMPUT, V30, P159, DOI 10.1007/s00371-013-0791-7
   Theisel Holger., 2000, P C VISION MODELING, P415
   Torsney-Weir T, 2011, IEEE T VIS COMPUT GR, V17, P1892, DOI 10.1109/TVCG.2011.248
   Turkay C, 2014, IEEE T VIS COMPUT GR, V20, P2033, DOI 10.1109/TVCG.2014.2346265
   Unger A, 2012, IEEE T VIS COMPUT GR, V18, P2216, DOI 10.1109/TVCG.2012.190
   van Wijk J. J., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P119, DOI 10.1109/VISUAL.1993.398859
   Vanegas CA, 2010, COMPUT GRAPH FORUM, V29, P25, DOI 10.1111/j.1467-8659.2009.01535.x
   Vanegas CA, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618457
   Vanegas CA, 2009, IEEE T VIS COMPUT GR, V15, P424, DOI 10.1109/TVCG.2008.193
   Waddell P, 2002, J AM PLANN ASSOC, V68, P297, DOI 10.1080/01944360208976274
   Zhou H, 2008, COMPUT GRAPH FORUM, V27, P1047, DOI 10.1111/j.1467-8659.2008.01241.x
NR 30
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2015
VL 31
IS 6-8
BP 1079
EP 1088
DI 10.1007/s00371-015-1096-9
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CM2CN
UT WOS:000357487500032
DA 2024-07-18
ER

PT J
AU Yatagawa, T
   Yamaguchi, Y
AF Yatagawa, Tatsuya
   Yamaguchi, Yasushi
TI Sparse pixel sampling for appearance edit propagation
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 32nd Computer Graphics International CGI 15 Conference
CY JUN 24-26, 2015
CL INSA Strasbourg Univ Strasbourg, Strasbourg, FRANCE
SP CNRS, iCUBE, Univ Strasbourg, CGS, Springer, Acm Incooperation, IGG, ACMSIGGRAPH, KIST Europe, Region Alsace, Visteon
HO INSA Strasbourg Univ Strasbourg
DE Image and video editing; Interactive editing; Edit propagation;
   Compressive sensing
ID IMAGE; PHOTOGRAPHY; FLASH; TONE
AB Edit propagation is an appearance-editing method using sparsely provided edit strokes from users. Although edit propagation has a wide variety of applications, it is computationally complex, owing to the need to solve large linear systems. To reduce the computational cost, interpolation-based approaches have been studied intensely. This study is inspired by an interpolation-based edit-propagation method that uses a clustering algorithm to determine samples. The method uses an interpolant, which approximates edit parameters with convex combinations of the samples. However, because the clustering algorithm generates samples that lie inside the set of pixels in a feature space, an interpolant with convex combinations does not allow for an exact reconstruction of the pixels outside the convex hull. To address this issue, this paper proposes a novel approximation model for interpolating image colors as well as edit parameters using affine combinations. In addition, this paper introduces sparse pixel sampling to determine the quantity and positions of samples and the weight coefficients of the affine combinations simultaneously. Sparse pixel sampling is performed by updating candidate pixels. Unnecessary pixels are discarded with compressive sensing, and new candidate pixels are greedily resampled following their approximation errors. This paper demonstrates that the proposed model achieves better approximation in terms of both image colors and edit parameters, and discusses the properties of the proposed model with various experiments.
C1 [Yatagawa, Tatsuya] Univ Tokyo, Meguro Ku, 3-8-1 Komaba, Tokyo 1538902, Japan.
   [Yamaguchi, Yasushi] Univ Tokyo, JST CREST, Meguro Ku, Tokyo 1538902, Japan.
C3 University of Tokyo; University of Tokyo
RP Yatagawa, T (corresponding author), Univ Tokyo, Meguro Ku, 3-8-1 Komaba, Tokyo 1538902, Japan.
EM run.boys.run.speedstar@gmail.com; yama@graco.c.u-tokyo.ac.jp
RI Yamaguchi, Yasushi/IZP-8277-2023; Yatagawa, Tatsuya/HKV-3976-2023;
   Yamaguchi, Yasushi/S-5779-2019
OI Yatagawa, Tatsuya/0000-0003-4653-2435; YAMAGUCHI,
   Yasushi/0000-0003-0790-4144
FU Japan Society for the Promotion of Science; Core Research for
   Evolutional Science and Technology of Japan Science and Technology
   Agency; Grants-in-Aid for Scientific Research [24650035, 14J00211]
   Funding Source: KAKEN
FX We would like to thank all anonymous reviewers for their constructive
   comments and suggestions. We also thank flickr users "Martin Abegglen
   (twicepix)," "Bahman Farzad (Bahman Farzad)," "John VanderWaagen
   (jvh33)" and "fluffster (Jeanie)" for the pictures used in the paper.
   This research is supported in part by Research Fellowship for Young
   Scientists of Japan Society for the Promotion of Science and by Core
   Research for Evolutional Science and Technology of Japan Science and
   Technology Agency.
CR An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   [Anonymous], 2015, 324 EIG
   [Anonymous], 2012, ACM T GRAPHIC
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   Bie XH, 2011, COMPUT GRAPH FORUM, V30, P2041, DOI 10.1111/j.1467-8659.2011.02059.x
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   Gastal ESL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185529
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Lang M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185530
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li Y, 2010, COMPUT GRAPH FORUM, V29, P2049, DOI 10.1111/j.1467-8659.2010.01791.x
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Ma LQ, 2014, COMPUT GRAPH-UK, V38, P167, DOI 10.1016/j.cag.2013.10.013
   Ma LQ, 2012, COMPUT GRAPH-UK, V36, P1005, DOI 10.1016/j.cag.2012.08.001
   Musialski P, 2013, VISUAL COMPUT, V29, P1173, DOI 10.1007/s00371-012-0761-5
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Pellacini F., ACM T GRAPH, V26
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tomioka R, 2009, IEEE SIGNAL PROC LET, V16, P1067, DOI 10.1109/LSP.2009.2030111
   Williams CKI, 2001, ADV NEUR IN, V13, P682
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Wu JL, 2012, VISUAL COMPUT, V28, P723, DOI 10.1007/s00371-012-0683-2
   Xiao CX, 2011, IEEE T VIS COMPUT GR, V17, P1135, DOI 10.1109/TVCG.2010.125
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618464
   Xu K, 2009, COMPUT GRAPH FORUM, V28, P1871, DOI 10.1111/j.1467-8659.2009.01565.x
   Xu L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508404
   Yang L., 2011, ACM T GRAPHIC, V30
NR 38
TC 4
Z9 5
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2015
VL 31
IS 6-8
BP 1101
EP 1111
DI 10.1007/s00371-015-1094-y
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CM2CN
UT WOS:000357487500034
DA 2024-07-18
ER

PT J
AU Kim, Y
   Kim, L
   Lee, D
   Shin, S
   Cho, H
   Roy, F
   Park, S
AF Kim, Youngjun
   Kim, Laehyun
   Lee, Deukhee
   Shin, Sangkyun
   Cho, Hyunchul
   Roy, Frederick
   Park, Sehyung
TI Deformable mesh simulation for virtual laparoscopic cholecystectomy
   training
SO VISUAL COMPUTER
LA English
DT Article
DE Medical simulation; Mesh deformation; Mesh carving; Mesh sculpting;
   Cholecystectomy
ID OPERATING-ROOM; PERFORMANCE
AB Virtual simulation of laparoscopic surgery is getting attention for training novice surgeons and medical residents for practice. Virtual surgical simulation has many advantages because it can provide users with a safe environment without animal or patient subjects. Although several solutions are available in the market, there are no reported studies with detailed technical descriptions of the virtual simulation of laparoscopic cholecystectomy (gallbladder removal surgery), one of the major surgeries performed using laparoscopic surgical procedures. Here, we present a realistic laparoscopic cholecystectomy training simulator. The system was developed by applying state-of-the-art computer graphical technologies using an open source library and proposing a new method of deformable mesh carving. The deformable mesh carving is a volume-based method using potential fields and hexahedral finite element method. In this paper, we describe the detailed techniques used to realize the laparoscopic cholecystectomy simulation. The experimental and user study results prove that the presented system simulates the cholecystectomy procedures in real time with high degree of realism and fidelity.
C1 [Kim, Youngjun; Kim, Laehyun; Lee, Deukhee; Shin, Sangkyun; Cho, Hyunchul; Roy, Frederick; Park, Sehyung] Korea Inst Sci & Technol, Seoul 136791, South Korea.
C3 Korea Institute of Science & Technology (KIST)
RP Park, S (corresponding author), Korea Inst Sci & Technol, Hwarangno 14 Gil 5, Seoul 136791, South Korea.
EM junekim@kist.re.kr; laehyunk@kist.re.kr; dkylee@kist.re.kr;
   supersk@kist.re.kr; hccho@kist.re.kr; froy@kist.re.kr;
   sehyung@kist.re.kr
FU KIST Institutional Program [2E24520, 2E24551]
FX This research was supported by the KIST Institutional Program (2E24520,
   2E24551).
CR Aggarwal R, 2007, ANN SURG, V246, P771, DOI 10.1097/SLA.0b013e3180f61b09
   Basdogan C, 2001, IEEE-ASME T MECH, V6, P269, DOI 10.1109/3516.951365
   Bruyns CD, 2002, STUD HEALTH TECHNOL, V85, P74
   Courtecuisse H, 2010, PROG BIOPHYS MOL BIO, V103, P159, DOI 10.1016/j.pbiomolbio.2010.09.016
   Duriez C, 2006, Comput Aided Surg, V11, P300
   Faure F., 2012, ser. Studies in Mechanobiology, Tissue Engineering and Biomaterials, P283
   Gallagher AG, 2005, ANN SURG, V241, P364, DOI 10.1097/01.sla.0000151982.85062.80
   Gauger PG, 2010, AM J SURG, V199, P72, DOI 10.1016/j.amjsurg.2009.07.034
   Georgii J., 2008, VRIPHYS, P11
   Hubert N., 2008, LAB COMPANION SERIES, V3
   Jerábková L, 2010, PROG BIOPHYS MOL BIO, V103, P217, DOI 10.1016/j.pbiomolbio.2010.09.012
   Kim L, 2006, VISUAL COMPUT, V22, P90, DOI 10.1007/s00371-006-0369-8
   Kim Y, 2013, J COMPUT SCI TECH-CH, V28, P499, DOI 10.1007/s11390-013-1351-3
   Labelle F, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239508
   Mauch S., 2013, TECHNICAL REPORT
   NESME M, 2005, RECENT RES DEV BIOME, V2
   Nesme M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531358
   Park JS, 2006, CLIN ANAT, V19, P216, DOI 10.1002/ca.20275
   Pemmod E., 2010, VCBM, V91-98, P2010
   Peterlík I, 2011, IEEE T HAPTICS, V4, P175, DOI [10.1109/TOH.2011.41, 10.1109/ToH.2011.41]
   Schijven MP, 2005, SURG ENDOSC, V19, P1220, DOI 10.1007/s00464-004-2240-1
   SOPER NJ, 1992, ARCH SURG-CHICAGO, V127, P917
   Velho L, 1999, ACM T GRAPHIC, V18, P329, DOI 10.1145/337680.337717
   Yiasemidou M, 2011, OPEN ACCESS SURG, V4, P39, DOI 10.2147/OAS.S25008
   Youngjun Kim, 2012, Mesh Processing in Medical Image Analysis 2012. Proceedings of MICCAI 2012 International Workshop MeshMed 2012, P70, DOI 10.1007/978-3-642-33463-4_8
   Zhang AM, 2008, SURG ENDOSC, V22, P1440, DOI 10.1007/s00464-007-9625-x
NR 26
TC 5
Z9 6
U1 1
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2015
VL 31
IS 4
BP 485
EP 495
DI 10.1007/s00371-014-0944-3
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD2IW
UT WOS:000350901600009
DA 2024-07-18
ER

PT J
AU Liu, W
   Wu, YH
   Guo, FS
   Hu, ZY
AF Liu, Wei
   Wu, Yihong
   Guo, Fusheng
   Hu, Zhanyi
TI An efficient approach for 2D to 3D video conversion based on structure
   from motion
SO VISUAL COMPUTER
LA English
DT Article
DE 2D to 3D conversion; Structure from motion; Depth warping; Depth map
ID STEREOSCOPIC VIDEO; DEPTH; GENERATION; IMAGES
AB With the popularity of 3D films, the conversion of existing 2D videos to 3D videos has attracted a wide interest in 3D content production. In this paper, we present an efficient approach for 2D to 3D video conversion based on structure from motion (SFM). The key contributions include a piece-wise SFM approach and a novel nonlinear depth warping considering the characteristics of stereoscopic 3D. The dense depth maps are generated and further refined with color segmentation. Experiments show that the proposed approach can yield more visually satisfactory results.
C1 [Liu, Wei] Chinese Acad Sci, Inst Microelect, Ctr Internet Things, Beijing 100029, Peoples R China.
   [Liu, Wei; Wu, Yihong; Guo, Fusheng; Hu, Zhanyi] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Microelectronics, CAS; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Liu, W (corresponding author), Chinese Acad Sci, Inst Microelect, Ctr Internet Things, Beijing 100029, Peoples R China.
EM lw3171796@163.com; yhwu@nlpr.ia.ac.cn; fusheng.guo@nlpr.ia.ac.cn;
   huzy@nlpr.ia.ac.cn
FU National Basic Research Program of China (973 Program) [2012CB316302];
   National Natural Science Foundation of China [61070107]
FX This work was supported by the National Basic Research Program of China
   (973 Program) under grant No. 2012CB316302 and the National Natural
   Science Foundation of China under grant No. 61070107.
CR Ahmed MT, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P231
   [Anonymous], 2006, IEEE WORKSHOP CONTEN
   Chenglei Wu, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P65
   Cigla C., 2012, 20 SIGN PROC COMM AP, P1
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Feng Y, 2011, IEEE T BROADCAST, V57, P500, DOI 10.1109/TBC.2011.2131030
   Guo G, 2008, INT CONF ACOUST SPEE, P2181
   Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Jung Y.J., 2009, P SPIE C STER DISPL, V72371U
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Kim C, 2007, ETRI J, V29, P353, DOI 10.4218/etrij.07.0106.0173
   Kim J., 2012, P SPIE C STER DISPL, V752412
   Knorr S., 2007, 3DTV C, P1
   Ko J., 2007, P SPIE C APPL DIG A, V66962A
   Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812
   Liao M, 2012, IEEE T VIS COMPUT GR, V18, P1079, DOI 10.1109/TVCG.2011.114
   Liu TC, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230813
   Nam SW, 2013, IEEE ICCE, P187, DOI 10.1109/ICCE.2013.6486852
   Pollefeys M, 2002, LECT NOTES COMPUT SC, V2351, P837
   Repko J, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P150, DOI 10.1109/3DIM.2005.4
   Rotem E, 2005, PROC SPIE, V5664, P198, DOI 10.1117/12.586599
   Schneidewind L., 2012, 2012 First International Workshop on Usability and Accessibility Focused Requirements Engineering (UsARE), P1, DOI 10.1109/UsARE.2012.6226786
   Tao Li, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P256, DOI 10.1049/cp:20080318
   Tsai YM, 2006, I S INTELL SIG PROC, P541
   Zhang GF, 2007, IEEE T VIS COMPUT GR, V13, P686, DOI 10.1109/TVCG.2007.1032
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zheng F., 2006, J INF TECHNOL, V1, P229
NR 29
TC 9
Z9 12
U1 2
U2 21
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2015
VL 31
IS 1
BP 55
EP 68
DI 10.1007/s00371-013-0904-3
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AY8ZQ
UT WOS:000347839600005
DA 2024-07-18
ER

PT J
AU Aiteanu, F
   Klein, R
AF Aiteanu, Fabian
   Klein, Reinhard
TI Hybrid tree reconstruction from inhomogeneous point clouds
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 31st CGI conference
CY JUN 10-13, 2014
CL Sydney, AUSTRALIA
DE Point clouds; Reconstruction; Trees
AB Trees are an important asset for natural-looking digital environments. We propose a novel method to automatically reconstruct tree geometry from inhomogeneous point clouds created by a laser scanner. While previous approaches focus either on dense or sparse point clouds, our hybrid method allows for the reconstruction of a tree from an inhomogeneous point cloud without further preprocessing. Using principal curvatures as indicators for branches, we detect ellipses in branch cross-sections and create branch skeletons for dense regions. For sparse regions we approximate branch skeletons with a spanning tree. Branch widths are obtained from the ellipse fitting in dense regions and propagated to the sparse regions, to create geometry for the whole tree. We demonstrate the effectiveness of our approach in several real-world examples.
C1 [Aiteanu, Fabian; Klein, Reinhard] Univ Bonn, Dept Comp Graph, Bonn, Germany.
C3 University of Bonn
RP Aiteanu, F (corresponding author), Univ Bonn, Dept Comp Graph, Bonn, Germany.
EM aiteanu@cs.uni-bonn.de; rk@cs.uni-bonn.de
FU German Research Foundation (DFG) [KL 1142/9-1]
FX We want to thank Martin Blome for providing the scanned tree data used
   throughout this paper. This work was partially funded by the German
   Research Foundation (DFG) under grant KL 1142/9-1 (Mapping on Demand).
CR [Anonymous], 2012, T EDUTAINMENT 8 TAIP
   Bucksch A, 2010, VISUAL COMPUT, V26, P1283, DOI 10.1007/s00371-010-0520-4
   Chen XJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409062
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   HONDA H, 1971, J THEOR BIOL, V31, P331, DOI 10.1016/0022-5193(71)90191-3
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Jayaratna S., 2009, THESIS U BONN
   Klasing K, 2009, IEEE INT CONF ROBOT, P2011
   Livny Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964948
   Livny Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866177
   Neubert B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239539
   Pfeifer N., 2004, Proceedings of 20th ISPRS Congress, P114
   Prusinkiewicz P, 1990, ALGORITHMIC BEAUTY P, V2
   Quan L, 2006, ACM T GRAPHIC, V25, P599, DOI 10.1145/1141911.1141929
   Reche A, 2004, ACM T GRAPHIC, V23, P720, DOI 10.1145/1015706.1015785
   ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I
   Shlyakhter I, 2001, IEEE COMPUT GRAPH, V21, P53, DOI 10.1109/38.920627
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Tan P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239538
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Wither J, 2009, COMPUT GRAPH FORUM, V28, P541, DOI 10.1111/j.1467-8659.2009.01394.x
   Xu H, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289610
   Yan DM, 2009, INT C COMP AID DES C, P572, DOI 10.1109/CADCG.2009.5246837
   Zhang X., 2009, J. Inf. Comput. Sci., V6, P1983
   Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2
NR 25
TC 29
Z9 31
U1 1
U2 25
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2014
VL 30
IS 6-8
BP 763
EP 771
DI 10.1007/s00371-014-0977-7
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA AI7GX
UT WOS:000337054700019
DA 2024-07-18
ER

PT J
AU Kim, K
   Park, NY
   Woo, W
AF Kim, Kiyoung
   Park, Noh-young
   Woo, Woontack
TI Vision-based all-in-one solution for augmented reality and its
   storytelling applications
SO VISUAL COMPUTER
LA English
DT Article
DE Augmented reality; Markerless tracking; Miniature; Framework;
   Storytelling
ID LOCALIZATION; RECOGNITION; TRACKING
AB In this paper, we propose a vision-based all-in-one solution for augmented reality where users want to exploit unknown 3D objects in their systems. In our solution, we facilitate two time-consuming off-line processes: obtaining information, such as keyframes and keypoints, for real-time tracking of unknown 3D targets, and estimating local coordinates with a scale for accurate registration of virtual content. The proposed solution only requires images with minimal interactions. The users do not need to know about 3D markerless tracking in depth. At the end, we propose a framework for AR miniatures systems to verify the effectiveness of our solution. As a result, all developed systems worked in real-time, more than 25 fps, and showed reliable registration even in severe viewpoint changes. Our demonstration videos are available in the supplemental materials.
C1 [Kim, Kiyoung] Qualcomm Austria Res Ctr GmbH, Vienna, Austria.
   [Park, Noh-young; Woo, Woontack] Korea Adv Inst Sci & Technol, UVR Lab, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Woo, W (corresponding author), Korea Adv Inst Sci & Technol, UVR Lab, Taejon 305701, South Korea.
EM kiyoungk@qti.qualcomm.com; nypark@kaist.ac.kr; wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421
FU Global Frontier R&D Program on <Humancentered Interaction for
   Coexistence>; National Research Foundation of Korea; Korean Government
   (MSIP) [NRF-2010-0029751]; DigiLog Miniature Augmented Reality Research
   Program; KAIST Research Foundation
FX This work was supported by the Global Frontier R&D Program on <
   Humancentered Interaction for Coexistence > funded by the National
   Research Foundation of Korea grant funded by the Korean Government
   (MSIP) (NRF-2010-0029751). And also this work was supported by the
   DigiLog Miniature Augmented Reality Research Program funded by KAIST
   Research Foundation.
CR Aittala M, 2010, VISUAL COMPUT, V26, P669, DOI 10.1007/s00371-010-0501-7
   [Anonymous], IEEE ACM INT S MIX A
   [Anonymous], 2010, P VRCAI 2010 ACM SIG, DOI DOI 10.1145/1900179.1900214
   [Anonymous], 2007, Proc. CVWW '07
   [Anonymous], SIFTGPU GPU GPU IMPL
   Bastian J., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P199, DOI 10.1109/ISMAR.2010.5643570
   Castle RO, 2011, IMAGE VISION COMPUT, V29, P524, DOI 10.1016/j.imavis.2011.05.002
   Castle RO, 2009, INT SYM MIX AUGMENT, P179, DOI 10.1109/ISMAR.2009.5336477
   Correia N, 2006, VISUAL COMPUT, V22, P991, DOI 10.1007/s00371-006-0039-x
   Dong ZL, 2009, IEEE I CONF COMP VIS, P1538
   Egges A, 2007, VISUAL COMPUT, V23, P317, DOI 10.1007/s00371-007-0113-z
   Fiala M, 2005, PROC CVPR IEEE, P590
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/CVPRW.2009.5206587
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kim K, 2010, VISUAL COMPUT, V26, P1145, DOI 10.1007/s00371-010-0490-6
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moreno- Noguer F., 2007, IEEE INT C COMPUTER, P1
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794
   Nister David, 2006, CVPR
   PILET J, 2006, P 5 IEEE ACM INT S M, P69
   Scherrer C, 2008, INT SYM MIX AUGMENT, P163, DOI 10.1109/ISMAR.2008.4637347
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   Taketa N, 2007, LECT NOTES COMPUT SC, V4558, P475
   van den Hengel A, 2009, INT SYM MIX AUGMENT, P107, DOI 10.1109/ISMAR.2009.5336482
NR 28
TC 3
Z9 3
U1 0
U2 23
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2014
VL 30
IS 4
BP 417
EP 429
DI 10.1007/s00371-013-0865-6
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD3SW
UT WOS:000333167500005
DA 2024-07-18
ER

PT J
AU Berbar, MA
AF Berbar, Mohamed Abdou
TI Three robust features extraction approaches for facial gender
   classification
SO VISUAL COMPUTER
LA English
DT Article
DE Faces gender classification; Discrete cosine transform; Grey-level
   cooccurrence matrix (GLCM); SVM
AB This research paper introduces three robust approaches for features extraction for gender classification. The first approach is based on using Discrete Cosine Transform (DCT) and consists of two different methods for calculating features values. The second approach is based on the extraction of texture features using the gray-level cooccurrence matrix (GLCM). The third approach is based on 2D-wavelet transform. The extracted features vectors are classified using SVM. For precise evaluation, the databases used for gender evaluation are based on images from the AT@T, Faces94, UMIST, and color FERET databases. K-fold cross validation is used in training the SVM. The accuracies of gender classification when using one of the two proposed DCT methods for features extraction are 98.6 %, 99.97 %, 99.90 %, and 93.3 % with 2-fold cross validation, and 98.93 %, 100 %, 99.9 %, and 92.18 % with 5-fold cross validation. The accuracies of GLCM texture features approach for facial gender classification are 98.8 %, 99.6 %, 100 %, and 93.11 %, for AT@T, Faces94, UMIST, and FERET, databases. The accuracies for all databases when using 2D-WT are ranging between 96.18 % and 99.6 % except FERET and its accuracy is 92 %.
C1 King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11543, Saudi Arabia.
C3 King Saud University
RP Berbar, MA (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11543, Saudi Arabia.
EM m_berbar@ksu.edu.sa
RI Berbar, Mohamed/GZN-1295-2022
FU Research Center of College of Computer and Information Sciences, King
   Saud University
FX This work was supported by the Research Center of College of Computer
   and Information Sciences, King Saud University. The author is grateful
   for this support.
CR An XH, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL II, P1, DOI 10.1145/1399504.1360639
   Andreu Y., 2008, COMPLEMENTARITY FACE
   [Anonymous], IEEE 3 INT C IM VIS
   [Anonymous], 2010, P 2010 IEEE INT C CO, DOI DOI 10.1109/ICCIC.2010.5705804
   Baluja S., 2007, INT J COMPUT VIS, V7
   Berbar M.A., 2012, EGYPT COMPUT SCI J, V36, P1110
   Brunelli R., 1992, P DARPA IMAGE UNDERS, P311
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   BURTON AM, 1993, PERCEPTION, V22, P153, DOI 10.1068/p220153
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Guo J.-M., 2010, INT C SYST SCI ENG, P637
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hsu C. W., 2010, Technical Report
   Hussain M., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P145, DOI 10.1109/CGIV.2011.31
   Jabid Taskeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2162, DOI 10.1109/ICPR.2010.373
   Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524
   Lian HC, 2005, LECT NOTES COMPUT SC, V3611, P438
   Lin G.-S., 2011, IEEE COMP SOC 1 INT, P40
   Lu A.A., 2010, PATTERN CLASS LETT, V31, P1422
   Lu HC, 2008, J REAL-TIME IMAGE PR, V3, P109, DOI 10.1007/s11554-008-0072-2
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Mozaffari Saeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1192, DOI 10.1109/ICPR.2010.297
   OZBUDAK O, 2010, 15 IEEE MED EL C MEL, P26
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Samaria F. S., 1994, P 2 IEEE WORKSH APPL
   Soh L., 1999, IEEE T GEOSCI REMOTE, V37
   Soyel H, 2010, ELECTRON LETT, V46, P343, DOI 10.1049/el.2010.0092
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176
   Wang CX, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 1, PROCEEDINGS, P312, DOI 10.1109/ISCSCT.2008.204
   Wu J, 2010, IMAGE VISION COMPUT, V28, P1039, DOI 10.1016/j.imavis.2009.09.003
   Zafeiriou S., 2008, 16 EUR SIGN PROC C E
   Zheng J, 2011, NEUROCOMPUTING, V74, P1926, DOI 10.1016/j.neucom.2010.07.032
NR 35
TC 28
Z9 29
U1 0
U2 13
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2014
VL 30
IS 1
BP 19
EP 31
DI 10.1007/s00371-013-0774-8
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 291AR
UT WOS:000329800500002
DA 2024-07-18
ER

PT J
AU Hulusic, V
   Debattista, K
   Chalmers, A
AF Hulusic, Vedad
   Debattista, Kurt
   Chalmers, Alan
TI Smoothness perception
SO VISUAL COMPUTER
LA English
DT Article
DE Perception; Cross-modal interaction; User-study
ID TEMPORAL VENTRILOQUISM; CROSSMODAL INTERACTION; TIME DIMENSION;
   INTEGRATION; DOMINANCE; IMPROVE; VISION
AB Despite the complexity of the Human Visual System (HVS), research over the last few decades has highlighted a number of its limitations. These limitations can be exploited in computer graphics to significantly reduce computational cost and thus required rendering time, without a viewer perceiving any difference in resultant image quality. Furthermore, cross-modal interaction between different modalities, such as the influence of audio on visual perception, has also been shown as significant both in psychology and computer graphics. In this paper we investigate the effect of beat rate on temporal visual perception, i.e. frame rate perception. For the visual quality and perception evaluation, a series of psychophysical experiments was conducted and the data analysed. The results indicate that beat rates in some cases do affect temporal visual perception and that certain beat rates can be used in order to reduce the amount of rendering required to achieve a perceptual high quality. This is another step towards a comprehensive understanding of auditory-visual cross-modal interaction and could be potentially used in high-fidelity interactive multi-sensory virtual environments.
C1 [Hulusic, Vedad] Univ Sarajevo, Sch Sci & Technol, Sarajevo 71000, Bosnia & Herceg.
   [Debattista, Kurt; Chalmers, Alan] Univ Warwick, Int Digital Lab, WMG, Coventry CV4 7AL, W Midlands, England.
C3 University of Sarajevo; University of Warwick
RP Hulusic, V (corresponding author), Univ Sarajevo, Sch Sci & Technol, Hrasnicka Cesta 3A, Sarajevo 71000, Bosnia & Herceg.
EM vedad.hulusic@ssst.edu.ba; k.debattista@warwick.ac.uk;
   alan.chalmers@warwick.ac.uk
OI Hulusic, Vedad/0000-0002-3675-095X
FU EPSRC [EP/K014056/1] Funding Source: UKRI
CR ALLMANWARD M, 2004, 33 INT C EXP NOIS CO
   [Anonymous], 2007, COMPUT ENTERTAINMENT
   [Anonymous], 1998, THESIS NAVAL POSTGRA
   [Anonymous], METH SUBJ ASS QUAL T
   Arif M., 2004, MEAS SCI REV, V4, P29
   Aschersleben G, 2003, INT J PSYCHOPHYSIOL, V50, P157, DOI 10.1016/S0167-8760(03)00131-4
   BARGARY G, 2007, 8 ANN M INT MULT RES
   Bertelson P, 2003, INT J PSYCHOPHYSIOL, V50, P147, DOI 10.1016/S0167-8760(03)00130-2
   Blake R., 2006, Perception, Vfifth
   Bonneel N, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658350
   Burr D, 2009, EXP BRAIN RES, V198, P49, DOI 10.1007/s00221-009-1933-z
   CHOE CS, 1975, PERCEPT PSYCHOPHYS, V18, P55, DOI 10.3758/BF03199367
   DEBATTISTA K, 2006, THESIS U BRISTOL
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Field A., 2009, Discovering statistics with SPSS, V3rd
   Funkhouser T. A., 1993, Computer Graphics Proceedings, P247, DOI 10.1145/166117.166149
   GEBHARD JW, 1959, AM J PSYCHOL, V72, P521, DOI 10.2307/1419493
   GERO JS, 2004, INT J DES SCI TECHNO, V12, P35
   Getzmann S, 2007, PERCEPTION, V36, P1089, DOI 10.1068/p5741
   GIUDICE S, 2006, 35 INT C EXP NOIS CO, P4428
   Grelaud D., 2009, P ACM SIGGRAPH S INT
   Howard I.P., 1966, Human Spatial Orientation
   Hulusic V, 2008, WSCG 2008, FULL PAPERS, P41
   HULUSIC V, 2011, EUROGRAPHICS STATE A
   Hulusic V., 2009, SPRING C COMP GRAPH, P167
   Hulusic V, 2011, VISUAL COMPUT, V27, P57, DOI 10.1007/s00371-010-0514-2
   Humphreys GlynW., 1989, Visual Cognition: Computational, Experimental, and Neuropsychological Perspectives
   James W., 1890, The Principles of Psychology, V1
   Kamitani Y, 2001, J VIS, V1, P478, DOI DOI 10.1167/1.3.478
   Kelly M.C., 2002, P AES 112 CONV MUN G
   Lécuyer A, 2006, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2006.31
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Mack Arien, 1998, Inattentional Blindness
   Mastoropoulou G, 2004, THEORY AND PRACTICE OF COMPUTER GRAPHICS 2004, PROCEEDINGS, P128, DOI 10.1109/TPCG.2004.1314462
   MASTOROPOULOU G, 2005, APGV 05, P9, DOI DOI 10.1145/1080402.1080404
   MASTOROPOULOU G, 2006, THESIS U BRISTOL
   MASTOROPOULOU G, 2005, GRAPHITE 05, P363, DOI DOI 10.1145/1101389.1101462
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Moore BrianC. J., 1982, An Introduction to the Psychology of Hearing
   Morein-Zamir S, 2003, COGNITIVE BRAIN RES, V17, P154, DOI 10.1016/S0926-6410(03)00089-2
   Ramanarayanan G, 2008, PROC SPIE, V6806, DOI 10.1117/12.767029
   Recanzone GH, 2003, J NEUROPHYSIOL, V89, P1078, DOI 10.1152/jn.00706.2002
   Recanzone GH, 2008, ANNU REV PSYCHOL, V59, P119, DOI 10.1146/annurev.psych.59.103006.093544
   Roach NW, 2006, P ROY SOC B-BIOL SCI, V273, P2159, DOI 10.1098/rspb.2006.3578
   Sekuler R, 1997, NATURE, V385, P308, DOI 10.1038/385308a0
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Shams L, 2002, COGNITIVE BRAIN RES, V14, P147, DOI 10.1016/S0926-6410(02)00069-1
   Shams L., 2004, The Handbook of Multisensory Processes, P27
   Shams L, 2010, PHYS LIFE REV, V7, P269, DOI 10.1016/j.plrev.2010.04.006
   SHIPLEY T, 1964, SCIENCE, V145, P1328, DOI 10.1126/science.145.3638.1328
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Stein BE, 1996, J COGNITIVE NEUROSCI, V8, P497, DOI 10.1162/jocn.1996.8.6.497
   Strayer DL, 2001, PSYCHOL SCI, V12, P462, DOI 10.1111/1467-9280.00386
   Su YH, 2011, EXP BRAIN RES, V214, P357, DOI 10.1007/s00221-011-2835-4
   Suied C, 2009, EXP BRAIN RES, V194, P91, DOI 10.1007/s00221-008-1672-6
   Van der Burg E, 2008, J EXP PSYCHOL HUMAN, V34, P1053, DOI 10.1037/0096-1523.34.5.1053
   Vroomen J., 1998, VISUAL INFLUENCE DIS
   Vroomen J., 2004, HDB MULTISENSORY PRO, P140
   Wada Y, 2003, INT J PSYCHOPHYSIOL, V50, P117, DOI 10.1016/S0167-8760(03)00128-4
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
NR 61
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD NOV
PY 2013
VL 29
IS 11
BP 1159
EP 1172
DI 10.1007/s00371-012-0760-6
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 236PL
UT WOS:000325811300005
DA 2024-07-18
ER

PT J
AU Margolin, R
   Zelnik-Manor, L
   Tal, A
AF Margolin, Ran
   Zelnik-Manor, Lihi
   Tal, Ayellet
TI Saliency for image manipulation
SO VISUAL COMPUTER
LA English
DT Article
DE Image saliency; Image manipulation; Painterly rendering; Cropping;
   Mosaicing
ID ATTENTION
AB Every picture tells a story. In photography, the story is portrayed by a composition of objects, commonly referred to as the subjects of the piece. Were we to remove these objects, the story would be lost. When manipulating images, either for artistic rendering or cropping, it is crucial that the story of the piece remains intact. As a result, the knowledge of the location of these prominent objects is essential. We propose an approach for saliency detection that combines previously suggested patch distinctness with an object probability map. The object probability map infers the most probable locations of the subjects of the photograph according to highly distinct salient cues. The benefits of the proposed approach are demonstrated through state-of-the-art results on common data sets. We further show the benefit of our method in various manipulations of real-world photographs while preserving their meaning.
C1 [Margolin, Ran; Zelnik-Manor, Lihi; Tal, Ayellet] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Margolin, R (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
EM margolin@tx.technion.ac.il
FU Intel; Ollendorf foundation; Israel Ministry of Science; Israel Science
   Foundation [1179/11]
FX This research was supported in part by Intel, the Ollendorf foundation,
   the Israel Ministry of Science, and by the Israel Science Foundation
   under Grant 1179/11.
CR Achanta R., 2009, SIGGRAPH ASIA
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Collomosse JP, 2002, 20TH EUROGRAPHICS UK CONFERENCE, PROCEEDINGS, P122, DOI 10.1109/EGUK.2002.1011281
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hays J., 2004, PROC NPAR 01, P113
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   PRINZMETAL W, 1995, CURR DIR PSYCHOL SCI, V4, P90, DOI 10.1111/1467-8721.ep10772335
   Rubinstein M., 2009, TOG, V28
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Yeshurun Y, 2009, VISION RES, V49, P1329, DOI 10.1016/j.visres.2008.01.014
   Zeng K., 2009, TOG, V29
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
NR 21
TC 81
Z9 91
U1 1
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2013
VL 29
IS 5
BP 381
EP 392
DI 10.1007/s00371-012-0740-x
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 127RD
UT WOS:000317715200006
DA 2024-07-18
ER

PT J
AU Rasool, S
   Sourin, A
AF Rasool, Shahzad
   Sourin, Alexei
TI Image-driven virtual simulation of arthroscopy
SO VISUAL COMPUTER
LA English
DT Article
DE Image-driven haptic interaction; Virtual surgery simulation; Tangible
   images; Augmented reality
ID TRAINING SYSTEM; REALITY; SURGERY
AB In recent years, minimally invasive arthroscopic surgery has replaced a number of conventional open orthopedic surgery procedures on joints. While this achieves a number of advantages for the patient, the surgeons have to learn very different skills, since the surgery is performed with special miniature pencil-like tools and cameras inserted through little incisions while observing the surgical field on video monitor. Therefore, virtual reality simulation becomes an alternative to traditional surgical training based on hundreds years old apprentice-master model that involves either real patients or increasingly difficult to procure cadavers. Normally, 3D simulation of the virtual surgical field requires significant efforts from the software developers but yet remains not always photorealistic. In contrast to this, for photorealistic visualization and haptic interaction with the surgical field we propose to use real arthroscopic images augmented with 3D object models. The proposed technique allows for feeling the joint cavity displayed on video monitor as real 3D objects rather than their images while various surgical procedures, such as menisectomy, are simulated in real time. In the preprocessing stage of the proposed approach, the arthroscopic images are stitched into panoramas and augmented with implicitly defined object models representing deformable menisci. In the simulation loop, depth information from the mixed scene is used for haptic rendering. The scene depth map and visual display are reevaluated only when the scene is modified.
C1 [Rasool, Shahzad] Nanyang Technol Univ, Sch Comp Engn, Fraunhofer IDM NTU, Singapore 639798, Singapore.
   [Sourin, Alexei] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Rasool, S (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Fraunhofer IDM NTU, Singapore 639798, Singapore.
EM shah0033@ntu.edu.sg; assourin@ntu.edu.sg
RI Sourin, Alexei/A-3701-2011; Rasool, Shahzad/AAE-8858-2019
OI Rasool, Shahzad/0000-0001-5504-3727; Sourin, Alexei/0000-0003-4051-2927
FU Singapore National Research Foundation [NRF2008IDM-IDM 004-002];
   Ministry of Education of Singapore [MOE 2011-T2-1-006]; Russian
   Foundation for Basic Research [12-07-00157-a]
FX This project is supported by the Singapore National Research Foundation
   Interactive Digital Media R&D Program, under research Grant
   NRF2008IDM-IDM 004-002 "Visual and Haptic Rendering in Co-Space", by the
   Ministry of Education of Singapore Grant MOE 2011-T2-1-006
   "Collaborative Haptic Modeling for Orthopedic Surgery Training in
   Cyberspace" and by the Russian Foundation for Basic Research grant
   12-07-00157-a "Virtual Modeling of Minimally Invasive Surgery
   Operations." The authors are very grateful to Fareed Kagda, M.D. for
   providing medical data and collaboration on developing the surgery
   training system.
CR Ackerman M. J, 1997, P IEEE INT C INF TEC, P29
   Bayona S., 2003, P IASTED INT C VIS I
   Gibson S, 1997, LECT NOTES COMPUT SC, V1205, P369
   GMV Innovative Solutions, 2010, INSIGHTARTHROVR VIRT
   Heng PA, 2004, IEEE T INF TECHNOL B, V8, P217, DOI 10.1109/TITB.2004.826720
   Mabrey J. D., 2002, ARTHROSCOPY, V18
   Mabrey JD, 2010, CLIN ORTHOP RELAT R, V468, P2586, DOI 10.1007/s11999-010-1426-1
   Megali G., 2002, LECT NOTES COMPUTER, V2489, P170
   Muller W., 1998, P MED MEETS VIRT REA
   Rasool S., 2011, SIGGRAPH AS 2011 SKE, P41
   Rasool S., 2012, P COMP GRAP IN PRESS
   Rasool S., 2011, P 10 INT C VIRTUAL R, P13
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sherman KP, 1999, ST HEAL T, V62, P335
   Simbionix Corporation, 2012, ARTHR MENT
   VirtaMed AG, 2012, VIRT ARTHR SIM
NR 16
TC 11
Z9 13
U1 0
U2 120
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2013
VL 29
IS 5
BP 333
EP 344
DI 10.1007/s00371-012-0736-6
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 127RD
UT WOS:000317715200002
DA 2024-07-18
ER

PT J
AU Niu, C
   Zhong, F
   Xu, SH
   Yang, CL
   Qin, XY
AF Niu, Chuan
   Zhong, Fan
   Xu, Songhua
   Yang, Chenglei
   Qin, Xueying
TI Cylindrical panoramic mosaicing from a pipeline video through MRF based
   optimization
SO VISUAL COMPUTER
LA English
DT Article
DE Panorama; MRF optimization; Forward moving camera; Belief propagation
   algorithm
ID VIEWPOINT; SCENES
AB Stratum structure detection is a fundamental problem in geological engineering. One of the most commonly employed detection technologies is to shoot videos of a borehole using a forward moving camera. Using this technology, the problem of stratum structure detection is transformed into the problem of constructing a panoramic image from a low quality video. In this paper, we propose a novel method for creating a panoramic image of a borehole from a video sequence without the need of camera calibration and tracking. To stitch together pixels of neighboring image frames, our camera model is designed with a focal length changing feature, along with a small rotational freedom in the two-dimensional image space. Our camera model assumes that target objects lie on a cylindrical wall and that the camera moves forward along the central axis of the cylindrical wall. Based on these two assumptions, our method robustly resolves these two degrees-of-freedoms in our camera model through KLT feature tracking. Since the quality of the result video is affected by possible illumination overflow, camera lens blurring, and low video resolution, we introduce a cost function for eliminating seams between stitching strips. Our cost function is designed based on Markov Random Field and optimized using a belief propagation algorithm. Using our method, we can automatically construct a panorama image with good resolution, smoothness, and continuousness both in the texture and illumination space. Experiment results show that our method could efficiently generate panoramas for long video sequences with satisfying visual quality.
C1 [Niu, Chuan; Zhong, Fan; Yang, Chenglei; Qin, Xueying] Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Peoples R China.
   [Niu, Chuan; Zhong, Fan; Yang, Chenglei; Qin, Xueying] Shandong Prov Key Lab Software Engn, Jinan, Peoples R China.
   [Xu, Songhua] Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
C3 Shandong University; United States Department of Energy (DOE); Oak Ridge
   National Laboratory
RP Yang, CL (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Peoples R China.
EM niuchuan@mail.sdu.edu.cn; zhongfan@sdu.edu.cn; xus1@ornl.gov;
   chl_yang@sdu.edu.cn; qxy@sdu.edu.cn
RI Qin, Xueying/AAM-8775-2021
OI Qin, Xueying/0000-0003-0057-295X
FU National Natural Science Foundation of China [U1035004, 61003149,
   61272243, 61173070]; Shandong Province Natural Science Foundation
   [ZR2010FQ011, ZR2012FQ026]; Natural Science Fund for Distinguished Young
   Scholars of Shandong Province [JQ200920]; US Department of Energy
   [DE-AC05-00OR22725]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. U1035004, 61003149, 61272243, 61173070), Shandong Province
   Natural Science Foundation (Nos. ZR2010FQ011, ZR2012FQ026), and the
   Natural Science Fund for Distinguished Young Scholars of Shandong
   Province (No. JQ200920). Songhua Xu performed this research as a Eugene
   P. Wigner Fellow and staff member at the Oak Ridge National Laboratory,
   managed by UT-Battelle, LLC, for the US Department of Energy under
   Contract DE-AC05-00OR22725.
CR Agarwala A, 2006, ACM T GRAPHIC, V25, P853, DOI 10.1145/1141911.1141966
   [Anonymous], DARPA IM UND WORKSH
   Behrens A, 2008, ACTA POLYTECH, V48, P50
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Chuan Niu, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P171, DOI 10.1109/CAD/Graphics.2011.32
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446
   Hansen M., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P54, DOI 10.1109/ACV.1994.341288
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883
   JAILLON P, 1994, INT C PATT RECOG, P253, DOI 10.1109/ICPR.1994.576267
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   LEViN Golan., 2005, An Informal Catalogue of Slit-ScanVideo Artworks and Research
   Lin SS, 2006, J OPT SOC AM A, V23, P2997, DOI 10.1364/JOSAA.23.002997
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MANN S, 1994, IEEE IMAGE PROC, P363, DOI 10.1109/ICIP.1994.413336
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794
   Rafajlowicz E., 2007, INT WORKSH MULT ND S, P9
   Rousso B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P945, DOI 10.1109/ICCV.1998.710830
   SAWHNEY HS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P583
   Swaminathan R., 1999, CVPR, P2413
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P44, DOI 10.1109/ACV.1994.341287
   Szeliski R., 1994, 942 DIG EQ CORP
   Teodosio L., 1993, ACM MULTIMEDIA, V93, P359
   Teodosio L., 1993, ACM MULTIMEDIA, V93, P3946
   Tomasi C, 1991, DETECTION TRACKING P
   Zomet A, 2003, IEEE T PATTERN ANAL, V25, P741, DOI 10.1109/TPAMI.2003.1201823
NR 32
TC 5
Z9 7
U1 0
U2 29
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2013
VL 29
IS 4
SI SI
BP 253
EP 263
DI 10.1007/s00371-012-0763-3
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 115AM
UT WOS:000316784200003
DA 2024-07-18
ER

PT J
AU Aristidou, A
   Lasenby, J
AF Aristidou, Andreas
   Lasenby, Joan
TI Real-time marker prediction and CoR estimation in optical motion capture
SO VISUAL COMPUTER
LA English
DT Article
DE Computer vision; Filtering; Marker prediction; Joint localisation;
   Motion capture; Inverse kinematics
ID INVERSE KINEMATIC SOLUTIONS; MISSING MARKERS; ROTATION; TRACKING;
   PERFORMANCE; OPTIMIZATION; AXIS
AB Optical motion capture systems suffer from marker occlusions resulting in loss of useful information. This paper addresses the problem of real-time joint localisation of legged skeletons in the presence of such missing data. The data is assumed to be labelled 3d marker positions from a motion capture system. An integrated framework is presented which predicts the occluded marker positions using a Variable Turn Model within an Unscented Kalman filter. Inferred information from neighbouring markers is used as observation states; these constraints are efficient, simple, and real-time implementable. This work also takes advantage of the common case that missing markers are still visible to a single camera, by combining predictions with under-determined positions, resulting in more accurate predictions. An Inverse Kinematics technique is then applied ensuring that the bone lengths remain constant over time; the system can thereby maintain a continuous data-flow. The marker and Centre of Rotation (CoR) positions can be calculated with high accuracy even in cases where markers are occluded for a long period of time. Our methodology is tested against some of the most popular methods for marker prediction and the results confirm that our approach outperforms these methods in estimating both marker and CoR positions.
C1 [Aristidou, Andreas; Lasenby, Joan] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
C3 University of Cambridge
RP Aristidou, A (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
EM aa462@cam.ac.uk; jl221@cam.ac.uk
RI Aristidou, Andreas/AAI-8096-2020
OI Aristidou, Andreas/0000-0001-7754-0791; Lasenby,
   Joan/0000-0002-0571-0218
CR [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 2012, Clifford algebra to geometric calculus: a unified language for mathematics and physics
   [Anonymous], 1985, P 1985 IEEE INT C RO
   Aristidou A., 2009, FINFENGTR632 CUED
   Aristidou A., 2009, FINFENGTR619 CUED, P619
   Aristidou A, 2008, LECT NOTES COMPUT SC, V5098, P238, DOI 10.1007/978-3-540-70517-8_23
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   ASSEO SJ, 1982, P NAT AER EL C NAECO, P916
   Backer A.S., 2009, THESIS CAMBRIDGE U C
   Balestrino A., 1984, P 9 IFAC WORLD C, V5, P2435, DOI [10.1016/S1474-6670(17)61347-8, DOI 10.1016/S1474-6670(17)61347-8]
   Broeren J, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-13
   Brown J, 2004, VISUAL COMPUT, V20, P165, DOI 10.1007/s00371-003-0226-y
   Buss S. R., 2005, Journal of Graphics Tools, V10, P37
   Cameron J, 2005, ACM SIGGRAPH, P107
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Chang LY, 2007, J BIOMECH, V40, P1392, DOI 10.1016/j.jbiomech.2006.05.010
   Courty N, 2010, COMPUT ANIMAT VIRT W, V21, P443, DOI 10.1002/cav.374
   Courty N, 2008, LECT NOTES COMPUT SC, V5098, P1, DOI 10.1007/978-3-540-70517-8_1
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   Dessai S.S., 2006, J VIRTUAL REAL BROAD, V3
   Doran C., 2003, GEOMETRIC ALGEBRA PH, DOI [10.1017/CBO9780511807497, DOI 10.1017/CBO9780511807497]
   Dorfmuller-Ulhaas K., 2003, TR20036 U I FUER INF
   Ehrig RM, 2006, J BIOMECH, V39, P2798, DOI 10.1016/j.jbiomech.2005.10.002
   FLETCHER R., 1987, PRACTICAL METHODS OP
   Gamage SSHU, 2002, J BIOMECH, V35, P87, DOI 10.1016/S0021-9290(01)00160-9
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Halvorsen K, 2003, J BIOMECH, V36, P999, DOI 10.1016/S0021-9290(03)00070-8
   Halvorsen K, 1999, J BIOMECH, V32, P1221, DOI 10.1016/S0021-9290(99)00120-7
   Hashiguichi J., 2006, P ANN M JAP SOC ORTH, V27, P325
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Herda L, 2000, COMP ANIM CONF PROC, P77, DOI 10.1109/CA.2000.889046
   Herda L, 2001, HUM MOVEMENT SCI, V20, P313, DOI 10.1016/S0167-9457(01)00050-1
   HOLZREITER S, 1991, J BIOMECH, V24, P643, DOI 10.1016/0021-9290(91)90297-Z
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Hornung A, 2005, P IEEE VIRT REAL ANN, P75
   Hsu Eugene, 2004, P ACM SIGGRAPH EUR S, P69, DOI DOI 10.1145/1028523.1028534
   Ishigaki S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531367
   Jazwinski A., 1970, STOCHASTIC PROCESSES
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Li L., 2010, P ACM S COMP AN MADR
   Li L, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P507
   Li XR, 2003, IEEE T AERO ELEC SYS, V39, P1333, DOI 10.1109/TAES.2003.1261132
   Lin M.C., 1998, PROC IMA C MATH SURF, P37
   Liu G., 2006, P 2006 S INTERACTIVE, P35, DOI [DOI 10.1145/1111411.1111418, 10.1145/1111411.1111418.]
   Liu GD, 2006, VISUAL COMPUT, V22, P721, DOI 10.1007/s00371-006-0080-9
   Maidi M, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/146123
   Menache Alberto., 1999, Understanding Motion Capture for Computer Animation and Video Games
   Merwe R.V.D., 2000, FINFENGTR380 CUED
   NAKAMURA Y, 1986, J DYN SYST-T ASME, V108, P163, DOI 10.1115/1.3143764
   O'Brien JF, 2000, PROC GRAPH INTERF, P53
   Park SI, 2006, ACM T GRAPHIC, V25, P881, DOI 10.1145/1141911.1141970
   Pechev AN, 2008, IEEE INT CONF ROBOT, P2005, DOI 10.1109/ROBOT.2008.4543501
   Phasespace inc, OPT MOT CAPT SYST
   Piazza T., 2009, P INT DES ENG TECHN
   Ringer M., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P747
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Silaghi MC, 1998, LECT NOTES ARTIF INT, V1537, P26
   SINGER RA, 1970, IEEE T AERO ELEC SYS, VAES6, P473, DOI 10.1109/TAES.1970.310128
   SINGER RA, 1971, IEEE T AERO ELEC SYS, VAES7, P100, DOI 10.1109/TAES.1971.310257
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   van Rhijn A, 2006, P IEEE VIRT REAL ANN, P135, DOI 10.1109/VR.2006.104
   WAMPLER CW, 1986, IEEE T SYST MAN CYB, V16, P93, DOI 10.1109/TSMC.1986.289285
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   Welch G., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P1, DOI 10.1145/323663.323664
   Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968
   Wolovich W. A., 1984, Proceedings of the 23rd IEEE Conference on Decision and Control (Cat. No. 84CH2093-3), P1359
   Yu Q, 2007, COMPUT GRAPH FORUM, V26, P477, DOI 10.1111/j.1467-8659.2007.01070.x
   Zordan V. B., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P245
NR 72
TC 46
Z9 51
U1 1
U2 18
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2013
VL 29
IS 1
BP 7
EP 26
DI 10.1007/s00371-011-0671-y
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 064HB
UT WOS:000313063400002
DA 2024-07-18
ER

PT J
AU Liu, XM
   Hao, AM
   Zhao, D
AF Liu, Xian-mei
   Hao, Ai-min
   Zhao, Dan
TI Optimization-based key frame extraction for motion capture animation
SO VISUAL COMPUTER
LA English
DT Article
DE Computer animation; Motion capture; Key frame extraction; Optimization
   algorithm
AB In this paper, we present a new solution for extracting key frames from motion capture data using an optimization algorithm to obtain compact and sparse key frame data that can represent the original dense human body motion capture animation. The use of the genetic algorithm helps determine the optimal solution with global exploration capability while the use of a probabilistic simplex method helps expedite the speed of convergence. By finding the chromosome that maximizes the fitness function, the algorithm provides the optimal number of key frames as well as the low reconstruction error with an ordinary interpolation technique. The reconstruction error is computed between the original motion and the reconstruction one by the weighted differences of joint positions and velocities. The resulting set of key frames is obtained by iterative application of the algorithm with initial populations generated randomly and intelligently. We also present experiments which demonstrate that the method can effectively extract key frames with a high compression ratio and reconstruct all other non key frames with high quality.
C1 [Liu, Xian-mei; Hao, Ai-min] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100083, Peoples R China.
   [Liu, Xian-mei; Zhao, Dan] NE Petr Univ, Sch Comp & Informat Technol, Daqing 163318, Peoples R China.
C3 Beihang University; Northeast Petroleum University
RP Liu, XM (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100083, Peoples R China.
EM liuxianmei@yeah.net; ham.buaa@163.com; faye135@126.com
FU State Key Program of National Natural Science of China [60533070];
   Special Foundation of the "211 Project" Subject Construction for Young
   Researcher at the Beijing University of Technology; Beijing Municipal
   Commission of Education of Science and Technology Program
   [KM200910005020]
FX This work is supported and funded by the State Key Program of National
   Natural Science of China (No. 60533070), the Special Foundation of the
   "211 Project" Subject Construction for Young Researcher at the Beijing
   University of Technology, the Beijing Municipal Commission of Education
   of Science and Technology Program (No. KM200910005020). We would like to
   acknowledge the help of the CMU Graphics Lab, who provided us with the
   human motion capture data. We also would like to thank the anonymous
   reviewers for their helpful comments and suggestions.
CR Arikan O., 2006, P ACM SIGGRAPH 2006, P1
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Cooper M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P25
   Eyuphan B., 2007, COMPUTER ANIMATION S
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Huang KS, 2005, VISUAL COMPUT, V21, P532, DOI 10.1007/s00371-005-0316-0
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee TY, 2008, IEEE T CIRC SYST VID, V18, P478, DOI 10.1109/TCSVT.2008.918456
   Lim IS, 2001, P ANN INT IEEE EMBS, V23, P1167
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Park MJ, 2004, COMPUT ANIMAT VIRT W, V15, P245, DOI 10.1002/cav.27
   Ren Zi-Wu, 2007, Acta Automatica Sinica, V33, P91, DOI 10.1360/aas-007-0091
   Shen Junxing, 2004, Journal of Computer Aided Design & Computer Graphics, V16, P719
   Yang Tao, 2006, Journal of Computer Aided Design & Computer Graphics, V18, P1691
   Yen J, 1998, IEEE T SYST MAN CY B, V28, P173, DOI 10.1109/3477.662758
   Zhu Dengming, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P787
NR 16
TC 24
Z9 33
U1 2
U2 15
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2013
VL 29
IS 1
BP 85
EP 95
DI 10.1007/s00371-012-0676-1
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 064HB
UT WOS:000313063400007
DA 2024-07-18
ER

PT J
AU Ivo, RF
   Vidal, CA
   Cavalcante-Neto, JB
AF Ivo, Rafael Fernandes
   Vidal, Creto Augusto
   Cavalcante-Neto, Joaquim Bento
TI A method for clipping splats on sharp edges and corners
SO VISUAL COMPUTER
LA English
DT Article
DE Surface splatting; Sharp features; Rendering
AB The intrinsic characteristic of surface splatting is the treatment of points as if they were discs to fill the gaps between the samples. That requires special processing near sharp edges and corners in order to prevent rendering artifacts from appearing. In this work, we present a clever way of clipping splats near sharp edges and corners by a classification of neighboring splats, which belong to distinct intersecting surfaces that are called clip partners. If the surface represented by the clip partners of a certain splat S is completely concave or convex, the union or the intersection of the clipping areas of each clip partner is performed to clip the splat properly depending of their position in relation to S. If that surface has an edge or a transition zone between a concave and a convex part, the clip partners are divided into two groups. Each group is classified using the proposed method and the results are combined properly. That method is capable of correctly clipping splats in general situations, even at low sampling rates, without additional modeling information beyond the splats' normals and radii.
C1 [Ivo, Rafael Fernandes; Vidal, Creto Augusto; Cavalcante-Neto, Joaquim Bento] Univ Fed Ceara, Dept Comp, Fortaleza, Ceara, Brazil.
C3 Universidade Federal do Ceara
RP Ivo, RF (corresponding author), Univ Fed Ceara, Dept Comp, Fortaleza, Ceara, Brazil.
EM rafaelivo@gmail.com
RI Vidal, Creto/AAK-7042-2020
CR Adams B, 2003, ACM T GRAPHIC, V22, P651, DOI 10.1145/882262.882320
   Adamson A, 2006, ACM T GRAPHIC, V25, P671, DOI 10.1145/1141911.1141940
   Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Botsch M., 2004, Proceedings Eurographics Symposium on Point-Based Graphics 2004, P25, DOI 10.5555/2386332.2386338
   Botsch Mario, 2005, P EUROGRAPHICSIEEE V, P17, DOI [DOI 10.2312/SPBG/SPBG05/017-024, 10.1109/PBG.2005.194059.6]
   Fleishman S, 2003, ACM T GRAPHIC, V22, P997, DOI 10.1145/944020.944023
   Grossman J. P., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P181
   Kobbelt LP, 2001, COMP GRAPH, P57, DOI 10.1145/383259.383265
   Levoy M, 1985, USE POINTS DISPLAY P
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   Wicke M, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P160, DOI 10.1109/PCCGA.2004.1348346
   Zwicker M, 2004, PROC GRAPH INTERF, P247
   Zwicker M, 2001, COMP GRAPH, P371, DOI 10.1145/383259.383300
NR 15
TC 1
Z9 2
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2012
VL 28
IS 10
SI SI
BP 995
EP 1004
DI 10.1007/s00371-012-0729-5
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 003XE
UT WOS:000308643900005
DA 2024-07-18
ER

PT J
AU Hata, M
   Toyoura, M
   Mao, XY
AF Hata, Michitaka
   Toyoura, Masahiro
   Mao, Xiaoyang
TI Automatic generation of accentuated pencil drawing with saliency map and
   LIC
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Conference on the Computer Graphics International (CGI)
CY 2012
CL Bournemouth, ENGLAND
DE Pencil drawing; Saliency map; LIC; Focus of attention; Multi-resolution
   pyramid
ID VIDEO ABSTRACTION; IMAGE; MODEL
AB An artist usually does not draw all the areas in a picture homogeneously but tries to make the work more expressive by emphasizing what is important while eliminating irrelevant details. Creating expressive painterly images with such accentuation effect remains to be a challenge because of the subjectivity of information selection. This paper presents a novel technique for automatically converting an input image into a pencil drawing with such emphasis and elimination effect. The proposed technique utilizes saliency map, a computational model for visual attention, to predict the focus of attention in the input image. A new level of detail controlling algorithm using multi-resolution pyramid is also developed for locally adapting the rendering parameters, such as the density, orientation and width of pencil strokes, to the degree of attention defined by saliency map. Experimental results show that the images generated with the proposed method present the visual effect similar to that of the real pencil drawing and can successfully direct the viewer's attention toward the focus.
C1 [Hata, Michitaka; Toyoura, Masahiro; Mao, Xiaoyang] Univ Yamanashi, Interdisciplinary Grad Sch Med & Engn, Kofu, Yamanashi 4008511, Japan.
C3 University of Yamanashi
RP Mao, XY (corresponding author), Univ Yamanashi, Interdisciplinary Grad Sch Med & Engn, 4-3-11 Takeda, Kofu, Yamanashi 4008511, Japan.
EM mao@yamanashi.ac.jp
OI Toyoura, Masahiro/0000-0002-5897-7573; mao, xiaoyang/0000-0001-9531-3197
FU Grants-in-Aid for Scientific Research [21300033] Funding Source: KAKEN
CR AlMeraj Z, 2009, COMPUT GRAPH-UK, V33, P496, DOI 10.1016/j.cag.2009.04.004
   Chen ZY, 2008, LECT NOTES COMPUT SC, V5353, P931, DOI 10.1007/978-3-540-89796-5_117
   Collomosse JP, 2002, 20TH EUROGRAPHICS UK CONFERENCE, PROCEEDINGS, P122, DOI 10.1109/EGUK.2002.1011281
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Guptill L.A, 1977, RENDERING PENCIL
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kwon Y, 2011, COMM COM INF SC, V206, P70
   Kyprianidis J.E, 2011, P 9 S NONPH AN REND
   Kyprianidis J. E., 2008, P EG UK THEOR PRACT, P51
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Lee H., 2006, NPAR 2006, P37, DOI [10. 1145/1124728. 1124735, DOI 10.1145/1124728.1124735]
   Linda G.C. S., 2001, Computer Vision
   Mao XY, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P240
   Matsui H, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P148
   Melikhov K., 2006, P 2006 INT C GAM RES, P17
   Qin B, 2010, LECT NOTES COMPUT SC, V6145, P397, DOI 10.1007/978-3-642-13495-1_49
   SAIDA S, 1979, PERCEPT PSYCHOPHYS, V25, P119, DOI 10.3758/BF03198797
   Semet Y, 2004, LECT NOTES COMPUT SC, V3102, P188
   Sousa MC, 1999, PROC GRAPH INTERF, P157
   Sousa MC, 1999, COMPUT GRAPH FORUM, V18, pC195, DOI 10.1111/1467-8659.00340
   Takgi S., 1999, Proceedings. Seventh Pacific Conference on Computer Graphics and Applications (Cat. No.PR00293), P250, DOI 10.1109/PCCGA.1999.803369
   Willats J., 1997, Art and Representation: New Principles in the Analysis of Pictures
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Xie DE, 2007, LECT NOTES COMPUT SC, V4847, P723
   Yamamoto S, 2004, I C COMP GRAPH IM VI, P251, DOI 10.1109/CGIV.2004.1323994
   Yamamoto S, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P329
   Yang H, 2011, KSII T INTERNET INF, V5, P1311, DOI 10.3837/tiis.2011.07.006
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
NR 31
TC 17
Z9 22
U1 1
U2 10
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2012
VL 28
IS 6-8
BP 657
EP 668
DI 10.1007/s00371-012-0689-9
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 947EW
UT WOS:000304411500014
DA 2024-07-18
ER

PT J
AU Hu, SJ
   Chiba, N
   He, DJ
AF Hu, Shaojun
   Chiba, Norishige
   He, Dongjian
TI Realistic animation of interactive trees
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Conference on the Computer Graphics International (CGI)
CY 2012
CL Bournemouth, ENGLAND
DE Natural phenomena; Physically based animation; Tree animation; Lissajous
   curve; 1/f(beta) noise
ID REAL-TIME ANIMATION
AB We present a mathematical model for animating trees realistically by taking into account the influence of natural frequencies and damping ratios. To create realistic motion of branches, we choose three basic mode shapes from the modal analysis of a curved beam, and combine them with a driven harmonic oscillator to approximate Lissajous curve which is observed in pull-and-release test of real trees. The forced vibration of trees is animated by utilizing local coordinate transformation before applying the forced vibration model of curved beams. In addition, we assume petioles are flexible to create natural motion of leaves. A wind field is generated by three-dimensional 1/f (beta) noises to interact with the trees. Besides, our animation model allows users to interactively manipulate trees. We demonstrate several examples to show the realistic motion of interactive trees without using pre-computation or GPU acceleration. Various motions of trees can be achieved by choosing different combinations of natural frequencies and damping ratios according to tree species and seasons.
C1 [Hu, Shaojun] NW A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Chiba, Norishige] Iwate Univ, Fac Engn, Dept Comp & Informat Sci, Morioka, Iwate 020, Japan.
C3 Northwest A&F University - China; Iwate University
RP Hu, SJ (corresponding author), NW A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
EM hsj@nwsuaf.edu.cn; nchiba@cis.iwate-u.ac.jp; hdj168@nwsuaf.edu.cn
OI HU, Shaojun/0000-0002-4686-7633
CR Akagi Y, 2006, COMPUT GRAPH-UK, V30, P529, DOI 10.1016/j.cag.2006.03.017
   Beaudoin J., 2004, Symp. on Computer Animation (SCA), P297
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Di Giacomo T, 2001, SPRING EUROGRAP, P65
   Diener J, 2009, COMPUT GRAPH FORUM, V28, P533, DOI 10.1111/j.1467-8659.2009.01393.x
   Diener Julien., 2006, Proceedings of the Eurographics Symposium on Computer Animation, P187
   Fujimoto T., 2005, IWAIT2005, P459
   Habel R, 2009, COMPUT GRAPH FORUM, V28, P523, DOI 10.1111/j.1467-8659.2009.01391.x
   Hu SJ, 2009, COMPUT ANIMAT VIRT W, V20, P279, DOI 10.1002/cav.309
   James K.R., 2005, ISAAC
   James K.R., 2010, AUSTR EARTHQ ENG SOC
   James KR, 2006, AM J BOT, V93, P1522, DOI 10.3732/ajb.93.10.1522
   Khorloo Oyundolgor, 2011, International Journal of Virtual Reality, V10, P53
   Moore JR, 2005, TREES-STRUCT FUNCT, V19, P363, DOI 10.1007/s00468-004-0387-y
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Ota S, 2004, VISUAL COMPUT, V20, P613, DOI 10.1007/s00371-004-0266-y
   Rao B.N., 2007, J SOUND VIBRATION, V304, P969
   Shinya M., 1992, Computer Graphics Forum, V11, pC119, DOI 10.1111/1467-8659.1130119
   Stam J, 1997, COMPUT GRAPH FORUM, V16, pC159, DOI 10.1111/1467-8659.00152
   Weber JP, 2008, IEEE COMPUT GRAPH, V28, P67, DOI 10.1109/MCG.2008.51
   Zhang L, 2006, LECT NOTES COMPUT SC, V4035, P735
NR 21
TC 11
Z9 15
U1 0
U2 19
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2012
VL 28
IS 6-8
BP 859
EP 868
DI 10.1007/s00371-012-0694-z
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 947EW
UT WOS:000304411500033
DA 2024-07-18
ER

PT J
AU Liao, J
   Yu, J
AF Liao, Jing
   Yu, Jinhui
TI Procedural models for cartoon cracks and fractures animations
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Conference on the Computer Graphics International (CGI)
CY 2012
CL Bournemouth, ENGLAND
DE Procedural modeling; Cracks and fractures; Non-photorealistic rendering;
   Cartoon animation
ID VORONOI DIAGRAMS
AB We present an approach for animating cracks and fractures in cartoon style. In our method we take a 2D hand-drawn object as input and then construct a 2.5D model of the object in order to approximate the object volume. Next, we generate the Voronoi textures on the 2.5D object model for visual abstraction of cartoon cracks. Further, cracking gaps on the Voronoi textures are widened progressively until Voronoi cells split apart and finally fall onto ground according to simplified physical rules. With minimum user intervention, our model is able to generate cartoon cracks and fractures animations procedurally, as demonstrated by examples given in the paper.
C1 [Liao, Jing; Yu, Jinhui] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Yu, J (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM liaojing@cad.zju.edu.cn; jhyu@cad.zju.edu.cn
OI LIAO, Jing/0000-0001-7014-5377
CR [Anonymous], 2012, PHYSX
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Federl P, 2004, LECT NOTES COMPUT SC, V3037, P138
   FEDERL P, 2002, P 13 W COMP GRAPH S
   FEDERL P, 1996, P 7 W COMP GRAPH S
   Gingold Y., 2004, P ACM SIGGRAPH EUR S
   GOBRON S, 2000, P INT C COMP GRAPH
   GOBRON S, 2001, P 9 PAC C COMP GRAPH
   Hirota K, 1998, VISUAL COMPUT, V14, P126, DOI 10.1007/s003710050128
   Hirota K, 2000, VISUAL COMPUT, V16, P371, DOI 10.1007/s003710000069
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Iben HN, 2009, GRAPH MODELS, V71, P198, DOI 10.1016/j.gmod.2008.12.005
   Lischinski D., 1994, Graphics Gems, V4, P47
   Martinet A., 2004, P INT C SHAP MOD APP
   Mazarak O, 1999, PROC GRAPH INTERF, P211
   Molino N, 2004, ACM T GRAPHIC, V23, P385, DOI 10.1145/1015706.1015734
   Mould D., 2005, P GRAPHICS INTERFACE
   Muller M., 2004, P COMPUTER GRAPHICS
   Muller M, 2004, P GRAPHICS INTERFACE
   Neff M, 1999, PROC GRAPH INTERF, P193
   Norton A., 1991, Visual Computer, V7, P210, DOI 10.1007/BF01900837
   O'Brien J.F., 2002, Proceedings of ACM SIGGRAPH
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Paquette E., 2002, P GRAPHICS INTERFACE
   Pauly M., 2005, P ACM SIGGRAPH
   Raghavachary S., 2002, ACM SIGGRAPH 2002 C, P187
   SKJELTORP AT, 1988, NATURE, V335, P424, DOI 10.1038/335424a0
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Worley S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P291, DOI 10.1145/237170.237267
   WYVILL B, 2004, P 3 INT S NONPH AN R
NR 31
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2012
VL 28
IS 6-8
BP 869
EP 875
DI 10.1007/s00371-012-0698-8
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 947EW
UT WOS:000304411500034
DA 2024-07-18
ER

PT J
AU Song, YQ
   Jin, SY
AF Song, Yuqing
   Jin, Shuyuan
TI Matching sequences of salient contour points characterized by Voronoi
   region features
SO VISUAL COMPUTER
LA English
DT Article
DE Shape matching; Voronoi tree; Restricted merge-split edit distance;
   Cyclic similarity
ID OBJECT RECOGNITION; SHAPE; DISTANCE
AB In this paper, we introduce a shape matching method by matching sequences of salient contour points that are characterized by Voronoi region features. The proposed approach is summarized as follows: (1) a sequence of salient contour points is selected using the Voronoi diagram of the contour point set, (2) the features of the salient points are computed based on the interior and exterior regions of the Voronoi diagram, and (3) a cyclic edit distance is used to match two shapes. Tests on the MPEG-7 and ETH-80 datasets demonstrated the effectiveness and efficiency of the proposed method.
C1 [Song, Yuqing] Tianjin Univ Technol & Educ, Tianjin 300222, Peoples R China.
   [Jin, Shuyuan] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
C3 Tianjin University of Technology & Education; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS
RP Song, YQ (corresponding author), Tianjin Univ Technol & Educ, 1310 Dagu S Rd, Tianjin 300222, Peoples R China.
EM yqsong7@gmail.com; jinshuyuan@software.ict.ac.cn
FU Natural Science Foundation of China [61070112, 61070116]; Hi-Tech
   Research and Development Program of China (863 Program) [2009AA01Z317]
FX This paper is partially supported by Natural Science Foundation of China
   under contracts no. 61070112 and no. 61070116, and Hi-Tech Research and
   Development Program of China (863 Program) under contract no.
   2009AA01Z317.
CR Adoram M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P597, DOI 10.1109/MMCS.1999.778552
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1975, P 16 ANN IEEE S FDN
   [Anonymous], 1997, ACM SIGACT NEWS
   [Anonymous], 2003, CVPR
   ARCELLI C, 1992, PATTERN RECOGN LETT, V13, P237, DOI 10.1016/0167-8655(92)90074-A
   ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509
   Attali D, 1997, COMPUT VIS IMAGE UND, V67, P261, DOI 10.1006/cviu.1997.0536
   Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Bille P, 2005, THEOR COMPUT SCI, V337, P217, DOI 10.1016/j.tcs.2004.12.030
   Bille P., 2003, TR200335 IT U COP
   Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154
   Ding L., 2008, P INT C PATT REC ICP
   Felzenszwalb P., 2007, CVPR
   Hagedoorn M, 1999, INT J COMPUT VISION, V31, P203, DOI 10.1023/A:1008022116857
   Hiransakolwong N, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P257, DOI 10.1109/ICME.2004.1394174
   Klein P, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P696
   Klein P. N., 1998, Algorithms - ESA '98. 6th Annual European Symposium. Proceedings, P91
   Lee YH, 1996, 10TH INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM - PROCEEDINGS OF IPPS '96, P424, DOI 10.1109/IPPS.1996.508090
   MAES M, 1990, INFORM PROCESS LETT, V35, P73, DOI 10.1016/0020-0190(90)90109-B
   Marzal A, 2005, LECT NOTES COMPUT SC, V3687, P644
   McNeill G., 2006, INT C PATT REC
   Mokhtarian F., 1996, Proceedings of International Workshop on Image Databases and Multimedia Search, P35
   PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6
   PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U
   Rote G., 2004, P 20 EUR WORKSH COMP, P147
   Sclaroff S, 1997, PATTERN RECOGN, V30, P627, DOI 10.1016/S0031-3203(96)00108-2
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sebastian TB, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P22, DOI 10.1109/ICIP.2001.958041
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Super BJ, 2003, P SOC PHOTO-OPT INS, V5267, P228, DOI 10.1117/12.519095
   Super BJ, 2004, IEEE WORKSH LEARN CO
   Tyng-Luh Liu, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P456, DOI 10.1109/ICCV.1999.791256
   VELTKAMP RC, 2001, UUCS200103
   Yang Xingwei., 2009, CVPR
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhu SC, 1996, INT J COMPUT VISION, V20, P187
NR 38
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2012
VL 28
IS 5
BP 475
EP 491
DI 10.1007/s00371-011-0643-2
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 926EJ
UT WOS:000302813800005
DA 2024-07-18
ER

PT J
AU Yuan, Z
   Zhao, Y
   Chen, F
AF Yuan, Zhi
   Zhao, Ye
   Chen, Fan
TI Incorporating stochastic turbulence in particle-based fluid simulation
SO VISUAL COMPUTER
LA English
DT Article
DE Fluid simulation; SPH; Stochastic turbulence; Swirling probability;
   Swirling incentive particle
AB We propose a new fluid modeling technique aimed at incorporating stochastic turbulence into a widely used Lagrangian fluid solver, the Smoothed Particle Hydrodynamics (SPH) method. We add to each SPH particle a swirling probability to model its likelihood to act as a swirling incentive particle (SIP). Particles are selected as a SIP randomly based on the probability, and a SIP spins its neighboring particles to rotate around itself by applying rotational force. The force is computed from a swirling vorticity of the SIP. We model the production, development, and spreading of the swirling probability and vorticity among all SPH particles. The algorithm inherently implements preferred turbulence evolution including vortex aggregation and decay. The turbulent effects are non-repeating and easily controlled by animators. Our method is fully integrated with the SPH scheme with minimal extra memory usage, computational load, and programming efforts.
C1 [Yuan, Zhi; Zhao, Ye; Chen, Fan] Kent State Univ, Dept Comp Sci, Kent, OH 44242 USA.
C3 University System of Ohio; Kent State University; Kent State University
   Kent; Kent State University Salem
RP Zhao, Y (corresponding author), Kent State Univ, Dept Comp Sci, Kent, OH 44242 USA.
EM zyuan@cs.kent.edu; zhao@cs.kent.edu; fchen@cs.kent.edu
FU NSF [IIS-0916131]; Div Of Information & Intelligent Systems; Direct For
   Computer & Info Scie & Enginr [0916131] Funding Source: National Science
   Foundation
FX This work is in part supported by NSF grant IIS-0916131. We thank the
   anonymous reviewers for helpful reviews and Dr. Arden Ruttan for
   improving the paper.
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   [Anonymous], COMPUTER GR IN PRESS
   [Anonymous], P ACM SIGGRAPH EUR S
   [Anonymous], 1995, Turbulence: The Legacy of A. N. Kolmogrov
   [Anonymous], P 8 INT S FLOW MOD T
   [Anonymous], 2008, Fluid Simulation for Computer Graphics
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Hong J., 2008, ACM SIGGRAPH 2008 papers, P1
   Keiser R., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P125, DOI 10.1109/PBG.2005.194073
   Kim Taewoon., 2008, Proceedings of the 2008 ACM CoNEXT Conference, CoNEXT '08, p57:1, DOI DOI 10.1145/1544012.1544069
   Kristof P, 2009, COMPUT GRAPH FORUM, V28, P219, DOI 10.1111/j.1467-8659.2009.01361.x
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   Monaghan JJ, 2002, MON NOT R ASTRON SOC, V335, P843, DOI 10.1046/j.1365-8711.2002.05678.x
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Narain Rahul., 2008, ACM SIGGRAPH Asia 2008 Papers, SIGGRAPH Asia'08, p166:1, DOI DOI 10.1145/1457515.1409119
   Park S. I., 2005, Computer Animation, Conference Proceedings, P261, DOI [DOI 10.1145/1073368.1073406, 10.1145/1073368.1073406]
   Pfaff T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618467
   Pope S. P., 2000, Turbulent Flows, DOI 10.1017/CBO9780511840531
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Sin F., 2009, P ACM SIGGRAPH EUR S, P247, DOI DOI 10.1145/1599470.1599502
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J., 1993, Computer Graphics Proceedings, P369, DOI 10.1145/166117.166163
   Yan H, 2009, COMPUT ANIMAT VIRT W, V20, P417, DOI 10.1002/cav.300
NR 35
TC 14
Z9 14
U1 0
U2 17
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2012
VL 28
IS 5
BP 435
EP 444
DI 10.1007/s00371-011-0626-3
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 926EJ
UT WOS:000302813800002
DA 2024-07-18
ER

PT J
AU Hoang, TD
   Low, KL
AF Hoang, Thai-Duong
   Low, Kok-Lim
TI Efficient screen-space approach to high-quality multiscale ambient
   occlusion
SO VISUAL COMPUTER
LA English
DT Article
DE Ambient occlusion; Multiresolution; Screen-space; Bilateral upsampling;
   Global illumination
AB We present a new screen-space ambient occlusion (SSAO) algorithm that improves on the state-of-the-art SSAO methods in both performance and quality. Our method computes ambient occlusion (AO) values at multiple image resolutions and combines them to obtain the final, high-resolution AO value for each image pixel. It produces high-quality AO that includes both high-frequency shadows due to nearby, occluding geometry and low-frequency shadows due to distant geometry. Our approach only needs to use very small sampling kernels at every resolution, thereby achieving high performance without resorting to random sampling. As a consequence, our results do not suffer from noise and excessive blur, which are common of other SSAO methods. Therefore, our method also avoids the expensive, final blur pass commonly used in other SSAO methods. The use of multiple resolutions also helps reduce errors that are caused by SSAO's inherent lack of visibility checking. Temporal incoherence caused by using coarse resolutions is solved with an optional temporal filtering pass. Our method produces results that are closer to ray-traced solutions than those of any existing SSAO methods, while running at similar or higher frame rates than the fastest ones.
C1 [Hoang, Thai-Duong; Low, Kok-Lim] Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
C3 National University of Singapore
RP Hoang, TD (corresponding author), Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
EM duong@comp.nus.edu.sg; lowkl@comp.nus.edu.sg
CR [Anonymous], ADV GLOBAL ILLUMINAT
   [Anonymous], 2009, P S INT 3D GRAPH GAM, DOI 10.1145/1507149.1507161.5,7
   Bavoil L., 2008, ACM SIGGRAPH 2008
   Bavoil L, 2009, ACM SIGGRAPH 2009
   Bunnell Michael., 2005, GPU GEMS, V2, P223
   Christensen P, 2008, 0801 PIX
   Filion D., 2008, SIGGRAPH 08, P133, DOI DOI 10.1145/1404435.1404441
   Fox M., 2008, GAME DEV MAG     MAR
   Glassner A. S., 1995, Principles of Digital Image Synthesis
   Hoberock J., 2007, GPU Gems 3, P257
   Kautz J., 2004, P 15 EUROGRAPHICS C, P179
   Keller A, 2001, SPRING EUROGRAP, P269
   Kontkanen Janne, 2005, P 2005 S INT 3D GRAP, P41, DOI 10.1145/1053427.1053434
   Kopf J., 2007, P ACM SIGGRAPH 2007
   Laine S, 2010, COMPUT GRAPH FORUM, V29, P1325, DOI 10.1111/j.1467-8659.2010.01728.x
   LANDIS H, 2002, SIGGRAPH 2002, P331
   Loos B.J., 2010, Proc. ACM SIGGRAPH Symp. Interactive 3D Graph. and Games, Washington, P151, DOI DOI 10.1145/1730804.1730829
   Malmer M., 2007, Journal of Graphics Tools, V12, P59
   Mattausch O, 2010, COMPUT GRAPH FORUM, V29, P2492, DOI 10.1111/j.1467-8659.2010.01784.x
   McGuire M., 2011, HIGH PERF GRAPH 2011
   McGuire M., 2010, Proceedings of the Conference on High Performance Graphics, HPG '10, P47
   Mittring M., 2007, ACM SIGGRAPH 2007 CO, P97, DOI [DOI 10.1145/1281500.1281671, 10.1145/1281500.1281671]
   Nehab Diego., 2007, Graphics Hardware
   Nichols G., 2009, P 2009 S INTERACTIVE, P83, DOI DOI 10.1145/1507149.1507162
   Nichols G, 2010, IEEE T VIS COMPUT GR, V16, P729, DOI 10.1109/TVCG.2009.97
   Nichols G, 2009, COMPUT GRAPH FORUM, V28, P1141, DOI 10.1111/j.1467-8659.2009.01491.x
   Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020
   Reinbothe C., 2009, EUR 2009 AR
   Ren Z, 2006, ACM T GRAPHIC, V25, P977, DOI 10.1145/1141911.1141982
   Scherzer Daniel, 2007, P 18 EUR C REND TECH, P45
   Shanmugam P, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P73
   Shishkovtsov O, 2005, DEFERRED SHADING STA, P143
   Sloan PP, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P97, DOI 10.1109/PG.2007.28
   Smedberg N., 2009, GAME DEV C
   Soler C., 2010, ACM SIGGRAPH 2010, P18
   Szirmay-Kalos L, 2010, IEEE COMPUT GRAPH, V30, P70, DOI 10.1109/MCG.2010.19
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhou K, 2005, ACM T GRAPHIC, V24, P1196, DOI 10.1145/1073204.1073332
   Zhukov S., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P45
NR 39
TC 2
Z9 3
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2012
VL 28
IS 3
BP 289
EP 304
DI 10.1007/s00371-011-0639-y
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 896QS
UT WOS:000300585400005
DA 2024-07-18
ER

PT J
AU Mohamed, W
   Ben Hamza, A
AF Mohamed, Waleed
   Ben Hamza, A.
TI Reeb graph path dissimilarity for 3D object matching and retrieval
SO VISUAL COMPUTER
LA English
DT Article
DE Skeletal graph; Morse theory; Shortest path; 3D matching and retrieval
AB We introduce a skeletal graph for topological 3D shape representation using Morse theory. The proposed skeletonization algorithm encodes a 3D shape into a topological Reeb graph using a normalized mixture distance function. We also propose a novel graph matching algorithm by comparing the relative shortest paths between the skeleton endpoints. Experimental results demonstrate the feasibility of the proposed topological Reeb graph as a shape signature for 3D object matching and retrieval.
C1 [Mohamed, Waleed; Ben Hamza, A.] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Ben Hamza, A (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM hamza@ciise.concordia.ca
RI Hamza, Abdessamad Ben/G-4571-2013
OI Ben Hamza, Abdessamad/0000-0002-3778-8167
FU NSERC
FX This work was supported in part by NSERC Discovery Grant.
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   Aouada D, 2010, IEEE T IMAGE PROCESS, V19, P306, DOI 10.1109/TIP.2009.2034693
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Damon J, 2007, INT J COMPUT VISION, V74, P103, DOI 10.1007/s11263-006-0004-1
   Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y
   do Carmo MP., 1992, RIEMANNIAN GEOMETRY
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Fomenko A.T., 1997, TOPOLOGICAL MODELING
   Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x
   Grigorishin T, 1998, PATTERN ANAL APPL, V1, P163, DOI 10.1007/BF01259366
   Guillemin V, 1974, Differential topology
   Hassouna MS, 2009, IEEE T PATTERN ANAL, V31, P2257, DOI 10.1109/TPAMI.2008.271
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   LAZARUS F., 1999, P ACM S SOL MOD APPL, P130, DOI [DOI 10.1145/304012.304025, 10.1145/304012.304025]
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Milnor J. W., 1963, Morse Theory, V51
   Mohamed W., 2011, COMP GRAPH INT OTT
   Ni XL, 2004, ACM T GRAPHIC, V23, P613, DOI 10.1145/1015706.1015769
   Nielson G. M., 1989, Mathematical Methods in Computer Aided Geometric Design, P445
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239509
   Patanè G, 2009, IEEE T VIS COMPUT GR, V15, P583, DOI 10.1109/TVCG.2009.22
   Reuter M, 2010, INT J COMPUT VISION, V89, P287, DOI 10.1007/s11263-009-0278-1
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P66, DOI 10.1109/38.90568
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Tagliasacchi Andrea, 2009, ACM T GRAPH, V28
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
NR 35
TC 30
Z9 31
U1 0
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2012
VL 28
IS 3
BP 305
EP 318
DI 10.1007/s00371-011-0640-5
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 896QS
UT WOS:000300585400006
DA 2024-07-18
ER

PT J
AU Pinto, FD
   Freitas, CMD
AF Pinto, Francisco de Moura
   Dal Sasso Freitas, Carla Maria
TI Dynamic Voronoi diagram of complex sites
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Conference on the Computer Graphics International (CGI)
CY JUN 12-15, 2011
CL Ottawa, CANADA
DE Dynamic; Voronoi diagram
ID COMPUTATION; SEGMENTS
AB The Voronoi diagram (VD) is a fundamental geometric structure in many applications. There are fast and simple algorithms to construct the VD of static point sets. For complex sites (i.e., other than points) the algorithms are more sophisticated, and a few efficient solutions exist. However, updating the VD of dynamic sites is still challenging, and efficient solutions exist only for points. We propose an algorithm for constructing and updating the VD of large dynamic sets of complex sites. Although existing incremental algorithms allow fast insertion of complex sites, this work presents the first efficient implementation of the removal operation.
C1 [Pinto, Francisco de Moura; Dal Sasso Freitas, Carla Maria] Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Pinto, FD (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, Av Bento Goncalves 9500,Bldg 43425, Porto Alegre, RS, Brazil.
EM fmpinto@inf.ufrgs.br; carla@inf.ufrgs.br
RI /H-3333-2011
OI /0000-0003-1986-8435
CR AICHHOLZER O, 2010, COMPUT GEOM THEORY A, V43
   ALT H, 1995, SCG 95, P89
   [Anonymous], P 8 CAN C COMP GEOM
   Devillers O., 1999, Proceedings of the Fifteenth Annual Symposium on Computational Geometry, P181, DOI 10.1145/304893.304969
   FISCHER I, 2005, TR0705 HARV U
   FORTUNE S, 1986, SCG 86, P313
   GOLD C, 1998, ALGORITHMICA SPECIAL
   GREEN PJ, 1978, COMPUT J, V21, P168, DOI 10.1093/comjnl/21.2.168
   GUIBAS L, 1985, ACM T GRAPHIC, V4, P74, DOI 10.1145/282918.282923
   GUIBAS LJ, 1992, WG 91 P 17 INT WORKS, P113
   Held M, 2001, COMP GEOM-THEOR APPL, V18, P95, DOI 10.1016/S0925-7721(01)00003-7
   Held M, 2009, COMPUT AIDED DESIGN, V41, P327, DOI 10.1016/j.cad.2008.08.004
   Hoff KennethE., 1999, SIGGRAPH
   KARAVELAS M, 2003, EUR S ALG
   MOSTAFAVI MA, 2003, DYNAMIC VORONOI DELA
   PINTO FD, 2009, SIBGRAPI
   SUD A, 2008, SIGGRAPH 08 ACM SIGG, P1
   YAP CK, 1987, DISCRETE COMPUT GEOM, V2, P365, DOI 10.1007/BF02187890
NR 18
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2011
VL 27
IS 6-8
BP 463
EP 472
DI 10.1007/s00371-011-0581-z
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 766FY
UT WOS:000290767600006
DA 2024-07-18
ER

PT J
AU Chung, F
   Schmid, J
   Magnenat-Thalmann, N
   Delingette, H
AF Chung, Francois
   Schmid, Jerome
   Magnenat-Thalmann, Nadia
   Delingette, Herve
TI Comparison of statistical models performance in case of segmentation
   using a small amount of training datasets
SO VISUAL COMPUTER
LA English
DT Article
DE Model based segmentation; Statistical models; Principal component
   analysis; Clustering
ID APPEARANCE MODELS; SHAPE; ALGORITHM; MRI
AB Model-based image segmentation has been extensively used in medical imaging to learn both the shape and appearance of anatomical structures from training datasets. The more training datasets are used, the more accurate is the segmented model, as we account for more information about its variability. However, training datasets of large size with a proper sampling of the population may not always be available. In this paper, we compare the performance of statistical models in the context of lower limb bones segmentation using MR images when only a small number of datasets is available for training. For shape, both PCA-based priors and shape memory strategies are tested. For appearance, methods based on intensity profiles are tested, namely mean intensity profiles, multivariate Gaussian distributions of profiles and multimodal profiles from EM clustering. Segmentation results show that local and simple methods perform the best when a small number of datasets is available for training. Conversely, statistical methods feature the best segmentation results when the number of training datasets is increased.
C1 [Chung, Francois; Delingette, Herve] INRIA Sophia Antipolis, Asclepios Res Team, F-06902 Sophia Antipolis, France.
   [Schmid, Jerome; Magnenat-Thalmann, Nadia] Univ Geneva, MIRALab, CH-1227 Carouge, Switzerland.
   [Magnenat-Thalmann, Nadia] Nanyang Technol Univ, Singapore, Singapore.
C3 University of Geneva; Nanyang Technological University
RP Chung, F (corresponding author), INRIA Sophia Antipolis, Asclepios Res Team, BP 93,2004 Route Lucioles, F-06902 Sophia Antipolis, France.
EM francois.chung@inria.fr; jerome.schmid@miralab.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960; Chung,
   Francois/0000-0003-0742-6621; Delingette, Herve/0000-0001-6050-5949;
   Schmid, Jerome/0000-0003-2464-8971
CR Ambroise C, 1997, QUANT GEO G, V9, P493
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   Behiels G, 2002, MED IMAGE ANAL, V6, P47, DOI 10.1016/S1361-8415(01)00051-2
   Chung F, 2009, LECT NOTES COMPUT SC, V5762, P1051, DOI 10.1007/978-3-642-04271-3_127
   COOTES T, 1996, BMVC 1996
   Cootes T. F., 1993, Information Processing in Medical Imaging. 13th International Conference, IPMI '93 Proceedings, P33, DOI 10.1007/BFb0013779
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Delingette H, 1999, INT J COMPUT VISION, V32, P111, DOI 10.1023/A:1008157432188
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Gilles B, 2010, MED IMAGE ANAL, V14, P291, DOI 10.1016/j.media.2010.01.006
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Heimann T, 2007, LECT NOTES COMPUT SC, V4584, P1
   Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004
   Holden M, 1999, LECT NOTES COMPUT SC, V1613, P472
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kim DW, 2004, PATTERN RECOGN, V37, P2009, DOI 10.1016/j.patcog.2004.04.007
   Schäfer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175
   Schmid J., 2010, 2010 International Conference on Indoor Positioning and Indoor Navigation (IPIN), P1, DOI [DOI 10.1109/IPIN.2010.5646831, 10.1109/IPIN. 2010.5646831]
   Schmid J, 2009, RECENT ADVANCES IN THE 3D PHYSIOLOGICAL HUMAN, P3, DOI 10.1007/978-1-84882-565-9_1
   Schmid J, 2008, LECT NOTES COMPUT SC, V5241, P119, DOI 10.1007/978-3-540-85988-8_15
   Seim H., 2008, EG VCBM 2008 - Eurographics Workshop on Visual Computing for Biomedicine, P93
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728
NR 24
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2011
VL 27
IS 2
SI SI
BP 141
EP 151
DI 10.1007/s00371-010-0536-9
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 722QR
UT WOS:000287449900007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kahlert, J
   Olson, M
   Zhang, H
AF Kahlert, Joe
   Olson, Matt
   Zhang, Hao
TI Width-bounded geodesic strips for surface tiling
SO VISUAL COMPUTER
LA English
DT Article
DE Geodesics; Surface tiling; Straight strips
ID PARAMETERIZATION
AB We present an algorithm for computing families of geodesic curves over an open mesh patch to partition the patch into strip-like segments. Specifically, the segments can be well approximated using strips obtained by trimming long, rectangular pieces of material having a prescribed width delta. We call this the width-bounded geodesic strip tiling of a curved surface, a problem with practical applications such as the surfacing of curved roofs. The strips are said to be straight since they are constrained to fit within rectangles of width delta, in contrast to arbitrary, possible highly curved, strip segments. The straightness criterion, as well as a bound on strip widths, distinguishes our problem from ones previously studied for developable surface decomposition.
   We start with a geodesic curve defined by a user-specified starting point and direction on the input mesh. We then iteratively compute the neighboring geodesics which respect the constraints and lead to optimal use of material (i.e., minimizing the trimmed material) until the surface mesh in question is completely tiled. Our algorithm is exact with respect to the polyhedral geometry of the mesh surface, and it runs on a variety of surfaces with a modest time complexity of O(n (1.5)) under reasonable input parameter settings, where n is the mesh size. We also show how the algorithm can be extended by relaxing the constraint that neighboring geodesics span the mesh, thus allowing the algorithm to be applied to meshes with greater undulation.
C1 [Kahlert, Joe; Olson, Matt; Zhang, Hao] Simon Fraser Univ, Sch Comp Sci, Graph Usabil & Visualizat GrUVi Lab, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Zhang, H (corresponding author), Simon Fraser Univ, Sch Comp Sci, Graph Usabil & Visualizat GrUVi Lab, Burnaby, BC V5A 1S6, Canada.
EM haoz@cs.sfu.ca
RI li, jinsong/HJH-9559-2023; Zhang, Hao/HHM-1940-2022
OI Zhang, Hao/0000-0003-1991-119X
FU MITACS
FX The authors would first like to thank the anonymous reviewers for their
   valuable feedback. Thanks should also go to Dr. Alla Sheffer and several
   members of the Graphics Usability and Visualization (GrUVi) lab at Simon
   Fraser University (SFU), specifically Dr. Ramsay Dyer and Oliver van
   Kaick, for their discussions on the paper and the ideas therein. This
   work has been supported in part by an MITACS Internship grant entitled
   "Covering Surfaces with Strips."
CR Aleksandrov A. D., 1967, INTRINSIC GEOMETRY S
   Alliez Pierre., 2005, RECENT ADV REMESHING
   [Anonymous], 2008, P 2008 ACM S SOL PHY
   Berger Marcel., 2000, PANORAMIC VIEW RIEMA
   Bommes D., 2007, Proceedings of the Vision, Modeling, and Visualization Conference 2007, VMV 2007, Saarbrcken, Germany, November 7-9, 2007, P151
   Carmo Do., 1976, DIFFERENTIAL GEOMETR
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Grundig L., 1996, P AS PAC C SHELL SPA
   KIMMEL R., 1998, COMPUTING GEODESIC P
   Liu Y, 2006, ACM T GRAPHIC, V25, P681, DOI 10.1145/1141911.1141941
   Liu YJ, 2007, VISUAL COMPUT, V23, P661, DOI 10.1007/s00371-007-0136-5
   MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045
   PATERNAIN G. P, 1999, Progress in Mathematics, V180
   Pogorelov A.V., 1949, Mat. Sbornik, V67, P275
   Polthier K., 1999, Data Visualization '99. Proceedings of the Joint EUROGRAPHICS and IEEE TCVG Symposium on Visualization, P179
   Polthier K., 2006, ACM SIGGRAPH 2006 CO, P30
   Pottmann H., 2007, Architectural Geometry
   Pottmann H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778780
   Pottmann H, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360675
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   Strobel D, 2000, P INT C COMP SHELL S
   Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228
   Vanecek P, 2007, COMPUT GRAPH-UK, V31, P100, DOI 10.1016/j.cag.2006.10.003
NR 24
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2011
VL 27
IS 1
BP 45
EP 56
DI 10.1007/s00371-010-0513-3
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 700YI
UT WOS:000285781100004
DA 2024-07-18
ER

PT J
AU Yamazaki, I
   Natarajan, V
   Bai, ZJ
   Hamann, B
AF Yamazaki, Ichitaro
   Natarajan, Vijay
   Bai, Zhaojun
   Hamann, Bernd
TI Segmenting point-sampled surfaces
SO VISUAL COMPUTER
LA English
DT Article
DE Point sets; Sampling; Features; Geodesic distance; Normalized cut;
   Topological methods; Spectral analysis; Multiphase segmentation;
   Hierarchical segmentation
ID PARAMETERIZATION; MESHES
AB Extracting features from point-based representations of geometric surface models is becoming increasingly important for purposes such as model classification, matching, and exploration. In an earlier paper, we proposed a multiphase segmentation process to identify elongated features in point-sampled surface models without the explicit construction of a mesh or other surface representation. The preliminary results demonstrated the strength and potential of the segmentation process, but the resulting segmentations were still of low quality, and the segmentation process could be slow. In this paper, we describe several algorithmic improvements to overcome the shortcomings of the segmentation process. To demonstrate the improved quality of the segmentation and the superior time efficiency of the new segmentation process, we present segmentation results obtained for various point-sampled surface models. We also discuss an application of our segmentation process to extract ridge-separated features in point-sampled surfaces of CAD models.
C1 [Yamazaki, Ichitaro; Bai, Zhaojun] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Hamann, Bernd] IDAV, Dept Comp Sci, Davis, CA 95616 USA.
   [Natarajan, Vijay] Indian Inst Sci, Dept Comp Sci & Automat, Supercomp Educ & Res Ctr, Bangalore 560012, Karnataka, India.
C3 University of California System; University of California Davis; Indian
   Institute of Science (IISC) - Bangalore
RP Yamazaki, I (corresponding author), Lawrence Berkeley Natl Lab, Computat Res Div, Berkeley, CA USA.
EM yamazaki@cs.ucdavis.edu; vijayn@csa.iisc.ernet.in; bai@cs.ucdavis.edu;
   hamann@cs.ucdavis.edu
FU National Science Foundation [0313390, 0611548, ACI 9624034]; Information
   Technology Research (ITR); Indian Institute of Science; Direct For
   Mathematical & Physical Scien; Division Of Materials Research [0313390]
   Funding Source: National Science Foundation; Direct For Mathematical &
   Physical Scien; Division Of Mathematical Sciences [0611548] Funding
   Source: National Science Foundation
FX The point sets used in our experiments were downloaded from on-line 3D
   scan repositories [54, 55]. We used qslim [56] to generate coarse point
   sets. Yamazaki and Bai were supported in part by the National Science
   Foundation grants 0313390 and 0611548. Natarajan and Hamann were
   supported in part by the National Science Foundation grant under
   contracts ACI 9624034 (CAREER Award) and a large Information Technology
   Research (ITR) grant. Natarajan was also supported by a faculty startup
   grant from the Indian Institute of Science. We thank the members of the
   Visualization and Computer Graphics Research Group at the Institute for
   Data Analysis and Visualization (IDAV) at the University of California,
   Davis for helpful discussions.
CR [Anonymous], P 19 DES AUT C
   [Anonymous], P WORKSH ALG DAT STR
   [Anonymous], 1963, MORSE THEORY AM 51, DOI [10.1515/9781400881802, DOI 10.1515/9781400881802]
   Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P14
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Biasotti S, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P245
   Bremer PT, 2004, IEEE T VIS COMPUT GR, V10, P385, DOI 10.1109/TVCG.2004.3
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   EDELSBRUNNER H, 2006, SCG 06, P127
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   GARLAND M, 2010, QSLIM SIMPLIFICATION
   Gotsman C, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P165
   Gregory A, 1999, VISUAL COMPUT, V15, P453, DOI 10.1007/s003710050192
   Gross M, 2006, IEEE COMPUT GRAPH, V26, P96, DOI 10.1109/MCG.2006.106
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kernighan B. W., 1970, The Bell System Technical Journal, V49, P291, DOI [10.1002/j.1538-7305.1970.tb01770.x, DOI 10.1002/J.1538-7305.1970.TB01770.X]
   Lee Y, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P279
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343
   Liu R, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P298
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Matsumoto Y, 2002, INTRO MORSE THEORY A
   MOUNT DM, 2010, ARYA LIB APPROXIMATE
   Natarajan V, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P320, DOI 10.1109/SMI.2005.50
   Page DL, 2003, PROC CVPR IEEE, P27
   Patanè G, 2004, COMPUT GRAPH FORUM, V23, P783, DOI 10.1111/j.1467-8659.2004.00808.x
   Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319
   Pfister H, 2004, IEEE COMPUT GRAPH, V24, P22, DOI 10.1109/MCG.2004.15
   ROGER P, 2003, ACM COMPUT SURV, V182, P167
   SAINZ M., 2004, Proceedings of Eurographics Symposium on Point-Based Graphics 2004, P121
   Sander P. V., 2003, Symposium on Geometry Processing, P146
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   Schloegel K., 2003, Sourcebook of parallel computing. chapter Graph Partitioning for High-performance Scientific Simulations, P491
   SHALFMAN S, 2002, P EUROGRAPH, V21, P219
   SHAMIR A, 2004, 3DPVT 04, P82, DOI DOI 10.1109/3DPVT.2004.13
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Vapnik V., 1999, NATURE STAT LEARNING
   Yamauchi H, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P236, DOI 10.1109/SMI.2005.21
   YAMAZAKI I, 2006, SMI 06, P4
   Zhang E, 2005, ACM T GRAPHIC, V24, P1, DOI 10.1145/1037957.1037958
   ZHOU K, 2004, SGP 04, P45
   Zhou YN, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P187
   ZOCKLER M, 2004, VISUAL COMPUT, V16, P241
   Zuckerberger E, 2002, COMPUT GRAPH-UK, V26, P733, DOI 10.1016/S0097-8493(02)00128-0
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
   2010, LEVEL DETAIL 3D GRAP
NR 55
TC 10
Z9 12
U1 0
U2 13
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2010
VL 26
IS 12
BP 1421
EP 1433
DI 10.1007/s00371-010-0428-z
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 678WA
UT WOS:000284112400001
DA 2024-07-18
ER

PT J
AU Tu, SC
   Tai, WK
   Isenburg, M
   Chang, CC
AF Tu, Shih-Chun
   Tai, Wen-Kai
   Isenburg, Martin
   Chang, Chin-Chen
TI An improved data hiding approach for polygon meshes
SO VISUAL COMPUTER
LA English
DT Article
DE Data hiding; Permutation steganography
ID WATERMARKING; STEGANOGRAPHY; ALGORITHM
AB We present an improved technique for data hiding in polygonal meshes, which is based on the work of Bogomjakov et al. (Comput. Graph. Forum 27(2):637-642, 2008). Like their method, we use an arrangement on primitives relative to a reference ordering to embed a message. But instead of directly interpreting the index of a primitive in the reference ordering as the encoded/decoded bits, our method slightly modifies the mapping so that our modification doubles the chance of encoding an additional bit compared to Bogomjakov et al.'s (Comput. Graph. Forum 27(2):637-642, 2008). We illustrate the inefficiency in the original mapping of Bogomjakov et al. (Comput. Graph. Forum 27(2):637-642, 2008) with an intuitive representation using a binary tree.
   Although both methods have the same minimal and maximal capacities and are both only one bit per primitive less than optimal, our method improves the average capacity up to 0.63 bits per primitive. Our embedding and extraction algorithms are just as simple to implement and just as efficient, O(n), as those of Bogomjakov et al. (Comput. Graph. Forum 27(2):637-642, 2008).
C1 [Tu, Shih-Chun; Tai, Wen-Kai] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Shoufeng 974, Hualien, Taiwan.
   [Isenburg, Martin] Lawrence Livermore Natl Lab, Livermore, CA USA.
   [Chang, Chin-Chen] Natl United Univ, Dept Comp Sci & Informat Engn, Kungching Li 360, Miaoli, Taiwan.
C3 National Dong Hwa University; United States Department of Energy (DOE);
   Lawrence Livermore National Laboratory; National United University
RP Tai, WK (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, 1,Sec 2,Da Hsueh Rd, Shoufeng 974, Hualien, Taiwan.
EM tusjtu@ms01.dahan.edu.tw; wktai@mail.ndhu.edu.tw; isenburg1@llnl.gov
RI Chang, Ching-Chun/JAN-6210-2023
FU National Science Council of Taiwan [NSC 98-2221-E-259025]; U.S.
   Department of Energy [W-7405-Eng-48]
FX This work is in part supported by the National Science Council of Taiwan
   Under grant number NSC 98-2221-E-259025 and was in part performed under
   the auspices of the U.S. Department of Energy by Lawrence Livermore
   National Laboratory under contract no. W-7405-Eng-48. Moreover, the
   authors wish to thank reviewers for their useful feedbacks and advices.
CR Artz D, 2001, IEEE INTERNET COMPUT, V5, P75, DOI 10.1109/4236.935180
   Aspert N, 2002, PROC SPIE, V4790, P211, DOI 10.1117/12.455358
   Benedens O, 1999, IEEE COMPUT GRAPH, V19, P46, DOI 10.1109/38.736468
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   CAYRE F, 2004, INRIA RES REP, V5223, P211
   Cheng YM, 2007, VISUAL COMPUT, V23, P721, DOI 10.1007/s00371-007-0147-2
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Cotting D, 2004, SMI 04, P233
   KANAI S, 1998, P 6 IFIP WG 5 2 GEO, P296
   Maret Y., 2004, P 2004 WORKSH MULT S, P68
   Ohbuchi R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P261, DOI 10.1145/266180.266377
   Ohbuchi R, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P392, DOI 10.1109/CW.2004.70
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Ohbuchi R., 2001, Graphics Interface, P9
   Praun E, 1999, COMP GRAPH, P49, DOI 10.1145/311535.311540
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Wagner M. G., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P201, DOI 10.1109/GMAP.2000.838252
   Wang CM, 2006, COMPUT GRAPH-UK, V30, P244, DOI 10.1016/j.cag.2006.01.030
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang CM, 2005, IEICE T COMMUN, VE88B, P190, DOI 10.1093/ietcom/E88-B.1.190
   WU HT, 2005, WI 05, P774
   Yu ZQ, 2003, PATTERN RECOGN, V36, P2603, DOI 10.1016/S0031-3203(03)00086-4
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
NR 25
TC 11
Z9 13
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2010
VL 26
IS 9
BP 1177
EP 1181
DI 10.1007/s00371-009-0398-1
PG 5
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 635JD
UT WOS:000280650500004
DA 2024-07-18
ER

PT J
AU Chen, WY
   Zheng, JM
   Cai, YY
AF Chen, Wenyu
   Zheng, Jianmin
   Cai, Yiyu
TI Monge mapping using hierarchical NURBS
SO VISUAL COMPUTER
LA English
DT Article
DE Depth; Texture mapping; Hierarchical NURBS; 3D local shape modeling
ID SPLINES; SURFACES
AB Texture mapping is an efficient and effective tool in computer graphics and animation. While computationally very cost-effective, texture mapping may produce non-realistic appearances of shapes in 3D environment, especially when viewing closely. To improve the realism of 3D modeling, bump mapping technique is developed to add details with the 3D models on top of texture mapping. Bump mapping, however, offers only simple and visual enhancement. Displacement mapping technique can further improve the localized detail of geometry. In this paper, Monge mapping technique is developed for detail and local shape modification of NURBS represented geometry in a 3D environment. Based on multiresolution and refinement schemes, Hierarchical NURBS (H-NURBS) is first investigated to design a mechanism for the purpose of carrying localized geometric information. Monge mapping on H-NURBS patch can be easily performed via simple cut-and-paste operation. Parametric control of the local shapes is developed to facilitate easier and better 3D local modeling.
C1 [Chen, Wenyu; Cai, Yiyu] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore.
   [Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Cai, YY (corresponding author), Nanyang Technol Univ, Sch Mech & Aerosp Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM ciweiyu@pmail.ntu.edu.sg; asjmzheng@ntu.edu.sg; myycai@ntu.edu.sg
RI Cai, Yiyu/A-3816-2011; Zheng, Jianmin/A-3717-2011; Chen,
   Wenyu/IQV-0732-2023
OI Cai, Yiyu/0000-0002-8406-9536; Zheng, Jianmin/0000-0002-5062-6226; Chen,
   Wenyu/0000-0002-6448-1806
FU ARC of Singapore [MOE2008-T2-1-075]
FX This work is supported by the ARC 9/09 Grant (MOE2008-T2-1-075) of
   Singapore.
CR [Anonymous], 1987, An Introduction to Splines for use in Computer Graphics Geometric Modeling
   Blinn J., 1978, Proceedings of the 5th annual conference on Computer graphics and interactive techniques-SIGGRAPH'78, V12, P286
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   CATMULL E, 1974, SUBDIVISION ALGORITH, P83
   Chen W., 2008, P 7 ACM SIGGRAPH INT
   COHEN E, 1980, COMPUT VISION GRAPH, V14, P87, DOI 10.1016/0146-664X(80)90040-4
   Cook R. L., 1984, Computers & Graphics, V18, P223
   Cook Robert L, 1987, ACM_SIGGRAPH_Computer_Graphics, V21, P95
   Farin G., 1996, CURVES SURFACES CAGD
   Forsey D. R., 1988, Computer Graphics, V22, P205, DOI 10.1145/378456.378512
   FORSEY DR, 1995, ACM T GRAPHIC, V14, P134, DOI 10.1145/221659.221665
   FOURNIER A, 1992, GRAPH INT 92 WORKSH, P45
   GEOFFREY Y, 1985, P 12 ANN C COMP GRAP
   Gonzalez-Ochen C., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P7, DOI 10.1145/300523.300524
   Heckbert P.S., 1989, Fundamentals of texture mapping and image warping
   LANE JM, 1980, IEEE T PATTERN ANAL, V2, P35, DOI 10.1109/TPAMI.1980.4766968
   Miller G. S., 1984, COURS NOT ADV COMP G
   MORKEN K, 1991, CONSTR APPROX, V7, P195, DOI 10.1007/BF01888153
   OLIVEIRA M, 2000, P 27 ANN C COMP GRAP
   Olsen L, 2007, COMPUT GRAPH-UK, V31, P449, DOI 10.1016/j.cag.2007.01.033
   OLSEN L, 2005, 3 EUR S GEOM PROC
   Piegl L., 1997, The Nurbs Book, Vsecond
   Samavati FF, 2007, SER MACH PERCEPT ART, V67, P65
   Strom K., 1993, Numerical Algorithms, V4, P323, DOI 10.1007/BF02145751
   Wang LF, 2003, ACM T GRAPHIC, V22, P334, DOI 10.1145/882262.882272
   Williams L., 1983, Computer Graphics, V17, P1, DOI 10.1145/964967.801126
   Yvart A, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P13, DOI 10.1109/SMI.2005.43
   Yvart A, 2005, ACM T GRAPHIC, V24, P1374, DOI 10.1145/1095878.1095885
NR 28
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 779
EP 789
DI 10.1007/s00371-010-0475-5
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800038
DA 2024-07-18
ER

PT J
AU Kang, SJ
   Kim, Y
   Kim, CH
AF Kang, Shin-Jin
   Kim, YongO
   Kim, Chang-Hun
TI Live path: adaptive agent navigation in the interactive virtual world
SO VISUAL COMPUTER
LA English
DT Article
DE Agent navigation; Virtual world; Pathfinding; Navigation mesh
AB We present a novel approach to adaptive navigation in the interactive virtual world by using data from the user. Our method constructs automatically a navigation mesh that provides new paths for agents by referencing the user movements. To acquire accurate data samples from all the user data in the interactive world, we use the following techniques: an agent of interest (AOI), a region of interest (ROI) map, and a discretized path graph (DPG). Our method enables adaptive changes to the virtual world over time and provides user-preferred path weights for smart-agent path planning. We have tested the usefulness of our algorithm with several example scenarios from interactive worlds such as video games. In practice, our framework can be applied easily to any type of navigation in an interactive world. In addition, it may prove useful for solving previous pathfinding problems in static navigation planning.
C1 [Kim, Chang-Hun] Korea Univ, Dept Comp Sci, Seoul, South Korea.
   [Kang, Shin-Jin] Hongik Univ, Sch Games, Yongi Gun, Chungnam, South Korea.
   [Kim, YongO] NCSoft, Seoul, South Korea.
C3 Korea University; Hongik University
RP Kim, CH (corresponding author), Korea Univ, Dept Comp Sci, Seoul, South Korea.
EM directx@hongik.ac.kr; koyanghi@korea.com; chkim@korea.ac.kr
FU Hongik University new faculty research
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was supported by the Hongik University new
   faculty research support fund.
CR [Anonymous], COMPUTATIONAL GEOMET
   *BLIZZ, 2009, WORLD WARCR
   *BUNG MICR, 2008, HALO3
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   *INT, 2009, HAV
   KAMPHUIS A, 2004, SCA 04, P19
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Li Y, 2007, IEEE INT CONF ROBOT, P1009, DOI 10.1109/ROBOT.2007.363117
   *NCSOFT, 2009, AION
   Pettré J, 2007, IEEE INT CONF ROBOT, P3062, DOI 10.1109/ROBOT.2007.363937
   Pettré J, 2006, COMPUT ANIMAT VIRT W, V17, P445, DOI 10.1002/cav.147
   Sas C, 2005, FUTURE GENER COMP SY, V21, P1157, DOI 10.1016/j.future.2004.04.003
   STENTZ A, 1995, INT J ROBOT AUTOM, V10, P89
   STOUT B, 2000, GAME PROGRAMMING GEM, P254
   Sud A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P91
   Sud A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P99
   *VALV, 2009, COUNT STRIK SOURC
   van den Berg J, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P139
NR 19
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 467
EP 476
DI 10.1007/s00371-010-0457-7
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800008
DA 2024-07-18
ER

PT J
AU Kim, K
   Lepetit, V
   Woo, W
AF Kim, Kiyoung
   Lepetit, Vincent
   Woo, Woontack
TI Scalable real-time planar targets tracking for digilog books
SO VISUAL COMPUTER
LA English
DT Article
DE Planar target tracking; Augmented reality; Digilog book; Vocabulary tree
AB We propose a novel 3D tracking method that supports several hundreds of pre-trained potential planar targets without losing real-time performance. This goes well beyond the state-of-the-art, and to reach this level of performances, two threads run in parallel: the foreground thread tracks feature points from frame-to-frame to ensure real-time performances, while a background thread aims at recognizing the visible targets and estimating their poses. The latter relies on a coarse-to-fine approach: assuming that one target is visible at a time, which is reasonable for digilog books applications, it first recognizes the visible target with an image retrieval algorithm, then matches feature points between the target and the input image to estimate the target pose. This background thread is more demanding than the foreground one, and is therefore several times slower. We therefore propose a simple but effective mechanism for the background thread to communicate its results to the foreground thread without lag. Our implementation runs at more than 125 frames per second, with 314 potential planar targets. Its applicability is demonstrated with an Augmented Reality book application.
C1 [Kim, Kiyoung; Woo, Woontack] GIST, U VR Lab, DIC, Kwangju, South Korea.
   [Lepetit, Vincent] Ecole Polytech Fed Lausanne, CVLab, CH-1015 Lausanne, Switzerland.
   [Woo, Woontack] GIST, CTI, Kwangju, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Swiss Federal
   Institutes of Technology Domain; Ecole Polytechnique Federale de
   Lausanne; Gwangju Institute of Science & Technology (GIST)
RP Woo, W (corresponding author), GIST, U VR Lab, DIC, Kwangju, South Korea.
EM kkim@gist.ac.kr; vincent.lepetit@epfl.ch; wwoo@gist.ac.kr
RI Woo, Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421
CR [Anonymous], 2007, Proc. CVWW '07
   [Anonymous], 2 IEEE ACM INT WORKS
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Fiala M, 2005, PROC CVPR IEEE, P590
   FRAUENDORFER F, 2008, 3D DATA PROCESSING V
   HA T, 2009, J VIRTUAL R IN PRESS
   Lee T, 2009, IEEE T VIS COMPUT GR, V15, P355, DOI 10.1109/TVCG.2008.190
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister David, 2006, CVPR
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Park J, 2009, LECT NOTES COMPUT SC, V5709, P234, DOI 10.1007/978-3-642-04052-8_26
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Scherrer C, 2008, INT SYM MIX AUGMENT, P163, DOI 10.1109/ISMAR.2008.4637347
   SIMON G, 2000, INT S MIX AUGM REAL, P137
   Taketa N, 2007, LECT NOTES COMPUT SC, V4558, P475
   Wagner D, 2009, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2009.5336497
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
NR 20
TC 25
Z9 26
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 1145
EP 1154
DI 10.1007/s00371-010-0490-6
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800073
DA 2024-07-18
ER

PT J
AU Ma, QL
   Xu, HX
   Zeng, L
   Cai, X
   Li, SK
AF Ma, Qianli
   Xu, Huaxun
   Zeng, Liang
   Cai, Xun
   Li, Sikun
TI Direct raycasting of unstructured cell-centered data by discontinuity
   Roe-average computation
SO VISUAL COMPUTER
LA English
DT Article
DE Unstructured grids; Cell-centered data; CFD visualization;
   Upwind-scheme; Roe-average; Raycasting
AB In the field of computational fluid dynamics (CFD), the upwind finite volume method (FVM) is widely applied to solve 3D flows with discontinuity phenomena (e.g., shock waves). It produces unstructured data at the center of each cell (cell-centered data) with the flow discontinuity constraint on the inner-face between face-neighboring cells. For visualization, existing approaches with interpolation usually pre-extrapolate cell-centered data into cell-vertexed data (data values given at cell vertices) and only handle cell-vertexed data during actual rendering, which unconsciously depress the rendering accuracy and violate the discontinuity constraint. In this paper, we propose a novel method to visualize cell-centered data directly avoiding extrapolation and keep the discontinuity in the rendering data on the framework of multi-pass raycasting. During resampling, the field is reconstructed using the original cell-centered data value and the cell-gradient estimated by Green-Gauss theorem. To keep the discontinuity, we reconstruct the field at an inner-face resampled point using both the face-adjacencies and get two discontinuous field values. Then the field is obtained by computing Roe-average of the two. The analysis and experiments demonstrate that our approach gains a high-accuracy reconstruction and leads to a high-quality image.
C1 [Ma, Qianli; Xu, Huaxun; Li, Sikun] Natl Univ Def Technol, Coll Comp Sci & Technol, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Ma, QL (corresponding author), Natl Univ Def Technol, Coll Comp Sci & Technol, Changsha, Hunan, Peoples R China.
EM maqianliemail@gmail.com; xxhhxx@163.com; liangzeng@263.net.cn;
   cx72838@163.com; lisikun@263.net.cn
FU National Basic Research Program [2009CB723803]; National Science
   Foundation Program of China [60873120]
FX This work is supported by the National Basic Research Program (No.
   2009CB723803) and the National Science Foundation Program (No. 60873120)
   of China. We would like to thank the anonymous reviewers for their
   careful and valuable comments.
CR [Anonymous], [No title captured], DOI DOI 10.1145/99308.99316
   Barth T., 1989, 27 AER SCI M AM I AE
   BERNARDON FF, 2006, J GRAPHICS TOOLS, V11, P1
   BUNYK P, P IEEE VIS 1997, P30
   CORREA CD, 2009, IEEE T VIS COMPUT GR
   FRINK NT, 1992, AIAA J, V30, P70, DOI 10.2514/3.10884
   FRINK NT, 1991, AIAA910102
   Godunov SK, 1959, Mat. Sb. (N. S.), V89, P271
   MAMMEN A, 1989, IEEE COMPUT GRAPH, V9, P43, DOI 10.1109/38.31463
   Max N, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012087
   MCLOUGHLIN T, 2010, COMPUT GRAP IN PRESS
   MITCHELL CR, 1994, 32 AIAA AER SCI M EX
   Muigg P, 2007, IEEE T VIS COMPUT GR, V13, P1592, DOI 10.1109/TVCG.2007.70588
   ROE PL, 1981, J COMPUT PHYS, V43, P357, DOI [10.1016/0021-9991(81)90128-5, 10.1006/jcph.1997.5705]
   ROTTGER S, P IEEE VIS 2000, P109
   SCHNEIDER PJ, 2003, GEOMETRIC TOOLS COMP, P9
   Silva C., 2005, BRAZIL J THEO APPL C, V12, P9
   VAN LEER B, 1979, J COMPUT PHYS, V32, P101, DOI 10.1016/0021-9991(79)90145-1
   WEILER M, P 14 IEEE VIS 2003, P333
NR 19
TC 4
Z9 5
U1 0
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2010
VL 26
IS 6-8
BP 1049
EP 1059
DI 10.1007/s00371-010-0447-9
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602JQ
UT WOS:000278135800064
DA 2024-07-18
ER

PT J
AU Liu, YJ
   Zhang, WQ
   Tang, K
AF Liu, Yong-Jin
   Zhang, Wen-Qi
   Tang, Kai
TI Some notes on maximal arc intersection of spherical polygons: its
   <i>NP</i>-hardness and approximation algorithms
SO VISUAL COMPUTER
LA English
DT Article
DE Spherical polygons intersection; NC machining; NP-hard problem;
   Approximation algorithms
ID SET COVER; WORKPIECE ORIENTATION; PRIORITY ALGORITHMS; 4-AXIS;
   MACHINABILITY
AB Finding a sequence of workpiece orientations such that the number of setups is minimized is an important optimization problem in manufacturing industry. In this paper we present some interesting notes on this optimal workpiece setup problem. These notes show that (1) The greedy algorithm proposed in Comput. Aided Des. 35 (2003), pp. 1269-1285 for the optimal workpiece setup problem has the performance ratio bounded by O(ln n - ln ln n+0.78), where n is the number of spherical polygons in the ground set; (2) In addition to greedy heuristic, linear programming can also be used as a near-optimal approximation solution; (3) The performance ratio by linear programming is shown to be tighter than that of greedy heuristic in some cases.
C1 [Liu, Yong-Jin; Zhang, Wen-Qi] Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Tang, Kai] Hong Kong Univ Sci & Technol, Dept Mech Engn, Kowloon, Hong Kong, Peoples R China.
C3 Tsinghua University; Hong Kong University of Science & Technology
RP Liu, YJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM liuyongjin@tsinghua.edu.cn
RI Tang, Kai/ABA-9642-2021; Liu, Yong/GWQ-6163-2022
OI Tang, Kai/0000-0002-5184-2086; 
FU Natural Science Foundation of China [60736019, 60603085, 60970099];
   Tsinghua SRT Project [091T0261]
FX The work was supported by the Natural Science Foundation of China
   (Project Nos. 60736019, 60603085, 60970099) and the Tsinghua SRT Project
   (Project No. 091T0261).
CR AGARWAL PK, 2008, P 16 EUR S ALG, P52
   Angelopoulos S, 2004, ALGORITHMICA, V40, P271, DOI 10.1007/s00453-004-1113-2
   [Anonymous], 1997, APPROXIMATION ALGORI
   Borodin A, 2003, ALGORITHMICA, V37, P295, DOI 10.1007/s00453-003-1036-3
   CHEN LL, 1993, ACM T GRAPHIC, V12, P305, DOI 10.1145/159730.159732
   Chvatal V., 1979, Mathematics of Operations Research, V4, P233, DOI 10.1287/moor.4.3.233
   Feige U, 1998, J ACM, V45, P634, DOI 10.1145/285055.285059
   GAN JG, 1994, J MECH DESIGN, V116, P357, DOI 10.1115/1.2919386
   Gary M. R., 1979, COMPUTERS INTRACTABI
   Gupta P, 1996, COMPUT AIDED DESIGN, V28, P577, DOI 10.1016/0010-4485(95)00071-2
   HOCHBAUM DS, 1982, SIAM J COMPUT, V11, P555, DOI 10.1137/0211045
   JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256, DOI 10.1016/S0022-0000(74)80044-9
   LOVASZ L, 1975, DISCRETE MATH, V13, P383, DOI 10.1016/0012-365X(75)90058-8
   Raz R., 1997, 29 ANN ACM S THEOR C, P475, DOI 10.1145/258533.258641
   Slavik P, 1997, J ALGORITHM, V25, P237, DOI 10.1006/jagm.1997.0887
   Tang HR, 2003, BIOMACROMOLECULES, V4, P1269, DOI 10.1021/bm0340772
   Tang K, 2005, GRAPH MODELS, V67, P17, DOI 10.1016/j.gmod.2004.07.001
   Tang K, 2004, IEEE T ROBOTIC AUTOM, V20, P636, DOI 10.1109/TRO.2004.829479
   Tang K, 2003, COMPUT AIDED DESIGN, V35, P1269, DOI 10.1016/S0010-4485(03)00040-X
   Tang K, 1998, COMPUT IND, V37, P27, DOI 10.1016/S0166-3615(98)00067-0
   TANG K, 1992, J MECH DESIGN, V114, P477, DOI 10.1115/1.2926576
NR 21
TC 0
Z9 1
U1 1
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2010
VL 26
IS 4
SI SI
BP 287
EP 292
DI 10.1007/s00371-009-0406-5
PG 6
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584JA
UT WOS:000276746600006
DA 2024-07-18
ER

PT J
AU Li, CL
   Lu, P
   Ma, LZ
AF Li, Canlin
   Lu, Ping
   Ma, Lizhuang
TI A camera on-line recalibration framework using SIFT
SO VISUAL COMPUTER
LA English
DT Article
DE Camera calibration; On-line; Recalibration; SIFT; Feature point
ID SELF-CALIBRATION
AB Camera calibration is a necessary step in many computer vision or photogrammetry tasks. During the execution of these tasks, initial camera calibration may be no longer valid because of intentional or accidental changes of camera parameters. We propose a camera on-line recalibration framework which is aimed at automatically maintaining the calibration of computer vision or photogrammetry system without using any particular calibration pattern again and interrupting the execution of the tasks. The proposed framework consists of initial calibration, followed by recalibration based on SIFT feature point detector and descriptor and a feature point match strategy proposed by us. Both synthetic data and real data have been used to test the framework, and very good results have been obtained. The experimental results of the framework are also compared with those of general on-line self-calibration methods. Both accuracy and speed are also reported. The proposed on-line recalibration framework yields higher accuracy and higher speed on calibrating camera parameters than on-line self-calibration methods do.
C1 [Li, Canlin; Lu, Ping; Ma, Lizhuang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Li, CL (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM lcl_zju@yahoo.com.cn
RI Li, Can-Lin/GNP-3900-2022
FU National Basic Research Program of China [2006CB303105]; National High
   Technology Research and Development Program of China [2009AA01Z334];
   Natural Science Foundation of China [60873136]
FX The authors would like to thank the anonymous reviewers for valuable
   comments. The authors are also very grateful to Prof. Feihu Qi at
   Shanghai Jiaotong University for the important help in providing
   relevant code and valuable comments and suggestions. This work was
   supported in part by funds from National Basic Research Program of China
   (973 Program No. 2006CB303105), National High Technology Research and
   Development Program of China (863 Program No. 2009AA01Z334) and Natural
   Science Foundation of China (No. 60873136).
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   [Anonymous], 1999, proceedings of Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.1999.786974
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   GORDON I, 2004, 3 IEEE ACM INT S MIX, P110
   Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135
   Junejo IN, 2006, INT C PATT RECOG, P880
   LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781
   Liu J, 2006, LECT NOTES COMPUT SC, V4291, P558
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning RA, 2001, PROC CVPR IEEE, P590
   Mikolajczyk K, 2003, PROC CVPR IEEE, P257
   Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   TRIGGS B, 1998, P 5 EUR C COMP VIS, P89
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 17
TC 14
Z9 16
U1 4
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2010
VL 26
IS 3
BP 227
EP 240
DI 10.1007/s00371-009-0400-y
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 558CW
UT WOS:000274719200006
DA 2024-07-18
ER

PT J
AU Hanák, I
   Janda, M
   Skala, V
AF Hanak, Ivo
   Janda, Martin
   Skala, Vaclav
TI Detail-driven digital hologram generation
SO VISUAL COMPUTER
LA English
DT Article
DE Digital holography; Hologram generation
ID 3-DIMENSIONAL SURFACE OBJECTS; COMPUTER; OCCLUSION; REMOVAL
AB Digital holography is a technology with a potential to provide realistic 3D images. However, generation of digital holograms is a computationally demanding task. Thus, the performance is a major concern. We propose a new method that reduces spatial resolution in order to accelerate hologram generation. It employs the propagation between parallel planes for efficient optical field values evaluation and a computer graphics approach for approximating visibility. Our results show that the proposed reduction has only a minimal impact on the visual quality, while the formal computational complexity confirms performance improvement.
C1 [Hanak, Ivo; Janda, Martin; Skala, Vaclav] Univ W Bohemia, Dept Comp Sci & Engn, Plzcn, Czech Republic.
C3 University of West Bohemia Pilsen
RP Hanák, I (corresponding author), Univ W Bohemia, Dept Comp Sci & Engn, Univ 22, Plzcn, Czech Republic.
EM hanak@kiv.zcu.cz
RI Hanak, Ivo/AAV-7265-2021; Skala, Vaclav/F-9141-2011
OI Skala, Vaclav/0000-0001-8886-4281
FU Ministry of Education, Youth and Sports of the Czech Republic
   [LC-06008]; EU [511568]
FX This work has been supported by the Ministry of Education, Youth and
   Sports of the Czech Republic under the research program LC-06008 (Center
   for Computer Graphics) and it has been supported by the EU project
   within FP6 under Grant 511568 with the acronym 3DTV. The access to the
   METACentrum computing facilities provided under the research intent
   MSM6383917201 is acknowledged.
CR Ahrenberg L, 2008, APPL OPTICS, V47, P1567, DOI 10.1364/AO.47.001567
   Ahrenberg L, 2006, OPT EXPRESS, V14, P7636, DOI 10.1364/OE.14.007636
   BLINN JF, 1977, COMPUT GRAPH, V11, P192
   Born M., 2005, PRINCIPLES OPTICS
   Esmer GB, 2006, PROC SPIE, V6252, DOI 10.1117/12.677162
   FUJIMOTO A, 1986, IEEE COMPUT GRAPH, V6, P16, DOI 10.1109/MCG.1986.276715
   GABOR D, 1949, PROC R SOC LON SER-A, V197, P454, DOI 10.1098/rspa.1949.0075
   Goodman J. W., 2005, INTRO FOURIER OPTICS
   Hariharan P., 1996, OPTICAL HOLOGRAPHY P
   Ito T, 2005, OPT EXPRESS, V13, P1923, DOI 10.1364/OPEX.13.001923
   Janda M, 2008, J OPT SOC AM A, V25, P3083, DOI 10.1364/JOSAA.25.003083
   KANG H, 2008, P BIOM OPT
   Kang H, 2008, APPL OPTICS, V47, pD44, DOI 10.1364/AO.47.000D44
   Kim H, 2008, APPL OPTICS, V47, pD117, DOI 10.1364/AO.47.00D117
   LESEM LB, 1968, COMMUN ACM, V11, P661, DOI 10.1145/364096.364111
   LUCENTE M, 1995, P SIGGRAPH, V95, P387
   Lucente M., 1994, THESIS MIT
   Masuda N, 2006, OPT EXPRESS, V14, P603, DOI 10.1364/OPEX.14.000603
   Matsushima K, 2000, APPL OPTICS, V39, P6587, DOI 10.1364/AO.39.006587
   Matsushima K, 2005, P SOC PHOTO-OPT INS, V5742, P25, DOI 10.1117/12.592520
   Matsushima K, 2005, APPL OPTICS, V44, P4607, DOI 10.1364/AO.44.004607
   Matsushima K, 2004, P SOC PHOTO-OPT INS, V5290, P90, DOI 10.1117/12.526747
   Nishi S, 2005, OPT REV, V12, P287, DOI 10.1007/s10043-005-0287-4
   Petz C, 2003, P SOC PHOTO-OPT INS, V5005, P266, DOI 10.1117/12.476879
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Ritter A, 1999, APPL OPTICS, V38, P1364, DOI 10.1364/AO.38.001364
   TOMMASI T, 1993, J OPT SOC AM A, V10, P299, DOI 10.1364/JOSAA.10.000299
   Underkoffler J, 1997, P SOC PHOTO-OPT INS, V3011, P19, DOI 10.1117/12.271359
   Watt A., 2000, 3D COMPUTER GRAPHICS
   Yoshikawa H, 2000, P SOC PHOTO-OPT INS, V3956, P48, DOI 10.1117/12.380022
   Ziegler R, 2008, COMPUT GRAPH FORUM, V27, P211, DOI 10.1111/j.1467-8659.2008.01118.x
NR 31
TC 7
Z9 7
U1 2
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2010
VL 26
IS 2
BP 83
EP 96
DI 10.1007/s00371-009-0378-5
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 543RE
UT WOS:000273595200001
DA 2024-07-18
ER

PT J
AU Meng, WL
   Sheng, B
   Lv, WW
   Sun, HQ
   Wu, EH
AF Meng, Weiliang
   Sheng, Bin
   Lv, Weiwei
   Sun, Hanqiu
   Wu, Enhua
TI Differential geometry images: remeshing and morphing with local shape
   preservation
SO VISUAL COMPUTER
LA English
DT Article
DE Remesh; Geometry images; Differential coordinates; Laplacian matrix;
   Shape space
ID PARAMETRIZATION
AB In this paper, we propose a novel conception of differential geometry images (DGIM), encapsulating differential coordinates to traditional geometry images. DGIM preserves the local geometric characteristics in many graphics applications, such as model remeshing and morphing. The traditional geometry images using Cartesian coordinates require normal maps for correctly rendering models, because they neglect the existence of local geometric details in the image structure, which leads us to compute the normals and curvatures imprecisely. Using our differential geometry images, normals can be reconstructed easily and correctly thereafter normal maps are no longer required. In addition, DGIM can be easily applied to mesh morphing due to its regular topology and well-preserved local details. In this paper, we also demonstrate a variety of plausible mesh morphing results based on DGIM in shape space.
C1 [Meng, Weiliang; Lv, Weiwei] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Sheng, Bin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese
   University of Hong Kong
RP Meng, WL (corresponding author), Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
EM mengwl@ios.ac.cn; bsheng@cse.cuhk.edu.hk; weiweilv@ios.ac.cn;
   hanqiu@cse.cuhk.edu.hk; ehwu@umac.mo
FU National Basic Research Program (973 Program) of China [2009CB320802];
   National ST 863 Program [2008AA01Z301]; NSFC [60773030, 60473105]; RGC
   [ref. 416007]; University of Macau
FX This work is supported by the National Basic Research Program (973
   Program) of China (2009CB320802), National S&T 863 Program
   (2008AA01Z301), NSFC (60773030,60473105), RGC research grant (ref.
   416007), and Grant of University of Macau.
CR [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Carmo MPD, 1976, DIFFERENTIAL GEOMETR, P16
   Cheng HL, 1998, PACIFIC GRAPHICS '98, PROCEEDINGS, P104, DOI 10.1109/PCCGA.1998.732056
   Cohen-Or D, 2006, SCCG06 P 22 SPRING C
   FALLGREN M, 2006, THESIS ROYAL I TECHN
   FIEDLER M, 1973, CZECH MATH J, V23, P298
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   FRIEDEL I, 2005, SIGGRAPH 05 ACM SIGG, P134
   Gotsman C, 2003, ACM T GRAPHIC, V22, P358, DOI 10.1145/882262.882276
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   HORMANN K, 1999, INNOVATIONS APPL MAT, P153
   Ji JF, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P108
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239515, 10.1145/1276377.1276457]
   Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   LOSASSO F, 2003, P EUR ACM SIGGRAPH S, P138
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   SABA S, 2005, SMI 05 P INT C SHAP, P258
   SANDER PV, 2003, P EUR ACM SIGGRAPH S, P146
   Sheffer A, 2005, ACM T GRAPHIC, V24, P311, DOI 10.1145/1061347.1061354
   Sheffer A, 2004, COMPUTING, V72, P185, DOI 10.1007/s00607-004-0056-9
   Shewchuk J. R., 1994, INTRO CONJUGATE GRAD
   Sorkine O., 2003, Symposium on Geometry Processing, P42
   Sorkine O., 2006, THESIS TEL AVIV U
   Tarini M, 2004, ACM T GRAPHIC, V23, P853, DOI 10.1145/1015706.1015810
   Toledo Sivan., 2003, Taucs: A library of sparse linear solvers
   Wu Jinzhong, 2007, Journal of Computer Aided Design & Computer Graphics, V19, P907
NR 30
TC 6
Z9 8
U1 1
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2010
VL 26
IS 1
BP 51
EP 62
DI 10.1007/s00371-009-0376-7
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 526WD
UT WOS:000272325300005
DA 2024-07-18
ER

PT J
AU Yano, K
   Harada, K
AF Yano, Ken
   Harada, Koichi
TI Reconstruction of B-spline skinning surface from generalized cylinder
   mesh
SO VISUAL COMPUTER
LA English
DT Article
DE Surface reconstruction; Skinning surface; Geometric modeling
AB We propose a novel method to reconstruct B-spline surfaces from generalized cylindrical meshes by skinning. Skinning is a well known surface creation technique and has been used in CAD and CG modeling. However, there are few papers which address the issue of automated creation and preparation of sectional curves for skinning. Although our method is only applicable to generalized cylindrical meshes, there are many real world objects which can be created or reconstructed by skinning. The proposed surface reconstruction method is fully automated with minimal user interventions. We have evaluated the validity of this method by reconstructing B-spline surfaces from various polygonal meshes varying in shapes and geometries. The final results show the effectiveness of our proposed method.
C1 [Yano, Ken; Harada, Koichi] Hiroshima Univ, Grad Sch Engn, Hiroshima, Japan.
C3 Hiroshima University
RP Yano, K (corresponding author), Hiroshima Univ, Grad Sch Engn, 1-4-1 Kagamiyama, Hiroshima, Japan.
EM d064016@hiroshima-u.ac.jp; harada@mis.hiroshima-u.ac.jp
RI Harada, Koichi/D-7410-2011
CR CURLESS B, 1996, P 23 C COMP GRAPH IN
   Dong S, 2005, COMPUT AIDED GEOM D, V22, P392, DOI 10.1016/j.cagd.2005.04.004
   FORSEY DR, 1995, ACM T GRAPHIC, V14, P134, DOI 10.1145/221659.221665
   Gotsman C, 2002, TUTORIALS ON MULTIRESOLUTION IN GEOMETRIC MODELLING, P319
   HILTON A, 1996, COMPUT VIS ECCV, V1064, P177
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Krishnamurthy V., 1996, P 23 ANN C COMP GRAP
   Lee S, 1997, IEEE T VIS COMPUT GR, V3, P228, DOI 10.1109/2945.620490
   LEVY B, 2001, P 28 ANN C COMP GRAP, V16, P12
   Liepa P., 2003, P 2003 EUR ACM SIGGR
   Ma W, 1998, INT J ADV MANUF TECH, V14, P918, DOI 10.1007/BF01179082
   Ma WY, 1998, COMPUT AIDED DESIGN, V30, P853, DOI 10.1016/S0010-4485(98)00042-6
   MA WY, 1995, COMPUT AIDED DESIGN, V27, P663, DOI 10.1016/0010-4485(94)00018-9
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Nooruddin F., 1999, SIMPLIFICATION REPAI
   Piegl L., 1997, The Nurbs Book, Vsecond
   Piegl LA, 2000, VISUAL COMPUT, V16, P386, DOI 10.1007/PL00013393
   Piegl LA, 2002, VISUAL COMPUT, V18, P273, DOI 10.1007/s003710100156
   Piegl LA, 2001, COMPUT AIDED DESIGN, V33, P593, DOI 10.1016/S0010-4485(00)00103-2
   Taubin G., 1995, P 22 ANN C COMP GRAP, P351, DOI DOI 10.1145/218380.218473
   Taubin G., 2000, Geometric Signal Processing on Polygonal Meshes
   TURK G, 1994, P 24 C COMP GRAPH IN
NR 22
TC 3
Z9 4
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JAN
PY 2010
VL 26
IS 1
BP 31
EP 40
DI 10.1007/s00371-009-0374-9
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 526WD
UT WOS:000272325300003
DA 2024-07-18
ER

PT J
AU Lin, YX
   Chen, C
   Song, ML
   Liu, ZC
AF Lin, Yuxu
   Chen, Chun
   Song, Mingli
   Liu, Zicheng
TI Dual-RBF based surface reconstruction
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT Computer Graphics International Conference 2009
CY MAY 26-29, 2009
CL Victoria, CANADA
DE Dual-RBF; Surface reconstruction; Polar field; GPU
ID RADIAL BASIS FUNCTIONS; IMPLICIT SURFACES; EDGE; POLYGONIZATION;
   ALGORITHM; CURVES
AB Surface reconstruction (Bloomenthal and Wyvill, Introduction to Implicit Surfaces, 1997) is a fundamental work in Computer Aided Design (CAD) and Computer Graphics (CG). In this paper, motivated by the physical polar field model (Yuxu Lin Chun Chen in Proceedings of the 3rd Pacific-Rim Symposium on Image and Video Technology, 1997), we propose a novel implicit surface reconstruction approach, named Dual-RBF. Through simulating the physical polar field model, Dual-RBF provides a nice initial reconstruction state firstly. Then, two simple nonlinear methods are introduced to adjust the configurations of Dual-RBF model, so that a more accurate reconstruction is reached. Thirdly, the Dual-RBF becomes even more robust to fill the holes on some flawed input point-clouds by adopting a multi-level strategy. Finally, the visualization of the surface reconstruction is speed up with GPU. Experimental results show that the proposed approach is faster and more robust than previous implicit surface reconstruction techniques.
C1 [Lin, Yuxu; Chen, Chun; Song, Mingli] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
   [Liu, Zicheng] Microsoft Res, Redmond, WA USA.
C3 Zhejiang University; Microsoft
RP Song, ML (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
EM linyuxu@zju.edu.cn; chenc@cs.zju.edu.cn; brooksong@ieee.org;
   zliu@microsoft.com
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   ALEXANDER E, 2004, P INT C GRAPH MOSC R
   Alexander M, 2001, INTERNETWEEK, P21
   [Anonymous], 1990, The design and analysis of spatial data structures
   [Anonymous], 2002, Numerical Recipes in C++: The Art of Scientific Computing
   [Anonymous], 1987, An Introduction to Splines for use in Computer Graphics Geometric Modeling
   [Anonymous], P 28 ANN C COMP GRAP, DOI DOI 10.1145/383259.383266
   [Anonymous], 1997, Introduction to Implicit Surfaces
   [Anonymous], P 1 INT C COMP GRAPH
   Beatson RK, 1999, ADV COMPUT MATH, V11, P253, DOI 10.1023/A:1018932227617
   Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760
   BLOOMENTHAL J, 1994, GRAPHICS GEMS, V4, P324
   Cermák M, 2005, VISUAL COMPUT, V21, P252, DOI 10.1007/s00371-005-0286-2
   Cermák M, 2007, INT J COMPUT SCI ENG, V3, P45, DOI 10.1504/IJCSE.2007.014464
   CHEN MSJ, 2009, P 3 PAC RIM S IM VID
   Dierckx P., 1993, Curve and Surface Fitting with Splines
   Fleishman S, 2003, ACM T GRAPHIC, V22, P997, DOI 10.1145/944020.944023
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   GREENGARD L, 1987, J COMPUT PHYS, V73, P325, DOI 10.1016/0021-9991(87)90140-9
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239474
   Halliday D., 2002, Physics
   Hart JC, 1996, VISUAL COMPUT, V12, P527, DOI 10.1007/s003710050084
   Hoppe H, 2008, P 2008 ACM S SOL PHY, P10, DOI DOI 10.1145/1364901.1364904
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   KITAGO M, 2006, S POINT BAS GRAPH EU
   Lewiner T., 2003, Journal of Graphics Tools, V8, P1, DOI 10.1080/10867651.2003.10487582
   Li Q, 2004, COMPUT GRAPH FORUM, V23, P55, DOI 10.1111/j.1467-8659.2004.00005.x
   Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470
   Morse B.S., 2005, ACM SIGGRAPH 2005 Courses, P78, DOI DOI 10.1145/1198555.1198645
   MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Ohtake Y, 2003, P SHAP MOD INT, P292
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Rongjiang Pan, 2007, 2007 10th IEEE International Conference on Computer Aided Design and Computer Graphics
   SAMOZINO M., 2006, SGP 06, P51
   Schall O., 2005, Proceedings of the International Workshop on Semantic Virtual Environments, P138
   Schroeder W., 1998, The visualization toolkit an object-oriented approach to 3D graphics
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Tobor I, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P19, DOI 10.1109/SMI.2004.1314490
   Toledo Sivan., 2003, Taucs: A library of sparse linear solvers
   Walder C, 2006, COMPUT GRAPH FORUM, V25, P635, DOI 10.1111/j.1467-8659.2006.00983.x
   WALDER C, 2006, IMPLICIT SURFACE MOD
NR 42
TC 11
Z9 12
U1 1
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2009
VL 25
IS 5-7
BP 599
EP 607
DI 10.1007/s00371-009-0349-x
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 438ES
UT WOS:000265539300025
DA 2024-07-18
ER

PT J
AU Frank, S
   Kaufman, A
AF Frank, Susan
   Kaufman, Arie
TI Dependency graph approach to load balancing distributed volume
   visualization
SO VISUAL COMPUTER
LA English
DT Article
DE Load balancing; Task scheduling; Large-scale volume data; Visualization
   cluster
AB We present a framework that uses data dependency information to automate load balanced volume distribution and ray-task scheduling for parallel visualization of massive volumes. This dependency graph approach improves load balancing for both ray casting and ray tracing. The main bottlenecks in distributed volume rendering involve moving data across the network and loading memory into rendering hardware. Our load balancing solution combines static network distribution with dynamic ray-task scheduling. At the core of the dependency graph approach are the flex-block tree, introduced in this paper, and the cell-tree. The flex-block tree is similar to a kd-tree except that leaf nodes are cells containing a combination of empty space and tightly cropped subvolumes, or flex-blocks. A main contribution of this paper is the moving walls algorithm, which uses dynamic programming to create a flex-block partition. We show results for optimizing distributed ray cast rendering using a time cost function. We compare data distribution using the moving walls algorithm, with distribution using a recursive solution, and with a grid combined with a local kd-tree partition on each render-node.
C1 [Frank, Susan; Kaufman, Arie] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Frank, S (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM sfrank@cs.sunysb.edu; ari@cs.sunysb.edu
FU NSF [CCF-0702699]
FX This work has been partially supported by NSF grant CCF-0702699. The IBM
   Deep Computing Visualization cluster is part of a Shared University
   Research ( SUR) award from IBM. Data sets were obtained as follows:
   Visible Korean, courtesy of Humintec, Visible Male data, courtesy of the
   National Library of Medicine, and teeth and fossil data, courtesy of the
   Stony Brook Anthropology Department. We also thank HP for providing
   Sepia-2a hardware and TeraRecon for supplying us with VolumePro 1000
   hardware.
CR [Anonymous], 1979, COMPUTERS INTRACTABI
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Chalmers A., 2002, PRACTICAL PARALLEL R
   Cohen D., 1994, Graph. Gems IV, V4, P366
   DACHILLE F, 2000, SIGGRAPH EUR WORKSH, P119
   DeMarle DE, 2003, PVG 2003 PROCEEDINGS, P87, DOI 10.1109/PVGS.2003.1249046
   FALBY JS, 1993, COMPUT GRAPH, V17, P65, DOI 10.1016/0097-8493(93)90052-B
   FRANK S, 2005, CAD GRAPHICS, P371
   FRANK S, 2008, DISTRIBUTED VOLUME R
   FRANK S, 2002, SIGGRAPH EUR WORKSH, P127
   Ghosh A, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P2, DOI 10.1109/CGI.2003.1214440
   Glassner A.S., 1995, PRINCIPLES DIGITAL I, VTwo
   GLASSNER AS, 1984, IEEE COMPUT GRAPH, V4, P15, DOI 10.1109/MCG.1984.6429331
   HAVRAN V, 2000, THESIS CZECH TU
   HEIRICH A, 2005, SIGGRAPH EUR WORKSH, P91
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   Li A J, 1996, NUTR FEED AQUATIC AN, P118
   Li W, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P317, DOI 10.1109/VISUAL.2003.1250388
   LOMBEYDA S, 2001, S PAR LARG DAT VIS G, P115
   MA K, 2004, IEEE COMPUT GRAPH, V21, P72
   MA KL, 1993, COMPUT GRAPH, V17, P31, DOI 10.1016/0097-8493(93)90049-F
   MOLL L, 1999, IEEE S FPGAS CUST CO, P146
   MOLNAR S, 1992, COMP GRAPH, V26, P231, DOI 10.1145/142920.134067
   Moloney B., 2007, PROC EG S PARALLEL G, P45
   Muraki S, 2003, PVG 2003 PROCEEDINGS, P95, DOI 10.1109/PVGS.2003.1249047
   Nishigaki H., 2001, SAE 2001 WORLD C, P1
   Park JS, 2006, CLIN ANAT, V19, P216, DOI 10.1002/ca.20275
   Parker S, 1998, VISUALIZATION '98, PROCEEDINGS, P233, DOI 10.1109/VISUAL.1998.745713
   PHARR M, 1997, ANN C SERIES, V31, P101
   REINHARD E, 1999, IEEE PAR VIS GRAPH S, P21
   Rubin S. M., 1980, Computer Graphics, V14, P110, DOI 10.1145/965105.807479
   Wald I, 2006, ACM T GRAPHIC, V25, P485, DOI 10.1145/1141911.1141913
   WOOP S, 2006, SIGGRAPH EUR WORKSH, P67
NR 33
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2009
VL 25
IS 4
BP 325
EP 337
DI 10.1007/s00371-008-0295-z
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 413YH
UT WOS:000263830600003
DA 2024-07-18
ER

PT J
AU Li, Z
   Ma, LZ
   Jin, XG
   Zheng, ZY
AF Li, Zhong
   Ma, Lizhuang
   Jin, Xiaogang
   Zheng, Zuoyong
TI A new feature-preserving mesh-smoothing algorithm
SO VISUAL COMPUTER
LA English
DT Article
DE Mesh smoothing; Principal curvature; Bi-quadratic Bezier surface;
   Least-square fitting
ID SEGMENTATION
AB We present a novel mesh denoising and smoothing method in this paper. Our approach starts by estimating the principal curvatures and mesh saliency value for each vertex. Then, we calculate the uniform principal curvature of each vertex based on the weighted average of local principal curvatures. After that, we use the weighted bi-quadratic B,zier surface to fit the neighborhood of each vertex using the least-square method and obtain the new vertex position by adjusting the parameters of the fitting surface. Experiments show that our smoothing method preserves the geometric feature of the original mesh model efficiently. Our approach also prevents the volume shrinkage of the input mesh and obtains smooth boundaries for non-closed mesh models.
C1 [Li, Zhong] Zhejiang Sci Tech Univ, Dept Math & Sci, Hangzhou 310018, Peoples R China.
   [Li, Zhong; Ma, Lizhuang; Zheng, Zuoyong] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang Sci-Tech University; Shanghai Jiao Tong University; Zhejiang
   University
RP Li, Z (corresponding author), Zhejiang Sci Tech Univ, Dept Math & Sci, Hangzhou 310018, Peoples R China.
EM lizhongzju@hotmail.com
FU National Natural Science Foundation of China [60573147]; Natural Science
   Foundation of Zhejiang Province of China [Y106207]; China 973 program
   [2002CB312101]; China 863 program [2006AA01Z314]
FX The authors are very grateful to the anonymous referees for the useful
   comments and suggestions which improved this paper considerably. This
   research was supported by the National Natural Science Foundation of
   China under Grant No. 60573147 and the Natural Science Foundation of
   Zhejiang Province of China under Grant No. Y106207. Xiao-gang Jin is
   supported by the China 973 program under Grant No. 2002CB312101 and the
   China 863 program under Grant No. 2006AA01Z314.
CR CHOUDHURY P, 2004, P EUR S REND, P186
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   KARBACHER S, 2003, P SPIE 03, P168
   Kobbelt L., 1996, P IMA C MATH SURFACE, P101
   Lee CH, 2005, P ACM SIGGRAPH, P659
   Liu Sheng-Lan, 2004, Chinese Journal of Computers, V27, P79
   LOOP C, 1994, COMPUT AIDED GEOM D, V11, P303, DOI [10.1016/0167-8396(94)90005-1, 10.1145/192161.192238]
   MAO Z, 2006, P SMART GRAPH 06, P105
   MENON JP, 1994, IEEE COMPUT GRAPH, V14, P24, DOI 10.1109/38.267468
   MEYER M, 2002, P VIS MATH, P52
   Milroy MJ, 1997, COMPUT AIDED DESIGN, V29, P299, DOI 10.1016/S0010-4485(96)00058-9
   OHTAKE Y, 2005, EUR S GEOM PROC EUR, P149
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Razdan A, 2005, COMPUT AIDED DESIGN, V37, P1481, DOI 10.1016/j.cad.2005.03.003
   Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600
   Taubin G., 1995, P 22 ANN C COMP GRAP, P351, DOI DOI 10.1145/218380.218473
   WELCH W, 1994, P SIGGRAPH 94, P247
   YOKOYA N, 1989, IEEE T PATTERN ANAL, V11, P643, DOI 10.1109/34.24798
NR 21
TC 16
Z9 24
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2009
VL 25
IS 2
BP 139
EP 148
DI 10.1007/s00371-008-0210-7
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 394XE
UT WOS:000262485700004
DA 2024-07-18
ER

PT J
AU Wei, L
   Sourin, A
   Sourina, O
AF Wei, Lei
   Sourin, Alexei
   Sourina, Olga
TI Function-based visualization and haptic rendering in shared virtual
   spaces
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds
CY OCT 24-27, 2007
CL Hannover, GERMANY
SP Welfenlab, Gottfried Wilhelm Leibniz Univ, EuroGraphics, ACM SIGWEB, ACM SIGART
DE web visualization; shared virtual environments; haptic interaction;
   implicit functions; parametric functions
AB We seek to further expand the collaborative potential of shared virtual spaces by using haptic force-feedback. We propose how to define tangible physical properties of the objects, together with their geometry and appearance, by using mathematical functions. We illustrate this concept by developing software which allows us to touch and feel surfaces of VRML and X3D objects, convert them to solid objects, as well as create any other solid objects using the function-based extension of VRML and X3D. We define geometry, appearance and tangible physical properties of the solid objects by implicit, explicit and parametric functions straight in the VRML/X3D code or in loadable libraries. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail. We illustrate the proposed models with several application examples.
C1 [Wei, Lei; Sourin, Alexei; Sourina, Olga] Nanyang Technol Univ, Singapore, Singapore.
C3 Nanyang Technological University
RP Sourin, A (corresponding author), Nanyang Technol Univ, Singapore, Singapore.
EM wei10004@ntu.edu.sg; assourin@ntu.edu.sg; eosourina@ntu.edu.sg
RI Sourin, Alexei/A-3701-2011; Sourina, Olga/A-5156-2011
OI Wei, Lei/0000-0001-8267-0283; Sourin, Alexei/0000-0003-4051-2927
CR Asano T., 2005, P 2005 ACM SIGCHI IN, P246
   BASDOGAN C, 2000, P ACM T COMP HUM INT, P443
   Fukuda I, 2002, PREN HAL IMSC P MULT, P137
   Goncharenko I, 2004, IEEE INFOR VIS, P533
   HAMAM A, 2006, P IEEE INT W S HAPT, P105
   HIKICHI K, 2002, P 16 INT WORKSH COMM, P218
   IGLESIAS R, 1915, P 15 INT C CENTR EUR, P241
   LIU Q, 2006, P ACM WEB3D 2006, P131
   Liu Q., 2005, P ACM WEB3D 2005, P123
   Liu Q, 2006, VISUAL COMPUT, V22, P977, DOI 10.1007/s00371-006-0044-0
   Liu Q, 2006, COMPUT GRAPH-UK, V30, P629, DOI 10.1016/j.cag.2006.03.006
   MCLAUGHLIN ML, 2000, P EVA 2000 C EL IM V
   OMALLEY M, 1911, P 11 S HAPT INT VIRT, P428
   Osama M., 2001, EUROHAPTICS, P60
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   REINKENSMEYER DJ, 2001, P 7 INT C REH ROB, P66
   Ruffaldi E., 2006, P ACM S VIRTUAL REAL, P320, DOI [10.1145/1180495.1180559, DOI 10.1145/1180495.1180559]
   SHEN X, 2006, P 8 IEEE INT S DISTR, P53
NR 18
TC 16
Z9 16
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD OCT
PY 2008
VL 24
IS 10
BP 871
EP 880
DI 10.1007/s00371-008-0285-1
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 347IQ
UT WOS:000259134200003
DA 2024-07-18
ER

PT J
AU Yang, WW
   Feng, JQ
   Jin, XG
AF Yang, Wenwu
   Feng, Jieqing
   Jin, Xiaogang
TI Shape deformation with tunable stiffness
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 26th International Conference on Computer Graphics
CY JUN 09-11, 2008
CL Istanbul, TURKEY
DE shape deformation; stiffness; rigidity
AB The paper presents a 2D or 3D shape deformation method which incorporates global and local stiffness controls. First, a geometric object is embedded into a regular lattice and then the deformation is conducted on the lattice; thus, the method is independent of the underlying object representation. The lattice cells are organized as overlapping local rigid regions, and the region width could be regarded as a means of the global lattice stiffness control. For each region, there is a local stiffness coefficient to control the lattice deformation locally. During the deformation a nonlinear objective function is optimized to achieve the natural lattice deformation with the prescribed global and local stiffnesses. Then, the lattice deformation is passed to the embedded object through bilinear or trilinear interpolation. In this way we can deform the object in a more physically plausible way with tunable stiffness. Experimental results show that the method is intuitive and flexible.
C1 [Yang, Wenwu; Feng, Jieqing; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM wwyang@cad.zju.edu.cn; jqfeng@cad.zju.edu.cn; jin@cad.zju.edu.cn
CR [Anonymous], 1997, TR9719 MITS EL RES L
   Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Au OKC, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239534, 10.1145/1276377.1276481]
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   Botsch Mario, 2006, SGP 06
   Davis T., UMFPACK: Unsymmetric Multifrontal Sparse LU Factorization Package
   Gudukbay U, 1997, COMPUT GRAPH-UK, V21, P335, DOI 10.1016/S0097-8493(97)00011-3
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   JAMES DL, 2004, SIGGRAPH 04, P38
   Kraevoy Vladislav., 2006, International Journal of Shape Modeling, V12, P29
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Nealen A., 2005, Eurographics State of the Art Report
   Platt J. C., 1988, Computer Graphics, V22, P279, DOI 10.1145/378456.378524
   Popa T, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P141
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Schiwietz T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P27, DOI 10.1109/PG.2007.44
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Shoemake K., 1992, Proceedings. Graphics Interface '92, P258
   SORKINE O, 2007, SGP 07, P109
   Sorkine O., 2004, SGP '04
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Weng YL, 2006, VISUAL COMPUT, V22, P653, DOI 10.1007/s00371-006-0054-y
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
NR 32
TC 8
Z9 13
U1 0
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUL
PY 2008
VL 24
IS 7-9
BP 495
EP 503
DI 10.1007/s00371-008-0230-3
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 322OI
UT WOS:000257384800005
DA 2024-07-18
ER

PT J
AU Yang, HP
   Jüttler, B
AF Yang, Huaiping
   Juettler, Bert
TI Evolution of T-spline level sets for meshing non-uniformly sampled and
   incomplete data
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Shape Modeling and Applications
CY JUN 13-15, 2007
CL Lyon, FRANCE
SP ACM SIGRAPT, CNRS, Groupement Rech Informat Mathemat, Reg Rhone Alpes, Univ Claude Bernard Lyon 1
DE mesh reconstruction; point cloud; displacement maps; T-spline; level
   sets
ID SHARP EDGES; TRIANGULATION
AB Given a large set of unorganized point sample data, we propose a new framework for computing a triangular mesh representing an approximating piecewise smooth surface. The data may be non-uniformly distributed, noisy, and may contain holes. This framework is based on the combination of two types of surface representations, triangular meshes and T-spline level sets, which are implicit surfaces defined by refinable spline functions allowing T-junctions. Our method contains three main steps. Firstly, we construct an implicit representation of a smooth (C-2 stop in our case) surface, by using an evolution process of T-spline level sets, such that the implicit surface captures the topology and outline of the object to be reconstructed. The initial mesh with high quality is obtained through the marching triangulation of the implicit surface. Secondly, we project each data point to the initial mesh, and get a scalar displacement field. Detailed features will be captured by the displaced mesh. Finally, we present an additional evolution process, which combines data-driven velocities and feature-preserving bilateral filters, in order to reproduce sharp features. We also show that various shape constraints, such as distance field constraints, range constraints and volume constraints can be naturally added to our framework, which is helpful to obtain a desired reconstruction result, especially when the given data contains noise and inaccuracies.
C1 [Yang, Huaiping; Juettler, Bert] Johannes Kepler Univ Linz, Inst Appl Geometry, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz
RP Yang, HP (corresponding author), Johannes Kepler Univ Linz, Inst Appl Geometry, A-4040 Linz, Austria.
EM yang.huaiping@jku.at; bert.juettler@jku.at
OI Juttler, Bert/0000-0002-5518-7795
CR Alexander M, 2001, INTERNETWEEK, P21
   Allègre R, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P33, DOI 10.1109/SMI.2005.11
   AMENTA N, 2000, SCG 00, P213
   [Anonymous], 2002, SURFACES
   [Anonymous], 2004, P 9 ACM S SOLID MODE
   Apodaca A. A., 1999, ADV RENDERMAN CREATI
   Attene M, 2005, IEEE T VIS COMPUT GR, V11, P181, DOI 10.1109/TVCG.2005.34
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Boissonnat JD, 2002, COMP GEOM-THEOR APPL, V22, P5, DOI 10.1016/S0925-7721(01)00054-2
   BOTSCH M, 2001, P VIS MOD VIS, P283
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Cheng KSD, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P16, DOI 10.1109/PCCGA.2004.1348330
   Cohen J.D., 1998, P 25 ANN C COMP GRAP, P115
   COOK RL, 1984, P 11 ANN C COMP GRAP, P223, DOI DOI 10.1145/800031.808602
   Dey T.K., 2003, P 8 ACM S SOL MOD AP, P127, DOI DOI 10.1145/781606.781627
   Eck M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P325, DOI 10.1145/237170.237271
   ENGEL HW, 1996, REGULARIZATION INVER
   Feichtinger R, 2008, COMPUT AIDED DESIGN, V40, P13, DOI 10.1016/j.cad.2007.08.003
   Fleishman S, 2005, ACM T GRAPHIC, V24, P544, DOI 10.1145/1073204.1073227
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Gavriliu M, 2001, IEEE VISUAL, P295, DOI 10.1109/VISUAL.2001.964524
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   Gu XF, 2006, GRAPH MODELS, V68, P237, DOI 10.1016/j.gmod.2006.03.004
   Gumhold S., 1999, Proceedings 1999 EUROGRAPHICS/SIGGRAPH Workshop on Graphics Hardware, P55, DOI 10.1145/311534.311578
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Hartmann E, 1998, VISUAL COMPUT, V14, P95, DOI 10.1007/s003710050126
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Hoppe H., 1994, PIECEWISE SMOOTH SUR, P295
   Hornung Alexander, 2006, ACM INT C PROCEED IN, P41, DOI DOI 10.2312/SGP/SGP06
   Hubeli A., 2001, P IEEE VIS 01, P16
   Jeong WK, 2002, GRAPH MODELS, V64, P78, DOI 10.1006/gmod.2002.0572
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Jüttler B, 2002, ADV COMPUT MATH, V17, P135, DOI 10.1023/A:1015200504295
   Karkanis T, 2001, IEEE COMPUT GRAPH, V21, P60, DOI 10.1109/38.909016
   Kobbelt LP, 2000, COMPUT GRAPH FORUM, V19, pC249, DOI 10.1111/1467-8659.00417
   KRISHNAMURTHY V, 1996, P SIGGRAPH 96, P313, DOI DOI 10.1145/237170.237270
   Lee A, 2000, COMP GRAPH, P85, DOI 10.1145/344779.344829
   Mederos B., 2005, Proc. Geometry Processing (Eurographics/ ACM SIGGRAPH), P53
   Ohtake Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P31, DOI 10.1109/SMI.2004.1314491
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Ohtake Y, 2006, GRAPH MODELS, V68, P255, DOI 10.1016/j.gmod.2006.03.002
   Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319
   Qin H, 1998, IEEE T VIS COMPUT GR, V4, P215, DOI 10.1109/2945.722296
   Raviv A., 1999, Proceedings of Fifth ACM Symposium on Solid Modeling and Applications, P246
   Sederberg TN, 2003, ACM T GRAPHIC, V22, P477, DOI 10.1145/882262.882295
   SHARF A, 2006, P EUR 06
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Thompson WB, 1999, IEEE T ROBOTIC AUTOM, V15, P57, DOI 10.1109/70.744602
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Velho L., 2002, IMPLICIT OBJECTS COM, DOI DOI 10.1007/B97350
   Wang CCL, 2006, IEEE T VIS COMPUT GR, V12, P629, DOI 10.1109/TVCG.2006.60
   Watanabe K, 2001, COMPUT GRAPH FORUM, V20, pC385, DOI 10.1111/1467-8659.00531
   YANG H, 2007, P SMI 07, P251
   Yang HP, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P247
   Yoon SH, 2006, LECT NOTES COMPUT SC, V4077, P677
   Zhao HK, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P194, DOI 10.1109/VLSM.2001.938900
NR 57
TC 10
Z9 12
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN
PY 2008
VL 24
IS 6
BP 435
EP 448
DI 10.1007/s00371-008-0222-3
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 299FP
UT WOS:000255741800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, B
   Tang, LX
   Shi, HM
AF Xu, Bin
   Tang, Lixin
   Shi, Hanmin
TI Shape from shading based on needle map and cellular automata
SO VISUAL COMPUTER
LA English
DT Article
DE computer vision; shape from shading; needle map; quadric smooth;
   cellular automata
AB This paper presents a method for computing depth from a single grayscale image in two steps. Firstly, surface normals are parallelly and gradually adjusted by a procedure which includes three constraints: the smooth constraint ensures the recovered normals are smooth and integrable, the intensity gradient constraint ensures the recovered normals are consistent with the image gradient field, and the intensity constraint guarantees the recovered intensity is equal to the input image. Unlike their usage in global methods, those constraints are separately used in local area in our method. Secondly, the surface is recovered from needle map using a two-dimensional cellular automata system. An experimental assessment is provided for our methods on both real world images and synthetic images with known ground truth. The experiment results demonstrate this approach is practicable and has better precision than traditional methods.
C1 [Xu, Bin; Tang, Lixin; Shi, Hanmin] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Xu, B (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
EM Stanfordxu2006@yahoo.com; Lixintang1998@163.com; Hmshi@163.net
CR [Anonymous], 1989, Shape from shading
   Brooks M., 1985, INT JOINT C ART INT, P932
   CHEN Y, 2004, P 3 INT C IM GRAPH I, P464
   COLLINGS SP, 2002, IEEE COMPUTER SOC, V4, P126
   Daniel P., 2000, P 4 AS C COMP VIS, P187
   Durou J-D., 2004, SURVEY NUMERICAL MET
   FALCONE M, 1997, P 9 IEEE ITN C IM AN, V1, P596
   Horn B K P, 1970, Tech. Rep.
   IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0
   KOENDERINK JJ, 1992, PERCEPT PSYCHOPHYS, V52, P487, DOI 10.3758/BF03206710
   LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247
   PACKARD NH, 1985, J STAT PHYS, V38, P901, DOI 10.1007/BF01010423
   PRADOS E, 2002, P 7 EUR C COMP VIS
   Smith GDJ, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1031, DOI 10.1109/ICDSP.2002.1028266
   TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7
   von Neumann J., 1966, THEORY SELF REPRODUC
   Wolfram S., 2002, A new kind of science
   Worthington PL, 2001, PATTERN RECOGN, V34, P823, DOI 10.1016/S0031-3203(00)00036-4
   Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang R, 1999, IEEE T SYST MAN CY A, V29, P318, DOI 10.1109/3468.759291
NR 21
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2008
VL 24
IS 3
BP 201
EP 212
DI 10.1007/s00371-007-0185-9
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 255ZA
UT WOS:000252695900004
DA 2024-07-18
ER

PT J
AU Dobashi, Y
   Enjyo, Y
   Yamamoto, T
   Nishita, T
AF Dobashi, Yoshinori
   Enjyo, Yoshihiro
   Yamamoto, Tsuyoshi
   Nishita, Tomoyuki
TI A fast rendering method for clouds illuminated by lightning taking into
   account multiple scattering
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 25th Computer Graphics International Conference (CGI)
CY MAY 30-JUN 02, 2007
CL Petropolis, BRAZIL
DE real-time rendering; clouds; lightning; multiple scattering
ID RADIANCE TRANSFER
AB Methods for rendering natural scenes are used in many applications such as virtual reality, computer games, and flight simulators. In this paper, we focus on the rendering of outdoor scenes that include clouds and lightning. In such scenes, the intensity at a point in the clouds has to be calculated by taking into account the illumination due to lightning. The multiple scattering of light inside clouds is an important factor when creating realistic images. However, the computation of multiple scattering is very time-consuming. To address this problem, this paper proposes a fast method for rendering clouds that are illuminated by lightning. The proposed method consists of two processes. First, basis intensities are prepared in a preprocess step. The basis intensities are the intensities at points in the clouds that are illuminated by a set of point light sources. In this precomputation, both the direct light and also indirect light (i.e., multiple scattering) are taken into account. In the rendering process, the intensities of clouds are calculated in real-time by using the weighted sum of the basis intensities. A further increase in speed is achieved by using a wavelet transformation. Our method achieves the real-time rendering of realistic clouds illuminated by lightning.
C1 Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 060, Japan.
   Univ Tokyo, Grad Sch Frontier Sci, Tokyo, Japan.
C3 Hokkaido University; University of Tokyo
RP Dobashi, Y (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 060, Japan.
EM doba@nis-ei.eng.hokudai.ac.jp; enjyo@nis-ei.eng.hokudai.ac.jp;
   yamamoto@nis-ei.eng.hokudai.ac.jp; nis@is.s.u-tokyo.ac.jp
RI Yamamoto, Tsuyoshi/C-8204-2009
CR Cabral B., 1994, P 1994 S VOLUME VISU, P91, DOI DOI 10.1145/197938.197972
   Daubert K, 2003, IEEE COMPUT GRAPH, V23, P28, DOI 10.1109/MCG.2003.1198260
   Dobashi Y, 2000, COMP GRAPH, P19, DOI 10.1145/344779.344795
   DOBASHI Y, 2001, P PAC GRAPH, P290
   Fearing P, 2000, COMP GRAPH, P37, DOI 10.1145/344779.344809
   Garg K, 2006, ACM T GRAPHIC, V25, P996, DOI 10.1145/1141911.1141985
   Hasan M, 2006, ACM T GRAPHIC, V25, P1089, DOI 10.1145/1141911.1141998
   JANSEN HW, 1997, P SIGGRAPH 1998, P311
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Kim T, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P267, DOI 10.1109/PCCGA.2004.1348357
   Kristensen AW, 2005, ACM T GRAPHIC, V24, P1208, DOI 10.1145/1073204.1073334
   Kruszewski P, 1999, COMPUT GRAPH-UK, V23, P287, DOI 10.1016/S0097-8493(99)00038-2
   Matsuyama K, 2006, VISUAL COMPUT, V22, P761, DOI 10.1007/s00371-006-0061-z
   Max N.L., 1994, WORKSHOP RENDERING, P87
   Nishita T, 1997, COMPUT GRAPH FORUM, V16, pC357, DOI 10.1111/1467-8659.00173
   Nishita T., 1996, Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, P379
   Reed T., 1994, Proceedings of the 21st annual conference on Computer graphics and interactive techniques, P359
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Stam Jos., 1995, Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, SIGGRAPH '95, P129
   STOLLNITZ EJ, 1995, IEEE COMPUT GRAPH, V15, P76, DOI 10.1109/38.376616
   SZIMARYKALOS L, 2005, P EUR S REND 2005, P277
NR 21
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2007
VL 23
IS 9-11
SI SI
BP 697
EP 705
DI 10.1007/s00371-007-0146-3
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 206UE
UT WOS:000249207600010
DA 2024-07-18
ER

PT J
AU Soga, A
   Umino, B
   Yasuda, T
   Yokoi, S
AF Soga, Asako
   Umino, Bin
   Yasuda, Takami
   Yokoi, Shigeki
TI Automatic composition and simulation system for ballet sequences
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds (CW 2006)
CY NOV 28-29, 2006
CL Lausanne, SWITZERLAND
SP EPFL, VRlab
DE human animation; dance; automatic composition; simulation
AB We have developed an automatic composition system for ballet choreographies by using 3DCG animation. Our goal is to develop useful tools in dance education such as a creation-support system for ballet teachers and a self-study system for students. The algorithm for automatic composition was integrated to create utilitarian choreographies. As a result of an evaluation test, we verified that the created choreographies had a possibility to be used in the actual lessons. This system is valuable for online virtual dance experimentation and exploration by teachers and choreographers involved in creative practices, improvisation, creative movement, or dance composition.
C1 Ryukoku Univ, Otsu, Shiga, Japan.
   Toyo Univ, Kawagoe, Saitama, Japan.
   Nagoya Univ, Nagoya, Aichi, Japan.
C3 Ryukoku University; Toyo University; Nagoya University
RP Soga, A (corresponding author), Ryukoku Univ, 1-5 Yokotani,Oe Cho, Otsu, Shiga, Japan.
EM asako@rins.ryukoku.ac.jp
RI UMINO, BIN/AAG-2897-2019
CR *AUT, 2006, MOTIONBUILDER
   Calvert T, 2005, IEEE COMPUT GRAPH, V25, P6, DOI 10.1109/MCG.2005.33
   *CRED INT, 2006, LIV FORMS
   *H AN WORK GROUP, 2006, H AN 200X SPEC
   HUTCHINSON A, 1984, LABANOTATION KINETOG
   *INN GRAPH SOL, 2006, MOTIONSTAR WIR
   Kalra P, 1998, IEEE COMPUT GRAPH, V18, P42, DOI 10.1109/38.708560
   MOSER H, 1999, IEEE T VISUALIZATION, V5, P281
   *MOT AN, 2006, EVA SYST
   NAKAMURA M, 2000, WORLD DANCE 2000 CHO, P131
   *PAR GRAPH, 2006, VRML VIEW
   Perlin Ken., 1996, SIGGRAPH 96, P205
   PULLEN K, 2002, P 29 ANN C COMP GRAP, P501
   Ryman R., 1997, Dictionary of classical ballet terminology
   Soga A, 2004, LECT NOTES COMPUT SC, V3179, P227
   Soga A, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P134, DOI 10.1109/ROMAN.2001.981891
   SOGA A, 2002, P 11 INT S EL ART, P16
   SOGA A, 2006, WEB3D DANCE RES PROJ
   Soga A, 2006, 2006 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P43, DOI 10.1109/CW.2006.17
   UMINO B, 2004, 18 WORLD C DANC RES
   *VIC MOT SYST, 2006, VICON512
NR 21
TC 14
Z9 14
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2007
VL 23
IS 5
BP 309
EP 316
DI 10.1007/s00371-007-0110-2
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 154JS
UT WOS:000245503600003
DA 2024-07-18
ER

PT J
AU Sourina, O
AF Sourina, Olga
TI Visual spatio-temporal function-based querying
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds (CW 2006)
CY NOV 28-29, 2006
CL Lausanne, SWITZERLAND
SP EPFL, VRlab
DE spatio-temporal range queries; function-based model; visual querying;
   implicit functions; molecular dynamics
ID VISUALIZATION
AB Visual interfaces are very important for human interactions in cyberworlds. Visual spatio-temporal querying should be one of the basic tools for data mining and retrieval in cyberworlds. In this paper, we propose a novel function-based query model for arbitrary shape spatio-temporal querying. The queries are defined as geometric shapes changing over time. In our model, data are interpreted geometrically as multidimensional points with time dimension or as moving points. The queries are formulated with geometric objects and operations over them to form the query solid changing over time. The proposed query model allows us to pose arbitrary shape spatio-temporal range queries. With the uniform geometric model we integrate visual mining and querying of time-dependent data employing 3D visualization tools. It allows for creating an intuitive visual interface using 2D projections of 3D query shapes. Our approach combines visualization of spatio-temporal data with visualization of the range query formulation employing very compact function-based query model. The implemented visual query system and its visual interface are proposed and described. An example of application of the system in analysis of simulation results in molecular dynamics is considered.
C1 Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Sourina, O (corresponding author), Nanyang Technol Univ, Nanyang Ave, Singapore 639798, Singapore.
EM eosourina@ntu.edu.sg
RI Sourina, Olga/A-5156-2011
CR [Anonymous], 2003, Data Mining: Introductory and Advanced Topics
   Bergman DL, 1997, J MOL GRAPH MODEL, V15, P301, DOI 10.1016/S1093-3263(98)00003-5
   Erwig M., 2000, Advances in Visual Information Management. Visual Database Systems. IFIP TC2 WG2.6 Fifth Working Conference on Visual Database Systems, P199
   Erwig M., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P441, DOI 10.1109/DEXA.1999.795206
   Güting RH, 2000, ACM T DATABASE SYST, V25, P1, DOI 10.1145/352958.352963
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Keim DA, 2002, IEEE T VIS COMPUT GR, V8, P1, DOI 10.1109/2945.981847
   Levinski K, 2007, COMPUT GRAPH-UK, V31, P66, DOI 10.1016/j.cag.2006.09.008
   Liu Q, 2006, COMPUT GRAPH-UK, V30, P629, DOI 10.1016/j.cag.2006.03.006
   Meng XF, 2003, LECT NOTES COMPUT SC, V2736, P444
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   RICCI A, 1973, COMPUT J, V16, P157, DOI 10.1093/comjnl/16.2.157
   SCHROEDER W, 2000, VISUALIZATION TOOLKI
   SHAPIRO V, 1991, CPA9110 TR CORN U
   Sourina O, 2005, J COMPUT THEOR NANOS, V2, P492, DOI 10.1166/jctn.2005.003
   Sourina O., 1996, International Journal of Information Technology, V2, P41
   Sourina O, 1998, DATA KNOWL ENG, V27, P207, DOI 10.1016/S0169-023X(97)00061-X
NR 17
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAY
PY 2007
VL 23
IS 5
BP 335
EP 346
DI 10.1007/s00371-007-0108-9
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 154JS
UT WOS:000245503600005
DA 2024-07-18
ER

PT J
AU Preusche, C
   Hirzinger, G
AF Preusche, Carsten
   Hirzinger, Gerd
TI Haptics in telerobotics - Current and future research and applications
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 2006 HAPTEX Workshop
CY NOV 21-23, 2006
CL Natl Commun Assoc, Helsinki, FINLAND
HO Natl Commun Assoc
DE haptics; telerobotics; bilateral control; haptic display; transparency
ID DOMAIN PASSIVITY CONTROL; ROBOTICS; SPACE
AB For telerobotic systems the ultimate goal is transparency, meaning the human operator cannot distinguish between operating in a local or a distant environment. To achieve this, the human operator is coupled with the telerobotic system with all necessary senses: visual, auditory and haptic modality. For the haptic modality this implies research in the following fields: robotic hardware, both handcontroller and teleoperators, and control aspects with time delay. The latter include both supervisory and bilateral control. In this paper the current and future aspects of haptics in telerobotics are shown focusing on the control research. With the evolving technology in these research areas telerobotic systems can now be found in a variety of different application fields, e.g. microassembly, surgery or space.
C1 DLR, Inst Robot & Mechatron, D-82234 Oberpfaffenhofen, Wessling, Germany.
C3 Helmholtz Association; German Aerospace Centre (DLR)
RP Preusche, C (corresponding author), DLR, Inst Robot & Mechatron, D-82234 Oberpfaffenhofen, Wessling, Germany.
EM Carsten.Preusche@dlr.de
CR ANDERSON RJ, 1989, IEEE T AUTOMAT CONTR, V34, P494, DOI 10.1109/9.24201
   [Anonymous], THESIS TU MUNCHEN
   ARTIGAS J, 2004, ROB 2004 MUN GERM JU, P101
   ARTIGAS J, 2006, P INT WORKSH HUM CTR
   ARTIGAS J, 2006, P INT C INT ROB SYST
   Avizzano CA, 2000, IEEE SYS MAN CYBERN, P989, DOI 10.1109/ICSMC.2000.885979
   BAIER H, 2000, P IEEE RSJ INT C INT
   BORST C, 2003, P IEEE INT C ROB AUT
   Buss M., 1999, Advances in Control. Highlights of ECC'99, P65
   Butterfass J, 2001, IEEE INT CONF ROBOT, P109, DOI 10.1109/ROBOT.2001.932538
   DEML B, 2005, JOINT INT WORKSH HUM
   *DLR I ROB MECH, KIN ROB MED APPL
   Hannaford B, 2002, IEEE T ROBOTIC AUTOM, V18, P1, DOI 10.1109/70.988969
   HIRZINGER G, 1993, IEEE T ROBOTIC AUTOM, V9, P649, DOI 10.1109/70.258056
   Hirzinger G, 2004, ADV ROBOTICS, V18, P139, DOI 10.1163/156855304322758006
   HIRZINGER G, 1994, IEEE INT C ROB AUT S
   KOEPPE R, 2001, P 10 INT S ROB RES I, P125
   Kuebler B, 2005, INT J MED ROBOT COMP, V1, P96, DOI 10.1581/mrcas.2005.010305
   LANDZETTEL K, 2002, P ADV SPAC TECHN ROB
   LANDZETTEL K, 2006, P INT C INT ROB SYST
   NIEMEYER G, 1991, IEEE J OCEANIC ENG, V16, P152, DOI 10.1109/48.64895
   Niemeyer G, 1998, IEEE INT CONF ROBOT, P1909, DOI 10.1109/ROBOT.1998.680592
   Norris JS, 2005, IEEE INT CONF ROBOT, P4618
   Ortmaier T, 2002, CARS 2002: COMPUTER ASSISTED RADIOLOGY AND SURGERY, PROCEEDINGS, P206
   ORTMAIER T, 2000, 6 INT IFAC S ROB CON
   ORTMAIER T, 2003, ICRA IEEE INT C ROB
   OTT C, 2006, HUMANOIDS 06 GEN IT
   Preusche C, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2944
   Preusche C, 2002, CONTROL ENG PRACT, V10, P1245, DOI 10.1016/S0967-0661(02)00084-9
   PREUSCHE C, 2003, P 3 INT C HUM ROB MU
   PREUSCHE C, 2001, WORKSH ADV INT MULT
   PREUSCHE C, 2005, P JOINT INT COE HAM, P35
   PREUSCHE C, 2004, P INT C MECH ROB IEE
   PREUSCHE C, 2006, P INT C INT ROB SYST
   Reintsema D, 2004, PRESENCE-VIRTUAL AUG, V13, P77, DOI 10.1162/105474604774048243
   Ryu JH, 2005, IEEE T CONTR SYST T, V13, P737, DOI 10.1109/TCST.2005.847336
   RYU JH, 2003, IEEE INT C ROB AUT T
   Schaetzle S., 2006, P EUT 2006 PAR, P557
   Sheridan Thomas B, 1992, TELEROBOTICS AUTOMAT
   SUPPA M, 2007, IN PRESS INT C ROB A
   Yokokohji Y., 1990, Proceedings. IROS '90. IEEE International Workshop on Intelligent Robots and Systems '90. Towards a New Frontier of Applications (Cat. No.90TH0332-7), P355, DOI 10.1109/IROS.1990.262411
   YOKOKOHJI Y, 1999, P 1999 IEEE RSJ INT, V3
   ZAEH M, 2004, P INT C MECH ROB IEE
NR 43
TC 13
Z9 16
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2007
VL 23
IS 4
BP 273
EP 284
DI 10.1007/s00371-007-0101-3
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 172ZW
UT WOS:000246844300006
DA 2024-07-18
ER

PT J
AU Liu, Q
   Prakash, EC
   Srinivasan, MA
AF Liu, Qiang
   Prakash, Edmond C.
   Srinivasan, Mandayam A.
TI Interactive deformable geometry maps
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 2005 HAPTEX Workshop
CY DEC 01, 2005
CL Hannover, GERMANY
DE deformable geometry; surgery simulation; haptics computing
ID HAPTICS
AB Haptics on 3D deformable models is a challenge because of the inevitable and expensive 3D deformation computation. In this paper, we propose a new technique that extends the conventional rigid geometry images approach proposed by Gu et al. [9]. Our approach not only flattens the geometry, but also helps to accomplish deformation in an effective and efficient manner. Our approach is suitable for haptics computing, as it performs the deformation on the geometry map itself thereby avoiding the expensive 3D deformation computation. We demonstrate construction of the deformable geometry map representation and its application utilizing practical methods for interactive surgery simulation and interactive textile simulation.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   MIT, Touch Lab, Cambridge, MA 02139 USA.
C3 Nanyang Technological University; Massachusetts Institute of Technology
   (MIT)
RP Liu, Q (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM pg04825433@ntu.edu.sg; asprakash@ntu.edu.sg; srini@mit.edu
CR ALLIEZ P, 2002, SIGGRAPH 02, P173
   [Anonymous], 1997, TR9719 MITS EL RES L
   Basdogan C, 2004, IEEE COMPUT GRAPH, V24, P56, DOI 10.1109/MCG.2004.1274062
   Basdogan C, 2002, HUM FAC ER, P117
   De S, 2002, STUD HEALTH TECHNOL, V85, P127
   De S, 2001, STUD HEALTH TECHNOL, V81, P113
   Du HX, 2005, GRAPH MODELS, V67, P43, DOI 10.1016/j.gmod.2004.06.002
   Grimm C. M., 2004, International Journal of Shape Modeling, V10, P51, DOI 10.1142/S0218654304000602
   GU X, 2002, SIGGRAPH 02, P355, DOI DOI 10.1145/566570.566589
   Hirota G, 2003, VISUAL COMPUT, V19, P291, DOI 10.1007/s00371-002-0188-5
   Lee HY, 2005, IEEE MULTIMEDIA, V12, P27, DOI 10.1109/MMUL.2005.5
   MAGNENATHALMANN N, 2005, P HAPTEX 05 VR WORKS, P1
   Onoue K, 2005, COMPUT GRAPH FORUM, V24, P51, DOI 10.1111/j.1467-8659.2005.00828.x
   Schein S, 2004, COMPUT GRAPH FORUM, V23, P727, DOI 10.1111/j.1467-8659.2004.00805.x
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
NR 15
TC 2
Z9 3
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD FEB
PY 2007
VL 23
IS 2
BP 119
EP 131
DI 10.1007/s00371-006-0033-3
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 125NZ
UT WOS:000243450200004
DA 2024-07-18
ER

PT J
AU Prasolova-Forland, E
   Sourin, A
   Sourina, O
AF Prasolova-Forland, Ekaterina
   Sourin, Alexei
   Sourina, Olga
TI Cybercampuses: design issues and future directions
SO VISUAL COMPUTER
LA English
DT Article
DE 3D educational cyberworlds; cybercampuses
AB In recent years, the usage of 3D cyberworlds for educational purposes has increased. The metaphors behind the visual design of such cyberworlds are quite diverse, from replication of real universities, art museums and scientific labs to non-existing fictitious places. In this paper, we focus specifically on "cybercampuses", i.e. virtual worlds representing real educational institutions such as universities and schools. Based on the results of a case study that we have performed, this paper provides an initial set of requirements for a cybercampus representing an existing university. In this connection, we analyze place metaphors and associated design features of the Virtual Campus of Nanyang Technological University in Singapore, discuss the correspondence between the identified metaphors and associated educational goals, and provide directions for further development. Finally, we outline the major challenges for the future evolution of cybercampuses in the context of organizational, social and technological development.
C1 Norwegian Univ Sci & Technol, N-7034 Trondheim, Norway.
   Nanyang Technol Univ, Singapore, Singapore.
C3 Norwegian University of Science & Technology (NTNU); Nanyang
   Technological University
RP Prasolova-Forland, E (corresponding author), Norwegian Univ Sci & Technol, N-7034 Trondheim, Norway.
EM ekaterip@idi.ntnu.no; assourin@ntu.edu.sg; eosourina@ntu.edu.sg
RI Sourina, Olga/A-5156-2011; Sourin, Alexei/A-3701-2011
OI Sourin, Alexei/0000-0003-4051-2927
CR BORNER K, 2001, UM 2001 WORKSH EMP E, P33
   Clark S, 2001, COMPUTER AIDED ARCHITECTURAL DESIGN FUTURES 2001, PROCEEDINGS, P187
   DEUFF D, 2005, CELDA 2005, P441
   Dickey M.D., 2003, Distance Education, V24, P105, DOI 10.1080/01587910303047
   GU N, 2003, CAADRIA 2003, P71
   Maher ML, 2000, COLLABORATIVE DESIGN, P391
   MAHER ML, 1999, COMPUTER SUPPORTED C, P376
   MCARDLE G, 2006, WBE 2006, P37
   NEAL L, 1997, ACM GROUP 1997, P81
   Nijholt A, 2000, STUD FUZZ SOFT COMP, V45, P148
   NIJHOLT A, 2005, ACTAS 2 9 S INT COM, P551
   Pekkola S., 2002, NORDICHI 02 P 2 NORD, P129
   Prasolova-Forland E., 2005, C COMPUTERS ADV TECH, P147
   Prasolova-Forland E., 2002, ICALT 2002, P259
   Prasolova-Forland E., 2005, WBE 2005, P349
   PRASOLOVAFORLAN.E, 2004, CYBERWORLDS 2004, P127
   PRASOLOVAFORLAN.E, 2005, ICALT 2005, P887
   PRASOLOVAFORLAN.E, 2003, ACM GROUP 2003, P58
   SCHROEDER R, 2000, FUTURES J POLICY PLA, V33, P569
   Talamo A, 2001, CYBERPSYCHOL BEHAV, V4, P109, DOI 10.1089/10949310151088479
   Thalmann D, 2001, FRONTIERS OF HUMAN-CENTRED COMPUTING, ONLINE COMMUNITIES AND VIRTUAL ENVIRONMENTS, P27
   Wyeld T. G., 2006, 2 INT GAMESETANDMATC, P568
   Yates F. A., 1966, ART MEMORY
   YOUNGBLUT C, 1998, D2128 I DEF AN
NR 24
TC 18
Z9 23
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2006
VL 22
IS 12
BP 1015
EP 1028
DI 10.1007/s00371-006-0042-2
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120HE
UT WOS:000243074300007
DA 2024-07-18
ER

PT J
AU Lai, SH
   Cheng, FH
AF Lai, Shuhua
   Cheng, Fuhua (Frank)
TI Similarity based interpolation using Catmull-Clark subdivision surfaces
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 14th Pacific Conference on Computer Graphics and Applications
CY OCT 11-13, 2005
CL Taipei, TAIWAN
DE subdivision; subdivision surfaces; Catmull-Clark subdivision surfaces;
   interpolation
AB A new method for constructing a Catmull-Clark subdivision surface (CCSS) that interpolates the vertices of a given mesh with arbitrary topology is presented. The new method handles both open and closed meshes. Normals or derivatives specified at any vertices of the mesh (which can actually be anywhere) can also be interpolated. The construction process is based on the assumption that, in addition to interpolating the vertices of the given mesh, the interpolating surface is also similar to the limit surface of the given mesh. Therefore, construction of the interpolating surface can use information from the given mesh as well as its limit surface. This approach, called similarity based interpolation, gives us more control on the smoothness of the interpolating surface and, consequently, avoids the need of shape fairing in the construction of the interpolating surface. The computation of the interpolating surface's control mesh follows a new approach, which does not require the resulting global linear system to be solvable. An approximate solution provided by any fast iterative linear system solver is sufficient. Nevertheless, interpolation of the given mesh is guaranteed. This is an important improvement over previous methods because with these features, the new method can handle meshes with large number of vertices efficiently. Although the new method is presented for CCSSs, the concept of similarity based interpolation can be used for other subdivision surfaces as well.
C1 Univ Kentucky, Dept Comp Sci, Graph & Geometr Modeling Lab, Lexington, KY 40506 USA.
C3 University of Kentucky
RP Lai, SH (corresponding author), Univ Kentucky, Dept Comp Sci, Graph & Geometr Modeling Lab, Lexington, KY 40506 USA.
EM slai2@cs.uky.edu; cheng@cs.uky.edu
CR [Anonymous], ACM SIGGRAPH 1997 C
   [Anonymous], 1998, SIGGRAPH 98 P 19 24
   Barsky B. A., 1982, Computers in Industry, V3, P17, DOI 10.1016/0166-3615(82)90028-8
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Halstead M., 1993, Computer Graphics Proceedings, P35, DOI 10.1145/166117.166121
   KERSEY S, SMOOTHING NEAR INTER
   KOBBELT L, 1996, COMPUT GRAPH FORUM E, V15
   Levin A, 1999, COMP GRAPH, P57, DOI 10.1145/311535.311541
   Litke N, 2001, IEEE VISUAL, P319, DOI 10.1109/VISUAL.2001.964527
   Nasri A. H., 1991, Computer-Aided Geometric Design, V8, P89, DOI 10.1016/0167-8396(91)90051-C
   Nasri AH, 2002, VISUAL COMPUT, V18, P259, DOI 10.1007/s003710100154
   SCHAEFER S., 2002, CURVES SURFACE FITTI, P373
   Shuhua Lai, 2006, Computer-Aided Design and Applications, V3, P513
   Stam J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P395, DOI 10.1145/280814.280945
   Zorin D, 2002, VISUAL COMPUT, V18, P299, DOI 10.1007/s003710100149
NR 16
TC 16
Z9 21
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2006
VL 22
IS 9-11
BP 865
EP 873
DI 10.1007/s00371-006-0072-9
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 082IW
UT WOS:000240381000029
DA 2024-07-18
ER

PT J
AU Panagiotakis, C
   Tziritas, G
AF Panagiotakis, Costas
   Tziritas, Georgios
TI Snake terrestrial locomotion synthesis in 3D virtual environments
SO VISUAL COMPUTER
LA English
DT Article
DE snake motion modeling; graph exploration; snake animation
ID ROADMAPS; REAL
AB We present a method for a 3D snake model construction and terrestrial snake locomotion synthesis in 3D virtual environments using image sequences. The snake skeleton is extracted and partitioned into equal segments using a new iterative algorithm for solving the equipartition problem. This method is applied to 3D model construction and at the motion analysis stage. Concerning the snake motion, the snake orientation is controlled by a path planning method. An animation synthesis algorithm, based on a physical motion model and tracking data from image sequences, describes the snake's velocity and skeleton shape transitions. Moreover, the proposed motion planning algorithm allows a large number of skeleton shapes, providing a general method for aperiodic motion sequences synthesis in any motion graph. Finally, the snake locomotion is adapted to the 3D local ground, while its behavior can be easily controlled by the model parameters yielding the appropriate realistic animations.
C1 Univ Crete, Dept Comp Sci, Iraklion, Greece.
C3 University of Crete
RP Panagiotakis, C (corresponding author), Univ Crete, Dept Comp Sci, POB 2208, Iraklion, Greece.
EM cpanag@csd.uoc.gr; tziritas@csd.uoc.gr
RI Tziritas, Georgios/AAO-5855-2021; Panagiotakis, Costas/I-5115-2019
OI Panagiotakis, Costas/0000-0003-3680-7087
CR Albrecht I., 2003, SIGGRAPH
   Barbier A, 2005, GRAPH MODELS, V67, P166, DOI 10.1016/j.gmod.2004.06.006
   Batalin MA, 2003, IEEE INT CONF ROBOT, P2714, DOI 10.1109/ROBOT.2003.1242003
   Chernousko FL, 2005, APPL MATH COMPUT, V164, P415, DOI 10.1016/j.amc.2004.06.057
   Dontcheva M, 2003, ACM T GRAPHIC, V22, P409, DOI 10.1145/882262.882285
   FAVREAU L, 2004, SIGGRAPH GREN FRANC
   Glardon P, 2006, VISUAL COMPUT, V22, P399, DOI 10.1007/s00371-006-0017-3
   Gray J., 1968, Animal locomotion
   IJSPEERT AJ, 1998, THESIS U EDINBURGH
   JAYNE BC, 1986, COPEIA, P915, DOI 10.2307/1445288
   Johnson M.P., 2003, Ph.D. thesis
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kim H, 2005, SIGNAL PROCESS-IMAGE, V20, P61, DOI 10.1016/j.image.2004.10.004
   Kovar L., 2002, SIGGRAPH
   LaValle SM, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1671, DOI 10.1109/ROBOT.1999.770349
   Miller G. S. P., 1988, Computer Graphics, V22, P169, DOI 10.1145/378456.378508
   Moon BR, 1998, J EXP BIOL, V201, P2669
   Nougaret JL, 1997, VISUAL COMPUT, V13, P435, DOI 10.1007/s003710050116
   Panagiotakis C, 2004, LECT NOTES COMPUT SC, V3179, P86
   PANAGIOTAKIS C, 2004, P 2 INT S 3D DAT PRO
   PANAGIOTAKIS C, 2006, EUR WORKSH COMP GEOM
   PANAGIOTAKIS C, 2005, UNPUB COMPUTATIONAL
   Ramanan D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P338
   Saito M, 2002, IEEE CONTR SYST MAG, V22, P64, DOI 10.1109/37.980248
   Sifakis E, 2002, EURASIP J APPL SIG P, V2002, P379, DOI 10.1155/S1110865702000744
   Sminchisescu C, 2005, INT J COMPUT VISION, V61, P81, DOI 10.1023/B:VISI.0000042935.43630.46
   Tsakiris DP, 2005, IEEE INT CONF ROBOT, P3018
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wilhelms J, 2003, VISUAL COMPUT, V19, P360, DOI 10.1007/s00371-003-0201-7
   Wu JC, 2003, ACM T GRAPHIC, V22, P888, DOI 10.1145/882262.882360
   YANG L, 2004, SIGGRAPH GREN FRANC, P37
NR 31
TC 9
Z9 9
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2006
VL 22
IS 8
BP 562
EP 576
DI 10.1007/s00371-006-0035-1
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TD
UT WOS:000240833100005
DA 2024-07-18
ER

PT J
AU Wang, R
   Hua, W
   Dong, ZL
   Peng, QS
   Bao, HJ
AF Wang, R
   Hua, W
   Dong, ZL
   Peng, QS
   Bao, HJ
TI Synthesizing trees by plantons
SO VISUAL COMPUTER
LA English
DT Article
DE tree modeling; modeling from samples; Markov model; image-based modeling
ID TEXTURE; MODELS
AB In this paper, we present a two-level statistical model for characterizing the stochastic and specific nature of trees. At the low level, we define plantons, which are a group of similar organs, to depict tree organ details statistically. At the high level, a set of transitions between plantons is provided to describe the stochastic distribution of organs.
   Based on such a tree model, we propose a novel tree modeling approach, synthesizing trees by plantons, which are extracted from tree samples. All tree samples are captured from the real world. We have designed a maximum likelihood estimation algorithm to acquire the two-level statistical tree model from single samples or multi- samples. Experimental results show that our new model is capable of synthesizing new trees with similar, yet visually different shapes.
C1 Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
EM rwang@cad.zju.edu.cn; huawei@cad.zju.edu.cn; zldong@cad.zju.edu.cn;
   peng@cad.zju.edu.cn; bao@cad.zju.edu.cn
CR [Anonymous], 1962, PROC S APPL MATH, DOI DOI 10.1090/PSAPM/014/9947
   [Anonymous], 1996, The Algorithmic Beauty of Plants
   [Anonymous], 1995, SIGGRAPH
   AONO M, 1984, IEEE COMPUT GRAPH, V4, P10, DOI 10.1109/MCG.1984.276141
   Boudon F, 2003, COMPUT GRAPH FORUM, V22, P591, DOI 10.1111/1467-8659.t01-2-00707
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Drake A. W., 1962, Observation of a Markov process through a noisy channel
   DURAND JB, 2004, P 4 INT WORKSH FUNCT, P61
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fournier A., 1986, Proceedings of Graphics Interface '86 and Vision Interface '86, P164
   FOURNIER A, 1982, COMMUN ACM, V25, P371, DOI 10.1145/358523.358553
   Galbraith C, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P78, DOI 10.1109/CGI.2004.1309195
   Galbraitht C, 2004, COMPUT GRAPH FORUM, V23, P351, DOI 10.1111/j.1467-8659.2004.00766.x
   Greene N., 1989, Computer Graphics, V23, P175, DOI 10.1145/74334.74351
   Guédon Y, 2001, J THEOR BIOL, V212, P481, DOI 10.1006/jtbi.2001.2392
   HOLTON M, 1994, COMPUT GRAPH FORUM, V13, P57, DOI 10.1111/1467-8659.1310057
   HONDA H, 1971, J THEOR BIOL, V31, P331, DOI 10.1016/0022-5193(71)90191-3
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   LINDENMAYER A, 1968, J THEOR BIOL, V18, P280, DOI 10.1016/0022-5193(68)90079-9
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Loop C, 1987, THESIS U UTAH
   Mandelbrot B. B., 1982, FRACTAL GEOMETRY NAT
   Oppenheimer P. E., 1986, Computer Graphics, V20, P55, DOI 10.1145/15886.15892
   Prusinkiewicz P, 2001, COMP GRAPH, P289, DOI 10.1145/383259.383291
   PRUSINKIEWICZ P, 1993, SIGGRAPH 93 C P, P351
   Prusinkiewicz Przemyslaw., 1994, Proceedings of the 21st annual conference on Computer graphics and interactive techniques. SIGGRAPH'94, P351, DOI DOI 10.1145/192161.192254
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Reche A, 2004, ACM T GRAPHIC, V23, P720, DOI 10.1145/1015706.1015785
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   REFFYE DP, 1988, SIGGRAPH COMPUT GRAP, V22, P151
   Reissell LM, 2001, COMPUT GRAPH FORUM, V20, pC339
   SAKAGUCHI T, 1999, P ACM S VIRT REAL SO, P139
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Shlyakhter I, 2001, IEEE COMPUT GRAPH, V21, P53, DOI 10.1109/38.920627
   Viennot X. G., 1989, Computer Graphics, V23, P31, DOI 10.1145/74334.74336
   WEBER J, 1995, SIGGRAPH 95, P119, DOI DOI 10.1145/218380.218427
   Zhang W, 2002, INT J NONLINEAR SCI, V3, P295, DOI 10.1515/IJNSNS.2002.3.3-4.295
NR 39
TC 5
Z9 7
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2006
VL 22
IS 4
BP 238
EP 248
DI 10.1007/s00371-006-0002-x
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 032DG
UT WOS:000236753500002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, CK
   Chiueh, TC
AF Yang, CK
   Chiueh, TC
TI Integration of volume decompression and out-of-core iso-surface
   extraction from irregular volume data
SO VISUAL COMPUTER
LA English
DT Article
DE irregular grids; tetrahedral mesh compression; iso-surface extraction;
   volume rendering; out-of-core
AB Volume datasets tend to grow larger and larger as modern technology advances, thus imposing a storage constraint on most systems. One general solution to alleviate this problem is to apply volume compression on volume datasets. However, as volume rendering is often the most important reason why a volume dataset was generated in the first place, we must take into account how a volume dataset could be efficiently rendered when it is stored in a compressed form. Our previous work [21] has shown that it is possible to perform an on-the-fly direct volume rendering from irregular volume data. In this paper, we further extend that work to demonstrate that a similar integration can also be achieved on iso-surface extraction and volume decompression for irregular volume data. In particular, our work involves a dataset decomposition process, where instead of a coordinate-based decomposition used by conventional out-of-core iso-surface extraction algorithms, we choose to use a layer-based structure. Each such layer contains a collection of tetrahedra whose associated scalar values fall within a specific range, and can be compressed independently to reduce its storage requirement. The layer structure is particularly suitable for out-of-core iso-surface extraction, where the required memory exceeds the physical memory capacity of the machine that the process is running on. Furthermore, with this work, we can perform on-the-fly iso-surface extraction during decompression, and the computation only involves the layer that contains the query value, rather than the entire dataset. Experiments show that our approach can improve the performance up to ten times when compared with the results based on traditional coordinate-based approaches.
C1 Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 106, Taiwan.
   SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 National Taiwan University of Science & Technology; State University of
   New York (SUNY) System; State University of New York (SUNY) Stony Brook
RP Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43 Keelung Rd,Sect 4, Taipei 106, Taiwan.
EM ckyang@cs.ntust.edu.tw; chiueh@cs.sunysb.edu
CR [Anonymous], 2002, NUMERICAL RECIPES C
   Bajaj CL, 1996, 1996 SYMPOSIUM ON VOLUME VISUALIZATION, PROCEEDINGS, P39, DOI 10.1109/SVV.1996.558041
   BAJAJ CL, 1997, IEEE VIS 97 LAT BREA
   Chiang YJ, 1998, VISUALIZATION '98, PROCEEDINGS, P167, DOI 10.1109/VISUAL.1998.745299
   Chiang YJ, 1997, VISUALIZATION '97 - PROCEEDINGS, P293, DOI 10.1109/VISUAL.1997.663895
   Cignoni P, 1997, IEEE T VIS COMPUT GR, V3, P158, DOI 10.1109/2945.597798
   EDELSBRUNNER H, 1980, F59 TU GRAZ I INF
   GALLAGHER RS, 1991, IEEE VISUALIZATION, P68
   GUEZIEC AP, 1999, IEEE VISUALIZATION 9, P73
   HONG W, 2003, ACM S SOL MOD APPL 2, P334
   HUNG C, 2005, EUROVIS 2005 EUR IEE, P125
   Itoh T, 1996, IEEE VISUAL, P303, DOI 10.1109/VISUAL.1996.568123
   Itoh T, 1995, IEEE T VIS COMPUT GR, V1, P319, DOI 10.1109/2945.485619
   Livnat Y, 1996, IEEE T VIS COMPUT GR, V2, P73, DOI 10.1109/2945.489388
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   MA K, 2001, P SPIE VIS DAT EXPL, V8, P111
   MCCREIGHT EM, 1980, CSL809 XER PAL ALT R
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Rossignac J., 1999, P 5 ACM S SOL MOD AP, P31
   WILHELMS J, 1992, ACM T GRAPHIC, V11, P201, DOI 10.1145/130881.130882
   Yang CK, 2000, IEEE VISUAL, P101, DOI 10.1109/VISUAL.2000.885682
NR 21
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2006
VL 22
IS 4
BP 249
EP 265
DI 10.1007/s00371-006-0003-9
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 032DG
UT WOS:000236753500003
DA 2024-07-18
ER

PT J
AU Attene, M
   Falcidieno, B
   Spagnuolo, M
AF Attene, M
   Falcidieno, B
   Spagnuolo, M
TI Hierarchical mesh segmentation based on fitting primitives
SO VISUAL COMPUTER
LA English
DT Article
DE clustering; denoising; sharp feature; shape abstraction; reverse
   engineering
AB In this paper, we describe a hierarchical face clustering algorithm for triangle meshes based on fitting primitives belonging to an arbitrary set. The method proposed is completely automatic, and generates a binary tree of clusters, each of which is fitted by one of the primitives employed. Initially, each triangle represents a single cluster; at every iteration, all the pairs of adjacent clusters are considered, and the one that can be better approximated by one of the primitives forms a new single cluster. The approximation error is evaluated using the same metric for all the primitives, so that it makes sense to choose which is the most suitable primitive to approximate the set of triangles in a cluster. Based on this approach, we have implemented a prototype that uses planes, spheres and cylinders, and have experimented that for meshes made of 100 K faces, the whole binary tree of clusters can be built in about 8 s on a standard PC. The framework described here has natural application in reverse engineering processes, but it has also been tested for surface denoising, feature recovery and character skinning.
C1 CNR, Ist Matemat Applicata & Tecnol Informat, I-16149 Genoa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Matematica
   Applicata e Tecnologie Informatiche "Enrico Magenes" (IMATI-CNR)
RP CNR, Ist Matemat Applicata & Tecnol Informat, Via Marini 6, I-16149 Genoa, Italy.
EM attene@ge.imati.cnr.it; falcidieno@ge.imati.cnr.it;
   spagnuolo@ge.imati.cnr.it
RI Spagnuolo, Michela/ABA-1927-2021; Spagnuolo, Michela/F-5068-2013
OI Spagnuolo, Michela/0000-0002-5682-6990; Spagnuolo,
   Michela/0000-0002-5682-6990
CR Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   [Anonymous], 1985, Introduction to non-linear optimization
   [Anonymous], P VIS MOD VIS C U ST
   Attene M, 2005, IEEE T VIS COMPUT GR, V11, P181, DOI 10.1109/TVCG.2005.34
   Attene M, 2003, VISUAL COMPUT, V19, P127, DOI 10.1007/s00371-002-0182-y
   Biasotti S., 2004, Topological Data Structures for Surfaces: An Introduction for Geographical Information Science, P87
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   Gelfand N., 2004, PROCEEDING S GEOMETR, P219, DOI DOI 10.2312/SGP/SGP04/219-228
   Glantz S., 2000, Primer of applied regression and analysis of variance, V2nd
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Marr D., 1982, Vision
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Mortara M, 2004, ALGORITHMICA, V38, P227, DOI 10.1007/s00453-003-1051-4
   Petitjean S, 2002, ACM COMPUT SURV, V34, P211, DOI 10.1145/508352.508354
   Ponce J., 1987, Three Dimensional Machine Vision, P195
   Pottmann H., 2004, Computer-Aided Design and Applications, V1, P513
   Pratt V., 1987, Computer Graphics, V21, P145
   RENNER G, 1998, P PROLAMAT 98 TRENT
   ROSSL C, 2000, P AAAI S SMART GRAPH, P71
   SANDER PV, 2003, P EUR ACM SIGGRAPH S, P146
   SAPIDIS NS, 1995, ACM T GRAPHIC, V14, P171, DOI 10.1145/221659.221672
   Thompson WB, 1999, IEEE T ROBOTIC AUTOM, V15, P57, DOI 10.1109/70.744602
   Varady T., 1998, International Journal of Shape Modeling, V4, P127, DOI 10.1142/S0218654398000106
   Varady Tamas., 2002, Handbook of Computer Aided Geometric Design, P651
   VERGEEST JSM, 1999, P 26 INT C COMP IND, P84
   Watanabe K, 2001, COMPUT GRAPH FORUM, V20, pC385, DOI 10.1111/1467-8659.00531
   Wu JH, 2005, COMPUT GRAPH FORUM, V24, P277, DOI 10.1111/j.1467-8659.2005.00852.x
   Yang M, 1999, COMPUT AIDED DESIGN, V31, P449, DOI 10.1016/S0010-4485(99)00042-1
NR 32
TC 284
Z9 348
U1 0
U2 23
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD MAR
PY 2006
VL 22
IS 3
BP 181
EP 193
DI 10.1007/s00371-006-0375-x
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 028UP
UT WOS:000236514600004
DA 2024-07-18
ER

PT J
AU Polonsky, O
   Patané, G
   Biasotti, S
   Gotsman, C
   Spagnuolo, M
AF Polonsky, O
   Patané, G
   Biasotti, S
   Gotsman, C
   Spagnuolo, M
TI What's in an image?: Towards the computation of the "best'' view of an
   object
SO VISUAL COMPUTER
LA English
DT Article; Proceedings Paper
CT 13th Pacific Conference on Computer Graphics and Applications
CY OCT 12-14, 2005
CL Macao, PEOPLES R CHINA
DE visualization; view entropy; scene composition
AB There are many possible 2D views of a given 3D object and most people would agree that some views are more aesthetic and/or more "informative" than others. Thus, it would be very useful, in many applications, to be able to automatically compute these "best" views. Although all measures of the quality of a view will ultimately be subjective, hence difficult to quantify, we propose some general principles which may be used to address this challenge. In particular, we describe a number of different ways to measure the goodness of a view, and show how to optimize these measures by reducing the size of the search space.
C1 Technion Israel Inst Technol, IL-32000 Haifa, Israel.
   Harvard Univ, Cambridge, MA 02138 USA.
   IMATI, CNR, Shape Modelling Grp, Genoa, Italy.
C3 Technion Israel Institute of Technology; Harvard University; Consiglio
   Nazionale delle Ricerche (CNR); Istituto di Matematica Applicata e
   Tecnologie Informatiche "Enrico Magenes" (IMATI-CNR)
RP Technion Israel Inst Technol, IL-32000 Haifa, Israel.
EM olegp@cs.technion.ac.il; patane@ge.imati.cnr.it;
   biasotti@ge.imati.cnr.it; gotsman@eecs.harvard.edu;
   spagnuolo@ge.imati.cnr.it
RI Spagnuolo, Michela/F-5068-2013; Spagnuolo, Michela/ABA-1927-2021;
   Biasotti, Silvia/G-8602-2012; Patane', Giuseppe/O-1322-2013
OI Spagnuolo, Michela/0000-0002-5682-6990; Spagnuolo,
   Michela/0000-0002-5682-6990; Biasotti, Silvia/0000-0002-9992-825X;
   Patane', Giuseppe/0000-0002-2276-9553; Gotsman,
   Craig/0000-0001-8579-3588
CR [Anonymous], 1981, Attention and Performance
   [Anonymous], P WORKSH ALG DAT STR
   [Anonymous], P 6 EUR WORKSH MULT
   Arbel T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P248, DOI 10.1109/ICCV.1999.791227
   BARRAL P, 2000, P EUR 2000 INT SWITZ, V19
   BIASOTTI S, 2004, THESIS U STUDI GENOV
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   BIRKHOFF GD, 1956, WORLD MATH, V4
   BIRKHOFF GEORGE DAVID, 1933, Aesthetic measure, DOI DOI 10.4159/HARVARD.9780674734470
   Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897
   BULTHOFF HH, 1995, CEREB CORTEX, V5, P247, DOI 10.1093/cercor/5.3.247
   ELAD M, 2000, HPL200020R1 HP LABS
   Gómez F, 2001, J VIS COMMUN IMAGE R, V12, P387, DOI 10.1006/jvci.2001.0488
   Gooch B, 2001, SPRING EUROGRAP, P83
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   KAMADA T, 1988, COMPUT VISION GRAPH, V41, P43, DOI 10.1016/0734-189X(88)90116-8
   KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information
   Milnor J. W., 1963, Morse Theory, V51
   Page DL, 2003, IEEE IMAGE PROC, P229
   PLEMENOS D, 1996, P GRAPHICON ST PET R
   ROBERTS DR, 1998, P BRIT MACH VIS C SO, V2, P740
   Stoev SL, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P545, DOI 10.1109/VISUAL.2002.1183826
   Tarr MJ, 2001, VISION RES, V41, P1981, DOI 10.1016/S0042-6989(01)00024-4
   Vazquez P.-P., 2001, Proceedings of Vision Modeling and Visualization Conference, P273
   Weinshall D, 1997, IEEE T PATTERN ANAL, V19, P97, DOI 10.1109/34.574783
NR 27
TC 64
Z9 86
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD SEP
PY 2005
VL 21
IS 8-10
SI SI
BP 840
EP 847
DI 10.1007/s00371-005-0326-y
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 964CX
UT WOS:000231857400037
DA 2024-07-18
ER

PT J
AU Dong, F
   Clapworthy, GJ
AF Dong, F
   Clapworthy, GJ
TI Volumetric texture synthesis for non-photorealistic volume rendering of
   medical data
SO VISUAL COMPUTER
LA English
DT Article
DE non-photorealistic rendering; texture synthesis; volume rendering;
   medical visualization
ID IMAGE
AB This paper presents a novel technique, called volumetric texture synthesis, for non-photorealistic volume rendering. It extends texture synthesis from 2D areas/3D surfaces to volumes. By selecting different texture samples, it allows for a wide variety of stylized rendering for the target volume. As a preprocessing step, volume data analysis is used to identify texture orientations for the volume. This is followed by volumetric texture synthesis, which generates 3D non-photorealistic textures along the identified texture orientations. Finally, standard volume rendering is applied to display the volume data decorated by the texture. Experimental results are provided in the paper.
C1 Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
   Univ Luton, Dept Comp & Informat Syst, Luton LU1 3JU, Beds, England.
C3 Brunel University; University of Bedfordshire
RP Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
CR [Anonymous], 2001, Schooling for Tomorrow
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265
   Csébfalvi B, 2001, COMPUT GRAPH FORUM, V20, pC452, DOI 10.1111/1467-8659.00538
   Dischler JM, 1998, COMPUT GRAPH FORUM, V17, pC87, DOI 10.1111/1467-8659.00256
   Dong F, 2003, IEEE COMPUT GRAPH, V23, P44, DOI 10.1109/MCG.2003.1210864
   Ebert D, 2000, IEEE VISUAL, P195, DOI 10.1109/VISUAL.2000.885694
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   ELBER G, 1999, COMPUT GRAPH FORUM, V19, P1
   GIRSHICK A, 2000, P 1 INT S NONPH AN R, P43, DOI DOI 10.1145/340916.340922
   Gooch B., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P31, DOI 10.1145/300523.300526
   Gorla G, 2003, IEEE T VIS COMPUT GR, V9, P512, DOI 10.1109/TVCG.2003.1260745
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Hertzmann A., 1998, Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques, P453
   Interrante V, 1995, VISUALIZATION '95 - PROCEEDINGS, P52, DOI 10.1109/VISUAL.1995.480795
   INTERRANTE V, 1997, P SIGGRAPH 97, P109
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   Litwinowicz P., 1997, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, SIGGRAPH '97, P407
   Lu AD, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P211, DOI 10.1109/VISUAL.2002.1183777
   Lum E.B., 2002, P 2 INT S NONPHOTORE, P67
   NAGY Z, 2002, P VIS MOD VIS 02
   Owada S, 2004, ACM T GRAPHIC, V23, P322, DOI 10.1145/1015706.1015723
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Praun E, 2000, COMP GRAPH, P465, DOI 10.1145/344779.344987
   SAITO, 1994, P S VOL VIS 94, P99
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   Treavett SMF, 2000, IEEE VISUAL, P203, DOI 10.1109/VISUAL.2000.885696
   Turk G, 2001, COMP GRAPH, P347, DOI 10.1145/383259.383297
   WEI L, 2001, THESIS STANFORD U ST
   Wei LY, 2001, COMP GRAPH, P355, DOI 10.1145/383259.383298
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   XU Y, 2000, MSRTR200032 MICR RES
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
NR 36
TC 9
Z9 15
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD AUG
PY 2005
VL 21
IS 7
BP 463
EP 473
DI 10.1007/s00371-005-0294-2
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 952GE
UT WOS:000230991200003
DA 2024-07-18
ER

PT J
AU Niederberger, C
   Gross, M
AF Niederberger, C
   Gross, M
TI Level-of-detail for cognitive real-time characters
SO VISUAL COMPUTER
LA English
DT Article
DE level of detail; multiagent systems; behavioral modeling
AB We present a solution for the real-time simulation of artificial environments containing cognitive and hierarchically organized agents at constant rendering framerates. We introduce a level-of-detail concept to behavioral modeling, where agents populating the world can be both reactive and proactive. The disposable time per rendered frame for behavioral simulation is variable and determines the complexity of the presented behavior. A special scheduling algorithm distributes this time to the agents depending on their level-of-detail such that visible and nearby agents get more time than invisible or distant agents. This allows for smooth transitions between reactive and proactive behavior. The time available per agent influences the proactive behavior, which becomes more sophisticated because it can spend time anticipating future situations. Additionally, we exploit the use of hierarchies within groups of agents that allow for different levels of control. We show that our approach is well-suited for simulating environments with up to several hundred agents with reasonable response times and the behavior adapts to the current viewpoint.
C1 ETH, Dept Comp Sci, Comp Graph Lab, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP ETH, Dept Comp Sci, Comp Graph Lab, Zurich, Switzerland.
EM niederberger@inf.ethz.ch; grossm@inf.ethz.ch
CR [Anonymous], P WORKSH COMP AN SIM
   ARIKAN O, 2001, P EUR WORKSH COMP AN, P151
   ARMANO G, 2001, P INT C ART INT ICAI
   Atkin M. S., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P425, DOI 10.1145/375735.376404
   AYLETT R, 2000, P 19 WORKSH UK PLANN
   BODDY M, 1994, ARTIF INTELL, V67, P245, DOI 10.1016/0004-3702(94)90054-X
   Brogan D. C., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P199
   BRUDERLIN A, 1997, P INT JOINT C ART IN, P27
   Burke R., 2001, P COMP GAME DEV C, P147
   CANAMERO D, 1997, P 1 INT C AUT AG, P147
   Carlson DA, 1997, PROC GRAPH INTERF, P1
   CHENNEY S, 2001, P EUR 2001
   Dean T., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P49
   Deloura M., 2000, Game Programming Gems
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   Gross MH, 1995, VISUALIZATION '95 - PROCEEDINGS, P135, DOI 10.1109/VISUAL.1995.480805
   Grosz BJ, 1999, AI MAG, V20, P23
   HECKBERT PS, 1994, GRAPH INTER, P43
   HOPPE H, 1997, COMPUTER GRAPHICS, V31, P189
   ISLA D, 2001, P IJCAI01
   MacNamee B., 2002, PROC AISB 2002, P59
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   MUSSE SR, 1999, P ECAL 99 5 EUR C AR, P345
   NIEDERBERGER C, 2003, P EUR 2003 COMP GRAP, P323
   O'Hara N, 2002, COMPUT GRAPH FORUM, V21, P723, DOI 10.1111/1467-8659.00630
   O'Sullivan C, 2002, COMPUT GRAPH FORUM, V21, P733, DOI 10.1111/1467-8659.00631
   Pajarola R, 1998, VISUALIZATION '98, PROCEEDINGS, P19, DOI 10.1109/VISUAL.1998.745280
   Russel S. J., 1996, ARTIFICIAL INTELLIGE
   SCHMALSTIEG D, 1999, COARSE VIEW DEPENDEN
   Tanenbaum A.S., 1992, Modern Operating Systems
   Ulicny B, 2001, SPRING EUROGRAP, P163
NR 32
TC 3
Z9 4
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2005
VL 21
IS 3
BP 188
EP 202
DI 10.1007/s00371-005-0279-1
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 921UV
UT WOS:000228791700005
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Shin, BS
AF Shin, BS
TI An efficient classification and rendering method using tagged distance
   maps
SO VISUAL COMPUTER
LA English
DT Article
DE fast classification; space-leaping; tagged distance map; distance
   transformation
AB Several high-speed volume rendering methods generate spatial data structures for speedup. Although they are useful for improving rendering speed, much time may be required to regenerate them. We propose an efficient classification and rendering method that supports fast classification. While original space-leaping needs to perform distance transformations for all voxels, our method modifies the values of some parts of the entire map by assigning predefined tag values when a voxel's transparency is changed. The rendering algorithm is an extension of the space-leaping method and it determines the next sampling position by interpreting the values of those tagged voxels. This allows us to reclassify the volume quickly and to render datasets without loss of image quality.
C1 Inha Univ, Sch Comp Engn, Inchon, South Korea.
C3 Inha University
RP Shin, BS (corresponding author), Inha Univ, Sch Comp Engn, 253 Yonghyeon Dong, Inchon, South Korea.
EM bsshin@inha.ac.kr
CR BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389
   COHEN D, 1994, VISUAL COMPUT, V11, P27, DOI 10.1007/BF01900824
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Cuisenaire O, 1999, IEE CONF PUBL, P856, DOI 10.1049/cp:19990446
   Cuisenaire O, 1999, INT CONF ACOUST SPEE, P3293, DOI 10.1109/ICASSP.1999.757545
   Danskin J., 1992, ACM WORKSHOP VOLUME, P91, DOI 10.1145/147130.147155
   DATTA A, 2001, 15 INT S PAR DISTR P, P1130
   FORSMOO A, 1999, INT C IM AN PROC, P114
   Hietala R, 2000, IEEE VISUAL, P29, DOI 10.1109/VISUAL.2000.885673
   Kim TY, 2001, COMPUT GRAPH-UK, V25, P819, DOI 10.1016/S0097-8493(01)00124-8
   LACROUTE P, 1995, THESIS STANFORD U
   Lacroute P, 1994, COMPUTER GRAPHICS, V28, P451
   LEE Y, 1996, INT C PAR DISTR SYST, P488
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Lin H, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P711, DOI 10.1109/IV.2001.942134
   Ming W, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P195, DOI 10.1109/VISUAL.2002.1183775
   Sramek M, 2000, IEEE T VIS COMPUT GR, V6, P236, DOI 10.1109/2945.879785
   SUBRAMANIAN KR, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P150, DOI 10.1109/VISUAL.1990.146377
   Wan M., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P379, DOI 10.1109/VISUAL.1999.809911
   Wan M., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P397, DOI 10.1109/VISUAL.1999.809914
   Yagel R., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P62, DOI 10.1109/VISUAL.1993.398852
   Yagel R., 1992, Computer Graphics Forum, V11, pC153, DOI 10.1111/1467-8659.1130153
   ZAMPIROLLI F, 2000, 13 BRAZ S COMP GRAPH, P292
   ZUIDERVELD K, 1992, VISUALIZATION BIOMED, V1808, P324
   [No title captured]
NR 26
TC 0
Z9 3
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD NOV
PY 2004
VL 20
IS 8-9
BP 540
EP 553
DI 10.1007/s00371-004-0257-z
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 866DC
UT WOS:000224752600003
DA 2024-07-18
ER

PT J
AU Xu, XL
   Harada, K
AF Xu, XL
   Harada, K
TI Automatic surface reconstruction with alpha-shape method
SO VISUAL COMPUTER
LA English
DT Article
DE surface reconstruction; alpha-shape; density estimation
ID KERNEL DENSITY-ESTIMATION; BANDWIDTH SELECTION; POINTS; TRANSFORMATIONS;
   SET
AB In this paper, we present an algorithm for the reconstruction of piecewise linear surfaces from unorganized sample points with an improved alpha-shape. Alpha-shape provides a nice mathematical definition of the "shape" of a set of points, but the selection of an alpha value is tricky in surface reconstruction. F or solving this problem and the non-uniform distribution, we scale the alpha ball according to the point's density. The method discussed in this paper might be applied for surface reconstruction, and the process is fully automatic.
C1 Hiroshima Univ, Grad Sch Engn, Hiroshima 730, Japan.
   Hiroshima Univ, Dept Integrated Arts & Sci, Hiroshima 730, Japan.
C3 Hiroshima University; Hiroshima University
RP Hiroshima Univ, Grad Sch Engn, Hiroshima 730, Japan.
EM xuxl@hiroshima-u.ac.jp; harada@mis.hiroshima-u.ac.jp
RI Harada, Koichi/D-7410-2011
CR Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   [Anonymous], 1991, Smoothing techniques: with implementation in S
   Attene M, 2000, COMPUT GRAPH FORUM, V19, pC457, DOI 10.1111/1467-8659.00438
   Bajaj CL, 1996, GRAPH MODEL IM PROC, V58, P524, DOI 10.1006/gmip.1996.0044
   Bernardini F, 1999, INT J COMPUT GEOM AP, V9, P327, DOI 10.1142/S0218195999000236
   BOISSONNAT JD, 1984, ACM T GRAPHIC, V3, P266, DOI 10.1145/357346.357349
   CAO R, 1994, COMPUT STAT DATA AN, V17, P153, DOI 10.1016/0167-9473(92)00066-Z
   Cheng MY, 1997, ANN STAT, V25, P1001, DOI 10.1214/aos/1069362735
   CIESIELSKI Z, 1990, INT S NUM M, V94, P25
   CIESIELSKI Z, 1991, PROBAB MATH STAT-POL, V12, P1
   DEY TK, 2002, OSUCISRC1202TR31 OH
   DOBKIN DP, 1989, ALGORITHMICA, V4, P3, DOI 10.1007/BF01553877
   EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635
   EDELSBRUNNER H, 1983, IEEE T INFORM THEORY, V29, P551, DOI 10.1109/TIT.1983.1056714
   Edelsbrunner H., 1992, Weighted alpha shapes
   EPPSTEIN D, 1994, DISCRETE COMPUT GEOM, V11, P321, DOI 10.1007/BF02574012
   Grund B, 1997, J NONPARAMETR STAT, V8, P97, DOI DOI 10.1080/10485259708832716
   Guo BI, 1997, COMPUT GRAPH FORUM, V16, P177, DOI 10.1111/1467-8659.00178
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Joe B., 1991, Computer-Aided Geometric Design, V8, P123, DOI 10.1016/0167-8396(91)90038-D
   Jones MC, 1996, COMPUTATION STAT, V11, P337
   Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420
   JONES MC, 1990, AUSTR J STATIST, V32, P361
   LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079
   MATOUSEK J, 1995, INFORM PROCESS LETT, V53, P217, DOI 10.1016/0020-0190(94)00190-A
   Melkemi M, 2003, INT J PATTERN RECOGN, V17, P301, DOI 10.1142/S0218001403002368
   Melkemi M., 1997, 13 ACM S COMP GEOM N, P367
   MENCL R, 1995, COMPUT GRAPH FORUM, V14, pC445, DOI 10.1111/j.1467-8659.1995.cgf143_0445.x
   OROURKE J, 1981, P INT JOINT C ART IN, P664
   OSULLIVAN F, 1993, J ROY STAT SOC B MET, V55, P509
   Park B. U., 1992, Computational Statistics, V7, P251
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190
   RUPPERT D, 1994, ANN STAT, V22, P185, DOI 10.1214/aos/1176325365
   Ruppert D, 1997, J AM STAT ASSOC, V92, P1049, DOI 10.2307/2965570
   SAIN SR, 1994, J AM STAT ASSOC, V89, P807, DOI 10.2307/2290906
   Scott D.W., 2015, Multivariate Density Estimation: Theory, Practice and Visualization, DOI 10.1002/9780470316849
   Sheather S.J., 1992, COMPUTATION STAT, V7, P225
   Teichmann M, 1998, VISUALIZATION '98, PROCEEDINGS, P67, DOI 10.1109/VISUAL.1998.745286
   TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768
   VELTKAMP RC, 1992, THESIS CTR MATH COMP
   Wand M.P., 1992, J NONPARAMETR STAT, V2, P1, DOI [DOI 10.1080/10485259208832538, 10.1080/10485259208832538]
   WAND MP, 1993, J AM STAT ASSOC, V88, P520, DOI 10.2307/2290332
   WAND MP, 1991, J AM STAT ASSOC, V86, P343, DOI 10.2307/2290569
   WAND MP, 1994, COMPUTATION STAT, V9, P97
NR 45
TC 29
Z9 37
U1 3
U2 10
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD DEC
PY 2003
VL 19
IS 7-8
BP 431
EP 443
DI 10.1007/s00371-003-0207-1
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 749YL
UT WOS:000186957600001
DA 2024-07-18
ER

EF