FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Lin, HW
   He, XH
   Qing, LB
   Teng, QZ
   Yang, SF
AF Lin, Hongwei
   He, Xiaohai
   Qing, Linbo
   Teng, Qizhi
   Yang, Songfan
TI Improved Low-Bitrate HEVC Video Coding Using Deep Learning Based
   Super-Resolution and Adaptive Block Patching
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE High-efficiency video coding (HEVC); key frames; low bitrate; motion
   estimation; patching; super-resolution; video compression
ID SINGLE IMAGE SUPERRESOLUTION; INTERPOLATION; REGRESSION
AB Good-quality video coding for low-bitrate applications is essential for narrow bandwidth transmission and limited capacity storage. In this paper, we propose an adaptive downsampling-based coding model to improve the low-bitrate compression efficiency of high-efficiency video coding (HEVC). At the encoder, the video sequence is adaptively divided into key frames (KFs) and nonkey frames (NKFs), which are encoded at the original resolution and at a reduced resolution, respectively. At the decoder, a super-resolution method based on deep learning and gradient transformation is used to upscale the NKFs. To improve the quality of NKFs without additional information during decoding, we use motion estimation to find the most similar blocks between the upscaled NKFs and the associated high-resolution KFs. Then, an adaptive patching-based method is used to warp the low-quality NKF blocks with the high-quality KF blocks. Experimental results indicate that for standard high-definition test video sequences, the maximum improvement in the peak signal-to-noise ratio can reach 3.54 dB, and the critical bitrate can reach 9.89 Mb/s at a low bitrate when compared to HEVC. These results demonstrate significant improvements compared to existing methods.
C1 [Lin, Hongwei; He, Xiaohai; Qing, Linbo; Teng, Qizhi; Yang, Songfan] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Peoples R China.
   [Lin, Hongwei] Northwest Minzu Univ, Coll Elect Engn, Lanzhou 730030, Peoples R China.
   [Yang, Songfan] TAL Educ Grp, Artificial Intelligence Lab, Beijing 100000, Peoples R China.
C3 Sichuan University; Northwest Minzu University
RP He, XH; Qing, LB (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Peoples R China.
EM linhongwei@xbmu.edu.cn; hxh@scu.edu.cn; qing_lb@scu.edu.cn;
   qzteng@scu.edu.cn; yangsongfan@100tal.com
OI Lin, Hongwei/0000-0001-9080-0615
FU National Natural Science Foundation of China [61871279]; Fundamental
   Research for the Central Universities [31920150065]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61871279 and in part by the Fundamental
   Research for the Central Universities under Grant 31920150065. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Prof. Yap-Peng Tan.
CR [Anonymous], 2014, PROC 9 INT C INF COM
   [Anonymous], 2003, P 9 INT WORKSH ART I
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Barreto D, 2007, MULTIDIM SYST SIGN P, V18, P59, DOI 10.1007/s11045-007-0019-y
   Brandi F, 2008, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2008.4711756
   Bruckstein AM, 2003, IEEE T IMAGE PROCESS, V12, P1132, DOI 10.1109/TIP.2003.816023
   Callicó GM, 2002, IEEE IND ELEC, P1439, DOI 10.1109/IECON.2002.1185489
   Chen HG, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013004
   Chen JX, 2016, INT CONF SIGN PROCES, P663, DOI 10.1109/ICSP.2016.7877915
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong J, 2014, IEEE T CIRC SYST VID, V24, P480, DOI 10.1109/TCSVT.2013.2278146
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Farsiu S., 2016, EURASIP J ADV SIG PR, V2006
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Georgis G, 2016, IEEE T CIRC SYST VID, V26, P332, DOI 10.1109/TCSVT.2015.2389431
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Hsu CC, 2015, IEEE T IMAGE PROCESS, V24, P919, DOI 10.1109/TIP.2014.2387416
   Hung EM, 2012, IEEE T CIRC SYST VID, V22, P1321, DOI 10.1109/TCSVT.2012.2201669
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang JJ, 2017, IEEE T CYBERNETICS, V47, P3991, DOI 10.1109/TCYB.2016.2594184
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Jin Z, 2016, IEEE T CIRC SYST VID, V26, P467, DOI 10.1109/TCSVT.2015.2412791
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kumar N, 2016, IEEE T MULTIMEDIA, V18, P1504, DOI 10.1109/TMM.2016.2571625
   Lee SH, 2010, IEEE T CONSUM ELECTR, V56, P770, DOI 10.1109/TCE.2010.5506000
   Lee SH, 2003, IEEE T CONSUM ELECTR, V49, P485, DOI 10.1109/TCE.2003.1233759
   Li Y, 2018, IEEE T CIRC SYST VID, V28, P2316, DOI 10.1109/TCSVT.2017.2727682
   Liang MY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/687074
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Liu JY, 2017, IEEE T MULTIMEDIA, V19, P302, DOI 10.1109/TMM.2016.2614427
   Misu T, 2013, PICT COD SYMP, P181, DOI 10.1109/PCS.2013.6737713
   Mosleh A, 2013, IEEE T IMAGE PROCESS, V22, P4460, DOI 10.1109/TIP.2013.2273672
   Mukherjee D, 2007, PROC SPIE, V6508, DOI 10.1117/12.703268
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Osendorfer C, 2014, LECT NOTES COMPUT SC, V8836, P250, DOI 10.1007/978-3-319-12643-2_31
   Pan ZM, 2012, IEEE DATA COMPR CONF, P139, DOI 10.1109/DCC.2012.22
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen MM, 2011, IEEE T CIRC SYST VID, V21, P755, DOI 10.1109/TCSVT.2011.2130390
   Shi W, 2015, IEEE ICCE, P298, DOI 10.1109/ICCE-TW.2015.7216908
   Simonyan K, 2008, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2008.4711763
   Song BC, 2011, IEEE T CIRC SYST VID, V21, P274, DOI 10.1109/TCSVT.2010.2087454
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang R.-J., 2010, P INT C IS T SPIE EL, P7542
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yehuda D., 2014, ARXIV14044026
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zhang J, 2016, IEEE T CIRC SYST VID, V26, P479, DOI 10.1109/TCSVT.2014.2367356
   Zhang YB, 2011, IEEE T IMAGE PROCESS, V20, P3291, DOI 10.1109/TIP.2011.2158226
   Zhang Z., 2016, ARXIV160308968
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
NR 57
TC 14
Z9 14
U1 0
U2 28
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2019
VL 21
IS 12
BP 3010
EP 3023
DI 10.1109/TMM.2019.2919433
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA KJ8ZS
UT WOS:000512345200004
DA 2024-07-18
ER

PT J
AU Zhang, J
   Mei, KZ
   Zheng, Y
   Fan, JP
AF Zhang, Ji
   Mei, Kuizhi
   Zheng, Yu
   Fan, Jianping
TI Exploiting Mid-Level Semantics for Large-Scale Complex Video
   Classification
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Mid-level semantics; word weighting methods; semantic similarities;
   learning using privileged information; large-scale video classification
ID EVENT RECOGNITION; FEATURES; SEGMENTS
AB As the amount of available video data has grown substantially, automatic video classification has become an urgent yet challenging task. Most video classification methods focus on acquiring discriminative spacial visual features and motion patterns for video representation, especially deep learning methods, which have achieved very good results on action recognition problems. However, the performance of most of these methods drastically degenerates for more generic video classification tasks where the video contents are much more complex. Thus, in this paper, the mid-level semantics of videos are exploited to bridge the semantic gap between low-level features and high-level video semantics. Inspired by the term "frequency-inverse document frequency", a word weighting method for the problem of text classification is introduced to the video domain. The visual objects in videos are regarded as the words in texts, and two new weighting methods are proposed to encode videos by weighting visual objects according to the characteristics of videos. In addition, the semantic similarities between video categories and visual objects are introduced from the text domain as privileged information to facilitate classifier training on the obtained semantic representations of videos. The proposed semantic encoding method (semantic stream) is then fused with the popular two-stream CNN model for the final classification results. Experiments are conducted on two large-scale complex video datasets, CCV and ActivityNet. The experimental results validate the effectiveness of the proposed methods.
C1 [Zhang, Ji; Mei, Kuizhi] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710054, Shaanxi, Peoples R China.
   [Zheng, Yu] Xidian Univ, Sch Cyber Engn, Xian 710126, Shaanxi, Peoples R China.
   [Fan, Jianping] Univ N Carolina, Charlotte, NC 28262 USA.
C3 Xi'an Jiaotong University; Xidian University; University of North
   Carolina; University of North Carolina Charlotte
RP Mei, KZ (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710054, Shaanxi, Peoples R China.
EM zhang_ji@stu.xjtu.edu.cn; meikuizhi@mail.xjtu.edu.cn;
   yuzheng.xidian@gmail.com; jfan@uncc.edu
RI Zheng, Yu/GRJ-5808-2022; Mei, Kuizhi/B-2284-2015
OI Mei, Kuizhi/0000-0002-8119-3726
FU National Key Research and Development Plan [2016YFB1001004]; Guangdong
   Science and Technology Project [2017B010123003]; National Natural
   Science Foundation of China [61772161]
FX This work was supported in part by the National Key Research and
   Development Plan under Grant 2016YFB1001004, in part by the Guangdong
   Science and Technology Project (2017B010123003), and in part by the
   National Natural Science Foundation of China under Grant 61772161.
CR [Anonymous], 2011, P 1 INT C MULT RETR
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2010, P NIPS
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ARXIV170403503
   [Anonymous], 2016, CUHK & ETHZ & SIAT submission to ActivityNet challenge 2016
   [Anonymous], 2012, CoRR
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Chang XJ, 2016, AAAI CONF ARTIF INTE, P3464
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Chen ZY, 2017, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INNOVATION AND MANAGEMENT, VOLS I & II, P1532
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Lai KT, 2014, PROC CVPR IEEE, P2251, DOI 10.1109/CVPR.2014.288
   Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mazloom M, 2016, IEEE T MULTIMEDIA, V18, P1378, DOI 10.1109/TMM.2016.2559947
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Niu L, 2017, IEEE T NEUR NET LEAR, V28, P1290, DOI 10.1109/TNNLS.2016.2518700
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466
   Sharmanska V, 2017, ADV COMPUT VIS PATT, P31, DOI 10.1007/978-3-319-50077-5_3
   Sharmanska V, 2013, IEEE I CONF COMP VIS, P825, DOI 10.1109/ICCV.2013.107
   Simonyan K., 2014, 14091556 ARXIV
   Singh G., 2016, ARXIV160701979
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Soltanian M, 2019, IEEE T MULTIMEDIA, V21, P157, DOI 10.1109/TMM.2018.2844101
   Song H, 2018, IEEE T MULTIMEDIA, V20, P1088, DOI 10.1109/TMM.2017.2763322
   Sun C, 2014, PROC CVPR IEEE, P2569, DOI 10.1109/CVPR.2014.329
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Takahashi N, 2018, IEEE T MULTIMEDIA, V20, P513, DOI 10.1109/TMM.2017.2751969
   Tang JJ, 2018, IEEE T NEUR NET LEAR, V29, P3463, DOI 10.1109/TNNLS.2017.2728139
   Tseng VS, 2008, IEEE T MULTIMEDIA, V10, P260, DOI 10.1109/TMM.2007.911832
   Vapnik V, 2017, ANN MATH ARTIF INTEL, V81, P3, DOI 10.1007/s10472-017-9538-x
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang JZ, 2018, IEEE T MULTIMEDIA, V20, P2578, DOI 10.1109/TMM.2018.2855081
   Wang L., 2016, P ECCV
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu ZX, 2016, PROC CVPR IEEE, P3112, DOI 10.1109/CVPR.2016.339
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Wu ZX, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P791, DOI 10.1145/2964284.2964328
   Wu ZX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P167, DOI 10.1145/2647868.2654931
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Zhang J, 2018, INT C PATT RECOG, P1695, DOI 10.1109/ICPR.2018.8545513
NR 64
TC 15
Z9 15
U1 0
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2019
VL 21
IS 10
BP 2518
EP 2530
DI 10.1109/TMM.2019.2907453
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA JD1IM
UT WOS:000489728400008
DA 2024-07-18
ER

PT J
AU Ke, X
   Zou, JW
   Niu, YZ
AF Ke, Xiao
   Zou, Jiawei
   Niu, Yuzhen
TI End-to-End Automatic Image Annotation Based on Deep CNN and Multi-Label
   Data Augmentation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image annotation; convolutional neural network; deep learning;
   generative adversarial networks; data augmentation
ID FUSION; NETWORKS; RANK
AB Automatic image annotation is a key step in image retrieval and image understanding. In this paper, we present an end-to-end automatic image annotation method based on a deep convolutional neural network (CNN) and multi-label data augmentation. Different from traditional annotation models that usually perform feature extraction and annotation as two independent tasks, we propose an end-to-end automatic image annotation model based on deep CNN (E2E-DCNN). E2E-DCNN transforms the image annotation problem into a multi-label learning problem. It uses a deep CNN structure to carry out the adaptive feature learning before constructing the end-to-end annotation structure using multiple cross-entropy loss functions for training. It is difficult to train a deep CNN model using small-scale datasets or scale up multi-label datasets using traditional data augmentation methods; hence, we propose a multi-label data augmentation method based on Wasserstein generative adversarial networks (ML-WGAN). The ML-WGAN generator can approximate the data distribution of a single multi-label image. The images generated by ML-WGAN can assist in the reduction of the over-fitting problem of training a deep CNN model and enhance the generalization ability of the trained CNN model. We optimize the network structure by using deformable convolution and spatial pyramid pooling. We experiment the proposed E2E-DCNN model with data augmentation by the proposed ML-WGAN on several public datasets. The experimental results demonstrate that the proposed model outperforms the state-of-the-art automatic image annotation models.
C1 [Ke, Xiao; Niu, Yuzhen] Fuzhou Univ, Minist Educ, Coll Math & Comp Sci, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou 350116, Fujian, Peoples R China.
   [Ke, Xiao; Niu, Yuzhen] Fuzhou Univ, Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou 350116, Fujian, Peoples R China.
   [Zou, Jiawei] Fuzhou Univ, Coll Math & Comp Sci, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou 350116, Fujian, Peoples R China.
C3 Fuzhou University; Fuzhou University; Fuzhou University
RP Niu, YZ (corresponding author), Fuzhou Univ, Minist Educ, Coll Math & Comp Sci, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou 350116, Fujian, Peoples R China.; Niu, YZ (corresponding author), Fuzhou Univ, Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou 350116, Fujian, Peoples R China.
EM kex@fzu.edu.cn; zjw_gary@163.com; yuzhenniu@gmail.com
FU National Natural Science Foundation of China [61502105, 61672158];
   Technology Guidance Project of Fujian Province [2017H0015]; Natural
   Science Foundation of Fujian Province [2018J1798]; University Production
   Project of Fujian Province [2017H6008]; Fujian Collaborative Innovation
   Center for Big Data Application in Governments
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61502105 and 61672158, in part by the
   Technology Guidance Project of Fujian Province under Grant 2017H0015, in
   part by the Natural Science Foundation of Fujian Province under Grant
   2018J1798, in part by the University Production Project of Fujian
   Province under Grant 2017H6008, and in part by the Fujian Collaborative
   Innovation Center for Big Data Application in Governments. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Dr. Jingdong Wang. (Corresponding author: Yuzhen Niu.)
CR Amiri SH, 2015, PATTERN RECOGN, V48, P2241, DOI 10.1016/j.patcog.2015.01.015
   [Anonymous], 2010, P ICML
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, ARXIV170801911
   [Anonymous], 2012, NIPS
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P ICCV
   Arjovsky M., 2017, ARXIV170107875
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen WF, 2013, IEEE INT CONF CON AU, P1274
   Cui CR, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P957
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Ding XM, 2016, IEEE T MULTIMEDIA, V18, P1616, DOI 10.1109/TMM.2016.2572000
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Fu H, 2012, LECT NOTES COMPUT SC, V7577, P86, DOI 10.1007/978-3-642-33783-3_7
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jiu MY, 2017, IEEE T IMAGE PROCESS, V26, P1820, DOI 10.1109/TIP.2017.2666038
   Ke X, 2019, IEEE T INTELL TRANSP, V20, P2157, DOI 10.1109/TITS.2018.2864612
   Ke X, 2017, PATTERN RECOGN, V71, P60, DOI 10.1016/j.patcog.2017.05.020
   Kuric E, 2015, COMPUT GRAPH-UK, V47, P1, DOI 10.1016/j.cag.2014.09.035
   Lei CY, 2016, IEEE T MULTIMEDIA, V18, P687, DOI 10.1109/TMM.2015.2477277
   Li X, 2018, IEEE T MULTIMEDIA, V20, P1169, DOI 10.1109/TMM.2017.2761985
   Li ZC, 2013, PATTERN RECOGN, V46, P2700, DOI 10.1016/j.patcog.2013.03.016
   Lin BR, 2006, TENCON IEEE REGION, P520
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Niu YZ, 2019, IEEE ACCESS, V7, P782, DOI 10.1109/ACCESS.2018.2885818
   Niu YZ, 2018, IEEE T CIRC SYST VID, V28, P2433, DOI 10.1109/TCSVT.2018.2859982
   Radford A., 2015, ARXIV
   Servajean M, 2017, IEEE T MULTIMEDIA, V19, P1376, DOI 10.1109/TMM.2017.2653763
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang H, 2011, PROC CVPR IEEE, P793, DOI 10.1109/CVPR.2011.5995379
   Wang Mei, 2008, Journal of Software, V19, P2449, DOI 10.3724/SP.J.1001.2008.02449
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang YR, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P340, DOI 10.1109/ICACI.2015.7184726
   Wu BY, 2018, PROC CVPR IEEE, P7967, DOI 10.1109/CVPR.2018.00831
   Wu BY, 2017, PROC CVPR IEEE, P6194, DOI 10.1109/CVPR.2017.656
   Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968
   Xu JJ, 2014, IEEE T MULTIMEDIA, V16, P403, DOI 10.1109/TMM.2013.2291218
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhang XC, 2015, NEUROCOMPUTING, V149, P1658, DOI 10.1016/j.neucom.2014.08.027
NR 50
TC 66
Z9 70
U1 6
U2 58
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2019
VL 21
IS 8
BP 2093
EP 2106
DI 10.1109/TMM.2019.2895511
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IK7YM
UT WOS:000476809700016
DA 2024-07-18
ER

PT J
AU Tang, C
   Zhu, XZ
   Liu, XW
   Li, MM
   Wang, PC
   Zhang, CQ
   Wang, LZ
AF Tang, Chang
   Zhu, Xinzhong
   Liu, Xinwang
   Li, Miaomiao
   Wang, Pichao
   Zhang, Changqing
   Wang, Lizhe
TI Learning a Joint Affinity Graph for Multiview Subspace Clustering
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Multiview subspace clustering; low-rank representation; affinity graph
   learning
ID SEMI-SUPERVISED CLASSIFICATION; ACTION RECOGNITION; ALGORITHM; MATRIX;
   SCALE; REPRESENTATION; FEATURES; FUSION; SCENE
AB With the ability to exploit the internal structure of data, graph-based models have received a lot of attention and have achieved great success in multiview subspace clustering for multimedia data. Most of the existing methods individually construct an affinity graph for each single view and fuse the result obtained from each single graph. However, the common representation shared by different views and the complementary diversity across these views are not efficiently exploited. In addition, noise and outliers are often mixed in original data, which adversely degenerate the clustering performance of many existing methods. In this paper, we propose addressing these issues by learning a joint affinity graph for multiview subspace clustering based on a low-rank representation with diversity regularization and a rank constraint. Specifically, a low-rank representation model is employed to learn a shared sample representation coefficient matrix to generate the affinity graph. At the same time, we use diversity regularization to learn the optimal weights for each view, which can suppress the redundancy and enhance the diversity among different feature views. In addition, the cluster number is used to promote affinity graph learning by using a rank constraint. The final clustering result is obtained by using normalized cuts on the learned affinity graph. An efficient algorithm based on an augmented Lagrangian multiplier with alternating direction minimization is carefully designed to solve the resulting optimization problem. Extensive experiments on various real-world datasets are conducted, and the results demonstrate well the effectiveness of the proposed algorithm.
C1 [Tang, Chang; Wang, Lizhe] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
   [Zhu, Xinzhong] Zhejiang Normal Univ, Coll Math Phys & Informat Engn, Jinhua 321004, Zhejiang, Peoples R China.
   [Zhu, Xinzhong] Res Inst Ningbo Cixing Co Ltd, Ningbo 315336, Zhejiang, Peoples R China.
   [Liu, Xinwang; Li, Miaomiao] Natl Univ Def Technol, Sch Engn, Changsha 410073, Hunan, Peoples R China.
   [Wang, Pichao] Alibaba Grp Inc, San Mateo, CA 94402 USA.
   [Zhang, Changqing] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
C3 China University of Geosciences; Zhejiang Normal University; National
   University of Defense Technology - China; Tianjin University
RP Zhu, XZ (corresponding author), Zhejiang Normal Univ, Coll Math Phys & Informat Engn, Jinhua 321004, Zhejiang, Peoples R China.; Liu, XW (corresponding author), Natl Univ Def Technol, Sch Engn, Changsha 410073, Hunan, Peoples R China.
EM tangchang@cug.edu.cn; zxz@zjnu.edu.cn; xinwangliu@nudt.edu.cn;
   miaomiaolinudt@gmail.com; pw212@uowmail.edu.au;
   zhangchangqing@tju.edu.cn; lizhe.wang@gmail.com
RI Lu, Rui/KCJ-8212-2024; LIU, Xinwang/L-8089-2019; Zhang,
   Chang/HTO-2939-2023; Tang, Chang/AAU-8995-2020; Wang, Lizhe/L-7453-2014
OI LIU, Xinwang/0000-0001-9066-1475; Tang, Chang/0000-0002-6515-7696; Wang,
   Pichao/0000-0002-1430-0237; Wang, Lizhe/0000-0003-2766-0845
FU Fundamental Research Funds for the Central Universities, China
   University of Geosciences (Wuhan) [CUG170654]; National Natural Science
   Foundation of China [61701451, 61773392, 61602221]; Open Research
   Project of The Hubei Key Laboratory of Intelligent Geo-Information
   Processing [KLIGIP-2017B04]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities, China University of Geosciences (Wuhan) under
   Grant CUG170654, in part by the National Natural Science Foundation of
   China under Grant 61701451, Grant 61773392, and Grant 61602221, and in
   part by the Open Research Project of The Hubei Key Laboratory of
   Intelligent Geo-Information Processing (KLIGIP-2017B04).
CR [Anonymous], 2011, INT C MACHINE LEARNI
   [Anonymous], 2014, P ADV NEURAL INFORM
   [Anonymous], 2003, P ADV NEUR INF PROC
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], P INT C MACH LEARN
   [Anonymous], 1997, CBMS REGIONAL C SERI
   Bache K, 2013, UCI machine learning repository
   BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582
   Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai X., 2013, 23 INT JOINT C ART I, P2598
   CAO XC, 2015, PROC CVPR IEEE, P586, DOI DOI 10.1109/CVPR.2015.7298657
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P4381, DOI 10.1109/TIP.2015.2463223
   Chao GQ, 2016, INFORM SCIENCES, V367, P296, DOI 10.1016/j.ins.2016.06.004
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Chen Ning, 2010, Advances in neural information processing systems, P361
   Chen YL, 2017, J PARALLEL DISTR COM, V103, P96, DOI 10.1016/j.jpdc.2016.11.008
   Collins MD, 2014, LECT NOTES COMPUT SC, V8691, P282, DOI 10.1007/978-3-319-10578-9_19
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3476
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482
   Gao Y, 2016, IEEE T MULTIMEDIA, V18, P2115, DOI 10.1109/TMM.2016.2581483
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Hong RC, 2016, IEEE T MULTIMEDIA, V18, P1555, DOI 10.1109/TMM.2016.2567071
   Hou CP, 2017, IEEE T KNOWL DATA EN, V29, P1998, DOI 10.1109/TKDE.2017.2681670
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Ikizler N., 2008, ICPR, P1, DOI DOI 10.1109/ICPR.2008.4761663
   Jiang XW, 2014, IEEE T CYBERNETICS, V44, P1795, DOI 10.1109/TCYB.2013.2295329
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Kim SM, 2016, IEEE INT CONF EMBED, P212, DOI 10.1109/RTCSA.2016.48
   Kuanar SK, 2015, IEEE T MULTIMEDIA, V17, P1166, DOI 10.1109/TMM.2015.2443558
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   LI S., 2015, SDM. SIAM, P748, DOI 10.1137/1.9781611974010.84
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Lin Z.C., 2010, 100920105055 ARXIV, V1009, P5055, DOI [DOI 10.1016/J.JSB.2012.10.010, 10.1016/j.jsb.2012.10.010]
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu XW, 2017, AAAI CONF ARTIF INTE, P2259
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohar B., 1991, GRAPH THEORY COMBINA, V2, P871
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nie F., 2016, IJCAI, P1881
   Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Niu D., 2010, ICML, P831, DOI DOI 10.5555/3104322.3104428
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   SELEE T. M., 2007, CSRI SUMM P, P87
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Simonyan K., 2014, 14091556 ARXIV
   Tang C, 2018, INFORM SCIENCES, V467, P219, DOI 10.1016/j.ins.2018.08.003
   Tang C, 2018, KNOWL-BASED SYST, V145, P109, DOI 10.1016/j.knosys.2018.01.009
   Tang C, 2018, MED BIOL ENG COMPUT, V56, P1271, DOI 10.1007/s11517-017-1751-6
   Tang C, 2018, EXPERT SYST APPL, V96, P64, DOI 10.1016/j.eswa.2017.11.053
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608
   Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125
   Tao H, 2017, IEEE T IMAGE PROCESS, V26, P4283, DOI 10.1109/TIP.2017.2717191
   Topsoe F, 2000, IEEE T INFORM THEORY, V46, P1602, DOI 10.1109/18.850703
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang LZ, 2017, SOFT COMPUT, V21, P213, DOI 10.1007/s00500-016-2246-3
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wang X, 2017, ACSR ADV COMPUT, V82, P923
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Y, 2016, INT CONF ACOUST SPEE, P1521, DOI 10.1109/ICASSP.2016.7471931
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2149
   Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740
   Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yang Y, 2017, IEEE T KNOWL DATA EN, V29, P1834, DOI 10.1109/TKDE.2017.2701825
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yin QY, 2018, IEEE T NEUR NET LEAR, V29, P5541, DOI 10.1109/TNNLS.2017.2786743
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu S, 2012, IEEE T PATTERN ANAL, V34, P1031, DOI 10.1109/TPAMI.2011.255
   Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646
   Zhang C., 2017, CVPR, P4279
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang CQ, 2017, IEEE T IMAGE PROCESS, V26, P648, DOI 10.1109/TIP.2016.2627806
   Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185
   Zhang L, 2016, IEEE T MULTIMEDIA, V18, P247, DOI 10.1109/TMM.2015.2510509
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhang ZY, 2017, IEEE T PATTERN ANAL, V39, P1675, DOI 10.1109/TPAMI.2016.2601608
   Zhang Z, 2014, IEEE T CIRC SYST VID, V24, P1663, DOI 10.1109/TCSVT.2014.2305552
   Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
   Zhou C. J., 2007, P 24 INT C MACH LEAR, P1159, DOI DOI 10.1145/1273496.1273642
   Zhu XF, 2017, AAAI CONF ARTIF INTE, P2963
NR 99
TC 209
Z9 221
U1 6
U2 64
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2019
VL 21
IS 7
BP 1724
EP 1736
DI 10.1109/TMM.2018.2889560
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IF6IF
UT WOS:000473183700009
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Wu, DP
   Liu, QR
   Wang, HG
   Yang, Q
   Wang, RY
AF Wu, Dapeng
   Liu, Qianru
   Wang, Honggang
   Yang, Qing
   Wang, Ruyan
TI Cache Less for More: Exploiting Cooperative Video Caching and Delivery
   in D2D Communications
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE User-centric communications; device-to-device communications; quality of
   experience; cooperative cache list; cellular networks
ID MODE SELECTION; NETWORKS
AB The ever-increasing demand for videos on mobile devices poses a significant challenge to existing cellular network infrastructures. To cope with the challenge, we propose a user-centric video transmission mechanism based on device-to-device communications that allows mobile users to cache and share videos between each other, in a cooperative manner. The proposed solution jointly considers users' similarity in accessing videos, users' sharing willingness, users' location distribution, and users' quality of experience (QoE) requirements, in order to achieve a QoE-guaranteed video streaming service in a cellular network. Specifically, a service set consisting of several service providers and mobile users, is dynamically configured to provide timely service according to the probability of successful service. Numerical results show that when the number of providers and demanded videos is 40 and 2, respectively, the improved users experience rate in the proposed solution is approximately 85%, and the data offload rate on base station(s) is about 78%.
C1 [Wu, Dapeng; Liu, Qianru; Wang, Ruyan] Chongqing Univ Posts & Telecommun, Chongqing 400065, Peoples R China.
   [Wang, Honggang] Univ Massachusetts, Dartmouth, MA 02747 USA.
   [Yang, Qing] Univ North Texas, Denton, TX 76207 USA.
C3 Chongqing University of Posts & Telecommunications; University of
   Massachusetts System; University Massachusetts Dartmouth; University of
   North Texas System; University of North Texas Denton
RP Wang, HG (corresponding author), Univ Massachusetts, Dartmouth, MA 02747 USA.
EM wudapengphd@gmail.com; 2370094121@qq.com; hwang1@umassd.edu;
   qing.yang@montana.edu; wangry@cqupt.edu.cn
RI Wu, Dapeng/IWE-0674-2023; Wang, Honggang/D-6079-2013
OI Wu, Dapeng/0000-0003-2105-9418; Wang, Honggang/0000-0001-9475-2630
FU Natural Science Foundation of China (NSFC) [61771082, 61871062];
   National Science Foundation (NSF) [1429120, 1451629]; Program for
   Innovation Team Building at Institutions of Higher Education in
   Chongqing [CXTDX201601020]
FX This work was supported in part by the Natural Science Foundation of
   China (NSFC) under Grants 61771082 and 61871062, in part by the National
   Science Foundation (NSF) under Grants 1429120 and 1451629, and in part
   by the Program for Innovation Team Building at Institutions of Higher
   Education in Chongqing under Grant CXTDX201601020.
CR Abana MA, 2016, IEEE ACCESS, V4, P2357, DOI 10.1109/ACCESS.2016.2569591
   Andrews J. G., 2010, 2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton), P1204, DOI 10.1109/ALLERTON.2010.5707051
   [Anonymous], 2015, ACM T MULTIMEDIA COM
   [Anonymous], 2016, PROC IEEE INFOCOM 35
   [Anonymous], 2016, P 35 ANN IEEE INT C
   [Anonymous], 2017, Cisco Visual Networking Index: Forecast and Trends
   [Anonymous], 2016, IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications
   Bai B, 2016, IEEE WIREL COMMUN, V23, P74, DOI 10.1109/MWC.2016.7553029
   Cai YM, 2015, IEEE ICC, P2931, DOI 10.1109/ICC.2015.7248772
   Ge XH, 2017, IEEE T MULTIMEDIA, V19, P2345, DOI 10.1109/TMM.2017.2733461
   Georgoulas K, 2017, IEEE T KNOWL DATA EN, V29, P200, DOI 10.1109/TKDE.2016.2602345
   Golrezaei N, 2014, IEEE T WIREL COMMUN, V13, P3665, DOI 10.1109/TWC.2014.2316817
   Gu YH, 2015, PROCEEDINGS OF 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL. 1, P373
   Hua S, 2011, IEEE T MULTIMEDIA, V13, P402, DOI 10.1109/TMM.2010.2103929
   Jiajia Liu, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P46, DOI 10.1109/INFOCOM.2015.7218366
   Li CL, 2018, IEEE T MULTIMEDIA, V20, P965, DOI 10.1109/TMM.2017.2757761
   Li HX, 2012, IEEE INFOCOM SER, P172, DOI 10.1109/INFCOM.2012.6195545
   Li SS, 2018, CURR ISSUES TOUR, V21, P1761, DOI 10.1080/13683500.2016.1223023
   Malandrino F, 2014, IEEE INFOCOM SER, P1536, DOI 10.1109/INFOCOM.2014.6848089
   Militano L, 2014, IEEE INT CONF COMM, P296, DOI 10.1109/ICCW.2014.6881212
   Pan YJ, 2017, IEEE J SEL AREA COMM, V35, P978, DOI 10.1109/JSAC.2017.2680938
   Su Z, 2017, IEEE T MULTIMEDIA, V19, P2210, DOI 10.1109/TMM.2017.2733338
   Sun LF, 2017, IEEE T MULTIMEDIA, V19, P609, DOI 10.1109/TMM.2016.2635589
   Wang C, 2016, IEEE T MOBILE COMPUT, V15, P1077, DOI 10.1109/TMC.2015.2451639
   Wang RY, 2016, IEEE WIREL COMMUN, V23, P28, DOI 10.1109/MWC.2016.7553023
   Wilk Stefan, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P429, DOI 10.1109/CCNC.2016.7444818
   Wu D, 2017, IEEE T MULTIMEDIA, V19, P2571, DOI 10.1109/TMM.2017.2700621
   Wu DP, 2017, IEEE T MULTIMEDIA, V19, P1908, DOI 10.1109/TMM.2017.2692648
   Xiang L., 2010, P 16 ACM SIGKDD INT, P723, DOI 10.1145/1835804.1835896
   Xu J, 2015, IEEE J-STSP, V9, P330, DOI 10.1109/JSTSP.2014.2370942
   Xu YL, 2017, IEEE T MULTIMEDIA, V19, P2597, DOI 10.1109/TMM.2017.2700208
   Yan JJ, 2017, IEEE ACCESS, V5, P3444, DOI 10.1109/ACCESS.2017.2671404
   Zhang Y, 2011, IEEE COMMUN MAG, V49, P44, DOI 10.1109/MCOM.2011.5741145
   Zhou C, 2016, IEEE T MULTIMEDIA, V18, P738, DOI 10.1109/TMM.2016.2522650
NR 34
TC 83
Z9 85
U1 2
U2 37
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2019
VL 21
IS 7
BP 1788
EP 1798
DI 10.1109/TMM.2018.2885931
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IF6IF
UT WOS:000473183700014
OA Bronze
DA 2024-07-18
ER

PT J
AU Xu, J
   Li, M
   Fan, JL
   Zhao, XQ
   Chang, ZG
AF Xu, Jian
   Li, Meng
   Fan, Jiulun
   Zhao, Xiaoqiang
   Chang, Zhiguo
TI Self-Learning Super-Resolution Using Convolutional Principal Component
   Analysis and Random Matching
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Super-resolution; random oscillation; neighbor embedding; self-learning;
   principal component analysis
ID SINGLE-IMAGE SUPERRESOLUTION; SPARSE REPRESENTATION; INTERPOLATION;
   PROJECTION
AB Self-learning super-resolution (SLSR) algorithms have the advantage of being independent of an external training database. This paper proposes an SLSR algorithm that uses convolutional principal component analysis (CPCA) and random matching. The technologies of CPCA and random matching greatly improve the efficiency of self-learning. There are two main steps in this algorithm: forming the training and testing the data sets and patch matching. In the data set forming step, we propose the CPCA to extract the low-dimensional features of the data set. The CPCA uses a convolutional method to quickly extract the principal component analysis (PCA) features of each image patch in every training and testing image. In the patch matching step, we propose a two-step random oscillation accompanied with propagation to accelerate the matching process. This patch matching method avoids exhaustive searching by utilizing the local similarity prior of natural images. The two-step random oscillation first performs a coarse patch matching using the variance feature and then performs a detailed matching using the PCA feature, which is useful to find reliable matching patches. The propagation strategy enables patches to propagate the good matching patches to their neighbors. The experimental results demonstrate that the proposed algorithm has a substantially lower time cost than that of many existing self-learning algorithms, leading to better reconstruction quality.
C1 [Xu, Jian; Li, Meng; Fan, Jiulun; Zhao, Xiaoqiang] Xian Univ Posts & Telecommun, Sch Commun & Informat Engn, Xian 710121, Shaanxi, Peoples R China.
   [Chang, Zhiguo] Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Chang'an University
RP Fan, JL (corresponding author), Xian Univ Posts & Telecommun, Sch Commun & Informat Engn, Xian 710121, Shaanxi, Peoples R China.
EM xujian_paper@126.com; 648516742@qq.com; jiulunf@163.com;
   zxq7703@126.com; chang_zg@126.com
RI Fan, Jiulun/AAG-4371-2020
OI Fan, Jiulun/0000-0002-7553-204X
FU National Natural Science Foundation of China [61601362, 41874173,
   61571361, 61671377, 41504115]; New Star Team of Xi'an University of
   Posts and Telecommunications [xyt2016-01]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61601362, 41874173, 61571361, 61671377,
   and 41504115, in part by the New Star Team of Xi'an University of Posts
   and Telecommunications xyt2016-01.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.618
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], CVGIP GRAPHICAL MODE
   [Anonymous], 2015, MATH PROBL ENG
   Bao CL, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487966
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cai J, 2016, NEUROCOMPUTING, V182, P322, DOI 10.1016/j.neucom.2015.12.039
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chang K, 2018, IEEE SIGNAL PROC LET, V25, P596, DOI 10.1109/LSP.2018.2815003
   Chen XX, 2014, IEEE SIGNAL PROC LET, V21, P79, DOI 10.1109/LSP.2013.2286417
   Chen XX, 2014, SIGNAL PROCESS, V94, P6, DOI 10.1016/j.sigpro.2013.06.016
   Chinh Dang, 2014, IEEE Signal Processing Letters, V21, P1245, DOI 10.1109/LSP.2014.2332118
   Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Hou B, 2018, IEEE T GEOSCI REMOTE, V56, P2312, DOI 10.1109/TGRS.2017.2778191
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P2650, DOI 10.1109/TIP.2018.2809472
   Jian X., 2015, J ELECT IMAG, V24, P1
   Jing XY, 2017, IEEE T IMAGE PROCESS, V26, P1363, DOI 10.1109/TIP.2017.2651364
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Li XY, 2015, NEUROCOMPUTING, V149, P940, DOI 10.1016/j.neucom.2014.07.040
   Li XY, 2014, NEUROCOMPUTING, V139, P310, DOI 10.1016/j.neucom.2014.02.026
   Li YB, 2015, IEEE I CONF COMP VIS, P450, DOI 10.1109/ICCV.2015.59
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Mandal D, 2016, IEEE T IMAGE PROCESS, V25, P3826, DOI 10.1109/TIP.2016.2577885
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Shi W., 2016, PROC IEEE C COMPUT V, P1
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Timofte R, 2016, COMPUT VIS IMAGE UND, V142, P1, DOI 10.1016/j.cviu.2015.09.008
   Timoteo R.D. A., 2014, Proc. Adv. Intl. Conf. Telecommun, V10, P119
   Wang S, 2018, IEEE T IMAGE PROCESS, V27, P1086, DOI 10.1109/TIP.2017.2768185
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2015, IEEE T IMAGE PROCESS, V24, P4359, DOI 10.1109/TIP.2015.2462113
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xian Y, 2016, J VIS COMMUN IMAGE R, V35, P91, DOI 10.1016/j.jvcir.2015.11.015
   Yang JC, 2012, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2012.6247948
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WM, 2016, IEEE T MULTIMEDIA, V18, P313, DOI 10.1109/TMM.2016.2515997
   Yin M, 2015, COMPUT VIS IMAGE UND, V132, P12, DOI 10.1016/j.cviu.2014.11.005
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang KB, 2017, IEEE T NEUR NET LEAR, V28, P1109, DOI 10.1109/TNNLS.2015.2511069
   Zhang KB, 2013, IEEE T NEUR NET LEAR, V24, P1648, DOI 10.1109/TNNLS.2013.2262001
   Zhang YB, 2016, IEEE T MULTIMEDIA, V18, P405, DOI 10.1109/TMM.2015.2512046
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 63
TC 10
Z9 10
U1 1
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2019
VL 21
IS 5
BP 1108
EP 1121
DI 10.1109/TMM.2018.2871948
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HV8HY
UT WOS:000466223600003
DA 2024-07-18
ER

PT J
AU Yu, E
   Sun, JD
   Li, J
   Chang, XJ
   Han, XH
   Hauptmann, AG
AF Yu, En
   Sun, Jiande
   Li, Jing
   Chang, Xiaojun
   Han, Xian-Hua
   Hauptmann, Alexander G.
TI Adaptive Semi-Supervised Feature Selection for Cross-Modal Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Semi-supervised; cross-modal retrieval; feature selection
ID REPRESENTATION
AB Inorder to exploit the abundant potential information of the unlabeled data and contribute to analyzing the correlation among heterogeneous data, we propose the semi-supervised model named adaptive semi-supervised feature selection for cross-modal retrieval. First, we utilize the semantic regression to strengthen the neighboring relationship between the data with the same semantic. And the correlation between heterogeneous data can be optimized via keeping the pairwise closeness when learning the common latent space. Second, we adopt the graph-based constraint to predict accurate labels for unlabeled data, and it can also keep the geometric structure consistency between the label space and the feature space of heterogeneous data in the common latent space. Finally, an efficient joint optimization algorithm is proposed to update the mapping matrices and the label matrix for unlabeled data simultaneously and iteratively. It makes samples from different classes to be far apart, while the samples from same class lie as close as possible. Meanwhile, the l(2,1)-norm constraint is used for feature selection and outlier reduction when the mapping matrices are learned. In addition, we propose learning different mapping matrices corresponding to different sub-tasks to emphasize the semantic and structural information of query data. Experiment results on three datasets demonstrate that our method performs better than the state-of-the-art methods.
C1 [Yu, En; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Li, Jing] Shandong Management Univ, Sch Mech & Elect Engn, Jinan 250014, Shandong, Peoples R China.
   [Li, Jing] Shandong Normal Univ, Jinan 250014, Shandong, Peoples R China.
   [Chang, Xiaojun] Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia.
   [Han, Xian-Hua] Yamaguchi Univ, Grad Sch Sci & Technol Innovat, Yamaguchi 7538511, Japan.
   [Hauptmann, Alexander G.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
C3 Shandong Normal University; Shandong Management University; Shandong
   Normal University; Monash University; Yamaguchi University; Carnegie
   Mellon University
RP Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM sdnu_enyu@hotmail.com; jiandesun@hotmail.com; lijingjdsun@hotmail.com;
   cxj273@gmail.com; hanxhua@yamaguchi-u.ac.jp; alex@cs.cmu.edu
RI YU, EN/JVZ-8283-2024; Chang, Xiaojun/A-2055-2015; Zhang,
   Yuchen/GYI-8858-2022; Han, Xian-Hua/A-5563-2017
OI YU, EN/0009-0005-3335-5486; Chang, Xiaojun/0000-0002-7778-8807; Yu,
   En/0000-0002-5050-6400; Han, Xian-Hua/0000-0002-5003-3180
FU Natural Science Foundation for Distinguished Young Scholars of Shandong
   Province [JQ201718]; Key Research and Development Foundation of Shandong
   Province [2016GGX101009]; Natural Science Foundation of China
   [U1736122]; Shandong Provincial Key Research and Development Plan
   [2017CXGC1504]; Intelligence Advanced Research Projects Activity (IARPA)
   via Department of Interior/Interior Business Center (DOI/IBC)
   [D17PC00340]
FX This work was supported in part by the Natural Science Foundation for
   Distinguished Young Scholars of Shandong Province (JQ201718), in part by
   the Key Research and Development Foundation of Shandong Province
   (2016GGX101009), in part by the Natural Science Foundation of China
   (U1736122), in part by Shandong Provincial Key Research and Development
   Plan (2017CXGC1504), and in part by the Intelligence Advanced Research
   Projects Activity (IARPA) via Department of Interior/Interior Business
   Center (DOI/IBC) contract no. D17PC00340.
CR [Anonymous], 2003, P ACM INT C MULT ACM
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2013, P 21 ACM INT C MULT
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao GQ, 2018, IEEE T CYBERNETICS, V48, P2542, DOI 10.1109/TCYB.2017.2742705
   Cao GQ, 2017, IEEE SIGNAL PROC LET, V24, P1537, DOI 10.1109/LSP.2017.2748392
   Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P227, DOI 10.1145/2964284.2967216
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Liang X, 2013, P 3 ACM INT C MULT R, P175
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Mandal D, 2017, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2017.282
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shao J, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P332, DOI 10.1145/3126686.3126726
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Simonyan K., 2014, 14091556 ARXIV
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Wu F, 2007, P IEEE INT C IM PROC, P1465
   Wu JL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P917, DOI 10.1145/3077136.3080678
   Yu Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2600428.2609563
   Zhai X., 2013, PROC 27 AAAI C ARTIF, P1198
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang H, 2013, NEUROCOMPUTING, V119, P10, DOI 10.1016/j.neucom.2012.03.033
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
   Zhang L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1355, DOI 10.1145/2964284.2964336
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhuang Y., 2013, P 27 AAAI C ART INT, P1070
   2014, PATTERN RECOGN, V47, P3168, DOI DOI 10.1016/J.PATCOG.2014.04.004
NR 45
TC 114
Z9 116
U1 1
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2019
VL 21
IS 5
BP 1276
EP 1288
DI 10.1109/TMM.2018.2877127
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HV8HY
UT WOS:000466223600016
DA 2024-07-18
ER

PT J
AU Chen, TS
   Chen, RQ
   Nie, L
   Luo, XN
   Liu, XB
   Lin, L
AF Chen, Tianshui
   Chen, Riquan
   Nie, Lin
   Luo, Xiaonan
   Liu, Xiaobai
   Lin, Liang
TI Neural Task Planning With AND-OR Graph Representations
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Scene understanding; task planning; action prediction; recurrent neural
   network
ID MODEL; NETWORKS
AB This paper focuses on semantic task planning, that is, predicting a sequence of actions toward accomplishing a specific task under a certain scene, which is a new problem in computer vision research. The primary challenges are how to model the task-specific knowledge and how to integrate this knowledge into the learning procedure. In this paper, we propose training a recurrent long short-term memory (LSTM) network to address this problem, that is, taking a scene image (including prelocated objects) and the specified task as input and recurrently predicting action sequences. However, training such a network generally requires large numbers of annotated samples to cover the semantic space (e.g., diverse action decomposition and ordering). To overcome this issue, we introduce a knowledge AND-OR graph (AOG) for task description, which hierarchically represents a task as atomic actions. With this AOG representation, we can produce many valid samples (i.e., action sequences according to common sense) by training another auxiliary LSTM network with a small set of annotated samples. Furthermore, these generated samples (i.e., task-oriented action sequences) effectively facilitate training of the model for semantic task planning. In our experiments, we create a new dataset that contains diverse daily tasks and extensively evaluates the effectiveness of our approach.
C1 [Chen, Tianshui; Chen, Riquan; Nie, Lin; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Luo, Xiaonan] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin 541004, Peoples R China.
   [Liu, Xiaobai] San Diego State Univ, Dept Comp Sci, San Diego, CA 92182 USA.
C3 Sun Yat Sen University; Guilin University of Electronic Technology;
   California State University System; San Diego State University
RP Nie, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM tianshuichen@gmail.com; 873070557@qq.com; nielin@mail.sysu.edu.cn;
   luoxn@guet.edu.cn; xiaobai.liu@sdsu.edu; linliang@ieee.org
RI Lin, L/HKO-8213-2023; L, J/JEF-9564-2023; liu, xiaobai/J-4120-2014; Lin,
   Liang/IQR-8601-2023; l, j/HNC-5728-2023; zhang, cl/JDW-6549-2023; l,
   j/JVZ-8480-2024; LU, LU/JEZ-4760-2023
OI Lin, Liang/0000-0003-2248-3755; 
FU State Key Development Program [2018YFC0830103]; National Natural Science
   Foundation of China [61622214, U1611461]; Science and Technology
   Planning Project of Guangdong Province [2017A020208041]; Guangdong
   Natural Science Foundation Project for Research Teams [2017A030312006]
FX This work was supported in part by the State Key Development Program
   under Grant 2018YFC0830103, in part by the National Natural Science
   Foundation of China under Grants 61622214 and U1611461, in part by the
   Science and Technology Planning Project of Guangdong Province under
   Grant 2017A020208041, and in part by the Guangdong Natural Science
   Foundation Project for Research Teams under Grant 2017A030312006. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Xavier Gir-i-Nieto. (Corresponding
   author: Lin Nie.)
CR Abdulnabi AH, 2015, IEEE T MULTIMEDIA, V17, P1949, DOI 10.1109/TMM.2015.2477680
   Agrawal Pulkit, 2016, NIPS, P5074
   ALLEN JF, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P3
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Beetz Michael, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P529, DOI 10.1109/Humanoids.2011.6100855
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   BIALYNICKIBIRULA I, 1975, COMMUN MATH PHYS, V44, P129, DOI 10.1007/BF01608825
   Bollini Mario., 2011, PR2 WORKSHOP RESULTS
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Cambon S, 2009, INT J ROBOT RES, V28, P104, DOI 10.1177/0278364908097884
   Cho K., 2014, ARXIV14061078
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188
   Finn Chelsea, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2786, DOI 10.1109/ICRA.2017.7989324
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Guo YA, 2016, IEEE T MULTIMEDIA, V18, P1977, DOI 10.1109/TMM.2016.2597007
   Gupta S, 2017, PROC CVPR IEEE, P7272, DOI 10.1109/CVPR.2017.769
   HARARY F, 1962, SIAM REV, V4, P202, DOI 10.1137/1004057
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kambhampati S., 1991, AAAI-91. Proceedings Ninth National Conference on Artificial Intelligence, P199
   KAUTZ H, 1992, ECAI 92 - 10TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE : PROCEEDINGS, P359
   Khan Faisal, 2011, ADV NEURAL INFORM PR, V24
   Kolve E, 2017, AI2 THOR INTERACTIVE
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Li WX, 2017, IEEE T MULTIMEDIA, V19, P367, DOI 10.1109/TMM.2016.2616279
   Lin L, 2017, IEEE INT CON MULTI, P625, DOI 10.1109/ICME.2017.8019345
   Lin L, 2009, PATTERN RECOGN LETT, V30, P180, DOI 10.1016/j.patrec.2008.02.023
   Miller S, 2012, INT J ROBOT RES, V31, P249, DOI 10.1177/0278364911430417
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Parker LE, 1997, ADV ROBOTICS, V11, P305, DOI 10.1163/156855397X00344
   Pascanu R., 2017, ARXIV170706170
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Plaku E, 2010, IEEE INT CONF ROBOT, P5002, DOI 10.1109/ROBOT.2010.5509563
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rintanen J, 2006, ARTIF INTELL, V170, P1031, DOI 10.1016/j.artint.2006.08.002
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   SACERDOTI ED, 1974, ARTIF INTELL, V5, P115, DOI 10.1016/0004-3702(74)90026-5
   Samanta S, 2014, IEEE T MULTIMEDIA, V16, P1525, DOI 10.1109/TMM.2014.2326734
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith DE, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P326
   Sung J., 2013, P INT C MACH LEARN
   Sung JY, 2014, IEEE INT C INT ROBOT, P2970, DOI 10.1109/IROS.2014.6942972
   Tang Jian, 2016, ARXIV161109900
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Wang L, 2017, IEEE T MULTIMEDIA, V19, P646, DOI 10.1109/TMM.2016.2617079
   Wen T.-H., 2015, P 2015 C EMP METH NA, P1711, DOI DOI 10.18653/V1/D15-1199
   Wolfe J. A., 2010, P INT C AUTOMATED PL, P254
   Wu BX, 2014, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2014.334
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Xiong CM, 2016, IEEE INT CONF ROBOT, P2144, DOI 10.1109/ICRA.2016.7487364
   Xu WR, 2017, IEEE T MULTIMEDIA, V19, P1494, DOI 10.1109/TMM.2017.2674622
   Yang Q, 2007, ARTIF INTELL, V171, P107, DOI 10.1016/j.artint.2006.11.005
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhu YK, 2017, INT CONF ACOUST SPEE, P5335, DOI 10.1109/ICASSP.2017.7953175
   Zhu Y, 2017, IEEE I CONF COMP VIS, P483, DOI 10.1109/ICCV.2017.60
   Zhu YK, 2014, LECT NOTES COMPUT SC, V8690, P408, DOI 10.1007/978-3-319-10605-2_27
NR 71
TC 10
Z9 12
U1 0
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2019
VL 21
IS 4
BP 1022
EP 1034
DI 10.1109/TMM.2018.2870062
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HQ4XD
UT WOS:000462413700017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kalluri, M
   Jiang, MQ
   Ling, N
   Zheng, JH
   Zhang, P
AF Kalluri, Madhusudan
   Jiang, Minqiang
   Ling, Nam
   Zheng, Jianhua
   Zhang, Philipp
TI Adaptive RD Optimal Sparse Coding With Quantization for Image
   Compression
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image compression; image coding; overcomplete dictionary; sparse
   representation; sparse coding; quantization
AB In image and video compression for many multimedia applications, an image/frame is divided into component blocks or patches and is then encoded using some type of transform. Traditional transforms use a complete dictionary of basis functions. A recent technique of growing interest is signal approximation using a linear combination of basis functions from an overcomplete dictionary. The result is a sparse set of coefficients that can represent the original signal and is called sparse coding. This is an NP-hard problem. Orthogonal matching pursuit is a greedy algorithm that is effectively used to address this problem. Keeping in mind the iterative nature of this algorithm, in a recent conference publication, we proposed a rate distortion optimization (RDO) method to select the best sparse representation among iterations up to a target sparsity level. In this paper, we expand the work and consider an adaptive coding scheme that takes advantage of both discrete cosine transform (DCT) and sparse coding. This scheme shows a better performance over plain DCT or sparse coding schemes. We further propose a scheme to increase the coding efficiency of sparse coding by quantizing the sparse coefficients. We investigate an RDO method to select the value of the quantization parameter from a range, balancing distortion, and bit rate. Based on experimental results, we provide a comparison between conventional DCT-based coding, sparse coding scheme, our mixed coding scheme, and the proposed method that includes quantization of the sparse coefficients.
C1 [Kalluri, Madhusudan; Jiang, Minqiang; Ling, Nam] Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
   [Zheng, Jianhua; Zhang, Philipp] HiSilicon Technol Co Ltd, Huawei Technol, Shenzhen 518129, Peoples R China.
C3 Santa Clara University; Huawei Technologies
RP Kalluri, M (corresponding author), Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
EM madhusudan_kalluri@yahoo.com; jmqjmq2003@yahoo.com; nling@scu.edu;
   zhengjianhua@hisilicon.com; philipp.zhang@huawei.com
FU HiSilicon Technologies Co., Ltd., under Huawei Technologies grant
FX This work was supported in part by the HiSilicon Technologies Co., Ltd.,
   under Huawei Technologies grant. The associate editor coordinating the
   review of this manuscript and approving it for publication was Prof.
   Susanto Rahardja.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Frossard P, 2004, IEEE T SIGNAL PROCES, V52, P525, DOI 10.1109/TSP.2003.821105
   Guha T, 2014, IEEE T MULTIMEDIA, V16, P980, DOI 10.1109/TMM.2014.2306175
   Horev I., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P592
   Jiang M., 2015, P INT S CIRC SYST MO, P2230
   Kang JW, 2013, IEEE T IMAGE PROCESS, V22, P2711, DOI 10.1109/TIP.2013.2256917
   Kang JW, 2011, IEEE INT SYMP CIRC S, P109
   Kutyniok G., THEORY APPL COMPRESS
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Neff R, 2000, IEEE T CIRC SYST VID, V10, P895, DOI 10.1109/76.867927
   Neff R, 1997, IEEE T CIRC SYST VID, V7, P158, DOI 10.1109/76.554427
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Rath G., 2008, 16 EUR SIGN PROC C L, P1
   Rubinstein R., 2008, CS200808 HAIF STAT U
   Taubman D.S., 2001, JPEG 2000: Image Compression Fundamentals, Standards and Practice
   Ventura RMFI, 2006, IEEE T IMAGE PROCESS, V15, P726, DOI 10.1109/TIP.2005.860596
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
NR 20
TC 16
Z9 17
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JAN
PY 2019
VL 21
IS 1
BP 39
EP 50
DI 10.1109/TMM.2018.2847228
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HF5DV
UT WOS:000454253700004
DA 2024-07-18
ER

PT J
AU Guo, DS
   Li, W
   Fang, XZ
AF Guo, Dashan
   Li, Wei
   Fang, Xiangzhong
TI Fully Convolutional Network for Multiscale Temporal Action Proposals
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Temporal convolution; receptive field; multiple scale ranges; duration
   regression
AB Similar to the function of object proposals in localizing objects within images, temporal action proposals can facilitate the extraction of semantic segments and simplify the computations required for temporal action localization in untrimmed videos. In this paper, we propose a fully convolutional network to identify multistale temporal action proposals (FCN-TAP) that utilizes only the temporal convolutions to retrieve accurate action proposals for video sequences. Using gated linear units, our network enables simple but powerful inferences, and by parallelizing the computations, it significantly improves performances compared with previous recurrent models. To capture more temporal contexts with fewer parameters, we apply dilated convolutions to expand the receptive fields of our network. Moreover, we divide the receptive fields into multiple scale ranges and then refine the corresponding temporal boundaries using duration regression at each scale. To generate suitable segments with arbitrary durations for training, we design a new strategy to select sampled candidates within the corresponding scale range. The power of our method is demonstrated through experiments on the THUMOS'14 and ActivityNet datasets, where FCN-TAP performs better and achieves a remarkable speedup compared to other state-of-the-art methods. Additional experiments show that our method generates high-quality proposals and improves the localization stage of existing action detection pipelines.
C1 [Guo, Dashan; Li, Wei; Fang, Xiangzhong] Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Guo, DS (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
EM dmlab_gds@sjtu.edu.cn; liweihfyz@sjtu.edu.cn; xzfang@sjtu.edu.cn
FU Shanghai Science and Technology Committee [14511110100]
FX This article is supported by the Shanghai Science and Technology
   Committee (Project ID: 14511110100). The associate editor coordinating
   the review of this manuscript and approving it for publication was Dr.
   David Crandall. (Corresponding author: Dashan Guo)
CR Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chollet F, 2015, KERAS
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Dauphin Y. N., 2016, CORR
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gehring J., 2017, P MACHINE LEARNING R, P1243
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hu WM, 2016, IEEE T MULTIMEDIA, V18, P76, DOI 10.1109/TMM.2015.2496372
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Krüger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030
   Lin T., 2017, P IEEE INT C COMP VI
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Theano Development Team, 2016, ARXIV160502688
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yu F., 2015, ARXIV
   Zhang Z, 2016, IEEE T MULTIMEDIA, V18, P2079, DOI 10.1109/TMM.2016.2594138
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhou Z, 2015, IEEE T MULTIMEDIA, V17, P512, DOI 10.1109/TMM.2015.2404779
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 45
TC 22
Z9 23
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2018
VL 20
IS 12
BP 3428
EP 3438
DI 10.1109/TMM.2018.2839534
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HA4EY
UT WOS:000450212600020
DA 2024-07-18
ER

PT J
AU Vlachos, E
   Lalos, AS
   Spathis-Papadiotis, A
   Moustakas, K
AF Vlachos, Evangelos
   Lalos, Aris S.
   Spathis-Papadiotis, Aristotelis
   Moustakas, Konstantinos
TI Distributed Consolidation of Highly Incomplete Dynamic Point Clouds
   Based on Rank Minimization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Incomplete dynamic point clouds; point cloud reconstruction; animated
   models; matrix completion; distributed optimization
ID MESHES; ALGORITHM; STEREO; DEPTH
AB Recently, there has been increasing interest for easy and reliable generation of 3-D animated models facilitating several real-time applications (like immersive telepresence, motion capture, and gaming). In most of these applications, the reconstruction of soft body animations is based on time - varying point clouds, which are non-uniformly sampled and highly incomplete. To overcome these significantly challenging imperfections without any additional information, first we introduce a novel reconstruction technique based on rank minimization theory, which can result in a unique solution to the otherwise ill-posed problem. This technique is further extended to exploit the spatial coherence, which usually characterizes the soft-body animations. Based on the developed tools, we propose a distributed consolidation technique where the reconstruction is performed by working simultaneously on several groups of frames. To achieve this, we impose temporal coherence between successive frame clusters by constraining the rank minimization problem. We validate the proposed techniques via experimental evaluation under different configurations and animated models, where we show that the high-frequency details of the models can be adequately recovered from a highly incomplete geometry data set.
C1 [Vlachos, Evangelos; Lalos, Aris S.; Spathis-Papadiotis, Aristotelis; Moustakas, Konstantinos] Univ Patras, Elect & Comp Engn Dept, GR-26500 Rion, Greece.
C3 University of Patras
RP Vlachos, E (corresponding author), Univ Patras, Elect & Comp Engn Dept, GR-26500 Rion, Greece.
EM vlaxose@ece.upatras.gr; aris.lalos@ece.upatras.gr;
   agspathis@ece.upatras.gr; moustakas@ece.upatras.gr
RI Lalos, Aris/W-6443-2019; Vlachos, Evangelos/Y-9808-2019
OI Lalos, Aris/0000-0003-0511-9302; Vlachos, Evangelos/0000-0003-1501-0722;
   Moustakas, Konstantinos/0000-0001-7617-227X
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Anguelov Dragomir., 2004, NIPS, P33
   [Anonymous], 2006, Effective Computational Geometry for Curves and Surfaces, DOI DOI 10.1007/978-3-540-33259-6_6
   [Anonymous], 2013, MATRIX COMPUTATIONS
   [Anonymous], 2002, THESIS STANFORD U
   Arvanitis G., 2017, P 3DTV C TRUE VIS CA, P1
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Bezanson J, 2014, CORR
   Blanz V, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P293, DOI 10.1109/TDPVT.2004.1335212
   Bouhamidi A, 2008, APPL MATH COMPUT, V206, P687, DOI 10.1016/j.amc.2008.09.022
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37
   Deng Y, 2012, IEEE J-STSP, V6, P566, DOI 10.1109/JSTSP.2012.2195472
   Deng Y, 2011, IEEE T IMAGE PROCESS, V20, P2329, DOI 10.1109/TIP.2011.2109729
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Jeff B., 2014, CORR
   Johnson C.R., 1990, P S APPL MATH, V40
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Lalos AS, 2017, VISUAL COMPUT, V33, P811, DOI 10.1007/s00371-017-1395-4
   Lalos AS, 2017, IEEE T MULTIMEDIA, V19, P41, DOI 10.1109/TMM.2016.2605927
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276405
   Liu SJ, 2012, IEEE COMPUT GRAPH, V32, P70, DOI 10.1109/MCG.2011.14
   Magnus J.R., 1999, MATRIX DIFFERENTIAL
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   SAAD Y, 1986, SIAM J SCI STAT COMP, V7, P856, DOI 10.1137/0907058
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Süssmuth J, 2008, COMPUT GRAPH FORUM, V27, P1469, DOI 10.1111/j.1467-8659.2008.01287.x
   Vása L, 2014, COMPUT GRAPH FORUM, V33, P145, DOI 10.1111/cgf.12304
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526
   Wang J, 2013, COMPUT GRAPH FORUM, V32, P207, DOI 10.1111/cgf.12187
   Weise T., 2007, IEEE CVPR, P1, DOI DOI 10.1109/CVPR.2007.383291
   Xiong SY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661263
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhou B, 2008, SYST CONTROL LETT, V57, P200, DOI 10.1016/j.sysconle.2007.08.010
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 39
TC 8
Z9 9
U1 1
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2018
VL 20
IS 12
BP 3276
EP 3288
DI 10.1109/TMM.2018.2839911
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HA4EY
UT WOS:000450212600008
DA 2024-07-18
ER

PT J
AU Liu, GG
AF Liu, Guangen
TI Robust Visual Tracking via Smooth Manifold Kernel Sparse Learning
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Online dictionary learning; Symmetric Positive Definite manifolds;
   sparse representation; spatial-temporal correlation; visual tracking
ID OBJECT TRACKING; FACE RECOGNITION; REPRESENTATION; BENCHMARK; MATRICES
AB Various sparse-representation-based tracking methods have been proposed to tackle visual tracking problems, and most of them use simple intensity feature as the observation of target object. Moreover, most of them only take into account either global or local image representation and only exploit the underlying relationship among target candidates in a single frame. All of these may make their appearance models less robust to deal with complex scenes. To overcome these problems, we propose a smooth manifold kernel sparse tracker under the framework of particle filter. The proposed method characterizes targets and candidates with region covariance matrix descriptors, and constructs object tracking as a kernel sparse learning model based on symmetric positive-definite (SPD) manifolds. The spatial-temporal interdependencies among candidates and global-local representations of candidates are jointly considered and unified via the kernel sparse learning model. Moreover, in order to make the model more robust, the detection of outlier tasks is also taken into account. To handle the variation of object appearance, we develop a robust and efficient online dictionary learning algorithm on SPD manifolds. Extensive experiments on multiple benchmark datasets demonstrate that our tracker performs favorably against state-of-the-art trackers.
C1 [Liu, Guangen] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, GG (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM lgelge95@stu.xjtu.edu.cn
FU Education Ministry Joint Foundation [614A0223]
FX This work was supported by the Education Ministry Joint Foundation under
   Project 614A0223.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Chen XT, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON ADVANCED FIBERS AND POLYMER MATERIALS, VOLS 1 AND 2, P746
   Cheng G, 2013, SIAM J IMAGING SCI, V6, P592, DOI 10.1137/110853376
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Gao SH, 2015, INT J COMPUT VISION, V111, P365, DOI 10.1007/s11263-014-0750-4
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Gong Pinghua, 2012, KDD, V2012, P895
   Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu HW, 2018, IEEE T NEUR NET LEAR, V29, P1786, DOI 10.1109/TNNLS.2017.2688448
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Li PH, 2013, IEEE I CONF COMP VIS, P1601, DOI 10.1109/ICCV.2013.202
   Li XT, 2008, IEEE BIPOL BICMOS, P1, DOI 10.1109/BIPOL.2008.4662699
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P5867, DOI 10.1109/TIP.2016.2615812
   Ma B, 2016, IEEE T CYBERNETICS, V46, P2411, DOI 10.1109/TCYB.2015.2477879
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P4199, DOI 10.1109/TIP.2016.2588329
   Ma B, 2015, IEEE I CONF COMP VIS, P4400, DOI 10.1109/ICCV.2015.500
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mei X, 2015, IEEE T NEUR NET LEAR, V26, P2874, DOI 10.1109/TNNLS.2015.2399233
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shen JB, 2018, IEEE T INTELL TRANSP, V19, P162, DOI 10.1109/TITS.2017.2750082
   Sui Y, 2018, INT J COMPUT VISION, V126, P515, DOI 10.1007/s11263-017-1049-z
   Sui Y, 2018, IEEE T IMAGE PROCESS, V27, P1282, DOI 10.1109/TIP.2017.2779275
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wang Wenguan, 2015, IEEE Trans Image Process, V24, P3137, DOI 10.1109/TIP.2015.2438550
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu YW, 2015, IEEE T IMAGE PROCESS, V24, P3729, DOI 10.1109/TIP.2015.2451953
   Wu YW, 2015, PATTERN ANAL APPL, V18, P45, DOI 10.1007/s10044-014-0430-6
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang SP, 2015, AAAI CONF ARTIF INTE, P3165
   Zhang SL, 2015, IEEE T IMAGE PROCESS, V24, P5723, DOI 10.1109/TIP.2015.2484068
   Zhang SL, 2015, PATTERN RECOGN, V48, P2474, DOI 10.1016/j.patcog.2015.02.008
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W., 2012, P COMP VIS PATT REC, P1940
NR 57
TC 10
Z9 10
U1 0
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2018
VL 20
IS 11
BP 2949
EP 2963
DI 10.1109/TMM.2018.2844685
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GX5WL
UT WOS:000447824800007
DA 2024-07-18
ER

PT J
AU Jiao, YF
   Li, ZT
   Huang, SC
   Yang, XS
   Liu, B
   Zhang, TZ
AF Jiao, Yifan
   Li, Zhetao
   Huang, Shucheng
   Yang, Xiaoshan
   Liu, Bin
   Zhang, Tianzhu
TI Three-Dimensional Attention-Based Deep Ranking Model for Video Highlight
   Detection
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Video highlight detection; attention model; deep ranking
ID SCENE DETECTION; FRAMEWORK; SELECTION; SALIENCY; SYSTEM
AB The video highlight detection task is to localize key elements (moments of user's major or special interest) in a video. Most of existing highlight detection approaches extract features from the video segment as a whole without considering the difference of local features both temporally and spatially. Due to the complexity of video content, this kind of mixed features will impact the final highlight prediction. In temporal extent, not all frames are worth watching because some of them only contain the background of the environment without human or other moving objects. In spatial extent, it is similar that not all regions in each frame are highlights especially when there are lots of clutters in the background. To solve the above problem, we propose a novel three-dimensional (3-D) (spatial+temporal) attention model that can automatically localize the key elements in a video without any extra supervised annotations. Specifically, the proposed attention model produces attention weights of local regions along both the spatial and temporal dimensions of the video segment. The regions of key elements in the video will be strengthened with large weights. Thus, the more effective feature of the video segment is obtained to predict the highlight score. The proposed 3-D attention scheme can be easily integrated into a conventional end-to-end deep ranking model that aims to learn a deep neural network to compute the highlight score of each video segment. Extensive experimental results on the YouTube and SumMe datasets demonstrate that the proposed approach achieves significant improvement over state-of-the-art methods. With the proposed 3-D attention model, video highlights can he accurately retrieved in spatial and temporal dimensions without human supervision in several domains, such as gymnastics, parkour, skating, skiing, surfing, and dog activities, on the public datasets.
C1 [Jiao, Yifan; Huang, Shucheng] Jiangsu Univ Sci & Technol, Zhenjiang 212003, Peoples R China.
   [Li, Zhetao] Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Peoples R China.
   [Yang, Xiaoshan; Zhang, Tianzhu] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   [Yang, Xiaoshan; Zhang, Tianzhu] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
   [Liu, Bin] Moshanghua Tech Co Ltd, Beijing 100030, Peoples R China.
C3 Jiangsu University of Science & Technology; Xiangtan University; Chinese
   Academy of Sciences; Institute of Automation, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Li, ZT (corresponding author), Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Peoples R China.
EM 657068096@qq.com; liztchina@hotmail.com; schuang2015@gmail.com;
   xiaoshan.yang@nlpr.ia.ac.cn; liubin@dress-plus.com;
   tzzhang@nlpr.ia.ac.cn
RI Zhang, Tianzhu/AGY-9389-2022; Jiao, Yifan/ABH-6111-2020; xu,
   mingyu/KMX-9517-2024; Li, Zhetao/H-1293-2017
OI Zhang, Tianzhu/0000-0003-0764-6106; Jiao, Yifan/0000-0002-8923-6997;
   zhang, tian zhu/0000-0003-1856-9564
FU National Natural Science Foundation of China [61532009, 61772244,
   61572498]; Key Research Program of Frontier Sciences, CAS
   [QYZDJ-SSW-JSC039]; Postgraduate Research & Practice Innovation Program
   of Jiangsu Province [SJCX17_0599]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61532009, 61772244, and 61572498; and
   in part by the Key Research Program of Frontier Sciences, CAS, under
   Grant QYZDJ-SSW-JSC039, and Postgraduate Research & Practice Innovation
   Program of Jiangsu Province, Grant NO. SJCX17_0599. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Jian Zhang.
CR [Anonymous], 2008, INFORMATIKTAGE
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kavukcuoglu K.., 2015, P INT C LEARNING REP, P1, DOI [10.48550/arXiv.1412.7755, DOI 10.48550/ARXIV.1412.7755]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin YL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P443, DOI 10.1109/ICCVW.2015.65
   Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31
   Liu S, 2015, IEEE T MULTIMEDIA, V17, P1347, DOI 10.1109/TMM.2015.2443559
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Liu S, 2012, IEEE T MULTIMEDIA, V14, P361, DOI 10.1109/TMM.2011.2174780
   Luo CZ, 2018, IEEE T IMAGE PROCESS, V27, P637, DOI 10.1109/TIP.2017.2745109
   Medentzidou P, 2015, INT SYMP IMAGE SIG, P199, DOI 10.1109/ISPA.2015.7306058
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Nepal S., 2001, ACM Multimedia, P261
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Richang Hong, 2015, IEEE Transactions on Big Data, V1, P152, DOI 10.1109/TBDATA.2016.2515640
   Rocktaschel T., 2016, 4 INT C LEARN REPR I
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51
   Wang M, 2017, IEEE T KNOWL DATA EN, V29, P1101, DOI 10.1109/TKDE.2017.2654445
   Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Xiaofeng Tong, 2005, 13th Annual ACM International Conference on Multimedia, P519, DOI 10.1145/1101149.1101266
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu M., 2006, P ACM MULT 06 SAN BA, P921
   Xu M, 2014, MULTIMED TOOLS APPL, V70, P757, DOI 10.1007/s11042-012-1046-8
   Xu M, 2013, SIGNAL PROCESS, V93, P2140, DOI 10.1016/j.sigpro.2012.06.026
   Xu M, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352015
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang H, 2015, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2015.526
   Yang XS, 2016, IEEE T MULTIMEDIA, V18, P1832, DOI 10.1109/TMM.2016.2582379
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yao Ting, 2016, PROC CVPR IEEE, P982, DOI DOI 10.1109/CVPR.2016.112
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang B, 2006, LECT NOTES COMPUT SC, V3936, P472
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhang TZ, 2018, IEEE T IMAGE PROCESS, V27, P2676, DOI 10.1109/TIP.2017.2781304
   Zhang TZ, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2602633
   Zhang TZ, 2012, IEEE T MULTIMEDIA, V14, P1206, DOI 10.1109/TMM.2012.2191944
   Zhang TZ, 2011, IEEE T CIRC SYST VID, V21, P853, DOI 10.1109/TCSVT.2011.2133090
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zhong Qu, 2013, Journal of Software, V8, P1751, DOI 10.4304/jsw.8.7.1751-1758
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
   Zhu L., 2015, J MATER CHEM A, V3, P124
NR 58
TC 46
Z9 47
U1 1
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2018
VL 20
IS 10
SI SI
BP 2693
EP 2705
DI 10.1109/TMM.2018.2815998
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GT9YH
UT WOS:000444903000013
DA 2024-07-18
ER

PT J
AU Shi, LF
   Chen, BH
   Huang, SC
   Larin, AO
   Seredin, OS
   Kopylov, AV
   Kuo, SY
AF Shi, Ling-Feng
   Chen, Bo-Hao
   Huang, Shih-Chia
   Larin, Alexander Olegovich
   Seredin, Oleg Sergeevich
   Kopylov, Andrei Valerievich
   Kuo, Sy-Yen
TI Removing Haze Particles From Single Image via Exponential Inference With
   Support Vector Data Description
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Atmospheric lights; haze removal; underexposed effects
ID VISIBILITY ENHANCEMENT; ALGORITHM
AB Outdoor images captured during hazy conditions have degraded visibility. The lack of both a medium transmission and atmospheric lights in a single haze image cause an ill-posed problem in the atmospheric scattering model. This paper proposes a novel haze density estimation model with a universal atmospheric-light extractor for single-image dehazing. The proposed method employs exponential inference to construct an exponential inference model to more accurately estimate haze density compared with the state-of-the-art methods. The coefficients in the proposed haze density estimation model are learned using a turbulent particle swarm optimization technique to obtain the best approximation of medium transmission. Moreover, a novel universal atmospheric-light extractor based on support vector data description is utilized to resolve the problem caused by a lack of atmospheric light. The overall results obtained by conducting qualitative and quantitative evaluations demonstrated that the proposed method has substantially higher dehazing efficacy and produces fewer artifacts than the state-of-the-art haze removal methods.
C1 [Shi, Ling-Feng] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Fujian, Peoples R China.
   [Shi, Ling-Feng; Chen, Bo-Hao] Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan 320, Taiwan.
   [Chen, Bo-Hao] Yuan Ze Univ, Innovat Ctr Big Data & Digital Convergence, Taoyuan 320, Taiwan.
   [Huang, Shih-Chia; Kuo, Sy-Yen] Natl Taipei Univ Technol, Dept Elect Engn, Taipei 106, Taiwan.
   [Larin, Alexander Olegovich; Seredin, Oleg Sergeevich; Kopylov, Andrei Valerievich] Tula State Univ, Inst Appl Math & Comp Sci, Tula 300012, Russia.
C3 Fuzhou University; Yuan Ze University; Yuan Ze University; National
   Taipei University of Technology; Tula State University
RP Chen, BH (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan 320, Taiwan.
EM s1046076@mail.yzu.edu.tw; bhchen@saturn.yzu.edu.tw; schuang@ntut.edu.tw;
   ekzebox@gmail.com; oseredin@yandex.ru; And.Kopylov@gmail.com;
   sykuo@ntu.edu.tw
RI Seredin, Oleg S/L-6282-2017; Kopylov, Andrei V/L-5993-2017; Larin,
   Aleksandr/AAC-9881-2022
OI Seredin, Oleg S/0000-0003-0410-7705; Kopylov, Andrei
   V/0000-0003-3193-583X; Larin, Aleksandr/0000-0003-3126-225X; Huang,
   Shih-Chia/0000-0002-6896-3415; Kuo, Sy-Yen/0000-0002-3021-8321
FU Ministry of Science and Technology, Taiwan [MOST 106-2221-E-155-066,
   MOST 106-2218-E-155-007, MOST 105-2218-E-155-003, MOST
   105-2218-E-155-010, MOST 106-2221-E-027-126-MY2, MOST
   106-2221-E-027-017-MY3, MOST 105-2923-E-027-001-MY3, MOST
   103-2923-E-002-011-MY3, RFBR 16-57-52042, RFBR 16-07-01039]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, under Grants MOST 106-2221-E-155-066, MOST 106-2218-E-155-007,
   MOST 105-2218-E-155-003, MOST 105-2218-E-155-010, MOST
   106-2221-E-027-126-MY2, MOST 106-2221-E-027-017-MY3, MOST
   105-2923-E-027-001-MY3, MOST 103-2923-E-002-011-MY3, RFBR 16-57-52042,
   and RFBR 16-07-01039.
CR [Anonymous], 2003, IEEE WORKSHOP COLOR
   [Anonymous], IEEE T NEURAL NETW L
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Chen BH, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2726947
   Cheng YJ, 2013, IEEE SYS MAN CYBERN, P3627, DOI 10.1109/SMC.2013.618
   Chou HH, 2013, IEEE T CYBERNETICS, V43, P296, DOI 10.1109/TSMCB.2012.2205678
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Huang SC, 2014, IEEE T INTELL TRANSP, V15, P2321, DOI 10.1109/TITS.2014.2314696
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Larin A, 2014, LECT NOTES ARTIF INT, V8556, P300, DOI 10.1007/978-3-319-08979-9_23
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Saini M, 2012, IEEE T MULTIMEDIA, V14, P555, DOI 10.1109/TMM.2012.2186957
   Shin JH, 2011, IEEE T INF TECHNOL B, V15, P438, DOI 10.1109/TITB.2011.2113352
   Tahir MA, 2013, IEEE T MULTIMEDIA, V15, P1653, DOI 10.1109/TMM.2013.2264927
   Tan KK, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P788, DOI 10.1109/ICIP.2000.899827
   Tan R. T., 2008, P IEEE C COMP VIS PA, P1
   Tsai TH, 2012, IEEE T MULTIMEDIA, V14, P669, DOI 10.1109/TMM.2011.2180705
   Yu J, 2011, INT CONF ACOUST SPEE, P1245
   Yu J, 2014, INFORM SCIENCES, V281, P674, DOI 10.1016/j.ins.2014.01.025
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 29
TC 11
Z9 11
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2018
VL 20
IS 9
BP 2503
EP 2512
DI 10.1109/TMM.2018.2807593
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GR1ZX
UT WOS:000442358200021
DA 2024-07-18
ER

PT J
AU Liu, MY
   Liu, H
   Chen, C
AF Liu, Mengyuan
   Liu, Hong
   Chen, Chen
TI Robust 3D Action Recognition Through Sampling Local Appearances and
   Global Distributions
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Depth data; human-computer interaction (HCI); spatial-temporal interest
   point (STIP); 3-D action recognition
ID HAND GESTURE RECOGNITION; DEPTH; DESCRIPTOR; HISTOGRAM; ENSEMBLE
AB Three-dimensional (3-D) action recognition has broad applications in human-computer interaction and intelligent surveillance. However, recognizing similar actions remains challenging since previous literature fails to capture motion and shape cues effectively from noisy depth data. In this paper, we propose a novel two-layer Bag-of-Visual-Words (BoVW) model, which suppresses the noise disturbances and jointly encodes both motion and shape cues. First, background clutter is removed by a background modeling method that is designed for depth data. Then, motion and shape cues are jointly used to generate robust and distinctive spatial-temporal interest points (STIPs): motion-based STIPs and shape-based STIPs. In the first layer of our model, a multiscale 3-D local steering kernel descriptor is proposed to describe local appearances of cuboids around motion-based STIPs. In the second layer, a spatial-temporal vector descriptor is proposed to describe the spatial-temporal distributions of shape-based STIPs. Using the BoVW model, motion and shape cues are combined to form a fused action representation. Our model performs favorably compared with common STIP detection and description methods. Thorough experiments verify that our model is effective in distinguishing similar actions and robust to background clutter, partial occlusions and pepper noise.
C1 [Liu, Mengyuan; Liu, Hong] Peking Univ, Fac Key Lab Machine Percept, Shenzhen Grad Sch, Beijing 100871, Peoples R China.
   [Liu, Mengyuan] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Chen, Chen] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA.
C3 Peking University; Nanyang Technological University; State University
   System of Florida; University of Central Florida
RP Liu, H (corresponding author), Peking Univ, Fac Key Lab Machine Percept, Shenzhen Grad Sch, Beijing 100871, Peoples R China.
EM liumengyuan@ntu.edu.sg; hongliu@pku.edu.cn; chenchen870713@gmail.com
RI , Chen_Chen/A-8825-2015; Liu, Mengyuan/HZL-2276-2023
OI , Chen_Chen/0000-0003-3957-7061; Liu, Mengyuan/0000-0002-6332-8316
FU National Natural Science Foundation of China [61340046, 61673030,
   U1613209]; Natural Science Foundation of Guangdong Province
   [2015A030311034]; Scientific Research Project of Guangdong Province
   [2015B010919004]; Specialized Research Fund for Strategic and
   Prospective Industrial Development of Shenzhen City
   [ZLZBCXLJZI20160729020003]; Scientific Research Project of Shenzhen City
   [JCYJ20170306164738129]; Shenzhen Key Laboratory for Intelligent
   Multimedia and Virtual Reality [ZDSYS201703031405467]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61340046, Grant 61673030, Grant
   U1613209, in part by the Natural Science Foundation of Guangdong
   Province under Grant 2015A030311034, in part by the Scientific Research
   Project of Guangdong Province under Grant 2015B010919004, in part by the
   Specialized Research Fund for Strategic and Prospective Industrial
   Development of Shenzhen City under Grant ZLZBCXLJZI20160729020003, in
   part by the Scientific Research Project of Shenzhen City under Grant
   JCYJ20170306164738129, and in part by the Shenzhen Key Laboratory for
   Intelligent Multimedia and Virtual Reality under Grant
   ZDSYS201703031405467. The associate editor coordinating the review of
   this manuscript and approving it for publication was Dr. Martha Larson.
CR Anirudh R, 2017, IEEE T PATTERN ANAL, V39, P922, DOI 10.1109/TPAMI.2016.2564409
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], 2014, ASIAN C COMPUTER VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2014, ARXIV14077390
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-710
   [Anonymous], 2009, P BRIT MACH VIS C
   Azary S, 2013, IEEE COMPUT SOC CONF, P492, DOI 10.1109/CVPRW.2013.79
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Benezeth Y, 2008, INT C PATT RECOG, P237, DOI 10.1109/icpr.2008.4760998
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen HZ, 2016, PATTERN RECOGN, V55, P148, DOI 10.1016/j.patcog.2016.01.020
   Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6
   Cho SS, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.3.033102
   Cirujeda Pol, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P657, DOI 10.1109/3DV.2014.10
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Hu MC, 2015, IEEE T CYBERNETICS, V45, P742, DOI 10.1109/TCYB.2014.2335540
   Hussein, 2013, INT JOINT C ART INT
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu MY, 2016, NEUROCOMPUTING, V175, P747, DOI 10.1016/j.neucom.2015.11.005
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389
   Rahmani H, 2016, PATTERN RECOGN LETT, V72, P62, DOI 10.1016/j.patrec.2015.07.015
   Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Rui PL, 2014, INFORMATION TECHNOLOGY AND COMPUTER APPLICATION ENGINEERING, P1
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Serra J., 1983, IMAGE ANAL MATH MORP
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Shapiro L.G, 2001, COMPUTER VISION
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Slama R, 2014, INT C PATT RECOG, P3499, DOI 10.1109/ICPR.2014.602
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira A. W., P PROGR PATT REC IM, P252
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Weng CQ, 2015, IEEE T MULTIMEDIA, V17, P626, DOI 10.1109/TMM.2015.2414720
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2017, IEEE T PATTERN ANAL, V39, P1028, DOI 10.1109/TPAMI.2016.2565479
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yu Kong, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163084
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
   Zhang EH, 2016, NEUROCOMPUTING, V208, P281, DOI 10.1016/j.neucom.2015.12.122
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao YL, 2012, IFIP ADV INF COMM TE, V369, P1
   Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005
NR 71
TC 28
Z9 29
U1 0
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2018
VL 20
IS 8
BP 1932
EP 1947
DI 10.1109/TMM.2017.2786868
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GN8BR
UT WOS:000439378600002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huo, SW
   Zhou, Y
   Lei, JJ
   Ling, N
   Hou, CP
AF Huo, Shuwei
   Zhou, Yuan
   Lei, Jianjun
   Ling, Nam
   Hou, Chunping
TI Iterative Feedback Control-Based Salient Object Segmentation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Saliency detection; linear control system; boundary prior
ID REGION DETECTION
AB In this paper, we establish a mathematical model that relates the control states and the saliency values in salient object detection. We show that a linear feedback control system (LFCS) is amenable to saliency detection tasks owing to its functional properties. This inspired us to employ an LFCS to detect salient objects in static images. Based on the novel iteration method, the system gradually converges to an optimized stable state, which is associated with an accurate saliency map. In addition, to initialize the system, we propose a so-called boundary homogeneity based on a priori knowledge of the boundary in order to estimate the background likelihood and indirectly obtain a foreground (saliency) map. The experimental results indicate that such a feedback control model can offer significant improvement in salient object detection performance.
C1 [Huo, Shuwei; Zhou, Yuan; Lei, Jianjun; Hou, Chunping] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Ling, Nam] Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
C3 Tianjin University; Santa Clara University
RP Zhou, Y (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM huosw@tju.edu.cn; zhouyuan@tju.edu.cn; jjlei@tju.edu.cn; nling@scu.edu;
   hcp@tju.edu.cn
RI Huo, Shuwei/JAO-1073-2023; Lei, Jianjun/P-2539-2018
OI Huo, Shuwei/0000-0002-7290-7838
FU National Natural Science Foundation of China [61571326, 61471262,
   61520106002]; National Natural Science Foundation of Tianjin
   [16JC-QNJC00900]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61571326, 61471262, and 61520106002,
   and in part by the National Natural Science Foundation of Tianjin under
   Grant 16JC-QNJC00900.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], SLIC SUPERPIXELS ECO
   [Anonymous], 2008, Salient Region Detection and Segmentation
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang SY, 2016, IEEE T IMAGE PROCESS, V25, P5892, DOI 10.1109/TIP.2016.2613686
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Kong YQ, 2016, LECT NOTES COMPUT SC, V9910, P583, DOI 10.1007/978-3-319-46466-4_35
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lai BS, 2016, PROC CVPR IEEE, P3630, DOI 10.1109/CVPR.2016.395
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440755
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Trentelman H., 2002, CONTROL THEORY LINEA
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 55
TC 21
Z9 23
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2018
VL 20
IS 6
BP 1350
EP 1364
DI 10.1109/TMM.2017.2769801
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GG0WG
UT WOS:000432400400006
DA 2024-07-18
ER

PT J
AU Li, XC
   Larson, M
   Hanjalic, A
AF Li, Xinchao
   Larson, Martha
   Hanjalic, Alan
TI Geo-Distinctive Visual Element Matching for Location Estimation of
   Images
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Geo-location Estimation; information retrieval; large scale image
   retrieval
ID RECOMMENDATION; RECOGNITION; FEATURES; GPS
AB We propose an image representation and matching approach that substantially improves visual-based location estimation for images. The main novelty of the approach, called distinctive visual element matching (DVEM), is its use of representations that are specific to the query image whose location is being predicted. These representations are based on visual element clouds, which robustly capture the connection between the query and visual evidence from candidate locations. We then maximize the influence of visual elements that are geo-distinctive because they do not occur in images taken at many other locations. We carry out experiments and analysis for both geo-constrained and geo-unconstrained location estimation cases using two large-scale, publicly available datasets: the San Francisco Landmark dataset with 1.06 million street-view images and the MediaEval' 15 Placing Task dataset with 5.6 million geo-tagged images from Flickr. We present examples that illustrate the highly transparent mechanics of the approach, which are based on commonsense observations about the visual patterns in image collections. Our results show that the proposed method delivers a considerable performance improvement compared to the state-of-the-art.
C1 [Li, Xinchao; Larson, Martha; Hanjalic, Alan] Delft Univ Technol, Multimedia Comp Grp, NL-2628 CD Delft, Netherlands.
   [Larson, Martha] Radboud Univ Nijmegen, NL-6525 HP Nijmegen, Netherlands.
C3 Delft University of Technology; Radboud University Nijmegen
RP Li, XC (corresponding author), Delft Univ Technol, Multimedia Comp Grp, NL-2628 CD Delft, Netherlands.
EM x.li-3@tudelft.nl; m.a.larson@tudelft.nl; a.hanjalic@tudelft.nl
RI Larson, Martha/E-9983-2014
OI Hanjalic, Alan/0000-0002-5771-2549
FU SURF Cooperative
FX This work was carried out on the Dutch national e-infrastructure with
   the support of SURF Cooperative.
CR [Anonymous], P MEDIAEVAL
   [Anonymous], P MEDIAEVAL
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], 1999, MODERN INFORM RETRIE
   [Anonymous], 2013, P 3 ACM C INT C MULT
   [Anonymous], PROC 11 EUR CONF
   [Anonymous], P MEDIAEVAL
   [Anonymous], MEDIAEVAL WORKSH BAR
   [Anonymous], ARXIV150301817
   [Anonymous], 2013, PROC THE 21 ACM INT
   [Anonymous], MULTIMODAL LOCATION
   [Anonymous], P AS C COMP VIS
   [Anonymous], P ICMR
   [Anonymous], P MEDIAEVAL 2015 WOR
   [Anonymous], 2012, P 20 ACM INT C MULT
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Cao JW, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P119, DOI 10.1145/2733373.2806249
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Chen YY, 2013, IEEE T MULTIMEDIA, V15, P1283, DOI 10.1109/TMM.2013.2265077
   Choi J, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P193, DOI 10.1145/2733373.2809934
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Chum O, 2010, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2010.5539997
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Gopalan R, 2015, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2015.7298857
   Gronát P, 2013, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2013.122
   Guan T, 2013, IEEE T MULTIMEDIA, V15, P1688, DOI 10.1109/TMM.2013.2265674
   Hays J, 2008, PROC CVPR IEEE, P3436
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Kalantidis Y, 2011, MULTIMED TOOLS APPL, V51, P555, DOI 10.1007/s11042-010-0651-7
   Larson M., 2011, P 1 ACM INT C MULT R, P51
   Li J, 2013, IEEE T MULTIMEDIA, V15, P2058, DOI 10.1109/TMM.2013.2280127
   Li XC, 2015, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR.2015.7299151
   Li XC, 2015, IEEE T MULTIMEDIA, V17, P674, DOI 10.1109/TMM.2015.2413351
   Li YP, 2009, IEEE I CONF COMP VIS, P1957, DOI 10.1109/ICCV.2009.5459432
   Liu JJ, 2013, PROC INT CONF DATA, P505, DOI 10.1109/ICDE.2013.6544851
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Min WQ, 2014, IEEE T MULTIMEDIA, V16, P623, DOI 10.1109/TMM.2014.2302744
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   Rudinac S, 2013, IEEE T MULTIMEDIA, V15, P921, DOI 10.1109/TMM.2013.2237896
   Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175
   Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243
   Schindler G., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Schindler G., 2008, PROC 2008 IEEE C COM, P1
   Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4
   Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Wang XY, 2015, IEEE T MULTIMEDIA, V17, P409, DOI 10.1109/TMM.2014.2385473
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Yang JC, 2012, IEEE T MULTIMEDIA, V14, P1642, DOI 10.1109/TMM.2012.2198458
   Yuan JS, 2010, IEEE T MULTIMEDIA, V12, P705, DOI 10.1109/TMM.2010.2051868
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
NR 55
TC 11
Z9 11
U1 1
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2018
VL 20
IS 5
BP 1179
EP 1194
DI 10.1109/TMM.2017.2763323
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GD7YD
UT WOS:000430728400013
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Chen, FH
   Ji, RR
   Su, JS
   Cao, DL
   Gao, Y
AF Chen, Fuhai
   Ji, Rongrong
   Su, Jinsong
   Cao, Donglin
   Gao, Yue
TI Predicting Microblog Sentiments via Weakly Supervised Multimodal Deep
   Learning
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Sentiment prediction; weakly supervised learning; multi-modality; deep
   learning
AB Predicting sentiments of multimodal microblogs composed of text, image, and emoticon have attracted ever-increasing research focus recently. The key challenge lies in the difficulty of collecting a sufficient amount of training labels to train a discriminative model for multimodal prediction. One potential solution is to exploit the labels collected from social media users, which is, however, restricted by the negative effect of label noise. Besides, we have quantitatively found that sentiments in different modalities may be independent, which disables the usage of previous multimodal sentiment analysis schemes in our problem. In this paper, we introduce a weakly supervised multimodal deep learning (WS-MDL) scheme toward robust and scalable sentiment prediction. WS-MDL learns convolutional neural networks iteratively and selectively from "weak" emoticon labels, which are cheaply available and noise containing In particular, to filter out the label noise and to capture the modality dependency, a probabilistic graphical model is introduced to simultaneously learn discriminative multi modal descriptors and infer the confidence of label noise. Extensive evaluations are conducted in a million scale, real-world microblog sentiment dataset crawled from Sina Weibo. We have validated the merits of the proposed scheme by quantitatively showing its superior performance over several stateof-the-art and alternative approaches.
C1 [Chen, Fuhai; Ji, Rongrong; Cao, Donglin] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
   [Su, Jinsong] Xiamen Univ, Sch Software, Xiamen 361005, Peoples R China.
   [Gao, Yue] Tsinghua Univ, Sch Software, Key Lab Informat Syst Secur, Minist Educ KLISS, Beijing 100086, Peoples R China.
C3 Xiamen University; Xiamen University; Tsinghua University
RP Ji, RR (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
EM cfh@qq.com; jirongrong@gmail.com; jssu@xmu.edu.cn; another@xmu.edu.cn;
   gaoyue@tsinghua.edu.cn
RI Gao, Yue/B-3376-2012; Su, Jinsong/JXM-6940-2024
FU National Key R&D Program of China [2016YFB1001503, 2017YFC011300];
   Nature Science Foundation of China [61422210, 61373076, 61402388,
   61572410]
FX This work was supported in part by the National Key R&D Program of China
   (No. 2016YFB1001503, and No. 2017YFC011300), and in part by the Nature
   Science Foundation of China under Grants 61422210, 61373076, 61402388,
   and 61572410. The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Hatice Gunes.
CR [Anonymous], PERSPECTIVES MULTIMO
   [Anonymous], P ICML WORKSH CHALL
   [Anonymous], 2014, MM
   [Anonymous], 2013, P ACM INT WORKSHOP I
   [Anonymous], 2016, ARXIV161008815
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], 2015, P 1 INT WORKSH AFF S, DOI 10.1145/2813524.2813530
   [Anonymous], 2014, P INT C INT MULT COM
   [Anonymous], P CICLING
   [Anonymous], 2014, Comput. Sci.
   [Anonymous], ARXIV150805357
   [Anonymous], ARXIV151106838
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   [Anonymous], 2014, arXiv preprint arXiv:1406.2080 2
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Cambria E, 2016, KNOWL-BASED SYST, V108, P1, DOI 10.1016/j.knosys.2016.07.025
   Cambria E, 2016, IEEE COMPUT INTELL M, V11, P9, DOI 10.1109/MCI.2016.2572481
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Ceron A, 2015, SOC SCI COMPUT REV, V33, P3, DOI 10.1177/0894439314521983
   Chen F, 2015, 2015 IEEE 6TH INTERNATIONAL SYMPOSIUM ON MICROWAVE, ANTENNA, PROPAGATION, AND EMC TECHNOLOGIES (MAPE), P1, DOI 10.1109/MAPE.2015.7510253
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Dragut EC, 2015, IEEE T KNOWL DATA EN, V27, P838, DOI 10.1109/TKDE.2014.2339855
   Hu X., 2013, WSDM
   Jou B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P159, DOI 10.1145/2733373.2806246
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei XJ, 2016, IEEE T MULTIMEDIA, V18, P1910, DOI 10.1109/TMM.2016.2575738
   Liaw SY, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3853
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Mnih V., 2012, P 29 INT C MACH LEAR, P567
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Raykar VC, 2009, P 26 ANN INT C MACH, P889, DOI [10.1145/1553374.1553488, DOI 10.1145/1553374.1553488]
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Nguyen TH, 2015, EXPERT SYST APPL, V42, P9603, DOI 10.1016/j.eswa.2015.07.052
   Wang H., 2012, P ACL 2012 SYST DEM, P115, DOI DOI 10.1145/1935826.1935854
   Wang Jingwen., 2016, IJCAI, P3484
   Wang YL, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2378
   Xu C., 2014, Visual sentiment prediction with deep convolutional neural networks
   You QZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1071, DOI 10.1145/2733373.2806284
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1008, DOI 10.1145/2964284.2964288
   You QZ, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P13, DOI 10.1145/2835776.2835779
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H.-P., 2003, Proc. of the second SIGHAN workshop on Chinese language process, P184, DOI [10.3115/1119250.1119280, DOI 10.3115/1119250.1119280]
NR 48
TC 55
Z9 63
U1 3
U2 51
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2018
VL 20
IS 4
BP 997
EP 1007
DI 10.1109/TMM.2017.2757769
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FZ5HM
UT WOS:000427623000018
DA 2024-07-18
ER

PT J
AU Li, LD
   Zhou, Y
   Gu, K
   Lin, WS
   Wang, SQ
AF Li, Leida
   Zhou, Yu
   Gu, Ke
   Lin, Weisi
   Wang, Shiqi
TI Quality Assessment of DIBR-Synthesized Images by Measuring Local
   Geometric Distortions and Global Sharpness
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE DIBR; disoccluded region; quality evaluation; ranking-based weighting;
   sharpness; view synthesis
ID BLUR; COMPRESSION; PREDICTION; VIEWS
AB Depth-image-based rendering (DIBR) is a fundamental technique in free viewpoint video, which is widely adopted to synthesize virtual viewpoints. The warping and rendering operations in DIBR generally introduce geometric distortions and sharpness change. The state-of-the-art quality indices are limited in dealing with such images since they are sensitive to geometric changes. In this paper, a new quality model for DIBR-synthesized view images is presented by measuring LOcal Geometric distortions in disoccluded regions and global Sharpness (LOGS). A disoccluded region detection method is first proposed using SIFT-flow-based warping. Then, the sizes and distortion strength of local disoccluded regions are combined to generate a score. Furthermore, a reblurring-based strategy is proposed to quantify the global sharpness. Finally, the overall quality score is calculated by pooling the scores of local disoccluded regions and global sharpness. Experiments on four public DIBR-synthesized image/video databases show the superiority of the proposed metric over the state-of-the-art quality models. The proposed method is further adopted for boosting the performances of existing quality metrics and benchmarking DIBR algorithms, both achieving very promising results.
C1 [Li, Leida; Zhou, Yu] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
   [Gu, Ke] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing, Peoples R China.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Wang, Shiqi] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 China University of Mining & Technology; Beijing University of
   Technology; Nanyang Technological University; City University of Hong
   Kong
RP Zhou, Y (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
EM lileida@cumt.edu.cn; zhouy7476@cumt.edu.cn; guke.doctor@gmail.com;
   wslin@ntu.edu.sg; shiqwang@cityu.edu.hk
RI li, li/HII-4157-2022; Lin, Weisi/A-3696-2011; Lin, Weisi/A-8011-2012;
   Gu, Ke/AAJ-9684-2021; Li, Li/AEM-3636-2022
OI Lin, Weisi/0000-0001-9866-1947; 
FU National Natural Science Foundation of China [61771473, 61379143];
   Fundamental Research Funds for the Central Universities [2017XKQY084];
   Qing Lan Project
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61771473 and 61379143, in part by the
   Fundamental Research Funds for the Central Universities under Grant
   2017XKQY084, and in part by the Qing Lan Project. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Abdulmotaleb El Saddik.
CR [Anonymous], P SPIE INT SOC OPT E
   [Anonymous], 2009, TEST PLAN EVALUATION
   [Anonymous], 2015, P IEEE TRUE VIS CAPT
   [Anonymous], IEEE T MULTIMEDIA
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Fan YC, 2013, IEEE IMTC P, P835
   Fang RG, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P653
   Farid MS, 2017, IEEE INT CON MULTI, P505, DOI 10.1109/ICME.2017.8019307
   Farid MS, 2015, IEEE IMAGE PROC, P3720, DOI 10.1109/ICIP.2015.7351499
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gu K., 2017, IEEE T IMAGE PROCESS, DOI [10.1109/T1P,2017,2733164, DOI 10.1109/T1P.2017.2733164]
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Gu K, 2014, IEEE IMAGE PROC, P506, DOI 10.1109/ICIP.2014.7025101
   Gu K, 2015, IEEE T BROADCAST, V61, P520, DOI 10.1109/TBC.2015.2459851
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2013, IEEE INT CON MULTI
   Gu K, 2013, IEEE INT SYMP CIRC S, P2365, DOI 10.1109/ISCAS.2013.6572353
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Jung YJ, 2016, IEEE T CIRC SYST VID, V26, P1201, DOI 10.1109/TCSVT.2015.2430632
   Kim H, 2017, IEEE T CIRC SYST VID, V27, P951, DOI 10.1109/TCSVT.2016.2515303
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Liu XK, 2015, IEEE T IMAGE PROCESS, V24, P4847, DOI 10.1109/TIP.2015.2469140
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ndjiki-Nya P, 2010, IEEE INT CON MULTI, P424, DOI 10.1109/ICME.2010.5583559
   Ryu S, 2014, IEEE IMAGE PROC, P585, DOI 10.1109/ICIP.2014.7025117
   Sandic-Stankovic D., 2015, P IEEE 7 INT WORKSH, P1
   Sandic-Stankovic D, 2016, J ELECTR ENG-SLOVAK, V67, P3, DOI 10.1515/jee-2016-0001
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Shao H., P IEEE TRUE VIS CAPT, P1
   Solh M., 2011, Multimedia and Expo (ICME), 2011 IEEE International Conference on, P1
   Song R, 2015, J INF SCI ENG, V31, P1593
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Le TH, 2016, ETRI J, V38, P1114, DOI 10.4218/etrij.16.2716.0041
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang SQ, 2016, IEEE T MULTIMEDIA, V18, P219, DOI 10.1109/TMM.2015.2510326
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 52
TC 82
Z9 84
U1 0
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2018
VL 20
IS 4
BP 914
EP 926
DI 10.1109/TMM.2017.2760062
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FZ5HM
UT WOS:000427623000012
DA 2024-07-18
ER

PT J
AU Calagari, K
   Elgharib, M
   Didyk, P
   Kaspar, A
   Matusik, W
   Hefeeda, M
AF Calagari, Kiana
   Elgharib, Mohamed
   Didyk, Piotr
   Kaspar, Alexandre
   Matusik, Wojciech
   Hefeeda, Mohamed
TI Data Driven 2-D-to-3-D Video Conversion for Soccer
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE 2-D-to-3-D conversion; depth estimation; three-dimensional (3-D) video
ID IMAGE; 2D; SEGMENTATION
AB A wide adoption of 3-D videos is hindered by the lack of high-quality 3-D content. One promising solution to this problem is through data-driven 2-D-to-3-D video conversion. Such approaches are based on learning depth maps from a large dataset of 2-D+Depth images. However, current conversion methods, while general, produce low-quality results with artifacts that are not acceptable to many viewers. We propose a novel, data-driven method for 2-D-to-3-D video conversion. Our method transfers the depth gradients from a large database of 2-D+Depth images. Capturing 2-D+Depth databases, however, are complex and costly, especially for outdoor sports games. We address this problem by creating a synthetic database from computer games and showing that this synthetic database can effectively he used to convert real videos. We propose a spatio-temporal method to ensure the smoothness of the generated depth within individual frames and across successive frames. In addition, we present an object boundary detection method customized for 2-D-to-3-D conversion systems, which produces clear depth boundaries for players. We implement our method and validate it by conducting user studies that evaluate depth perception and visual comfort of the converted 3-D videos. We show that our method produces high-quality 3-D videos that are almost indistinguishable from videos shot by stereo cameras. In addition, our method significantly outperforms the current state-of-the-art methods. For example, up to 20% improvement in the perceived depth is achieved by our method, which translates to improving the mean opinion score from good to excellent.
C1 [Calagari, Kiana; Hefeeda, Mohamed] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   [Elgharib, Mohamed] HBKU, Qatar Comp Res Inst, Doha, Qatar.
   [Didyk, Piotr] Saarland Univ, Excellence Cluster Multimodal Comp & Interact, D-66123 Saarbrucken, Germany.
   [Kaspar, Alexandre; Matusik, Wojciech] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
C3 Simon Fraser University; Qatar Foundation (QF); Hamad Bin Khalifa
   University-Qatar; Qatar Computing Research Institute; Saarland
   University; Massachusetts Institute of Technology (MIT)
RP Calagari, K (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
EM kcalagar@sfu.ca; melgharib@qf.org.qa; piotrdidyk@gmail.com;
   akaspar@mit.edu; wojciech@csail.mit.edu; mhefeeda@sfu.ca
OI Didyk, Piotr/0000-0003-0768-8939
FU NSERC (Natural Sciences and Engineering Research Council of Canada);
   QCRI-CSAIL partnership; National Science Foundation [IIS-1111415]
FX This work was supported in part by NSERC (Natural Sciences and
   Engineering Research Council of Canada), in part by the QCRI-CSAIL
   partnership, in part by the National Science Foundation under Grant
   IIS-1111415.
CR Angot L. J., 2010, P SOC PHOTO-OPT INS, V7526
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, CORR
   [Anonymous], 2017, BERKELEY 3 D OBJECT
   [Anonymous], SUBJ METH ASS STER 3
   Bhat P, 2008, LECT NOTES COMPUT SC, V5303, P114, DOI 10.1007/978-3-540-88688-4_9
   Bouman CA., 1998, CLUSTER UNSUPERVISED
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Calagari K, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P331, DOI 10.1145/2733373.2806262
   Calagari K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P337, DOI 10.1145/2647868.2654899
   Corrigan D., 2008, EURASIP J ADV SIG PR, V2008, P153
   Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158
   Hefeeda M, 2015, IEEE T MULTIMEDIA, V17, P420, DOI 10.1109/TMM.2015.2389628
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Jiang HQ, 2015, IEEE T MULTIMEDIA, V17, P3, DOI 10.1109/TMM.2014.2368273
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Ko Jee Yeoun, 2008, THESIS
   Konrad J., 2012, P SOC PHOTO-OPT INS, V8288
   Konrad J, 2013, IEEE T IMAGE PROCESS, V22, P3485, DOI 10.1109/TIP.2013.2270375
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Liao M, 2012, IEEE T VIS COMPUT GR, V18, P1079, DOI 10.1109/TVCG.2011.114
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu Ce, 2009, THESIS
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Park M, 2013, IEEE T MULTIMEDIA, V15, P1569, DOI 10.1109/TMM.2013.2264926
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Phan R, 2014, IEEE T MULTIMEDIA, V16, P122, DOI 10.1109/TMM.2013.2283451
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Schnyder L., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1961, DOI 10.1109/ICIP.2011.6115857
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang Z., 2007, Proceedings of the 15th international conference on Multimedia, P882
   Zhang L, 2011, IEEE T BROADCAST, V57, P372, DOI 10.1109/TBC.2011.2122930
   Zhang ZB, 2013, IEEE T CIRC SYST VID, V23, P1795, DOI 10.1109/TCSVT.2013.2269023
   Zhang ZB, 2011, IEEE IMAGE PROC, P909, DOI 10.1109/ICIP.2011.6116707
NR 37
TC 6
Z9 8
U1 1
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2018
VL 20
IS 3
BP 605
EP 619
DI 10.1109/TMM.2017.2748458
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FW5ZH
UT WOS:000425397500008
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Xu, YL
   Liu, F
AF Xu, Yanli
   Liu, Feng
TI QoS Provisionings for Device-to-Device Content Delivery in Cellular
   Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Caching management; content delivery; device-to-device (D2D)
   communication; energy efficiency; resource allocation
ID QUALITY; DELAY; PLACEMENT; SERVICE; SUPPORT
AB Device-to-device (D2D) technique provides a feasible way for content delivery among proximal users without deploying additional infrastructures. For the realization of D2D content delivery, it is important to guarantee quality-of-service (QoS) for supporting real-time content transmissions. In this paper, we formulate the content delivery problem based on a flow model and investigate mechanisms providing delay QoS guarantee. The delay performance is analyzed for the content dissemination with the aid of D2D communication. Based on the analyses of parameters affecting the performance of content delivery, an optimal resource allocation scheme is proposed to achieve the best energy efficiency of content delivery in cellular networks with guaranteed delay constraints for hybrid content requests. Then effects of content caching on D2D content delivery is studied and a caching management scheme is proposed to avoid cache overflow of users with a certain probability and satisfy QoS requirements of content delivery. Simulation results are presented that verify the analyzed influencing factors on D2D content delivery and the proposed QoS-provisioning schemes.
C1 [Xu, Yanli; Liu, Feng] Shanghai Maritime Univ, Dept Informat Engn, Shanghai 201306, Peoples R China.
C3 Shanghai Maritime University
RP Xu, YL (corresponding author), Shanghai Maritime Univ, Dept Informat Engn, Shanghai 201306, Peoples R China.
EM ylxu@shmtu.edu.cn; liufeng@shmtu.edu.cn
RI xu, yanli/AAA-1590-2020
FU National Natural Science Foundation of China [61601283, 61271283]
FX This work was supported in part by the Project of National Natural
   Science Foundation of China under Grant 61601283 and Grant 61271283. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Xiaoqing Zhu. (Corresponding
   author: Yanli Xu.)
CR Abdrabou A, 2011, IEEE J SEL AREA COMM, V29, P129, DOI 10.1109/JSAC.2011.110113
   Al-Hourani A, 2016, IEEE T VEH TECHNOL, V65, P3005, DOI 10.1109/TVT.2015.2450223
   Altieri A, 2015, IEEE T WIREL COMMUN, V14, P4958, DOI 10.1109/TWC.2015.2430341
   Altieri A, 2014, 2014 11TH INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATIONS SYSTEMS (ISWCS), P863, DOI 10.1109/ISWCS.2014.6933474
   Andrews JG, 2011, IEEE T COMMUN, V59, P3122, DOI 10.1109/TCOMM.2011.100411.100541
   [Anonymous], 2014, Probability: An Introduction
   [Anonymous], 2014, 36843 3GPP WG RAN1
   Asadi A, 2014, IEEE COMMUN SURV TUT, V16, P1801, DOI 10.1109/COMST.2014.2319555
   Barbera MV, 2014, AD HOC NETW, V19, P92, DOI 10.1016/j.adhoc.2014.01.012
   Chan KHK, 2010, IEEE T MULTIMEDIA, V12, P743, DOI 10.1109/TMM.2010.2053524
   Chhajed D, 2008, INT SER OPER RES MAN, V115, P1, DOI 10.1007/978-0-387-73699-0
   Choi KW, 2015, IEEE J SEL AREA COMM, V33, P55, DOI 10.1109/JSAC.2014.2369591
   Chuang YJ, 2012, IEEE WCNC, P3188, DOI 10.1109/WCNC.2012.6214356
   Du QH, 2010, IEEE J SEL AREA COMM, V28, P420, DOI 10.1109/JSAC.2010.100413
   Fodor G, 2012, IEEE COMMUN MAG, V50, P170, DOI 10.1109/MCOM.2012.6163598
   Ghorbani S., 2015, P 14 ACM WORKSH HOT, P1
   Golrezaei N, 2014, IEEE T WIREL COMMUN, V13, P3665, DOI 10.1109/TWC.2014.2316817
   Han B, 2012, IEEE T MOBILE COMPUT, V11, P821, DOI 10.1109/TMC.2011.101
   Huang SL, 2016, IEEE T MULTIMEDIA, V18, P752, DOI 10.1109/TMM.2016.2530411
   Jindal N, 2008, IEEE T WIREL COMMUN, V7, P5482, DOI 10.1109/T-WC.2008.071439
   Kang HJ, 2014, IEEE CONF COMPUT, P299, DOI 10.1109/INFCOMW.2014.6849248
   Lei L, 2012, IEEE WIREL COMMUN, V19, P96, DOI 10.1109/MWC.2012.6231164
   Li Y, 2011, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON CHALLENGED NETWORKS (CHANTS '11), P43
   Li Y, 2016, CHINA COMMUN, V13, P30, DOI 10.1109/CC.2016.7464120
   Luo HY, 2010, IEEE COMMUN MAG, V48, P102, DOI 10.1109/MCOM.2010.5402671
   Malak D, 2014, IEEE GLOBE WORK, P863, DOI 10.1109/GLOCOMW.2014.7063541
   Pääkkönen J, 2013, IEEE GLOBE WORK, P671, DOI 10.1109/GLOCOMW.2013.6825065
   Seppälä J, 2011, 2011 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P986, DOI 10.1109/WCNC.2011.5779270
   Shah GA, 2012, IEEE T MULTIMEDIA, V14, P1442, DOI 10.1109/TMM.2012.2196510
   Sheikh AM, 2014, IEEE T MULTIMEDIA, V16, P2294, DOI 10.1109/TMM.2014.2357716
   Sung J, 2016, IEEE T MULTIMEDIA, V18, P1163, DOI 10.1109/TMM.2016.2543658
   Trestian I, 2012, IEEE ACM T NETWORK, V20, P1010, DOI 10.1109/TNET.2011.2172952
   Wang XF, 2013, IEEE T MULTIMEDIA, V15, P811, DOI 10.1109/TMM.2013.2239630
   Weber S, 2007, IEEE T INFORM THEORY, V53, P4127, DOI 10.1109/TIT.2007.907482
   Wu DP, 2003, IEEE T WIREL COMMUN, V2, P630, DOI 10.1109/TWC.2003.814353
   Xu YL, 2016, IEEE T VEH TECHNOL, V65, P9330, DOI 10.1109/TVT.2016.2519456
   Xu YL, 2016, IEEE COMMUN LETT, V20, P728, DOI 10.1109/LCOMM.2016.2524401
   Zhang X, 2006, IEEE COMMUN MAG, V44, P100, DOI 10.1109/MCOM.2006.1580939
   Zheng ZJ, 2014, IEEE CONF COMPUT, P219, DOI 10.1109/INFCOMW.2014.6849234
NR 39
TC 15
Z9 15
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2017
VL 19
IS 11
BP 2597
EP 2608
DI 10.1109/TMM.2017.2700208
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FJ9CT
UT WOS:000413068200019
DA 2024-07-18
ER

PT J
AU Puthenputhussery, A
   Liu, QF
   Liu, CJ
AF Puthenputhussery, Ajit
   Liu, Qingfeng
   Liu, Chengjun
TI A Sparse Representation Model Using the Complete Marginal Fisher
   Analysis Framework and Its Applications to Visual Recognition
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Discriminative sparse representation; complete marginal Fisher analysis
   (CMFA); dictionary screening rule; discriminatory features; column
   space; null space; scatter matrix; visual recognition
ID SHRINKAGE-THRESHOLDING ALGORITHM; FACE RECOGNITION;
   DISCRIMINANT-ANALYSIS; IMAGE CLASSIFICATION; DICTIONARY; SCALE
AB This paper presents an innovative sparse representation model using the complete marginal Fisher analysis (CMFA) framework for different challenging visual recognition tasks. First, a complete marginal Fisher analysis method is presented by extracting the discriminatory features in both the column space of the local samples based within the class scatter matrix and the null space of its transformed matrix. The rationale of extracting features in both spaces is to enhance the discriminatory power by further utilizing the null space, which is not accounted for in the marginal Fisher analysis method. Second, a discriminative sparse representation model is proposed by integrating a representation criterion such as the sparse representation and a discriminative criterion for improving the classification capability. In this model, the largest step size for learning the sparse representation is derived to address the convergence issues in optimization, and a dictionary screening rule is presented to purge the dictionary items with null coefficients for improving the computational efficiency. Experiments on some challenging visual recognition tasks using representative datasets, such as the Painting-91 dataset, the 15 scene categories dataset, the MIT-67 indoor scenes dataset, the Caltech 101 dataset, the Caltech 256 object categories dataset, the AR face dataset, and the extended Yale B dataset, show the feasibility of the proposed method.
C1 [Puthenputhussery, Ajit; Liu, Qingfeng; Liu, Chengjun] New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
C3 New Jersey Institute of Technology
RP Puthenputhussery, A (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
EM avp38@njit.edu; ql69@njit.edu; cliu@njit.edu
CR Altintakan UL, 2015, IEEE T MULTIMEDIA, V17, P323, DOI 10.1109/TMM.2014.2388312
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2016, Adaptive deep pyramid matching for remote sensing scene classification
   [Anonymous], 2015, 2015 IEEE INT C MULT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2010, P NIPS
   [Anonymous], 2004, Workshop on Generative Model Based Vision
   [Anonymous], 2011, P CVPR 2011 COL SPRI
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587652
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2011, Advances in Neural Information Processing Systems
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE T NEUR IN PRESS
   [Anonymous], 2007, IJCAI
   Beck A, 2009, INT CONF ACOUST SPEE, P693, DOI 10.1109/ICASSP.2009.4959678
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chen S, 2014, IEEE T IMAGE PROCESS, V23, P1629, DOI 10.1109/TIP.2013.2294548
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Feng QX, 2016, IEEE T MULTIMEDIA, V18, P1956, DOI 10.1109/TMM.2016.2602062
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Goh H, 2014, IEEE T NEUR NET LEAR, V25, P2212, DOI 10.1109/TNNLS.2014.2307532
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jian M, 2016, IEEE T MULTIMEDIA, V18, P458, DOI 10.1109/TMM.2016.2515367
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jin LL, 2007, PR IEEE COMP DESIGN, P114
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115
   Liu CJ, 2014, PATTERN RECOGN, V47, P359, DOI 10.1016/j.patcog.2013.06.023
   Liu QF, 2015, PROC CVPR IEEE, P1329, DOI 10.1109/CVPR.2015.7298738
   Liu Quanru, 2014, ScientificWorldJournal, V2014, P180219, DOI 10.1155/2014/180219
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo CZ, 2016, IEEE T MULTIMEDIA, V18, P40, DOI 10.1109/TMM.2015.2495248
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Peng KC, 2015, IEEE IMAGE PROC, P3057, DOI 10.1109/ICIP.2015.7351365
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Puthenputhussery A, 2016, LECT NOTES COMPUT SC, V9912, P612, DOI 10.1007/978-3-319-46484-8_37
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Shechtman E., 2007, PROC IEEE C COMPUT V, P1
   Simonyan K., 2014, CORR
   Sivalingam R, 2011, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2011.6126346
   Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
NR 76
TC 12
Z9 16
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2017
VL 19
IS 8
BP 1757
EP 1770
DI 10.1109/TMM.2017.2685179
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FH5VV
UT WOS:000411240400006
DA 2024-07-18
ER

PT J
AU Han, XT
   Singh, B
   Morariu, VI
   Davis, LS
AF Han, Xintong
   Singh, Bharat
   Morariu, Vlad I.
   Davis, Larry S.
TI VRFP: On-the-Fly Video Retrieval Using Web Images and Fast Fisher Vector
   Products
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Fast inner products; Fisher Vectors; video retrieval; web-based
   retrieval
ID EVENT RECOGNITION; VISUAL KNOWLEDGE; OBJECT RETRIEVAL; QUANTIZATION
AB On-the-fly video retrieval using web images and fast Fisher Vector products (VRFP) is a real-time video retrieval framework based on short text input queries, which obtains weakly labeled training images from the web after the query is known. The retrieved web images representing the query and each database video are treated as unordered collections of images, and each collection is represented using a single Fisher Vector built on CNN features. Our experiments show that a Fisher Vector is robust to noise present in web images and compares favorably in terms of accuracy to other standard representations. While a Fisher Vector can be constructed efficiently for a new query, matching against the test set is slow due to its high dimensionality. To perform matching in real time, we present a lossless algorithm that accelerates the inner product computation between high-dimensional Fisher Vectors. We prove that the expected number of multiplications required decreases quadratically with the sparsity of Fisher Vectors. We are not only able to construct and apply query models in real time, but with the help of a simple reranking scheme, we also outperform state-of-the-art automatic retrieval methods by a significant margin on TRECVID MED13 (3.5%), MED14 (1.3%), and CCV datasets (5.2%). We also provide a direct comparison on standard datasets between two different paradigms for automatic video retrieval: zero-shot learning and on-the-fly retrieval.
C1 [Han, Xintong; Singh, Bharat; Morariu, Vlad I.; Davis, Larry S.] Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Han, XT (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.
EM xintong@umiacs.umd.edu; bharat@umiacs.umd.edu; morariu@umiacs.umd.edu;
   lsd@umiacs.umd.edu
FU Intelligence Advanced Research Projects Activity (IARPA) via the
   Department of Interior National Business Center [D11PC20071]
FX This work was supported by the Intelligence Advanced Research Projects
   Activity (IARPA) via the Department of Interior National Business Center
   under Contract D11PC20071. The associate editor coordinating the review
   of this manuscript and approving it for publication was Dr. Jingdong
   Wang. (Xintong Han and Bharat Singh contributed equally to this work.)
CR [Anonymous], 2013, NIST TRECVID MULTIME
   Arandjelovic R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.92
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Chatfield K., 2014, Asian Conf. on Comput. Vision, P129
   Chatfield K., 2012, LECT NOTES COMPUT SC
   Chatfield K, 2015, INT J MULTIMED INF R, V4, P75, DOI 10.1007/s13735-015-0077-0
   Chen Jiawei., 2014, Proceedings of International Conference on Multimedia Retrieval, P1
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cui Yin., 2014, CoRR
   Dalton J, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1857, DOI 10.1145/2505515.2507880
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Habibian A, 2014, ICMR
   Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913
   Jain M, 2015, IEEE I CONF COMP VIS, P4588, DOI 10.1109/ICCV.2015.521
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918
   Jiang L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P49, DOI 10.1145/2733373.2806237
   Jiang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P27, DOI 10.1145/2671188.2749399
   Jiang Y. -G., 2011, P 1 ACM INT C MULT R, P29
   Jiang YG, 2015, IEEE T MULTIMEDIA, V17, P1174, DOI 10.1109/TMM.2015.2436813
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu J, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P297, DOI 10.1109/ROBIO.2014.7090346
   Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928
   Mazloom M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P123, DOI 10.1145/2671188.2749402
   Mazloom M, 2016, IEEE T MULTIMEDIA, V18, P1378, DOI 10.1109/TMM.2016.2559947
   Mazloom M, 2014, IEEE T MULTIMEDIA, V16, P2214, DOI 10.1109/TMM.2014.2359771
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Singh B, 2015, IEEE I CONF COMP VIS, P4561, DOI 10.1109/ICCV.2015.518
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P371, DOI 10.1145/2733373.2806226
   Tang Kevin, 2012, P INT C NEUR INF PRO, P647
   Vedaldi A., 2010, Proceedings of the international conference on Multimedia - MM'10, P1469
   Wu S, 2014, PROC CVPR IEEE, P2665, DOI 10.1109/CVPR.2014.341
   Wu ZX, 2016, PROC CVPR IEEE, P3112, DOI 10.1109/CVPR.2016.339
   Xia Y, 2015, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2015.177
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   Yu Q., 2012, P 20 ACM INT C MULT, P1073
   Yu SI, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P419, DOI 10.1145/2671188.2749398
   Yuster R, 2005, ACM T ALGORITHMS, V1, P2, DOI 10.1145/1077464.1077465
   Zhang XS, 2015, IEEE T MULTIMEDIA, V17, P1562, DOI 10.1109/TMM.2015.2449660
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng Liang, 2016, ARXIV
NR 60
TC 10
Z9 13
U1 0
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2017
VL 19
IS 7
BP 1583
EP 1595
DI 10.1109/TMM.2017.2671414
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5ZN
UT WOS:000404061800015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, BY
   Jia, J
   Yang, Y
   Zhao, PJ
   Tang, J
   Tian, Q
AF Wu, Boya
   Jia, Jia
   Yang, Yang
   Zhao, Peijun
   Tang, Jie
   Tian, Qi
TI Inferring Emotional Tags From Social Images With User Demographics
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Emotion; image; user demographics
ID GENDER-DIFFERENCES; RECOGNITION; FEATURES; STATES
AB Social images, which are images uploaded and shared on social networks, are used to express users' emotions. Inferring emotional tags from social images is of great importance; it can benefit many applications, such as image retrieval and recommendation. Whereas previous related research has primarily focused on exploring image visual features, we aim to address this problem by studying whether user demographics make a difference regarding users' emotional tags of social images. We first consider how to model the emotions of social images. Then, we investigate how user demographics, such as gender, marital status, and occupation, are related to the emotional tags of social images. A partially labeled factor graph model named the demographics factor graph model (D-FGM) is proposed to leverage the uncovered patterns. Experiments on a data set collected from the world's largest image sharing website Flickr(1) confirm the accuracy of the proposed model. We also find some interesting phenomena. For example, men and women have different patterns to tag "anger" for social images.
C1 [Wu, Boya; Jia, Jia; Zhao, Peijun; Tang, Jie] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Wu, Boya; Jia, Jia; Zhao, Peijun] Minist Educ, Key Lab Pervas Comp, Beijing 100084, Peoples R China.
   [Wu, Boya; Jia, Jia; Zhao, Peijun] TNList, Beijing 100084, Peoples R China.
   [Yang, Yang] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Tsinghua University; Zhejiang University; University of Texas System;
   University of Texas at San Antonio (UTSA)
RP Jia, J (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.; Jia, J (corresponding author), Minist Educ, Key Lab Pervas Comp, Beijing 100084, Peoples R China.; Jia, J (corresponding author), TNList, Beijing 100084, Peoples R China.
EM wuboya10@gmail.com; jjia@tsinghua.edu.cn; yangya@zju.edu.cn;
   421769833@qq.com; jietang@tsinghua.edu.cn; qi.tian@utsa.edu
RI jia, jia/JKJ-5720-2023; tang, jie/KIE-8633-2024; Yang, Yang/A-6288-2017
FU National Key Research and Development Plan [2016YFB1001200]; Innovation
   Method Fund of China [2016IM010200]; National Natural Science Foundation
   of China [61370023, 61521002, 61561130160, 61602033]; Major Project of
   the National Social Science Foundation of China [13ZD189]; National
   Science Foundation of China [61429201]; ARO [W911NF-15-1-0290]; Faculty
   Research Gift Awards by NEC Laboratories of America and Blippar
FX This work was supported in part by the National Key Research and
   Development Plan under Grant 2016YFB1001200, in part by the Innovation
   Method Fund of China under Grant 2016IM010200, in part by the National
   Natural Science Foundation of China under Grant 61370023, Grant
   61521002, Grant 61561130160, and Grant 61602033, in part by the Major
   Project of the National Social Science Foundation of China (13&ZD189),
   and in part by the National Science Foundation of China under Grant
   61429201. The work of Q. Tian was supported by the ARO under Grant
   W911NF-15-1-0290, and by the Faculty Research Gift Awards by NEC
   Laboratories of America and Blippar. The associate editor coordinating
   the review of this manuscript and approving it for publication was Dr.
   Hatice Gunes. (Corresponding author: Jia Jia.)
CR [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], THESIS
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 2013, P 21 ACM INT C MULTI
   Bakhshi S, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P443, DOI 10.1145/2566486.2568021
   Bi B., 2013, P 22 INT C WORLD WID, P131, DOI DOI 10.1145/2488388.2488401
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Brea Jorge., 2014, Proceedings of the 8th Workshop on Social Network Mining and Analysis, P1
   Calix RA, 2010, IEEE T MULTIMEDIA, V12, P544, DOI 10.1109/TMM.2010.2052026
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen M, 2015, IEEE IMAGE PROC, P4491, DOI 10.1109/ICIP.2015.7351656
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Crawford J., 1992, EMOTION GENDER CONST
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Della Rocca M, 2011, BRILL S IN, V196, P17
   Dong YX, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P15, DOI 10.1145/2623330.2623703
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fischer AH, 2004, EMOTION, V4, P87, DOI 10.1037/1528-3542.4.1.87
   Fivush R, 2000, SEX ROLES, V42, P233, DOI 10.1023/A:1007091207068
   Hu SM, 2013, VISUAL COMPUT, V29, P393, DOI 10.1007/s00371-013-0792-6
   Huang H., 2014, P 23 INT C WORLD WID, P499, DOI [DOI 10.1145/2567948.2576940, 10.1145/2567948.2576940]
   Jiang YG, 2014, AAAI CONF ARTIF INTE, P73
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Lang P., 2008, A8 ASI I
   Lee PM, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION COMPANION (GECCO'12), P375
   Levesque J.-C., 2013, AUT FAC GEST REC FG, P1
   Li B, 2012, P 20 ACM INT C MULT, P1365
   Lin JC, 2012, IEEE T MULTIMEDIA, V14, P142, DOI 10.1109/TMM.2011.2171334
   Luengo I, 2010, IEEE T MULTIMEDIA, V12, P490, DOI 10.1109/TMM.2010.2051872
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moll J, 2005, COGN BEHAV NEUROL, V18, P68, DOI 10.1097/01.wnn.0000152236.46475.a7
   Mower E, 2009, IEEE T MULTIMEDIA, V11, P843, DOI 10.1109/TMM.2009.2021722
   Olkiewicz K. A., 2010, Proceedings 2010 International Multiconference on Computer Science and Information Technology (IMCSIT 2010), P89
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Osgood C. E., 1957, The measurement of meaning
   Ozkan D, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P477
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Peng KC, 2014, IEEE IMAGE PROC, P4637, DOI 10.1109/ICIP.2014.7025940
   PENNEBAKER JW, 1992, J SOC CLIN PSYCHOL, V11, P199, DOI 10.1521/jscp.1992.11.3.199
   Plutchik R, 1980, EMOTION THEORY RES E, P3
   Siersdorfer S., 2010, ACM MM, P715
   Simon RW, 2004, AM J SOCIOL, V109, P1137, DOI 10.1086/382111
   Singla P., 2008, Proceedings of the 17th international conference on World Wide Web, WWW '08, P655, DOI DOI 10.1145/1367497.1367586
   Song Y, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P237, DOI 10.1145/2522848.2522851
   Tang J, 2012, IEEE T AFFECT COMPUT, V3, P132, DOI 10.1109/T-AFFC.2011.23
   Tang WB, 2011, LECT NOTES ARTIF INT, V6913, P381
   Tawari A, 2010, IEEE T MULTIMED, V12, P6
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Wang SF, 2015, IEEE T MULTIMEDIA, V17, P2185, DOI 10.1109/TMM.2015.2484966
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wang XH, 2015, IEEE T AFFECT COMPUT, V6, P286, DOI 10.1109/TAFFC.2015.2400917
   Wang XH, 2013, IEEE IMAGE PROC, P3230, DOI 10.1109/ICIP.2013.6738665
   Wang YJ, 2012, IEEE T MULTIMEDIA, V14, P597, DOI 10.1109/TMM.2012.2189550
   Wei-Ning W, 2006, IEEE SYS MAN CYBERN, P3534, DOI 10.1109/ICSMC.2006.384667
   Wu B., 2010, INFOCOM IEEE Conference on Computer Communications Workshops , 2010, P1
   Wu CH, 2013, IEEE T MULTIMEDIA, V15, P1880, DOI 10.1109/TMM.2013.2269314
   Wu CH, 2013, IEEE T MULTIMEDIA, V15, P1732, DOI 10.1109/TMM.2013.2272917
   Yang Y, 2016, AAAI CONF ARTIF INTE, P65
   Yang Y, 2014, AAAI CONF ARTIF INTE, P306
   You QZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1071, DOI 10.1145/2733373.2806284
   Zhao SC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P879, DOI 10.1145/2733373.2806354
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhao X. W., 2014, P 20 ACM SIGKDD INT
NR 68
TC 14
Z9 14
U1 2
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2017
VL 19
IS 7
BP 1670
EP 1684
DI 10.1109/TMM.2017.2655881
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Telecommunications
GA EY5ZN
UT WOS:000404061800021
DA 2024-07-18
ER

PT J
AU Lu, DY
   Sang, JT
   Chen, ZN
   Xu, M
   Mei, T
AF Lu, Dongyuan
   Sang, Jitao
   Chen, Zhineng
   Xu, Min
   Mei, Tao
TI Who Are Your "Real" Friends: Analyzing and Distinguishing Between
   Offline and Online Friendships From Social Multimedia Data
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Photo sharing behavior analysis; offline friendship identification;
   social multimedia mining
ID COMPETITION; NETWORKS; MEDIA
AB The Internet has extended the physical boundary of people's social circles to manage an inordinate number of online friends. It is recognized that only a fraction of these online friends are also known with each other in offline circumstances, i.e., the offline friends. An important type of offline friend, onsite offline friend, is defined and addressed in this paper. We explores the possibility of utilizing users' online photo sharing-related behaviors and network topologies to analyze and distinguish between online and onsite offline friendships. Different from traditional social science studies which rely on survey-based data, we employ users' tagged people on the shared Instagram photos as the ground-truth for onsite offline friends. This enables a large-scale and objective analysis and experimental evaluation, which compares between different factors and identifies the features that are key to onsite offline friend identification.
C1 [Lu, Dongyuan] Univ Int Business & Econ, Sch Informat Technol & Management, Beijing 100029, Peoples R China.
   [Sang, Jitao] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100049, Peoples R China.
   [Sang, Jitao] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210000, Jiangsu, Peoples R China.
   [Chen, Zhineng] Chinese Acad Sci, Inst Automat, Beijing 100049, Peoples R China.
   [Xu, Min] Univ Technol Sydney, Sch Comp & Commun, Ultimo, NSW 2007, Australia.
   [Mei, Tao] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 University of International Business & Economics; Chinese Academy of
   Sciences; Institute of Automation, CAS; Nanjing University; Chinese
   Academy of Sciences; Institute of Automation, CAS; University of
   Technology Sydney; Microsoft; Microsoft Research Asia
RP Lu, DY (corresponding author), Univ Int Business & Econ, Sch Informat Technol & Management, Beijing 100029, Peoples R China.
EM ludy@uibe.edu.cn; sangjitao@gmail.com; zhineng.chen@ia.ac.cn;
   Min.Xu@uts.edu.au; tmei@microsoft.com
RI chen, zhineng/AAD-6723-2020; Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307; Xu, Min/0000-0001-9581-8849
FU National Science Foundation of China [61602115, 61303175, 61672518];
   "the Fundamental Research Funds for the Central Universities" in UIBE
   [15QD09]
FX This work was supported by the National Science Foundation of China
   under Grant 61602115, Grant 61303175, and Grant 61672518, and by "the
   Fundamental Research Funds for the Central Universities" in UIBE
   (15QD09). The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Beniot Huet.
CR [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], 2012, P 20 ACM INT C MULT, DOI DOI 10.1145/2393347.2393439
   [Anonymous], 2008, Cambridge Series in Statistical and Probabilistic Mathematics
   [Anonymous], 1999, Networks in the Global Village: Life in Contemporary Communities
   Anthenunis M.L., 2012, Cyberpsychology: Journal of Psychosocial Research on Cyberspace, V6, DOI DOI 10.5817/CP2012-3-6
   Baym NK, 2004, NEW MEDIA SOC, V6, P299, DOI 10.1177/1461444804041438
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Burgoon JK, 2002, J COMMUN, V52, P657, DOI 10.1111/j.1460-2466.2002.tb02567.x
   Cha M, 2009, WWW 09 P 18 INT WORL, DOI DOI 10.1145/1526709.1526806
   Chang Y., 2008, P WORKSHOP CAUSATION, V3, P53
   Consalvo M., 2011, HDB INTERNET STUDIES
   Cranshaw J, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P119
   Cristani M., 2013, P 21 ACM INT C MULT, P213
   Dimmick J, 2000, COMMUN RES, V27, P227, DOI 10.1177/009365000027002005
   Doran D, 2016, AI COMMUN, V29, P57, DOI 10.3233/AIC-150683
   DUNBAR RIM, 1992, J HUM EVOL, V22, P469, DOI 10.1016/0047-2484(92)90081-J
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P1031, DOI 10.1109/TMM.2015.2430819
   Fang Q, 2014, IEEE T MULTIMEDIA, V16, P796, DOI 10.1109/TMM.2014.2298216
   FoucaultWelles Brooke., 2010, EXTENDED ABSTRACTS H, P4027
   Jiang AH, 2015, I C INTELL COMPUT TE, P722, DOI 10.1109/ICICTA.2015.183
   Jin Xin, 2010, P 18 ACM INT C MULT, P1235, DOI [10.1145/1873951.1874196, DOI 10.1145/1873951.1874196]
   Kompatsiaris I, 2013, IEEE T MULTIMEDIA, V15, P1229, DOI 10.1109/TMM.2013.2264232
   Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110
   Lee Wee Sun, 2003, P INT C MACH LEARN, P448
   Liu B., 2007, Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data
   Liu B., 2002, ICML, P387
   Liu X., 2012, Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. KDD '12, P1032, DOI DOI 10.1145/2339530.2339693
   McCroskey J. C., 1974, W SPEECH COMM ASS CO
   Mesch G, 2006, INFORM SOC, V22, P137, DOI 10.1080/01972240600677805
   Paolillo J.C., 2008, P 41 ANN HAWAII INT, P156, DOI DOI 10.1109/HICSS.2008.415
   Papacharissi Z, 2009, NEW MEDIA SOC, V11, P199, DOI 10.1177/1461444808099577
   Putnam R.D., 2000, Bowling alone: The collapse and revival of American community
   Reagans R, 2005, MANAGE SCI, V51, P1374, DOI 10.1287/mnsc.1050.0389
   Rosenthal R., 1966, Experimenter effects in behavioral research
   Subrahmanyam K, 2008, J APPL DEV PSYCHOL, V29, P420, DOI 10.1016/j.appdev.2008.07.003
   van der Laan M., 2010, Amstat News
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xie LX, 2013, IEEE T MULTIMEDIA, V15, P1244, DOI 10.1109/TMM.2013.2264929
   Yan M., 2013, 2013 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI DOI 10.1109/ICME.2013.6607510
   You QZ, 2015, IEEE T MULTIMEDIA, V17, P2271, DOI 10.1109/TMM.2015.2487863
   Yu T, 2009, PROC CVPR IEEE, P1462, DOI 10.1109/CVPRW.2009.5206526
   Yuan NicholasJing., 2013, P 1 ACM C ONLINE SOC, P3
   Zheng D., 2014, P 3 ACM MULT WORKSH, P21
   Zhu JH, 2013, INT CONF DAT MIN WOR, P421, DOI 10.1109/ICDMW.2013.112
NR 45
TC 10
Z9 10
U1 1
U2 43
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2017
VL 19
IS 6
BP 1299
EP 1313
DI 10.1109/TMM.2016.2646181
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Telecommunications
GA EY5YS
UT WOS:000404059400015
DA 2024-07-18
ER

PT J
AU Zhu, HY
   Lu, JB
   Cai, JF
   Zheng, JM
   Lu, SJ
   Thalmann, NM
AF Zhu, Hongyuan
   Lu, Jiangbo
   Cai, Jianfei
   Zheng, Jianmin
   Lu, Shijian
   Thalmann, Nadia Magnenat
TI Multiple Human Identification and Cosegmentation: A Human-Oriented CRF
   Approach With Poselets
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cosegmentation; cross-region support; human identification; poselets;
   shape cues
ID SEGMENTATION; RECOGNITION; SALIENCY
AB Localizing, identifying, and extracting humans with consistent appearance jointly from a personal photo stream is an important problem and has wide applications. The strong variations in foreground and background and irregularly occurring foreground humans make this realistic problem challenging. Inspired by advancements in object detection, scene understanding, and image cosegmentation, we explore explicit constraints to label and segment human objects rather than other nonhuman objects and "stuff." We refer to such a problem as multiple human identification and cosegmentation (MHIC). To identify specific human subjects, we propose an efficient human instance detector by combining an extended color line model with a poselet-based human detector. Moreover, to capture high-level human shape information, a novel soft shape cue is proposed. It is initialized by the human detector, then further enhanced through a generalized geodesic distance transform, and finally refined with a joint bilateral filter. We also propose to capture the rich feature context around each pixel by using an adaptive cross-region data structure, which gives a higher discriminative power than a single pixel-based estimation. The high-level object cues from the detector and the shape are then integrated with the low-level pixel cues and midlevel contour cues into a principled conditional random field (CRF) framework, which can be efficiently solved by using fast graph cut algorithms. We evaluate our method over a newly created NTU-MHIC human dataset, which contains 351 images with manually annotated groundtruth segmentation. Both visual and quantitative results demonstrate that our method achieves state-of-the-art performance for the MHIC task.
C1 [Zhu, Hongyuan; Lu, Jiangbo] Adv Digital Sci Ctr, Singapore 138632, Singapore.
   [Zhu, Hongyuan; Cai, Jianfei; Zheng, Jianmin; Thalmann, Nadia Magnenat] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Zhu, Hongyuan; Lu, Shijian] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.
C3 Nanyang Technological University; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Lu, JB (corresponding author), Adv Digital Sci Ctr, Singapore 138632, Singapore.
EM zhuh@i2r.a-star.edu.sg; jiangbo.lu@adsc.com.sg; asjfcai@ntu.edu.sg;
   asjmzheng@ntu.edu.sg; slu@i2r.a-star.edu.sg; nadiathalmann@ntu.edu.sg
RI Lu, Shijian/AAU-4831-2021; Thalmann, Nadia/AAK-5195-2021; Zheng,
   Jianmin/A-3717-2011; Cai, Jianfei/A-3691-2011
OI Lu, Shijian/0000-0002-6766-2506; Thalmann, Nadia/0000-0002-1459-5960;
   Zheng, Jianmin/0000-0002-5062-6226; Cai, Jianfei/0000-0002-9444-3763;
   Lu, Jiangbo/0000-0002-0048-3140
FU Singapore's Agency for Science, Technology and Research (A*STAR)
FX This work was supported by the research grant for the Human-Centered
   Cyber-Physical Systems Programme at the Advanced Digital Sciences Center
   from Singapore's Agency for Science, Technology and Research (A*STAR).
   The associate editor coordinating the review of this manuscript and
   approving it for publication was Prof. Klara Nahrstedt. (Corresponding
   author: Jiangbo Lu.)
CR Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   Anguelov D, 2007, PROC CVPR IEEE, P673
   [Anonymous], 2003, ACM Multimedia Conference
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2012, IEEE C COMP VIS PATT
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x
   Bourdev L. D., 2010, EUR C COMP VIS CRET
   Collins M. D., 2012, IEEE C COMP VIS PATT
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Criminisi A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857910
   Efros A. A., 2003, 9 INT C COMP VIS NIC
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x
   Garg R, 2011, PROC CVPR IEEE, P1793, DOI 10.1109/CVPR.2011.5995546
   HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965
   Joulin A., 2010, IEEE C COMP VIS PATT
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kohli P, 2009, IEEE T PATTERN ANAL, V31, P1645, DOI 10.1109/TPAMI.2008.217
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Ladicky L., 2010, EUR C COMP VIS SAN F
   Ladicky L., 2010, EUR C COMP VIS HER G
   Ladicky L, 2013, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2013.459
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Ma TY, 2013, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2013.255
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Mukherjee L, 2011, PROC CVPR IEEE
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubio J. C., 2012, IEEE C COMP VIS PATT
   Shi J., 2013, IEEE INT C COMP VIS
   Shi K., 2013, IEEE C COMP VIS PATT
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Sivic J., 2006, BRIT MACH VIS C ED U
   Song Y., 2006, EUR C COMP VIS GRAZ
   Tapaswi M, 2012, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2012.6247986
   Tighe J, 2013, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2013.386
   Torralba A, 2004, PROC CVPR IEEE, P762
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Vineet V, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.80
   Wang KZ, 2015, IEEE T IMAGE PROCESS, V24, P3019, DOI 10.1109/TIP.2015.2432712
   Wei Y., 2007, IEEE INT C COMP VIS
   Yang H., 2014, IEEE C COMP VIS PATT
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yu G, 2011, IEEE T MULTIMEDIA, V13, P507, DOI 10.1109/TMM.2011.2128301
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhu H., 2013, IEEE INT S CIRC SYST
   Zhu HY, 2016, J VIS COMMUN IMAGE R, V34, P12, DOI 10.1016/j.jvcir.2015.10.012
   Zhu HY, 2014, IEEE WINT CONF APPL, P485, DOI 10.1109/WACV.2014.6836062
   Zhu HY, 2013, IEEE T IMAGE PROCESS, V22, P4019, DOI 10.1109/TIP.2013.2268973
NR 56
TC 11
Z9 11
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2016
VL 18
IS 8
BP 1516
EP 1530
DI 10.1109/TMM.2016.2571629
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DR5YJ
UT WOS:000379978000006
DA 2024-07-18
ER

PT J
AU Patrona, F
   Iosifidis, A
   Tefas, A
   Nikolaidis, N
   Pitas, I
AF Patrona, Foteini
   Iosifidis, Alexandros
   Tefas, Anastasios
   Nikolaidis, Nikolaos
   Pitas, Ioannis
TI Visual Voice Activity Detection in the Wild
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Action recognition; bag of words model; kernel extreme learning machine;
   space-time interest points; voice activity detection in the wild
ID EXTREME LEARNING-MACHINE; IMAGE CLASSIFICATION; SPEECH RECOGNITION;
   INFORMATION; RETRIEVAL; NETWORKS; VIDEOS
AB The visual voice activity detection (V-VAD) problem in unconstrained environments is investigated in this paper. A novel method for V-VAD in the wild, exploiting local shape and motion information appearing at spatiotemporal locations of interest for facial video segment description and the bag of words model for facial video segment representation, is proposed. Facial video segment classification is subsequently performed using the state-of-the-art classification algorithms. Experimental results on one publicly available V-VAD dataset denote the effectiveness of the proposed method, since it achieves better generalization performance in unseen users, when compared to the recently proposed state-of-the-art methods. Additional results on a new unconstrained dataset provide evidence that the proposed method can be effective even in such cases in which any other existing method fails.
C1 [Patrona, Foteini; Iosifidis, Alexandros; Tefas, Anastasios; Nikolaidis, Nikolaos; Pitas, Ioannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
   [Iosifidis, Alexandros] Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
   [Pitas, Ioannis] Univ Bristol, Bristol BS8 1TH, Avon, England.
C3 Aristotle University of Thessaloniki; Tampere University; University of
   Bristol
RP Patrona, F; Iosifidis, A; Tefas, A; Nikolaidis, N; Pitas, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.; Iosifidis, A (corresponding author), Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.; Pitas, I (corresponding author), Univ Bristol, Bristol BS8 1TH, Avon, England.
EM fotinip@aiia.csd.auth.gr; alexandros.iosifidis@tut.fi;
   tefas@aiia.csd.auth.gr; nikolaid@aiia.csd.auth.gr;
   pitas@aiia.csd.auth.gr
RI Nikolaidis, Nikos/F-1819-2010; Tefas, Anastasios/ABA-2328-2020
OI Nikolaidis, Nikos/0000-0003-1515-7986; 
FU European Union [287674]
FX This work was supported by the European Union Seventh Framework Program
   (FP7/2007-2013) under Grant 287674 (3DTVS). The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Qi Tian.
CR [Anonymous], 2008, SIGN PROC C 2008 16
   [Anonymous], 2009, PROC AVSP
   [Anonymous], P 4 ALV VIS C, DOI DOI 10.5244/C.2.23
   [Anonymous], 2011, 2011 8 INT C INF COM, DOI DOI 10.1109/ICICS.2011.6174265
   Aubrey AJ, 2010, IET IMAGE PROCESS, V4, P463, DOI 10.1049/iet-ipr.2009.0042
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2008, NEUROCOMPUTING, V71, P576, DOI 10.1016/j.neucom.2007.07.025
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Iosifidis A, 2015, PATTERN RECOGN LETT, V54, P11, DOI 10.1016/j.patrec.2014.12.003
   Iosifidis A, 2014, PATTERN RECOGN LETT, V49, P185, DOI 10.1016/j.patrec.2014.07.011
   Iosifidis A, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854640
   Iosifidis A, 2013, IEEE T CIRC SYST VID, V23, P1968, DOI 10.1109/TCSVT.2013.2269774
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu QJ, 2014, IEEE T MULTIMEDIA, V16, P1610, DOI 10.1109/TMM.2014.2322824
   Minotto Vicente P., 2014, IEEE Transactions on Multimedia, V16, P1032, DOI 10.1109/TMM.2014.2305632
   Minotto VP, 2013, IEEE J-STSP, V7, P147, DOI 10.1109/JSTSP.2012.2237379
   Nathwani K, 2013, IEEE T MULTIMEDIA, V15, P1326, DOI 10.1109/TMM.2013.2247391
   Navarathna R., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P134, DOI 10.1109/DICTA.2011.29
   Navarathna R., 2010, C INT SPEECH COMM AS
   Patterson EK, 2002, INT CONF ACOUST SPEE, P2017
   Petridis S, 2011, IEEE T MULTIMEDIA, V13, P216, DOI 10.1109/TMM.2010.2101586
   Saenko K, 2005, IEEE I CONF COMP VIS, P1424, DOI 10.1109/ICCV.2005.251
   Sargin M., 2007, IEEE T MULTIMEDIA, V9, P1520
   Siatras S., 2006, EUR SIGN PROC C FLOR
   Sodoyer D., 2006, INT C AC SPEECH SIGN
   Sodoyer D, 2009, J ACOUST SOC AM, V125, P1184, DOI 10.1121/1.3050257
   Stamou GN, 2007, J MULTIMODAL USER IN, V1, P31, DOI 10.1007/BF02910057
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Wang H., 2009, BRIT MACH VIS C LOND
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang C, 2008, IEEE T MULTIMEDIA, V10, P1541, DOI 10.1109/TMM.2008.2007344
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
   Zoidi O, 2013, IEEE T CIRC SYST VID, V23, P870, DOI 10.1109/TCSVT.2012.2226527
NR 42
TC 20
Z9 21
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2016
VL 18
IS 6
BP 967
EP 977
DI 10.1109/TMM.2016.2535357
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DM1LP
UT WOS:000376107100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gao, ZP
   Zhai, GT
   Zhou, JT
AF Gao, Zhongpai
   Zhai, Guangtao
   Zhou, Jiantao
TI Factorization Algorithms for Temporal Psychovisual Modulation Display
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Hierarchical alternating least squares (HALS); image display;
   nonnegative matrix factorization (NMF); temporal psychovisual modulation
   (TPVM); visual signal processing
ID NONNEGATIVE MATRIX FACTORIZATION
AB Temporal psychovisual modulation (TPVM) is a new information display technology which aims to generate multiple visual percepts for different viewers on a single display simultaneously. In a TPVM system, the viewers wearing different active liquid crystal (LC) glasses with varying transparency levels can see different images (called personal views). The viewers without LC glasses can also see a semantically meaningful image (called shared view). The display frames and weights for the LC glasses in the TPVM system can be computed through nonnegative matrix factorization (NMF) with three additional constrains: 1) the values of images and modulation weights should have upper bound (i.e., limited luminance of the display and transparency level of the LC); 2) the shared view without using viewing devices should be considered (i.e., the sum of all basis images should be a meaningful image); and 3) the sparsity of modulation weights should be considered due to the material property of LC. In this paper, we proposed to solve the constrained NMF problem by a modified version of hierarchical alternating least squares (HALS) algorithms. Through experiments, we analyze the choice of parameters in the setup of TPVM system. This work serves as a guideline for practical implementation of TPVM display system.
C1 [Gao, Zhongpai; Zhai, Guangtao] Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
   [Zhou, Jiantao] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 Shanghai Jiao Tong University; University of Macau
RP Zhai, GT (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
EM gaozhongpai@sjtu.edu.cn; zhaiguangtao@sjtu.edu.cn; jtzhou@umac.mo
RI Zhai, Guangtao/X-5949-2019; Gao, Zhongpai/ABA-9234-2021
OI Zhai, Guangtao/0000-0001-8165-9322; Gao, Zhongpai/0000-0003-4344-4501
FU National Science Foundation of China [61422112, 61371146, 61521062,
   61331014]; Foundation for the Author of National Excellent Doctoral
   Dissertation of China [201339]
FX This work was supported in part by the National Science Foundation of
   China under Grant 61422112, Grant 61371146, Grant 61521062, and Grant
   61331014, and in part by the Foundation for the Author of National
   Excellent Doctoral Dissertation of China under Grant 201339. This paper
   was presented at the IEEE International Symposium on Circuits and
   Systems, Lisbon, Portugal, May 2015. The associate editor coordinating
   the review of this manuscript and approving it for publication was Dr.
   Sen-Ching Samson Cheung.
CR Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Chen R. H., 2011, LIQUID CRYSTAL TELEV, P369
   Cichocki A, 2009, IEICE T FUND ELECTR, VE92A, P708, DOI 10.1587/transfun.E92.A.708
   Feng JZ, 2014, IEEE T CIRC SYST VID, V24, P553, DOI 10.1109/TCSVT.2013.2280089
   Fujimura W., 2012, P SIGGRAPH AS 2012 E, P11
   Gao Z., 2015, P ACM INT C MULT, P675
   Gao ZP, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P145, DOI 10.1109/VCIP.2014.7051525
   Gao ZP, 2014, IEEE IMAGE PROC, P2168, DOI 10.1109/ICIP.2014.7025436
   Gao ZP, 2014, IEEE INT SYMP CIRC S, P449, DOI 10.1109/ISCAS.2014.6865167
   Gillis N, 2012, NEURAL COMPUT, V24, P1085, DOI 10.1162/NECO_a_00256
   Gonzalez E., 2005, TR0502 RIC U DEP COM
   Gu Ye, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P147, DOI 10.1109/ISMAR.2010.5643563
   Hu CJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P785, DOI 10.1145/2733373.2807404
   Hu CJ, 2014, C IND ELECT APPL, P944, DOI 10.1109/ICIEA.2014.6931299
   Jiao LB, 2013, IEEE SIGNAL PROC LET, V20, P1203, DOI 10.1109/LSP.2013.2285284
   Karnik A., 2012, P SIGCHI C HUM FACT, P2541, DOI DOI 10.1145/2207676.2208641
   Karnik A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P271
   Kim J, 2011, SIAM J SCI COMPUT, V33, P3261, DOI 10.1137/110821172
   Ko H., 2010, [Stereoscopic screen sharing method and apparatus, US Patent Appl], Patent No. [12/503,029, 12503029]
   Lanman D., 2011, P 2011 SIGGRAPH AS C
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee J.-H., 2008, INTRO FLAT PANEL DIS, V20
   Liu J., 2014, P SIGGRAPH AS 2014 T
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   NAKAMURA H, 2001, SID Symposium Digest of Technical Papers, V32, P1256
   Nashel Andrew., 2009, 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video, 2009, P1
   Reinhard E., 2005, The Morgan Kaufmann Series in Computer Graphics
   Scher S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487229
   Texas Instruments Dallas TX USA, 2015, DLP DISC 4100 DEV KI
   Tian WM, 2014, INT CONF COMPUT INFO, P118, DOI 10.1109/CIT.2014.134
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wetzstein G, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185576
   Wu X., 2012, P SIGGRAPH AS EM TEC
   Wu XL, 2013, IEEE SIGNAL PROC MAG, V30, P136, DOI 10.1109/MSP.2012.2219678
   Zhai GT, 2014, IEEE SIGNAL PROC MAG, V31, P144, DOI 10.1109/MSP.2014.2328506
   Zhai GT, 2014, J DISP TECHNOL, V10, P757, DOI 10.1109/JDT.2014.2317810
NR 36
TC 11
Z9 12
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2016
VL 18
IS 4
BP 614
EP 626
DI 10.1109/TMM.2016.2523425
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DH4XZ
UT WOS:000372790300006
DA 2024-07-18
ER

PT J
AU Liu, Y
   Pados, DA
AF Liu, Ying
   Pados, Dimitris A.
TI Compressed-Sensed-Domain <i>L</i><sub>1</sub>-PCA Video Surveillance
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Background and foreground extraction; compressed sensing; compressive
   sampling; convex optimization; feature extraction; L-1 principle
   component analysis; singular value decomposition; total-variation
   minimization; video surveillance
ID MOVING OBJECT DETECTION; SIGNAL RECOVERY; DETECTION ALGORITHM; MOTION
   DETECTION; OUTLIERS; NETWORK
AB We consider the problem of foreground and background extraction from compressed-sensed (CS) surveillance videos that are captured by a static CS camera. We propose, for the first time in the literature, a principal component analysis (PCA) approach that computes directly in the CS domain the low-rank subspace of the background scene. Rather than computing the conventional L-2-norm-based principal components, which are simply the dominant left singular vectors of the CS-domain data matrix, we compute the principal components under an L-1-norm maximization criterion. The background scene is then obtained by projecting the CS measurement vector onto the L-1 principal components followed by total-variation (TV) minimization image recovery. The proposed L1-norm procedure directly carries out low-rank background representation without reconstructing the video sequence and, at the same time, exhibits significant robustness against outliers in CS measurements compared to L-2-norm PCA. An adaptive CS-L-1-PCA method is also developed for low-latency video surveillance. Extensive experimental studies described in this paper illustrate and support the theoretical developments.
C1 [Liu, Ying; Pados, Dimitris A.] SUNY Buffalo, Dept Elect Engn, Buffalo, NY 14260 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo
RP Liu, Y; Pados, DA (corresponding author), SUNY Buffalo, Dept Elect Engn, Buffalo, NY 14260 USA.
EM y172@buffalo.edu; pados@buffalo.edu
FU National Science Foundation [CNS-1117121, CNS-1422874]; Direct For
   Computer & Info Scie & Enginr; Division Of Computer and Network Systems
   [1503609] Funding Source: National Science Foundation; Directorate For
   Engineering; Div Of Electrical, Commun & Cyber Sys [1462341] Funding
   Source: National Science Foundation
FX This work was supported in part by the National Science Foundation under
   Grant CNS-1117121 and Grant CNS-1422874. This paper was presented in
   part at the SPIE DSS Sensing Technology and Applications Conference,
   Baltimore, MD, USA, April 2015. The associate editor coordinating the
   review of this manuscript and approving it for publication was Prof.
   Yap-Peng Tan.
CR [Anonymous], CORR
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2003, CMUCS03172
   [Anonymous], SPIE J ELECT IMAGING
   [Anonymous], P AS C COMP VIS JEJ
   Candes E.J., 2005, l1-MAGIC: Recovery of sparse signals via convex programming
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chen BH, 2014, IEEE T MULTIMEDIA, V16, P837, DOI 10.1109/TMM.2014.2298377
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dadkhah MR, 2010, INT CONF ACOUST SPEE, P1310, DOI 10.1109/ICASSP.2010.5495429
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139
   Ganapathy H, 2011, IEEE T COMMUN, V59, P1411, DOI 10.1109/TCOMM.2011.020811.090405
   Ganapathy H, 2011, IEEE T COMMUN, V59, P1123, DOI 10.1109/TCOMM.2011.020411.090404
   Gao K, 2011, IEEE T SIGNAL PROCES, V59, P4759, DOI 10.1109/TSP.2011.2160860
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Haque M, 2008, INT C PATT RECOG, P1001
   Huang SC, 2014, IEEE T CYBERNETICS, V44, P114, DOI 10.1109/TCYB.2013.2248057
   Huang SC, 2013, IEEE T NEUR NET LEAR, V24, P1920, DOI 10.1109/TNNLS.2013.2270314
   Huang SC, 2014, IEEE T IND ELECTRON, V61, P2099, DOI 10.1109/TIE.2013.2262764
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   Jiang H, 2012, INVERSE PROBL IMAG, V6, P201, DOI 10.3934/ipi.2012.6.201
   Ke J, 2011, OPT COMMUN, V284, P1170, DOI 10.1016/j.optcom.2010.11.028
   Ke QF, 2005, PROC CVPR IEEE, P739
   Kundu Sandipan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8028, DOI 10.1109/ICASSP.2014.6855164
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Li C., 2010, EFFICIENT ALGORITHM
   Liu Y, 2013, ADV MATH PHYS, V2013, DOI 10.1155/2013/787891
   Liu YZ, 2007, J VIS COMMUN IMAGE R, V18, P253, DOI 10.1016/j.jvcir.2007.01.003
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Ma S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587391
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Markopoulos PP, 2014, IEEE T SIGNAL PROCES, V62, P5046, DOI 10.1109/TSP.2014.2338077
   Nie F., 2011, P INT JOINT C ART IN
   Piccardi M, 2004, IEEE IMAGE PROC, P3399
   Pudlewski S, 2013, IEEE T MULTIMEDIA, V15, P2072, DOI 10.1109/TMM.2013.2280245
   Seo JW, 2014, IEEE T MULTIMEDIA, V16, P2333, DOI 10.1109/TMM.2014.2353772
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yu LB, 2012, INT CONF ACOUST SPEE, P1377, DOI 10.1109/ICASSP.2012.6288147
   Zheng Yi, 2010, Proceedings 2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering (ISKE 2010), P270, DOI 10.1109/ISKE.2010.5680866
   Zhou Q., 2001, Proc. IEEE Workshop on Performance Evaluation of Tracking and Surveillance, P1
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 49
TC 53
Z9 57
U1 0
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2016
VL 18
IS 3
BP 351
EP 363
DI 10.1109/TMM.2016.2514848
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DG2WP
UT WOS:000371931600004
DA 2024-07-18
ER

PT J
AU Tohidypour, HR
   Pourazad, MT
   Nasiopoulos, P
AF Tohidypour, Hamid Reza
   Pourazad, Mahsa T.
   Nasiopoulos, Panos
TI Probabilistic Approach for Predicting the Size of Coding Units in the
   Quad-Tree Structure of the Quality and Spatial Scalable HEVC
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Bayesian classifier; coding tree unit structure; low complexity
   compression; quality scalable HEVC; spatial scalable HEVC; video
   compression
ID MODE DECISION ALGORITHM; MOTION ESTIMATION
AB The scalable extension of HEVC (known as SHVC), the recent scalable video coding standard, results in an improved compression performance at the cost of significant increase in computational coding complexity. One of the main factors that contribute to the SHVC encoder complexity is choosing the best partitioning structure for the coding tree units (CTUs). Our study focuses on developing a scheme for predicting the CTU structure in the quality and spatial scalable extension of HEVC. The proposed scheme uses the CTU partitioning structure of the already encoded CTUs in the enhancement layers (ELs) and base layer (BL) to predict the coding unit sizes of the to-be-encoded CTUs in the EL. Performance evaluations confirm that our proposed complexity reduction scheme significantly reduces the execution time of the SHVC encoder, while maintaining the overall quality of the coded streams.
C1 [Tohidypour, Hamid Reza] Univ British Columbia, Dept Elect Engn, Vancouver, BC V6T 1Z4, Canada.
   [Pourazad, Mahsa T.] TELUS Commun Inc, Vancouver, BC V6B 0M3, Canada.
   [Pourazad, Mahsa T.] Univ British Columbia, Inst Comp Informat & Cognit Syst, Vancouver, BC V6T 1Z4, Canada.
   [Nasiopoulos, Panos] Univ British Columbia, Inst Comp Informat & Cognit Syst, Dept Elect Engn, Vancouver, BC V6T 1Z4, Canada.
C3 University of British Columbia; University of British Columbia;
   University of British Columbia
RP Tohidypour, HR (corresponding author), Univ British Columbia, Dept Elect Engn, Vancouver, BC V6T 1Z4, Canada.; Pourazad, MT (corresponding author), TELUS Commun Inc, Vancouver, BC V6B 0M3, Canada.; Pourazad, MT (corresponding author), Univ British Columbia, Inst Comp Informat & Cognit Syst, Vancouver, BC V6T 1Z4, Canada.; Nasiopoulos, P (corresponding author), Univ British Columbia, Inst Comp Informat & Cognit Syst, Dept Elect Engn, Vancouver, BC V6T 1Z4, Canada.
EM htohidyp@ece.ubc.ca; pourazad@ece.ubc.ca; panosn@ece.ubc.ca
FU Natural Sciences and Engineering Research Council of Canada [NSERC-STPGP
   447339-13]; NSERC DIVA Strategic Research Network, TELUS
FX This work was supported in part by the Natural Sciences and Engineering
   Research Council of Canada under Grant NSERC-STPGP 447339-13, in part by
   the NSERC DIVA Strategic Research Network, TELUS, and in part by other
   industry partners. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Yonghong Tian.
CR [Anonymous], 2014, JCTVCQ1009
   [Anonymous], 2010, JTC1SC29WG11 ISOIEC
   [Anonymous], 2001, VCEGM33
   [Anonymous], 2011, JCTVCG543 ITUTISOIEC
   [Anonymous], 2012, JCTVCH0022
   [Anonymous], 2011, JCTVCF900
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2013, JTC1SC29WG11 ISOIEC
   Bailleul Robin, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P193, DOI 10.1109/ICCE.2014.6775968
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Hu N, 2014, IEEE T CIRC SYST VID, V24, P1310, DOI 10.1109/TCSVT.2014.2306035
   Huang A., 2009, P CNMT JAN, P18
   Joint Preliminary Call for Proposals on Scalable Video Coding Extensions of High Efficiency Video Coding (HEVC), 2012, WP316 ITUT
   Jung SW, 2010, IEEE T CIRC SYST VID, V20, P201, DOI 10.1109/TCSVT.2009.2031387
   Kim J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P449, DOI 10.1109/PCS.2012.6213251
   Kim ST, 2010, IEEE IMAGE PROC, P1297, DOI 10.1109/ICIP.2010.5650805
   Lee B, 2011, IEEE T CIRC SYST VID, V21, P88, DOI 10.1109/TCSVT.2011.2106273
   Lim S, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1897
   Lin HC, 2007, IEEE IMAGE PROC, P853
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Park C., 2010, IEEE T CIRCUITS SYST, V19, P1915
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Shen LQ, 2010, IEEE IMAGE PROC, P4229, DOI 10.1109/ICIP.2010.5651298
   Shen LQ, 2010, IEEE SIGNAL PROC LET, V17, P887, DOI 10.1109/LSP.2010.2066966
   Shen LQ, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3478882
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V., 2014, INTEGRATED CIRCUITS
   Tohidypour H. R., 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P191, DOI 10.1109/ICCE.2014.6775967
   Tohidypour H. R., 2013, P 6 BALK C INF BCI T, P61
   Tohidypour HR, 2013, INT CONF ACOUST SPEE, P1744, DOI 10.1109/ICASSP.2013.6637951
   Wang DY, 2014, LECT NOTES COMPUT SC, V8588, P693, DOI 10.1007/978-3-319-09333-8_75
   Wien M., 2014, SIGNALS COMMUNICATIO
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yeh CH, 2010, IEEE T CIRC SYST VID, V20, P563, DOI 10.1109/TCSVT.2010.2041825
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zuo XG, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P394, DOI 10.1109/VCIP.2014.7051589
NR 44
TC 33
Z9 35
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2016
VL 18
IS 2
BP 182
EP 195
DI 10.1109/TMM.2015.2510332
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DB3HX
UT WOS:000368402400004
DA 2024-07-18
ER

PT J
AU Wang, SQ
   Gu, K
   Ma, SW
   Lin, WS
   Liu, XM
   Gao, W
AF Wang, Shiqi
   Gu, Ke
   Ma, Siwei
   Lin, Weisi
   Liu, Xianming
   Gao, Wen
TI Guided Image Contrast Enhancement Based on Retrieved Images in Cloud
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Contrast enhancement; image quality assessment; retrieved images;
   unsharp masking; sigmoid transfer mapping; free-energy; surface quality
ID FREE-ENERGY PRINCIPLE; HISTOGRAM EQUALIZATION; QUALITY ASSESSMENT;
   VISUAL-ATTENTION
AB We propose a guided image contrast enhancement framework based on cloud images, in which the context-sensitive and context-free contrast is jointly improved via solving a multi-criteria optimization problem. In particular, the context-sensitive contrast is improved by performing advanced unsharp masking on the input and edge-preserving filtered images, while the context-free contrast enhancement is achieved by the sigmoid transfer mapping. To automatically determine the contrast enhancement level, the parameters in the optimization process are estimated by taking advantages of the retrieved images with similar content. For the purpose of automatically avoiding the involvement of low-quality retrieved images as the guidance, a recently developed no-reference image quality metric is adopted to rank the retrieved images from the cloud. The image complexity from the free-energy-based brain theory and the surface quality statistics in salient regions are collaboratively optimized to infer the parameters. Experimental results confirm that the proposed technique can efficiently create visually-pleasing enhanced images which are better than those produced by the classical techniques in both subjective and objective comparisons.
C1 [Wang, Shiqi; Ma, Siwei; Gao, Wen] Peking Univ, Inst Digital Media, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.
   [Gu, Ke; Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Liu, Xianming] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Peking University; Nanyang Technological University; Harbin Institute of
   Technology
RP Wang, SQ; Ma, SW; Gao, W (corresponding author), Peking Univ, Inst Digital Media, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.; Gu, K; Lin, WS (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.; Liu, XM (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM sqwang1986@gmail.com; gukes.doctor@gmail.com; swma@pku.edu.cn;
   wslin@ntu.edu.sg; xmliu.hit@gmail.com; wgao@pku.edu.cn
RI Lin, Weisi/A-8011-2012; Gu, Ke/AAJ-9684-2021; Lin, Weisi/A-3696-2011
OI Lin, Weisi/0000-0001-9866-1947; Wang, Shiqi/0000-0002-3583-959X
FU National High-Tech R&D Program of China, 863 Program [2015AA015903];
   National Natural Science Foundation of China [61322106, 61571017,
   61421062, 61300110]; Shenzhen Peacock Plan
FX This work was supported in part by the National High-Tech R&D Program of
   China, 863 Program, under Grant 2015AA015903, in part by the National
   Natural Science Foundation of China under Grant 61322106, Grant
   61571017, Grant 61421062, and Grant 61300110, and in part by the
   Shenzhen Peacock Plan. The associate editor coordinating the review of
   this manuscript and approving it for publication was Dr. Shu-Ching Chen.
CR Allred SR, 2009, J OPT SOC AM A, V26, P949, DOI 10.1364/JOSAA.26.000949
   [Anonymous], 2002, 50011 ITU BT
   [Anonymous], P IEEE VIS COMM IM P
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Fischer M, 2002, IEEE T IMAGE PROCESS, V11, P717, DOI [10.1109/TIP.2002.800893, 10.1109/TIP2002.800893]
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Gu K., IEEE T BROADCAST
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2013, IEEE IMAGE PROC, P383, DOI 10.1109/ICIP.2013.6738079
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hung EM, 2014, IEEE SIGNAL PROC LET, V21, P1140, DOI 10.1109/LSP.2014.2326551
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lukac R, 2007, SIGNAL PROCESS, V87, P2085, DOI 10.1016/j.sigpro.2007.02.009
   Ma S., IEEE T CIRC IN PRESS
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Min XK, 2014, IEEE INT SYMP CIRC S, P894, DOI 10.1109/ISCAS.2014.6865280
   Motoyoshi I, 2007, NATURE, V447, P206, DOI 10.1038/nature05724
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Ramponi G, 1998, SIGNAL PROCESS, V67, P211, DOI 10.1016/S0165-1684(98)00038-3
   Reynolds JH, 2003, NEURON, V37, P853, DOI 10.1016/S0896-6273(03)00097-7
   Shi ZB, 2014, IEEE J EM SEL TOP C, V4, P17, DOI 10.1109/JETCAS.2014.2298291
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Wang J., 2015, P SOC PHOTO-OPT INS, V939
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang ZJ, 2011, IEEE SIGNAL PROC MAG, V28, P2, DOI 10.1109/MSP.2011.940297
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Wu XL, 2011, IEEE T IMAGE PROCESS, V20, P1262, DOI 10.1109/TIP.2010.2092438
   Xu HT, 2014, IEEE T MULTIMEDIA, V16, P68, DOI 10.1109/TMM.2013.2283453
   Yue H., 2013, IEEE T IMAGE PROCESS, V22, P1057
   Yue HJ, 2013, IEEE T MULTIMEDIA, V15, P845, DOI 10.1109/TMM.2013.2239629
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
   Zhang L., 2013, MODELING SELECTIVE V
   Zhang X., P IEEE INT IN PRESS
   Zhang X, 2014, IEEE IMAGE PROC, P4472, DOI 10.1109/ICIP.2014.7025907
NR 54
TC 41
Z9 43
U1 1
U2 36
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2016
VL 18
IS 2
BP 219
EP 232
DI 10.1109/TMM.2015.2510326
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DB3HX
UT WOS:000368402400007
DA 2024-07-18
ER

PT J
AU Kereliuk, C
   Sturm, BL
   Larsen, J
AF Kereliuk, Corey
   Sturm, Bob L.
   Larsen, Jan
TI Deep Learning and Music Adversaries
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE AEA-MIR content-based processing and music information retrieval; deep
   learning
ID INFORMATION-RETRIEVAL; CLASSIFICATION; ARCHITECTURES; DIRECTIONS
AB An adversary is an agent designed to make a classification system perform in some particular way, e.g., increase the probability of a false negative. Recent work builds adversaries for deep learning systems applied to image object recognition, exploiting the parameters of the system to find the minimal perturbation of the input image such that the system misclassifies it with high confidence. We adapt this approach to construct and deploy an adversary of deep learning systems applied to music content analysis. In our case, however, the system inputs are magnitude spectral frames, which require special care in order to produce valid input audio signals from network-derived perturbations. For two different train-test partitionings of two benchmark datasets, and two different architectures, we find that this adversary is very effective. We find that convolutional architectures are more robust compared to systems based on a majority vote over individually classified audio frames. Furthermore, we experiment with a new system that integrates an adversary into the training loop, but do not find that this improves the resilience of the system to new adversaries.
C1 [Kereliuk, Corey] Tech Univ Denmark, DTU Compute, Lyngby, Denmark.
   [Sturm, Bob L.] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
   [Larsen, Jan] Tech Univ Denmark, DK-2800 Lyngby, Denmark.
C3 Technical University of Denmark; University of London; Queen Mary
   University London; Technical University of Denmark
RP Kereliuk, C (corresponding author), Tech Univ Denmark, DTU Compute, Frederiksber 4TV2000, Lyngby, Denmark.
EM coreyker@gmail.com; b.sturm@qmul.ac.uk; janla@dtu.dk
RI Sturm, Bob/C-2613-2013
OI Sturm, Bob/0000-0003-2549-6367; Larsen, Jan/0000-0003-1880-1810
FU Danish Council for Strategic Research, Danish Agency for Science
   Technology and Innovation under the CoSound project [Case 11-115328]
FX The work of C. Kereliuk and J. Larsen was supported in part by the
   Danish Council for Strategic Research, Danish Agency for Science
   Technology and Innovation under the CoSound project, Case 11-115328. The
   guest editor coordinating the review of this manuscript and approving it
   for publication was Dr. Hugo Larochelle.
CR ALLEN JB, 1977, P IEEE, V65, P1558, DOI 10.1109/PROC.1977.10770
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], 1999, AISB S MUSICAL CREAT
   [Anonymous], 2004, Journal of negative results in speech and audio sciences
   [Anonymous], 2015, Deep learning
   [Anonymous], P IEEE WORKSH APPL S
   [Anonymous], 2012, Lecture Notes in Computer Science
   [Anonymous], 2012, ARXIV12115590
   Aucouturier JJ, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P105, DOI 10.1109/ICME.2002.1035729
   Battenberg E., 2012, Proceedings of the 13th International Society for Music Information Retrieval Conference, P37
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bergstra J., 2010, PYTH SCI COMP C AUST
   Bertin-Mahieux T., 2011, ISMIR, P591
   Bertin-Mahieux T., 2010, Machine Audition : Principles, Algorithms and Systems
   Boulanger-Lewandowski N., 2013, ISMIR, P335, DOI 10.5281/zenodo.1418319
   Burges CJC, 2003, IEEE T SPEECH AUDI P, V11, P165, DOI 10.1109/TSA.2003.811538
   Casey M, 2008, IEEE T AUDIO SPEECH, V16, P1015, DOI 10.1109/TASL.2008.925883
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Chiyuan Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6984, DOI 10.1109/ICASSP.2014.6854954
   Collins Nick., 2010, Proceedings of the 11th International Conference on Music Information Retrieval (ISMIR), P177
   Dalvi N. N., 2004, P 10 ACM SIGKDD INT, P99, DOI DOI 10.1145/1014052.1014066
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Dieleman S., 2011, 12th International Society for Music Information Retrieval Conference (ISMIR-2011), P669
   Dixon S., 2004, P INT C MUS INF RETR, P509, DOI DOI 10.5281/ZENODO.1416220
   Ewert S, 2014, IEEE SIGNAL PROC MAG, V31, P116, DOI 10.1109/MSP.2013.2296076
   Flexer A., 2010, ISMIR 2010, P171
   Flexer A., 2007, P 8 INT C MUS INF RE, P341
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Griffith NiallPeter M. Todd., 1999, Musical Networks: Parallel Distributed Perception and Performance
   Gu Shixiang., 2014, CoRR
   Hamel P., 2010, ISMIR, P339
   Hastie T., 2009, The Elements of Statistical Learning
   Henaff Mikael., 2011, INT SOC MUSIC INFORM, P681
   Humphrey Eric J., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6974, DOI 10.1109/ICASSP.2014.6854952
   Humphrey EJ, 2013, J INTELL INF SYST, V41, P461, DOI 10.1007/s10844-013-0248-5
   Jr Silla., 2008, Information Society for Music Information Retrieval, P451
   Lee HT, 2009, ACM T WEB, V3, DOI 10.1145/1541822.1541823
   Li TLH, 2010, LECT NOTES ENG COMP, P546
   Matityaho B., 1995, P CONV EL EL ENG ISR, P1, DOI DOI 10.1109/EEIS.1995.514161
   Pampalk E., 2005, Proceedings of the International Conference on Music Information Retrieval, P628
   Pikrakis A., 2013, P INT WORKSH MACH LE, P1
   Schedl M, 2013, J INTELL INF SYST, V41, P523, DOI 10.1007/s10844-013-0247-6
   Schwarz D, 2006, J NEW MUSIC RES, V35, P3, DOI 10.1080/09298210600696857
   Sigtia Siddharth, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6959, DOI 10.1109/ICASSP.2014.6854949
   Sturm Bob L., 2015, Mathematics and Computation in Music. 5th International Conference, MCM 2015. Proceedings: LNCS 9110, P335, DOI 10.1007/978-3-319-20603-5_34
   Sturm B. L., 2014, P INT WORKSH COGN IN, P1
   Sturm B. L., P ACM COMP IN PRESS
   Sturm B.L., 2012, P 2 INT ACM WORKSHOP, V2012, P7, DOI 10.1145/2390848.2390851
   Sturm BL, 2014, LECT NOTES COMPUT SC, V8382, P29, DOI 10.1007/978-3-319-12093-5_2
   Sturm BL, 2014, LECT NOTES COMPUT SC, V8905, P89, DOI 10.1007/978-3-319-12976-1_6
   Sturm BL, 2014, J NEW MUSIC RES, V43, P147, DOI 10.1080/09298215.2014.894533
   Sturm BL, 2013, J INTELL INF SYST, V41, P371, DOI 10.1007/s10844-013-0250-y
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Urbano J, 2013, J INTELL INF SYST, V41, P345, DOI 10.1007/s10844-013-0249-4
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Vempala N., 2012, P 9 INT S COMP MUS M, P336
   Wang A., 2003, P 4 INT SOC MUSIC IN, P7, DOI DOI 10.1109/IITAW.2009.110
   Weninger Felix, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5412, DOI 10.1109/ICASSP.2014.6854637
   Whitman B, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P559, DOI 10.1109/NNSP.2001.943160
   Wiggins GA, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P477, DOI 10.1109/ISM.2009.36
   Yang XH, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2444
   Yang YH, 2011, MULTIMEDIA COMPUT CO, P1
NR 65
TC 62
Z9 71
U1 1
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2015
VL 17
IS 11
SI SI
BP 2059
EP 2071
DI 10.1109/TMM.2015.2478068
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CV2QV
UT WOS:000364102400018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pang, L
   Zhu, SA
   Ngo, CW
AF Pang, Lei
   Zhu, Shiai
   Ngo, Chong-Wah
TI Deep Multimodal Learning for Affective Analysis and Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cross-modal retrieval; deep Boltzmann machine; emotion analysis;
   multimodal learning
AB Social media has been a convenient platform for voicing opinions through posting messages, ranging from tweeting a short text to uploading a media file, or any combination of messages. Understanding the perceived emotions inherently underlying these user-generated contents (UGC) could bring light to emerging applications such as advertising and media analytics. Existing research efforts on affective computation are mostly dedicated to single media, either text captions or visual content. Few attempts for combined analysis of multiple media are made, despite that emotion can be viewed as an expression of multimodal experience. In this paper, we explore the learning of highly non-linear relationships that exist among low-level features across different modalities for emotion prediction. Using the deep Bolzmann machine (DBM), a joint density model over the space of multimodal inputs, including visual, auditory, and textual modalities, is developed. The model is trained directly using UGC data without any labeling efforts. While the model learns a joint representation over multimodal inputs, training samples in absence of certain modalities can also be leveraged. More importantly, the joint representation enables emotion-oriented cross-modal retrieval, for example, retrieval of videos using the text query "crazy cat". The model does not restrict the types of input and output, and hence, in principle, emotion prediction and retrieval on any combinations of media are feasible. Extensive experiments on web videos and images show that the learnt joint representation could be very compact and be complementary to hand-crafted features, leading to performance improvement in both emotion classification and cross-modal retrieval.
C1 [Pang, Lei; Ngo, Chong-Wah] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Zhu, Shiai] Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Commun Res Lab MCRLab, Ottawa, ON K1N 6N5, Canada.
C3 City University of Hong Kong; University of Ottawa
RP Pang, L (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM leipang3-c@my.cityu.edu.hk; zshiai@gmail.com; cwngo@cs.cityu.edu.hk
OI Ngo, Chong Wah/0000-0003-4182-8261
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [CityU 11210514, CityU 120213]; National Hi-Tech Research and
   Development Program (863 Program) of China [2014AA015102]
FX This work was supported in part by the Research Grants Council of the
   Hong Kong Special Administrative Region, China, under Grant CityU
   11210514 and Grant CityU 120213, and by the National Hi-Tech Research
   and Development Program (863 Program) of China under Grant 2014AA015102.
   The guest editor coordinating the review of this manuscript and
   approving it for publication was Dr. Jiebo Luo.
CR [Anonymous], 2010, P INT C NEUR INF PRO
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], 2011, P ICML
   [Anonymous], 2010, P NIPS
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2012, NEURAL NETWORKS TRIC
   Baveye Y, 2013, INT CONF AFFECT, P13, DOI 10.1109/ACII.2013.9
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bergstra J, 2006, MACH LEARN, V65, P473, DOI 10.1007/s10994-006-9019-7
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Bravo-Marquez F, 2013, P 2 INT WORKSH ISS S, DOI [10.1145/2502069.2502071, DOI 10.1145/2502069.2502071]
   Chen T., 2014, CoRR, Vabs/1403.2111
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Goodfellow I., 2009, ADV NEURAL INFORM PR, P646, DOI DOI 10.5555/2984093.2984166
   Hamel P., 2010, ISMIR, P339
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jiang YG, 2014, AAAI CONF ARTIF INTE, P73
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Jou B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P213, DOI 10.1145/2647868.2656408
   Kouloumpis E., 2011, TWITTER SENTIMENT AN, P538
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mathieu B., 2010, P 11 INT C MUS INF R, P441
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Saif H., 2012, CEUR WORKSHOP P, P2
   Salakhutdinov R., 2009, AISTATS
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Tieleman T., 2008, P 25 INT C MACHINE L, V307, P1064, DOI 10.1145/1390156
   Tieleman T., 2009, P 26 ANN INT C MACH, P1033
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Xu M, 2013, SIGNAL PROCESS, V93, P2140, DOI 10.1016/j.sigpro.2012.06.026
   Yang YH, 2011, IEEE T AUDIO SPEECH, V19, P762, DOI 10.1109/TASL.2010.2064164
   Yang YH, 2009, IEEE T CIRC SYST VID, V19, P1880, DOI 10.1109/TCSVT.2009.2026978
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 42
TC 103
Z9 106
U1 3
U2 91
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2015
VL 17
IS 11
SI SI
BP 2008
EP 2020
DI 10.1109/TMM.2015.2482228
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CV2QV
UT WOS:000364102400014
OA Green Published
DA 2024-07-18
ER

PT J
AU Guo, JM
   Prasetyo, H
   Wang, NJ
AF Guo, Jing-Ming
   Prasetyo, Heri
   Wang, Nai-Jian
TI Effective Image Retrieval System Using Dot-Diffused Block Truncation
   Coding Features
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Dot-diffused block truncation coding (DDBTC); feature descriptor; image
   classification; image retrieval
ID COLOR; TEXTURE; WAVELET; CLASSIFICATION; SIMILARITY; DESCRIPTOR;
   HISTOGRAM; PATTERNS
AB This paper presents a new approach to derive the image feature descriptor from the dot-diffused block truncation coding (DDBTC) compressed data stream. The image feature descriptor is simply constructed from two DDBTC representative color quantizers and its corresponding bitmap image. The color histogram feature (CHF) derived from two color quantizers represents the color distribution and image contrast, while the bit pattern feature (BPF) constructed from the bitmap image characterizes the image edges and textural information. The similarity between two images can be easily measured from their CHF and BPF values using a specific distance metric computation. Experimental results demonstrate the superiority of the proposed feature descriptor compared to the former existing schemes in image retrieval task under natural and textural images. The DDBTC method compresses an image efficiently, and at the same time, its corresponding compressed data stream can provide an effective feature descriptor for performing image retrieval and classification. Consequently, the proposed scheme can be considered as an effective candidate for real-time image retrieval applications.
C1 [Guo, Jing-Ming; Prasetyo, Heri; Wang, Nai-Jian] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
C3 National Taiwan University of Science & Technology
RP Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
EM jmguo@seed.net.tw; heri_inf_its_02@yahoo.co.id; njwang@mail.ntust.edu.tw
RI Prasetyo, Heri/AAD-2388-2022
OI Prasetyo, Heri/0000-0002-1257-4832
CR [Anonymous], ELECT LETT
   [Anonymous], COR PHOT COLL COL IM
   [Anonymous], 2010, SIAM SDM
   [Anonymous], P 10 EUR C COMP VIS
   [Anonymous], [No title captured]
   [Anonymous], 2009, INT J COMPUTER SCI I
   [Anonymous], 2006, J INF TECHNOL APPL, DOI DOI 10.1109/TMM.20082001357
   [Anonymous], MIT MED LAB VISMOD G
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Backes AR, 2012, PATTERN RECOGN, V45, P1984, DOI 10.1016/j.patcog.2011.11.009
   Bianconi F, 2009, PATTERN RECOGN LETT, V30, P765, DOI 10.1016/j.patrec.2009.02.006
   Bouachir W., 2009, Proceedings of the 2009 Fifth International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2009), P215, DOI 10.1109/SITIS.2009.43
   Brodatz P., 1996, TEXTURES PHOTOGRAPHI
   Burghouts GJ, 2009, PATTERN RECOGN LETT, V30, P306, DOI 10.1016/j.patrec.2008.10.005
   CHEN CC, 1989, IEEE T MED IMAGING, V8, P133, DOI 10.1109/42.24861
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen X., 2009, P INT C ADV KNOWL DI, P27
   Sa JJD, 2014, IEEE T IMAGE PROCESS, V23, P3751, DOI 10.1109/TIP.2014.2333655
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Distasi R, 2003, IEEE T IMAGE PROCESS, V12, P373, DOI 10.1109/TIP.2003.811041
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Elsayad I., 2010, P INT C CONT BAS MUL, P1
   Fränti P, 1999, SIGNAL PROCESS-IMAGE, V14, P677, DOI 10.1016/S0923-5965(98)00037-X
   Gahroudi M. R., 2007, PROC INT S SIGNAL PR, P1
   Guha T, 2014, IEEE T MULTIMEDIA, V16, P980, DOI 10.1109/TMM.2014.2306175
   Guo JM, 2014, IEEE T IMAGE PROCESS, V23, P1269, DOI 10.1109/TIP.2013.2257812
   Guo JM, 2010, DIGIT SIGNAL PROCESS, V20, P97, DOI 10.1016/j.dsp.2009.04.007
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hoang MA, 2005, SIGNAL PROCESS, V85, P265, DOI 10.1016/j.sigpro.2004.10.009
   Huang CS, 1997, IEEE SIGNAL PROC LET, V4, P328, DOI 10.1109/97.650036
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Lasfar A, 2000, INT C PATT RECOG, P1031, DOI 10.1109/ICPR.2000.905647
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin CH, 2011, EXPERT SYST APPL, V38, P11412, DOI 10.1016/j.eswa.2011.03.014
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1606, DOI 10.1109/TIP.2014.2305072
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Lu ZM, 2005, ELECTRON LETT, V41, P956, DOI 10.1049/el:20052176
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Moghaddam HA, 2006, INT C PATT RECOG, P925
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2001, PATTERN RECOGN, V34, P727, DOI 10.1016/S0031-3203(00)00010-8
   Paschos G, 2003, PATTERN RECOGN LETT, V24, P309, DOI 10.1016/S0167-8655(02)00244-1
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   Pi M, 2008, IET IMAGE PROCESS, V2, P218, DOI 10.1049/iet-ipr:20070055
   Pi MG, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P585
   Pi MH, 2005, IEEE T MULTIMEDIA, V7, P597, DOI 10.1109/TMM.2005.846796
   Porebski A., 2008, PROC 1 WORKSHOPS IMA, P1
   Poursistani P, 2013, MATH COMPUT MODEL, V57, P1005, DOI 10.1016/j.mcm.2011.11.064
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P93, DOI 10.1109/TIP.2002.807356
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Schouten BAM, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P534, DOI 10.1109/ICIP.2000.899474
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Subrahmanyam M, 2012, EXPERT SYST APPL, V39, P5104, DOI 10.1016/j.eswa.2011.11.029
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   UDPIKAR VR, 1987, IEEE T COMMUN, V35, P352, DOI 10.1109/TCOM.1987.1096773
   Usc-Sipi, 1977, USC SIPI IMAGE DATAB
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wu YG, 1998, IEEE T CONSUM ELECTR, V44, P317
   WU YY, 1991, IEEE T COMMUN, V39, P1283, DOI 10.1109/26.99132
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Zhang AD, 1995, P SOC PHOTO-OPT INS, V2606, P338, DOI 10.1117/12.227256
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3604, DOI 10.1109/TIP.2014.2329182
   Zhu L, 2014, IET IMAGE PROCESS, V8, P509, DOI 10.1049/iet-ipr.2013.0375
NR 83
TC 38
Z9 38
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2015
VL 17
IS 9
SI SI
BP 1576
EP 1590
DI 10.1109/TMM.2015.2449234
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CP0RN
UT WOS:000359583000017
DA 2024-07-18
ER

PT J
AU Xie, LX
   Wang, JD
   Zhang, B
   Tian, Q
AF Xie, Lingxi
   Wang, Jingdong
   Zhang, Bo
   Tian, Qi
TI Fine-Grained Image Search
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Applications; evaluation; fine-grained image search; problem
   formulation; semantic indexing
ID SCALE; RETRIEVAL; REPRESENTATION; CONSISTENCY; GEOMETRY
AB Large-scale image search has been attracting lots of attention from both academic and commercial fields. The conventional bag-of-visual-words (BoVW) model with inverted index is verified efficient at retrieving near-duplicate images, but it is less capable of discovering fine-grained concepts in the query and returning semantically matched search results. In this paper, we suggest that instance search should return not only near-duplicate images, but also fine-grained results, which is usually the actual intention of a user. We propose a new and interesting problem named fine-grained image search, which means that we prefer those images containing the same fine-grained concept with the query. We formulate the problem by constructing a hierarchical database and defining an evaluation method. We thereafter introduce a baseline system using fine-grained classification scores to represent and co-index images so that the semantic attributes are better incorporated in the online querying stage. Large-scale experiments reveal that promising search results are achieved with reasonable time and memory consumption. We hope this paper will be the foundation for future work on image search. We also expect more follow-up efforts along this research topic and look forward to commercial fine-grained image search engines.
C1 [Xie, Lingxi; Zhang, Bo] Tsinghua Natl Lab Informat Sci & Technol TNList, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.
   [Xie, Lingxi; Zhang, Bo] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Wang, Jingdong] Microsoft Res, Beijing 100080, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Tsinghua University; Tsinghua University; Microsoft; University of Texas
   System; University of Texas at San Antonio (UTSA)
RP Xie, LX (corresponding author), Tsinghua Natl Lab Informat Sci & Technol TNList, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.
EM 198808xc@gmail.com; jingdw@microsoft.com; dcszb@mail.tsinghua.edu.cn;
   qitian@cs.utsa.edu
RI Wang, Jingdong/E-9920-2017; Xie, Lingxi/ABF-6996-2020
OI Wang, Jingdong/0000-0002-4888-4445; 
FU National Basic Research Program (973 Program) of China [2013CB329403,
   2012CB316301, 2014CB347600]; National Natural Science Foundation of
   China [61332007, 61273023, 61429201]; Tsinghua University Initiative
   Scientific Research Program [20121088071]; NEC Laboratories of America
   Faculty Research Awards under ARO [W911NF-12-1-0057]
FX Manuscript received August 13, 2014; revised December 07, 2014; accepted
   February 18, 2015. Date of publication March 04, 2015; date of current
   version April 15, 2015. This work was supported by the National Basic
   Research Program (973 Program) of China under Grant 2013CB329403, Grant
   2012CB316301, and Grant 2014CB347600, by the National Natural Science
   Foundation of China under Grant 61332007, Grant 61273023, and Grant
   61429201, and by the Tsinghua University Initiative Scientific Research
   Program under Grant 20121088071. The work of Q. Tian was supported in
   part by the NEC Laboratories of America Faculty Research Awards under
   ARO Grant W911NF-12-1-0057. The associate editor coordinating the review
   of this manuscript and approving it for publication was Dr. Vasileios
   Mezaris.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], 2012, P 20 ACM MULTIMEDIA
   [Anonymous], 2013, CORR
   [Anonymous], 2013, P 26 ANN C LEARN THE
   [Anonymous], 2011, TECH REP CNS T 2011
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2011, P 19 ACM INT C MULT, DOI DOI 10.1145/2072298.2072365
   [Anonymous], 1998, WORDNET
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Chang SF, 1997, COMMUN ACM, V40, P63, DOI 10.1145/265563.265573
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595
   Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fellbaum C., 2005, Encyclopedia of language and linguistics
   Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Hyvonen E., 2003, 200203 HELS I INF TE
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   Jiang YN, 2012, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2012.6248042
   Jing YS, 2013, IEEE T MULTIMEDIA, V15, P2022, DOI 10.1109/TMM.2013.2279663
   Khosla A., 2011, CVPR
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1606, DOI 10.1109/TIP.2014.2305072
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu YJ, 2010, IEEE T MULTIMEDIA, V12, P288, DOI 10.1109/TMM.2010.2046292
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mezaris V, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P511
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Miller George, 1998, WORDNET ELECT LEXICA
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Nister David, 2006, CVPR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Philbin J., 2008, P CVPR, P1
   Romberg S., 2011, P 1 ACM INT C MULT R, P1
   Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   STANCHEV P, 2003, INT J INFORM THEORIE, V10, P283
   Tian Q, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1019, DOI 10.1109/ICME.2004.1394376
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang JD, 2014, IEEE T PATTERN ANAL, V36, P388, DOI 10.1109/TPAMI.2013.125
   Wang JQ, 2012, PROCEEDINGS OF THE 8TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, MICE, HOSPITALITY MANAGEMENT AND EDUCATION SESSION, PT III, P179
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Xie HT, 2011, IEEE T MULTIMEDIA, V13, P1319, DOI 10.1109/TMM.2011.2167224
   Xie L., 2015, P INT C AC SPEECH SI
   Xie LX, 2014, IEEE IMAGE PROC, P5716, DOI 10.1109/ICIP.2014.7026156
   Xie LX, 2014, PROC CVPR IEEE, P3734, DOI 10.1109/CVPR.2014.477
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Xie LX, 2013, IEEE IMAGE PROC, P2607, DOI 10.1109/ICIP.2013.6738537
   Xie LX, 2014, COMPUT VIS IMAGE UND, V124, P31, DOI 10.1016/j.cviu.2013.12.011
   Xie LX, 2014, IEEE T IMAGE PROCESS, V23, P1994, DOI 10.1109/TIP.2014.2310117
   Yang LJ, 2012, IEEE T MULTIMEDIA, V14, P871, DOI 10.1109/TMM.2012.2187778
   Yang S., 2012, Advances in Neural Information Processing Systems, P3122
   Yu FX, 2012, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2012.6248023
   Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3604, DOI 10.1109/TIP.2014.2329182
   Zhou WG, 2014, IEEE T MULTIMEDIA, V16, P601, DOI 10.1109/TMM.2014.2301979
NR 80
TC 56
Z9 65
U1 0
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2015
VL 17
IS 5
BP 636
EP 647
DI 10.1109/TMM.2015.2408566
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CG3AH
UT WOS:000353148300006
DA 2024-07-18
ER

PT J
AU Chu, WT
   Yu, CH
   Wang, HH
AF Chu, Wei-Ta
   Yu, Chia-Hsiang
   Wang, Hsin-Han
TI Optimized Comics-Based Storytelling for Temporal Image Sequences
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Comics-based storytelling; genetic algorithm; layout selection; page
   allocation; particle swarm optimization; speech balloon placement
ID VIDEO; VISUALIZATION; SYSTEM; LAYOUT
AB We propose a system to transform any temporal image sequence into a comics-based presentation, as an effective and interesting storytelling manner. Three main components, including page allocation, layout selection, and speech balloon placement, are respectively formulated as optimization problems, and systematic approaches are proposed to find solutions. Page allocation is viewed as a labeling problem, and the best solution is determined by the genetic algorithm. Importance values of images and predefined layouts are both represented in vector forms, and the best layout is selected by finding the best match between vectors. Feasible solutions of speech balloons constitute a solution space, and the best solution that jointly describes the best locations of all balloons in a page is determined by the particle swarm optimization algorithm. Objective evaluation and subjective evaluation are designed from various perspectives to demonstrate effectiveness and superiority of the proposed system.
C1 [Chu, Wei-Ta; Yu, Chia-Hsiang; Wang, Hsin-Han] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Min Hsiung 62102, Taiwan.
C3 National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Min Hsiung 62102, Taiwan.
EM wtchu@cs.ccu.edu.tw; xneonvisionx@hotmail.com; xinghan177@gmail.com
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
FU Ministry of Science and Technology in Taiwan [NSC101-2221-E-194-055-MY2,
   MOST103-2221-E-194-027-MY3]
FX This work was supported in part by the Ministry of Science and
   Technology in Taiwan under Grant NSC101-2221-E-194-055-MY2 and and Grant
   MOST103-2221-E-194-027-MY3. The associate editor coordinating the review
   of this manuscript and approving it for publication was Dr. Vasileios
   Mezaris.
CR [Anonymous], 2006, INT WORKSH MULT INF
   [Anonymous], 2010, P 18 ACM INT C MULTI, DOI [DOI 10.1145/1873951.1874033, 10.1145/1873951.1874033]
   [Anonymous], 2013, INTRO OPTIMIZATION
   Austin Michael., 2011, USEFUL FICTIONS EVOL
   Balabanovic M., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P564, DOI 10.1145/332040.332505
   Brabrand G. B., 2008, THESIS GJOVIK U COLL
   Calic J, 2007, IEEE T CIRC SYST VID, V17, P931, DOI 10.1109/TCSVT.2007.897466
   Cao Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366160
   Chan C., 2009, PROCEEDING ACM CHI 2, P3589
   Chen Jun-Cheng, 2006, P 14 ACM INT C MULTI, P25
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chu W.-T., 2013, PROC INT WORKSHOP IN, P1
   Chu Wei-Ta, 2012, P 2 ACM INT WORKSH I, P3, DOI [10.1145/2390821.2390825, DOI 10.1145/2390821.2390825]
   Chun BK, 2006, LECT NOTES COMPUT SC, V4292, P576
   Girgensohn A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P77
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Herranz Luis, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P464, DOI 10.1007/978-3-642-34778-8_43
   Herranz L, 2012, IEEE T MULTIMEDIA, V14, P1290, DOI 10.1109/TMM.2012.2192917
   Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Millidge G. S., 2009, COMIC BOOK DESIGN ES
   Myodo Emi, 2011, P 19 ACM INT C MULT, P795, DOI [10.1145/2072298.2072461, DOI 10.1145/2072298.2072461]
   Platt JC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P6
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Ricketts J. H., 1997, THESIS ROYAL MELBOUR
   Sawada T., 2013, INT C MULT MOD, P467
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Tobita H., 2010, CHI 2010, P3751
   Tobita Hiroaki, 2010, P INT C ADV VIS INT, P281, DOI [10.1145/1842993.1843043, DOI 10.1145/1842993.1843043]
   Toyoura M, 2012, LECT NOTES COMPUT SC, V7131, P406
   Troiano Luigi, 2009, Proceedings of the 11th International Conference on Enterprise Information Systems. HCI, P118
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Vinciarelli Alessandro., 2007, Proceedings of the 15th international conference on Multimedia, MULTIMEDIA '07, P261, DOI DOI 10.1145/1291233.1291287
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P858, DOI 10.1109/TMM.2012.2187181
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Wang Y, 2010, LECT NOTES COMPUT SC, V5916, P793, DOI 10.1007/978-3-642-11301-7_90
   Wen MH, 2012, CONF TECHNOL APPL, P314, DOI 10.1109/TAAI.2012.28
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
NR 41
TC 13
Z9 16
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2015
VL 17
IS 2
BP 201
EP 215
DI 10.1109/TMM.2014.2383616
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AZ4RN
UT WOS:000348210500005
DA 2024-07-18
ER

PT J
AU Motahari, A
   Adjouadi, M
AF Motahari, Amin
   Adjouadi, Malek
TI Barcode Modulation Method for Data Transmission in Mobile Devices
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Barcode; data transfer; differential phase shift keying; orthogonal
   frequency-division multiplexing (OFDM) modulation
ID OFDM; COMMUNICATION; SYSTEMS
AB The concept of 2-D barcodes is of great relevance for use in wireless data transmission between handheld electronic devices. In a typical setup, any file on a cell phone, for example, can be transferred to a second cell phone through a series of images on the LCD which are then captured and decoded through the camera of the second cell phone. In this study, a new approach for data modulation in 2-D barcodes is introduced, and its performance is evaluated in comparison to other standard methods of barcode modulation. In this new approach, orthogonal frequency-division multiplexing (OFDM) modulation is used together with differential phase shift keying (DPSK) over adjacent frequency domain elements. A specific aim of this study is to establish a system that is proven tolerant to camera movements, picture blur, and light leakage within neighboring pixels of an LCD.
C1 [Motahari, Amin; Adjouadi, Malek] Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA.
C3 State University System of Florida; Florida International University
RP Motahari, A (corresponding author), Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA.
EM motahari@ieee.org; adjouadi@fiu.edu
RI Adjouadi, Malek/AAV-2037-2021
OI Motahari, Amin/0000-0001-6314-3867; Adjouadi, Malek/0000-0001-5380-3155
FU National Science Foundation [CNS-0959985, HRD-0833093, CNS-1042341,
   IIP-1338922, IIP-1230661]; Ware Foundation; Florida International
   University Open Access Publishing Fund; Direct For Computer & Info Scie
   & Enginr; Division Of Computer and Network Systems [1042341] Funding
   Source: National Science Foundation; Division Of Computer and Network
   Systems; Direct For Computer & Info Scie & Enginr [0959985] Funding
   Source: National Science Foundation; Div Of Industrial Innovation &
   Partnersh; Directorate For Engineering [1237818] Funding Source:
   National Science Foundation
FX The work was supported by the National Science Foundation under Grant
   CNS-0959985, Grant HRD-0833093, Grant CNS-1042341, Grant IIP-1338922,
   and Grant IIP-1230661, and by the Ware Foundation. This work was
   supported in part by the Florida International University Open Access
   Publishing Fund. The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Ali C. Begen.
CR [Anonymous], 2012, 2012 14 INT C TRANSP
   [Anonymous], 2006, 180042006 ISOIEC
   Ashok A, 2014, INT CONF PERVAS COMP, P112, DOI 10.1109/PerCom.2014.6813951
   Belussi LFF, 2013, J MATH IMAGING VIS, V45, P277, DOI 10.1007/s10851-012-0355-x
   Bruckstein AM, 1998, IEEE T INFORM THEORY, V44, P3156, DOI 10.1109/18.737548
   Coleri S, 2002, IEEE T BROADCAST, V48, P223, DOI 10.1109/TBC.2002.804034
   Dimitrov S, 2012, IEEE T COMMUN, V60, P1072, DOI 10.1109/TCOMM.2012.022712.100493
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Kato H, 2007, TENCON IEEE REGION, P28
   Kato H, 2007, IEEE PERVAS COMPUT, V6, P76, DOI 10.1109/MPRV.2007.80
   Kuzdeba S, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P184, DOI 10.1109/CCNC.2013.6488444
   Lin JA, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/848276
   Liu Y, 2008, 2008 CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-11, P203, DOI 10.1109/CCDC.2008.4597299
   Maeda N, 2003, IEICE T COMMUN, VE86B, P300
   Memeti Jeton., 2013, PRAXIS INFORMATIONSV, V36, P31
   Mondal MRH, 2014, J LIGHTWAVE TECHNOL, V32, P922, DOI 10.1109/JLT.2013.2294647
   Mondal MRH, 2012, ASIA-PAC CONF COMMUN, P617, DOI 10.1109/APCC.2012.6388269
   Morelli M, 2001, IEEE T SIGNAL PROCES, V49, P3065, DOI 10.1109/78.969514
   Morrison R, 2001, IEEE VTS VEH TECHNOL, P664, DOI 10.1109/VTC.2001.956853
   Ochiai H, 2002, IEEE T COMMUN, V50, P89, DOI 10.1109/26.975762
   Pei CC, 2013, IEEE ICCE, P100, DOI 10.1109/ICCE.2013.6486812
   Perli SD, 2010, MOBICOM 10 & MOBIHOC 10: PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING AND THE 11TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P137
   Proakis J., 2008, Digital Communication, Vthird
   Sathananthan K, 2001, IEEE T COMMUN, V49, P1884, DOI 10.1109/26.966051
   SRIPAD AB, 1977, IEEE T ACOUST SPEECH, V25, P442, DOI 10.1109/TASSP.1977.1162977
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Tsonev D, 2013, J LIGHTWAVE TECHNOL, V31, P3064, DOI 10.1109/JLT.2013.2278675
   Woodland, 1952, U.S. Patent, Patent No. [US2612994, 2612994]
   Xu L, 2008, IEEE T MULTIMEDIA, V10, P361, DOI 10.1109/TMM.2008.917353
NR 29
TC 12
Z9 13
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JAN
PY 2015
VL 17
IS 1
BP 118
EP 127
DI 10.1109/TMM.2014.2366601
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AX6QW
UT WOS:000347047400011
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, C
   Liu, Z
   Chan, SC
AF Wang, Chong
   Liu, Zhong
   Chan, Shing-Chow
TI Superpixel-Based Hand Gesture Recognition With Kinect Depth Camera
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Hand gesture recognition; human-computer interaction; Kinect; superpixel
   earth mover's distance
ID MOTION; MODEL
AB This paper presents a new superpixel-based hand gesture recognition system based on a novel superpixel earth mover's distance metric, together with Kinect depth camera. The depth and skeleton information from Kinect are effectively utilized to produce markerless hand extraction. The hand shapes, corresponding textures and depths are represented in the form of superpixels, which effectively retain the overall shapes and color of the gestures to be recognized. Based on this representation, a novel distance metric, superpixel earth mover's distance (SP-EMD), is proposed to measure the dissimilarity between the hand gestures. This measurement is not only robust to distortion and articulation, but also invariant to scaling, translation and rotation with proper preprocessing. The effectiveness of the proposed distance metric and recognition algorithm are illustrated by extensive experiments with our own gesture dataset as well as two other public datasets. Simulation results show that the proposed system is able to achieve high mean accuracy and fast recognition speed. Its superiority is further demonstrated by comparisons with other conventional techniques and two real-life applications.
C1 [Wang, Chong; Liu, Zhong; Chan, Shing-Chow] Univ Hong Kong, Dept EEE, Pokfulam, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Wang, C (corresponding author), Univ Hong Kong, Dept EEE, Pokfulam, Hong Kong, Peoples R China.
EM cwang@eee.hku.hk; liuzhong@eee.hku.hk; scchan@eee.hku.hk
RI Wang, Chong/IRZ-7328-2023
OI Wang, Chong/0000-0001-6016-6545; Liu, Zhong/0000-0001-9650-6097
FU General Research Fund (GRF) of the Hong Kong Research Grant Council
   (RGC)
FX This work was supported in part by the General Research Fund (GRF) of
   the Hong Kong Research Grant Council (RGC). The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Enrico Magli.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], I SYMP CONSUM ELECTR
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Bai X, 2007, LECT NOTES COMPUT SC, V4679, P362
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chen MY, 2013, IEEE T MULTIMEDIA, V15, P561, DOI 10.1109/TMM.2012.2237024
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dardas N. H., 2011, PROC CIMSA, P1
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dejmal I, 2006, IEEE T BIO-MED ENG, V53, P2455, DOI 10.1109/TBME.2006.883795
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Heikkilä J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788
   Kaâniche MB, 2012, IEEE T PATTERN ANAL, V34, P2247, DOI 10.1109/TPAMI.2012.19
   Kölsch M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P614, DOI 10.1109/AFGR.2004.1301601
   Kry PG, 2006, ACM T GRAPHIC, V25, P872, DOI 10.1145/1141911.1141969
   Liang H, 2014, IEEE T MULTIMEDIA, V16, P1241, DOI 10.1109/TMM.2014.2306177
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Mihalcea Rada., 2012, Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis, WASSA'12, page, P1
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Stenger B, 2001, PROC CVPR IEEE, P310
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Suau X, 2012, IEEE T MULTIMEDIA, V14, P575, DOI 10.1109/TMM.2012.2189853
   Tang B, 2013, IEEE SYS MAN CYBERN, P1, DOI 10.1109/SMC.2013.8
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wang C, 2015, J SIGNAL PROCESS SYS, V79, P1, DOI [10.1007/s11265-013-0819-2, 10.1155/2013/390534]
   Wang LC, 2014, IEEE T MULTIMEDIA, V16, P751, DOI 10.1109/TMM.2014.2298382
   Wu Y, 2005, IEEE T PATTERN ANAL, V27, P1910, DOI 10.1109/TPAMI.2005.233
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
NR 34
TC 223
Z9 243
U1 2
U2 81
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JAN
PY 2015
VL 17
IS 1
BP 29
EP 39
DI 10.1109/TMM.2014.2374357
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AX6QW
UT WOS:000347047400004
DA 2024-07-18
ER

PT J
AU Sheikh, AM
   Fiandrotti, A
   Magli, E
AF Sheikh, Anooq Muzaffar
   Fiandrotti, Attilio
   Magli, Enrico
TI Distributed Scheduling for Low-Delay and Loss-Resilient Media Streaming
   With Network Coding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Distributed scheduling; media streaming; network coding; P2P
ID PUSH
AB Network coding (NC) has been shown to be very effective for collaborative media streaming applications. A pivotal issue in media streaming with NC lies in the packet scheduling policy at the network nodes, which affects the perceived media quality. In this paper, we address the problem of finding the packet scheduling policy that maximizes the number of media segments recovered in the network. We cast this as a distributed minimization problem and propose heuristic solutions that make the proposed framework robust to infrequent or inaccurate feedback information. Moreover, the proposed framework accounts for the properties of layered and multiple description encoded media to provide graceful quality degradation in case of packet losses or lack of upload bandwidth. Experimental results on a local testbed as well as PlanetLab suggest that our scheduling framework achieves better media quality, lower playback delay, and lower bandwidth consumption than a random-push scheme.
C1 [Sheikh, Anooq Muzaffar; Fiandrotti, Attilio; Magli, Enrico] Politecn Torino, Dept Elect & Telecommun, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Sheikh, AM (corresponding author), Politecn Torino, Dept Elect & Telecommun, I-10129 Turin, Italy.
EM anooq.sheikh@polito.it; attilio.fiandrotti@polito.it;
   enrico.magli@polito.it
OI Fiandrotti, Attilio/0000-0002-9991-6822
FU PRIN ARACNE - Italian Ministry of Education and Research; COAST-ICT
   STREP; European Union
FX This work was supported in part by PRIN ARACNE, a research project
   funded by the Italian Ministry of Education and Research and COAST-ICT
   STREP, a research project funded by the European Union. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Prof. Liang Zhou.
CR Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   Annapureddy S., 2007, Proc. Int'l WWW Conference, P903
   [Anonymous], P 43 ANN ALL C COMM
   Chan KHK, 2010, IEEE T MULTIMEDIA, V12, P743, DOI 10.1109/TMM.2010.2053524
   Chou P.A., 2003, Proc. Annual Allerton Conference on Communication control and Computing, V41, P40
   Chun B, 2003, ACM SIGCOMM COMP COM, V33, P3, DOI 10.1145/956993.956995
   Cleju N, 2011, IEEE T MULTIMEDIA, V13, P1103, DOI 10.1109/TMM.2011.2161448
   Cui LZ, 2012, IEEE ICC, P2075, DOI 10.1109/ICC.2012.6364294
   Feng C., 2008, Proceedings of the 16th ACM international conference on Multimedia, P269
   Fiandrotti A, 2014, IEEE T MULTIMEDIA, V16, P521, DOI 10.1109/TMM.2013.2285518
   Fiandrotti A, 2012, EUR SIGNAL PR CONF, P1529
   Fragouli C, 2006, ACM SIGCOMM COMP COM, V36, P63, DOI 10.1145/1111322.1111337
   Liu Zhong-Hua, 2011, International Journal of Neuropsychopharmacology, V14, P618, DOI 10.1017/S1461145710000520
   Magli E, 2013, IEEE T MULTIMEDIA, V15, P1195, DOI 10.1109/TMM.2013.2241415
   Nguyen AT., 2010, IEEE INFOCOM'10, San Diego, CA, USA, P1
   Nguyen K, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P396
   Papadopoulos I, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P3578, DOI 10.1109/PIMRC.2013.6666770
   Ramasubramonian A. K., P SPIE, V7882
   Ramasubramonian A. K., P SPIE, V7257
   Sanna M., 2013, 20 INT PACK VID WORK, P1
   Sheikh AM, 2013, INT CONF ACOUST SPEE, P3597, DOI 10.1109/ICASSP.2013.6638328
   Thomos N., 2007, Proc. the international workshop on mobile video, New York, NY, P19
   Thomos N, 2011, IEEE T MULTIMEDIA, V13, P776, DOI 10.1109/TMM.2011.2111364
   Thomos N, 2010, IEEE T CIRC SYST VID, V20, P1834, DOI 10.1109/TCSVT.2010.2087830
   Thomos N, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P497, DOI 10.1109/ICME.2008.4607480
   Toldo M., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P400, DOI 10.1109/MMSP.2010.5662054
   Toni L, 2013, IEEE INT WORKSH MULT, P446, DOI 10.1109/MMSP.2013.6659330
   Wang M, 2007, IEEE J SEL AREA COMM, V25, P1655, DOI 10.1109/JSAC.2007.071205
   Wang M, 2007, IEEE INFOCOM SER, P1082, DOI 10.1109/INFCOM.2007.130
   Wang M, 2007, IEEE T MULTIMEDIA, V9, P1554, DOI 10.1109/TMM.2007.907460
   Yu LJ, 2009, IEEE T CONSUM ELECTR, V55, P576, DOI 10.1109/TCE.2009.5174425
   Zhao J, 2006, IEEE T MULTIMEDIA, V8, P1021, DOI 10.1109/TMM.2006.879847
NR 32
TC 15
Z9 15
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2014
VL 16
IS 8
BP 2294
EP 2306
DI 10.1109/TMM.2014.2357716
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AU4HL
UT WOS:000345571300018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, X
   Su, L
   Qi, HG
   Huang, QM
   Li, GR
AF Wang, Xi
   Su, Li
   Qi, Honggang
   Huang, Qingming
   Li, Guorong
TI Face Distortion Recovery Based on Online Learning Database for
   Conversational Video
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Conversational video coding; face alignment; face distortion recovery;
   online learning
AB With the real-time requirement for video conversation, the coding system needs to adopt low delay and low complexity strategy to encode conversational videos, which may result in a significant decline of the video quality under the constrained bandwidth of network. In conversational videos, the face region attracts most human attentions. Therefore, recovering the distortion of face region will effectively improve the visual quality of conversational video. Actually, the participants in a conversation are usually unchanged in a relative long period, and similar facial expressions of the participants would be often repetitive. However, conventional video coding methods just consider the correlation of several neighboring frames while the long-range correlation of similar face regions in the whole conversational video has not been fully used. In this paper, we propose a face distortion recovery system to improve the visual quality of decoded conversational video by online learning an own face feature database for each user. First, at the sender side, the face feature database is established and online updated to include different facial expressions of the person. Then, at the receiver side, the low quality face regions in decoded video are recovered with the face patches in the database. Experimental results show that, under low bits rates the proposed method achieves average 5.22 dB gain with small burden to update the database.
C1 [Wang, Xi; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Wang, Xi; Su, Li; Qi, Honggang; Huang, Qingming; Li, Guorong] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Wang, X (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM xi.wang@vipl.ict.ac.cn; suli@ucas.ac.cn; hgqi@ucas.ac.cn;
   qmhuang@ucas.ac.cn; liguorong@ucas.ac.cn
RI 丽, 苏/JVO-8581-2024; Li, Guorong/C-3806-2015
FU National Basic Research Program of China (973 Program) [2012CB316400];
   National Natural Science Foundation of China [61025011, 61332016,
   61303153, 61472388, 61472389]; China Postdoctoral Science Foundation
   [2014T70111]
FX This work was supported in part by the National Basic Research Program
   of China (973 Program) under Grant 2012CB316400, the National Natural
   Science Foundation of China under Grants 61025011, 61332016, 61303153,
   61472388, and 61472389, and the China Postdoctoral Science Foundation
   under Grant 2014T70111. The associate editor coordinating the review of
   this manuscript and approving it for publication was Prof. Enrico Magli.
CR [Anonymous], P INT C MACH LEARN
   Boccignone G, 2008, IEEE T CIRC SYST VID, V18, P1727, DOI 10.1109/TCSVT.2008.2005798
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Li F., 2011, P INT WIR COMM MOB C, P2033
   Liu HR, 2013, IEEE T PATTERN ANAL, V35, P2131, DOI 10.1109/TPAMI.2013.16
   Liu HY, 2013, IEEE I CONF COMP VIS, P3232, DOI 10.1109/ICCV.2013.401
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wang J, 2005, IEEE DATA COMPR CONF, P309
   Wang X, 2013, IEEE DATA COMPR CONF, P526, DOI 10.1109/DCC.2013.105
   Xiong B, 2011, IEEE T CIRC SYST VID, V21, P917, DOI 10.1109/TCSVT.2011.2133530
   Yu HB, 2004, IEEE T CONSUM ELECTR, V50, P329, DOI 10.1109/TCE.2004.1277881
NR 15
TC 2
Z9 2
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2014
VL 16
IS 8
BP 2130
EP 2140
DI 10.1109/TMM.2014.2355134
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AU4HL
UT WOS:000345571300005
DA 2024-07-18
ER

PT J
AU Han, YH
   Wei, XX
   Cao, XC
   Yang, Y
   Zhou, XF
AF Han, Yahong
   Wei, Xingxing
   Cao, Xiaochun
   Yang, Yi
   Zhou, Xiaofang
TI Augmenting Image Descriptions Using Structured Prediction Output
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image descriptions; image annotation; structured learning;
   tree-structured semantic unit
ID RETRIEVAL
AB The need for richer descriptions of images arises in a wide spectrum of applications ranging from image understanding to image retrieval. While the Automatic Image Annotation (AIA) has been extensively studied, image descriptions with the output labels lack sufficient information. This paper proposes to augment image descriptions using structured prediction output. We define a hierarchical tree-structured semantic unit to describe images, from which we can obtain not only the class and subclass one image belongs to, but also the attributes one image has. After defining a new feature map function of structured SVM, we decompose the loss function into every node of the hierarchical tree-structured semantic unit and then predict the tree-structured semantic unit for testing images. In the experiments, we evaluate the performance of the proposed method on two open benchmark datasets and compare with the state-of-the-art methods. Experimental results show the better prediction performance of the proposed method and demonstrate the strength of augmenting image descriptions.
C1 [Han, Yahong; Wei, Xingxing] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Han, Yahong] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
   [Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Yang, Yi; Zhou, Xiaofang] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
C3 Tianjin University; Tianjin University; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS; University of Queensland
RP Han, YH (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM yahong@tju.edu.cn; xwei@tju.edu.cn; caoxiaochun@iie.ac.cn;
   yee.i.yang@gmail.com; zxf@itee.uq.edu.au
RI Zhou, Xiaofang/C-6169-2013; yang, yang/GVT-5210-2022; Yang,
   Yi/B-9273-2017; Lang, Ming/HIK-0758-2022; yang, yang/GWB-9426-2022;
   Zhou, Xiangfeng/KDO-8724-2024; yang, yang/HGT-7999-2022
OI Zhou, Xiaofang/0000-0001-6343-1455; Yang, Yi/0000-0002-0512-880X; 
FU National Program on Key Basic Research Project (973 Program)
   [2013CB329301]; NSFC [61202166, 61332012]; Ministry of Education of
   China [20120032120042]; Chinese Academy of Sciences; ARC DECRA
   [DE130101311]; Australian Research Council [DE130101311] Funding Source:
   Australian Research Council
FX This work was supported in part by the National Program on Key Basic
   Research Project (973 Program) under Grant 2013CB329301, the NSFC under
   Grants 61202166 and 61332012, the Doctoral Fund of Ministry of Education
   of China under Grant 20120032120042, and the 100 Talents Programme of
   the Chinese Academy of Sciences. The work of Y. Yang was supported in
   part by the ARC DECRA project under Grant DE130101311. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Prof. Alan Hanjalic.
CR Aggarwal G, 2002, IEEE T MULTIMEDIA, V4, P201, DOI 10.1109/TMM.2002.1017734
   [Anonymous], P INT C COMP VIS BAR
   [Anonymous], 2012, P IEEE C COMP VIS PA
   [Anonymous], 2009, P 17 ACM INT C MULTI
   [Anonymous], 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539924
   [Anonymous], 2008, P 4 IEEE IFIP WORLDW
   [Anonymous], 2009, PROC 17 ACM INT C MU
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan JP, 2008, IEEE T MULTIMEDIA, V10, P167, DOI 10.1109/TMM.2007.911775
   Farhadi Ali, 2009, CVPR
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Harchaoui Z, 2012, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2012.6248078
   Huang S.-J., 2012, Association for the Advancement of Artificial Intelligence, P949, DOI DOI 10.5555/2900728.2900863
   Joachims T, 2009, COMMUN ACM, V52, P97, DOI 10.1145/1592761.1592783
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Keerthi S., 2007, CRF versus SVM-struct for sequence labeling
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li L, 2012, IEEE T MULTIMEDIA, V14, P1401, DOI 10.1109/TMM.2012.2194993
   Li Yanjun, 2008, PLoS One, V3, pe2166, DOI 10.1371/journal.pone.0002166
   Lovato P., 2013, Proceedings of the 11th Asian conference on Computer Vision - Volume Part I, P45
   Marszalek M, 2008, LECT NOTES COMPUT SC, V5305, P479, DOI 10.1007/978-3-540-88693-8_35
   Mattivi R., 2012, P 2 ACM INT C MULT R, P62
   Nguyen N., 2007, P INT C MACH LEARN
   Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033
   Stöttinger J, 2012, IEEE T IMAGE PROCESS, V21, P2681, DOI 10.1109/TIP.2012.2186143
   Szummer M., 2008, P EUR C COMP VIS, P1
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Valenti R, 2012, INT J COMPUT VISION, V98, P324, DOI 10.1007/s11263-011-0511-6
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Wang Y, 2010, LECT NOTES COMPUT SC, V6315, P155, DOI 10.1007/978-3-642-15555-0_12
   Wu F., 2010, Proceedings of the International Conference on Multimedia (MM'10), P15, DOI DOI 10.1145/1873951.1873957
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815
NR 38
TC 15
Z9 15
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2014
VL 16
IS 6
BP 1665
EP 1676
DI 10.1109/TMM.2014.2321530
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AT1UW
UT WOS:000344720200015
DA 2024-07-18
ER

PT J
AU Kalamaras, I
   Drosou, A
   Tzovaras, D
AF Kalamaras, Ilias
   Drosou, Anastasios
   Tzovaras, Dimitrios
TI Multi-Objective Optimization for Multimodal Visualization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image clustering; multi-objective optimization; multimodal
   visualization; pareto optimization
AB Using data visualization techniques can be of significant assistance in exploring multimedia databases. Data visualization is typically addressed as a unimodal learning task, where data are described with only one feature set, or modality. However, using multiple data modalities has been proved to increase the performance of learning methods. In this paper a novel approach for exploiting the multiple available modalities for visualization is proposed, motivated by the field of multi-objective optimization. Initially, each modality is considered separately. A graph of the dissimilarities among the data and the corresponding minimum spanning tree are formed. The suitability of a particular data placement is quantified using multiple cost functions, one for each modality. The utilized cost functions are defined in terms of graph aesthetic measures, computed for the unimodal minimum spanning trees. The cost functions are then used as the multiple objectives of a multi-objective optimization problem. Solving the problem results in a set of Pareto optimal placements, which represent different trade-offs among the various objectives. Experimental evaluation shows that the proposed method outperforms current multimodal visualization methods both in discovering more visualizations and in producing ones which are more aesthetically pleasing and easily perceivable.
C1 [Kalamaras, Ilias] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
   [Kalamaras, Ilias; Drosou, Anastasios; Tzovaras, Dimitrios] Ctr Res & Technol Hellas, Informat Technol Inst, Thessaloniki, Greece.
C3 Imperial College London; Centre for Research & Technology Hellas
RP Kalamaras, I (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
EM i.kalamaras11@imperial.ac.uk; drosou@iti.gr; dimitrios.tzovaras@iti.gr
RI Drosou, Anastasios/AAV-5969-2020; Tzovaras, Dimitrios/ABB-9576-2021
OI Tzovaras, Dimitrios/0000-0001-6915-6722
FU EU [FP7-ICT-287704]
FX This work was supported by the EU funded project CUbRIK
   (FP7-ICT-287704). The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Chong-Wah Ngo.
CR [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], 2002, Information Visualization in Data Mining and Knowledge Discovery
   [Anonymous], MULT IM SOUND DAT BI
   [Anonymous], SIGNAL PROCESSING PA
   [Anonymous], TIK REP
   [Anonymous], BIRD SOUNDS AM
   [Anonymous], 2004, Metaheuristics for Multiobjective Optimisation
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Berg AC, 2001, PROC CVPR IEEE, P607
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Chen C., 2008, HDB DATA VISUALIZATI
   Chen M, 2010, IEEE T VIS COMPUT GR, V16, P1206, DOI 10.1109/TVCG.2010.132
   Coello Carlos A Coello, 2007, EVOLUTIONARY ALGORIT, V5
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dhillon IS, 2003, P 9 ACM SIGKDD INT C, P89, DOI DOI 10.1145/956750.956764
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Ehrgott M., 2005, Multicriteria optimization, V2
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Goldstein E., 2013, SENSATION PERCEPTION
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Günter S, 2003, PATTERN RECOGN LETT, V24, P1107, DOI 10.1016/S0167-8655(02)00257-X
   HAJELA P, 1992, STRUCT OPTIMIZATION, V4, P99, DOI 10.1007/BF01759923
   Handl J, 2003, FR ART INT, V104, P204
   Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337
   HORN DL, 1993, POLIT GEOGR, V12, P103, DOI 10.1016/0962-6298(93)90031-2
   Jaegul Choo, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P67, DOI 10.1109/VAST.2009.5332629
   Jitao Sang, 2012, Journal of Multimedia, V7, P9, DOI 10.4304/jmm.7.1.9-20
   Kohler W. W., 1929, Gestalt Psychology
   Krapac J, 2010, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR.2010.5540092
   Becerra RL, 2006, LECT NOTES COMPUT SC, V4193, P543
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Lin YY, 2011, IEEE T PATTERN ANAL, V33, P1147, DOI 10.1109/TPAMI.2010.183
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malitz S., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P527, DOI 10.1145/129712.129764
   Marler RT, 2010, STRUCT MULTIDISCIP O, V41, P853, DOI 10.1007/s00158-009-0460-7
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Revaud J, 2013, PROC CVPR IEEE, P2459, DOI 10.1109/CVPR.2013.318
   WIERZBICKI AP, 1986, OR SPEKTRUM, V8, P73, DOI 10.1007/BF01719738
   Wu XA, 2011, IEEE MULTIMEDIA, V18, P38, DOI 10.1109/MMUL.2011.12
   Xue Y, 2007, J MACH LEARN RES, V8, P35
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Zhang DQ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P117
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhang H, 2006, LECT NOTES COMPUT SC, V4261, P979
NR 50
TC 28
Z9 30
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2014
VL 16
IS 5
BP 1460
EP 1472
DI 10.1109/TMM.2014.2316473
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AN0SZ
UT WOS:000340295600025
DA 2024-07-18
ER

PT J
AU Guha, T
   Ward, RK
AF Guha, Tanaya
   Ward, Rabab K.
TI Image Similarity Using Sparse Representation and Compression Distance
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Compression; image similarity; Kolmogorov complexity; overcomplete
   dictionary; sparse representation
ID INFORMATION
AB A new line of research uses compression methods to measure the similarity between signals. Two signals are considered similar if one can be compressed significantly when the information of the other is known. The existing compression-based similarity methods, although successful in the discrete one dimensional domain, do not work well in the context of images. This paper proposes a sparse representation-based approach to encode the information content of an image using information from the other image, and uses the compactness (sparsity) of the representation as a measure of its compressibility (how much can the image be compressed) with respect to the other image. The sparser the representation of an image, the better it can be compressed and the more it is similar to the other image. The efficacy of the proposed measure is demonstrated through the high accuracies achieved in image clustering, retrieval and classification.
C1 [Guha, Tanaya; Ward, Rabab K.] Univ British Columbia, Image & Signal Proc Lab, Dept Elect & Comp Engn, Vancouver, BC V6T1R9, Canada.
C3 University of British Columbia
RP Guha, T (corresponding author), Univ British Columbia, Image & Signal Proc Lab, Dept Elect & Comp Engn, Vancouver, BC V6T1R9, Canada.
EM tanaya@ece.ubc.ca; rababw@ece.ubc.ca
OI Guha, Tanaya/0000-0003-2167-4891
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 1993, DIGITAL IMAGES HUMAN
   [Anonymous], 2008, EFFICIENT IMPLEMENTA
   Campana B. J. L., 2010, STAT ANAL DATA MININ, V3
   Cerra D, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P509, DOI 10.1109/DCC.2008.46
   CHAITIN GJ, 1966, J ACM, V13, P547, DOI 10.1145/321356.321363
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Chen WY, 2011, IEEE T PATTERN ANAL, V33, P568, DOI 10.1109/TPAMI.2010.88
   Chen X, 2004, IEEE T INFORM THEORY, V50, P1545, DOI 10.1109/TIT.2004.830793
   Cilibrasi R, 2004, COMPUT MUSIC J, V28, P49, DOI 10.1162/0148926042728449
   Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Kang LW, 2011, IEEE T MULTIMEDIA, V13, P1019, DOI 10.1109/TMM.2011.2159197
   Keogh E. J., 2004, KDD, P206, DOI [DOI 10.1145/1014052.1014077, 10.1145/1014052.1014077]
   Kolmogorov A. N., 1968, International Journal of Computer Mathematics, V2, P157, DOI 10.1080/00207166808803030
   Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Li M., 1997, INTRO KOLMOGOROV COM
   Li M, 2006, LECT NOTES ARTIF INT, V3918, P704
   Macedonas A, 2008, J VIS COMMUN IMAGE R, V19, P464, DOI 10.1016/j.jvcir.2008.06.006
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI
   Pati Y., 1993, P AS SIGN SYST COMP
   Pinho A. J., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1993, DOI 10.1109/ICIP.2011.6115866
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Silva D., 2013, P INT SOC MUS INF RE
   SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P1, DOI 10.1016/S0019-9958(64)90223-2
   Tataw OM, 2013, PROC INT CONF DOC, P180, DOI 10.1109/ICDAR.2013.43
   Theodorakopoulos I, 2011, IEEE I CONF COMP VIS, P1647, DOI 10.1109/ICCV.2011.6126426
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   Watanabe T, 2002, IEEE T PATTERN ANAL, V24, P579, DOI 10.1109/34.1000234
   Wohlberg B, 2003, IEEE T SIGNAL PROCES, V51, P3053, DOI 10.1109/TSP.2003.819006
   Zeppelzauer M., 2013, P 2 ACM INT WORKSHOP, P3
NR 35
TC 41
Z9 43
U1 0
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2014
VL 16
IS 4
BP 980
EP 987
DI 10.1109/TMM.2014.2306175
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AJ8LN
UT WOS:000337955800008
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Nguyen, LS
   Frauendorfer, D
   Mast, MS
   Gatica-Perez, D
AF Laurent Son Nguyen
   Frauendorfer, Denise
   Mast, Marianne Schmid
   Gatica-Perez, Daniel
TI Hire me: Computational Inference of Hirability in Employment Interviews
   Based on Nonverbal Behavior
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Employment interviews; hirability; nonverbal behavior; social computing
ID VALIDITY; IMPRESSIONS
AB Understanding the basis on which recruiters form hirability impressions for a job applicant is a key issue in organizational psychology and can be addressed as a social computing problem. We approach the problem from a face-to-face, nonverbal perspective where behavioral feature extraction and inference are automated. This paper presents a computational framework for the automatic prediction of hirability. To this end, we collected an audio-visual dataset of real job interviews where candidates were applying for a marketing job. We automatically extracted audio and visual behavioral cues related to both the applicant and the interviewer. We then evaluated several regression methods for the prediction of hirability scores and showed the feasibility of conducting such a task, with ridge regression explaining 36.2% of the variance. Feature groups were analyzed, and two main groups of behavioral cues were predictive of hirability: applicant audio features and interviewer visual cues, showing the predictive validity of cues related not only to the applicant, but also to the interviewer. As a last step, we analyzed the predictive validity of psychometric questionnaires often used in the personnel selection process, and found that these questionnaires were unable to predict hirability, suggesting that hirability impressions were formed based on the interaction during the interview rather than on questionnaire data.
C1 [Laurent Son Nguyen; Gatica-Perez, Daniel] Idiap Res Inst, CH-1920 Martigny, Switzerland.
   [Laurent Son Nguyen; Gatica-Perez, Daniel] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
   [Frauendorfer, Denise; Mast, Marianne Schmid] Univ Neuchatel, CH-2000 Neuchatel, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; University of Neuchatel
RP Nguyen, LS (corresponding author), Idiap Res Inst, CH-1920 Martigny, Switzerland.
EM lnguyen@idiap.ch; denise.frauendorfer@unine.ch;
   marianne.schmid@unine.ch; gatica@idiap.ch
FU Swiss National Science Foundation (SNSF)
FX The authors would like to thank C. Duc and A. Loude for the annotations,
   and the applicants who kindly accepted to share their data. This work
   was supported by the project "Sensing and Analyzing Organizational
   Nonverbal Behavior" (SONVB) of the Sinergia interdisciplinary program of
   the Swiss National Science Foundation (SNSF).
CR AMBADY N, 1995, J PERS SOC PSYCHOL, V69, P518, DOI 10.1037/0022-3514.69.3.518
   ANDERSON N, 1990, J OCCUP PSYCHOL, V63, P63, DOI 10.1111/j.2044-8325.1990.tb00510.x
   [Anonymous], THESIS U S FLORIDA T
   [Anonymous], 2008, P ICMI 2008, DOI DOI 10.1145/1452392.1452404
   [Anonymous], 2003, P EUROSPEECH
   [Anonymous], P INT C AUGM COGN
   [Anonymous], THESIS
   [Anonymous], 2011, P INT AAAI C WEB SOC
   [Anonymous], BUSINESS PSYCHOL
   [Anonymous], DISS ABSTR INT
   BARRICK MR, 1991, PERS PSYCHOL, V44, P1, DOI 10.1111/j.1744-6570.1991.tb00688.x
   Batrinca L, 2011, P 13 INT C MULT INT, P255, DOI [DOI 10.1145/2070481.2070528, 10.1145/2070481.2070528]
   Biel JI, 2013, IEEE T MULTIMEDIA, V15, P41, DOI 10.1109/TMM.2012.2225032
   Breiman L., 2001, Mach. Learn., V45, P5
   Caldwell DF, 1998, PERS PSYCHOL, V51, P119, DOI 10.1111/j.1744-6570.1998.tb00718.x
   Costa P., 1992, REVISED PERSONALITY
   Curhan JR, 2007, J APPL PSYCHOL, V92, P802, DOI 10.1037/0021-9010.92.3.802
   DeGroot T, 2009, J BUS PSYCHOL, V24, P179, DOI 10.1007/s10869-009-9098-0
   Favre S., 2008, Proc. ACM International Conference on Multimodal Interfaces, P29
   FORBES RJ, 1980, J OCCUP PSYCHOL, V53, P65, DOI 10.1111/j.2044-8325.1980.tb00007.x
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   GIFFORD R, 1985, J APPL PSYCHOL, V70, P729, DOI 10.1037/0021-9010.70.4.729
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Howard JL, 1996, J APPL SOC PSYCHOL, V26, P112, DOI 10.1111/j.1559-1816.1996.tb01841.x
   Huffcutt AI, 2001, J APPL PSYCHOL, V86, P897, DOI 10.1037//0021-9010.86.5.897
   IMADA AS, 1977, J APPL PSYCHOL, V62, P295, DOI 10.1037/0021-9010.62.3.295
   Jayagopi DB, 2009, IEEE T AUDIO SPEECH, V17, P501, DOI 10.1109/TASL.2008.2008238
   Jayagopi D, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P433
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Knapp M.L., 2009, Nonverbal communication in human interaction, V7th
   Nguyen L, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P289
   LIDEN RC, 1993, ACAD MANAGE J, V36, P372, DOI 10.5465/256527
   MCDANIEL MA, 1994, J APPL PSYCHOL, V79, P599, DOI 10.1037/0021-9010.79.4.599
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Park S, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P19
   PARSONS CK, 1984, J APPL PSYCHOL, V69, P557, DOI 10.1037/0021-9010.69.4.557
   Posthuma RA, 2002, PERS PSYCHOL, V55, P1, DOI 10.1111/j.1744-6570.2002.tb00103.x
   RIGGIO RE, 1986, J PERS SOC PSYCHOL, V51, P649, DOI 10.1037/0022-3514.51.3.649
   Rothmann S., 2003, IND PSYCHOL, V29, P68, DOI DOI 10.4102/SAJIP.V29I1.88
   Sanchez-Cortes D, 2012, IEEE T MULTIMEDIA, V14, P816, DOI 10.1109/TMM.2011.2181941
   Scherer S, 2013, IEEE INT CONF AUTOMA
   Song Y, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P27
   WIESNER WH, 1988, J OCCUP PSYCHOL, V61, P275, DOI 10.1111/j.2044-8325.1988.tb00467.x
NR 43
TC 107
Z9 116
U1 1
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2014
VL 16
IS 4
BP 1018
EP 1031
DI 10.1109/TMM.2014.2307169
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Telecommunications
GA AJ8LN
UT WOS:000337955800011
DA 2024-07-18
ER

PT J
AU Olaizola, IG
   Quartulli, M
   Flórez, J
   Sierra, B
AF Olaizola, Igor G.
   Quartulli, Marco
   Florez, Julian
   Sierra, Basilio
TI Trace Transform Based Method for Color Image Domain Identification
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE CBIR; image domain identification; pattern recognition; trace transform
ID CONTEXT; SHAPE
AB Context categorization is a fundamental pre-requisite for multi-domain multimedia content analysis applications. Most feature extraction methods require prior knowledge to decide if they are suitable for a specific domain and to optimize their input parameters. In this paper, we introduce a new color image context categorizationmethod (DITEC) based on the trace transform. The problem of dimensionality reduction of the obtained trace transform signal is addressed through statistical descriptors of its frequency representation that keep the underlying information. We also analyze the distortions produced by the parameters that determine the sampling of the discrete trace transform. Moreover, Feature Subset Selection (FSS) is applied to both, improve the classification performance and compact the final length of the descriptor thatwill be provided to the classifier. These extracted features offer a highly discriminant behavior for content categorization without prior knowledge requirements. The method has been experimentally validated through two different datasets.
C1 [Olaizola, Igor G.; Quartulli, Marco; Florez, Julian] Dept Digital TV & Multimedia Serv, San Sebastian 20009, Spain.
   [Sierra, Basilio] Univ Basque Country, San Sebastian 20008, Spain.
C3 University of Basque Country
RP Olaizola, IG (corresponding author), Dept Digital TV & Multimedia Serv, San Sebastian 20009, Spain.
EM iolaizola@vicomtech.org; mquartulli@vicomtech.org;
   jflorez@vicomtech.org; b.sierra@ehu.es
RI Sierra, Basilio/AAX-9544-2020; Olaizola, Igor García/C-2957-2009;
   Sierra, Basilio/L-3160-2014
OI Olaizola, Igor García/0000-0002-9965-2038; Sierra,
   Basilio/0000-0001-8062-9332
CR [Anonymous], MPEG 7 OVERVIEW
   [Anonymous], P IEEE C INT C PATT
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Blanco R, 2004, INT J PATTERN RECOGN, V18, P1373, DOI 10.1142/S0218001404003800
   Bober M., 2007, JTC1SC29WG11 ISOIEC
   Bouachir Wassim., 2010, 5th International Symposium on I N Communications and Mobile Network (ISVC), 2010, P1
   Bouker M. A., 2011, Proceedings of the Seventh International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2011), P218, DOI 10.1109/SITIS.2011.75
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   Fooprateepsiri R, 2009, LECT NOTES COMPUT SC, V5863, P788, DOI 10.1007/978-3-642-10677-4_90
   Kadyrov A, 2001, IEEE T PATTERN ANAL, V23, P811, DOI 10.1109/34.946986
   Kadyrov A, 1998, INT C PATT RECOG, P1037, DOI 10.1109/ICPR.1998.711868
   Kadyrov A, 2006, IEEE T PATTERN ANAL, V28, P1631, DOI 10.1109/TPAMI.2006.198
   Li J, 2009, IEEE T IMAGE PROCESS, V18, P889, DOI 10.1109/TIP.2008.2011381
   Liu N., 2007, P 6 INT C INF COMM S, P1
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Marcos G, 2009, PROCEEDINGS 2009 FOURTH INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, P33, DOI 10.1109/SMAP.2009.16
   Nasrudin Mohammad F., 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P151, DOI 10.1109/CGIV.2010.31
   O'Callaghan R., 2008, 9581 ISOIEC TC JTC1S, V01
   Olaizola I. G., 2009, P IEEE INT S BROADB, P1
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Petrou M, 2004, IEEE T PATTERN ANAL, V26, P30, DOI 10.1109/TPAMI.2004.1261077
   Poynton CharlesA., 1996, TECHNICAL INTRO DIGI
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Richardson I.E.G., 2002, Video Codec Design: Developing Image and Video Compression Systems
   Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2010, COMPUTER, V43, P76, DOI 10.1109/MC.2010.183
   Srisuk S., 2003, P IEEE COMP SOC C CO, V1
   STRAT TM, 1991, IEEE T PATTERN ANAL, V13, P1050, DOI 10.1109/34.99238
   Torralba A, 2010, COMMUN ACM, V53, P107, DOI 10.1145/1666420.1666446
   TORRALBA A, 2001, P IEEE INT C COMP VI
   Turán J, 2005, TELSIKS 2005, PROCEEDINGS, VOLS 1 AND 2, P189
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Zajic G., 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P176, DOI 10.1049/cp:20080304
NR 35
TC 8
Z9 9
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2014
VL 16
IS 3
BP 679
EP 685
DI 10.1109/TMM.2014.2300843
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AD3BJ
UT WOS:000333111500009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, JJ
   Jagadeesh, V
   Manjunath, BS
AF Xu, Jiejun
   Jagadeesh, Vignesh
   Manjunath, B. S.
TI Multi-Label Learning With Fused Multimodal Bi-Relational Graph
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Graph-based semi-supervised learning; multi-label classification;
   multimodal
AB The problem of multi-label image classification using multiple feature modalities is considered in this work. Given a collection of images with partial labels, we first model the association between different feature modalities and the images labels. These associations are then propagated with a graph diffusion kernel to classify the unlabeled images. Towards this objective, a novel Fused Multimodal Bi-relational Graph representation is proposed, with multiple graphs corresponding to different feature modalities, and one graph corresponding to the image labels. Such a representation allows for effective exploitation of both feature complementariness and label correlation. This contrasts with previous work where these two factors are considered in isolation. Furthermore, we provide a solution to learn the weight for each image graph by estimating the discriminative power of the corresponding feature modality. Experimental results with our proposed method on two standard multi-label image datasets are very promising.
C1 [Xu, Jiejun] Univ Calif Santa Barbara, Dept Comp Sci, CA UC Santa Barbara, Santa Barbara, CA 93106 USA.
   [Jagadeesh, Vignesh; Manjunath, B. S.] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara;
   University of California System; University of California Santa Barbara
RP Xu, JJ (corresponding author), Univ Calif Santa Barbara, Dept Comp Sci, CA UC Santa Barbara, Santa Barbara, CA 93106 USA.
RI Manjunath, B S/AAM-8190-2020
OI Manjunath, B S/0000-0003-2804-3611
FU NSF III [0808772]; ONR [N00014-10-1-0478, N00014-12-1-0503]
FX This work was supported by the following awards: NSF III 0808772, ONR
   #N00014-10-1-0478, and #N00014-12-1-0503. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Selcuk Candan.
CR Anderson E., 1999, LAPACK USERSGUIDE, Vthird
   [Anonymous], P IEEE INT C MULT IN
   [Anonymous], 2007, Computer Vision
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2008, P INT C MULT INF RET
   [Anonymous], P AAAI
   Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Bo LF, 2011, PROC CVPR IEEE, P1729, DOI 10.1109/CVPR.2011.5995719
   Boutell M. R., 2004, PATTERN RECOGNIT, V37
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen G., 2008, P SIAM INT C DAT MIN, P410, DOI DOI 10.1137/1.9781611972788.37
   Clinchant S., 2011, P ICMR
   Elisseeff A, 2002, ADV NEUR IN, V14, P681
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Fu Z., 2011, P ACM MULT
   Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   He J., P 12 ANN ACM INT C M, P9, DOI 10.1145/1027527.1027531
   Ji CJ, 2012, LECT NOTES COMPUT SC, V7575, P688, DOI 10.1007/978-3-642-33765-9_49
   Ji SW, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1754428.1754431
   Kang F., 2006, CVPR, V2, P1719
   KUMAR S, 2003, P NIPS
   LIU Y, 2006, P AAAI
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath B.S., 1996, TEXTURE FEATURES BRO
   Moxley E, 2010, IEEE T MULTIMEDIA, V12, P184, DOI 10.1109/TMM.2010.2041101
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   QI G, 2007, P ACM MULT
   Tan H., 2011, P ICMR, P15
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Tang JH, 2009, IEEE T SYST MAN CY B, V39, P409, DOI 10.1109/TSMCB.2008.2006045
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   WANG C, 2006, P ACM MULT
   Wang H, 2011, PROC CVPR IEEE, P793, DOI 10.1109/CVPR.2011.5995379
   Wang H, 2009, IEEE I CONF COMP VIS, P2029, DOI 10.1109/ICCV.2009.5459447
   Wang M., 2007, ACM Multi- media, P862
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yu G., 2012, Pro- ceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, P1077
   Yu K., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P258, DOI 10.1145/1076034.1076080
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
   Zhou D., 2003, P NIPS
   Zhou D., 2006, Advances in Neural Information Processing Systems, P1036
   Zhu S., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P274, DOI 10.1145/1076034.1076082
   Zhu X, 2003, ICML
NR 49
TC 27
Z9 30
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2014
VL 16
IS 2
BP 403
EP 412
DI 10.1109/TMM.2013.2291218
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 297HF
UT WOS:000330245800010
DA 2024-07-18
ER

PT J
AU Benavent, X
   Garcia-Serrano, A
   Granados, R
   Benavent, J
   de Ves, E
AF Benavent, Xaro
   Garcia-Serrano, Ana
   Granados, Ruben
   Benavent, Joan
   de Ves, Esther
TI Multimedia Information Retrieval Based on Late Semantic Fusion
   Approaches: Experiments on a Wikipedia Image Collection
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Content-based information retrieval; multimedia information fusion;
   multimedia retrieval; textual-based information retrieval.
ID RELEVANCE FEEDBACK; FEATURES; MERGE
AB Main goal of this work is to show the improvement of using a textual pre-filtering combined with an image re-ranking in a Multimedia Information Retrieval task. The defined three step-based retrieval processes and a well-selected combination of visual and textual techniques help the developed Multimedia Information Retrieval System to overcome the semantic gap in a given query. In the paper, five different late semantic fusion approaches are discussed and experimented in a realistic scenario for multimedia retrieval like the one provided by the publicly available ImageCLEF Wikipedia Collection.
C1 [Benavent, Xaro; Benavent, Joan; de Ves, Esther] Univ Valencia, Dept Comp Sci, Valencia 46022, Spain.
   [Garcia-Serrano, Ana; Granados, Ruben] UNED, ETSI Informat, Madrid 28040, Spain.
C3 University of Valencia; Universidad Nacional de Educacion a Distancia
   (UNED)
RP Benavent, X (corresponding author), Univ Valencia, Dept Comp Sci, Valencia 46022, Spain.
EM xaro.benavent@uv.es; agarcia@lsi.uned.es
RI de Ves Cuenca, Esther/R-8157-2018; Garcia, Xaro Benavent/AAA-1420-2019;
   Garcia-Serrano, Ana/L-2037-2013
OI de Ves Cuenca, Esther/0000-0002-7702-8808; Garcia, Xaro
   Benavent/0000-0002-3133-6223; Garcia-Serrano, Ana/0000-0003-0975-7205
FU Spanish project BUSCAMEDIA [CEN-20091026]; Spanish project MA2VICMR
   [S2009/TIC-1542]; Spanish project MCYT [TEC2009-12980]
FX This work was supported in part by Spanish projects BUSCAMEDIA under
   CEN-20091026, MA2VICMR under S2009/TIC-1542, and MCYT under
   TEC2009-12980.
CR [Anonymous], 1993, TREC 1
   [Anonymous], 2008, P 1 ACM INT C MULTIM
   Aslam J. A., 2001, SIGIR Forum, P276
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Benavent J., P CLEF 2010 PAD IT
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Clinchant S, 2011, P 1 ACM INT C MULT R, P44
   Csurka G., 2011, CLEF 2011 WORK NOT S
   Depeursinge A, 2010, INFORM RETRIEVAL SER, V32, P95, DOI 10.1007/978-3-642-15181-1_6
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   García-Serrano A, 2010, LECT NOTES COMPUT SC, V6242, P142, DOI 10.1007/978-3-642-15751-6_15
   García-Serrano A, 2009, LECT NOTES COMPUT SC, V5706, P568, DOI 10.1007/978-3-642-04447-2_69
   Granados R., 2011, P CLEF 2011 LABS WOR
   Grubinger M., 2007, THESIS VICTORIA U ME
   Kludas J., 2007, AMR INT WORKSH RETR
   León T, 2007, PATTERN RECOGN, V40, P2621, DOI 10.1016/j.patcog.2007.02.002
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Montague M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P538, DOI 10.1145/584792.584881
   Muller H, 2010, INFORM RETRIEVAL SER, V32, P1, DOI 10.1007/978-3-642-15181-1
   Popescu A., 2010, NOTEBOOK PAPERS
   RUI Y, 1998, IEEE T CIRCUITS SYST, V8
   Tsikrika T., 2011, P CLEF 2011 LABS WOR
   Wu SL, 2006, LECT NOTES COMPUT SC, V4182, P642
   Xin Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1590, DOI 10.1109/ICPR.2010.393
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
NR 26
TC 20
Z9 22
U1 0
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2013
VL 15
IS 8
BP 2009
EP 2021
DI 10.1109/TMM.2013.2267726
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 257OI
UT WOS:000327393900023
OA Bronze
DA 2024-07-18
ER

PT J
AU Hu, H
   Zhu, XQ
   Wang, Y
   Pan, R
   Zhu, J
   Bonomi, F
AF Hu, Hao
   Zhu, Xiaoqing
   Wang, Yao
   Pan, Rong
   Zhu, Jiang
   Bonomi, Flavio
TI Proxy-Based Multi-Stream Scalable Video Adaptation Over Wireless
   Networks Using Subjective Quality and Rate Models
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Scalable video coding (SVC); subjective video quality model; video rate
   adaptation; wireless video streaming
ID TRANSMISSION
AB Despite growing maturity in broadband mobile networks, wireless video streaming remains a challenging task, especially in highly dynamic environments. Rapidly changing wireless link qualities, highly variable round trip delays, and unpredictable traffic contention patterns often hamper the performance of conventional end-to-end rate adaptation techniques such as TCP-friendly rate control (TFRC). Furthermore, existing approaches tend to treat all flows leaving the network edge equally, without accounting for heterogeneity in the underlying wireless link qualities or the different rate utilities of the video streams. In this paper, we present a proxy-based solution for adapting the scalable video streams at the edge of a wireless network, which can respond quickly to highly dynamic wireless links. Our design adopts the recently standardized scalable video coding (SVC) technique for lightweight rate adaptation at the edge. Leveraging previously developed rate and quality models of scalable video with both temporal and amplitude scalability, we derive the rate-quality model that relates the maximum quality under a given rate by choosing the optimal frame rate and quantization stepsize. The proxy iteratively allocates rates of different video streams to maximize a weighted sum of video qualities associated with different streams, based on the periodically observed link throughputs and the sending buffer status. The temporal and amplitude layers included in each video are determined to optimize the quality while satisfying the rate assignment. Simulation studies show that our scheme consistently outperforms TFRC in terms of agility to track link qualities and overall subjective quality of all streams. In addition, the proposed scheme supports differential services for different streams, and competes fairly with TCP flows.
C1 [Hu, Hao; Zhu, Xiaoqing; Pan, Rong; Zhu, Jiang; Bonomi, Flavio] Cisco Syst, Adv Architecture & Res Grp, San Jose, CA 95134 USA.
   [Wang, Yao] NYU, Polytech Inst, Dept Elect & Comp Engn, Brooklyn, NY 11201 USA.
C3 Cisco Systems Inc; New York University; New York University Tandon
   School of Engineering
RP Hu, H (corresponding author), Cisco Syst, Adv Architecture & Res Grp, San Jose, CA 95134 USA.
EM hahu2@cisco.com; xiaoqzhu@cisco.com; yao@poly.edu; ropan@cisco.com;
   jiangzhu@cisco.com; flavio@cisco.com
OI Wang, Yao/0000-0003-3199-3802
FU Cisco Systems, Inc.
FX This work was supported in part by a gift award from Cisco Systems, Inc.
   The associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Zhihai (Henry) He.
CR [Anonymous], 2005, H264 ITUT
   [Anonymous], P IEEE INT C COMM IC
   [Anonymous], 2008, 5348 RFC
   Cabrera J, 2002, IEEE T CIRC SYST VID, V12, P496, DOI 10.1109/TCSVT.2002.800306
   Chakareski J, 2006, IEEE T MULTIMEDIA, V8, P207, DOI 10.1109/TMM.2005.864284
   Chakareski J, 2011, IEEE T MULTIMEDIA, V13, P1092, DOI 10.1109/TMM.2011.2157673
   Chen JYC, 2007, IEEE T SYST MAN CY A, V37, P1063, DOI 10.1109/TSMCA.2007.904779
   Chen MH, 2004, IEEE INFOCOM SER, P1181
   Cisco, 2011, VIS NETW IND GLOB MO
   Cisco, QOS WIR LAN CONTR LI
   Haratcherev I, 2006, IEEE COMMUN MAG, V44, P115, DOI 10.1109/MCOM.2006.1580941
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Jin SH, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P131, DOI 10.1109/MMSP.2007.4412835
   Kelly FP, 1998, J OPER RES SOC, V49, P237, DOI 10.2307/3010473
   Khan S, 2007, ADV MULTIMED, V2007, DOI 10.1155/2007/94918
   Kohler E., 2006, Datagram Congestion Control Protocol (DCCP) (No. rfc4340)
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   Lu SW, 1999, IEEE ACM T NETWORK, V7, P473, DOI 10.1109/90.793003
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Srikant R., 2003, MATH INTERNET CONGES, V1st
   Stockhammer T., 2005, P IEEE ICME 2005 JUL, P1396
   Ulukus S, 1998, IEEE T COMMUN, V46, P784, DOI 10.1109/26.681417
   van Beek P., 2005, P IEEE INT C IM PROC, V2, P173
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Wang Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1719, DOI 10.1109/ICME.2004.1394585
   Ying-Hong Wang, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P1, DOI [10.1109/ICBBE.2009.5163482, 10.1109/UIC-ATC.2009.19]
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Yamagishi K., 2006, GLOB TEL C 2006 GLOB, P1
   Yang G, 2006, ACM T MULTIM COMPUT, V2, P109, DOI 10.1145/1142020.1142022
   Yang KC, 2007, IEEE T MULTIMEDIA, V9, P1528, DOI 10.1109/TMM.2007.906576
   Zhang HH, 2010, IEEE J SEL AREA COMM, V28, P344, DOI 10.1109/JSAC.2010.100406
   Zhang Q, 2005, P IEEE, V93, P123, DOI 10.1109/JPROC.2004.839603
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
   Zhu X., 2010, P IEEE INT C COMP CO
   Zhu XQ, 2010, IEEE T CIRC SYST VID, V20, P1462, DOI 10.1109/TCSVT.2010.2077492
NR 39
TC 31
Z9 33
U1 1
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2013
VL 15
IS 7
BP 1638
EP 1652
DI 10.1109/TMM.2013.2266092
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 236PQ
UT WOS:000325811800015
DA 2024-07-18
ER

PT J
AU Aiello, LM
   Petkos, G
   Martin, C
   Corney, D
   Papadopoulos, S
   Skraba, R
   Göker, A
   Kompatsiaris, I
   Jaimes, A
AF Maria Aiello, Luca
   Petkos, Georgios
   Martin, Carlos
   Corney, David
   Papadopoulos, Symeon
   Skraba, Ryan
   Goeker, Ayse
   Kompatsiaris, Ioannis
   Jaimes, Alejandro
TI Sensing Trending Topics in Twitter
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Information filtering; social media; social sensing; text mining; topic
   detection; Twitter
AB Online social and news media generate rich and timely information about real-world events of all kinds. However, the huge amount of data available, along with the breadth of the user base, requires a substantial effort of information filtering to successfully drill down to relevant topics and events. Trending topic detection is therefore a fundamental building block to monitor and summarize information originating from social sources. There are a wide variety of methods and variables and they greatly affect the quality of results. We compare six topic detection methods on three Twitter datasets related to major events, which differ in their time scale and topic churn rate. We observe how the nature of the event considered, the volume of activity over time, the sampling procedure and the pre-processing of the data all greatly affect the quality of detected topics, which also depends on the type of detection method used. We find that standard natural language processing techniques can perform well for social streams on very focused topics, but novel techniques designed to mine the temporal distribution of concepts are needed to handle more heterogeneous streams containing multiple stories evolving in parallel. One of the novel topic detection methods we propose, based on n-grams cooccurrence and df - idf(t) topic ranking, consistently achieves the best performance across all these conditions, thus being more reliable than other state-of-the-art techniques.
C1 [Maria Aiello, Luca; Jaimes, Alejandro] Yahoo Res, Barcelona, Spain.
   [Petkos, Georgios; Papadopoulos, Symeon; Kompatsiaris, Ioannis] CERTH, Inst Informat Technol, Thessaloniki, Greece.
   [Martin, Carlos; Corney, David] City Univ London, Sch Informat, London EC1V 0HB, England.
   [Skraba, Ryan] Alcatel Lucent Bell Labs France, Paris, France.
   [Goeker, Ayse] Robert Gordon Univ, Sch Comp, IDEAS Res Inst, Aberdeen AB9 1FR, Scotland.
C3 Yahoo! Inc; Yahoo! Inc Spain; Centre for Research & Technology Hellas;
   City University London; Alcatel-Lucent; Robert Gordon University
RP Aiello, LM (corresponding author), Yahoo Res, Barcelona, Spain.
EM alucca@yahoo-inc.com; gpetkos@iti.gr; martin.carlos.1@city.ac.uk;
   david.corney.1@city.ac.uk; papadop@iti.gr;
   ryan.skraba@alcatel-lucent.com; a.s.goker@rgu.ac.uk; ikom@iti.gr;
   ajaimes@yahoo-inc.com
RI Papadopoulos, Symeon/AET-0683-2022; Aiello, Luca Maria/ABB-2507-2021;
   Corney, David/P-6941-2019; Kompatsiaris, Ioannis/P-8594-2015; Goker,
   Ayse/GXZ-6153-2022; Corney, David/C-1601-2008
OI Aiello, Luca Maria/0000-0002-0654-2527; Kompatsiaris,
   Ioannis/0000-0001-6447-9020; Papadopoulos, Symeon/0000-0002-5441-7341;
   Goker, Ayse/0000-0002-4462-5489; Corney, David/0000-0002-0651-9028
FU Social Sensor FP7 project; EC [287975]
FX Manuscript received September 21, 2012; revised February 12, 2013;
   accepted March 21, 2013. Date of publication June 06, 2013; date of
   current version September 13, 2013. The majority of this work was
   conducted while A. Goker was at City University London. This work was
   supported by the Social Sensor FP7 project, partially funded by the EC
   under contract number 287975. The associate editor coordinating the
   review of this manuscript and approving it for publication was Prof.
   Alan Hanjalic.
CR Aiello LM, 2012, ACM T WEB, V6, DOI 10.1145/2180861.2180866
   Allan J., 2002, INTRO TOPIC DETECTIO
   [Anonymous], 2012, P INT AAAI C WEB SOC
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], 1997, READINGS INFORM RETR
   [Anonymous], 2009, ICWSM
   [Anonymous], 2010, HLT 10
   [Anonymous], 2009, P 17 ACM SIGSPATIAL, DOI DOI 10.1145/1653771.1653781
   [Anonymous], 2011, ICWSM
   Becker H., 2011, P ICWSM 5 INT AAAI C
   Blei D.M., 2006, INT C MACHINE LEARNI, DOI [DOI 10.1145/1143844.1143859, 10.1145/1143844.1143859]
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boshmaf Y, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P93
   Cataldi M., 2010, P MDMKDD 10 INT WORK, P4
   Cha M, 2009, WWW 09 P 18 INT WORL, DOI DOI 10.1145/1526709.1526806
   Cohen S, 2011, COMMUN ACM, V54, P66, DOI 10.1145/2001269.2001288
   Conover M. D., 2011, P SOCIALCOM 3 IEEE I
   Diplaris S., 2012, P 2012 NEM SUMM OCT, P47
   Finkel Jenny Rose, 2005, ACL, P363
   Fung G.P. C., 2005, VLDB, P181
   Goethals B., 2005, FREQUENT SET MINING, P377
   Gyorodi C., 2004, COMP STUDY ASS RULES
   Kumar R., 2006, P 12 ACM SIGKDD INT, P611, DOI DOI 10.1007/978-1-4419-6515-8_13
   Lehmann J., 2012, Proc. ACM Intl. World Wide Web Conf. (WWW), P251, DOI DOI 10.1145/2187836.2187871
   Leskovec J., 2008, P 14 ACM SIGKDD INT, P462, DOI DOI 10.1145/1401890.1401948
   Leskovec J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P497
   Li HY, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P107
   Mathioudakis M., 2010, P 2010 ACM SIGMOD IN, P1155
   MURTAGH F, 1983, COMPUT J, V26, P354, DOI 10.1093/comjnl/26.4.354
   O'Connor B., 2010, ICWSM
   Panisson A., 2011, VISUALIZATION EGYPTI
   Papadopoulos S, 2010, LECT NOTES COMPUT SC, V6263, P65, DOI 10.1007/978-3-642-15105-7_6
   Papadopoulos S, 2010, INT J DATA WAREHOUS, V6, P20, DOI 10.4018/JDWM.2010090802
   Phuvipadawat S., 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology - Workshops (WI-IAT 2010), P120, DOI 10.1109/WI-IAT.2010.205
   Qi He, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P207
   Quercia Daniele., 2012, Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work, P965, DOI DOI 10.1145/2145204.2145347
   Ratkiewicz J., 2011, P ICSWM 5 INT AAAI C
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Salton G, 1986, Introduction to Modern Information Retrieval
   Shamma DavidA., 2011, P ACM 2011 C COMPUTE, P355, DOI [10.1145/1958824.1958878, DOI 10.1145/1958824.1958878]
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wall M, 2011, INT J COMMUN-US, V5, P1333
   Xu XW, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P824, DOI 10.1145/1281192.1281280
   Yang J., 2011, P 4 ACM INT C WEB SE, P177, DOI DOI 10.1145/1935826.1935863
NR 44
TC 254
Z9 280
U1 0
U2 103
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2013
VL 15
IS 6
BP 1268
EP 1282
DI 10.1109/TMM.2013.2265080
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 222XH
UT WOS:000324765400005
DA 2024-07-18
ER

PT J
AU Zhang, XG
   Xu, Y
   Hu, H
   Liu, Y
   Guo, ZM
   Wang, Y
AF Zhang, Xinggong
   Xu, Yang
   Hu, Hao
   Liu, Yong
   Guo, Zongming
   Wang, Yao
TI Modeling and Analysis of Skype Video Calls: Rate Control and Video
   Quality
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Rate control; Skype; user QoE aware; video conferencing; video quality
AB Video-conferencing has recently gained its momentum and is widely adopted by end-consumers. But there have been very few studies on the network impacts of video calls and the user Quality-of-Experience (QoE) under different network conditions. In this paper, we study the rate control and video quality of Skype video call, and analyze the network impacts in large-scale networks. We first measure the behaviors of Skype video call on a controlled network testbed. By varying packet loss rate, propagation delay and available network bandwidth, we observe how Skype adjusts its sending rate, FEC redundancy, video rate and frame rate. It is found that Skype is robust against mild packet losses and propagation delays, and can efficiently utilize the available network bandwidth. We also find that it employs an overly aggressive FEC protection strategy. Based on the measurement results, we develop rate control model, FEC model, and video quality model for Skype video calls. Extrapolating from the models, we conduct numerical analysis to study the network impacts. We demonstrate that user back-offs upon quality degradation serve as an effective user-level rate control scheme. We also show that Skype video calls are indeed TCP-friendly and respond to congestion quickly when the network is overloaded. Through a case study of a 4G wireless network, we demonstrate that the proposed models can be used in user-QoE-aware network provisioning.
C1 [Zhang, Xinggong; Guo, Zongming] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Xu, Yang; Hu, Hao; Liu, Yong; Wang, Yao] NYU, Polytech Inst, Dept Elect & Comp Engn, Brooklyn, NY 11201 USA.
C3 Peking University; New York University; New York University Tandon
   School of Engineering
RP Zhang, XG (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM zhangxg@pku.edu.cn; yxu10@poly.edu; hhu01@poly.edu; yongliu@poly.edu;
   guozongming@pku.edu.cn; yao@poly.edu
RI Budiyanto, Setiyo/AAB-5628-2021; Zhang, Xinggong/U-3544-2019; xu,
   yang/HOC-0456-2023
OI Wang, Yao/0000-0003-3199-3802; Xu, Yang/0000-0002-0958-8547
FU Natural Science Foundation of China [61071082]; National Basic Research
   Program (973 Program) of China [2009CB320907]; National Key Technology
   R&D Program of China [2012BAH18B03]; Division Of Computer and Network
   Systems; Direct For Computer & Info Scie & Enginr [0953682] Funding
   Source: National Science Foundation
FX Manuscript received May 27, 2012; revised September 12, 2012; accepted
   November 07, 2012. Date of publication February 20, 2013; date of
   current version September 13, 2013. This work was supported by Natural
   Science Foundation of China under contract No. 61071082, National Basic
   Research Program (973 Program) of China under contract No. 2009CB320907
   and National Key Technology R&D Program of China under Grant
   2012BAH18B03. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Pal Halvorsen.
CR [Anonymous], 2007, G1070 ITUM
   [Anonymous], 1975, QUEUEING SYST
   [Anonymous], TEXT GRAB WIND
   [Anonymous], 2003, REC M 1645 FRAM OV O
   Baset S., 2006, IEEE INT C COMPUTER, P1, DOI DOI 10.1109/INFOCOM.2006.312
   BONFIGLIO D., 2008, INFOCOM, P261, DOI [DOI 10.1109/INF0C0M.2008.61, 10.1109/INFOCOM.2008.61, DOI 10.1109/INFOCOM.2008.61]
   Bu T., 2006, P IEEE INFOCOM
   CAO J, 2002, P IEEE INFOCOM
   Cardwell N., 1998, MODELLING PERFORMANC
   Chen K., 2006, P ACM SIGCOMM OCT, V36
   Cicco L. D., 2008, P IEEE C DEC CONTR D
   De Cicco L, 2011, COMPUT NETW, V55, P558, DOI 10.1016/j.comnet.2010.09.010
   e2eSoft, VCAM WEBC EM
   Floyd S, 1999, IEEE ACM T NETWORK, V7, P458, DOI 10.1109/90.793002
   Google Inc, ON2 VID COD
   Guha S., 2006, Proceedings of The 5th International Workshop on Peer-to-Peer Systems (IPTPS'06), P1
   Hu N., 2004, P 2004 C APPL TECHN
   Huang TY, 2010, IEEE NETWORK, V24, P42, DOI 10.1109/MNET.2010.5430143
   Huang TY, 2009, IEEE INFOCOM SER, P1179, DOI 10.1109/INFCOM.2009.5062031
   Jain M., 2002, P PASSIVE ACTIVE MEA, P14, DOI DOI 10.1109/JSAC.2003.814505
   Microsoft Resarch Asia, NETW EM WIND TOOLK N
   Morris R., 2004, MODEL ANAL ROLES NET
   Skype Inc, SKYP FEAT
   Tirumala Ajay., IPERF
   Yamagishi K., 2006, GLOB TEL C 2006 GLOB, P1
NR 25
TC 28
Z9 33
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2013
VL 15
IS 6
BP 1446
EP 1457
DI 10.1109/TMM.2013.2247988
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 222XH
UT WOS:000324765400019
DA 2024-07-18
ER

PT J
AU Aggarwal, V
   Gopalakrishnan, V
   Jana, R
   Ramakrishnan, KK
   Vaishampayan, VA
AF Aggarwal, Vaneet
   Gopalakrishnan, Vijay
   Jana, Rittwik
   Ramakrishnan, K. K.
   Vaishampayan, Vinay A.
TI Optimizing Cloud Resources for Delivering IPTV Services Through
   Virtualization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cloud computing; IPTV; Live TV; Video-on-Demand; optimization; earliest
   deadline first; server-capacity region
AB Virtualized cloud-based services can take advantage of statistical multiplexing across applications to yield significant cost savings. However, achieving similar savings with real-time services can be a challenge. In this paper, we seek to lower a provider's costs for real-time IPTV services through a virtualized IPTV architecture and through intelligent time-shifting of selected services.
   Using Live TV and Video-on-Demand (VoD) as examples, we show that we can take advantage of the different deadlines associated with each service to effectively multiplex these services. We provide a generalized framework for computing the amount of resources needed to support multiple services, without missing the deadline for any service. We construct the problem as an optimization formulation that uses a generic cost function. We consider multiple forms for the cost function (e. g., maximum, convex and concave functions) reflecting the cost of providing the service. The solution to this formulation gives the number of servers needed at different time instants to support these services. We implement a simple mechanism for time-shifting scheduled jobs in a simulator and study the reduction in server load using real traces from an operational IPTV network. Our results show that we are able to reduce the load by similar to 24% (compared to a possible similar to 31.3% as predicted by the optimization framework).
C1 [Aggarwal, Vaneet; Gopalakrishnan, Vijay; Jana, Rittwik; Ramakrishnan, K. K.; Vaishampayan, Vinay A.] AT&T Labs Res, Florham Pk, NJ 07932 USA.
C3 AT&T
RP Aggarwal, V (corresponding author), AT&T Labs Res, Florham Pk, NJ 07932 USA.
EM vaneet@research.att.com; gvijay@research.att.com;
   rjana@research.att.com; kkrama@research.att.com; vinay@research.att.com
RI ; Aggarwal, Vaneet/A-4843-2017
OI Ramakrishnan, Kadangode/0000-0003-1849-5155; Aggarwal,
   Vaneet/0000-0001-9131-4723; Vaishampayan, Vinay/0000-0001-7781-0990
CR Aggarwal V., 2012, P IEEE INT C COMM SY
   Aggarwal V., 2011, P IEEE C COMP COMM W
   Banodkar D., 2008, P IEEE COMSWARE JAN
   Lagar-Cavilla HA, 2011, ACM T COMPUT SYST, V29, DOI 10.1145/1925109.1925111
   RAMAMURTHY G, 1991, IEEE T COMMUN, V39, P1107, DOI 10.1109/26.87216
   Sergeev SI, 2007, AUTOMAT REM CONTR+, V68, P399, DOI 10.1134/S0005117907030034
   Stankovic J. A., 1998, Deadline Scheduling for RealTime Systems EDF and Related Algorithms
   Thoai N. V., 1980, MATH OPER RES, V5
   Tuy H., 1964, SOV MATH, V5, P1437
NR 9
TC 23
Z9 26
U1 0
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2013
VL 15
IS 4
BP 789
EP 801
DI 10.1109/TMM.2013.2240287
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 148FK
UT WOS:000319228500008
DA 2024-07-18
ER

PT J
AU Wang, P
   Dai, R
   Akyildiz, IF
AF Wang, Pu
   Dai, Rui
   Akyildiz, Ian F.
TI A Differential Coding-Based Scheduling Framework for Wireless Multimedia
   Sensor Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Differential coding; scheduling; spatial correlation; wireless
   multimedia sensor networks
ID RESOURCE-ALLOCATION; ALGORITHMS; INFORMATION
AB In wireless multimedia sensor networks (WMSNs), visual correlation exists among multiple nearby cameras, thus leading to considerable redundancy in the collected images. This paper proposes a differential coding-based scheduling framework for efficiently gathering visually correlated images. This framework consists of two components including MinMax Degree Hub Location (MDHL) and Maximum Lifetime Scheduling (MLS). The MDHL problem aims to find the optimal locations for the multimedia processing hubs, which operate on different channels for concurrently collecting images from adjacent cameras, such that the number of channels required for frequency reuse is minimized. After associating camera sensors with proper hubs, the MLS problem targets at designing a schedule for the cameras such that the network lifetime of the cameras is maximized by letting highly correlated cameras perform differential coding on the fly. It is proven in this paper that the MDHL problem is NP-complete, and the MLS problem is NP-hard. Consequently, approximation algorithms are proposed to provide bounded performance. Since the designed algorithms only take the camera settings as inputs, they are independent of specific multimedia applications. Experiments and simulations show that the proposed differential coding-based scheduling can effectively enhance the network throughput and the energy efficiency of camera sensors.
C1 [Wang, Pu; Akyildiz, Ian F.] Georgia Inst Technol, Sch Elect & Comp Engn, Broadband Wirless Networking Lab, Atlanta, GA 30332 USA.
   [Dai, Rui] N Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA.
C3 University System of Georgia; Georgia Institute of Technology; North
   Dakota State University Fargo
RP Wang, P (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Broadband Wirless Networking Lab, Atlanta, GA 30332 USA.
EM pwang40@ece.gatech.edu; rui.dai@ndsu.edu; ian@ece.gatech.edu
RI Wang, Pu/ABD-6654-2021; Akyildiz, Ian F/G-7136-2011; Akyildiz,
   Ian/ABD-5310-2021
OI Wang, Pu/0000-0003-1988-5016
FU National Science Foundation [ECCS-0701559]
FX This work was supported by the National Science Foundation under Grant
   ECCS-0701559. The associate editor coordinating the review of this
   manuscript and approving it for publication was Eckehard G. Steinbach.
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Casares M, 2011, IEEE T CIRC SYST VID, V21, P1438, DOI 10.1109/TCSVT.2011.2162762
   Cui SG, 2005, IEEE ICC, P3278
   Dai R, 2009, IEEE T MULTIMEDIA, V11, P1148, DOI 10.1109/TMM.2009.2026100
   Dam T., 2003, the 1st International Conference on Embedded Networked Sensor Systems, P171, DOI DOI 10.1145/958491.958512
   Dieber B, 2011, IEEE T CIRC SYST VID, V21, P1424, DOI 10.1109/TCSVT.2011.2162770
   Fortet R., 1960, Revue Francaise dAutomatique, dInformatique et de Recherche Oprationnelle, V4, P17
   GOEMANS MX, 1994, SIAM J DISCRETE MATH, V7, P656, DOI 10.1137/S0895480192243516
   Gould R., 1988, Graph Theory
   He ZH, 2006, IEEE T CIRC SYST VID, V16, P590, DOI 10.1109/TCSVT.2006.873154
   Janssen J, 1999, IEEE T VEH TECHNOL, V48, P533, DOI 10.1109/25.752578
   Kuhn F., 2006, P 25 ACM S PRINC DIS, p7C15
   Kulkarni SS, 2004, 24TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P604, DOI 10.1109/ICDCSW.2004.1284094
   Nunes Mario, 2007, 2007 32nd IEEE Conference on Local Computer Networks, P239
   Parthasarathy S, 2004, LECT NOTES COMPUT SC, V3328, P447
   RAGHAVAN P, 1987, COMBINATORICA, V7, P365, DOI 10.1007/BF02579324
   Saxena N, 2008, IEEE VTS VEH TECHNOL, P183, DOI 10.1109/VETECS.2008.50
   Shiang HP, 2010, IEEE T CIRC SYST VID, V20, P505, DOI 10.1109/TCSVT.2009.2035837
   Wang P, 2011, IEEE INFOCOM SER, P2489, DOI 10.1109/INFCOM.2011.5935072
   Wang P, 2011, IEEE T MULTIMEDIA, V13, P388, DOI 10.1109/TMM.2010.2100374
   Wang Pu., 2010, INFOCOM, P2106
   Ye W, 2004, IEEE ACM T NETWORK, V12, P493, DOI 10.1109/TNET.2004.828953
   Younis O, 2004, IEEE T MOBILE COMPUT, V3, P366, DOI 10.1109/TMC.2004.41
   Yu C, 2010, IEEE T IMAGE PROCESS, V19, P2042, DOI 10.1109/TIP.2010.2046794
NR 24
TC 19
Z9 22
U1 0
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2013
VL 15
IS 3
BP 684
EP 697
DI 10.1109/TMM.2012.2236304
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 109ZM
UT WOS:000316410900018
DA 2024-07-18
ER

PT J
AU Mosleh, A
   Bouguila, N
   Ben Hamza, A
AF Mosleh, Ali
   Bouguila, Nizar
   Ben Hamza, A.
TI Video Completion Using Bandlet Transform
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Bandlets; inpainting; motion; video completion
ID ADAPTIVE SPARSE RECONSTRUCTIONS; IMAGE
AB In this paper, we address the video completion problem for two general cases: 1) filling-in the missing regions of videos captured by a non-stationary camera, and 2) filling-in the missing part of video sequences recorded by a stationary camera. For each case, a novel video completion technique based on the bandlet transform is presented. In the first case, a priority-based exemplar algorithm, which applies the bandlet transform and its generated coefficients along with motion information, is used to fill-in the occluded moving object or the removed region. In the second case, our proposed method is followed by a foreground/background segmentation preprocessing step to generate moving objects and background frames in order to facilitate the video completion task. The technique fills-in the background frames after removing objects by means of a precise optimization in the bandlet transform domain. Then, the occluded part of a moving object is completed by a priority-based algorithm which applies frames' geometry properties using the bandlet transform. Our experimental results indicate that the proposed video completion technique maintains both the spatial and temporal consistency and also demonstrate the effectiveness of the bandlet transform in video completion.
C1 [Mosleh, Ali] Concordia Univ, Fac Engn & Comp Sci, Dept Elect & Comp Engn, Montreal, PQ H3G 2W1, Canada.
   [Bouguila, Nizar; Ben Hamza, A.] Concordia Univ, Fac Engn & Comp Sci, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 2W1, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Mosleh, A (corresponding author), Concordia Univ, Fac Engn & Comp Sci, Dept Elect & Comp Engn, Montreal, PQ H3G 2W1, Canada.
EM mos_ali@encs.concordia.ca; bouguila@ciise.con-cordia.ca;
   hamza@ciise.concordia.ca
RI Bouguila, Nizar/AGN-5929-2022; Bouguila, Nizar/AAJ-2518-2020; Hamza,
   Abdessamad Ben/G-4571-2013
OI Ben Hamza, Abdessamad/0000-0002-3778-8167; Mosleh,
   Ali/0000-0003-4298-0126
FU NSERC
FX This work was supported in part by NSERC Discovery grants. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Dr. Feng Wu.
CR Alatas O, 2007, IEEE T CIRC SYST VID, V17, P584, DOI 10.1109/TCSVT.2007.893832
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   [Anonymous], 1993, 11 ISOIEC
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bertalmío M, 2006, IEEE T IMAGE PROCESS, V15, P1934, DOI 10.1109/TIP.2006.877067
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Cheung SCS, 2006, IEEE IMAGE PROC, P705, DOI 10.1109/ICIP.2006.312432
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Ghoniem M, 2009, IEEE IMAGE PROC, P1349, DOI 10.1109/ICIP.2009.5413568
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P539, DOI 10.1109/TIP.2005.863057
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P555, DOI 10.1109/TIP.2005.863055
   Jia JY, 2006, IEEE T PATTERN ANAL, V28, P832, DOI 10.1109/TPAMI.2006.108
   Jia JY, 2003, PROC CVPR IEEE, P643
   Jia YT, 2005, VISUAL COMPUT, V21, P601, DOI 10.1007/s00371-005-0313-3
   Le Pennec E, 2005, MULTISCALE MODEL SIM, V4, P992, DOI 10.1137/040619454
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Ling CH, 2011, IEEE T MULTIMEDIA, V13, P292, DOI 10.1109/TMM.2010.2095000
   Mallat S, 2008, COMMUN PUR APPL MATH, V61, P1173
   Mallat S, 2007, NUMER ALGORITHMS, V44, P205, DOI 10.1007/s11075-007-9092-4
   Mosleh A., 2011, P IEEE INT C MULT EX, P1
   Patwardhan K., 2005, P IEEE INT C IMAGE P, V2, P69
   Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343
   Peyré G, 2005, ACM T GRAPHIC, V24, P601, DOI 10.1145/1073204.1073236
   Shih T., 2006, Proceedings of ACM International Conference on Multimedia, P133
   Shih TK, 2009, IEEE T CIRC SYST VID, V19, P347, DOI 10.1109/TCSVT.2009.2013519
   Starck JL, 2004, ADV IMAG ELECT PHYS, V132, P287, DOI 10.1016/S1076-5670(04)32006-9
   Tang NC, 2011, IEEE T MULTIMEDIA, V13, P602, DOI 10.1109/TMM.2011.2112642
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Zhang YJ, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P516
NR 30
TC 13
Z9 16
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2012
VL 14
IS 6
BP 1591
EP 1601
DI 10.1109/TMM.2012.2198802
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 046YE
UT WOS:000311800400009
DA 2024-07-18
ER

PT J
AU Ren, SL
   van der Schaar, M
AF Ren, Shaolei
   van der Schaar, Mihaela
TI Pricing and Investment for Online TV Content Platforms
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Online TV content platforms; pricing; two-sided market
ID CONTENT DELIVERY NETWORK; INTERNET; ACCESS
AB Online television (TV) market has been expanding rapidly over the last few years and provided TV studios with a cost-effective and reliable channel for the delivery of high-quality TV content. To maximize profit by setting up an online TV content platform, two major challenges are faced by the platform owner: what is the optimal investment (e. g., how many hosting servers, bandwidth acquisition) and how to price TV content producers who utilize the platform as a channel to distribute their content. To address these two challenges, we first derive the optimal pricing policy based on the widely-adopted "pay-per-usage" model, and then formalize and solve the optimal investment decision problem. Rationality of self-interested TV content producers and audiences is also taken into account. Specifically, we first use a model with a representative content viewer to determine how many times a TV content with a certain quality is watched. Then, by modeling the content providers as self-interested agents making independent production decisions, we show that for any price charged by the platform, there always exists a unique equilibrium in the content production stage, which makes it possible for the platform owner to maximize its profit without uncertainties because of the unique outcome in the content producers' decision stage. Finally, we develop an algorithm to derive the optimal price and then formalize the investment decision problem to maximize the platform's profit.
C1 [Ren, Shaolei] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33174 USA.
   [van der Schaar, Mihaela] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA.
C3 State University System of Florida; Florida International University;
   University of California System; University of California Los Angeles
RP Ren, SL (corresponding author), Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33174 USA.
EM sren@cs.fiu.edu; mihaela@ee.ucla.edu
RI Ren, Shaolei/K-6526-2013
OI Ren, Shaolei/0000-0001-9003-4324
FU National Science Foundation [0830556]; Division of Computing and
   Communication Foundations; Direct For Computer & Info Scie & Enginr
   [0830556] Funding Source: National Science Foundation
FX This work was supported in part by the National Science Foundation by
   Grant 0830556. The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Oscar Bonastre.
CR [Anonymous], 1993, Elements of algebraic topology
   Bertini M, 2006, IEEE T MULTIMEDIA, V8, P433, DOI 10.1109/TMM.2006.870762
   Boyd S., 2004, CONVEX OPTIMIZATION
   Cranor CD, 2001, IEEE INTERNET COMPUT, V5, P66, DOI 10.1109/4236.939452
   DIXIT AK, 1977, AM ECON REV, V67, P297
   Evans G.W., 2012, Learning and Expectations in Macroeconomics
   Garcia-Valverde T., 2010, P INT JOINT C NEUR N
   Hagiu Andrei., 2007, Review of Network Economics, V6, DOI [10.2202/1446-9022.1113, DOI 10.2202/1446-9022.1113]
   Hallak J. C., EFFECT CROSS COUNTRY
   Hande P., 2009, P IEEE INFOCOM
   Jin Y., 2008, P NETECON AUG
   Kim JY, 2010, IEEE T MULTIMEDIA, V12, P337, DOI 10.1109/TMM.2010.2046362
   Kontothanassis L, 2004, P IEEE, V92, P1408, DOI 10.1109/JPROC.2004.832956
   Li Y., 2003, P S APPL INT
   Liu JC, 2003, IEEE MULTIMEDIA, V10, P22, DOI 10.1109/MMUL.2003.1167919
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Moreno BM, 2006, COMPUT COMMUN, V29, P2396, DOI 10.1016/j.comcom.2006.02.016
   Moreno B. Molina, 2004, COMPUT COMMUN, V27, P1401
   Musacchio J., 2009, TEL POL RES C
   Musacchio J, 2009, REV NETW ECON, V8, P22
   Osborne M. J., 1994, COURSE GAME THOEORY
   Parsons J., 2004, P AAAI WORKSH SEM WE
   Ren S., PRICING INVESTMENT O
   Rochet JC, 2006, RAND J ECON, V37, P645, DOI 10.1111/j.1756-2171.2006.tb00036.x
   Shetty N, 2010, IEEE ACM T NETWORK, V18, P1725, DOI 10.1109/TNET.2010.2048757
   Shirazi H, 2010, IEEE T BROADCAST, V56, P44, DOI 10.1109/TBC.2009.2036956
   Sun HM, 2008, IEEE T MULTIMEDIA, V10, P1109, DOI 10.1109/TMM.2008.2001381
   van der Schaar M., 2007, MULTIMEDIA IP WIRELE
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Xu Y., 2010, P INT C ED NETW TECH
   Zhou C., 2004, P IEEE WCNC
NR 31
TC 6
Z9 8
U1 4
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2012
VL 14
IS 6
BP 1566
EP 1578
DI 10.1109/TMM.2012.2217120
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 046YE
UT WOS:000311800400007
DA 2024-07-18
ER

PT J
AU Li, L
   Jiang, SQ
   Huang, QM
AF Li, Liang
   Jiang, Shuqiang
   Huang, Qingming
TI Learning Hierarchical Semantic Description Via Mixed-Norm Regularization
   for Image Understanding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image representation; large-scale systems; pattern analysis; semantic
   web; statistical learning
ID CODEBOOKS; OBJECT
AB This paper proposes a new perspective-Vicept representation to solve the problem of visual polysemia and concept polymorphism in the large-scale semantic image understanding. Vicept characterizes the membership probability distribution between visual appearances and semantic concepts, and forms a hierarchical representation of image semantic from local to global. In the implementation, incorporating group sparse coding, visual appearance is encoded as a weighted sum of dictionary elements, which could obtain more accurate image representation with sparsity at the image level. To obtain discriminative Vicept descriptions with structural sparsity, mixed-norm regularization is adopted in the optimization problem for learning the concept membership distribution of visual appearance. Furthermore, we introduce a novel image distance measurement based on the hierarchical Vicept description, where different levels of Vicept distance are fused together by multi-level separability analysis. Finally, the wide applications of Vicept description are validated in our experiments, including large-scale semantic image search, image annotation, and semantic image re-ranking.
C1 [Li, Liang; Jiang, Shuqiang] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Huang, Qingming] Chinese Acad Sci, Grad Univ, Beijing 100190, Peoples R China.
   [Huang, Qingming] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Li, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM lli@jdl.ac.cn; sqjiang@jdl.ac.cn; qmhuang@jdl.ac.cn
RI Huang, Qingming/GLR-3473-2022
OI Huang, Qingming/0000-0002-3025-7099; Li, Liang/0000-0002-1943-8219
FU National Basic Research Program of China (973 Program) [2012CB316400];
   National Natural Science Foundation of China [61025011, 61035001,
   61070108, 60833006]; Beijing Natural Science Foundation [4111003]
FX This work was supported in part by National Basic Research Program of
   China (973 Program): 2012CB316400, in part by National Natural Science
   Foundation of China: 61025011, 61035001, 61070108, and 60833006, and in
   part by Beijing Natural Science Foundation: 4111003.
CR [Anonymous], P NIPS
   [Anonymous], IEEE CVPR JUN
   [Anonymous], 2007, P 2007 IEEE C COMPUT
   [Anonymous], 2008, P IEEE CVPR
   [Anonymous], 743 U CAL
   [Anonymous], IEEE 11 INT C COMP V
   [Anonymous], P ACM MULT
   [Anonymous], P ECCV HER CRET GREE
   [Anonymous], 2007, P IEEE CVPR
   [Anonymous], P NIPS
   [Anonymous], Pattern Classification
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bronstein AM, 2010, LECT NOTES COMPUT SC, V6312, P197, DOI 10.1007/978-3-642-15552-9_15
   Cai HP, 2010, PROC CVPR IEEE, P2320, DOI 10.1109/CVPR.2010.5539918
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duchi J., 2009, P 26 ANN INT C MACHI, P297
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Li L, 2011, PROC CVPR IEEE, P825, DOI 10.1109/CVPR.2011.5995570
   Liu Dong., 2010, Proceedings of the International Conference on Multimedia, P491
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Negahban S., 2008, P 21 INT C NEURAL IN
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Nister David, 2006, CVPR
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Qi GJ, 2011, PROC CVPR IEEE, P897, DOI 10.1109/CVPR.2011.5995312
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Torralba A., 2008, PROC CVPR 08, P1
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   van Gemert JC, 2010, COMPUT VIS IMAGE UND, V114, P450, DOI 10.1016/j.cviu.2009.08.004
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang ZX, 2010, LECT NOTES COMPUT SC, V6311, P706, DOI 10.1007/978-3-642-15549-9_51
   Weinberger K.Q., 2008, Proceedings of the 25th international conference on Machine learning, P1160, DOI DOI 10.1145/1390156.1390302
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
NR 45
TC 56
Z9 60
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2012
VL 14
IS 5
BP 1401
EP 1413
DI 10.1109/TMM.2012.2194993
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 008XT
UT WOS:000308990600003
DA 2024-07-18
ER

PT J
AU Huurnink, B
   Snoek, CGM
   de Rijke, M
   Smeulders, AWM
AF Huurnink, Bouke
   Snoek, Cees G. M.
   de Rijke, Maarten
   Smeulders, Arnold W. M.
TI Content-Based Analysis Improves Audiovisual Archive Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Benchmark testing; content based retrieval; multimedia databases; search
   problems
ID INFORMATION-RETRIEVAL; SEARCH
AB Content-based video retrieval is maturing to the point where it can be used in real-world retrieval practices. One such practice is the audiovisual archive, whose users increasingly require fine-grained access to broadcast television content. In this paper, we take into account the information needs and retrieval data already present in the audiovisual archive, and demonstrate that retrieval performance can be significantly improved when content-based methods are applied to search. To the best of our knowledge, this is the first time that the practice of an audiovisual archive has been taken into account for quantitative retrieval evaluation. To arrive at our main result, we propose an evaluation methodology tailored to the specific needs and circumstances of the audiovisual archive, which are typically missed by existing evaluation initiatives. We utilize logged searches, content purchases, session information, and simulators to create realistic query sets and relevance judgments. To reflect the retrieval practice of both the archive and the video retrieval community as closely as possible, our experiments with three video search engines incorporate archive-created catalog entries as well as state-of-the-art multimedia content analysis results. A detailed query-level analysis indicates that individual content-based retrieval methods such as transcript-based retrieval and concept-based retrieval yield approximately equal performance gains. When combined, we find that content-based video retrieval incorporated into the archive's practice results in significant performance increases for shot retrieval and for retrieving entire television programs. The time has come for audiovisual archives to start accommodating content-based video retrieval methods into their daily practice.
C1 [Smeulders, Arnold W. M.] Ctr Wiskunde & Informat CWI, Amsterdam, Netherlands.
   [Huurnink, Bouke; Snoek, Cees G. M.; de Rijke, Maarten] Univ Amsterdam, Intelligent Syst Lab Amsterdam, Amsterdam, Netherlands.
C3 University of Amsterdam
RP Huurnink, B (corresponding author), Netherlands Inst Sound & Vis, Hilversum, Netherlands.
EM bhuurnink@uva.nl; cgmsnoek@uva.nl; derijke@uva.nl;
   Arnold.Smeulders@cwi.nl
OI Snoek, Cees/0000-0001-9092-1556; de Rijke, Maarten/0000-0002-1086-0202
FU European Union; CIP ICT-PSP [250430]; European Community [258191,
   288024]; IM-Pact BeeldCanon; STW SEARCHER; Netherlands Organisation for
   Scientific Research (NWO) [612.061.814, 612.061.815, 640.004.802,
   380-70-011]; Center for Creation, Content and Technology (CCCT); Service
   Innovation ICT program; CLARIN-nl program; Dutch national program
   COMMIT; ESF Research Network
FX This work was supported by the European Union's ICT Policy Support
   Programme as part of the Competitiveness and Innovation Framework
   Programme, CIP ICT-PSP under grant agreement nr 250430, the European
   Community's Seventh Framework Programme (FP7/2007-2013) under grant
   agreements nr 258191 (PROMISE Network of Excellence) and 288024
   (LiMoSINe project), IM-Pact BeeldCanon, STW SEARCHER, the Netherlands
   Organisation for Scientific Research (NWO) project nrs 612.061.814,
   612.061.815, 640.004.802, 380-70-011, the Center for Creation, Content
   and Technology (CCCT), the Hyperlocal Service Platform project funded by
   the Service Innovation & ICT program, the WAHSP project funded by the
   CLARIN-nl program, the Dutch national program COMMIT under projects
   Infiniti and SEALINCMedia, and by the ESF Research Network Program
   ELIAS. The associate editor coordinating the review of this manuscript
   and approving it for publication was Dr. Shin'ichi Satoh.
CR Allauzen A, 2005, INT CONF ACOUST SPEE, P1013
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   Brown M. G., 1995, P ACM MULT SAN FRANC
   Carmichael J., 2008, P CBMI, P93
   Carter S., 2008, P IWSLT, P104
   Chaisorn L., 2010, P TRECVID
   Chen X., 2010, P TRECVID
   de Jong FAG, 2007, IEEE T CIRC SYST VID, V17, P365, DOI 10.1109/TCSVT.2007.890834
   De Rooij O., 2008, P ACM INT C IM VID R, P485
   Despres J., 2009, P INTERSPEECH
   Foote J, 1999, MULTIMEDIA SYST, V7, P2, DOI 10.1007/s005300050106
   Garofolo J. S., 2000, Information Technology: Eighth Text REtrieval Conference (TREC-8) (NIST SP 500-246), P107
   Hauff C., 2008, P 17 ACM C INF KNOWL, P439
   Hauptmann A, 2005, LECT NOTES COMPUT SC, V3568, P215
   Hauptmann Alexander., 2007, CIVR 07, P627
   He JY, 2008, LECT NOTES COMPUT SC, V4956, P689
   HOFMANN K, 2010, P SIGIR, P761
   Huijbregts M., 2007, LNCS
   Huurnink B., 2010, P CLEF
   Huurnink B., 2010, JASIST, V61
   Huurnink B., 2010, P CIVR
   Huurnink B., 2007, P 9 ACM SIGMM INT WO, P177
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   Kennedy L, 2008, P IEEE, V96, P567, DOI 10.1109/JPROC.2008.916345
   Larson M., 2010, MEDIAEVAL 2010 WORKS
   Larson M, 2010, LECT NOTES COMPUT SC, V6242, P354, DOI 10.1007/978-3-642-15751-6_46
   Lux M., 2010, P TRECVID
   Mei T., 2008, P TRECVID GAITH MD
   Monz C, 2002, LECT NOTES COMPUT SC, V2406, P262
   Natsev A., 2005, 13th Annual ACM International Conference on Multimedia, P598, DOI 10.1145/1101149.1101288
   Neo SY, 2006, LECT NOTES COMPUT SC, V4071, P143
   Oomen J, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.60
   Petersohn C., 2004, P TRECVID
   Ponte JM, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   Radlinski F., 2008, Proceedings of the 17th ACM Conference on Information and Knowledge Management. CIKM'08, P43, DOI [DOI 10.1145/1458082.1458092, DOI 10.1145/1458082.1458092.21K, 10.1145/1458082.1458092]
   Salton G., 1993, SIGIR Forum, P49
   Sjoberg M., 2010, P TRECVID
   Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek C. G. M., 2008, P TRECVID GAITH MD
   Snoek CGM, 2008, IEEE MULTIMEDIA, V15, P86, DOI 10.1109/MMUL.2008.21
   Snoek CGM, 2010, COMPUTER, V43, P76, DOI 10.1109/MC.2010.183
   Tan H., 2011, P ICMR, P15
   Terris O., 1998, J FILM PRESERV, V56, P54
   Tian XM, 2011, IEEE T MULTIMEDIA, V13, P639, DOI 10.1109/TMM.2011.2111363
   Tsikrika T, 2011, MULTIMED TOOLS APPL, V55, P27, DOI 10.1007/s11042-010-0584-1
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Voorhees EM, 2002, LECT NOTES COMPUT SC, V2406, P355
   Wactlar HD, 1999, COMPUTER, V32, P66, DOI 10.1109/2.745722
   Wei XY, 2008, IEEE T MULTIMEDIA, V10, P1085, DOI 10.1109/TMM.2008.2001382
   Westerveld T., 2004, THESIS U TWENTE ENSC
   Wilkins P., 2009, THESIS DUBLIN CITY U
   Wilkinson R., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P311
   Wright R., 2001, Milano, Archives Museum Informatics, P47
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
   Yang J, 2004, LECT NOTES COMPUT SC, V3115, P270
   Yang J., 2006, PROC ACM INT WORKSHO, P33
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
NR 60
TC 11
Z9 13
U1 1
U2 26
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2012
VL 14
IS 4
BP 1166
EP 1178
DI 10.1109/TMM.2012.2193561
PN 2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 976QM
UT WOS:000306599400005
DA 2024-07-18
ER

PT J
AU de Fez, I
   Fraile, F
   Belda, R
   Guerri, JC
AF de Fez, Ismael
   Fraile, Francisco
   Belda, Roman
   Carlos Guerri, Juan
TI Analysis and Evaluation of Adaptive LDPC AL-FEC Codes for Content
   Download Services
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Multimedia and Expo (ICME)
CY JUL 11-15, 2011
CL Univ Ramon Llull, La Salle, Barcelona, SPAIN
SP IEEE, IEEE Signal Proc Soc, IEEE Circuits & Syst Soc, IEEE Comp Soc, IEEE Commun Soc
HO Univ Ramon Llull, La Salle
DE Adaptive codes; application layer-forward error correction (AL-FEC);
   file delivery over unidirectional transport (FLUTE); low density parity
   check (LDPC)
AB This paper proposes the use of adaptive low density parity check (LDPC) application layer-forward error correction (AL-FEC) codes for content download services over erasure channels. In adaptive LDPC codes, clients inform the content download server of the losses they are experiencing. Using this information, the server makes forward error correction (FEC) parity symbols available to the client at an optimum code rate. This paper presents an analytical model of the proposed adaptive LDPC codes. The model is validated through measurements realized with an application prototype. In addition, results show the performance of these codes in different scenarios, compared to the performance of non-adaptive AL-FEC, optimum LDPC AL-FEC codes, and an almost ideal rateless code. Adaptive LDPC AL-FEC codes achieve download times similar to almost ideal rateless codes with less coding complexity, at the expense of an interaction channel between server and clients.
C1 [de Fez, Ismael; Fraile, Francisco; Belda, Roman; Carlos Guerri, Juan] Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia
RP de Fez, I (corresponding author), Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Valencia 46022, Spain.
EM isdefez@iteam.upv.es; ffraile@iteam.upv.es; robelor@iteam.upv.es;
   jcguerri@dcom.upv.es
RI Belda, Román/IAM-8676-2023; de+Fez+Lava, Ismael/AAJ-1048-2020; Fraile,
   Francisco/AAM-6680-2020; Guerri, Juan Carlos/K-9659-2014
OI Fraile, Francisco/0000-0003-0852-8953; Guerri, Juan
   Carlos/0000-0002-5807-1923; de Fez, Ismael/0000-0002-1337-1973; Belda,
   Roman/0000-0003-2244-2371
CR Bai Haowei, 2003, IEEE Communications Surveys & Tutorials, V5, P2, DOI 10.1109/COMST.2003.5341334
   Byers J. W., 1998, Computer Communication Review, V28, P56, DOI 10.1145/285243.285258
   de Fez I., 2011, MULTIMEDIA TOOLS APP
   de Fez I, 2011, IEEE INT CON MULTI
   Digital Video Broadcasting (DVB), 2009, 102034 ETSI TS
   DOWNEY AB, 2001, 9 INT S MOD AN SIM C
   GALLAGER RG, 1962, IRE T INFORM THEOR, V8, P21, DOI 10.1109/tit.1962.1057683
   Lacan J., 2009, IETF RFC, V5510
   Lam W, 2003, SYM REL DIST SYST, P5
   Luby M., 2011, IETF RFC, V6330
   Luby M., 2007, IETF RFC
   Paila T., 2004, IETF RFC, V3926
   Paolini Enrico, 2008, 2008 4th Advanced Satellite Mobile Systems (ASMS), P274, DOI 10.1109/ASMS.2008.54
   Peltotalo J., 2009, IEEE INT S BROADB MU
   Peltotalo J, 2007, INT J COMMUN SYST, V20, P633, DOI 10.1002/dac.835
   Richardson TJ, 2001, IEEE T INFORM THEORY, V47, P619, DOI 10.1109/18.910578
   Roca V., 2003, 5 INT WORKSH NETW GR
   ROCA V, 2004, RR5225 INRIA
   Roca V., 2008, IETF RFC, V5170
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Watson M., 2009, IETF RFC, V5445
   Watson M., 2007, IETF RFC, V5052
NR 22
TC 16
Z9 16
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2012
VL 14
IS 3
BP 641
EP 650
DI 10.1109/TMM.2012.2190392
PN 1
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 943ZG
UT WOS:000304166300015
OA Green Published
DA 2024-07-18
ER

PT J
AU Yeh, YR
   Lin, TC
   Chung, YY
   Wang, YCF
AF Yeh, Yi-Ren
   Lin, Ting-Chu
   Chung, Yung-Yu
   Wang, Yu-Chiang Frank
TI A Novel Multiple Kernel Learning Framework for Heterogeneous Feature
   Fusion and Variable Selection
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Multimedia and Expo (ICME)
CY JUL 11-15, 2011
CL Univ Ramon Llull, La Salle, Barcelona, SPAIN
SP IEEE, IEEE Signal Proc Soc, IEEE Circuits & Syst Soc, IEEE Comp Soc, IEEE Commun Soc
HO Univ Ramon Llull, La Salle
DE Feature fusion; multiple kernel learning; variable selection
ID SCALE
AB We propose a novel multiple kernel learning (MKL) algorithm with a group lasso regularizer, called group lasso regularized MKL (GL-MKL), for heterogeneous feature fusion and variable selection. For problems of feature fusion, assigning a group of base kernels for each feature type in an MKL framework provides a robust way in fitting data extracted from different feature domains. Adding a mixed norm constraint (i.e., group lasso) as the regularizer, we can enforce the sparsity at the group/feature level and automatically learn a compact feature set for recognition purposes. More precisely, our GL-MKL determines the optimal base kernels, including the associated weights and kernel parameters, and results in improved recognition performance. Besides, our GL-MKL can also be extended to address heterogeneous variable selection problems. For such problems, we aim to select a compact set of variables (i.e., feature attributes) for comparable or improved performance. Our proposed method does not need to exhaustively search for the entire variable space like prior sequential-based variable selection methods did, and we do not require any prior knowledge on the optimal size of the variable subset either. To verify the effectiveness and robustness of our GL-MKL, we conduct experiments on video and image datasets for heterogeneous feature fusion, and perform variable selection on various UCI datasets.
C1 [Yeh, Yi-Ren; Lin, Ting-Chu; Chung, Yung-Yu; Wang, Yu-Chiang Frank] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 11529, Taiwan.
   [Wang, Yu-Chiang Frank] Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan.
C3 Academia Sinica - Taiwan; Academia Sinica - Taiwan
RP Yeh, YR (corresponding author), Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 11529, Taiwan.
EM yryeh@citi.sinica.edu.tw; tingchulin@citi.sinica.edu.tw;
   ychung@iastate.edu; ycwang@citi.sinica.edu.tw
CR [Anonymous], P NIPS WORKSH KERN L
   [Anonymous], 2007, Computer Vision
   [Anonymous], P IEEE INT JOINT C N
   [Anonymous], P 18 INT C MULT FIR
   [Anonymous], BRIEF DESCRIPTIONS V
   [Anonymous], 2004, P 21 INT C MACH LEAR
   Cao LL, 2009, IEEE I CONF COMP VIS, P1095, DOI 10.1109/ICCV.2009.5459401
   Chang C.C., LIBSVM: a library for support vector machines
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dileep A. D., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P717, DOI 10.1109/IJCNN.2009.5178897
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Irie G, 2010, IEEE T MULTIMEDIA, V12, P523, DOI 10.1109/TMM.2010.2051871
   Jiang W, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823748
   Kumar A., 2007, PROC IEEE INT C COMP, P1
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Nakariyakul S, 2009, PATTERN RECOGN, V42, P1932, DOI 10.1016/j.patcog.2008.11.018
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shechtman E., 2007, PROC IEEE C COMPUT V, P1
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Sun S S, 2011, P IEEE ICC, P1
   Vailaya A, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P3, DOI 10.1109/IVL.1998.694464
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Xu Zenglin., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P1145, DOI DOI 10.1145/1553374.1553520
   Yang JJ, 2009, IEEE I CONF COMP VIS, P436, DOI 10.1109/ICCV.2009.5459172
NR 34
TC 54
Z9 68
U1 1
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2012
VL 14
IS 3
BP 563
EP 574
DI 10.1109/TMM.2012.2188783
PN 1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 943ZG
UT WOS:000304166300008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ogawa, T
   Haseyama, M
AF Ogawa, Takahiro
   Haseyama, Miki
TI Missing Image Data Reconstruction Based on Adaptive Inverse Projection
   via Sparse Representation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image reconstruction; image texture analysis; interpolation; inverse
   projection; sparse representation
ID QUALITY ASSESSMENT; FILLING-IN; INTERPOLATION; ALGORITHM
AB In this paper, a missing image data reconstruction method based on an adaptive inverse projection via sparse representation is proposed. The proposed method utilizes sparse representation for obtaining low-dimensional subspaces that approximate target textures including missing areas. Then, by using the obtained low-dimensional subspaces, inverse projection for reconstructing missing areas can be derived to solve the problem of not being able to directly estimate missing intensities. Furthermore, in this approach, the proposed method monitors errors caused by the derived inverse projection, and the low-dimensional subspaces optimal for target textures are adaptively selected. Therefore, we can apply adaptive inverse projection via sparse representation to target missing textures, i.e., their adaptive reconstruction becomes feasible. The proposed method also introduces some schemes for color processing into the calculation of subspaces on the basis of sparse representation and attempts to avoid spurious color caused in the reconstruction results. Consequently, successful reconstruction of missing areas by the proposed method can be expected. Experimental results show impressive improvement of our reconstruction method over previously reported reconstruction methods.
C1 [Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
C3 Hokkaido University
RP Ogawa, T (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
EM ogawa@lmd.ist.hokudai.ac.jp; miki@ist.hokudai.ac.jp
RI Haseyama, Miki/A-6163-2012; Ogawa, Takahiro/A-5207-2012
OI Ogawa, Takahiro/0000-0001-5332-8112
FU Japan Society for the Promotion of Science (JSPS) [21300030];
   Grants-in-Aid for Scientific Research [21300030, 22700088] Funding
   Source: KAKEN
FX Manuscript received October 25, 2010; revised February 28, 2011 and May
   09, 2011; accepted July 03, 2011. Date of publication July 14, 2011;
   date of current version September 16, 2011. Some preliminary parts of
   this work appeared as a conference paper in Proceedings of 2010 IEEE
   International Conference on Multimedia and Expo (ICME2010), pp. 352-357,
   2010. This work was supported in part by Grant-in-Aid for Scientific
   Research (B) 21300030, Japan Society for the Promotion of Science
   (JSPS). The associate editor coordinating the review of this manuscript
   and approving it for publication was Dr. Homer H. Chen.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Amano T., 2007, Systems and Computers in Japan, V38, P87, DOI 10.1002/scj.10319
   [Anonymous], P IEEE COMP VIS PATT
   Aràndiga F, 2003, SIGNAL PROCESS, V83, P459, DOI 10.1016/S0165-1684(02)00445-0
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Battiato S, 2002, IMAGE VISION COMPUT, V20, P805, DOI 10.1016/S0262-8856(02)00089-6
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   DAVIS G, 1994, OPT ENG, V33, P2183, DOI 10.1117/12.173207
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fidaner I. B., SURVEY VARIATIONAL I
   Girod Bernd, 1993, P207
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351, DOI 10.1109/TPAMI.2005.181
   Kokaram A, 2004, IMAGE VISION COMPUT, V22, P165, DOI 10.1016/j.imavis.2003.07.010
   Kwok TH, 2010, IEEE T IMAGE PROCESS, V19, P3106, DOI 10.1109/TIP.2010.2052270
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mika S, 1999, ADV NEUR IN, V11, P536
   Ogawa T, 2007, IEICE T FUND ELECTR, VE90A, P1519, DOI 10.1093/ietfec/e90-a.8.1519
   Ogawa T, 2009, IEICE T FUND ELECTR, VE92A, P1950, DOI 10.1587/transfun.E92.A.1950
   PATI YC, 1993, C REC 27 AS C SIGN S, V1
   Rane SD, 2003, IEEE T IMAGE PROCESS, V12, P296, DOI 10.1109/TIP.2002.804264
   Rao BD, 2003, IEEE T SIGNAL PROCES, V51, P760, DOI 10.1109/TSP.2002.808076
   Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251
   Rares A, 2005, IEEE T IMAGE PROCESS, V14, P1454, DOI 10.1109/TIP.2005.854466
   Schölkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shen B, 2009, INT CONF ACOUST SPEE, P697, DOI 10.1109/ICASSP.2009.4959679
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   VELJKOVIC D, 2007, P IEEE INT C IM PROC, P449
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   WOHLBERG B, 2009, P IEEE INT C AC SPEE, P689
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
NR 45
TC 15
Z9 19
U1 1
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2011
VL 13
IS 5
BP 974
EP 992
DI 10.1109/TMM.2011.2161760
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 821XI
UT WOS:000295007300012
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhu, XQ
   Pan, R
   Prabhu, MS
   Dukkipati, N
   Subramanian, V
   Bonomi, F
AF Zhu, Xiaoqing
   Pan, Rong
   Prabhu, Mythili S.
   Dukkipati, Nandita
   Subramanian, Vijay
   Bonomi, Flavio
TI Layered Internet Video Adaptation (LIVA): Network-Assisted Bandwidth
   Sharing and Transient Loss Protection for Video Streaming
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Explicit congestion notification (ECN); forward error correction (FEC);
   media-aware bandwidth sharing; scalable video coding (SVC)
ID CONGESTION CONTROL; FAIRNESS
AB As video traffic increases in the Internet and competes for limited bandwidth resources, it is important to design bandwidth-sharing and loss-protection schemes that account for video characteristics, beyond the traditional paradigm of fair-rate allocation among data flows. Ideally, such a scheme should handle both persistent and transient congestion as video streaming applications demand low-latency transmissions and low packet-loss ratios. This paper presents a novel scheme, layered Internet video adaptation (LIVA), in which network nodes feed back virtual congestion levels to video senders to assist both media-aware bandwidth sharing and transient-loss protection. The video senders respond to such feedback by adapting the rates of encoded scalable bitstreams based on their respective video rate-distortion (R-D) characteristics. The same feedback is employed to calculate the amount of forward error correction (FEC) protection for combating transient losses. Simulation studies show that LIVA can minimize the total distortion of all participating video streams and hence maximize their overall quality. At steady state, video streams experience no queueing delays or packet losses. In the face of transient congestion, the network-assisted adaptive FEC promptly protects video packets from losses. Our Linux-based demonstration showcases how LIVA can be implemented in a simple manner in real systems. We also present a solution for LIVA streams to coexist with TCP flows based on explicit congestion notification signaling. Finally, our theoretical analysis guarantees system stability for an arbitrary number of streams with round-trip delays below a prescribed limit.
C1 [Zhu, Xiaoqing; Pan, Rong; Prabhu, Mythili S.; Dukkipati, Nandita; Subramanian, Vijay; Bonomi, Flavio] Cisco Syst Inc, Adv Architecture & Res Grp, San Jose, CA 95134 USA.
C3 Cisco Systems Inc
RP Zhu, XQ (corresponding author), Cisco Syst Inc, Adv Architecture & Res Grp, San Jose, CA 95134 USA.
EM xiaoqzhu@cisco.com; ropan@cisco.com; mysuryan@cisco.com;
   nanditad@stanfordalumni.org; vijaynsu@cisco.com; flavio@cisco.com
CR Adam N, 2009, 2009 JOINT URBAN REMOTE SENSING EVENT, VOLS 1-3, P129
   [Anonymous], J INTERNETWORKIN OCT
   [Anonymous], P IEEE 16 INT PACK V
   [Anonymous], CISCO VISUAL NETWORK
   [Anonymous], MAXNET THEORY IMPLEM
   [Anonymous], P IEEE 7 INT C NETW
   [Anonymous], 1449610 ITUT ISOIEC
   [Anonymous], 1449610AVC ITUT ISOI
   [Anonymous], P 4 IFIP IEEE INT C
   [Anonymous], 3448 RFC
   Böröczky L, 1999, IBM J RES DEV, V43, P511, DOI 10.1147/rd.434.0511
   Chakareski J, 2006, IEEE T MULTIMEDIA, V8, P207, DOI 10.1109/TMM.2005.864284
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   Dai M, 2006, IEEE T MULTIMEDIA, V8, P1135, DOI 10.1109/TMM.2006.884626
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   Hellge C, 2008, IEEE IMAGE PROC, P2304, DOI 10.1109/ICIP.2008.4712252
   Kang S.-R., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P123, DOI 10.1145/1065983.1066012
   Katabi D, 2002, ACM SIGCOMM COMP COM, V32, P89, DOI 10.1145/964725.633035
   Kelly FP, 1998, J OPER RES SOC, V49, P237, DOI 10.2307/3010473
   Krunz M, 1999, IEEE COMMUN MAG, V37, P40, DOI 10.1109/35.739277
   Paganini F, 2005, IEEE ACM T NETWORK, V13, P43, DOI 10.1109/TNET.2004.842216
   Papadimitriou P, 2007, COMPUT NETW, V51, P4377, DOI 10.1016/j.comnet.2007.06.018
   Ramakrishnan K., 2001, The Addition of Explicit Congestion Notification (ECN) to IP
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Tan WT, 2001, IEEE T CIRC SYST VID, V11, P373, DOI 10.1109/76.911162
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
NR 27
TC 13
Z9 16
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2011
VL 13
IS 4
BP 720
EP 732
DI 10.1109/TMM.2011.2115996
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 805EX
UT WOS:000293710300012
DA 2024-07-18
ER

PT J
AU Tan, KH
   Robinson, IN
   Culbertson, B
   Apostolopoulos, J
AF Tan, Kar-Han
   Robinson, Ian N.
   Culbertson, Bruce
   Apostolopoulos, John
TI ConnectBoard: Enabling Genuine Eye Contact and Accurate Gaze in Remote
   Collaboration
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Eye contact; gaze awareness; immersive experiences; natural interaction;
   remote collaboration
ID PERCEPTION
AB Conventional telepresence systems allow remote users to see one another and interact with shared media, but users cannot make eye contact, and gaze awareness with respect to shared media and documents is lost. In this paper, we describe a remote collaboration system based on a see-through display to create an experience where local and remote users are seemingly separated only by a vertical sheet of glass. Users can see each other and media displayed on the shared surface. Face detectors are applied on the local and remote video streams to introduce an offset in the video display so as to bring the local user's face, the local camera, and the remote user's face image into collinearity. This ensures that, when the local user looks at the remote user's image, the camera behind the see-through display captures an image with the "Mona Lisa effect," where the eyes of an image appears to follow the viewer. Experiments show that, for one-on-one meetings, our system is capable of capturing and delivering realistic, genuine eye contact as well as accurate gaze awareness with respect to shared media.
C1 [Tan, Kar-Han; Robinson, Ian N.; Culbertson, Bruce; Apostolopoulos, John] Hewlett Packard Labs, Palo Alto, CA 94304 USA.
C3 Hewlett-Packard
RP Tan, KH (corresponding author), Hewlett Packard Labs, Palo Alto, CA 94304 USA.
EM Kar-han.tan@hp.com; Ian.robinson@hp.com; Bruce.cul-bertson@hp.com;
   japos@hpl.hp.com
OI Tan, Kar Han/0000-0001-9294-2932
CR ACKER SR, 1987, J BROADCAST ELECTRON, V31, P181
   Adi MN, 2010, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2010.5444801
   [Anonymous], APPL COMPUTER VISION
   ANSTIS SM, 1969, AM J PSYCHOL, V82, P474, DOI 10.2307/1420441
   Baker H.Harlyn., 2005, ACM Trans. Multimedia Comput. Commun. Appl, V1, P190, DOI DOI 10.1145/1062253.1062258
   BUXTON B, 1990, P IFIP WG 8 4 C MULT, P11
   Chen M., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P49, DOI 10.1145/503376.503386
   Gemmell J., 2000, IEEE Multimedia, V7, P26, DOI 10.1109/93.895152
   Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350
   Ishii H., 1992, P SIGCHI C HUM FACT, P3525, DOI [10.1145/142750.142977, DOI 10.1145/142750.142977]
   Izadi S., 2008, P 21 ANN ACM S US IN, P269
   Jones A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531370
   JORKE H, 2003, P EL DISPL, P407
   Koenderink JJ, 2001, PERCEPTION, V30, P431, DOI 10.1068/p3030
   Koenderink JJ, 2004, PERCEPTION, V33, P513, DOI 10.1068/p3454
   Kuechler M, 2006, P IEEE VIRT REAL ANN, P81, DOI 10.1109/VR.2006.71
   Oppenheimer J., 1959, US Patent, Patent No. 2883902
   Shiwa S., 1991, SID Digest, V22, P327
   Tan Kah-Shien., 2009, Proceedings of EOMAS, P1, DOI [10.1145/1750405.1750415, DOI 10.1145/1750405.1750415]
   TANG JC, 1991, CHI 91, P315
   Tanguay D., 2004, HPL2004132
   Todd JT, 2001, PSYCHOL SCI, V12, P191, DOI 10.1111/1467-9280.00335
   Todorovic D, 2006, VISION RES, V46, P3549, DOI 10.1016/j.visres.2006.04.011
   VIOLA P, 2001, CRL200101 COMP
   Wilson A.C., 2004, INDIGENIZING ACAD, P69, DOI [10.1145/1027933.1027946, DOI 10.1145/1027933.1027946]
   Wollaston W. H., 1824, PHILOS T R SOC LOND, V114, P247, DOI DOI 10.1098/RSTL.1824.0016
   ZHANG C, 2009, P IEEE WORKSH MULT S, P1
NR 27
TC 4
Z9 12
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2011
VL 13
IS 3
BP 466
EP 473
DI 10.1109/TMM.2011.2130516
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Telecommunications
GA 765UI
UT WOS:000290733700006
DA 2024-07-18
ER

PT J
AU Fu, YW
   Guo, YW
   Zhu, YS
   Liu, F
   Song, CM
   Zhou, ZH
AF Fu, Yanwei
   Guo, Yanwen
   Zhu, Yanshu
   Liu, Feng
   Song, Chuanming
   Zhou, Zhi-Hua
TI Multi-View Video Summarization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Multi-objective optimization; multi-view video; random walks;
   spatio-temporal graph; video summarization
ID RETRIEVAL; FRAMEWORK; IMAGE
AB Previous video summarization studies focused on monocular videos, and the results would not be good if they were applied to multi-view videos directly, due to problems such as the redundancy in multiple views. In this paper, we present a method for summarizing multi-view videos. We construct a spatio-temporal shot graph and formulate the summarization problem as a graph labeling task. The spatio-temporal shot graph is derived from a hypergraph, which encodes the correlations with different attributes among multi-view video shots in hyperedges. We then partition the shot graph and identify clusters of event-centered shots with similar contents via random walks. The summarization result is generated through solving a multi-objective optimization problem based on shot importance evaluated using a Gaussian entropy fusion scheme. Different summarization objectives, such as minimum summary length and maximum information coverage, can be accomplished in the framework. Moreover, multi-level summarization can be achieved easily by configuring the optimization parameters. We also propose the multi-view storyboard and event board for presenting multi-view summaries. The storyboard naturally reflects correlations among multi-view summarized shots that describe the same important event. The event-board serially assembles event-centered multi-view shots in temporal order. Single video summary which facilitates quick browsing of the summarized multi-view video can be easily generated based on the event board representation.
C1 [Fu, Yanwei; Zhu, Yanshu; Song, Chuanming; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
   [Guo, Yanwen] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
   [Guo, Yanwen] Nanjing Univ, Jiangyin Informat Technol Res Inst, Nanjing 210093, Peoples R China.
   [Liu, Feng] Univ Wisconsin, Dept Comp Sci, Madison, WI 53562 USA.
C3 Nanjing University; Nanjing University; Nanjing University; University
   of Wisconsin System; University of Wisconsin Madison
RP Fu, YW (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
EM ztwztq2006@gmail.com; ywguo@nju.edu.cn; yszhu@cs.hku.hk;
   fliu@cs.wisc.edu; chmsong@graphics.nju.edu.cn; zhouzh@nju.edu.cn
RI Fu, Yanwei/JTT-7059-2023
OI Fu, Yanwei/0000-0002-6595-6893
FU National Science Foundation of China [60703084, 60723003, 60721002];
   National Fundamental Research Program of China [2010CB327903]; Jiangsu
   Science Foundation [BK2009081]; Jiangsu 333 High-Level Talent
   Cultivation Program
FX Manuscript received August 28, 2009; revised December 21, 2009 and March
   26, 2010; accepted May 18, 2010. Date of publication June 07, 2010; date
   of current version October 15, 2010. This work was supported in part by
   the National Science Foundation of China under Grants 60703084,
   60723003, and 60721002, the National Fundamental Research Program of
   China (2010CB327903), the Jiangsu Science Foundation (BK2009081), and
   the Jiangsu 333 High-Level Talent Cultivation Program. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Dr. Zhu Liu.
CR [Anonymous], P SIGGRAPH
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   [Anonymous], 2008, P 14 ACM SIGKDD INT
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Babaguchi N, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1519, DOI 10.1109/ICME.2000.871056
   BAILER W, 2008, P ICIP, P29
   BENMOKHTAR R, 2007, P 10 INT C INF FUS, P1
   Berge C., 1989, Hypergraphs
   Christodoulou MI, 2008, ANN RHEUM DIS, V67, pA12
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   GONG Y, 2001, P INT C MULT EXP, P607
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   HANJALIC A, 1998, IMAGE DATABASES MULT
   LEE J, 2005, P ACM INT C MULT ACM, P810
   Li D.F., 1996, J Fuzzy Math, V4, P829
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Liu Xueliang., P 15 INT C MULTIMEDI, DOI [10.1145/1291233.1291341, DOI 10.1145/1291233.1291341]
   LOU JG, 2005, P 13 ANN ACM INT C M, P161
   Lu S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1959, DOI 10.1109/ICME.2004.1394645
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mei T, 2009, VISUAL COMPUT, V25, P39, DOI 10.1007/s00371-008-0282-4
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Nam J., 1999, PROC 7 ACM INT C MUL, P53
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Ngo CW, 2001, IEEE T CIRC SYST VID, V11, P941, DOI 10.1109/76.937435
   Orriols X, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P335, DOI 10.1109/ICCV.2001.937645
   PAN CM, 2007, P ACM MULT WORKSH TR, P23
   Peng YX, 2006, IEEE T CIRC SYST VID, V16, P612, DOI 10.1109/TCSVT.2006.873157
   Press W. H., 2007, NUM REC ART SCI COMP
   RADHAKRISHNAN R, 2004, P 6 ACM SIGMM INT WO, P157
   Sakarya U, 2008, MULTIMEDIA SYST, V14, P277, DOI 10.1007/s00530-008-0145-x
   Shao X, 2006, ACM T MULTIM COMPUT, V2, P127, DOI 10.1145/1142020.1142023
   Shumway R. H., 2000, TIME SERIES ANAL ITS
   Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414
   Sundaram Hari., 2002, COMUNICA O APRESENTA, DOI [DOI 10.1145/641007.641042, 10.1145/641007.641042]
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang F, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL 1, P238
   XIANG T, 2005, P IEEE INT C COMP VI, P1238
   Xu C., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P361, DOI 10.1145/1076034.1076097
   Xu CS, 2005, IEEE T SPEECH AUDI P, V13, P441, DOI 10.1109/TSA.2004.840939
   YAHIAOUI I, 2001, P CBMIR C
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   YU B, 2003, P 11 ACM INT C MULT, P382
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   ZHANG J, 1993, MULTIMEDIA SYSTEMS, V1, P10
   ZHAO Z, 2006, P AS PAC WORKSH VIS
   Zhou D., 2007, P ADV NEUR INF PROC
NR 53
TC 123
Z9 142
U1 2
U2 26
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2010
VL 12
IS 7
BP 717
EP 729
DI 10.1109/TMM.2010.2052025
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 670SV
UT WOS:000283448500009
DA 2024-07-18
ER

PT J
AU Casanovas, AL
   Monaci, G
   Vandergheynst, P
   Gribonval, R
AF Casanovas, Anna Llagostera
   Monaci, Gianluca
   Vandergheynst, Pierre
   Gribonval, Remi
TI Blind Audiovisual Source Separation Based on Sparse Redundant
   Representations
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Audiovisual processing; blind source separation; Gaussian mixture
   models; sparse signal representation
ID SPEECH
AB In this paper, we propose a novel method which is able to detect and separate audiovisual sources present in a scene. Our method exploits the correlation between the video signal captured with a camera and a synchronously recorded one-microphone audio track. In a first stage, audio and video modalities are decomposed into relevant basic structures using redundant representations. Next, synchrony between relevant events in audio and video modalities is quantified. Based on this co-occurrence measure, audiovisual sources are counted and located in the image using a robust clustering algorithm that groups video structures exhibiting strong correlations with the audio. Next periods where each source is active alone are determined and used to build spectral Gaussian mixture models (GMMs) characterizing the sources acoustic behavior. Finally, these models are used to separate the audio signal in periods during which several sources are mixed. The proposed approach has been extensively tested on synthetic and natural sequences composed of speakers and music instruments. Results show that the proposed method is able to successfully detect, localize, separate, and reconstruct present audiovisual sources.
C1 [Casanovas, Anna Llagostera; Monaci, Gianluca; Vandergheynst, Pierre] Ecole Polytech Fed Lausanne, Signal Proc Lab 2, CH-1015 Lausanne, Switzerland.
   [Gribonval, Remi] INRIA Rennes Bretagne Atlantique, Ctr Rech, Rennes, France.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Universite de Rennes
RP Casanovas, AL (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Lab 2, CH-1015 Lausanne, Switzerland.
EM anna.llagostera@epfl.ch; gianluca.monaci@philips.com;
   pierre.vandergheynst@epfl.ch; remi.gribonval@inria.fr
RI Vandergheynst, Pierre/ISU-3951-2023; Monaci, Gianluca/HLH-8132-2023;
   Monaci, Gianluca/F-5823-2012
OI Monaci, Gianluca/0000-0001-5514-8457; Vandergheynst,
   Pierre/0000-0002-9070-900X
FU Swiss NFS [200021-117884]; EU [FP7-ICT-225913-SMALL]
FX Manuscript received May 25, 2009; revised October 22, 2009 and January
   22, 2010; accepted March 03, 2010. Date of publication May 18, 2010;
   date of current version July 16, 2010. This work was supported in part
   by the Swiss NFS under grant number 200021-117884 and in part by the EU
   Framework 7 FET-Open project FP7-ICT-225913-SMALL: Sparse Models,
   Algorithms and Learning for Large-Scale data. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Alex C. Kot.
CR Baken R., 2000, Clinical measurement of speech and voice
   BARZELAY Z, 2007, P CVPR
   Benaroya L., 2003, P ICA, P957
   CASANOVAS AL, 2007, BLIND AUDIOVISUAL SO
   Chetty G, 2007, LECT NOTES COMPUT SC, V4815, P469
   DANSEREAU R, 2004, P IEEE INT C AC SPEE, V5, P645
   Deligne S, 2002, SAM2002: IEEE SENSOR ARRAY AND MULTICHANNEL SIGNAL PROCESSING WORKSHOP PROCEEDINGS, P68, DOI 10.1109/SAM.2002.1191001
   Escoda OD, 2009, IEEE T IMAGE PROCESS, V18, P1703, DOI 10.1109/TIP.2009.2021315
   Fritsch J., 2004, P INT C INTELLIGENT, P898
   Girin L, 2001, J ACOUST SOC AM, V109, P3007, DOI 10.1121/1.1358887
   Goecke R, 2002, INT CONF ACOUST SPEE, P2025
   Lucey S, 2005, IEEE T MULTIMEDIA, V7, P495, DOI 10.1109/TMM.2005.846777
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Monaci G, 2006, SIGNAL PROCESS, V86, P3534, DOI 10.1016/j.sigpro.2006.02.044
   Okuno HG, 2003, LECT NOTES COMPUT SC, V2686, P118
   Ozerov A, 2007, IEEE T AUDIO SPEECH, V15, P1564, DOI 10.1109/TASL.2007.899291
   Patterson E. K., 2002, EURASIP Journal on Applied Signal Processing, V2002, P1189, DOI 10.1155/S1110865702206101
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Rajaram S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P657
   Rivet B, 2007, IEEE T AUDIO SPEECH, V15, P96, DOI 10.1109/TASL.2006.872619
   Saraceno C, 1998, INT J IMAG SYST TECH, V9, P320, DOI 10.1002/(SICI)1098-1098(1998)9:5<320::AID-IMA2>3.0.CO;2-C
   SIGG C, 2007, P IEEE WORKSH MACH L
   Sodoyer D, 2004, SPEECH COMMUN, V44, P113, DOI 10.1016/j.specom.2004.10.002
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Summerfield Q., 1987, Hearing by eye: The psychology of lipreading, P3
   Vincent E, 2007, SIGNAL PROCESS, V87, P1933, DOI 10.1016/j.sigpro.2007.01.016
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wang WW, 2005, INT CONF ACOUST SPEE, P425
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
NR 29
TC 46
Z9 53
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2010
VL 12
IS 5
BP 358
EP 371
DI 10.1109/TMM.2010.2050650
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 656DN
UT WOS:000282306500002
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Kobayashi, M
   Nakayama, H
   Ansari, N
   Kato, N
AF Kobayashi, Masahiro
   Nakayama, Hidehisa
   Ansari, Nirwan
   Kato, Nei
TI Reliable Application Layer Multicast Over Combined Wired and Wireless
   Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Application layer multicast; heterogeneous networks; layered multiple
   description coding; wired/wireless networks
ID AVAILABLE BANDWIDTH; ROBUST
AB During the last several years, the Internet has evolved from a wired infrastructure to a hybrid of wired and wireless domains by spreading worldwide interoperability for microwave access (WiMAX), Wi-Fi, and cellular networks. Therefore, there is a growing need to facilitate reliable content delivery over such heterogeneous networks. On the other hand, application layer multicast(ALM) has become a promising approach for streaming media content from a server to a large number of interested nodes. ALM nodes construct a multicast tree and deliver the stream through this tree. However, if a node leaves, it cannot deliver the stream to its descendant nodes. In this case, quality-of-service (QoS) is compromised dramatically. Especially, this problem is exacerbated in wireless networks because of packet errors and handovers. In order to cope with this problem, multiple-tree multicasts have been proposed. However, existing methods fail to deliver contents reliably in combined wired and wireless networks. In this paper, we propose a method to ensure the robustness of node departure, while meeting various bandwidth constraints by using layered multiple description coding (LMDC). Finally, we evaluate the proposed method via extensive simulations by using the network simulator (ns-2). By comparing our proposed method with the existing ones, we demonstrate that our method provides better performance in terms of total throughput, relative delay penalty (RDP), and relative delay variation (RDV). The results indicate that our approach is a more reliable content delivery system when compared with contemporary methods in the context of heterogeneous networks containing wired and wireless environments.
C1 [Kobayashi, Masahiro] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 980579, Japan.
   [Nakayama, Hidehisa] Tohoku Inst Technol, Fac Engn, Dept Elect & Intelligent Syst, Sendai, Miyagi 9828577, Japan.
   [Ansari, Nirwan] New Jersey Inst Technol, Dept Elect & Comp Engn, Adv Networking Lab, Newark, NJ 07102 USA.
   [Kato, Nei] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 9808579, Japan.
C3 Tohoku University; Tohoku Institute Technology; New Jersey Institute of
   Technology; Tohoku University
RP Kobayashi, M (corresponding author), NTT Serv Integrat Labs, Tokyo 1808585, Japan.
EM kobayashi.masahiro@lab.ntt.co.jp; hidehisa@m.ieice.org;
   Nirwan.Ansari@njit.edu; kato@it.ecei.tohoku.ac.jp
RI KATO, NEI/T-5892-2019; Ansari, Nirwan/N-1264-2019
OI KATO, NEI/0000-0001-8769-302X; Ansari, Nirwan/0000-0001-8541-3565;
   Kobayashi, Masahiro/0000-0002-6501-7095
FU Japan Science and Technology Agency (JST); National Science Foundation
   Cyber Trust (NSF) [0726549]; Direct For Computer & Info Scie & Enginr;
   Division Of Computer and Network Systems [0726549] Funding Source:
   National Science Foundation
FX This work was supported in part through the strategic international
   cooperative program between the Japan Science and Technology Agency
   (JST) and the National Science Foundation Cyber Trust (NSF) under grant
   no. 0726549. The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Zhihai (Henry) He.
CR Alasti M, 2001, IEEE T INFORM THEORY, V47, P891, DOI 10.1109/18.915641
   ALFONSI B, 2005, IEEE DISTRIB SYST ON, V6
   [Anonymous], NETWORK SIMULATOR NS
   [Anonymous], 2007, 802112007 ANSIIEEE
   *ANSI IEEE, 2004, 802162004 ANSIIEEE
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Castro M, 2002, IEEE J SEL AREA COMM, V20, P1489, DOI 10.1109/JSAC.2002.803069
   Chen LJ, 2008, IEEE J SEL AREA COMM, V26, P761, DOI 10.1109/JSAC.2008.080603
   Chen YS, 2001, J SYST ARCHITECT, V47, P73, DOI 10.1016/S1383-7621(00)00041-2
   CHOU PA, 2003, P INT PACK VID WORKS
   Chu YH, 2002, IEEE J SEL AREA COMM, V20, P1456, DOI 10.1109/JSAC.2002.803066
   DABEK F, 2004, P 2004 C APPL TECHN, P15
   DAY K, 1991, TR9143 U MINN COMP S
   DESHPANDE H, 2001, CS200131 STANF U
   Francis P., 2000, Yoid: Extending the Internet Multicast Architecture
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Hamad AM, 2002, IEEE NETWORK, V16, P36, DOI 10.1109/MNET.2002.1020234
   Hosseini M, 2007, IEEE COMMUN SURV TUT, V9, P58, DOI 10.1109/COMST.2007.4317616
   Hu NN, 2003, IEEE J SEL AREA COMM, V21, P879, DOI 10.1109/JSAC.2003.814505
   Huang YC, 2007, IEEE T MULTIMEDIA, V9, P798, DOI 10.1109/TMM.2007.893343
   Jain M, 2003, IEEE ACM T NETWORK, V11, P537, DOI 10.1109/TNET.2003.815304
   Kobayashi M, 2009, IEEE T MULTIMEDIA, V11, P166, DOI 10.1109/TMM.2008.2008933
   Mathew R, 1997, IEEE T CIRC SYST VID, V7, P882, DOI 10.1109/76.644068
   Ng ISE, 2002, IEEE INFOCOM SER, P170, DOI 10.1109/INFCOM.2002.1019258
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Pendarakis D, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 3RD USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P49
   Roca V, 2001, LECT NOTES COMPUT SC, V2093, P610
   Stankovic V, 2005, IEEE SIGNAL PROC LET, V12, P154, DOI 10.1109/LSP.2004.840895
   Tian RX, 2005, IEEE T CIRC SYST VID, V15, P961, DOI 10.1109/TCSVT.2005.852416
   Tran DA, 2004, IEEE J SEL AREA COMM, V22, P121, DOI 10.1109/JSAC.2003.818803
   Zegura EW, 1996, IEEE INFOCOM SER, P594, DOI 10.1109/INFCOM.1996.493353
NR 33
TC 18
Z9 22
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2009
VL 11
IS 8
BP 1466
EP 1477
DI 10.1109/TMM.2009.2032692
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 520KL
UT WOS:000271843000007
DA 2024-07-18
ER

PT J
AU Park, J
   Lee, H
   Lee, S
   Bovik, AC
AF Park, Jincheol
   Lee, Hyungkeuk
   Lee, Sanghoon
   Bovik, Alan C.
TI Optimal Channel Adaptation of Scalable Video Over a Multicarrier-Based
   Multicell Environment
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cross-layer optimization; human visual system (HVS); inter-cell
   interference (ICI); OFDM-based system; scalable video coding (SVC);
   unequal error protection (UEP); visual entropy
ID WIRELESS NETWORKS; TRANSPORT; SVC
AB To achieve seamless multimedia streaming services over wireless networks, it is important to overcome inter-cell interference (ICI), particularly in cell border regions. In this regard scalable video coding (SVC) has been actively studied due to its advantage of channel adaptation. We explore an optimal solution for maximizing the expected visual entropy over an orthogonal frequency division multiplexing (OFDM)-based broadband network from the perspective of cross-layer optimization. An optimization problem is parameterized by a set of source and channel parameters that are acquired along the user location over a multicell environment. A suboptimal solution is suggested using a greedy algorithm that allocates the radio resources to the scalable bitstreams as a function of their visual importance. The simulation results show that the greedy algorithm effectively resists ICI in the cell border region, while conventional nonscalable coding suffers severely because of ICI.
C1 [Park, Jincheol; Lee, Hyungkeuk; Lee, Sanghoon] Yonsei Univ, Wireless Network Lab, Dept Elect & Elect Engn, Seoul 120749, South Korea.
   [Bovik, Alan C.] Univ Texas Austin, Dept Elect & Comp Engn, LIVE, Austin, TX 78712 USA.
C3 Yonsei University; University of Texas System; University of Texas
   Austin
RP Park, J (corresponding author), Yonsei Univ, Wireless Network Lab, Dept Elect & Elect Engn, Seoul 120749, South Korea.
EM dewofdawn@yonsei.ac.kr; punktank@yonsei.ac.kr; slee@yonsei.ac.kr;
   bovik@ece.utexas.edu
RI Lee, Sanghoon/A-3430-2019; Bovik, Alan/B-6717-2012
OI Lee, Sanghoon/0000-0001-9895-5347; Bovik, Alan/0000-0001-6067-710X
FU Korea government (MOST) [R01-2007-000-11708-0]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) grant funded by the Korea government (MOST) (No.
   R01-2007-000-11708-0). The associate editor coordinating the review of
   this manuscript and approving it for publication was Prof. Aggelos K.
   Katsaggelos.
CR *3GPP TSG RAN WG1, 2005, R1051341 3GPP TSG RA
   CHITPRASERT B, 1990, IEEE T COMMUN, V38
   CONCI N, 2005, P IEEE INT C IM PROC, V1, P11
   Geisler W. S., 1998, P SPIE, V3299
   GRIOD B, 1993, DIGITAL IMAGES HUMAN, P207
   HANG HM, 1997, IEEE T CIRCUITS SYST, V7, P197
   Jiang H, 2005, IEEE COMMUN MAG, V43, P120, DOI 10.1109/MCOM.2005.1561929
   Lee S, 2003, IEEE T CIRC SYST VID, V13, P149, DOI 10.1109/TCSVT.2002.808441
   Lee SH, 2001, J MATER PROCESS MANU, V10, P7, DOI [10.1177/1062065602010001388, 10.1106/106206502026388]
   LEE TW, 2001, J TAIWAN FISH RES, V9, P129
   Li ZG, 2006, J VIS COMMUN IMAGE R, V17, P376, DOI 10.1016/j.jvcir.2005.04.004
   Proakis J. G., 1995, DIGITAL COMMUNICATIO
   Reichhardt CJO, 2007, EUR PHYS J E, V22, P11, DOI 10.1140/epje/e2007-00003-4
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Son H, 2005, IEICE T COMMUN, VE88B, P4094, DOI 10.1093/ietcom/e88-b.10.4094
   Son H, 2006, IEEE COMMUN LETT, V10, P360, DOI 10.1109/LCOMM.2006.05027
   TIZON N, 2008, EURASIP J ADV SIG PR, P1
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   Wenger S, 2007, IEEE T CIRC SYST VID, V17, P1164, DOI 10.1109/TCSVT.2007.905523
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Wu DP, 2001, P IEEE, V89, P6, DOI 10.1109/5.904503
NR 22
TC 21
Z9 22
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2009
VL 11
IS 6
BP 1062
EP 1071
DI 10.1109/TMM.2009.2026084
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 493YW
UT WOS:000269776700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jung, CR
AF Jung, Claudio Rosito
TI Efficient Background Subtraction and Shadow Removal for Monochromatic
   Video Sequences
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Background subtraction; monochromatic video sequences; object tracking;
   shadow removal
ID MOVING CAST SHADOWS; SEGMENTATION; OBJECTS
AB This letter presents a new method for background subtraction and shadow removal for grayscale video sequences. The background image is modeled using robust statistical descriptors, and a noise estimate is obtained. Foreground pixels are extracted, and a statistical approach combined with geometrical constraints are adopted to detect and remove shadows.
C1 Univ Vale Rio dos Sinos, Grad Sch Appl Comp, PIPCA, BR-93022000 Sao Leopoldo, RS, Brazil.
C3 Universidade do Vale do Rio dos Sinos (Unisinos)
RP Jung, CR (corresponding author), Univ Vale Rio dos Sinos, Grad Sch Appl Comp, PIPCA, BR-93022000 Sao Leopoldo, RS, Brazil.
EM crjung@unisinos.br
FU HIP Brazil RD; Brazilian agency CNPq
FX Manuscript received May 12, 2008; revised November 02, 2008. First
   published February 27, 2009; current version published March 18, 2009.
   This work was supported in part by HIP Brazil R&D and Brazilian agency
   CNPq. The associate editor coordinating the review of this manuscript
   and approving it for publication was Prof. Ling Guan.
CR [Anonymous], 1992, R. woods digital image processing
   Bloomberg DS, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P209
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Cucchiara R, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P334, DOI 10.1109/ITSC.2001.948679
   HORPRASERT T, 1999, P IEEE ICCV FRAM RAT
   Huber Peter J, 2011, ROBUST STAT, P1248
   JACQUES JCS, 2006, P IEEE INT C IM PROC, P1817
   KIM SJ, 1992, ANN STAT, V20, P1534, DOI 10.1214/aos/1176348783
   Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017
   Martel-Brisson N, 2005, PROC CVPR IEEE, P643
   Martel-Brisson N, 2007, IEEE T PATTERN ANAL, V29, P1133, DOI 10.1109/TPAMI.2007.1039
   Mikic I, 2000, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2000.905341
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   Tian YL, 2005, PROC CVPR IEEE, P1182
   Wang Y, 2005, PATTERN RECOGN, V38, P1937, DOI 10.1016/j.patcog.2005.02.006
   Zhang W, 2007, IEEE T MULTIMEDIA, V9, P1202, DOI 10.1109/TMM.2007.902842
   Zhang W, 2006, INT C PATT RECOG, P73
NR 20
TC 80
Z9 99
U1 1
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2009
VL 11
IS 3
BP 571
EP 577
DI 10.1109/TMM.2009.2012924
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 425JH
UT WOS:000264632300023
DA 2024-07-18
ER

PT J
AU Kozat, UC
   Harmanci, Ö
   Kanumuri, S
   Demircin, MU
   Civanlar, MR
AF Kozat, Ulas C.
   Harmanci, Oeztan
   Kanumuri, Sandeep
   Demircin, Mehmet Umut
   Civanlar, M. Reha
TI Peer Assisted Video Streaming With Supply-Demand-Based Cache
   Optimization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cache optimization; content distribution networks (CDN); peer-to-peer
   (P2P); streaming; supply-demand; video-on-demand (VoD)
AB In this paper, we consider a hybrid P2P video on-demand architecture that utilizes both the server and the peer resources for efficient transmission of popular videos. In our system architecture, each peer dedicates some cache space to store a particular segment of a video file as well as some of its upload bandwidth to serve the cached segment to other peers. Peers join the system and issue a streaming request to a control server. Control server directs the peers to streaming servers or to other peers who have the desired video segments. Control server also decides which peer should cache which video segment. Our main contribution in this paper is to determine the proper caching strategies at peers such that we minimize the average load on the streaming servers.
   To minimize the server load, we pose the caching problem as a supply-demand-based utility optimization problem. By exploiting the inherent structure of a typical on-demand streaming application as well as the availability of a global view on the current supply-demand at the control server, we demonstrate how the system performance can be significantly improved over the brute-force caching decisions. In our analysis, we mainly consider three caching mechanisms. In the first mechanism (cache prefetching), a segment is prefetched to a given peer for caching purposes upon peer's arrival to the system regardless of whether that segment is currently demanded by that peer or not. In the second mechanism (opportunistic cache update), a peer has the option of replacing the segment that is currently in its cache with the last segment that it finished streaming. In the third mechanism, we combine both mechanisms as a hybrid caching strategy. In particular, we find that a dynamic-programming (DP)-based utility maximization solution using only the cache update method performs significantly better in reducing the server load. Furthermore, our findings suggest that even less sophisticated cache update solutions can perform almost as good as prefetching strategies in interesting regions of operation.
C1 [Kozat, Ulas C.; Harmanci, Oeztan; Kanumuri, Sandeep; Demircin, Mehmet Umut; Civanlar, M. Reha] DoCoMo USA Labs, Palo Alto, CA 94304 USA.
C3 NTT Docomo
RP Kozat, UC (corresponding author), DoCoMo USA Labs, Palo Alto, CA 94304 USA.
EM kozat@docomolabs-usa.com; oztanharmanci@gmail.com;
   kanumari@docomolabs-usa.com; demircin@ti.com; m.civanlar@ieee.org
RI Civanlar, Mehmet/E-4656-2010; Demircin, Mehmet Umut/AGX-7237-2022;
   Civanlar, Mehmet/M-9929-2019
OI Civanlar, Mehmet/0000-0002-6171-5814
CR ANNAPUREDDY S, 2007, P IEEE INF 2007 MAY
   Annapureddy S., 2006, P INT PROT TELEVISIO
   BOURAS C, 2004, PREDICTIVE PREFETCHI
   Cao P., 1997, P 1997 US S INT TECH
   Chan S., 1999, CACHING SCHEMES DIST
   Cohen B., 2003, INCENTIVES BUILD ROB
   Dana C., 2005, Multimedia Signal Processing, 2005 IEEE 7th Workshop on, P1, DOI [DOI 10.1109/MMSP.2005.248586, 10.1109/MMSP.2005.248586.]
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   GUO M, 2004, P IEEE INT C COMP CO
   Guo PH, 2007, J ZHEJIANG UNIV-SC A, V8, P605, DOI 10.1631/jzus.2007.A0605
   ISHIKAWA E, 2001, P 1 INT C NETW 2, P776
   Jia Wang, 1999, Computer Communication Review, V29, P36, DOI 10.1145/505696.505701
   JOHARI R, 2007, P 45 ALL C SEP
   Jurca D, 2007, IEEE COMMUN MAG, V45, P108, DOI 10.1109/MCOM.2007.374427
   Kozat UC, 2006, GLOB TELECOMM CONF
   Li B, 2007, IEEE COMMUN MAG, V45, P94, DOI 10.1109/MCOM.2007.374425
   MACCARTHAIGH C, 2007, JOOST NETWORK ARCHIT
   Padmanabhan Venkata N., 1996, P ACM SIGCOMM 96 C S
   Palpanas T., 1999, P 4 INT WEB CACH WOR
   Pinho LB, 2002, 14TH SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH PERFORMANCE COMPUTING, PROCEEDINGS, P117, DOI 10.1109/CAHPC.2002.1180767
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   SETTON E, 2007, P INT C IM PROC ICIP
   SHODONG J, 2002, P 22 INT C DISTR COM, P153
   Stark P, 2001, POPTRONICS, V2, P3
   Tang Y, 2007, IEEE COMMUN MAG, V45, P100, DOI 10.1109/MCOM.2007.374426
   Wu KL, 2004, IEEE T MULTIMEDIA, V6, P770, DOI 10.1109/TMM.2004.834870
   Yiu WPK, 2007, IEEE J SEL AREA COMM, V25, P1717, DOI 10.1109/JSAC.2007.071210
   Zhang M., 2005, P ACM MULTIMEDIA, P287, DOI DOI 10.1145/1101149.1101206
   ZHANG X, 2005, P IEEE INFOCOM MAR
   ZHENG C, 2005, P WORKSH ADV PEER TO
NR 30
TC 20
Z9 23
U1 1
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2009
VL 11
IS 3
BP 494
EP 508
DI 10.1109/TMM.2009.2012918
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 425JH
UT WOS:000264632300015
DA 2024-07-18
ER

PT J
AU Luo, JB
   Hanjalic, A
   Tian, Q
   Jaimes, A
AF Luo, Jiebo
   Hanjalic, Alan
   Tian, Qi
   Jaimes, Alejandro
TI Integration of Context and Content for Multimedia Management: An
   Introduction to the Special Issue
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
C1 [Luo, Jiebo] Kodak Res Labs, Rochester, NY 14650 USA.
   [Hanjalic, Alan] Delft Univ Technol, Delft, Netherlands.
   [Tian, Qi] Microsoft Res Asia, Beijing, Peoples R China.
   [Jaimes, Alejandro] Telefon Res, Madrid, Spain.
C3 Eastman Kodak; Delft University of Technology; Microsoft; Microsoft
   Research Asia; Telefonica SA
RP Luo, JB (corresponding author), Kodak Res Labs, Rochester, NY 14650 USA.
EM jiebo.luo@kodak.com; A.Hanjalic@ewi.tudelft.nl; qitian@microsoft.com;
   ajaimes@tid.es
RI Luo, Jiebo/AAI-7549-2020
OI Hanjalic, Alan/0000-0002-5771-2549; Luo, Jiebo/0000-0002-4516-9729
NR 0
TC 4
Z9 5
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855 USA
SN 1520-9210
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2009
VL 11
IS 2
BP 193
EP 195
DI 10.1109/TMM.2008.2009179
PG 3
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 398EG
UT WOS:000262714800001
DA 2024-07-18
ER

PT J
AU Guan, W
   Cai, JF
   Zheng, JM
   Chen, CW
AF Guan, Wei
   Cai, Jianfei
   Zheng, Jianmin
   Chen, Chang Wen
TI Segmentation-based view-dependent 3-D graphics model transmission
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Multimedia and Expo (ICME 2007)
CY JUL 02-05, 2007
CL Beijing, PEOPLES R CHINA
SP IEEE Signal Proc Soc, IEEE Circuits & Syst Soc, IEEE Commun Soc, IEEE Comp Soc
DE view-dependent 3-D mesh transmission; 3-D graphics model; 3-D mesh
   coding; 3-D mesh segmentation
ID COMPRESSION
AB For wireless network based graphics applications, a key challenge is how to efficiently transmit complex 3-D models over bandwidth-limited wireless channels. Most existing 3-D mesh transmission systems do not consider such a view-dependent delivery issue, and thus transmit unnecessary portions of 3-D mesh models, which leads to the waste in precious wireless network bandwidth. In this paper, we propose a novel view-dependent 3-D model transmission scheme, where a 3-D model is partitioned into a number of segments, each segment is then independently coded using the MPEG-4 3DMC coding algorithm, and finally only the visible segments are selected and delivered to the client. Moreover, we also propose analytical models to find the optimal number of segments so as to minimize the average transmission size. Simulation results show that such a view-based 3-D model transmission is able to substantially save the transmission bandwidth and therefore has a significant impact on wireless graphics applications.
C1 [Guan, Wei; Cai, Jianfei; Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Chen, Chang Wen] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
C3 Nanyang Technological University; State University of New York (SUNY)
   System; State University of New York (SUNY) Buffalo
RP Guan, W (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM guan0006@ntu.edu.sg; asjfcai@ntu.edu.sg; asjmzheng@ntu.edu.sg;
   chencw@buffalo.edu
RI Guan, Wei/A-6654-2012; Zheng, Jianmin/A-3717-2011; Cai,
   Jianfei/A-3691-2011
OI Zheng, Jianmin/0000-0002-5062-6226; Cai, Jianfei/0000-0002-9444-3763
CR [Anonymous], ACM SIGGRAPH 1996 C
   Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P14
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Chazelle B, 1997, COMP GEOM-THEOR APPL, V7, P327, DOI 10.1016/S0925-7721(96)00024-7
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Deering M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P13, DOI 10.1145/218380.218391
   Elzinga J., 1972, Transp. Sci, V6, P379
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   KIM J, 2004, SMI 04, P209
   Liu R, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P298
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   SHLAFMAN S, 2002, EUROGRAPHICS, P219
   Sim JY, 2005, IEEE T CIRC SYST VID, V15, P854, DOI 10.1109/TCSVT.2005.848349
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   TAUBIN G, 1999, IEEE T VIS COMPUT GR, V5, P47
   TAUBIN G, 1998, ACM SIGGRAPH, P19
   TO DSP, 1999, P ACM S VIRT REAL SO, P88
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   Yan ZD, 2005, IEEE T CIRC SYST VID, V15, P138, DOI 10.1109/TCSVT.2004.837023
   Yang S, 2004, IEEE T CIRC SYST VID, V14, P1249, DOI 10.1109/TCSVT.2004.835153
   ZHOU K, 2004, EUR ACM SIGGRAPH S G, P45
NR 26
TC 6
Z9 9
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2008
VL 10
IS 5
BP 724
EP 734
DI 10.1109/TMM.2008.922785
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 334LR
UT WOS:000258223800006
DA 2024-07-18
ER

PT J
AU Kokiopoulou, E
   Frossard, P
AF Kokiopoulou, Effrosyni
   Frossard, Pascal
TI Semantic coding by supervised dimensionality reduction
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE dimensionality reduction; multimedia data mining; redundant dictionaries
ID NONNEGATIVE MATRIX FACTORIZATION; SIMULTANEOUS SPARSE APPROXIMATION;
   ALGORITHMS
AB This paper addresses the problem of representing multimedia information under a compressed form that permits efficient classification. The semantic coding problem starts from a subspace method where dimensionality reduction is formulated as a matrix factorization problem. Data samples are jointly represented in a common subspace extracted from a redundant dictionary of basis functions. We first build on greedy pursuit algorithms for simultaneous sparse approximations to solve the dimensionality reduction problem. The method is extended into a supervised algorithm, which further encourages the class separability in the extraction of the most relevant features. The resulting supervised dimensionality reduction scheme provides an interesting tradeoff between approximation (or compression) and discriminant feature extraction (or classification). The algorithm provides a compressed signal representation that can directly be used for multimedia data mining. The application of the proposed algorithm to image recognition problems further demonstrates classification performances that are competitive with state-of-the-art solutions in handwritten digit or face recognition. Semantic coding certainly represents an interesting solution to the challenging problem of processing huge volumes of multidimensional data in modern multimedia systems, where compressed data have to be processed and analyzed with limited computational complexity.
C1 [Kokiopoulou, Effrosyni; Frossard, Pascal] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Kokiopoulou, E (corresponding author), Swiss Fed Inst Technol, LTS4 Lab, Inst Elect Engn, EPFL, CH-1015 Lausanne, Switzerland.
EM effrosyni.kokiopoulou@epfl.ch; pascal.frossard@epfl.ch
RI Frossard, Pascal/AAF-2268-2019
CR Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cotter Robert J, 2005, J Mass Spectrom Soc Jpn, V53, P7
   Eickeler S, 2000, IMAGE VISION COMPUT, V18, P279, DOI 10.1016/S0262-8856(99)00055-4
   Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46
   Golub Gene H, 2012, MATRIX COMPUTATIONS
   Gu L, 2001, PROC CVPR IEEE, P116
   He X., 2003, ADV NEURAL INFORM PR, P153
   Heiler M, 2005, IEEE I CONF COMP VIS, P1667
   Heiler M, 2006, J MACH LEARN RES, V7, P1385
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Jost P, 2006, IEEE T SIGNAL PROCES, V54, P4685, DOI 10.1109/TSP.2006.882080
   Kluckner S, 2007, IEEE I CONF COMP VIS, P47
   Kokiopoulou E, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P234, DOI 10.1109/ICDM.2005.113
   Kokiopoulou E, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1962
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Leviatan D, 2006, ADV COMPUT MATH, V25, P73, DOI 10.1007/s10444-004-7613-4
   MALLAT S, 1998, WAVELET TOOR SIGNAL
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60
   Pauca VP, 2006, LINEAR ALGEBRA APPL, V416, P29, DOI 10.1016/j.laa.2005.06.025
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030
   Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031
   Ventura RMFI, 2006, IEEE T IMAGE PROCESS, V15, P726, DOI 10.1109/TIP.2005.860596
   WANG H, 2006, P SPIE IMAGE PROCESS, V6064, P523
   WANG Y, 2004, P 6 AS C COMP VIS JA, P806
   Webb A.R., 2003, Statistical Pattern Recognition
   Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291
   MC BIOL C LEARNING C
NR 33
TC 22
Z9 28
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2008
VL 10
IS 5
BP 806
EP 818
DI 10.1109/TMM.2008.922806
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 334LR
UT WOS:000258223800013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mol, JD
   Epema, DHP
   Sips, HJ
AF Mol, Jan David
   Epema, Dick H. P.
   Sips, Henk J.
TI The orchard algorithm building multicast trees for P2P video
   multicasting without free-riding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE distributed algorithms; free-riding; multicast channels; multiple
   description coding; peer-to-peer
AB The main purpose of many current peer-to-peer (P2P) networks is off-line file sharing. However, a potentially very promising use of such networks is to share video streams (e.g., TV programs) in real time. In order to do so, the peers in a P2P network who are interested in the same video stream may employ Application Level Multicasting (ALM). In existing P2P networks, peers may exhibit behavior which is problematic for ALM: they are not always willing to donate! resources (free-riding), and they may arrive and depart at a high rate (churn). In this paper we propose the Orchard algorithm for creating and maintaining ALM trees in P2P networks, which deals with both these problems. By employing a technique called Multiple Description Coding, we split a video stream into several substreams. Orchard creates a dynamic spanning tree for each of these substreams in such a way that in the resulting forest, no peer has to forward more substreams than it receives. Based on an analysis of the expected performance of Orchard and on experiments in a real system, we find that Orchard is capable of maintaining a multicast forest, even when peers join and leave the forest at a high rate.
C1 Delft Univ Technol, Dept Comp Sci, NL-2628 CD Delft, Netherlands.
C3 Delft University of Technology
RP Mol, JD (corresponding author), Delft Univ Technol, Dept Comp Sci, NL-2628 CD Delft, Netherlands.
EM j.j.d.mol@tudelft.nl
RI Tavares, António JV/A-7115-2008
CR Alagöz A, 2006, ISCN '06: PROCEEDINGS OF THE 7TH INTERNATIONAL SYMPOSIUM ON COMPUTER NETWORKS, P248
   Andrade N., 2005, P 2005 ACM SIGCOMM W, P111
   [Anonymous], P 1 INT WORKSH PEER
   BANERJEE S, 2003, P ACM SIGMETRICS SAN, P102, DOI DOI 10.1145/781027.781041
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chu Yang-hua., 2004, Proceedings of the ACM SIGCOMM Workshop on Practice and Theory of Incentives in Networked Systems (PINS), P205
   Chu YH, 2000, PERF E R SI, V28, P1, DOI 10.1145/345063.339337
   Chun B, 2003, ACM SIGCOMM COMP COM, V33, P3, DOI 10.1145/956993.956995
   *DAS, DISTR ASCI SUP
   Eugster PT, 2004, COMPUTER, V37, P60, DOI 10.1109/MC.2004.1297243
   Ferreira RA, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING, PROCEEDINGS, P165, DOI 10.1109/P2P.2005.33
   FITZEK F, 2004, WIRELESS PERSONAL MU, P524
   Garbacki P, 2006, SIXTH IEEE INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING, PROCEEDINGS, P23, DOI 10.1109/P2P.2006.1
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Habib A, 2004, INT WORKSH QUAL SERV, P171
   Jelasity M, 2006, SIXTH IEEE INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING, PROCEEDINGS, P117, DOI 10.1109/P2P.2006.25
   Li HC, 2006, USENIX ASSOCIATION 7TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P191
   Mathy L, 2004, IEEE INFOCOM SER, P1318
   NGAN TWJ, 2004, P 2 WORKSH EC PEER P
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Pai V, 2005, LECT NOTES COMPUT SC, V3640, P127
   POUWELSE J, IN PRESS CONCURRENCY
   Pouwelse JA, 2004, IEEE SYS MAN CYBERN, P4599
   Saroiu S, 2002, P SOC PHOTO-OPT INS, V4673, P156
   STUTZBACH D, 2005, CISTR200503 U OREG E
   Taal JR, 2005, PROC SPIE, V5960, P2172, DOI 10.1117/12.633445
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Yu H., 2006, P 1 ACM SIGOPS EUROS, P333
NR 28
TC 22
Z9 25
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2007
VL 9
IS 8
BP 1593
EP 1604
DI 10.1109/TMM.2007.907450
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 233SF
UT WOS:000251109900006
OA Green Published
DA 2024-07-18
ER

PT J
AU Su, CW
   Liao, HYM
   Tyan, HR
   Lin, CW
   Chen, DY
   Fan, KC
AF Su, Chih-Wen
   Liao, Hong-Yuan Mark
   Tyan, Hsiao-Rong
   Lin, Chia-Wen
   Chen, Duan-Yu
   Fan, Kuo-Chin
TI Motion flow-based video retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE motion analysis; video retrieval
ID MOVING-OBJECTS; SEGMENTATION; MODELS
AB In this paper, we propose the use of motion vectors embedded in MPEG bitstreams to generate so-called "motion flows", which are applied to perform video retrieval. By using the motion vectors directly, we do not need to consider the shape of a moving object and its corresponding trajectory. Instead, we simply "link" the local motion vectors across consecutive video frames to form motion flows, which are then recorded and stored in a video database. In the video retrieval phase, we propose a new matching strategy to execute the video retrieval task. Motions that do not belong to the mainstream motion flows are filtered out by our proposed algorithm. The retrieval process can be triggered by query-by-sketch or query-by-example. The experiment results show that our method is indeed superb in the video retrieval process.
C1 Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   Chung Yuan Christian Univ, Inst Informat & Comp Engn, Chungli 320, Taiwan.
   Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 30013, Taiwan.
   Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 320, Taiwan.
C3 Academia Sinica - Taiwan; National Yang Ming Chiao Tung University;
   Chung Yuan Christian University; National Tsing Hua University; National
   Central University
RP Su, CW (corresponding author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
EM lucas@iis.sinica.edu.tw; liao@iis.sinica.edu.tw; cwlin@ee.nthu.edu.tw;
   dychen@iis.sinica.edu.tw; kcfan@csie.ncu.edu.tw
RI Lin, Chia-Wen/ABH-6075-2020; Fan, K/GXH-3734-2022; Liao, Hong-Yuan
   Mark/AAQ-5514-2021; Lin, Chia-Wen/M-4571-2013
OI Lin, Chia-Wen/0000-0002-9097-2318
CR Babu RV, 2007, MULTIMED TOOLS APPL, V32, P93, DOI 10.1007/s11042-006-0048-9
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dagtas S, 2000, IEEE T IMAGE PROCESS, V9, P88, DOI 10.1109/83.817601
   Deng YN, 1998, IEEE T CIRC SYST VID, V8, P616, DOI 10.1109/76.718508
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Fablet R, 2002, IEEE T IMAGE PROCESS, V11, P393, DOI 10.1109/TIP.2002.999674
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   HAMRAPUR A, 1997, SPIE P STORAGE RETRI, V5, P188
   LAN DJ, 2003, P INT C MULT EXP BAL, V3, P469
   Ma YF, 2002, INT C PATT RECOG, P548, DOI 10.1109/ICPR.2002.1048361
   Manjunath B.S., 2002, INTRO MPEG 7
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P782, DOI 10.1109/TCSVT.2004.828341
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Rao C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P939
   SHIH CC, LECT NOTES COMPUTER, V2195, P819
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Su CW, 2005, IEEE T MULTIMEDIA, V7, P1106, DOI 10.1109/TMM.2005.858394
   SU CW, 2005, P 7 ACM SIGMM INT WO, P10
   Tsaig Y, 2002, IEEE T CIRC SYST VID, V12, P597, DOI 10.1109/TCSVT.2002.800513
   Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784
   Wang R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P691, DOI 10.1109/ICIP.1999.817204
NR 22
TC 38
Z9 44
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2007
VL 9
IS 6
BP 1193
EP 1201
DI 10.1109/TMM.2007.902875
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 215XJ
UT WOS:000249842000010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Babaguchi, N
   Ohara, K
   Ogura, T
AF Babaguchi, Noboru
   Ohara, Kouzou
   Ogura, Takehiro
TI Learning personal preference from viewer's operations for browsing and
   its application to baseball video retrieval and summarization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE broadcast baseball video; personalization; video retrieval; video
   summarization; viewer profile
AB Personalization is one of the most important mechanisms to make multimedia systems easy to use. In video applications, its embodiment is to tailor video contents for a particular viewer. For this purpose, we are now developing a system of retrieving and browsing video segments, called video portal with personalization (VIPP). VIPP is characterized by 1) supporting the viewer's access to video contents and making a summarized video clip by taking his/her preference into account and 2) acquiring the viewer's profile from his/her operations automatically. In this paper, we propose a method for learning to personalize from the viewer's operations such as retrieval and browsing, as well as describe how the personalized retrieval and summarization of videos can be realized. From the experiments, we clarify the effect of personalization on retrieval and summarization of baseball videos on VIPP.
C1 Osaka Univ, Dept Informat & Commun Technol, Suita, Osaka 5650871, Japan.
   NHK Japan Broadcasting Corp, Tokyo, Japan.
   Osaka Univ, ISIR, Osaka 5670047, Japan.
C3 Osaka University; NHK Japan Broadcasting Corp; Osaka University
RP Babaguchi, N (corresponding author), Osaka Univ, Dept Informat & Commun Technol, 2-2 Yamadaoka, Suita, Osaka 5650871, Japan.
EM babaguchi@comm.eng.osaka-u.ac.jp
CR [Anonymous], USER MODEL USER ADAP
   Ardissono L, 2004, HUM-COMPUT INT-SPRIN, P3
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   BABAGUCHI N, 2003, 4 IEEE PAC RIM C MUL
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   Chen C. C., 2001, P WORKSH MACH LEARN
   Chen L., 1998, Proceedings of the Second International Conference on Autonomous Agents, P132, DOI 10.1145/280765.280789
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Hirsh H, 2000, COMMUN ACM, V43, P102, DOI 10.1145/345124.345159
   Hjelsvold R., 2001, P 10 INT C WORLD WID, P129, DOI [https://doi.org/10.1145/371920.371969, DOI 10.1145/371920.371969]
   Jaimes A, 2002, IEEE IMAGE PROC, P133
   Jasinschi RS, 2001, INT CONF ACOUST SPEE, P1405, DOI 10.1109/ICASSP.2001.941192
   Kim H. R., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P101, DOI 10.1145/604045.604064
   Maglio P, 2000, COMMUN ACM, V43, P96, DOI 10.1145/345124.345158
   Magnini B, 2004, USER MODEL USER-ADAP, V14, P239, DOI 10.1023/B:USER.0000028980.13669.44
   MARTINEZ JM, 2001, JTC1SC29WG11 ISO IEC
   Maybury M, 2004, USER MODEL USER-ADAP, V14, P119, DOI 10.1023/B:USER.0000010142.18921.eb
   Merialdo B, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P323, DOI 10.1145/319463.319637
   Ogura T., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P309, DOI 10.1109/ICME.2002.1035588
   OHARA K, 2003, P KES2003, P1062
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Smyth B, 2000, COMMUN ACM, V43, P107, DOI 10.1145/345124.345161
   Smyth B, 2001, AI MAG, V22, P89
   Syeda-Mahmood T., 2001, PROC ACM MULITMEDIA, V9, P119, DOI DOI 10.1145/500141.500161
   Tseng BL, 2004, J VIS COMMUN IMAGE R, V15, P370, DOI 10.1016/j.jvcir.2004.04.011
   Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175
   WINDYANTORO DH, 1999, P 8 ACM INT C INF KN, P405
   YU B, 2003, P 11 ACM INT C MULT, P382
   ZIMMERMAN J, 2004, PERSONALIZED DIGITAL
NR 29
TC 9
Z9 9
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2007
VL 9
IS 5
BP 1016
EP 1025
DI 10.1109/TMM.2007.898890
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 193ZX
UT WOS:000248314800011
DA 2024-07-18
ER

PT J
AU Kyperountas, M
   Kotropoulos, C
   Pitas, I
AF Kyperountas, Marios
   Kotropoulos, Constantine
   Pitas, Ioannis
TI Enhanced eigen-audioframes for audiovisual scene change detection
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE audio-visual video segmentation; eigen-audioframes; scene change
   detection; TRECVID2003
AB In this paper, a novel audio-visual scene change detection algorithm is presented and evaluated experimentally. An enhanced set of eigen-audioframes is created that is related to an audio signal subspace, where audio background changes are easily discovered. An analysis is presented that justifies why this subspace favors scene change detection. Additionally, a novel process is developed in order to detect audio scene change candidates in this subspace. Visual information is used to align audio scene change indications with neighboring video shot changes and, accordingly, to reduce the false alarm rate of the audio-only scene change detection. Moreover, video fade effects are identified and used independently in order to track scene changes. The false alarm rate is reduced further by extracting acoustic features in order to verify that the scene change indications are valid. The detection methodology was tested on newscast videos provided by the TRECVID2003 video test set. The experimental results demonstrate that the proposed method achieves an F - measure exceeding 0.85. Accordingly, it effectively tackles the scene change detection problem.
C1 Aristotle Univ Thessaloniki, Dept Informat, GR-54006 Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Kyperountas, M (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, GR-54006 Thessaloniki, Greece.
EM costas@aiia.csd.auth.gr
RI Kotropoulos, Constantine/AAI-2364-2019; Kotropoulos, Constantine
   L/B-7928-2010
OI Kotropoulos, Constantine/0000-0001-9939-7930; 
CR ALBIOL A, 2002, P ICME, V2, P353
   BEROLDI N, 2003, P 25 EUR C IR RES AD, V2633, P520
   Bertini M, 2001, PATTERN RECOGN LETT, V22, P503, DOI 10.1016/S0167-8655(00)00113-6
   Cerneková Z, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P421, DOI 10.1109/ICIP.2002.1038995
   CERNEKOVA Z, 2006, IEEE T CIRCUITS SYST, V16
   CHEN SC, 2002, P IEEE ICME, V2, P365
   DESANTO M, 2001, LECT NOTES COMPUTER, V2184, P192
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   HSU WHM, 2003, P 2003 IEEE INT C MU, V2, P413
   Huang CL, 2001, IEEE T CIRC SYST VID, V11, P1281, DOI 10.1109/76.974682
   Huang JC, 2005, IEEE T MULTIMEDIA, V7, P538, DOI 10.1109/TMM.2005.843346
   Huang JC, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P526, DOI 10.1109/ICIP.1998.727252
   Jiang H, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1507, DOI 10.1109/ICME.2000.871053
   Kyperountas M, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P353
   Lee SM, 2001, PRICM 4: FORTH PACIFIC RIM INTERNATIONAL CONFERENCE ON ADVANCED MATERIALS AND PROCESSING, VOLS I AND II, P473
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   Lu Lie., 2001, Proceedings of the ninth ACM international conference on Multimedia, P203
   *NAT I STAND TECHN, GUID TRECVID 2003
   Nitanda N, 2005, IEEE INT SYMP CIRC S, P4030, DOI 10.1109/ISCAS.2005.1465515
   NITANDA N, 2004, P 2004 INT S CIRC SY, V2, P89
   Nwe TL, 2005, INT CONF ACOUST SPEE, P1065
   OHARE A, 2004, P 2004 IEEE INT C AC, V3, P1028
   Sugano M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P17
   Sundaram H, 2000, INT CONF ACOUST SPEE, P2441, DOI 10.1109/ICASSP.2000.859335
   Truong BT, 2003, IEEE T CIRC SYST VID, V13, P5, DOI 10.1109/TCSVT.2002.808084
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang P, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P787
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   WEIQIANG W, 2002, J COMPUT SCI TECHNOL, V17, P189
   Zhu YY, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P229
NR 30
TC 14
Z9 16
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2007
VL 9
IS 4
BP 785
EP 797
DI 10.1109/TMM.2007.893337
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 170NW
UT WOS:000246671200010
DA 2024-07-18
ER

PT J
AU Lee, GG
   Wang, MJ
   Lin, HY
   Su, DWC
   Lin, BY
AF Lee, Gwo Giun (Chris)
   Wang, Ming-Jiun
   Lin, He-Yuan
   Su, Drew Wei-Chi
   Lin, Bo-Yun
TI Algorithm/architecture co-design of 3-D spatio-temporal motion
   estimation for video coding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE algorithm and architecture co-design; motion estimation; spatio-temporal
   prediction; VLSI architecture
ID ESTIMATION ALGORITHMS; HEXAGONAL SEARCH; ARCHITECTURE; ELIMINATION;
   PATTERN; MPEG2
AB This paper presents a new spatio-temporal motion estimation algorithm and its VLSI architecture for video coding based on algorithm and architecture co-design methodology. The algorithm consists of the new strategies of spatio-temporal motion vector prediction, modified one-at-a-time search scheme, and multiple update paths derived from optimization theory. The hardware specification is for high-definition video coding. We applied the ME algorithm to H.264 reference software. Our algorithm surpasses recently published research and achieves close performance to full search. The VLSI implementation proves the low cost feature of our algorithm. The algorithm and architecture co-design concept is highly emphasized in this paper. We provide some quantitative example to show the necessity of algorithm and architecture co-design.
C1 Natl Cheng Kung Univ, Dept Elect Engn, Media SoC Lab, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Lee, GG (corresponding author), Natl Cheng Kung Univ, Dept Elect Engn, Media SoC Lab, 1 Univ Rd, Tainan 70101, Taiwan.
EM clee@mail.ncku.edu.tw; n2894155@mail.ncku.edu.tw;
   n2894157@mail.ncku.edu.tw; n2693238@cc-mail.ncku.edu.tw;
   n2694447@mail.ncku.edu.tw
CR BHASKARAN V, 1997, IMAGE VIDEO COMPRESS, P117
   Bierling M., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V1001, P942, DOI 10.1117/12.969046
   Brünig M, 2001, IEEE T CIRC SYST VID, V11, P241, DOI 10.1109/76.905989
   Chen CY, 2006, IEEE T CIRCUITS-I, V53, P578, DOI 10.1109/TCSI.2005.858488
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   Chimienti A, 2002, IEEE T IMAGE PROCESS, V11, P387, DOI 10.1109/TIP.2002.999673
   de Haan G, 1998, IEEE T CIRC SYST VID, V8, P85, DOI 10.1109/76.660831
   de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088
   *ISO IEC, 1996, 13818 ISOIEC
   *ISO IEC, 1993, 11172 ISOIEC
   *ISO IEC, 2000, 144962 ISOIEC
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   KOGA T, 1981, P NTC 81 NEW ORL LA
   KONIG J, 1995, MICROPROC MICROPROG, V41, P339, DOI 10.1016/0165-6074(95)00020-O
   LEE GG, 2004, P 47 MIDW S CIRC SYS, V2, P449
   Lengwehasatit K, 2001, IEEE T CIRC SYST VID, V11, P139, DOI 10.1109/76.905981
   Luo JH, 2002, IEEE T CIRC SYST VID, V12, P700, DOI 10.1109/TCSVT.2002.800859
   Montrucchio B, 2005, IEEE T CIRC SYST VID, V15, P210, DOI 10.1109/TCSVT.2004.841689
   Murachi Y, 2005, IEICE T FUND ELECTR, VE88A, P3492, DOI 10.1093/ietfec/e88-a.12.3492
   Namuduri KR, 2004, IEEE T CIRC SYST VID, V14, P1111, DOI 10.1109/TCSVT.2004.831975
   Natarajan B, 1997, IEEE T CIRC SYST VID, V7, P702, DOI 10.1109/76.611181
   Nie Y, 2005, IEEE T CIRC SYST VID, V15, P789, DOI 10.1109/TCSVT.2005.848305
   Song BC, 2003, P SOC PHOTO-OPT INS, V5022, P236, DOI 10.1117/12.476525
   Song XD, 2000, IEEE T CIRC SYST VID, V10, P1015, DOI 10.1109/76.875506
   SRINIVASAN R, 1985, IEEE T COMMUN, V33, P888, DOI 10.1109/TCOM.1985.1096398
   Tabatabai AJ, 1998, J FRANKLIN I, V335B, P1411, DOI 10.1016/S0016-0032(98)00007-6
   TEKALP, 1995, DIGITAL VIDEO PROCES, P72
   Tourapis AM, 2001, P SOC PHOTO-OPT INS, V4310, P883
   Venkatachalapathya K, 2004, J VIS COMMUN IMAGE R, V15, P203, DOI 10.1016/j.jvcir.2003.08.001
   Wang CN, 2004, IEEE T CIRC SYST VID, V14, P429, DOI 10.1109/TCSVT.2004.825550
   Yi X, 2005, PROC SPIE, V5685, P995, DOI 10.1117/12.588128
   ZHANG N, 2001, THESIS U CALIFORNIA
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu C, 2004, IEEE T CIRC SYST VID, V14, P1210, DOI 10.1109/TCSVT.2004.833166
   Zhu C, 2005, IEEE T IMAGE PROCESS, V14, P213, DOI 10.1109/TIP.2004.840702
   ZHU S, 1998, IEEE T IMAGE PROCESS, V9, P369
NR 36
TC 26
Z9 29
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2007
VL 9
IS 3
BP 455
EP 465
DI 10.1109/TMM.2006.889355
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 148PW
UT WOS:000245088100002
DA 2024-07-18
ER

PT J
AU Tseng, YH
   Wu, EHK
   Chen, GH
AF Tseng, Yi-Hsien
   Wu, Eric Hsiao-Kuang
   Chen, Gen-Huey
TI Scene-change aware dynamic bandwidth allocation for real-time VBR video
   transmission over IEEE 802.15.3 wireless home networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE dynamic bandwidth allocation; IEEE 802.15.3; NLMS; QoS
ID PREDICTION; SIZE
AB IEEE 802.15.3, an emerging wireless technology, was designed to provide high-quality multimedia services at home. Dynamic bandwidth allocation for a multimedia connection should be considered in order to achieve higher channel utilization, less buffer and less delay, especially for variable bit rate (VBR) multimedia connections. For real-time VBR videos, the bandwidth requirement should be predicted adaptively for effective channel-time requests. Previously, the adaptive least-mean square (LMS) algorithm with fixed step size was applied to predict channel time requirements due to its simplicity and relatively good performance. However, the performance might degrade when scene changes occurred. In this paper, we modify the variable step-size LMS algorithm and apply it as our predictor (VSSNLMS) so that the prediction errors on scene changes can be effectively reduced. Using the prediction results of VSSNLMS, we propose a dynamic bandwidth-allocation scheme that is scene-change aware and can guarantee the delay bound of real-time VBR videos. Simulation results show that the VSSNLMS predictor is superior to previous LMS-type predictors in performance, and the proposed scheme has better performance in channel utilization, buffer usage, and packet loss.
C1 Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
   Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 32054, Taiwan.
C3 National Taiwan University; National Central University
RP Tseng, YH (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
EM d91007@csie.ntu.edu.tw; hsiao@csie.ncu.edu.tw; ghchen@csie.ntu.edu.tw
CR Adas AM, 1998, IEEE ACM T NETWORK, V6, P635, DOI 10.1109/90.731200
   [Anonymous], ADAPTIVE FILTER THEO, DOI DOI 10.1109/ISCAS.2017.8050871
   [Anonymous], TIME SERIES ANAL FOR
   [Anonymous], 1985, Adaptive Signal Processing
   [Anonymous], P IEEE ICC
   [Anonymous], 1994, ACM SIGCOMM
   CHIRUVOLU G, 1998, COMPUT COMMUN REV, V28, P27
   DALQIC I, 1997, IEEE J SEL AREA COMM, V15, P1115
   FENG S, 1999, P IEEE GLOBECOM 99 A, V1, P209
   HOSKING JRM, 1981, BIOMETRIKA, V68, P165, DOI 10.1093/biomet/68.1.165
   *IEEE, 2003, 802153 IEEE
   KWONG RH, 1992, IEEE T SIGNAL PROCES, V40, P1633, DOI 10.1109/78.143435
   LELAND WE, 1994, IEEE ACM T NETWORK, V2, P1, DOI 10.1109/90.282603
   Lopez-Ardao J. C., 2000, ACM Transactions on Modeling and Computer Simulation, V10, P125, DOI 10.1145/364996.365004
   Mandic DP, 2004, IEEE SIGNAL PROC LET, V11, P115, DOI 10.1109/LSP.2003.821649
   REISSLEIN M, 2003, TRAFFIC QUALITY CHAR
   Sadek N, 2003, IEEE IC COMP COM NET, P359, DOI 10.1109/ICCCN.2003.1284194
   Seeling P, 2004, IEEE COMMUN SURV TUT, V6, P58, DOI 10.1109/COMST.2004.5342293
   Sen S, 2000, IEEE T MULTIMEDIA, V2, P37, DOI 10.1109/6046.825793
   Shu YT, 2000, IEEE ICC, P1325, DOI 10.1109/ICC.2000.853713
   Stroh S, 2003, IEEE SPECTRUM, V40, P23, DOI 10.1109/MSPEC.2003.1228004
   Yoo SJ, 2002, IEEE T BROADCAST, V48, P10, DOI 10.1109/11.992849
NR 22
TC 19
Z9 23
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2007
VL 9
IS 3
BP 642
EP 654
DI 10.1109/TMM.2006.888019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 148PW
UT WOS:000245088100018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhu, P
   Zeng, WJ
   Li, C
AF Zhu, Peng
   Zeng, Wenjun
   Li, Chunwen
TI Joint design of source rate control and QoS-aware congestion control for
   video streaming over the Internet
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE congestion control; cross-layer design; Internet; QoS; video streaming
ID ADAPTATION
AB Multimedia streaming over the Internet has been a very challenging issue due to the dynamic uncertain nature of the channels. This paper proposes an algorithm for the joint design of source rate control and congestion control for video streaming over the Internet. With the incorporation of a virtual network buffer management mechanism (VB), the quality of service (QoS) requirements of the application can be translated into the constraints of the source rate and the sending rate. Then at the application layer, the source rate control is implemented based on the derived constraints, and at the transport layer, a QoS-aware congestion control mechanism is proposed that strives to meet the send rate constraint derived from VB, by allowing temporary violation of transport control protocol (TCP)-friendliness when necessary. Long-term TCP-friendliness, nevertheless, is preserved by introducing a rate-compensation algorithm. Simulation results show that compared with traditional source rate/congestion control algorithms, this cross-layer design approach can better support the QoS requirements of the application, and significantly improve the playback quality by reducing the overflow and underflow of the decoder buffer, and improving quality smoothness, while maintaining good long-term TCP-friendliness.
C1 Hitachi China R&D Corp, Beijing, Peoples R China.
   Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   Univ Missouri, Dept Comp Engn, Columbia, MO 65211 USA.
C3 Tsinghua University; University of Missouri System; University of
   Missouri Columbia
RP Zhu, P (corresponding author), Hitachi China R&D Corp, Beijing, Peoples R China.
EM pzhu@hitachi.cn; zengw@missouri.edu; lcw@mail.tsinghua.edu.cn
CR [Anonymous], 3448 IETF RFC
   Bansal D, 2001, IEEE INFOCOM SER, P631, DOI 10.1109/INFCOM.2001.916251
   Cai L, 2005, IEEE T MULTIMEDIA, V7, P339, DOI 10.1109/TMM.2005.843360
   de Cuetos P, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P405, DOI 10.1109/ICME.2002.1035804
   de Cuetos P., 2002, NOSSDAV '02: Proceedings of the 12th international workshop on Network and operating systems support for digital audio and video, P3
   Fenger J, 1999, ENVIRONM POLLUT SER, V1, P3
   Floyd S., NETWORK SIMULATOR LB
   FLOYD S, 2005, INTERNET DRAFT IEFT
   Hsu CY, 1997, IEEE J SEL AREA COMM, V15, P1016, DOI 10.1109/49.611156
   Jacobs DE, 1998, INT J ENVIRON POLLUT, V9, P126
   Kalman M, 2004, IEEE T CIRC SYST VID, V14, P841, DOI 10.1109/TCSVT.2004.828335
   Kim T, 2005, IEEE J SEL AREA COMM, V23, P344, DOI 10.1109/JSAC.2004.839390
   KIM T, 1999, P INT C COMP COMM NE, P412
   Kim YG, 2004, IEEE T CIRC SYST VID, V14, P256, DOI 10.1109/TCSVT.2003.819186
   PADHYE JD, 2000, THESIS U MASSACHUSET
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   Rejaie R, 1999, IEEE INFOCOM SER, P1337, DOI 10.1109/INFCOM.1999.752152
   Ribas-Corbera J, 2003, IEEE T CIRC SYST VID, V13, P674, DOI 10.1109/TCSVT.2003.814965
   Sastry NR, 2005, IEEE ACM T NETWORK, V13, P330, DOI 10.1109/TNET.2005.845545
   SCHULZRINNE H, 2003, 3550 FETE RFC
   Sehgal A, 2004, IEEE IMAGE PROC, P2083
   Sen S, 2000, IEEE T MULTIMEDIA, V2, P37, DOI 10.1109/6046.825793
   Shakkottai S, 2003, IEEE COMMUN MAG, V41, P74, DOI 10.1109/MCOM.2003.1235598
   SISALEM D, 2000, THESIS TU BERLIN BER
   Viéron J, 2004, IEEE T MULTIMEDIA, V6, P634, DOI [10.1109/TMM.2004.830805, 10.1109/tmm.2004.830805]
   Wang B., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P908
   Widmer J, 2004, ACM SIGCOMM COMP COM, V34, P137, DOI 10.1145/997150.997162
   Widmer J, 2001, IEEE NETWORK, V15, P28, DOI 10.1109/65.923938
   WIDMER J, 2004, INTERNET DRAFT
   Xie B., 2004, P IEEE INT C MULT EX
   Yang YR, 2000, 2000 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P187, DOI 10.1109/ICNP.2000.896303
   ZHU P, 2006, P IEEE INT C MULT EX
NR 32
TC 29
Z9 29
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2007
VL 9
IS 2
BP 366
EP 376
DI 10.1109/TMM.2006.886284
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 135CO
UT WOS:000244131900014
DA 2024-07-18
ER

PT J
AU Wang, JZ
   Yu, PS
AF Wang, Jarnes Z.
   Yu, Philip S.
TI Fragmental proxy caching for streaming multimedia objects
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE fragmental proxy caching; multimedia streaming; tunable victimization
   procedure; VCR functions
ID VIDEO
AB In this paper, a fragmental proxy-caching scheme that efficiently manages the streaming multimedia data in proxy cache is proposed to improve the quality of streaming multimedia services. The novel data-fragmentation method in this scheme not only provides finer granularity caching units to allow more effective cache replacement, but also offers a unique and natural way of handling the interactive VCR functions in the proxy-caching environment. Furthermore, a cache-replacement scheme, based on user request arrival rates for different multimedia objects and the playback rates of these objects, is proposed to address the drawbacks in existing cache-replacement schemes, most of which consider only the user access frequencies in their cache-replacement decisions. In this cache-replacement scheme, a sliding history window is employed to monitor the dynamic user request arrivals, and a tunable-victimization procedure is used to provide an excellent method of managing the cached multimedia data in accordance with different quality-of-service requirements of the streaming multimedia applications. Performance studies demonstrate that the fragmental proxy-caching scheme significantly outperforms other caching schemes, in terms of byte-hit ratio and the number of delayed starts, and can be tuned to either maximize the byte-hit ratio or minimize the number of delayed starts.
C1 Clemson Univ, Dept Comp Sci, Clemson, SC 29634 USA.
   IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA.
C3 Clemson University; International Business Machines (IBM)
RP Wang, JZ (corresponding author), Clemson Univ, Dept Comp Sci, Clemson, SC 29634 USA.
EM jzwang@cs.clemson.edu; psyu@us.ibm.com
RI Yu, Philip S/A-2815-2012
CR ALMEIDA JM, 2001, P MULT COM P NETW 20
   BALAFOUTIS E, LNCS, V2345, P214
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Chae YS, 2002, IEEE J SEL AREA COMM, V20, P1328, DOI 10.1109/JSAC.2002.802062
   CHEN MS, 1994, P ACM MULT, P391
   CHEN SQ, 2003, P 13 ACM INT WORKSH
   GUO L, 2005, P 25 INT C DISTR COM
   GUO Y, 2002, P IEEE ICC 2002 SEAT
   Kangasharju J, 2001, IEEE INFOCOM SER, P1791, DOI 10.1109/INFCOM.2001.916677
   KIM M, 2003, P IEEE INT C COMM MA, V3, P1557
   Lee D, 1999, PERFORMANCE EVALUATION REVIEW, SPECIAL ISSUE, VOL 27 NO 1, JUNE 1999, P134, DOI 10.1145/301464.301487
   Leung KY, 2004, WORLD WIDE WEB, V7, P297, DOI 10.1023/B:WWWJ.0000028182.49617.09
   Lim EJ, 2001, 15TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING, PROCEEDINGS, P720, DOI 10.1109/ICOIN.2001.905554
   LIU J, 2004, P IEEE INFOCOM 04 HO
   Miao ZR, 2002, IEEE J SEL AREA COMM, V20, P1315, DOI 10.1109/JSAC.2002.802061
   Paknikar S., 2000, Proceedings ACM Multimedia 2000, P13, DOI 10.1145/354384.354397
   PARK SH, 2001, WORKSH PAR DISTR COM
   Podlipnig S, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA49
   REISSLEIN M, 2000, P 1 INT WORKSH INT M, P588
   REISSLEIN M, 2000, P 1 INT WORKSH INT M
   ROBINSON JT, 1990, PERF E R SI, V18, P134, DOI 10.1145/98460.98523
   SEN S, 1999, P IEEE INFOCOM NEW Y
   Shen B, 2004, IEEE T MULTIMEDIA, V6, P375, DOI 10.1109/TMM.2003.822791
   SHEN B, 2004, P IEEE INFOCOM HONG
   TRAN DA, 2003, P IEEE S APPL INT OR
   Wang B, 2002, IEEE INFOCOM SER, P1726, DOI 10.1109/INFCOM.2002.1019426
   WANG RK, 2004, COHERENT DOMAIN OPTI, V2, P3
   Wessels D, 1998, IEEE J SEL AREA COMM, V16, P345, DOI 10.1109/49.669043
   Wu KL, 2004, IEEE T MULTIMEDIA, V6, P770, DOI 10.1109/TMM.2004.834870
   WU KL, 2001, P 10 INT C WORLD WID, P36
   Yeung SF, 2005, IEEE T MULTIMEDIA, V7, P330, DOI 10.1109/TMM.2005.843361
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
   Zink M, 2004, IEEE COMMUN MAG, V42, P96, DOI 10.1109/MCOM.2004.1321399
NR 33
TC 15
Z9 19
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JAN
PY 2007
VL 9
IS 1
BP 147
EP 156
DI 10.1109/TMM.2006.886379
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 119VE
UT WOS:000243041500014
DA 2024-07-18
ER

PT J
AU Grangetto, M
   Magli, E
   Olmo, G
AF Grangetto, Marco
   Magli, Enrico
   Olmo, Gabriella
TI Multimedia selective encryption by means of randomized arithmetic coding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE arithmetic coding; conditional access; JPEG 2000; selective encryption
ID GENERATION; SYSTEM
AB We propose a novel multimedia security framework based on a modification of the arithmetic coder, which is used by most international image and video coding standards as entropy coding stage. In particular, we introduce a randomized arithmetic coding paradigm, which achieves encryption by inserting some randomization in the arithmetic coding procedure; notably, and unlike previous works on encryption by arithmetic coding, this is done at no expense in terms of coding efficiency.
   The proposed technique can be applied to any multimedia coder employing arithmetic coding; in this paper we describe an implementation tailored to the JPEG 2000 standard. The proposed approach turns out to be robust towards attempts to estimating the image or discovering the key, and allows very flexible protection procedures at the code-block level, allowing to perform total and selective encryption, as well as conditional access.
C1 CERCOM, Dipartimento Elettr, Politecn Torino, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Grangetto, M (corresponding author), CERCOM, Dipartimento Elettr, Politecn Torino, I-10129 Turin, Italy.
EM marco.grangetto@polito.it; enrico.magli@polito.it;
   gabriella.olmo@polito.it
RI Grangetto, Marco/AFM-8024-2022; Olmo, Gabriella/AAB-4987-2021
OI Grangetto, Marco/0000-0002-2709-7864; OLMO,
   Gabriella/0000-0002-3670-9412
CR *AM NAT STAND I, 1985, X917 AM NAT STAND I
   Barbir A, 1997, SOUTHEAST SYMP SYSTE, P266, DOI 10.1109/SSST.1997.581631
   Bergen H. A., 1993, Computers & Security, V12, P157, DOI 10.1016/0167-4048(93)90099-Q
   BERGEN HA, 1992, COMPUT SECURITY, V11
   Bernardini R, 2001, IEEE T CIRCUITS-I, V48, P552, DOI 10.1109/81.922458
   BERNSTEIN GM, 1990, IEEE T CIRCUITS SYST, V37, P1157, DOI 10.1109/31.57604
   BLUM L, 1986, SIAM J COMPUT, V15, P364, DOI 10.1137/0215025
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   CLEARY JG, 1995, COMPUT SECUR, V14, P167, DOI 10.1016/0167-4048(95)97050-K
   DENNING DE, 1994, IEEE COMMUN MAG, V32, P58, DOI 10.1109/35.312844
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   *FIPS, 2001, 197 FIPS PUBS
   *FIPS, 1993, 462 FIPS PUBS
   FLUHRER SR, 2001, P ANN INT WORKSH SEL
   Gerosa A, 2002, IEEE T CIRCUITS-I, V49, P993, DOI 10.1109/TCSI.2002.800833
   GOLDBURG B, 1993, IEEE J SEL AREA COMM, V11, P735, DOI 10.1109/49.223875
   GRANGETTO M, 2004, P IEEE INT WORKSH MU
   GROSBOIS R, 2001, P SPIE 46 ANN M
   Hu YP, 2004, IEEE T INFORM THEORY, V50, P714, DOI 10.1109/TIT.2004.825256
   *ISO IEC, 1544442002 ISOIEC
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   JONES D, 1988, COMMUN ACM       AUG, P996
   Kankanhalli MS, 2002, IEEE T CONSUM ELECTR, V48, P356, DOI 10.1109/TCE.2002.1010142
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   LIU X, 1997, P 6 IMA INT C CRYPT
   Lookabaugh T, 2004, IEEE COMMUN MAG, V42, P124, DOI 10.1109/MCOM.2004.1299355
   MASSEY JL, 1988, P IEEE, V76, P533, DOI 10.1109/5.4440
   MOO PW, 1999, P IEEE INT C MULT CO
   MOO PW, 1999, P IEEE INT C IM PROC
   Naor D, 2003, COMPUTER, V36, P47, DOI 10.1109/MC.2003.1212690
   OKAMOTO E, 1989, IEEE J SEL AREA COMM, V7, P481, DOI 10.1109/49.17711
   Sadourny W, 2003, IEEE T CONSUM ELECTR, V49, P846, DOI 10.1109/TCE.2003.1261164
   Schneier B., 1995, APPL CRYPTOGRAPHY, V2nd
   Servetti A, 2002, IEEE T SPEECH AUDI P, V10, P637, DOI 10.1109/TSA.2002.804300
   Taubman D., 2012, JPEG2000: image compression fundamentals, standards and practice, V642
   Wee SJ, 2001, P IEEE INT C IM PROC
   WEN J, 2001, P INT C MED FUT
   Wen JT, 2002, IEEE T CIRC SYST VID, V12, P545, DOI 10.1109/TCSVT.2002.800321
   Witten I. H., 1988, Computers & Security, V7, P397, DOI 10.1016/0167-4048(88)90580-9
   WU M, 2002, P IEEE INT WORKSH MU
   WU Y, 2004, P IEEE INT C IM PROC
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   ZHU Y, 2001, P IEEE INT C IM PROC
NR 43
TC 155
Z9 172
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2006
VL 8
IS 5
BP 905
EP 917
DI 10.1109/TMM.2006.879919
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 091TY
UT WOS:000241052400003
DA 2024-07-18
ER

PT J
AU De Mulder, T
   Martens, JP
   Pauws, S
   Vignoli, F
   Lesaffre, M
   Leman, M
   De Baets, B
   De Meyer, H
AF De Mulder, Tom
   Martens, Jean-Pierre
   Pauws, Steffen
   Vignoli, Fabio
   Lesaffre, Micheline
   Leman, Marc
   De Baets, Bernard
   De Meyer, Hans
TI Factors affecting music retrieval in query-by-melody
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE error analysis; man-machine systems; multimedia systems; music
AB This paper assesses the impact of three factors on the music retrieval accuracy of a query-by-melody (QBM) system. The investigated factors are the accuracy of the query provider (the singer), the query transcription accuracy of the acoustic front-end and the length of the query. The music retrieval accuracy is described in terms of a new concept, called the remaining information fraction (RIF). With this new concept it is possible to get more insight in the way the individual factors affect the music retrieval accuracy. The experimental results reported in this paper support the following conclusions: i) the music retrieval accuracy of a QBM system, as assessed on a large set of queries, is strongly correlated with the query transcription accuracy of its front-end, as assessed on a small set of manually transcribed queries, ii) there is still a significant gap between the accuracies obtained with manual and automatically generated query transcriptions, and iii) the music retrieval accuracy starts to drop quickly as soon as the query consists of less than 20 notes.
C1 Univ Ghent, Elect & Informat Syst Dept, B-9000 Ghent, Belgium.
   Philips Res Labs, Eindhoven, Netherlands.
   Univ Ghent, Dept Art Mus & Theatre Sci, B-9000 Ghent, Belgium.
   Univ Ghent, Dept Appl Math Biometr & Proc Control, B-9000 Ghent, Belgium.
   Univ Ghent, Dept Appl Math & Comp Sci, B-9000 Ghent, Belgium.
C3 Ghent University; Philips; Philips Research; Ghent University; Ghent
   University; Ghent University
RP De Mulder, T (corresponding author), Univ Ghent, Elect & Informat Syst Dept, B-9000 Ghent, Belgium.
EM tom.demulder@ugent.be; martens@elis.ugent.be; steffen.pauws@philips.com;
   fabio.vignoli@philips.com; micheline.lesaffre@ugent.be;
   marc.leman@ugent.be; bernard.debaets@ugent.be; hans.demeyer@ugent.be
RI ; De Baets, Bernard/E-8877-2010
OI Leman, Marc/0000-0002-9780-2194; De Baets, Bernard/0000-0002-3876-620X
CR Adams N., 2004, INT SOC MUSIC INFORM, P303
   Clarisse L., 2002, Proceedings of the International Conference on Music Information Retrieval, P116
   Dannenberg R.B., 2003, Proceedings of the International Conference on Music Information Retrieval, P41
   De Mulder T, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P257
   Doraisamy S., 2002, Proceedings of the Third International Conference on Music Information Retrieval, P101
   Dowling W.J., 1986, MUSIC COGNITION
   FISHER L, 1993, BIOSTATISTICS CHAPTE
   GHIAS A, 1995, P INT C ACM MULT, P213
   HEINZ T, 2003, P 114 AUD ENG SOC CO
   Kosugi N., 2000, Proceedings ACM Multimedia 2000, P333, DOI 10.1145/354384.354520
   LESAFFRE M, 2003, P 4 INT C MUS INF RE, P65
   LEVITIN DJ, 1994, PERCEPT PSYCHOPHYS, V56, P414, DOI 10.3758/BF03206733
   Levitin DJ, 1996, PERCEPT PSYCHOPHYS, V58, P927, DOI 10.3758/BF03205494
   Lie WN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P929
   MCNAB RJ, 1997, DIGITAL LIB MAGAZINE, P11
   Pauws S., 2002, INT SOC MUSIC INFORM, P187
   Pauws S., 2003, P INT C MUS INF RETR, P57
   Rolland PY, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P81, DOI 10.1145/319463.319473
   Shalev-Shwartz S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P331
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shifrin Jonah., 2003, Proceedings of the 4th International Conference on Music Information Retrieval, P33
   Song J., 2002, P INT S MUS INF RETR, P133
   VOORHEES E, 1999, P 8 TEXT RETR C TREC, P83
NR 24
TC 5
Z9 5
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2006
VL 8
IS 4
BP 728
EP 739
DI 10.1109/TMM.2006.876291
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Telecommunications
GA 069BS
UT WOS:000239420300008
DA 2024-07-18
ER

PT J
AU Habib, A
   Chuang, J
AF Habib, Ahsan
   Chuang, John
TI Service differentiated peer selection: An incentive mechanism for
   peer-to-peer media streaming
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE incentive mechanism; media streaming; peer-to-peer networks; rank order
   tournaments
AB We propose a service differentiated peer selection mechanism for peer-to-peer media streaming systems. The mechanism provides flexibility and choice in peer selection to the contributors of the system, resulting in high quality streaming sessions. Free-riders are given limited options in peer selection, if any, and hence receive low quality streaming. The proposed incentive mechanism follows the characteristics of rank-order tournaments theory that considers only the relative performance of the players, and the top prizes are awarded to the winners of the tournament. Using rank-order tournaments, we analyze the behavior of utility maximizing users. Through simulation and wide-area measurement studies, we verify that the proposed incentive mechanism can provide near optimal streaming quality to the cooperative users until the bottleneck shifts from the streaming sources to the network.
C1 Siemens Technol Business Ctr, Berkeley, CA 94704 USA.
   Univ Calif Berkeley, Sch Informat Management & Syst, Berkeley, CA 94720 USA.
C3 Siemens AG; University of California System; University of California
   Berkeley
RP Habib, A (corresponding author), Siemens Technol Business Ctr, Berkeley, CA 94704 USA.
EM ahsan.habib@ttb.siemens.com; chuang@sims.berkeley.edu
OI Chuang, John/0000-0003-4348-6226
CR ADAR E, 2000, FIRST MONDAY, V5
   [Anonymous], P 13 INT C MOD TECHN
   Bognanno ML, 2001, J LABOR ECON, V19, P290, DOI 10.1086/319562
   BURAGOHAIN C, 2003, P P2P            SEP
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   CHU YH, 2004, P ACM SIGCOMM 04 AUG
   COHEN B, 2003, WORKSHOP EC P2P  JUN
   Feldman M., 2004, EC 04, P102, DOI [10.1145/988772.988788, DOI 10.1145/988772.988788]
   Friedman EJ, 2001, J ECON MANAGE STRAT, V10, P173, DOI 10.1111/j.1430-9134.2001.00173.x
   Golle P., 2001, Proceedings of the 3rd ACM Conference on Electronic Commerce. EC'01, P264, DOI DOI 10.1145/501158.501193
   Gupta M., 2003, P 13 ACM INT WORKSHO, P144
   Heffeeda M., 2003, P ACM MULTIMEDIA, P45
   Jain M, 2003, IEEE ACM T NETWORK, V11, P537, DOI 10.1109/TNET.2003.815304
   JIANG X, 2002, P IEEE INT C MULT EX
   Kamvar M. T., 2003, P 12 INT C WORLD WID, P640
   LAZEAR EP, 1981, J POLIT ECON, V89, P841, DOI 10.1086/261010
   LI J, 2004, MSRTR2004101
   MA RTB, 2004, P JOINT INT C MEAS M, P189
   McCanne S., NETWORK SIMULATOR NS
   Nowak MA, 1998, NATURE, V393, P573, DOI 10.1038/31225
   OKEEFFE M, 1984, J LABOR ECON, V2, P27, DOI 10.1086/298022
   PADMANABHAN VN, 2003, P IEEE INT C NETW PR
   RANGANATHAN K, 2003, WORKSHOP EC PEER PEE
   Saroiu S, 2003, MULTIMEDIA SYST, V9, P170, DOI 10.1007/s00530-003-0088-1
   Turner D., 2003, The lightweight currency protocol
   VISHNUMURTHY V, 2003, WORKSHOP EC PEER JUN
   WILCOXOHEARN B, 2002, P 1 INT WORKSH PEER
NR 27
TC 76
Z9 90
U1 0
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2006
VL 8
IS 3
BP 610
EP 621
DI 10.1109/TMM.2006.870724
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 046OX
UT WOS:000237822000017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chakareski, J
   Frossard, P
AF Chakareski, J
   Frossard, P
TI Rate-distortion optimized distributed packet scheduling of multiple
   video streams over shared communication resources
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE distributed systems; multimedia streaming; optimization; packet
   scheduling; rate-distortion; video communication; wireless networks
ID WIRELESS; TRANSMISSION; NETWORKS
AB We consider the problem of distributed packet selection and scheduling for multiple video streams sharing a communication channel. An optimization framework is proposed, which enables the multiple senders to coordinate their packet transmission schedules, such that the average quality over all video clients is maximized. The framework relies on rate-distortion information that is used to characterize a video packet. This information consists of two quantities: the size of the packet in bits, and its importance for the reconstruction quality of the corresponding stream. A distributed streaming strategy then allows for trading off rate and distortion, not only within a single video stream, but also across different streams. Each of the senders allocates to its own video packets a share of the available bandwidth on the channel in proportion to their importance. We evaluate the performance of the distributed packet scheduling algorithm for two canonical problems in streaming media, namely adaptation to available bandwidth and adaptation to packet loss through prioritized packet retransmissions. Simulation results demonstrate that, for the difficult case of scheduling nonscalably encoded video streams, our framework is very efficient in terms of video quality, both over all streams jointly and also over the individual videos. Compared to a conventional streaming system that does not consider the relative importance of the video packets, the gains in performance range up to 6 dB for the scenario of bandwidth adaptation, and even up to 10 dB for the scenario of random packet loss adaptation.
C1 Ecole Polytech Fed Lausanne, Signal Proc Inst, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Ecole Polytech Fed Lausanne, Signal Proc Inst, CH-1015 Lausanne, Switzerland.
EM jakov.cakareski@epfl.ch; pascal.frossard@cpfl.ch
RI Frossard, Pascal/AAF-2268-2019
CR [Anonymous], 1998, Network Optimization: Continuous and Discrete Models
   Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   Bjork N, 1998, IEEE T CONSUM ELECTR, V44, P88, DOI 10.1109/30.663734
   Bucciol P, 2004, GLOB TELECOMM CONF, P3027
   Chakareski J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1387, DOI 10.1109/ICME.2004.1394489
   Chakareski J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P1001
   CHAKARESKI J, 2005, P ICME AMST THE NETH
   CHAKARESKI J, 2006, P INT PACK VID WORKS
   Chen M, 2004, IEEE T CONSUM ELECTR, V50, P158, DOI 10.1109/TCE.2004.1277856
   CHEN Y, 2003, P IEEE INT C IM PROC, V3, P285
   Davies AC, 2002, 1ST IEEE INTERNATIONAL CONFERENCE ON CIRCUITS AND SYSTEMS FOR COMMNICATIONS, PROCEEDINGS, P206, DOI 10.1109/OCCSC.2002.1029081
   Etoh M, 2005, P IEEE, V93, P111, DOI 10.1109/JPROC.2004.839605
   HE L, 2005, P INFOCOM MIAM FL MA
   Horn U, 1999, SIGNAL PROCESS-IMAGE, V15, P77, DOI 10.1016/S0923-5965(99)00025-9
   *ITU T, 2003, H264 ITUT
   KALMAN M, 2005, P ICIP GEN IT SEPT
   KHANSARI M, 1994, IEEE IMAGE PROC, P258, DOI 10.1109/ICIP.1994.413315
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Li Q, 2004, IEEE T MULTIMEDIA, V6, P278, DOI 10.1109/TMM.2003.822792
   Majumdar A, 2002, IEEE T CIRC SYST VID, V12, P524, DOI 10.1109/TCSVT.2002.800315
   Masala E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P345
   McCanne S, 1997, IEEE J SEL AREA COMM, V15, P983, DOI 10.1109/49.611154
   Pahlavan Kaveh., 2001, PRINCIPLES WIRELESS, V1st
   Radha H, 1999, SIGNAL PROCESS-IMAGE, V15, P95, DOI 10.1016/S0923-5965(99)00026-0
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   SICHER A, 2000, IEEE S EM TECHN BROA
   Stevens W, 1994, TCP/ IP Illustrated, V1
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   TU W, 2004, P INT PACK VID WORKS
   VANBEEK P, 2004, P SPIE C VIS COMM IM
   Warabino T, 2000, IEEE COMMUN MAG, V38, P66, DOI 10.1109/35.874971
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   XU X, 2004, P ICASSP MONTR QC CA, V5, P989
NR 33
TC 69
Z9 80
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2006
VL 8
IS 2
BP 207
EP 218
DI 10.1109/TMM.2005.864284
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 028GY
UT WOS:000236476300003
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Tang, CW
   Chen, CH
   Yu, YH
   Tsai, CJ
AF Tang, CW
   Chen, CH
   Yu, YH
   Tsai, CJ
TI Visual sensitivity guided bit allocation for video coding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE bit allocation; H.264; psychovisual model; rate-visual distortion
   analysis; visual attention; visual masking
AB A video bit allocation technique adopting a visual distortion sensitivity model for better rate-visual distortion Coding control is proposed in this paper. Instead of applying complicated semantic understanding, the proposed automatic distortion sensitivity analysis process analyzes both the motion and the texture structures in the video sequences in order to achieve better bit allocation for rate-constrained video coding. The proposed technique evaluates the perceptual distortion sensitivity on a macroblock basis, and allocates fewer bits to regions permitting large perceptual distortions for rate reduction. The proposed algorithm can be incorporated into existing video coding rate control schemes to achieve same visual quality at reduced bitrate. Experiments based on H.264 JM7.6 show that this technique achieves bit-rate saving of up to 40.61%. However, the conducted subjective viewing experiments show that there is no perceptual quality degradation.
C1 Ind Technol Res Inst, Mech Ind Res Labs, Hsinchu 310, Taiwan.
   Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu 300, Taiwan.
C3 Industrial Technology Research Institute - Taiwan; National Yang Ming
   Chiao Tung University
RP Ind Technol Res Inst, Mech Ind Res Labs, Hsinchu 310, Taiwan.
EM cwtang@itri.org.tw; chingho@csie.nctu.edu.tw; yhyu@csie.nctu.edu.tw;
   cjtsai@csie.nctu.edu.tw
CR Adiono T, 2000, 2000 IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P461, DOI 10.1109/APCCAS.2000.913536
   [Anonymous], 2000, FIN REP VID QUAL EXP
   [Anonymous], 1992, R. woods digital image processing
   [Anonymous], 1999, Network: Computation in Neural Systems
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHEN MJ, 2003, IEEE T CONSUMER ELEC, V49
   Girod B., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V1001, P398, DOI 10.1117/12.968979
   HAN J, 2003, P INT C IM PROC, V2, P403
   ITTI L, 1998, IEEE T PATT ANAL MAC, V20
   James W., 1890, The Principles of Psychology, V1
   KELLY DH, 1977, OPT ACTA, V24, P107, DOI 10.1080/713819495
   LAI KC, 2002, P INT C SIGN PROC AU, V1, P656
   Lee SH, 2001, J MATER PROCESS MANU, V10, P7, DOI [10.1177/1062065602010001388, 10.1106/106206502026388]
   MA YF, 2002, ACM MULTIMEDIA 02
   MA YF, 2002, P ICIP, V1, pI129
   *MPEG, 2004, MPEG M
   NETRAVALI AN, 1980, P IEEE, V68, P366, DOI 10.1109/PROC.1980.11647
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Osberger W, 1998, INT C PATT RECOG, P701, DOI 10.1109/ICPR.1998.711240
   SENGUPTA S, 2003, P ICIP, V3, P793
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   WANG Z, 2000, P INT C MULT PROC SY
   WONG CW, 2003, P INT C MULT EXP JUL, V3, P361
NR 23
TC 84
Z9 92
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2006
VL 8
IS 1
BP 11
EP 18
DI 10.1109/TMM.2005.861295
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 005UR
UT WOS:000234850000002
DA 2024-07-18
ER

PT J
AU Aucouturier, JJ
   Pachet, F
   Sandler, M
AF Aucouturier, JJ
   Pachet, F
   Sandler, M
TI "The way it sounds": Timbre models for analysis and retrieval of music
   signals
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE feature extraction; information retrieval; multimedia database; music;
   pattern recognition
AB Electronic Music Distribution is in need of robust and automatically extracted music descriptors. An important attribute of a piece of polyphonic music is what is commonly referred to as "the way it sounds". While there has been a large quantity of research done to model the timbre of individual instruments, little work has been done to analyze "real world" timbre mixtures such as the ones found in popular music. In this paper, we present our research about such "polyphonic timbres". We describe an effective way to model the textures found in a given music signal, and show that such timbre models provide new solutions to many issues traditionally encountered in music signal processing and music information retrieval. Notably, we describe their applications for music similarity, segmentation and pattern induction.
C1 SONY Comp Sci Lab, F-75005 Paris, France.
   Univ London Queen Mary Coll, Dept Elect Engn, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP Aucouturier, JJ (corresponding author), SONY Comp Sci Lab, F-75005 Paris, France.
EM jj@csl.sony.fr; pachet@csl.sony.fr; mark.sandler@elec.qmul.ac.uk
OI Aucouturier, Jean-Julien/0000-0002-4477-4812
CR Allamanche E., 2001, PROC 2 INT S MUSIC I
   Aucouturier J.-J., 2002, P 3 INT S MUS INF RE
   Aucouturier Jean-Julien., 2004, J NEGATIVE RESULTS S, V1
   Aucouturier JJ, 2003, J NEW MUSIC RES, V32, P83, DOI 10.1076/jnmr.32.1.83.16801
   AUCOUTURIER JJ, 2001, P 2 INT S MUS INF RE
   AUCOUTURIER JJ, 2001, P 110 CONV AES AMST
   AUCOUTURIER JJ, 2002, P AES 22 INT C VIRT
   BARTSCH M, 2001, P 2001 IEEE WORKSH A
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Crochemore M., 1994, TEXT ALGORITHMS
   DUBNOV S, 1999, STOCHASTIC MODELING
   Foote J, 2003, P SPIE STORAGE RETRI, V5021
   Goto M., 2002, P 3 INT C MUS INF RE, V2, P287
   Herrera-Boyer P, 2003, J NEW MUSIC RES, V32, P3, DOI 10.1076/jnmr.32.1.3.16798
   Klapuri AP, 2003, IEEE T SPEECH AUDI P, V11, P804, DOI 10.1109/TSA.2003.815516
   PACHET F, 2003, J AM SOC INFORM SCI
   PACHET F, 2001, P WED C FIR IT
   PEETERS G, 2002, P 3 INT S MUS INF RE
   Plumbley MD, 2002, CYBERNET SYST, V33, P603, DOI 10.1080/01969720290040777
   RABINER L, 1983, P IEEE, V77, P257
   Raphael C, 1999, IEEE T PATTERN ANAL, V21, P360, DOI 10.1109/34.761266
   ROSSIGNOL S, 1998, P INT COMP MUS C ANN
   SCHEIRER E, 2000, THESIS MIT CAMBRIDGE
   SCHWARZ D, 1999, P INT COMP MUS C BEI
   SIGIYAMA S, 1993, P INT C AC SPEECH SI, V2, P395
   TZANETAKIS G, 1999, IEEE WORKSH APPL SIG
   VOORHES E, 2000, P 8 TEXT RETR C TREC
NR 27
TC 67
Z9 79
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855 USA
SN 1520-9210
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2005
VL 7
IS 6
BP 1028
EP 1035
DI 10.1109/TMM.2005.858380
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 986SY
UT WOS:000233471200004
DA 2024-07-18
ER

PT J
AU Su, CW
   Liao, HYM
   Tyan, HR
   Fan, KC
   Chen, LH
AF Su, CW
   Liao, HYM
   Tyan, HR
   Fan, KC
   Chen, LH
TI A motion-tolerant dissolve detection algorithm
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE dissolve detection; fade detection; shot change detection
ID RETRIEVAL
AB Gradual shot change detection is one of the most important research issues in the field of video indexing/retrieval. Among the numerous types of gradual transitions, the dissolve-type gradual transition is considered the most common one, but it is also the most difficult one to detect. In most of the existing dissolve detection algorithms, the false/miss detection problem caused by motion is very serious. In this paper, we present a novel dissolve-type transition detection algorithm that can correctly distinguish dissolves from disturbance caused by motion. We carefully model a dissolve based on its nature and then use the model to filter out possible confusion caused by the effect of motion. Experimental results show that the proposed algorithm is indeed powerful.
C1 Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 320, Taiwan.
   Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, Taipei 242, Taiwan.
C3 National Central University; Academia Sinica - Taiwan; Fu Jen Catholic
   University
RP Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 320, Taiwan.
EM lucas@iis.sinica.edu.tw; liao@iis.sinica.edu.tw; kcfan@csie.ncu.edu.tw
RI Fan, K/GXH-3734-2022
CR [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Bertini M, 2001, PATTERN RECOGN LETT, V22, P503, DOI 10.1016/S0167-8655(00)00113-6
   Chen LF, 2002, IEEE T CIRC SYST VID, V12, P1, DOI 10.1109/76.981841
   Corridoni JM, 1998, PATTERN RECOGN, V31, P2027, DOI 10.1016/S0031-3203(98)00061-2
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   Fernando W. A. C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P299, DOI 10.1109/ICIP.1999.817121
   LI D, 2000, P 7 IEEE INT C EL CI, V1, P541
   LI ZN, 2000, P IEEE INT C IM PROC, V2, P295
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Lienhart R, 2001, PROC SPIE, V4315, P219, DOI 10.1117/12.410931
   NAM J, 2000, P IEEE INT C MULT EX
   Ngo CW, 2003, IEEE T IMAGE PROCESS, V12, P341, DOI 10.1109/TIP.2003.809020
   NGO CW, 1999, P IEEE COMP VIS PATT, V1, P36
   NGO CW, 2002, INT J COMPUT VIS, V50
   Özer IB, 2002, J VIS COMMUN IMAGE R, V13, P425, DOI 10.1006/jvci.2002.0509
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   Sahouria E, 1999, IEEE T CIRC SYST VID, V9, P1290, DOI 10.1109/76.809163
   Shan MK, 2001, PATTERN RECOGN LETT, V22, P517, DOI 10.1016/S0167-8655(00)00120-3
   Shih CC, 2001, LECT NOTES COMPUT SC, V2195, P819
   Wu M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P893, DOI 10.1109/ICIP.1998.723664
   ZABIH R, 1995, ACM J MULTIMEDIA SYS, V7
NR 22
TC 39
Z9 41
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2005
VL 7
IS 6
BP 1106
EP 1113
DI 10.1109/TMM.2005.858394
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 986SY
UT WOS:000233471200011
DA 2024-07-18
ER

PT J
AU Boggia, G
   Camarda, P
   Mazzeo, L
   Mongiello, M
AF Boggia, G
   Camarda, P
   Mazzeo, L
   Mongiello, M
TI Performance of batching schemes for multimedia-on-demand services
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE analytical and simulation model; hatching techniques; multimedia
   services
ID INTERACTIVE VIDEO
AB Recent advances in information and communication technologies have made multimedia-on-demand services technically and economically feasible. Important aspects of such systems are the resource sharing techniques, which allow the simultaneous service of a large number of users with considerable savings in terms of network bandwidth and server resources. In this paper, we report the results of a study which analyzes hatching and buffering techniques, which involves serving all video requests issued during a short interval of time with a single stream. The mathematical model, based on queueing networks, allows the evaluation of the main system performance (average and probability distribution of the number of streams, percentage reduction of resources, and so on) as a function of load and hatching interval duration. Simulation experiments confirm the analytical model in the whole range of considered conditions.
C1 Politecn Bari, Dept Elettrotecn & Elettron, I-70125 Bari, Italy.
   RSI Sistemi, Altran Grp, I-20123 Milan, Italy.
C3 Politecnico di Bari
RP Boggia, G (corresponding author), Politecn Bari, Dept Elettrotecn & Elettron, 4, I-70125 Bari, Italy.
EM g.boggia@poliba.it; camarda@poliba.it; luigi.mazzeo@rsisistemi.it;
   mongiello@poliba.it
RI Mongiello, Marina/M-7607-2019; Mongiello, Marina/E-8740-2015
OI Mongiello, Marina/0000-0002-1477-1434; Mongiello,
   Marina/0000-0002-1477-1434
CR Aggarwal CC, 2001, IEEE T COMPUT, V50, P97, DOI 10.1109/12.908987
   ALMEIDA J, 2001, P ACM SPIE MULT COMP, P200
   Almeroth KC, 1996, IEEE J SEL AREA COMM, V14, P1110, DOI 10.1109/49.508282
   Boggia G, 2002, INT J COMMUN SYST, V15, P531, DOI 10.1002/dac.550
   BRADSHAW MK, 2001, P ACM MULT OCT, P280
   CARTER SW, 1997, P ICCCN 97 LAS VEG N
   Chan SHG, 2001, IEEE ACM T NETWORK, V9, P125, DOI 10.1109/90.917070
   Dan A, 1996, P SOC PHOTO-OPT INS, V2667, P344, DOI 10.1117/12.235887
   DIJK NMV, 1993, QUEUING NETWORKS PRO
   DOUGALL MH, 1987, SIMULATING COMPUTER
   Eager D, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P199, DOI 10.1145/319463.319601
   EAGER D, 1998, P WORKSH MULT INF SY
   Eager DL, 2000, PERFORM EVALUATION, V42, P163, DOI 10.1016/S0166-5316(00)00029-8
   FONSECA NLS, 2002, IEEE T MULTIMEDIA, V4, P114
   Gao L., 2001, IEEE T MULTIMEDIA, V3, P405
   Gao LX, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P203
   GARCIA AL, 1989, PROBABILITY RANDOM P
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   GOLUBCHIK L, 1995, P ACM SIGMETRICS PER
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   KAMATH M, P 4 INT C DAT SYST A, P79
   Kleinrock L., 1975, Queueing Systems-Volume 1: Theory, V1
   Lau SW, 1998, MULTIMEDIA SYST, V6, P29, DOI 10.1007/s005300050074
   LAVENBERG SS, 1983, COMPUTER PERFORMANCE
   Li VOK, 1996, IEEE J SEL AREA COMM, V14, P1099, DOI 10.1109/49.508281
   Meliksetian D, 2000, IEEE T MULTIMEDIA, V2, P62, DOI 10.1109/6046.825798
   NUSSBAUMER JP, 1995, IEEE J SEL AREA COMM, V13, P779, DOI 10.1109/49.391753
   SEN S, 1999, P INFOOCM 99 MAR
   SEN S, 1999, P ITN WORKSH NETW OP
   SEN S, 2001, P IEEE IP CCC 2001 A
   Shachnai H, 1998, PERFORM EVALUATION, V33, P201, DOI 10.1016/S0166-5316(98)00017-0
   YU PS, 1995, MULTIMEDIA SYST, V3, P137, DOI 10.1007/BF02176235
   Zhang ZL, 1997, IEEE J SEL AREA COMM, V15, P1148, DOI 10.1109/49.611165
NR 33
TC 9
Z9 9
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2005
VL 7
IS 5
BP 920
EP 931
DI 10.1109/TMM.2005.854383
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 967IM
UT WOS:000232084900013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, CP
   Kuo, CCJ
AF Wu, CP
   Kuo, CCJ
TI Design of integrated multimedia compression and encryption systems
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE confidentiality; CELP; entropy coder; G.723.1 speech coding; Huffman
   coding; multimedia encryption; selective encryption; signal scrambling;
   QM coder
AB Two approaches for integrating encryption with multimedia compression systems are studied in this research, i.e., selective encryption and modified entropy coders with multiple statistical models. First, we examine the limitations of selective encryption using cryptanalysis, and provide examples that use selective encryption successfully. Two rules to determine whether selective encryption is suitable for a compression system are concluded. Next, we propose another approach that turns entropy coders into encryption ciphers using multiple statistical models. Two specific encryption schemes are obtained by applying this approach to the Huffman coder and the QM coder. It is shown that security is achieved without sacrificing the compression performance and the computational speed. This modified entropy coding methodology can be applied to most modern compressed audio/video such as MPEG audio, MPEG video, and JPEG/JPEG2000 images.
C1 Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
   Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
C3 University of Southern California; University of Southern California
RP Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
EM chungpin@sipi.usc.edu; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR AGI I, 1996, P ISOC SNDSS 96 FEB
   Barbir A, 1997, SOUTHEAST SYMP SYSTE, P266, DOI 10.1109/SSST.1997.581631
   Beker H., 1985, SECURE SPEECH COMMUN
   Bergen H. A., 1993, Computers & Security, V12, P157, DOI 10.1016/0167-4048(93)90099-Q
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   CLEARY JG, 1995, COMPUT SECUR, V14, P167, DOI 10.1016/0167-4048(95)97050-K
   DAWSON E, 1991, ELECTRON LETT, V27, P613, DOI 10.1049/el:19910385
   DIEZDELRIO L, 1994, P ICASSP 94 APR
   Droogenbroeck M. V., 2002, P ACIVS GHENT BELG S
   FILIOL E, 2001, P 8 IMA C CRYPT COD
   Gillman DW, 1996, IEEE T INFORM THEORY, V42, P972, DOI 10.1109/18.490558
   GOLDBURG B, 1993, IEEE J SEL AREA COMM, V11, P735, DOI 10.1109/49.223875
   GOLDBURG B, 1993, P I ELECTR ENG COMMU, V140, P235
   Kuo C. J., 1991, Proceedings. 25th Annual 1991 IEEE International Carnahan Conference on Security Technology (Cat. No.91CH3031-2), P149, DOI 10.1109/CCST.1991.202208
   LIM J, 1997, 2 AUSTR C INF SEC PR, P216
   LUBBE VD, 1998, BASIC METHODS CRYPTO
   Ma FL, 1996, ELECTRON LETT, V32, P719, DOI 10.1049/el:19960471
   Meyer J., 1995, SECURITY MECH MULTIM
   MILOSEVIC V, 1997, P IEEE INT C DIG SIG
   Nechvatal J., 2000, REPORT DEV ADV ENCRY
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   QIAO L, 1997, P 1 INT C IM SCI SYS
   Qiao L, 1998, INT J COMPUT GRAPH, V22
   QIAO L, 1997, P IEEE INT S CONS EL
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Servetti A, 2002, IEEE T SPEECH AUDI P, V10, P637, DOI 10.1109/TSA.2002.804300
   Servetti A, 2002, INT CONF ACOUST SPEE, P621
   SHI C, 1998, P 6 ACM INT C MULT S
   SHI C, 1999, P PDPTA 99 JUN, V6, P2822
   SPANOS GA, 1996, P 15 IEEE INT PHOEN
   SPANOS GA, 1995, P INT C COMP COMM NE
   SRIDHARAN S, 1991, IEE PROC-I, V138, P215, DOI 10.1049/ip-i-2.1991.0029
   Tang L., 1996, P 4 ACM INT MULT C A, P219
   TERRY DB, 1988, ACM T COMPUT SYST, V6, P3, DOI 10.1145/35037.35038
   Witten I. H., 1988, Computers & Security, V7, P397, DOI 10.1016/0167-4048(88)90580-9
   Wu C.P., 2000, SPIE INT S INFORM TE, V4209, P284
   Wu CP, 2001, PROC SPIE, V4314, P128, DOI 10.1117/12.435392
   XYDEAS C, 1994, IEE C SEC CRYPT APPL, P9
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
NR 39
TC 230
Z9 259
U1 0
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2005
VL 7
IS 5
BP 828
EP 839
DI 10.1109/TMM.2005.854469
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 967IM
UT WOS:000232084900004
DA 2024-07-18
ER

PT J
AU Yang, XK
   Zhu, C
   Li, ZG
   Lin, X
   Ling, N
AF Yang, XK
   Zhu, C
   Li, ZG
   Lin, X
   Ling, N
TI An unequal packet loss resilience scheme for video over the Internet
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE data partitioning; error resilience; forward error correction; packet
   loss resilience; video over the Internet
ID TRANSMISSION
AB We present an unequal packet loss resilience scheme for robust transmission of video over the Internet. By jointly exploiting the unequal importance existing in different levels of syntax hierarchy in video coding schemes, GOP-level and Resynchronization-packet-level Integrated Protection (GRIP) is designed for joint unequal loss protection (ULP) in these two levels using forward error correction (FEC) across packets. Two algorithms are developed to achieve efficient FEC assignment for the proposed GRIP framework: a model-based FEC assignment algorithm and a heuristic FEC assignment algorithm. The model-based FEC assignment algorithm is to achieve optimal allocation of FEC codes based on a simple but effective performance metric, namely distortion-weighted expected length of error propagation, which is adopted to quantify the temporal propagation effect of packet loss on video quality degradation. The heuristic FEC assignment algorithm aims at providing a much simpler yet effective FEC assignment with little computational complexity. The proposed GRIP together with any of the two developed FEC assignment algorithms demonstrates strong robustness against burst packet losses with adaptation to different channel status. Index Terms-Data partitioning, error resilience, forward error correction, packet loss resilience, video over the Internet.
C1 Shanghai Jiao Tong Univ, Dept Elect Engn, Inst Image Commun & Informat Proc, Shanghai 200030, Peoples R China.
   Inst Infocomm Res, Singapore, Singapore.
   Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   Agcy Sci Technoll & Res, Inst Infocomm Res, Media Div, Singapore 119613, Singapore.
   Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
C3 Shanghai Jiao Tong University; Agency for Science Technology & Research
   (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Nanyang
   Technological University; Agency for Science Technology & Research
   (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Santa Clara
   University
RP Shanghai Jiao Tong Univ, Dept Elect Engn, Inst Image Commun & Informat Proc, Shanghai 200030, Peoples R China.
EM xkyang@ieee.org; eczhu@ntu.edu.sg; ezgli@i2r.a-star.edu.sg;
   linxiao@i2r.a-star.edu.sg; nling@scu.edu
RI Yang, Xiaokang/C-6137-2009; Zhu, Ce/AEN-1875-2022
OI Yang, Xiaokang/0000-0003-4029-3322; 
CR Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   Budagavi M, 2000, IEEE SIGNAL PROC MAG, V17, P36, DOI 10.1109/79.814645
   Chung-How JTH, 2001, SIGNAL PROCESS-IMAGE, V16, P891, DOI 10.1016/S0923-5965(00)00051-5
   Civanlar MR, 2001, IEEE T CIRC SYST VID, V11, P265, DOI 10.1109/TCSVT.2001.911154
   ELLIOTT EO, 1965, AT&T TECH J, V44, P89, DOI 10.1002/j.1538-7305.1965.tb04139.x
   FEAMSTER N, 2002, P IEEE INT PACK VID
   GIROD B, 1999, P SPIE VCIP SAN JOS
   Hartanto F, 2001, 10TH IEEE WORKSHOP ON LOCAL AND METROPOLITAN AREA NETWORKS, SELECTED PAPERS, P126, DOI 10.1109/LANMAN.1999.939966
   *ISO IEC JTC1SC29W, 2001, 496 ISOIEC JTC1SC29W
   LEICHER P, 1994, TR94058 ICSI
   LIANG YJ, 2002, IEEE 5 WORKSH MULT S
   Liu H, 1996, WIREL NETW, V2, P219, DOI 10.1007/BF01201055
   Moccagatta I, 2000, IEEE J SEL AREA COMM, V18, P899, DOI 10.1109/49.848245
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   REIBMAN AR, 2002, IEEE T CIRCUITS SYST, V12, P895
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WORRALL S, 2000, P IEEE PACK VID SARD
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Yang XK, 2003, SIGNAL PROCESS-IMAGE, V18, P157, DOI 10.1016/S0923-5965(02)00128-5
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 21
TC 41
Z9 49
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2005
VL 7
IS 4
BP 753
EP 765
DI 10.1109/TMM.2005.846782
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 946XQ
UT WOS:000230607000015
DA 2024-07-18
ER

PT J
AU Peng, J
   Sikdar, B
AF Peng, J
   Sikdar, B
TI An efficient and scalable loss-recovery scheme for video multicast
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE algorithm/protocol design and analysis; error control; loss recovery;
   multicast
ID ERROR CONTROL
AB With the increased popularity of multimedia services on the Internet, efficient video multicast strategies that can scale easily are of critical importance. This paper addresses the issue of video multicast loss recovery and presents an efficient and scalable scheme: Active Injection Recovery (AIR). The proposed scheme has three distinguishing features: active injection of repair packets into loss regions, on-demand construction of loss-recovery structures, and unique rate control over repair traffic. All of these features can save considerable network resources in a large-scale video multicast session. In addition, the proposed scheme simultaneously meets the three well-known requirements for efficiency and scalability in multicast loss recovery: request suppression, local recovery, and retransmission scoping. Another important feature of the proposed scheme is its low recovery latency, which is essential for video multicast. Our results show that the proposed scheme achieves significantly better overall performance as compared to existing multicast loss recovery schemes.
C1 Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Rensselaer Polytechnic Institute
RP Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
EM pengj2@rpi.edu; bsikdar@poisson.ecse.rpi.edu
CR [Anonymous], P ACM SIGCOMM OCT
   [Anonymous], P ACM SIGCOMM
   Byers J.W., 1998, P ACM SIGCOMM 98 C A, P56
   CAIN B, 2000, GENERIC ROUTER ASSIS
   Calderon M, 1998, IEEE NETWORK, V12, P46, DOI 10.1109/65.690961
   Chou PA, 2001, IEEE T MULTIMEDIA, V3, P108, DOI 10.1109/6046.909598
   Costello AM, 1999, IEEE INFOCOM SER, P1256, DOI 10.1109/INFCOM.1999.752143
   Gao Y, 2000, 2000 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P83, DOI 10.1109/ICNP.2000.896294
   Griffioen J., 1995, PROC ACM MULTIMEDIA, P333
   Kasera SK, 2000, IEEE NETWORK, V14, P48, DOI 10.1109/65.819171
   KERMODE R, 1998, P ACM SIGCOMM 98 VAN, P278
   Lehman LWH, 1998, IEEE INFOCOM SER, P581, DOI 10.1109/INFCOM.1998.665078
   Levine BN, 1997, 1997 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS - PROCEEDINGS, P241, DOI 10.1109/ICNP.1997.643723
   Li VOK, 2002, P IEEE, V90, P360, DOI 10.1109/5.993404
   Nonnenmacher J, 1998, IEEE INFOCOM SER, P972, DOI 10.1109/INFCOM.1998.662906
   Nonnenmacher J, 1998, IEEE ACM T NETWORK, V6, P349, DOI 10.1109/90.720869
   Papadopoulos C, 1998, IEEE INFOCOM SER, P1188, DOI 10.1109/INFCOM.1998.662932
   Paul S, 1997, IEEE J SEL AREA COMM, V15, P407, DOI 10.1109/49.564138
   Pejhan S, 1996, IEEE ACM T NETWORK, V4, P413, DOI 10.1109/90.502240
   SPEAKMAN T, 1998, INTERNET DRAFT   AUG
   Tan WT, 2001, IEEE T CIRC SYST VID, V11, P373, DOI 10.1109/76.911162
   Yajnik M, 1996, IEEE GLOBECOM 1996 - GLOBAL INTERNET'96, CONFERENCE RECORD, P94, DOI 10.1109/GLOCOM.1996.586133
NR 22
TC 3
Z9 3
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2005
VL 7
IS 2
BP 356
EP 365
DI 10.1109/TMM.2005.843351
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 909OO
UT WOS:000227869400016
DA 2024-07-18
ER

PT J
AU Shanableh, T
   Ghanabari, M
AF Shanableh, T
   Ghanabari, M
TI Multilayer transcoding with format portability for multicasting of
   single-layered video
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE compressed domain processing; scalable video coding; video networking;
   video transcoding
ID SCALABILITY; NETWORKS
AB This paper proposes a novel multilayer video transcoding approach for multicasting pre-encoded video to heterogeneous end-systems via diverse grouping of networks. Multilayer transcoding is first addressed by means of multiquality or SNR scalability of the MPEG-2 standard. Frequency domain transcoding and drift-compensated transcoding are derived from the closed-loop and multiloop SNR scalabilities, respectively. The proposed transcoding architectures are verified in terms of eliminating picture drift whilst preserving compatibility with the MPEG-2 SNR decoder. Multilayer transcoding is then addressed by means of multiresolution or spatial scalability of the MPEG-2 standard that supports different video formats. The transcoder retains the full resolution of the incoming video stream in its enhancement layer while generating a low spatio-temporal resolution base-layer compatible with the H.263 video format. Hence providing both multilayer transcoding and video format portability. The resultant video layers are shown to be free from drift with PSNR results comparable to those of the respective scalable encoders.
C1 Amer Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates.
   Univ Essex, Dept Elect Syst Engn, Colchester CO4 3SQ, Essex, England.
C3 American University of Sharjah; University of Essex
RP Amer Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates.
EM tshanableh@aus.ac.ae; ghan@essex.ac.uk
RI Shanableh, Tamer/AAC-7893-2021
OI Shanableh, Tamer/0000-0002-7651-3094
CR Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   AMIR E, 1995, P ACM MULTIMEDIA 95
   Arnold JE, 2000, IEEE T CIRC SYST VID, V10, P70, DOI 10.1109/76.825862
   Assuncao P., 1996, P 7 INT WORKSH PACK, P235
   Assunçao PAA, 1998, IEEE T CIRC SYST VID, V8, P953, DOI 10.1109/76.736724
   Assuncao PAA, 1997, IEE P-VIS IMAGE SIGN, V144, P377, DOI 10.1049/ip-vis:19971558
   Assunçao PAA, 2000, IEEE T CIRC SYST VID, V10, P83, DOI 10.1109/76.825863
   BARRAU E, 2002, P IEEE INT C IM PROC
   DEERING S, 1993, MULT INT C EUR MICE
   GHANBARI M, 1989, IEEE J SEL AREA COMM, V7, P771, DOI 10.1109/49.32340
   GHANBARI M, 1992, IEEE T COMMUN, V40, P1481, DOI 10.1109/26.163569
   HEMY M, 1999, P PACKET VIDEO 99
   HOFFMAN D, 1993, P 4 INT WORKSH NETW
   *ISO IEC, 1993, MPEG93457
   *ISO IEC, 1993, JTCISC29WG11N0400
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   LIN YC, 2002, P IEEE INT C CONS EL
   Mathew R, 1997, IEEE T CIRC SYST VID, V7, P882, DOI 10.1109/76.644068
   MCCANNNE S, 1996, P ACM SIGCOMM 96
   SERVETTO SD, 2000, P ICIP 2000
   SHANABLEH T, 2000, P ICIP2000
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   SHANABLEH TJ, 2001, THESIS U ESSEX UK
   WALKER M, 1999, P INT WORKSH PACK VI
   Werner O, 1999, IEEE T IMAGE PROCESS, V8, P179, DOI 10.1109/83.743853
NR 25
TC 11
Z9 13
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2005
VL 7
IS 1
BP 1
EP 15
DI 10.1109/TMM.2004.840602
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 893CQ
UT WOS:000226697300001
DA 2024-07-18
ER

PT J
AU Iskander, CD
   Mathiopoulos, PT
AF Iskander, CD
   Mathiopoulos, PT
TI Online smoothing of VBR H.263 video for the CDMA2000 and IS-95B uplinks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT 55th IEEE Vehicular Technology Conference (VTC 2002)
CY MAY 06-09, 2002
CL BIRMINGHAM, AL
SP IEEE Vehicular Technol Soc
DE CDMA2000; H.263; IS-95B; smoothing; video transmission
ID FADING CHANNELS; TRANSMISSION; TRANSPORT
AB The variable bit rate nature of compressed video remains a major challenge to the transmission of real-time video over mobile CDMA cellular networks. Indeed, H.263 and MPEG-4 video bitstreams can exhibit high peak rates and frequent rate variations, which are difficult to support in 2.5G and 3G mobile networks. In this paper, we consider smoothing)schemes to minimize the peak rate, variance, and average bandwidth of the transmitted signal, in order to obtain a lower bit-error-rate and thus, a higher received video quality than if unsmoothed video were transmitted. By introducing a delay in the decoding process, the video output stream can be buffered at the video decoder end: this buffering capability is used in order to perform real-time smoothing of the video streams. The transmitter chooses among the set of rates provided by the IS-95B or cdma2000 standards, in a mobility scenario, in order to support the rate variations. We simulate two end-to-end video communication systems based on IS-95B and cdma2000. They consist of an H.263 codec, an H.223 multiplexer, a rate management system and the physical layer components of the IS-95B and cdma2000 standards. The transmitted signal is subject to multipath fading and multiple-access interference, obtained by simulating all the other users in the cell. Results show a significant gain in the video quality obtained through smoothing of the video streams.
C1 Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada.
C3 University of British Columbia
RP Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada.
EM iskander@fau.edu
RI Mathiopoulos, Takis P./M-8289-2013; Mathiopoulos, P. Takis/L-8370-2013
OI Mathiopoulos, P. Takis/0000-0002-3332-4699
CR Aramvith S, 2001, IEEE T CIRC SYST VID, V11, P569, DOI 10.1109/76.920187
   Chan NHL, 2000, IEEE J SEL AREA COMM, V18, P996, DOI 10.1109/49.848252
   Chang PR, 1999, P IEEE, V87, P1807, DOI 10.1109/5.790639
   Feng WC, 1997, MULTIMEDIA SYST, V5, P297, DOI 10.1007/s005300050062
   Feng WC, 1999, IEEE T MULTIMEDIA, V1, P302, DOI 10.1109/6046.784468
   Fitzek FHP, 2001, IEEE J SEL AREA COMM, V19, P2015, DOI 10.1109/49.957315
   Hsu CY, 1997, IEEE J SEL AREA COMM, V15, P1016, DOI 10.1109/49.611156
   Hsu CY, 1999, IEEE J SEL AREA COMM, V17, P756, DOI 10.1109/49.768193
   ISKANDER CD, 2002, P AS C SIGN SYST COM
   ISKANDER CD, 2002, P ICT BEIJING CHINA
   ISKANDER CD, 2001, P IEEE VTC
   ISKANDER CD, 2002, P IEEE VTC
   ISKANDER CD, 2002, P ICT BEIJING CHIN J
   ISKANDER CD, 2001, P 13 INT C WIR COMM
   *ITU T, 1998, ITU T REC H 223 MULT
   *ITU T, 1998, ITU T REC H 324 TERM
   *ITU T, 1998, ITU T REC H263 VERS
   Khansari M, 1996, IEEE T CIRC SYST VID, V6, P1, DOI 10.1109/76.486415
   Knisely DN, 1998, IEEE COMMUN MAG, V36, P140, DOI 10.1109/35.722150
   Lam SS, 1996, IEEE ACM T NETWORK, V4, P697, DOI 10.1109/90.541318
   Lee J. S., 1998, CDMA systems engineering handbook
   LIU H, 1998, ACM BALTZER MOBILE N, V3, P49
   Rao SG, 1999, MULTIMEDIA SYST, V7, P222, DOI 10.1007/s005300050124
   Rexford J, 1999, GLOBECOM'99: SEAMLESS INTERCONNECTION FOR UNIVERSAL SERVICES, VOL 1-5, P1823, DOI 10.1109/GLOCOM.1999.832476
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   Sen S, 2000, IEEE T MULTIMEDIA, V2, P37, DOI 10.1109/6046.825793
   TIA PN 4694 TIA EIA
NR 27
TC 6
Z9 7
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2004
VL 6
IS 4
BP 647
EP 658
DI 10.1109/tmm.2004.830808
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 838RC
UT WOS:000222729800012
DA 2024-07-18
ER

PT J
AU Ye, DJ
   Barker, JC
   Xiong, ZX
   Zhu, WW
AF Ye, DJ
   Barker, JC
   Xiong, ZX
   Zhu, WW
TI Wavelet-based VBR video traffic smoothing
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT GLOBECOM 2001 Conference
CY NOV 25-29, 2001
CL SAN ANTONIO, TX
SP Natl Sci Fdn, Army Res Off, Off Naval Res
DE traffic smoothing; variable bit rate (VBR) video; video on demand;
   wavelets
ID BIT-RATE VIDEO; SERVICE; MODEL
AB In a typical video application, such as video-on-demand, videos are continuously streamed from a video server to a distributed set of receivers. The constant-quality video compression technique commonly used, variable bit rate (VBR) encoding, produces flows with multiple time-scale rate variability, so smoothing the VBR video traffic within an entire distribution tree presents a challenging task. This paper proposes a novel wavelet-based traffic smoothing (WTS) algorithm. Unlike existing algorithms, the WTS algorithm considers traffic smoothing at multiple resolutions. It results in a pruned version of a full tree, which corresponds to the original VBR traffic. Theoretical analysis and numerical evaluation demonstrate that: 1) WTS performs well across several metrics in smoothing bursty traffic and 2) for a video bit stream with N frames, the computational complexity of WTS is O(N log N).
C1 Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA.
   Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Tsinghua University; Texas A&M University System; Texas A&M University
   College Station; Microsoft; Microsoft Research Asia
RP Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
EM zx@ee.tamu.edu
CR Abry P, 1998, IEEE T INFORM THEORY, V44, P2, DOI 10.1109/18.650984
   [Anonymous], 1997, WAVELET TOUR SIGNAL
   [Anonymous], 2000, SELF SIMILAR NETWORK, DOI DOI 10.1002/047120644X
   BARKER C, 2002, P PACK WORKSH 02 PIT
   BERAN J, 1995, IEEE T COMMUN, V43, P1566, DOI 10.1109/26.380206
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   FENG W, 1996, THESIS U MICHIGAN AN
   FENG W, 1997, J ACM MULTIMEDIA SYS, P297
   Feng WC, 1997, IEEE INFOCOM SER, P58, DOI 10.1109/INFCOM.1997.635114
   FENG WC, 1995, COMPUT COMMUN, V18, P709, DOI 10.1016/0140-3664(95)98484-M
   Feng WC, 1999, IEEE T MULTIMEDIA, V1, P302, DOI 10.1109/6046.784468
   Garett M.W., 1994, P ACM SIGCOMM, P269
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   Gringeri S, 1998, IEEE NETWORK, V12, P94, DOI 10.1109/65.752648
   Grossglauser M, 1997, IEEE ACM T NETWORK, V5, P741, DOI 10.1109/90.650136
   Hadar O, 2001, REAL-TIME IMAGING, V7, P301, DOI 10.1006/rtim.2001.0229
   HURST HE, 1951, T AM SOC CIV ENG, V116, P770
   Jelenkovic PR, 1997, IEEE J SEL AREA COMM, V15, P1052, DOI 10.1109/49.611159
   LELAND WE, 1994, IEEE ACM T NETWORK, V2, P1, DOI 10.1109/90.282603
   LINDLEY DV, 1952, P CAMB PHILOS SOC, V48, P277, DOI 10.1017/S0305004100027638
   Ma S, 2001, IEEE ACM T NETWORK, V9, P634, DOI 10.1109/90.958331
   Ma S, 1998, IEEE COMMUN LETT, V2, P100, DOI 10.1109/4234.664218
   McManus JM, 1996, IEEE J SEL AREA COMM, V14, P1087, DOI 10.1109/49.508280
   NORROS I, 1994, QUEUEING SYST, V16, P387, DOI 10.1007/BF01158964
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Rathgeb E. P., 1993, International Journal of Digital and Analog Communication Systems, V6, P213, DOI 10.1002/dac.4510060406
   Rexford J, 1999, IEEE ACM T NETWORK, V7, P202, DOI 10.1109/90.769768
   Riedi RH, 1999, IEEE T INFORM THEORY, V45, P992, DOI 10.1109/18.761337
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   Ten Daubechies I., 1992, lecture on wavelets
   Tuan T, 1999, PERFORM EVALUATION, V36-7, P359, DOI 10.1016/S0166-5316(99)00024-3
   Vetterli Martin, 1995, Wavelets and Subband Coding
   ZHANG H, 1995, P IEEE, V83, P1374, DOI 10.1109/5.469298
   Zhang JB, 1998, COMPUT COMMUN, V21, P375, DOI 10.1016/S0140-3664(97)00170-9
   Zhang ZL, 1997, IEEE J SEL AREA COMM, V15, P1148, DOI 10.1109/49.611165
   1998, TELECOMMUN SYST, V9
NR 37
TC 9
Z9 13
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2004
VL 6
IS 4
BP 611
EP 623
DI 10.1109/tmm.2004.830817
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 838RC
UT WOS:000222729800009
DA 2024-07-18
ER

PT J
AU Stankovic, V
   Hamzaoui, R
   Xiong, ZX
AF Stankovic, V
   Hamzaoui, R
   Xiong, ZX
TI Efficient channel code rate selection algorithms for forward error
   correction of packetized multimedia bitstreams in varying channels
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT IEEE ICIP 2003 Meeting
CY SEP, 2003
CL Barcelona, SPAIN
SP IEEE ICIP
DE joint-source channel coding; packetization; streaming media; varying
   channels
ID IMAGE TRANSMISSION; COMPRESSION
AB We study joint source-channel coding systems for the transmission of images over varying channels without feedback. We consider the situation where the channel statistics are unknown to the transmitter and focus on systems that enable good performance over a wide range of channel conditions. We first propose a-linear-time channel code rate selection algorithm for a hybrid transmission system that combines packetization of an embedded wavelet bitstream into independently decodable packets and forward error correction with a concatenated cyclic redundancy check/rate-compatible punctured convolutional (RCPC) channel coder. We then consider an extension of this hybrid system with additional Reed-Solomon (RS) coding across the packets and give a linear-time algorithm for the efficient selection of both the RS and RCPC code rates. Experimental results for a wireline/wireless link modeled as the combination of a packet erasure channel and a Rayleigh flat-fading channel showed that our schemes significantly outperformed the best previous forward error correction systems in many situations where the actual channel parameter values deviated from the ones used in the optimization of the source-channel rate allocation.
C1 Texas A&M Univ, College Stn, TX 77843 USA.
   Univ Konstanz, D-7750 Constance, Germany.
C3 Texas A&M University System; Texas A&M University College Station;
   University of Konstanz
RP Texas A&M Univ, College Stn, TX 77843 USA.
EM stankovi@ee.tamu.edu; Raouf.Hamzaoui@uni-konstanz.de; zx@ee.tamu.edu
RI Stankovic, Vladimir/L-6584-2016
OI Stankovic, Vladimir/0000-0002-1075-2420
CR [Anonymous], 1974, MICROWAVE MOBILE COM
   Cosman PC, 2000, IEEE T IMAGE PROCESS, V9, P982, DOI 10.1109/83.846241
   Creusere CD, 1997, IEEE T IMAGE PROCESS, V6, P1436, DOI 10.1109/83.624967
   FRENGER P, 1998, R0211998 CHALM U TEC
   Kim TY, 2000, IEEE T CIRC SYST VID, V10, P693, DOI 10.1109/76.856447
   Röder M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P801, DOI 10.1109/ICME.2002.1035903
   Rogers JK, 1998, IEEE SIGNAL PROC LET, V5, P105, DOI 10.1109/97.668942
   Sachs DG, 2000, PROC SPIE, V3974, P300, DOI 10.1117/12.382963
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sherwood PG, 1997, IEEE SIGNAL PROC LET, V4, P189, DOI 10.1109/97.596882
   Sherwood PG, 1998, IEEE T COMMUN, V46, P1555, DOI 10.1109/26.737389
   TAUBMAN DS, 2001, IPEG 2000 IMAGE COMP
   Wu XL, 2001, IEEE T MULTIMEDIA, V3, P132, DOI 10.1109/6046.909600
NR 13
TC 42
Z9 46
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2004
VL 6
IS 2
BP 240
EP 248
DI 10.1109/TMM.2003.822789
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 807NO
UT WOS:000220508400003
DA 2024-07-18
ER

PT J
AU Lombardo, A
   Morabito, G
   Schembra, G
AF Lombardo, A
   Morabito, G
   Schembra, G
TI Modeling intramedia and intermedia relationships in multimedia network
   analysis through multiple timescale statistics
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Markov models; MPEG; multimedia; performance analysis; traffic modeling
ID MEASUREMENT-BASED TOOL; ATM MULTIPLEXER; ANALYTICAL PARADIGM; MPEG
   VIDEO; PERFORMANCE; SYNCHRONIZATION; ENVIRONMENT; STREAMS; SMAQ
AB In this paper, a hierarchical paradigm modeling both the intramedia and the intermedia time relationships of multimedia sources is derived. Each multimedia source is considered as being made up of a master monomedia source, which is independent, and slave monomedia sources, which are dependent on the master. The paradigm takes different timescale statistics into account and is used to characterize intermedia relationships in terms of the second-order statistics of the multimedia source. Finally, the impact of the intermedia relationships on the performance of each monomedia source making up a multimedia source is analyzed when a number of multimedia sources are multiplexed together. The error introduced in both loss and jitter performance analysis when intermedia relationships are not modeled is evaluated through a case study. Numerical results show that this error may be dramatically significant in many common scenarios.
C1 Univ Catania, Dipartimento Ingn Informat & Telecommun, Catania, Italy.
C3 University of Catania
RP Lombardo, A (corresponding author), Univ Catania, Dipartimento Ingn Informat & Telecommun, Catania, Italy.
EM lombardo@diit.unict.it; giacomo.morabito@diit.unict.it;
   schembra@diit.unict.it
RI Schembra, Giovanni/AAA-3947-2021
OI Schembra, Giovanni/0000-0002-7432-8389; Morabito,
   Giacomo/0000-0002-8714-4001; Lombardo, Alfio/0000-0003-3617-7732
CR Beritelli F, 1999, IEEE J SEL AREA COMM, V17, P63, DOI 10.1109/49.743697
   BRADY PT, 1969, BELL SYST TECH J SEP
   GARRETT M, 1994, ACM SIGCOMM 94 LOND
   HASHIDA O, 1991, IEEE J SEL AREA COMM, V9, P394, DOI 10.1109/49.76638
   HUANG C, 1995, ACM SIGCOMM95 CAMBR
   Jelenkovic PR, 1997, IEEE J SEL AREA COMM, V15, P1052, DOI 10.1109/49.611159
   KIM YH, 1996, INFOCOM96 SAN FRANC
   Koenen R, 2000, N3536 ISOIEC JTC1SC2
   La Corte A, 1997, COMPUT NETWORKS ISDN, V29, P1881, DOI 10.1016/S0169-7552(97)00102-5
   LACORTE A, 1996, P IEEE INFOCOM96 SAN
   LELAND WE, 1994, IEEE ACM T NETWORK, V2, P1, DOI 10.1109/90.282603
   Li SQ, 1997, IEEE ACM T NETWORK, V5, P429, DOI 10.1109/90.611107
   Li SQ, 1998, IEEE COMMUN MAG, V36, P66
   Li SQ, 1998, IEEE COMMUN MAG, V36, P56
   LIKHANOV N, 1995, IEEE INFOCOM95 BOST
   Lombardo A, 1999, PERFORM EVALUATION, V35, P75, DOI 10.1016/S0166-5316(98)00048-0
   Lombardo A, 2001, IEEE T MULTIMEDIA, V3, P5, DOI 10.1109/6046.909590
   Lombardo A, 1997, IEEE ACM T NETWORK, V5, P958, DOI 10.1109/90.650153
   Lombardo A, 1999, IEEE ACM T NETWORK, V7, P122, DOI 10.1109/90.759335
   LOMBARDO A, 1998, IEEE INFOCOM98 SAN F
   Rangan PV, 1996, IEEE J SEL AREA COMM, V14, P52, DOI 10.1109/49.481693
   RANGAN PV, 1992, IEEE COMMUN MAG, V30, P56, DOI 10.1109/35.144778
   SEN P, 1989, IEEE J SEL AREA COMM, V7, P865, DOI 10.1109/49.32350
   STEINMETZ R, 1994, ACM SPRINGER MULTIME, V1
   Stern HP, 1996, WIREL NETW, V2, P359, DOI 10.1007/BF01262053
   TSE DNC, 1995, IEEE J SEL AREA COMM, V13, P1028, DOI 10.1109/49.400658
   White L, 2000, POETRY WALES, V35, P5
   2001, SYNCML REPR PROT SPE
NR 28
TC 22
Z9 22
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855 USA
SN 1520-9210
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2004
VL 6
IS 1
BP 142
EP 157
DI 10.1109/TMM.2003.819750
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 765QP
UT WOS:000188295200011
DA 2024-07-18
ER

PT J
AU Trappe, W
   Song, J
   Poovendran, R
   Liu, KJR
AF Trappe, W
   Song, J
   Poovendran, R
   Liu, KJR
TI Key management and distribution for secure multimedia multicast
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE data embedding; key management; multimedia; secure multicast
ID WATERMARKING; VIDEO
AB The problem of controlling access to multimedia multicasts; requires the distribution and maintenance of keying information. Typically, the problem of key management is considered separately from the problem of distributing the rekeying messages. Multimedia sources provide two approaches to distributing the rekeying messages associated with securing group communication. The first, and more conventional, approach employs the use of a media-independent channel to convey rekeying messages. We propose, however, a second approach that involves the use of a media-dependent channel, and is achieved for multimedia by using data embedding techniques. Compared to a media-independent channel, the use of data embedding to convey rekeying messages provides enhanced security by masking the presence of rekeying operations. This covert communication makes it difficult for an adversary to gather information regarding the group membership and its dynamics. In addition to proposing a new mode of conveyance for the rekeying messages, we introduce a new message format that is suitable for multicast key management schemes. This new message format uses one-way functions to securely distribute new key material to subgroups of users. An advantage of this approach over the traditional message format is that no additional messages must be sent to flag the users which portion of the message is intended for them, thereby reducing communication overhead. We then show how to map the message to a tree structure in order to achieve desirable scalability in communication and computational overhead. Next, as an example of the interplay between the key management scheme and the mode of conveyance, we study the feasibility of embedding rekeying messages using a data embedding method that has been recently proposed for fractional-pel video coding standards such as H.263 and MPEG-2. Finally, since multimedia services will involve multiple layers or objects, we extend the tree-based key management schemes to include new operations needed to handle multilayer multimedia applications where group members may subscribe or cancel membership to some layers while maintaining membership to other layers.
C1 Rutgers State Univ, Wireless Informat Network Lab, Piscataway, NJ 08854 USA.
   Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
   Agere Syst, Holmdel, NJ 07733 USA.
   Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
   Univ Maryland, Syst Res Inst, College Pk, MD 20742 USA.
C3 Rutgers University System; Rutgers University New Brunswick; Rutgers
   University System; Rutgers University New Brunswick; Broadcom; LSI
   Corporation; University of Washington; University of Washington Seattle;
   University System of Maryland; University of Maryland College Park;
   University System of Maryland; University of Maryland College Park
RP Rutgers State Univ, Wireless Informat Network Lab, Piscataway, NJ 08854 USA.
EM trappe@winlab.rutgers.edu; jiesong@agere.com; radha@ee.washington.edu;
   kjrliu@eng.wnd.edu
RI Liu, K.J. Ray/C-2798-2009
OI Poovendran, Radha/0000-0003-0269-8097
CR [Anonymous], 1998, INTERNET DRAFT
   [Anonymous], 1998, Video coding for low bitrate communication
   [Anonymous], 2002, Introduction to Cryptography with Coding Theory
   Balenson D.M., 2000, KEY MANAGEMENT LARGE
   Blundo C., 1994, Journal of Computer Security, V3, P309
   Canetti R, 1999, IEEE INFOCOM SER, P708, DOI 10.1109/INFCOM.1999.751457
   CANETTI R, 1999, EUROCRYPT, P456
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Hartung F, 1997, INT CONF ACOUST SPEE, P2621, DOI 10.1109/ICASSP.1997.595326
   HERPEL C, 2000, SIGN PROC COMMUN SER, V2, P367
   Horn U, 1999, SIGNAL PROCESS-IMAGE, V15, P77, DOI 10.1016/S0923-5965(99)00025-9
   Just M., 1994, 2nd ACM Conference on Computer and Communications Security, P81, DOI 10.1145/191177.191195
   Mitchell J.L., 1997, MPEG VIDEO COMPRESSI
   Nonnenmacher J, 1998, IEEE ACM T NETWORK, V6, P349, DOI 10.1109/90.720869
   PAUL S, 1998, MULTICASTING INTERNE
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Poovendran R., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P624
   Poovendran R, 2001, IEEE T INFORM THEORY, V47, P2824, DOI 10.1109/18.959263
   Puri A., 2000, Multimedia Systems, Standards, and Networks
   Reed MG, 1998, IEEE J SEL AREA COMM, V16, P482, DOI 10.1109/49.668972
   Song J, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P390, DOI 10.1109/ISCAS.1999.780024
   SONG J, 2001, IEEE T MULTIMEDIA, V3, P415
   SONG J, 2001, SPIE 2001 SEC WAT MU
   TRAPPE W, 2001, IEEE ICASSP
   WESTFELD A, 1998, 2 INT WORKSH INF HID
   Wong CK, 2000, IEEE ACM T NETWORK, V8, P16, DOI 10.1109/90.836475
   WU M, 2001, P SPIE ITCOM 01, V4518
   Zheng HT, 2000, IEEE SIGNAL PROC MAG, V17, P44, DOI 10.1109/79.855912
   1997, HDB APPL CRYPTOGRAPH
NR 29
TC 48
Z9 92
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2003
VL 5
IS 4
BP 544
EP 557
DI 10.1109/TMM.2003.813279
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 742VA
UT WOS:000186537700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Wei, ZJ
   Kelton, C
   Ahn, S
   Balasubramanian, A
   Zelinsky, GJ
   Samaras, D
AF Chakraborty, Souradeep
   Wei, Zijun
   Kelton, Conor
   Ahn, Seoyoung
   Balasubramanian, Aruna
   Zelinsky, Gregory J.
   Samaras, Dimitris
TI Predicting Visual Attention in Graphic Design Documents
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Predictive models; Graphics; Layout; Computational modeling;
   Visualization; Deep learning; Faces; Graphic design; webpage; mobile UI;
   segmen- tation; layout; visual attention
ID BANNER BLINDNESS; MODEL
AB We present a model for predicting visual attention during the free viewing of graphic design documents. While existing works on this topic have aimed at predicting static saliency of graphic designs, our work is the first attempt to predict both spatial attention and dynamic temporal order in which the document regions are fixated by gaze using a deep learning based model. We propose a two-stage model for predicting dynamic attention on such documents, with webpages being our primary choice of document design for demonstration. In the first stage, we predict the saliency maps for each of the document components (e.g. logos, banners, texts, etc. for webpages) conditioned on the type of document layout. These component saliency maps are then jointly used to predict the overall document saliency. In the second stage, we use these layout-specific component saliency maps as the state representation for an inverse reinforcement learning model of fixation scanpath prediction during document viewing. To test our model, we collected a new dataset consisting of eye movements from 41 people freely viewing 450 webpages (the largest dataset of its kind). Experimental results show that our model outperforms existing models in both saliency and scanpath prediction for webpages, and also generalizes very well to other graphic design documents such as comics, posters, mobile UIs, etc. and natural images.
C1 [Chakraborty, Souradeep; Wei, Zijun; Kelton, Conor; Balasubramanian, Aruna; Zelinsky, Gregory J.; Samaras, Dimitris] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Ahn, Seoyoung] SUNY Stony Brook, Dept Psychol, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Chakraborty, S (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM souchakrabor@cs.stonybrook.edu; zijwei@cs.stonybrook.edu;
   ckelton@cs.stonybrook.edu; seoyoung.ahn@stonybrook.edu;
   arunab@cs.stonybrook.edu; gregory.zelinsky@stonybrook.edu;
   samaras@cs.stonybrook.edu
RI Ahn, Seoyoung/KRP-6770-2024
OI Ahn, Seoyoung/0000-0002-7842-9208; Samaras, Dimitris/0000-0002-1373-0294
FU National Science Foundation [CNS-1718014]; US National Science
   Foundation [IIS-1763981]; Partner University Fund; SUNY2020
   Infrastructure Transportation Security Center
FX This work was supported by the National Science Foundation under grant
   CNS-1718014, in part by the US National Science Foundation Award
   IIS-1763981, in part by the Partner University Fund, and in part by the
   SUNY2020 Infrastructure Transportation Security Center. The Associate
   Editor coordinating the review of this manuscript and approving it for
   publication was Prof. C. Zhao.
CR Adeli H, 2017, J NEUROSCI, V37, P1453, DOI 10.1523/JNEUROSCI.0825-16.2016
   [Anonymous], 2008, Advances in neural information processing systems
   Apon A., 2006, P ALAR C APPL RES IN
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Assens M, 2019, LECT NOTES COMPUT SC, V11133, P406, DOI 10.1007/978-3-030-11021-5_25
   Bannier K, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204560
   Benway JP, 1998, HUM FAC ERG SOC P, P463
   Borji A, 2021, IEEE T PATTERN ANAL, V43, P679, DOI 10.1109/TPAMI.2019.2935715
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Deka B, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P845, DOI 10.1145/3126594.3126651
   Dewhurst R, 2012, BEHAV RES METHODS, V44, P1079, DOI 10.3758/s13428-012-0212-2
   Faraday P, 2000, SPRING COMP SCI, P155
   FINDLAY JM, 1982, VISION RES, V22, P1033, DOI 10.1016/0042-6989(82)90040-2
   Fosco C., 2020, P 33 ANN ACM S USER, P249
   Fu Y, 2017, I S INTELL SIG PROC, P44, DOI 10.1109/ISPACS.2017.8266443
   Gu YJ, 2019, 3RD INTERNATIONAL CONFERENCE ON INNOVATION IN ARTIFICIAL INTELLIGENCE (ICIAI 2019), P157, DOI 10.1145/3319921.3319932
   Gupta P, 2018, IEEE WINT CONF APPL, P1529, DOI 10.1109/WACV.2018.00171
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He S, 2019, PROC CVPR IEEE, P10198, DOI 10.1109/CVPR.2019.01045
   Hervet G, 2011, APPL COGNITIVE PSYCH, V25, P708, DOI 10.1002/acp.1742
   Ho J, 2016, ADV NEUR IN, V29
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103887
   Jones D., 2012, MAJESTIC MILLION CSV
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Kelton C, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P545
   Kocak A., 2014, P BRIT MACH VIS C
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Lagun D, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P113, DOI 10.1145/2835776.2835833
   Leiva L. A., 2020, P 22 INT C HUM COMP, P1
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2016, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2016.7532442
   Linardos A., 2021, P IEEECVF INT C COMP, P12919
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Min XK, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3470970
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P6054, DOI 10.1109/TIP.2020.2988148
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P3805, DOI 10.1109/TIP.2020.2966082
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Pan J., 2017, P CVPR SCEN UND WORK, P1
   Pang XF, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982422
   Ramanishka V, 2017, PROC CVPR IEEE, P3135, DOI 10.1109/CVPR.2017.334
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Schwetlick L, 2020, COMMUN BIOL, V3, DOI 10.1038/s42003-020-01429-8
   Sharma S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P192, DOI 10.1109/ICACCCT.2016.7831628
   Shen CY, 2015, IEEE T MULTIMEDIA, V17, P2084, DOI 10.1109/TMM.2015.2483370
   Shen CY, 2014, LECT NOTES COMPUT SC, V8695, P33, DOI 10.1007/978-3-319-10584-0_3
   Sun WJ, 2021, IEEE T PATTERN ANAL, V43, P2101, DOI 10.1109/TPAMI.2019.2956930
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verdu S., 2014, P INF THEOR APPL WOR, P1
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Xia C, 2020, IEEE ACCESS, V8, P15598, DOI 10.1109/ACCESS.2020.2966628
   Xia C, 2019, IEEE T IMAGE PROCESS, V28, P3502, DOI 10.1109/TIP.2019.2897966
   Xiongkuo Min, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457921
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Yang S, 2020, IEEE T MULTIMEDIA, V22, P2163, DOI 10.1109/TMM.2019.2947352
   Yang ZB, 2020, PROC CVPR IEEE, P190, DOI [10.1109/CVPR42600.2020.00027, 10.1109/cvpr42600.2020.00027]
   Yao SY, 2021, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP42928.2021.9506089
   Zanca D, 2020, IEEE T PATTERN ANAL, V42, P2983, DOI 10.1109/TPAMI.2019.2920636
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zheng QL, 2018, LECT NOTES COMPUT SC, V11218, P300, DOI 10.1007/978-3-030-01264-9_18
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 73
TC 0
Z9 0
U1 8
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 4478
EP 4493
DI 10.1109/TMM.2022.3176942
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA W1OJ1
UT WOS:001089390200029
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chang, Z
   Zhang, XF
   Wang, SS
   Ma, SW
   Gao, W
AF Chang, Zheng
   Zhang, Xinfeng
   Wang, Shanshe
   Ma, Siwei
   Gao, Wen
TI STAM: A SpatioTemporal Attention Based Memory for Video Prediction
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Global spatiotemporal information; spatio temporal receptive field; 3D
   convolutional neural network; spatiotemporal attention; sequence
   learning; video prediction
ID INTER-PREDICTION
AB Video prediction has always been a very challenging problem in video representation learning due to the complexity in spatial structure and temporal variation. However, existing methods mainly predict videos by employing language-based memory structures from the traditional Long Short-Term Memories (LSTMs) or Gated Recurrent Units (GRUs), which may not be powerful enough to model the long-term dependencies in videos, consisting of much more complex spatiotemporal dynamics than sentences. In this paper, we propose a SpatioTemporal Attention based Memory (STAM), which can efficiently improve the long-term spatiotemporal memorizing capacity by incorporating the global spatiotemporal information in videos. In the temporal domain, the proposed STAM aims to observe temporal states from a wider temporal receptive field to capture accurate global motion information. In the spatial domain, the proposed STAM aims to jointly utilize both the high-level semantic spatial state and the low-level texture spatial states to model a more reliable global spatial representation for videos. In particular, the global spatiotemporal information is extracted with the help of an Efficient SpatioTemporal Attention Gate (ESTAG), which can adaptively apply different levels of attention scores to different spatiotemporal states according to their importance. Moreover, the proposed STAM are built with 3D convolutional layers due to their advantages in modeling spatiotemporal dynamics for videos. Experimental results show that the proposed STAM can achieve state-of-the-art performance on widely used datasets by leveraging the proposed spatiotemporal representations for videos.
C1 [Chang, Zheng] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Chang, Zheng] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
   [Zhang, Xinfeng] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Chang, Zheng; Wang, Shanshe; Ma, Siwei; Gao, Wen] Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS; Peking University
RP Ma, SW (corresponding author), Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
EM changzheng18@mails.ucas.ac.cn; xfzhang@ucas.ac.cn; sswang@pku.edu.cn;
   swma@pku.edu.cn; wgao@pku.edu.cn
RI Zhang, Xinfeng/X-8148-2019
OI Zhang, Xinfeng/0000-0002-7517-3868; Chang, Zheng/0000-0002-8986-6841
FU National Natural Science Foundation of China [62025101, 62072008,
   62071449, U20A20184]; Fundamental Research Funds for the Central
   Universities; High-performance Computing Platform of Peking University
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62025101, 62072008, 62071449, and
   U20A20184 and in part by the Fundamental Research Funds for the Central
   Universities, and High-performance Computing Platform of Peking
   University .
CR Babaeizadeh M., 2018, PROC INT C LEARN REP
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bhattacharyya A, 2018, PROC CVPR IEEE, P4194, DOI 10.1109/CVPR.2018.00441
   Byeon W, 2018, LECT NOTES COMPUT SC, V11220, P781, DOI 10.1007/978-3-030-01270-0_46
   Chai ZH, 2022, Arxiv, DOI arXiv:2102.03586
   Chang Zheng, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME51207.2021.9428231
   Chang Z., 2021, ADV NEUR IN, V34
   Chen XT, 2020, IEEE T MULTIMEDIA, V22, P1591, DOI 10.1109/TMM.2019.2946475
   Cox D., 2017, INT C LEARNING REPRE
   De Brabandere B, 2016, ADV NEUR IN, V29
   Denton E., 2018, ARXIV180207687
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Fidler S., 2020, PROC INT C LEARN REP
   Finn C, 2016, ADV NEUR IN, V29
   Franceschi J. -Y., 2020, INT C MACH LEARN, P3233
   Gao W, 2021, IEEE T CIRC SYST VID, V31, P4147, DOI 10.1109/TCSVT.2021.3104305
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hao ZK, 2018, PROC CVPR IEEE, P7854, DOI 10.1109/CVPR.2018.00819
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Isobe Takashi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8005, DOI 10.1109/CVPR42600.2020.00803
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jin BB, 2020, PROC CVPR IEEE, P4553, DOI 10.1109/CVPR42600.2020.00461
   Jin BB, 2018, IEEE INT C INT ROBOT, P5801, DOI 10.1109/IROS.2018.8594264
   Junbo Yin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11492, DOI 10.1109/CVPR42600.2020.01151
   Kalbkhani H, 2017, IEEE T MULTIMEDIA, V19, P999, DOI 10.1109/TMM.2016.2639379
   Kalchbrenner Nal, 2017, INT C MACHINE LEARNI, P1771
   Kang MK, 2014, IEEE T MULTIMEDIA, V16, P1563, DOI 10.1109/TMM.2014.2323939
   Kim N, 2021, IEEE T MULTIMEDIA, V23, P3986, DOI 10.1109/TMM.2020.3035281
   Kingma D. P., 2015, P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR, P1
   Kwon YH, 2019, PROC CVPR IEEE, P1811, DOI 10.1109/CVPR.2019.00191
   Lee S, 2021, PROC CVPR IEEE, P3053, DOI 10.1109/CVPR46437.2021.00307
   Lei Ba J., 2016, arXiv
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Li J, 2020, IEEE T MULTIMEDIA, V22, P2990, DOI 10.1109/TMM.2020.2965434
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P4626
   Liang XD, 2017, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2017.194
   Liao XY, 2019, LECT NOTES COMPUT SC, V11366, P620, DOI 10.1007/978-3-030-20876-9_39
   Lin ZH, 2020, AAAI CONF ARTIF INTE, V34, P11531
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mathieu M., 2015, PROC INT C LEARN REP
   Oh J., 2015, Advances in neural information processing systems, P2863
   Oliu M, 2018, LECT NOTES COMPUT SC, V11218, P745, DOI 10.1007/978-3-030-01264-9_44
   Oprea S, 2022, IEEE T PATTERN ANAL, V44, P2806, DOI 10.1109/TPAMI.2020.3045007
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Ranzato M, 2016, Arxiv, DOI [arXiv:1412.6604, DOI 10.48550/ARXIV.1412.6604]
   Reda FA, 2018, LECT NOTES COMPUT SC, V11211, P747, DOI 10.1007/978-3-030-01234-2_44
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shi XJ, 2015, ADV NEUR IN, V28
   Shi XJ, 2017, ADV NEUR IN, V30
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Su Jiahao, 2020, ADV NEURAL INF PROCE, V33, P13714
   Villegas R., 2017, PROC 5 INT C LEARN R, P1
   Wang Y., 2018, INT C MACH LEARN, P5123, DOI 10.48550/arXiv.1804.06300
   Wang Y., 2019, ARXIV191007512, P1
   Wang YB, 2019, PROC CVPR IEEE, P9146, DOI 10.1109/CVPR.2019.00937
   Wang YB, 2017, ADV NEUR IN, V30
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HX, 2021, PROC CVPR IEEE, P15430, DOI 10.1109/CVPR46437.2021.01518
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Lee AX, 2018, Arxiv, DOI arXiv:1804.01523
   Xu JW, 2018, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR.2018.00158
   Xu Jingwei, 2020, P MACHINE LEARNING R, P10628
   Xu SQ, 2021, IEEE INT C INTELL TR, P3047, DOI 10.1109/ITSC48978.2021.9564951
   Yang ZT, 2021, PROC CVPR IEEE, P1863, DOI 10.1109/CVPR46437.2021.00190
   Kim SY, 2019, Arxiv, DOI arXiv:1812.09079
   Zhang JB, 2017, AAAI CONF ARTIF INTE, P1655
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng Chang, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME51207.2021.9428362
   Zupancic I, 2016, IEEE T MULTIMEDIA, V18, P1677, DOI 10.1109/TMM.2016.2579505
NR 74
TC 4
Z9 4
U1 9
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 2354
EP 2367
DI 10.1109/TMM.2022.3146721
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA J1QV6
UT WOS:001007432100058
DA 2024-07-18
ER

PT J
AU Chen, ZL
   Yao, J
   Xiao, GB
   Wang, SP
AF Chen, Zhaoliang
   Yao, Jie
   Xiao, Guobao
   Wang, Shiping
TI Efficient and Differentiable Low-Rank Matrix Completion With Back
   Propagation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Low-rank matrix completion; back propagation; image recovery;
   collaborative filtering; Schatten-p norm
ID VARIABLE SELECTION; NONCONVEX; ALGORITHMS
AB The low-rank matrix completion has gained rapidly increasing attention from researchers in recent years for its efficient recovery of the matrix in various fields. Numerous studies have exploited the popular neural networks to yield low-rank outputs under the framework of low-rank matrix factorization. However, due to the discontinuity and nonconvexity of rank function, it is difficult to directly optimize the rank function via back propagation. Although a large number of studies have attempted to find relaxations of the rank function, e.g., Schatten-p norm, they still face the following issues when updating parameters via back propagation: 1) These methods or surrogate functions are still non-differentiable, bringing obstacles to deriving the gradients of trainable variables. 2) Most of these surrogate functions perform singular value decomposition upon the original matrix at each iteration, which is time-consuming and blocks the propagation of gradients. To address these problems, in this paper, we develop an efficient block-wise model dubbed differentiable low-rank learning (DLRL) framework that adopts back propagation to optimize the Multi-Schatten-p norm Surrogate (MSS) function. Distinct from the original optimization of this surrogate function, the proposed framework avoids singular value decomposition to admit the gradient propagation and builds a block-wise learning scheme to minimize values of Schatten-p norms. Accordingly, it speeds up the computation and makes all parameters in the proposed framework learnable according to a predefined loss function. Finally, we conduct substantial experiments in terms of image recovery and collaborative filtering. The experimental results verify the superiority of the proposed framework in terms of both runtimes and learning performance compared with other state-of-the-art low-rank optimization methods. Our codes are available at https://github.com/chenzl23/DLRL.
C1 [Chen, Zhaoliang; Yao, Jie; Wang, Shiping] Fuzhou Univ, Coll Comp & Data Sci, Fuzhou, Peoples R China.
   [Xiao, Guobao] Minjiang Univ, Coll Comp & Control Engn, Fuzhou, Peoples R China.
   [Chen, Zhaoliang; Yao, Jie; Xiao, Guobao; Wang, Shiping] Fuzhou Univ, Fujian Prov Key Lab Network Comp & Intelligent Inf, Fuzhou 350116, Peoples R China.
C3 Fuzhou University; Minjiang University; Fuzhou University
RP Wang, SP (corresponding author), Fuzhou Univ, Coll Comp & Data Sci, Fuzhou, Peoples R China.; Wang, SP (corresponding author), Fuzhou Univ, Fujian Prov Key Lab Network Comp & Intelligent Inf, Fuzhou 350116, Peoples R China.
EM chenzl23@outlook.com; jieyao926@163.com; gbx@mju.edu.cn;
   shipingwangphd@163.com
RI Chen, Zhaoliang/KGL-0282-2024
OI Chen, Zhaoliang/0000-0002-7832-908X; Xiao, Guobao/0000-0003-2928-8100
FU National Natural Science Foundation of China [U1705262]; Natural Science
   Foundation of Fujian [2020J01130193, 2018J07005]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1705262 and in part by the Natural
   Science Foundation of Fujian under Grants 2020J01130193 and 2018J07005.
   The Associate Editor coordinating the review of this manuscript and
   approving it for publication was Prof. Susanto Rahardja.
CR Acharya Anish, 2019, AAAI CONF ARTIF INTE, V33, P6196
   Arora S., 2019, ADV NEURAL INFORM PR
   Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9
   Chen JW, 2020, AAAI CONF ARTIF INTE, V34, P3470
   Du SD, 2021, IEEE T SIGNAL PROCES, V69, P4623, DOI 10.1109/TSP.2021.3101979
   Du YL, 2019, IEEE T MULTIMEDIA, V21, P555, DOI 10.1109/TMM.2018.2887018
   Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273
   Friedman JH, 2012, INT J FORECASTING, V28, P722, DOI 10.1016/j.ijforecast.2012.05.001
   Gregor K., 2010, P 27 INT C INT C MAC, P399
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Han YN, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5188
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Huang XJ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P637
   Huang Y, 2020, IEEE T IMAGE PROCESS, V29, P2244, DOI 10.1109/TIP.2019.2949383
   Jing PG, 2022, IEEE T MULTIMEDIA, V24, P1277, DOI 10.1109/TMM.2021.3062736
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu YP, 2019, IEEE T MULTIMEDIA, V21, P338, DOI 10.1109/TMM.2018.2859026
   Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760
   Lu CY, 2015, AAAI CONF ARTIF INTE, P1805
   Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584
   Lu CY, 2014, PROC CVPR IEEE, P4130, DOI 10.1109/CVPR.2014.526
   Lu YW, 2018, IEEE T IMAGE PROCESS, V27, P5248, DOI 10.1109/TIP.2018.2855433
   Nguyen LT, 2020, I C INF COMM TECH CO, P17, DOI 10.1109/ICTC49870.2020.9289469
   Mazumder R, 2010, J MACH LEARN RES, V11, P2287
   Monti F, 2017, ADV NEUR IN, V30
   Mu J, 2020, IEEE T IMAGE PROCESS, V29, P5374, DOI 10.1109/TIP.2020.2975931
   Nie F., 2012, AAAI, P655
   Nitanda A, 2014, ADV NEUR IN, V27
   Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Shang FH, 2016, AAAI CONF ARTIF INTE, P2016
   Shang FH, 2018, IEEE T PATTERN ANAL, V40, P2066, DOI 10.1109/TPAMI.2017.2748590
   Shang FH, 2016, JMLR WORKSH CONF PRO, V51, P620
   Takács G, 2009, J MACH LEARN RES, V10, P623
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Wang HY, 2017, IEEE T MULTIMEDIA, V19, P969, DOI 10.1109/TMM.2016.2638624
   Wang J, 2018, IEEE T CYBERNETICS, V48, P2620, DOI 10.1109/TCYB.2017.2747400
   Wang SP, 2022, IEEE T PATTERN ANAL, V44, P5042, DOI 10.1109/TPAMI.2021.3082632
   Wang Z, 2021, IEEE T MULTIMEDIA, V23, P1855, DOI 10.1109/TMM.2020.3003747
   Xiao XL, 2021, IEEE T IMAGE PROCESS, V30, P108, DOI 10.1109/TIP.2020.3031813
   Xie Xingyu, 2019, International Conference on Machine Learning, P6902
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xu C, 2017, AAAI CONF ARTIF INTE, P926
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Yang MY, 2022, IEEE T KNOWL DATA EN, V34, P2190, DOI 10.1109/TKDE.2020.3005978
   Yang SJ, 2019, IEEE T MULTIMEDIA, V21, P2916, DOI 10.1109/TMM.2019.2912735
   Yang Y, 2016, 30 C NEURAL INFORM P, V29
   Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729
   Zhang HM, 2020, IEEE T IMAGE PROCESS, V29, P3132, DOI 10.1109/TIP.2019.2957925
   Zhang HM, 2019, IEEE T NEUR NET LEAR, V30, P2916, DOI 10.1109/TNNLS.2019.2900572
   Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196
   Zhang LM, 2020, IEEE T MULTIMEDIA, V22, P1273, DOI 10.1109/TMM.2019.2938664
   Zhang M, 2013, IEEE T INFORM THEORY, V59, P4316, DOI 10.1109/TIT.2013.2250577
NR 55
TC 7
Z9 7
U1 2
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 228
EP 242
DI 10.1109/TMM.2021.3124087
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 9E8KM
UT WOS:000937028400017
DA 2024-07-18
ER

PT J
AU Ding, GD
   Yao, A
AF Ding, Guodong
   Yao, Angela
TI Temporal Action Segmentation With High-Level Complex Activity Labels
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Temporal action segmentation; weakly supervised learning; hungarian
   matching; prototype learning; activity recognition
ID ACTION RECOGNITION
AB The temporal action segmentation task segments videos temporally and predicts action labels for all frames. Fully supervising such a segmentation model requires dense frame-wise action annotations, which are expensive and tedious to collect. This work is the first to propose a Constituent Action Discovery (CAD) framework that only requires the video-wise high-level complex activity label as supervision for temporal action segmentation. The proposed approach automatically discovers constituent video actions using an activity classification task. Specifically, we define a finite number of latent action prototypes to construct video-level dual representations with which these prototypes are learned collectively through the activity classification training. This setting endows our approach with the capability to discover potentially shared actions across multiple complex activities. Due to the lack of action-level supervision, we adopt the Hungarian matching algorithm to relate latent action prototypes to ground truth semantic classes for evaluation. We show that with the high-level supervision, the Hungarian matching can be extended from the existing video and activity levels to the global level. The global-level matching allows for action sharing across activities, which has never been considered in the literature before. Extensive experiments demonstrate that our discovered actions can help perform temporal action segmentation and activity recognition tasks.
C1 [Ding, Guodong; Yao, Angela] Natl Univ Singapore, Sch Comp, Singapore 117418, Singapore.
C3 National University of Singapore
RP Yao, A (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117418, Singapore.
EM dinggd@comp.nus.edu.sg; ayao@comp.nus.edu.sg
OI Ding, Guodong/0000-0001-6080-5220; Yao, Angela/0000-0001-7418-6141
FU National Research Foundation, Singapore [NRFNRFFAI1-2019-0001]
FX This work was supported by the National Research Foundation, Singapore
   under NRF Fellowship for AI under Grant NRFNRFFAI1-2019-0001.
CR Aakur SN, 2019, PROC CVPR IEEE, P1197, DOI 10.1109/CVPR.2019.00129
   Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   Alayrac JB, 2016, PROC CVPR IEEE, P4575, DOI 10.1109/CVPR.2016.495
   Allen KR, 2019, PR MACH LEARN RES, V97
   Bojanowski P, 2014, LECT NOTES COMPUT SC, V8693, P628, DOI 10.1007/978-3-319-10602-1_41
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chang CY, 2019, PROC CVPR IEEE, P3541, DOI 10.1109/CVPR.2019.00366
   Ding L, 2018, PROC CVPR IEEE, P6508, DOI 10.1109/CVPR.2018.00681
   Du Z., 2022, P IEEECVF C COMPUTER, P3323
   Elhamifar E, 2019, IEEE I CONF COMP VIS, P6350, DOI 10.1109/ICCV.2019.00644
   Fayyaz M, 2020, PROC CVPR IEEE, P498, DOI 10.1109/CVPR42600.2020.00058
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fried D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2569
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   Huang DA, 2016, LECT NOTES COMPUT SC, V9908, P137, DOI 10.1007/978-3-319-46493-0_9
   Hussein N, 2020, Arxiv, DOI arXiv:2003.08275
   Hussein N, 2019, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2019.00034
   Ishikawa Y, 2021, IEEE WINT CONF APPL, P2321, DOI 10.1109/WACV48630.2021.00237
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kuehne H, 2017, COMPUT VIS IMAGE UND, V163, P78, DOI 10.1016/j.cviu.2017.06.004
   Kuehne H, 2016, IEEE WINT CONF APPL
   Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105
   Kukleva A, 2019, PROC CVPR IEEE, P12058, DOI 10.1109/CVPR.2019.01234
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Li D, 2019, IEEE T MULTIMEDIA, V21, P416, DOI 10.1109/TMM.2018.2862341
   Li J, 2021, PROC CVPR IEEE, P12623, DOI 10.1109/CVPR46437.2021.01244
   Li J, 2019, IEEE I CONF COMP VIS, P6252, DOI 10.1109/ICCV.2019.00634
   Li SJ, 2023, IEEE T PATTERN ANAL, V45, P6647, DOI 10.1109/TPAMI.2020.3021756
   Li T, 2006, IEEE DATA MINING, P362
   Li Z, 2021, PROC CVPR IEEE, P8361, DOI 10.1109/CVPR46437.2021.00826
   Min-Hung Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9451, DOI 10.1109/CVPR42600.2020.00947
   Moniruzzaman M, 2022, IEEE T MULTIMEDIA, V24, P689, DOI 10.1109/TMM.2021.3058050
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Paszke Adam, 2017, NIPS 2017 WORKSH AUT
   Richard A, 2018, PROC CVPR IEEE, P7386, DOI 10.1109/CVPR.2018.00771
   Richard A, 2018, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2018.00627
   Richard A, 2017, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2017.140
   Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341
   Roy D, 2019, IEEE T MULTIMEDIA, V21, P1672, DOI 10.1109/TMM.2018.2887021
   Sarfraz MS, 2021, PROC CVPR IEEE, P11220, DOI 10.1109/CVPR46437.2021.01107
   Sener F, 2018, PROC CVPR IEEE, P8368, DOI 10.1109/CVPR.2018.00873
   Sener O, 2015, IEEE I CONF COMP VIS, P4480, DOI 10.1109/ICCV.2015.509
   Tirupattur P, 2021, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR46437.2021.00151
   VidalMata RG, 2021, IEEE WINT CONF APPL, P1237, DOI 10.1109/WACV48630.2021.00128
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037
   Yang HM, 2018, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2018.00366
   Yifei Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14021, DOI 10.1109/CVPR42600.2020.01404
   Yu TZ, 2019, IEEE T MULTIMEDIA, V21, P2504, DOI 10.1109/TMM.2019.2907060
   Zhao PS, 2021, IEEE T MULTIMEDIA, V23, P3441, DOI 10.1109/TMM.2020.3025665
   Zhenzhi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P34, DOI 10.1007/978-3-030-58595-2_3
NR 54
TC 1
Z9 1
U1 3
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 1928
EP 1939
DI 10.1109/TMM.2022.3231099
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA J1QV6
UT WOS:001007432100027
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gong, GQ
   Zhu, LC
   Mu, YD
AF Gong, Guoqiang
   Zhu, Linchao
   Mu, Yadong
TI Language-Guided Multi-Granularity Context Aggregation for Temporal
   Sentence Grounding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Videos; Proposals; Grounding; Semantics; Location awareness;
   Convolution; Task analysis; Vision-language learning; video
   understanding; temporal sentence grounding; multi-modality learning
AB Temporal sentence grounding in videos is a crucial task in vision-language learning. Its goal is retrieving a video segment from an untrimmed video that semantically corresponds to a natural language query. A video usually contains multiple semantic events, which are rarely isolated. They tend to be temporally ordered and semantically correlated (e.g., some event is often the precursor of another event). To precisely localize a semantic moment from a video, it is critical to effectively extract and aggregate multi-granularity contextual information, including the fine-grained local context around the moment-related video segment (in short snippet-level) and coarse-grained semantic correlation (in segment-level). Additionally, a second main insight in this work is that the above context aggregation should be favorably guided by the queries, rather than fully query-agnostic. Putting above ideas together, we here present a new network that does language-guided multi-granularity context aggregation. It is comprised of two major modules. The core of the first module is a novel language-guided temporal adaptive convolution (LTAC) devised to extract fine-grained information over video snippets around the ground-truth video segment. It decomposes a convolution into two channel-oriented / temporal-oriented ones. In particular, the convolutional channels are supposed to be more susceptible to queries, thus we learn to generate a dynamic channel-oriented kernel with respect to the querying sentence. As a second module, we propose a language-guided global relation block (LGRB) that extracts video-level context. It augments the contextual feature by using a multi-scale temporal attention that tackles the scale variation of ground-truth video segments, and a multi-modal semantic attention that relies on syntactic of the query. For the validation purpose, we have conducted comprehensive experiments on two popularly-adopted video benchmarks (i.e., ActivityNet Captions and Charades-STA). All experimental results and ablation studies have clearly corroborated the effectiveness of our model designs, outstripping prior state-of-the-art methods in terms of major performance metrics for the task.
C1 [Gong, Guoqiang; Mu, Yadong] Peking Univ, Wangxuan Inst Comp Technol, Beijing 100871, Peoples R China.
   [Zhu, Linchao] Zhejiang Univ, Sch Comp Sci, Hangzhou 310027, Peoples R China.
   [Mu, Yadong] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Peking University; Zhejiang University; Peng Cheng Laboratory
RP Mu, YD (corresponding author), Peking Univ, Wangxuan Inst Comp Technol, Beijing 100871, Peoples R China.; Mu, YD (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.
EM gonggq@pku.edu.cn; zhulinchao7@gmail.com; muyadong@gmail.com
FU Science and Technology Innovation-New Generation Artificial Intelligence
   [2020AAA0104401]; Beijing Natural Science Foundation [Z190001]; Peng
   Cheng Laboratory Key Research Project [PCL2021A07]
FX This work was supported in part by the Science and Technology Innovation
   2030-New Generation Artificial Intelligence under Grant 2020AAA0104401,
   in part by the Beijing Natural Science Foundation, under Grant Z190001,
   and in part by Peng Cheng Laboratory Key Research Project under Grant
   PCL2021A07. A part of this work was performed when the Guoqiang Gong was
   an Intern with Baidu Research. The Associate Editor coordinating the
   review of this manuscript and approving it for publication was Dr. Chang
   Xu.
CR Buch S., 2017, P BRIT MACH VIS C BM
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Cao D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P898, DOI 10.1145/3394171.3413841
   Cao D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4162, DOI 10.1145/3394171.3413840
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen JY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P162
   Chen L, 2020, AAAI CONF ARTIF INTE, V34, P10551
   Chen PH, 2020, IEEE T MULTIMEDIA, V22, P2723, DOI 10.1109/TMM.2019.2959977
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Ding X., 2021, P IEEE CVF INT C COM, P11573
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Gao J., 2021, P IEEECVF INT C COMP, P1523
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao JY, 2017, IEEE I CONF COMP VIS, P5277, DOI 10.1109/ICCV.2017.563
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Ge RZ, 2019, IEEE WINT CONF APPL, P245, DOI 10.1109/WACV.2019.00032
   Gong GQ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102850
   He DL, 2019, AAAI CONF ARTIF INTE, P8393
   Hendricks LA, 2017, IEEE I CONF COMP VIS, P5804, DOI 10.1109/ICCV.2017.618
   Jonghwan Mun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10807, DOI 10.1109/CVPR42600.2020.01082
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kim J. H., 2017, PROC INT C LEARN REP, P1
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P4626
   Li YH, 2017, IEEE I CONF COMP VIS, P2098, DOI 10.1109/ICCV.2017.229
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Liu BB, 2018, LECT NOTES COMPUT SC, V11207, P569, DOI 10.1007/978-3-030-01219-9_34
   Liu DZ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4070, DOI 10.1145/3394171.3414026
   Liu DZ, 2021, PROC CVPR IEEE, P11230, DOI 10.1109/CVPR46437.2021.01108
   Liu M, 2018, ACM/SIGIR PROCEEDINGS 2018, P15, DOI 10.1145/3209978.3210003
   Liu W., 2019, Neural Inf. Process. Syst., P536
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Lu CJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5144
   Mengmeng Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10153, DOI 10.1109/CVPR42600.2020.01017
   Nan GS, 2021, PROC CVPR IEEE, P2764, DOI 10.1109/CVPR46437.2021.00279
   Peisen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P539, DOI 10.1007/978-3-030-58598-3_32
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rodriguez Cristian, 2020, WACV, P2464
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2021, PROC CVPR IEEE, P7022, DOI 10.1109/CVPR46437.2021.00695
   Wang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4116, DOI 10.1145/3394171.3413975
   Wang JW, 2020, AAAI CONF ARTIF INTE, V34, P12168
   Wang WN, 2019, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2019.00042
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu J, 2020, AAAI CONF ARTIF INTE, V34, P12386
   Xiao SN, 2021, AAAI CONF ARTIF INTE, V35, P2986
   Xu HJ, 2019, AAAI CONF ARTIF INTE, P9062
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Yuan YT, 2019, AAAI CONF ARTIF INTE, P9159
   Zeng R., 2020, CVPR
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhang D, 2019, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2019.00134
   Zhang Hao, 2020, P 58 ANN M ASS COMPU, P6543
   Zhang MX, 2021, PROC CVPR IEEE, P12664, DOI 10.1109/CVPR46437.2021.01248
   Zhang SY, 2022, IEEE T PATTERN ANAL, V44, P9073, DOI 10.1109/TPAMI.2021.3120745
   Zhang SY, 2020, AAAI CONF ARTIF INTE, V34, P12870
   Zhang SY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1230, DOI 10.1145/3343031.3350879
   Zhang Z, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P655, DOI 10.1145/3331184.3331235
   Zhao Y, 2021, PROC CVPR IEEE, P4195, DOI 10.1109/CVPR46437.2021.00418
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhou H, 2021, PROC CVPR IEEE, P8441, DOI 10.1109/CVPR46437.2021.00834
NR 71
TC 2
Z9 2
U1 1
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 7402
EP 7414
DI 10.1109/TMM.2022.3222664
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA Y1AC7
UT WOS:001102654000049
DA 2024-07-18
ER

PT J
AU Guo, ZQ
   Yang, GB
   Chen, JY
   Sun, XM
AF Guo, Zhiqing
   Yang, Gaobo
   Chen, Jiyou
   Sun, Xingming
TI Exposing Deepfake Face Forgeries With Guided Residuals
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Faces; Feature extraction; Deepfakes; Forgery; Robustness; Image
   forensics; Biology; Deepfake detection; image forensics; guided
   residuals; attention fusion mechanism
ID MANIPULATION DETECTION; IMAGE; RECOGNITION; NETWORKS
AB For Deepfake detection, residual-based features can preserve tampering traces and suppress irrelevant image content. However, inappropriate residual prediction brings side effects on detection accuracy. Meanwhile, residual-domain features are easily affected by some image operations such as lossy compression. Most existing works exploit either spatial-domain or residual-domain features, which are fed into the backbone network for feature learning. Actually, both types of features are mutually correlated. In this work, we propose an adaptive fusion based guided residuals network (AdapGRnet), which fuses spatial-domain and residual-domain features in a mutually reinforcing way, for Deepfake detection. Specifically, we present a fine-grained manipulation trace extractor (MTE), which is a key module of AdapGRnet. Compared with the prediction-based residuals, MTE can avoid the potential bias caused by inappropriate prediction. Moreover, an attention fusion mechanism (AFM) is designed to selectively emphasize feature channel maps and adaptively allocate the weights for two streams. Experimental results show that AdapGRnet achieves better detection accuracies than the state-of-the-art works on four public fake face datasets including HFF, FaceForensics++, DFDC and CelebDF. Especially, AdapGRnet achieves an accuracy up to 96.52% on the HFF-JP60 dataset, which improves about 5.50%. That is, AdapGRnet achieves better robustness than the existing works.
C1 [Guo, Zhiqing; Yang, Gaobo; Chen, Jiyou] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Hunan University; Nanjing University of Information Science & Technology
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Peoples R China.
EM guozhiqing@hnu.edu.cn; yanggaobo@hnu.edu.cn; jiyouchen@hnu.edu.cn;
   sunnudt@163.com
RI Sun, Xingming/AAD-1866-2019
OI chen, jiyou/0000-0001-8883-9430; Yang, Gaobo/0000-0003-2734-659X
FU National Natural Science Foundation of China
FX No Statement Available
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Berthelot D, 2017, Arxiv, DOI arXiv:1703.10717
   Bonettini N, 2021, INT C PATT RECOG, P5012, DOI 10.1109/ICPR48806.2021.9412711
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Das S, 2021, IEEE INT CONF COMP V, P3769, DOI 10.1109/ICCVW54120.2021.00421
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dolhansky B, 2019, Arxiv, DOI arXiv:1910.08854
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   Nguyen HH, 2019, Arxiv, DOI arXiv:1910.12467
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jeong Y, 2022, IEEE WINT CONF APPL, P2878, DOI 10.1109/WACV51458.2022.00293
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Karras T., 2018, INT C LEARN REPR, P1, Patent No. 171010196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma Durk P., 2018, ADV NEURAL INFORM PR
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Li HD, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107616
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Liang LY, 2019, IEEE T MULTIMEDIA, V21, P3068, DOI 10.1109/TMM.2019.2918717
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Marra F, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P506, DOI 10.1109/MIPR.2019.00103
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nguyen HH, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185974
   Peng F, 2020, IEEE T MULTIMEDIA, V22, P2511, DOI 10.1109/TMM.2019.2959443
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   R”ssler A, 2018, Arxiv, DOI arXiv:1803.09179
   Simonyan K, 2014, ADV NEUR IN, V27
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Wang CR, 2021, PROC CVPR IEEE, P14918, DOI 10.1109/CVPR46437.2021.01468
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Yang JC, 2022, IEEE T CIRC SYST VID, V32, P4854, DOI 10.1109/TCSVT.2021.3133859
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zhao TC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15003, DOI 10.1109/ICCV48922.2021.01475
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
   Zheng Zhao, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P291, DOI 10.1145/3404555.3404564
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 65
TC 5
Z9 5
U1 6
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 8458
EP 8470
DI 10.1109/TMM.2023.3237169
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CN3Z4
UT WOS:001125902000058
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, S
   Zhang, YH
   Fu, LL
   Wang, SP
AF Huang, Sheng
   Zhang, Yunhe
   Fu, Lele
   Wang, Shiping
TI Learnable Multi-View Matrix Factorization With Graph Embedding and
   Flexible Loss
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Neural networks; Linear programming; Data mining; Clustering algorithms;
   Laplace equations; Neural network; multi-view clustering; deep matrix
   factorization; shared representation; graph embedding
ID ALGORITHMS; FUSION
AB The goal of multi-view learning is to learn latent patterns from various data sources. Most of previous research focused on fitting feature embedding in target tasks. There is very limited research on the connection between feature representations with hidden layers of neural networks. In this paper, a multi-view deep matrix factorization model is proposed to learn a shared feature representation. The proposed model automatically explores the most discriminative features of multi-view data and makes these features meet the requirements of specific applications. Here we explore the connection between deep learning and feature representations. First, the model constructs a scalable neural network with shared hidden layers for exploring a low-dimensional representations of all views. Second, the quality of representation matrix is evaluated via relaxed graph regularization and evaluators to improve the feature representation capability of matrix factorization. Finally, the effectiveness of the proposed method is verified through comparative experiments with eight state-of-the-art multi-view clustering algorithms on eight real-world datasets.
C1 [Huang, Sheng; Zhang, Yunhe; Fu, Lele; Wang, Shiping] Fuzhou Univ, Coll Comp & Data Sci, Fuzhou 350116, Peoples R China.
   [Huang, Sheng; Zhang, Yunhe; Fu, Lele; Wang, Shiping] Fuzhou Univ, Data Sci, Fuzhou 350116, Peoples R China.
   [Huang, Sheng; Zhang, Yunhe; Fu, Lele; Wang, Shiping] Fuzhou Univ, Key Lab Network Comp & Intelligent Informat Proc, Fuzhou 350116, Peoples R China.
C3 Fuzhou University; Fuzhou University; Fuzhou University
RP Wang, SP (corresponding author), Fuzhou Univ, Coll Comp & Data Sci, Fuzhou 350116, Peoples R China.; Wang, SP (corresponding author), Fuzhou Univ, Data Sci, Fuzhou 350116, Peoples R China.; Wang, SP (corresponding author), Fuzhou Univ, Key Lab Network Comp & Intelligent Informat Proc, Fuzhou 350116, Peoples R China.
EM hshs0594@163.com; zhangyhannie@163.com; lawrencefzu@gmail.com;
   shipingwangphd@163.com
RI Fu, Lele/GLV-0220-2022
OI huang, sheng/0000-0001-9813-0572
FU National Natural Science Foundation of China
FX No Statement Available
CR Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   Chen Y, 2018, IEEE T MULTIMEDIA, V20, P1823, DOI 10.1109/TMM.2017.2775220
   Chen ZL, 2023, IEEE T MULTIMEDIA, V25, P228, DOI 10.1109/TMM.2021.3124087
   Choi S, 2008, IEEE IJCNN, P1828, DOI 10.1109/IJCNN.2008.4634046
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Guillamet D, 2001, PROC CVPR IEEE, P942
   Houthuys L, 2018, INFORM FUSION, V44, P46, DOI 10.1016/j.inffus.2017.12.002
   Huang SD, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107015
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Karami M, 2017, ADV NEUR IN, V30
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li S, 2020, AAAI CONF ARTIF INTE, V34, P4691
   Li YF, 2019, IEEE T NEUR NET LEAR, V30, P615, DOI 10.1109/TNNLS.2018.2849932
   Liu CH, 2022, AAAI CONF ARTIF INTE, P7542
   Liu HF, 2010, AAAI CONF ARTIF INTE, P506
   Mohar B., 1991, GRAPH THEORY COMBINA, V2, P871
   Mohotti Wathsala Anupama, 2020, Neural Information Processing. 27th International Conference, ICONIP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12533), P270, DOI 10.1007/978-3-030-63833-7_23
   Nie F., 2016, IJCAI, P1881
   Nie FP, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107207
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Peng S., 2021, Pattern Recognit., V111, P1
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P1724, DOI 10.1109/TMM.2018.2889560
   Tao H, 2017, IEEE T IMAGE PROCESS, V26, P4283, DOI 10.1109/TIP.2017.2717191
   Trigeorgis G, 2017, IEEE T PATTERN ANAL, V39, P417, DOI 10.1109/TPAMI.2016.2554555
   Wang BY, 2021, IEEE T MULTIMEDIA, V23, P216, DOI 10.1109/TMM.2020.2975394
   Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810
   Wang H, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3418227
   Wang Q, 2022, IEEE T PATTERN ANAL, V44, P390, DOI 10.1109/TPAMI.2020.3007673
   Wang SP, 2022, IEEE T PATTERN ANAL, V44, P5042, DOI 10.1109/TPAMI.2021.3082632
   Wang XB, 2019, PATTERN RECOGN, V88, P50, DOI 10.1016/j.patcog.2018.09.009
   Wang YH, 2021, IEEE T MULTIMEDIA, V23, P2782, DOI 10.1109/TMM.2020.3016222
   Wei SW, 2020, AAAI CONF ARTIF INTE, V34, P6348
   Wen J, 2021, IEEE T MULTIMEDIA, V23, P2493, DOI 10.1109/TMM.2020.3013408
   Xi JN, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2218-y
   Xie Y, 2020, IEEE T CYBERNETICS, V50, P572, DOI 10.1109/TCYB.2018.2869789
   Xue HJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3203
   Yang B, 2021, IEEE T IMAGE PROCESS, V30, P2575, DOI 10.1109/TIP.2020.3045631
   Yang ML, 2019, PATTERN RECOGN, V88, P236, DOI 10.1016/j.patcog.2018.11.015
   Yi BL, 2019, IEEE T IND INFORM, V15, P4591, DOI 10.1109/TII.2019.2893714
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646
   Zhang C, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4156, DOI 10.1145/3474085.3475548
   Zhang XC, 2015, AAAI CONF ARTIF INTE, P3174
   Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335
   Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zong LL, 2017, NEURAL NETWORKS, V88, P74, DOI 10.1016/j.neunet.2017.02.003
NR 51
TC 12
Z9 12
U1 6
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 3259
EP 3272
DI 10.1109/TMM.2022.3157997
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AD7R0
UT WOS:001116593700006
DA 2024-07-18
ER

PT J
AU Li, YM
   Yang, XS
   Huang, XH
   Ma, Z
   Xu, CS
AF Li, Yiming
   Yang, Xiaoshan
   Huang, Xuhui
   Ma, Zhe
   Xu, Changsheng
TI Zero-Shot Predicate Prediction for Scene Graph Parsing
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Deep learning; zero-shot; scene graph
AB The scene graph is a structured semantic representation of an image, which represents objects and relationships with vertices and edges, respectively. Since it is impossible to manually label all potential relationships in the real world, some previous methods try to apply the zero-shot method for scene graph generation. However, existing methods take triplet (i.e., (subject -predicate -object)) as the basic unit of a relationship. Each element (i.e., subject, predicate, or object) of the unseen relationship is actually seen in the training data. Therefore, they ignore the unseen predicate. To predict the unseen predicate, we introduce a novel task named zero-shot predicate prediction, which is crucial to extending existing scene graph generation methods to recognize more relationship classes. The new task is challenging and cannot be simply resolved through conventional zero-shot learning methods because there is a large intra-class variation of each predicate. Firstly, the large intra-class variation leads to the difficulty of computing the discriminative instance-level feature of the predicate class. Secondly, the large intra-class variation also brings more difficulties when knowledge is transferred from seen classes to unseen classes. For the first challenge, we propose distilling lexical knowledge of different objects and construct multi-modal representations of pairwise objects to reduce the intra-class variation of the predicate. To respond to the second challenge, we build a compact semantic space where the representations of unseen classes are reconstructed based on the seen classes for zero-shot predicate classification. We evaluate the proposed method on the public dataset Visual Genome. The extensive experiment results under the zero-shot/few-shot/supervised settings demonstrate the effectiveness of the proposed method.
C1 [Li, Yiming] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
   [Yang, Xiaoshan; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   [Yang, Xiaoshan; Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
   [Yang, Xiaoshan; Xu, Changsheng] PengCheng Lab, Shenzhen 518066, Peoples R China.
   [Huang, Xuhui; Ma, Zhe] CASIC, Acad 2, Lab 10, Beijing 100854, Peoples R China.
C3 Zhengzhou University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Xu, CS (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM 202011171010153@gs.zzu.edu.cn; xiaoshan.yang@nlpr.ia.ac.cn;
   starhxh@126.com; mazhe_thu@126.com; csxu@nlpr.ia.ac.cn
RI Li, Yiming/GSE-1311-2022; xu, cj/HJZ-3488-2023
OI xu, chang sheng/0000-0001-8343-9665
FU National Key Research and Development Program of China [2018AAA0100604];
   National Natural Science Foundation of China [61720106006, 62036012,
   61721004, 62072455, U1836220, U1705262, 61872424]; Key Research Program
   of Frontier Sciences of CAS [QYZDJ-SSW-JSC039]; Beijing Natural Science
   Foundation [L201001]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018AAA0100604, in part by the
   National Natural Science Foundation of China under Grants 61720106006,
   62036012, 61721004, 62072455, U1836220, U1705262, and 61872424, in part
   by the Key Research Program of Frontier Sciences of CAS under Grant
   QYZDJ-SSW-JSC039, and in part by Beijing Natural Science Foundation
   under Grant L201001.
CR Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   Atzmon Yuval, 2020, Advances in Neural Information Processing Systems, V33, P1462
   Ba J, 2016, ADV NEUR IN, V29
   Bansal A, 2018, LECT NOTES COMPUT SC, V11205, P397, DOI 10.1007/978-3-030-01246-5_24
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chen TS, 2019, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2019.00632
   Chen VS, 2019, IEEE I CONF COMP VIS, P2580, DOI [10.1109/iccv.2019.00267, 10.1109/ICCV.2019.00267]
   Cong WL, 2018, Arxiv, DOI arXiv:1811.08075
   Dornadula A, 2019, IEEE INT CONF COMP V, P1730, DOI 10.1109/ICCVW.2019.00214
   Frome A., 2013, PROC 27 ANN C NEURAL, V26, P1
   Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354
   Gao JY, 2020, IEEE T MULTIMEDIA, V22, P3088, DOI 10.1109/TMM.2020.2969787
   Ghosh S., 2019, arXiv
   Guo JC, 2021, IEEE T MULTIMEDIA, V23, P524, DOI 10.1109/TMM.2020.2984091
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hsu Y.-C., 2018, ICLR, P1
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kipf T. N., 2017, 8 INT C LEARN REPR, P1
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li XY, 2019, IEEE T MULTIMEDIA, V21, P2117, DOI 10.1109/TMM.2019.2896516
   Li YK, 2018, LECT NOTES COMPUT SC, V11205, P346, DOI 10.1007/978-3-030-01246-5_21
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Li YK, 2017, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2017.766
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Miller George, 1998, WORDNET ELECT LEXICA
   Parkash A, 2012, LECT NOTES COMPUT SC, V7574, P354, DOI 10.1007/978-3-642-33712-3_26
   Rahman S, 2020, INT J COMPUT VISION, V128, P2979, DOI 10.1007/s11263-020-01355-6
   Rahman S, 2020, IEEE T MULTIMEDIA, V22, P242, DOI 10.1109/TMM.2019.2924511
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romera-Paredes Bernardino, 2015, ICML
   Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P131, DOI 10.1162/neco.1992.4.1.131
   Schönfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Tang KH, 2020, PROC CVPR IEEE, P3713, DOI 10.1109/CVPR42600.2020.00377
   Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang WL, 2018, AAAI CONF ARTIF INTE, P4211
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xu BJ, 2020, IEEE T MULTIMEDIA, V22, P1423, DOI 10.1109/TMM.2019.2943753
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Xu N, 2019, J VIS COMMUN IMAGE R, V58, P477, DOI 10.1016/j.jvcir.2018.12.027
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yang X, 2019, PROC CVPR IEEE, P4061, DOI 10.1109/CVPR.2019.00419
   Zareian Alireza, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P606, DOI 10.1007/978-3-030-58592-1_36
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
NR 52
TC 0
Z9 0
U1 5
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 3140
EP 3153
DI 10.1109/TMM.2022.3155928
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA O7RP6
UT WOS:001045742200015
DA 2024-07-18
ER

PT J
AU Lin, X
   Sun, SZ
   Huang, W
   Sheng, B
   Li, P
   Feng, DD
AF Lin, Xiao
   Sun, Shuzhou
   Huang, Wei
   Sheng, Bin
   Li, Ping
   Feng, David Dagan
TI EAPT: Efficient Attention Pyramid Transformer for Image Processing
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Transformers; attention mechanism; pyramid; classification; object
   detection; semantic segmentation
AB Recent transformer-based models, especially patch-based methods, have shown huge potentiality in vision tasks. However, the split fixed-size patches divide the input features into the same size patches, which ignores the fact that vision elements are often various and thus may destroy the semantic information. Also, the vanilla patch-based transformer cannot guarantee the information communication between patches, which will prevent the extraction of attention information with a global view. To circumvent those problems, we propose an Efficient Attention Pyramid Transformer (EAPT). Specifically, we first propose the Deformable Attention, which learns an offset for each position in patches. Thus, even with split fixed-size patches, our method can still obtain non-fixed attention information that can cover various vision elements. Then, we design the Encode-Decode Communication module (En-DeC module), which can obtain communication information among all patches to get more complete global attention information. Finally, we propose a position encoding specifically for vision transformers, which can be used for patches of any dimension and any length. Extensive experiments on the vision tasks of image classification, object detection, and semantic segmentation demonstrate the effectiveness of our proposed model. Furthermore, we also conduct rigorous ablation studies to evaluate the key components of the proposed structure.
C1 [Lin, Xiao; Sun, Shuzhou] Shanghai Normal Univ, Dept Comp Sci, Shanghai 200234, Peoples R China.
   [Lin, Xiao; Sun, Shuzhou] Shanghai Engn Res Ctr Intelligent Educ & Bigdata, Shanghai 200240, Peoples R China.
   [Huang, Wei] Univ Shanghai Sci & Technol, Dept Comp Sci & Engn, Shanghai 200093, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong 999077, Peoples R China.
   [Feng, David Dagan] Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol Res Grp, Sydney, NSW 2006, Australia.
C3 Shanghai Normal University; University of Shanghai for Science &
   Technology; Shanghai Jiao Tong University; Hong Kong Polytechnic
   University; University of Sydney
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM lin6008@shnu.edu.cn; 1000479143@smail.shnu.edu.cn;
   191380039@usst.edu.cn; shengbin@cs.sjtu.edu.cn; p.li@polyu.edu.hk;
   dagan.feng@sydney.edu.au
RI CHEN, AN/KFT-3370-2024; Li, Ping/AAO-2019-2020; LIU, HAO/JBI-9623-2023;
   LI, Xiang-Yang/JZE-0275-2024; li, xiaomin/KCX-9845-2024
OI Li, Ping/0000-0002-1503-0240; Sheng, Bin/0000-0001-8678-2784
FU National Natural Science Foundation of China [61872241, 62077037];
   Shanghai Municipal Science and Technology Major Project
   [2021SHZDZX0102]; Science and Technology Commission of Shanghai
   Municipality [18410750700, 17411952600]; Shanghai Lin-Gang Area Smart
   Manufacturing Special Project [ZN2018020202-3]; Project of Shanghai
   Municipal Health Commission [2018ZHYL0230]; Hong Kong Polytechnic
   University [P0030419, P0030929, P0035358]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61872241 and 62077037, in part by
   Shanghai Municipal Science and Technology Major Project under Grant
   2021SHZDZX0102, in part by the Science and Technology Commission of
   Shanghai Municipality under Grants 18410750700 and 17411952600, in part
   by Shanghai Lin-Gang Area Smart Manufacturing Special Project under
   Grant ZN2018020202-3, in part by Project of Shanghai Municipal Health
   Commission under Grant 2018ZHYL0230, and in part by the Hong Kong
   Polytechnic University under Grants P0030419, P0030929, and P0035358.
   The associate editor coordinating the review of this manuscript and
   approving it for publication was Professor Liqiang Nie.
CR Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen HF, 2021, IEEE T MULTIMEDIA, V23, P4171, DOI 10.1109/TMM.2020.3037496
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Y., 2020, ADV NEURAL INF PROCE, V33, P5621
   Chen ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2899, DOI 10.1145/3474085.3475467
   Chi C., 2020, P NEUR INF PROC SYST, P1
   Dai J., 2021, ICLR
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2019, PROC C N AM CHAPTER, P563
   Dosovitskiy Alexey, 2021, ICLR
   Du X., 2020, PROC IEEE C COMPUT V, p11 589
   Fu J, 2019, IEEE I CONF COMP VIS, P6747, DOI 10.1109/ICCV.2019.00685
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ghiasi G., 2020, PROC IEEECVF C COMPU, P2918
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kingma D. P., 2015, INT C LEARNING REPRE
   Liang Justin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9128, DOI 10.1109/CVPR42600.2020.00915
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu X, 2020, INT C MACHINE LEARNI, P6327
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2905, DOI 10.1109/TMM.2020.2965491
   Lyu F, 2019, IEEE T MULTIMEDIA, V21, P1971, DOI 10.1109/TMM.2019.2894964
   Minghao Yin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P191, DOI 10.1007/978-3-030-58555-6_12
   Nie LQ, 2017, IEEE T KNOWL DATA EN, V29, P1186, DOI 10.1109/TKDE.2017.2669982
   Pan ZQ, 2022, IEEE T MULTIMEDIA, V24, P519, DOI 10.1109/TMM.2021.3054509
   Qian YQ, 2020, IEEE T MULTIMEDIA, V22, P421, DOI 10.1109/TMM.2019.2929949
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Radosavovic Ilija, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10425, DOI 10.1109/CVPR42600.2020.01044
   Shaw P., 2018, P 2018 NAACL, V2, P464, DOI [DOI 10.18653/V1/N18-2074, 10.18653/v1/N18-2074]
   Shi C, 2020, IEEE T MULTIMEDIA, V22, P487, DOI 10.1109/TMM.2019.2928491
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tan M., 2020, PROC IEEE C COMPUT V, p10 778
   Tan MX, 2019, PR MACH LEARN RES, V97
   Touvron H., 2020, P INT C MACH LEARN, P10347
   Vaswani A, 2017, ADV NEUR IN, V30
   Wagner J, 2019, PROC CVPR IEEE, P9089, DOI 10.1109/CVPR.2019.00931
   Wang QR, 2019, IEEE T MULTIMEDIA, V21, P930, DOI 10.1109/TMM.2018.2869277
   Wang X, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1543, DOI 10.1145/3178876.3186066
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Xiaolin Chen, 2021, IEEE Transactions on Multimedia, V23, P3957, DOI 10.1109/TMM.2020.3034540
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang H., ResNeSt: Split-Attention Networks, P2020, DOI DOI 10.48550/ARXIV.2004.08955
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhong HS, 2021, IEEE T MULTIMEDIA, V23, P1264, DOI 10.1109/TMM.2020.2995278
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
NR 53
TC 91
Z9 92
U1 34
U2 65
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 50
EP 61
DI 10.1109/TMM.2021.3120873
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 9E8KM
UT WOS:000937028400004
HC Y
HP Y
DA 2024-07-18
ER

PT J
AU Liu, ZM
   Guo, S
   Guo, JC
   Xu, YY
   Huo, FS
AF Liu, Ziming
   Guo, Song
   Guo, Jingcai
   Xu, Yuanyuan
   Huo, Fushuo
TI Towards Unbiased Multi-Label Zero-Shot Learning With Pyramid and
   Semantic Attention
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Semantics; Image recognition; Feature extraction; Training; Correlation;
   Computational modeling; Task analysis; Multi-label zero-shot learning;
   attention mechanism; semantic feature space; classification; pattern
   recognition
ID CLASSIFICATION
AB Multi-label zero-shot learning extends conventional single-label zero-shot learning to a more realistic scenario that aims at recognizing multiple unseen labels of classes for each input sample. Existing works usually exploit attention mechanism to generate the correlation among different labels. However, most of them are usually biased on several major classes while neglect most of the minor classes with the same importance in input samples, and may thus result in overly diffused attention maps that cannot sufficiently cover minor classes. We argue that disregarding the connection between major and minor classes, i.e., correspond to the global and local information, respectively, is the cause of the problem. In this paper, we propose a novel framework of unbiased multi-label zero-shot learning, by considering various class-specific regions to calibrate the training process of the classifier. Specifically, Pyramid Feature Attention (PFA) is proposed to build the correlation between global and local information of samples to balance the presence of each class. Meanwhile, for the generated semantic representations of input samples, we propose Semantic Attention (SA) to strengthen the element-wise correlation among these vectors, which can encourage the coordinated representation of them. Extensive experiments on the large-scale multi-label benchmarks MS-COCO, NUS-WIDE and Open-Images demonstrate that the proposed method surpasses other representative methods by significant margins.
C1 [Liu, Ziming; Guo, Song; Guo, Jingcai; Huo, Fushuo] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Xu, Yuanyuan] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
C3 Hong Kong Polytechnic University; University of Electronic Science &
   Technology of China
RP Guo, S; Guo, JC (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
EM ziming.liu@connect.polyu.hk; song.guo@polyu.edu.hk;
   jingcai.guo@gmail.com; hyries@std.uestc.edu.cn; fushuohuo@163.com
RI Guo, Song/AAZ-4542-2020; Huo, Fushuo/IAL-9198-2023
OI Guo, Song/0000-0001-9831-2202; Huo, Fushuo/0000-0003-1030-7834; Guo,
   Jingcai/0000-0002-0449-4525
FU Key-Area Research and Development Program of Guangdong Province
   [2021B0101400003]; Hong Kong RGC Research Impact Fund [R5060-19]; Hong
   Kong RGC General Research Fund [152221/19E, 152203/20E, 152244/21E];
   National Natural Science Foundation of China [61872310, 62102327];
   Shenzhen Science and Technology Innovation Commission
   [JCYJ20200109142008673]
FX This work was supported in part by the Key-Area Research and Development
   Program of Guangdong Province under Grant 2021B0101400003, in part by
   Hong Kong RGC Research Impact Fund under Grant R5060-19, in part by Hong
   Kong RGC General Research Fund under Grants 152221/19E, 152203/20E, and
   152244/21E, in part by the National Natural Science Foundation of China
   under Grants 61872310 and 62102327, and in part by Shenzhen Science and
   Technology Innovation Commission under Grant JCYJ20200109142008673.
CR Akata Z, 2016, PROC CVPR IEEE, P59, DOI 10.1109/CVPR.2016.14
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Bucher M, 2016, LECT NOTES COMPUT SC, V9909, P730, DOI 10.1007/978-3-319-46454-1_44
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Dat Huynh, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8773, DOI 10.1109/CVPR42600.2020.00880
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deutsch S, 2017, PROC CVPR IEEE, P5292, DOI 10.1109/CVPR.2017.562
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Durand T, 2019, PROC CVPR IEEE, P647, DOI 10.1109/CVPR.2019.00074
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Feng L, 2019, AAAI CONF ARTIF INTE, P3550
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gao BB, 2021, IEEE T IMAGE PROCESS, V30, P5920, DOI 10.1109/TIP.2021.3088605
   Gong YC, 2014, Arxiv, DOI arXiv:1312.4894
   Guo JC, 2021, IEEE T MULTIMEDIA, V23, P524, DOI 10.1109/TMM.2020.2984091
   Guo JC, 2019, IEEE INT CON MULTI, P73, DOI 10.1109/ICME.2019.00021
   Guo JC, 2019, INT CONF ACOUST SPEE, P3287, DOI 10.1109/ICASSP.2019.8682869
   Gupta A., 2021, arXiv:2101.11606, P1
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Ji Z, 2020, IEEE T IMAGE PROCESS, V29, P6549, DOI 10.1109/TIP.2020.2991527
   Jin Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P649, DOI 10.1007/978-3-030-58589-1_39
   Kim JH, 2018, ADV NEUR IN, V31
   Kingma D. P., 2014, arXiv
   Kipf TN, 2016, ARXIV
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170
   Li YN, 2017, PROC CVPR IEEE, P5207, DOI 10.1109/CVPR.2017.553
   Li Y, 2023, IEEE T MULTIMEDIA, V25, P1600, DOI 10.1109/TMM.2021.3139211
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313
   Min SB, 2021, IEEE T MULTIMEDIA, V23, P3919, DOI 10.1109/TMM.2020.3033124
   Morgado P, 2017, PROC CVPR IEEE, P2037, DOI 10.1109/CVPR.2017.220
   Nam J., 2017, ADV NEURAL INF PROCE, P5413
   Norouzi M., 2014, P INT C LEARN REPR
   Rahman S, 2020, IEEE T MULTIMEDIA, V22, P242, DOI 10.1109/TMM.2019.2924511
   Rahman S, 2018, IEEE T IMAGE PROCESS, V27, P5652, DOI 10.1109/TIP.2018.2861573
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Weston J, 2011, IJCAI
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Yazici Vacit Oguz, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13437, DOI 10.1109/CVPR42600.2020.01345
   You RC, 2020, AAAI CONF ARTIF INTE, V34, P12709
   Yu HF, 2014, PR MACH LEARN RES, V32
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XX, 2020, IEEE T MULTIMEDIA, V22, P1692, DOI 10.1109/TMM.2019.2959433
   Zhang Y, 2016, PROC CVPR IEEE, P5985, DOI 10.1109/CVPR.2016.644
   Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111
NR 66
TC 1
Z9 1
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 7441
EP 7455
DI 10.1109/TMM.2022.3222657
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA Y1AC7
UT WOS:001102654000052
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ma, L
   Liu, RS
   Wang, YY
   Fan, X
   Luo, ZX
AF Ma, Long
   Liu, Risheng
   Wang, Yiyang
   Fan, Xin
   Luo, Zhongxuan
TI Low-Light Image Enhancement via Self-Reinforced Retinex Projection Model
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Lighting; Optimization; Image enhancement; Smoothing methods; Image
   color analysis; Estimation; Image edge detection; Low-light image
   enhancement; retinex model; image denoising; illumination estimation
ID HISTOGRAM EQUALIZATION; FUSION NETWORK; ILLUMINATION
AB Low-light image enhancement aims to improve the quality of images captured under low-lightening conditions, which is a fundamental problem in computer vision and multimedia areas. Although many efforts have been invested over the years, existing illumination-based models tend to generate unnatural-looking results (e.g., over-exposure). It is because that the widely-adopted illumination adjustment (e.g., Gamma Correction) breaks down the favorable smoothness property of the original illumination derived from the well-designed illumination estimation model. To settle this issue, a great-efficiency and high-quality Self-Reinforced Retinex Projection (SRRP) model is developed in this paper, which contains optimization modules of both illumination and reflectance layers. Specifically, we construct a new fidelity term with the self-reinforced function for the illumination optimization to eliminate the dependence of the illumination adjustment to obtain a desired illumination with the excellent smoothing property. By introducing a flexible feasible constraint, we obtain a reflectance optimization module with projection. Owing to its flexibility, we can extend our model to an enhanced version by integrating a data-driven denoising mechanism as the projection, which is able to effectively handle the generated noises/artifacts in the enhanced procedure. In the experimental part, on one side, we make ample comparative assessments on multiple benchmarks with considerable state-of-the-art methods. These evaluations fully verify the outstanding performance of our method, in terms of the qualitative and quantitative analyses and execution efficiency. On the other side, we also conduct extensive analytical experiments to indicate the effectiveness and advantages of our proposed model.
C1 [Ma, Long; Luo, Zhongxuan] Dalian Univ Technol, Sch Software Technol, Dalian 116024, Peoples R China.
   [Ma, Long] Peng Cheng Lab, Shenzhen 518052, Peoples R China.
   [Liu, Risheng; Fan, Xin] Dalian Univ Technol, DUT RU Int Sch Informat Sci & Engn, Dalian 116024, Peoples R China.
   [Wang, Yiyang] Dalian Maritime Univ, Coll Artificial Intelligence, Dalian 116026, Peoples R China.
C3 Dalian University of Technology; Peng Cheng Laboratory; Dalian
   University of Technology; Dalian Maritime University
RP Liu, RS (corresponding author), Dalian Univ Technol, DUT RU Int Sch Informat Sci & Engn, Dalian 116024, Peoples R China.
EM malone94319@gmail.com; rsliu@dlut.edu.cn; yywerica@dlmu.edu.cn;
   xin.fan@dlut.edu.cn; zxluo@dlut.edu.cn
OI Liu, Risheng/0000-0002-9554-0565; Wang, Yiyang/0000-0002-8924-3468; Ma,
   Long/0000-0001-5125-0198
FU National Natural Science Foundation of China [61922019, 61733002,
   62027826]; Fundamental Research Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61922019, 61733002, and 62027826 and in
   part by the Fundamental Research Funds for the Central Universities. The
   Associate Editor coordinating the review of this manuscript and
   approving it for publication was Dr. Xavier Giro-i-Nieto.
CR Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Galdran A, 2018, PROC CVPR IEEE, P8212, DOI 10.1109/CVPR.2018.00857
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang B, 2020, IEEE T MULTIMEDIA, V22, P2820, DOI 10.1109/TMM.2020.2965482
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Li JA, 2018, IEEE T MULTIMEDIA, V20, P1645, DOI 10.1109/TMM.2017.2772796
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Lim S, 2021, IEEE T MULTIMEDIA, V23, P4272, DOI 10.1109/TMM.2020.3039361
   LIU R, 2021, IEEE T NEURAL NETW L
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Liu RS, 2019, IEEE T IMAGE PROCESS, V28, P5013, DOI 10.1109/TIP.2019.2913536
   Liu RS, 2019, IEEE T IMAGE PROCESS, V28, P1528, DOI 10.1109/TIP.2018.2875568
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lu K, 2021, IEEE T MULTIMEDIA, V23, P4093, DOI 10.1109/TMM.2020.3037526
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   MA L, 2021, IEEE T NEURAL NETW L
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Pan JS, 2021, IEEE T PATTERN ANAL, V43, P2449, DOI 10.1109/TPAMI.2020.2969348
   Poynton C, 2012, DIGITAL VIDEO AND HD: ALGORITHMS AND INTERFACES, 2ND EDITION, P1
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vonikakis V, 2018, MULTIMED TOOLS APPL, V77, P9211, DOI 10.1007/s11042-017-4783-x
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Xie YQ, 2021, IEEE IPCCC, DOI 10.1109/IPCCC51483.2021.9679370
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Yuan L, 2012, LECT NOTES COMPUT SC, V7575, P771, DOI 10.1007/978-3-642-33765-9_55
   Yun SH, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P203, DOI 10.1109/ICCE.2011.5722541
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang Q, 2021, IEEE T MULTIMEDIA, V23, P189, DOI 10.1109/TMM.2020.2982045
   Zhang YH, 2021, INT J COMPUT VISION, V129, P1013, DOI 10.1007/s11263-020-01407-x
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao SY, 2021, IEEE T IMAGE PROCESS, V30, P3391, DOI 10.1109/TIP.2021.3060873
NR 65
TC 14
Z9 14
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 3573
EP 3586
DI 10.1109/TMM.2022.3162493
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FE2H4
UT WOS:001144015500007
DA 2024-07-18
ER

PT J
AU Mou, LT
   Zhou, C
   Xie, PT
   Zhao, PF
   Jain, R
   Gao, W
   Yin, BC
AF Mou, Luntian
   Zhou, Chao
   Xie, Pengtao
   Zhao, Pengfei
   Jain, Ramesh
   Gao, Wen
   Yin, Baocai
TI Isotropic Self-Supervised Learning for Driver Drowsiness Detection With
   Attention-Based Multimodal Fusion
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Feature extraction; Convolutional neural networks; Videos; Hidden Markov
   models; Vehicles; Dictionaries; Computational modeling; Attention;
   driver drowsiness detection; isotropic self-supervised learning
   (IsoSSL); momentum contrast (MoCo); multimodal fusion model
ID NETWORKS
AB Driverdrowsiness is an important cause of traffic accidents. Many studies using computer vision techniques to detect driver drowsiness states, such as slow blinking, yawning, and nodding, have demonstrated excellent potential. Although existing studies have made significant progress, the number of samples in the training corpora is small, which makes it difficult for a model to learn effective drowsiness representations from images or videos. To address this issue, we develop an isotropic self-supervised learning (IsoSSL) approach to learn powerful representations of images without relying on human-provided annotations and propose an IsoSSL-MoCo model by combining IsoSSL with momentum contrast (MoCo). To exploit the complementarity of multimodal data, an attention-based multimodal fusion model is also proposed to fuse features from the eye, mouth, and optical flow of the head. Specifically, we first use the IsoSSL-MoCo model to pretrain the image encoders for the three modalities in other datasets. Then, these encoders are fine-tuned and integrated into the proposed fusion model. The feature vectors generated by the image encoders of the three modalities are fed into the recursive layer to extract temporal information. To capture the importance degrees of the effects of temporal features from the three modalities on drowsiness detection, an attention mechanism is introduced to automatically weigh the feature vectors from the recursive layer to improve detection accuracy. Finally, a vector representation is generated by the attention layer and is used to detect driver drowsiness states. Experimental results based on two challenging datasets show that our method outperforms the baseline methods and the latest existing methods.
C1 [Mou, Luntian; Zhou, Chao; Zhao, Pengfei; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing Inst Artificial Intelligence, Beijing 100124, Peoples R China.
   [Xie, Pengtao] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Jain, Ramesh] Univ Calif Irvine, Inst Future Hlth, Bren Sch Informat & Comp Sci, Irvine, CA 92697 USA.
   [Gao, Wen] Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
   [Gao, Wen] Peking Univ, Shenzhen Grad Sch, Sch Elect & Comp Engn, Shenzhen 518055, Peoples R China.
C3 Beijing University of Technology; University of California System;
   University of California San Diego; University of California System;
   University of California Irvine; Peking University; Peking University
RP Yin, BC (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing Inst Artificial Intelligence, Beijing 100124, Peoples R China.
EM ltmou@pku.edu.cn; zhouc@emails.bjut.edu.cn; p1xie@ucsd.edu;
   ffly@emails.bjut.edu.cn; jain@ics.uci.edu; wgao@pku.edu.cn;
   ybc@bjut.edu.cn
RI ; Mou, Luntian/ACX-6553-2022
OI Jain, Ramesh/0000-0003-2373-4966; Mou, Luntian/0000-0002-1551-4448
FU National Natural Science Foundation of China [61672068]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61672068.
CR Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   [Anonymous], 2018, FACTS STATS
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], 2017, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-54526-4_10
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Carneiro D, 2017, NEUROCOMPUTING, V231, P41, DOI 10.1016/j.neucom.2016.05.105
   Caron M, 2019, IEEE I CONF COMP VIS, P2959, DOI 10.1109/ICCV.2019.00305
   Chen T, 2020, PR MACH LEARN RES, V119
   Chiou CY, 2020, IEEE T INTELL TRANSP, V21, P346, DOI 10.1109/TITS.2019.2892155
   Cho K., 2014, ARXIV14061078
   Choi IH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050137
   Costa R., 2017, Proceedings of International Conference on Neural Information Processing Systems (NIPS), P271
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dua M, 2021, NEURAL COMPUT APPL, V33, P3155, DOI 10.1007/s00521-020-05209-7
   Dwivedi K, 2014, IEEE INT ADV COMPUT, P995, DOI 10.1109/IAdCC.2014.6779459
   Fusek R, 2018, LECT NOTES COMPUT SC, V11241, P433, DOI 10.1007/978-3-030-03801-4_38
   Ghoddoosian R, 2019, IEEE COMPUT SOC CONF, P178, DOI 10.1109/CVPRW.2019.00027
   Ghourabi A, 2020, INT C INTELL COMP CO, P407, DOI [10.1109/iccp51029.2020.9266160, 10.1109/ICCP51029.2020.9266160]
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ji QA, 2006, IEEE T SYST MAN CY A, V36, P862, DOI 10.1109/TSMCA.2005.855922
   Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kang HB, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P616, DOI 10.1109/ICCVW.2013.85
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kwasigroch A., 2020, ELECTRONICS-SWITZ, V9, P1
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Li NX, 2013, IEEE T MULTIMEDIA, V15, P1213, DOI 10.1109/TMM.2013.2241416
   Li Q., 2019, J ALLOY COMPD, V40, P41
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mandal B, 2017, IEEE T INTELL TRANSP, V18, P545, DOI 10.1109/TITS.2016.2582900
   Mou LT, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114693
   Ngxande M, 2017, 2017 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS (PRASA-ROBMECH), P156, DOI 10.1109/RoboMech.2017.8261140
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Savas BK, 2020, IEEE ACCESS, V8, P12491, DOI 10.1109/ACCESS.2020.2963960
   Sikander G, 2019, IEEE T INTELL TRANSP, V20, P2339, DOI 10.1109/TITS.2018.2868499
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Song KT, 2019, PR MACH LEARN RES, V97
   Vu TH, 2019, IEICE T INF SYST, VE102D, P2637, DOI 10.1587/transinf.2019EDL8079
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xie YQ, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P532, DOI 10.1109/SSCI.2018.8628881
   Yang H, 2021, IEEE T MULTIMEDIA, V23, P572, DOI 10.1109/TMM.2020.2985536
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yuan L, 2020, IEEE T MULTIMEDIA, V22, P2711, DOI 10.1109/TMM.2019.2959451
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang C, 2019, IEEE ACCESS, V7, P11829, DOI 10.1109/ACCESS.2019.2891971
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang W, 2015, IEEE IJCNN
   Zhao L, 2020, MULTIMED TOOLS APPL, V79, P26683, DOI 10.1007/s11042-020-09259-w
   Zhao L, 2018, IET INTELL TRANSP SY, V12, P127, DOI 10.1049/iet-its.2017.0183
   Zhao N, 2017, IEEE T MULTIMEDIA, V19, P2080, DOI 10.1109/TMM.2017.2722687
   Zhou P, 2019, INT CONF ACOUST SPEE, P6565, DOI 10.1109/ICASSP.2019.8683733
   Zhuang CX, 2019, IEEE I CONF COMP VIS, P6001, DOI 10.1109/ICCV.2019.00610
NR 65
TC 10
Z9 10
U1 9
U2 37
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 529
EP 542
DI 10.1109/TMM.2021.3128738
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 9B8PL
UT WOS:000934993800015
DA 2024-07-18
ER

PT J
AU Qiu, Y
   Liu, Y
   Chen, YA
   Zhang, JW
   Zhu, JC
   Xu, J
AF Qiu, Yu
   Liu, Yun
   Chen, Yanan
   Zhang, Jianwen
   Zhu, Jinchao
   Xu, Jing
TI A2SPPNet: Attentive Atrous Spatial Pyramid Pooling Network for Salient
   Object Detection
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Salient object detection; saliency detection; ASPP; A2SPP; attention
   mechanism
ID IMAGE; MODEL; REPRESENTATION; FEATURES; DRIVEN
AB Recent progress in salient object detection (SOD) mainly depends on the Atrous Spatial Pyramid Pooling (ASPP) module for multi-scale learning. Intuitively, different input images, different pixels, and different network layers may have different preferences for various feature scales. However, ASPP treats all feature scales as equally important by a simple sum operation. To this end, we propose Attentive Atrous Spatial Pyramid Pooling (A2SPP) by adding a new Cubic Information-Embedding Attention (CIEA) module at each branch of ASPP. In this way, each position in the 3D feature map can automatically learn the feature scales it prefers. Specifically, CIEA consists of Spatial-Embedding Channel Attention (SECA) and Channel-Embedding Spatial Attention (CESA). Instead of the previous direct squeeze and ignoring of one dimension when computing the attention for the other dimension, SECA/CESA attempts to embed spatial/channel information into channel/spatial attention, respectively. In addition, CIEA learns SECA and CESA for each 3D position simultaneously rather than previous separate computation of channel and spatial attention for each 2D position. Incorporating A2SPP and CIEA, the proposed A2SPPNet performs favorably against previous state-of-the-art SOD methods.
C1 [Qiu, Yu; Chen, Yanan; Zhang, Jianwen; Zhu, Jinchao; Xu, Jing] Nankai Univ, Coll Artificial Intelligence, Tianjin 300350, Peoples R China.
   [Liu, Yun] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland.
C3 Nankai University; Swiss Federal Institutes of Technology Domain; ETH
   Zurich
RP Xu, J (corresponding author), Nankai Univ, Coll Artificial Intelligence, Tianjin 300350, Peoples R China.; Liu, Y (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland.
EM yqiu@mail.nankai.edu.cn; yun.liu@vision.ee.ethz.ch; cynh_e@126.com;
   219609@supinfo.com; jczhu@mail.nankai.edu.cn; xujing@nankai.edu.cn
RI LI, LIXIN/KFS-0074-2024; ZHANG, JIANWEN/JMQ-9363-2023
OI Qiu, Yu/0000-0001-6722-3039; Zhu, Jinchao/0000-0003-2821-4847; Liu,
   Yun/0000-0001-6143-0264
FU Tianjin Research Innovation Project [2020YJSZXB04]
FX This work was supported by the Tianjin Research Innovation Project for
   Postgraduate Students under Grant 2020YJSZXB04. The Associate Editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Ramazan S Aygun.
CR [Anonymous], 2006, P CVPR
   [Anonymous], 2016, INT C LEARNING REPRE
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen L, 2015, 2ND INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY FOR EDUCATION (ICTE 2015), P1
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen XW, 2017, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2017.119
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017
   Fu KR, 2019, IEEE T MULTIMEDIA, V21, P457, DOI 10.1109/TMM.2018.2859746
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Goferman S, 2010, COMPUT GRAPH FORUM, V29, P459, DOI 10.1111/j.1467-8659.2009.01615.x
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang H., 2011, PROC ACM SIGGRAPH C, P1
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Islam MA, 2018, PROC CVPR IEEE, P7142, DOI 10.1109/CVPR.2018.00746
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li JX, 2021, IEEE T MULTIMEDIA, V23, P1397, DOI 10.1109/TMM.2020.2997192
   Li L, 2013, IEEE MULTIMEDIA, V20, P13, DOI 10.1109/MMUL.2013.15
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Liu Y, 2019, IEEE I CONF COMP VIS, P1232, DOI 10.1109/ICCV.2019.00132
   Liu Y, 2020, IEEE T IMAGE PROCESS, V29, P360, DOI 10.1109/TIP.2019.2930906
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P1415, DOI 10.1109/TPAMI.2020.3023152
   Liu Y, 2022, INT J COMPUT VISION, V130, P179, DOI 10.1007/s11263-021-01539-8
   Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P3804, DOI 10.1109/TIP.2021.3065239
   Liu Y, 2022, IEEE T CYBERNETICS, V52, P6131, DOI 10.1109/TCYB.2021.3051350
   Liu Y, 2021, IEEE T CYBERNETICS, V51, P4439, DOI 10.1109/TCYB.2020.3035613
   Liu Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P864
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Ma GX, 2020, IEEE T MULTIMEDIA, V22, P324, DOI 10.1109/TMM.2019.2929943
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Meger D, 2008, ROBOT AUTON SYST, V56, P503, DOI 10.1016/j.robot.2008.03.008
   Nawaz M, 2021, IEEE T MULTIMEDIA, V23, P2902, DOI 10.1109/TMM.2020.3019688
   Park J., 2018, PROC BRIT MACH VIS C
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qiu Y, 2021, AAAI CONF ARTIF INTE, V35, P4846
   Qiu Y, 2019, IEEE IMAGE PROC, P4010, DOI [10.1109/icip.2019.8803646, 10.1109/ICIP.2019.8803646]
   Ren QH, 2021, IEEE T MULTIMEDIA, V23, P1442, DOI 10.1109/TMM.2020.2997178
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984
   Sun JD, 2013, IEEE T BROADCAST, V59, P602, DOI 10.1109/TBC.2013.2272172
   Tang YB, 2019, IEEE T MULTIMEDIA, V21, P2237, DOI 10.1109/TMM.2019.2900908
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3897, DOI 10.1109/TIP.2021.3065822
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xu BW, 2021, AAAI CONF ARTIF INTE, V35, P3004
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu YY, 2019, IEEE I CONF COMP VIS, P3788, DOI 10.1109/ICCV.2019.00389
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733
   Zeng Y, 2018, PROC CVPR IEEE, P1644, DOI 10.1109/CVPR.2018.00177
   Zhang D., 2020, NIPS, p12 236
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang Q, 2019, PATTERN RECOGN, V92, P119, DOI 10.1016/j.patcog.2019.03.023
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 110
TC 14
Z9 14
U1 16
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 1991
EP 2006
DI 10.1109/TMM.2022.3141933
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA J1QV6
UT WOS:001007432100032
DA 2024-07-18
ER

PT J
AU Qiu, YK
   Hong, FT
   Li, WH
   Zheng, WS
AF Qiu, Yu-Kun
   Hong, Fa-Ting
   Li, Wei-Hong
   Zheng, Wei-Shi
TI Learning Relation Models to Detect Important People in Still Images
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Visualization; Feature extraction; Predictive models; Task analysis;
   Faces; Data models; Graph neural networks; Important People Detection
ID NETWORK
AB Important people detection aims to identify the most important people (i.e., the people who play the main roles in scenes) in images, which is challenging since people's importance in images depends not only on their appearance but also on their interactions with others (i.e., relations among people) and their roles in the scene (i.e., relations between people and underlying events). In this work, we propose the People Relation Network (PRN) to solve this problem. PRN consists of three modules (i.e., the feature representation, relation and classification modules) to extract visual features, model relations and estimate people's importance, respectively. The relation module contains two submodules to model two types of relations, namely, the person-person relation submodule and the person-event relation submodule. The person-person relation submodule infers the relations among people from the interaction graph and the person-event relation submodule models the relations between people and events by considering the spatial correspondence between features. With the help of them, PRN can effectively distinguish important people fromother individuals. Extensive experiments on the Multi-Scene Important People (MS) and NCAA Basketball Image (NCAA) datasets show that PRN achieves state-of-the-art performance and generalizes well when available data is limited.
C1 [Qiu, Yu-Kun; Hong, Fa-Ting; Li, Wei-Hong; Zheng, Wei-Shi] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Zheng, Wei-Shi] Pengcheng Lab, Shenzhen, Peoples R China.
   [Zheng, Wei-Shi] Minist Educ, Key Lab Machine Intelligence & Adv Comp, Beijing, Peoples R China.
C3 Sun Yat Sen University
RP Zheng, WS (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM qiuyk@mail2.sysu.edu.cn; hongft3@mail2.sysu.edu.cn; w.h.li@ed.ac.uk;
   wszheng@ieee.org
OI Qiu, Yu-Kun/0000-0001-9490-5502; Hong, Fating/0000-0003-0108-8596; Li,
   Wei-Hong/0000-0003-4942-822X
FU NSFC [U21A20471, U1911401, U1811461]; Guangdong NSF [2020B1515120085,
   2018B030312002]; Guangzhou Research Project [201902010037]; Key-Area
   Research and Development Program of Guangzhou [202007030004]
FX This work was supported in part by the NSFC under Grants U21A20471,
   U1911401, and U1811461, in part by the Guangdong NSF under Projects
   2020B1515120085 and 2018B030312002, in part by the Guangzhou Research
   Project under Grant 201902010037, and in part by the Key-Area Research
   and Development Program of Guangzhou under Grant 202007030004. The
   Associate Editor coordinating the review of this manuscript and
   approving it for publication was Prof. Lamberto Ballan.
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122
   Cheng YH, 2020, AAAI CONF ARTIF INTE, V34, P10623
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong FT, 2020, PROC CVPR IEEE, P4145, DOI 10.1109/CVPR42600.2020.00420
   Inayoshi Sho, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P682, DOI 10.1007/978-3-030-58558-7_40
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kipf TN, 2017, INT C LEARN REPR
   Lee JB, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1666, DOI 10.1145/3219819.3219980
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Li WH, 2018, IEEE INT CONF AUTOMA, P234, DOI 10.1109/FG.2018.00042
   Liu AA, 2021, IEEE T MULTIMEDIA, V23, P4515, DOI 10.1109/TMM.2020.3043084
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Mathialagan CS, 2015, PROC CVPR IEEE, P4858, DOI 10.1109/CVPR.2015.7299119
   Kipf TN, 2016, Arxiv, DOI [arXiv:1611.07308, DOI 10.48550/ARXIV.1611.07308]
   Ramanathan V, 2016, PROC CVPR IEEE, P3043, DOI 10.1109/CVPR.2016.332
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Tajrobehkar M, 2022, IEEE T MULTIMEDIA, V24, P1266, DOI 10.1109/TMM.2021.3062543
   Tamura M, 2021, PROC CVPR IEEE, P10405, DOI 10.1109/CVPR46437.2021.01027
   Tan JH, 2019, IEEE T MULTIMEDIA, V21, P2686, DOI 10.1109/TMM.2019.2904878
   Tang Y., 2017, P IEEE INT C ADV VID, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic Petar, 2018, INT C LEARN REPR
   Wang TC, 2020, PROC CVPR IEEE, P4115, DOI 10.1109/CVPR42600.2020.00417
   Wang X, 2021, AAAI CONF ARTIF INTE, V35, P2809
   Wu J, 2021, IEEE T MULTIMEDIA, V23, P2413, DOI 10.1109/TMM.2020.3011317
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu BJ, 2019, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2019.00212
   Xu BJ, 2020, IEEE T MULTIMEDIA, V22, P1423, DOI 10.1109/TMM.2019.2943753
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Yu Y, 2020, PROC CVPR IEEE, P7312, DOI 10.1109/CVPR42600.2020.00734
   Zhan YB, 2019, PROC CVPR IEEE, P5123, DOI 10.1109/CVPR.2019.00527
   Zhang JN, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P339
   Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103
NR 40
TC 0
Z9 0
U1 1
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 6601
EP 6615
DI 10.1109/TMM.2022.3211390
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA X5KG5
UT WOS:001098831500069
DA 2024-07-18
ER

PT J
AU Song, XM
   Fang, ST
   Chen, XL
   Wei, YW
   Zhao, ZZ
   Nie, LQ
AF Song, Xuemeng
   Fang, Shi-Ting
   Chen, Xiaolin
   Wei, Yinwei
   Zhao, Zhongzhou
   Nie, Liqiang
TI Modality-Oriented Graph Learning Toward Outfit Compatibility Modeling
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Visualization; Feature extraction; Estimation; Predictive models;
   Footwear; Task analysis; Shape; Graph convolutional network; multi-modal
   recommendation; outfit compatibility modeling
AB Outfit compatibility modeling, which aims to automatically evaluate the matching degree of an outfit, has drawn great research attention. Regarding the comprehensive evaluation, several previous studies have attempted to solve the task of outfit compatibility modeling by integrating the multi-modal information of fashion items. However, these methods primarily focus on fusing the visual and textual modalities, but seldom consider the category modality as an essential modality. In addition, they mainly focus on the exploration of the intra-modal compatibility relation among fashion items in an outfit but ignore the importance of the inter-modal compatibility relation, i.e., the compatibility across different modalities between fashion items. Since each modality of the item could deliver the same characteristics of the item as other modalities, as well as certain exclusive features of the item, overlooking the inter-modal compatibility could yield sub-optimal performance. To address these issues, a multi-modal outfit compatibility modeling scheme with modality-oriented graph learning is proposed, dubbed as MOCM-MGL, which takes both the visual, textual, and category modalities as input and jointly propagates the intra-modal and inter-modal compatibilities among fashion items. Experimental results on the real-world Polyvore Outfits-ND and Polyvore Outfits-D datasets have demonstrated the superiority of our proposed model over existing methods.
C1 [Song, Xuemeng; Fang, Shi-Ting; Nie, Liqiang] Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Shandong, Peoples R China.
   [Chen, Xiaolin] Shandong Univ, Sch Software, Jinan 250100, Shandong, Peoples R China.
   [Wei, Yinwei] Natl Univ Singapore, Sch Comp, Singapore 11840, Singapore.
   [Zhao, Zhongzhou] DAMO Acad, Alibaba Grp, Hangzhou 311121, Zhejiang, Peoples R China.
C3 Shandong University; Shandong University; National University of
   Singapore; Alibaba Group
RP Nie, LQ (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Shandong, Peoples R China.
EM sxmustc@gmail.com; fangshiting@mail.sdu.edu.cn; cxlicd@gmail.com;
   weiyinwei@hotmail.com; zhongzhou.zhaozz@alibaba-inc.com;
   nieliqiang@gmail.com
RI Wei, Yinwei/JHX-9398-2023
OI Wei, Yinwei/0000-0003-1791-3159; Chen, Xiaolin/0000-0003-4638-0603
FU Shandong Provincial Natural Science Foundation [ZR2019JQ23]; Key
   Research and Development Program of Shandong [2020CXGC010111]; National
   Natural Science Foundation of China [U1936203]; Young Creative Team in
   Universities of Shandong Province [2020KJN012]
FX This work was supported in part by the Shandong Provincial Natural
   Science Foundation under Grant ZR2019JQ23, in part by the Key Research
   and Development Program of Shandong (Major scientific and technological
   innovation projects) under Grant 2020CXGC010111, in part by the National
   Natural Science Foundation of China under Grant U1936203, in part by the
   Young Creative Team in Universities of Shandong Province under Grant
   2020KJN012, and in part by Alibaba Group through Alibaba Innovative
   Research Program.
CR Chaidaroon S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1229, DOI 10.1145/3331184.3331365
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen W, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2662, DOI 10.1145/3292500.3330652
   Cucurull G, 2019, PROC CVPR IEEE, P12609, DOI 10.1109/CVPR.2019.01290
   Cui ZY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P307, DOI 10.1145/3308558.3313444
   Dong X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P771, DOI 10.1145/3397271.3401047
   Dong X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P302, DOI 10.1145/3343031.3350905
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Gori M, 2005, IEEE IJCNN, P729
   Gu XL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P190, DOI 10.1145/3123266.3123441
   Guo B, 2019, NEUROCOMPUTING, V363, P366, DOI 10.1016/j.neucom.2019.07.052
   Guo S, 2019, IEEE INT CONF COMP V, P3113, DOI 10.1109/ICCVW.2019.00377
   Hamilton WL, 2017, ADV NEUR IN, V30
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Inoue N, 2017, IEEE INT CONF COMP V, P2261, DOI 10.1109/ICCVW.2017.265
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D. P., 2014, arXiv
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Kollias D, 2021, IEEE T AFFECT COMPUT, V12, P595, DOI 10.1109/TAFFC.2020.3014171
   Laenen K, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102316
   Li XC, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P159, DOI 10.1145/3397271.3401080
   Li Y., 2016, ICLR, P1, DOI DOI 10.48550/ARXIV.1511.05493
   Li YC, 2017, IEEE T MULTIMEDIA, V19, P1946, DOI 10.1109/TMM.2017.2690144
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Lin YL, 2020, PROC CVPR IEEE, P3308, DOI 10.1109/CVPR42600.2020.00337
   Liu F, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1296, DOI 10.1145/3442381.3449986
   Liu JW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P665, DOI 10.1145/3343031.3350991
   Liu JH, 2019, NEUROCOMPUTING, V359, P249, DOI 10.1016/j.neucom.2019.05.081
   Liu X, 2021, IEEE T MULTIMEDIA, V23, P2894, DOI 10.1109/TMM.2020.3018021
   Lu X, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1414, DOI 10.1145/3474085.3475598
   Lu X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P715, DOI 10.1145/3331184.3331217
   Lu Z, 2019, PROC CVPR IEEE, P10554, DOI 10.1109/CVPR.2019.01081
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Song XM, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P320, DOI 10.1145/3343031.3350956
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Sun GL, 2020, NEUROCOMPUTING, V395, P237, DOI 10.1016/j.neucom.2018.06.098
   Tan R., 2019, P IEEE CVF INT C COM, p10 372
   Tangseng P., 2017, P IEEE WINT C APPL C, P268
   Vasileva MI, 2018, LECT NOTES COMPUT SC, V11220, P405, DOI 10.1007/978-3-030-01270-0_24
   Wang X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P329, DOI 10.1145/3343031.3350909
   Wei YW, 2022, IEEE T MULTIMEDIA, V24, P2701, DOI 10.1109/TMM.2021.3088307
   Wei YW, 2020, IEEE T IMAGE PROCESS, V29, P1, DOI 10.1109/TIP.2019.2923608
   Wen HK, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1369, DOI 10.1145/3404835.3462967
   Wu JX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P827, DOI 10.1145/3343031.3350938
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yang X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P941, DOI 10.1145/3397271.3401150
   Yang X, 2019, AAAI CONF ARTIF INTE, P403
   Ye FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P55, DOI 10.1145/3394171.3413941
   Zhang J, 2017, IEEE T MULTIMEDIA, V19, P2439, DOI 10.1109/TMM.2017.2701641
   Zhang ZW, 2021, IEEE T MULTIMEDIA, V23, P1799, DOI 10.1109/TMM.2020.3003592
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
   Zhu L, 2020, IEEE T IMAGE PROCESS, V29, P4643, DOI 10.1109/TIP.2020.2974065
NR 53
TC 6
Z9 6
U1 3
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 856
EP 867
DI 10.1109/TMM.2021.3134164
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA C4YC5
UT WOS:000961977900014
DA 2024-07-18
ER

PT J
AU Sun, MJ
   Xiao, JM
   Lim, EG
   Zhao, Y
AF Sun, Mingjie
   Xiao, Jimin
   Lim, Eng Gee
   Zhao, Yao
TI Cycle-Free Weakly Referring Expression Grounding With Self-Paced
   Learning
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Task analysis; Training; Pipelines; Linguistics; Visualization;
   Optimization; Image reconstruction; Referring expression grounding;
   weakly supervised learning; self-paced learning
AB In this paper, we are tackling the weakly referring expression grounding task to localize the target object in an image according to a given query sentence, where the mapping between the query sentence and image regions is blind during the training period. Previous methods all follow a cyclic forward-backward pipeline to handle this task, where the query sentence is firstly converted to the result region through the forward module, and then the result region is converted back to a sentence through the backward module, with the difference between the reconstructed sentence and original query used as the loss to optimize the entire network. These existing methods, however, suffer from the deviation issue when the result region, generated through the forward module, totally deviates from the target area, but the backward module still reconstructs a similar sentence. The aforementioned loss function cannot penalize this kind of deviation because of the consistent prediction of the sentence. To overcome this limitation, we propose a cycle-free pipeline, where a region describer network is designed to predict the textual description for each candidate region, and a result region is selected according to the similarity between the predicted description and the query sentence. Furthermore, a self-paced learning mechanism is designed to avoid the drift issue during the warm-up period of the optimization process. The proposed method achieves a higher average accuracy on RefCOCO and RefCOCO+ datasets, compared with all previous state-of-the-art methods.
C1 [Sun, Mingjie; Xiao, Jimin; Lim, Eng Gee] Univ Liverpool, Liverpool, England.
   [Sun, Mingjie; Xiao, Jimin; Lim, Eng Gee] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215123, Peoples R China.
   [Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 University of Liverpool; Xi'an Jiaotong-Liverpool University; Beijing
   Jiaotong University
RP Xiao, JM (corresponding author), Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215123, Peoples R China.
EM trap94@126.com; jimin.xiao@xjtlu.edu.cn; enggee.lim@xjtlu.edu.cn;
   yzhao@bjtu.edu.cn
RI lim, eng GEE/JMC-6208-2023
OI lim, eng GEE/0000-0003-0199-7386; SUN, MINGJIE/0000-0002-3697-7927;
   Zhao, Yao/0000-0002-8581-9554
FU National Key Research and Development of China [2018AAA0102100];
   National Natural Science Foundation of China [61972323, 62120106009];
   KSF fund in XJTLU [KSF-T-02, KSF-P-02]
FX This work was supported in part by the National Key Research and
   Development of China under Grant 2018AAA0102100, in part by the National
   Natural Science Foundation of China under Grants 61972323 and
   62120106009, and in part by the KSF fund in XJTLU under Grants KSF-T-02
   and KSF-P-02.
CR Bansal Ankan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P51, DOI 10.1007/978-3-030-58589-1_4
   Chen D., 2014, P 2014 C EMPIRICAL M, P740, DOI DOI 10.3115/V1/D14-1082
   Chen FH, 2018, IEEE T MULTIMEDIA, V20, P997, DOI 10.1109/TMM.2017.2757769
   Chen K, 2018, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2018.00425
   Chen Z., 2021, PROC INT C LEARN REP, P1
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Gan C, 2017, IEEE I CONF COMP VIS, P1829, DOI 10.1109/ICCV.2017.201
   Han LF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1816
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P18, DOI 10.1007/978-3-030-58586-0_2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Honnibal M., 2017, IN PRESS, DOI DOI 10.3233/978-1-60750-588-4-1080
   Hu YT, 2018, IEEE T MULTIMEDIA, V20, P927, DOI 10.1109/TMM.2017.2760101
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Jiang H., 2020, IEEE CVF C COMP VIS, DOI 10.1109/CVPR42600.2020.01028
   Junyeong Kim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10103, DOI 10.1109/CVPR42600.2020.01012
   Kazemzadeh S., 2014, EMNLP, P787, DOI DOI 10.3115/V1/D14-1086
   Kingma D. P., 2014, arXiv
   Li H, 2022, IEEE T CIRC SYST VID, V32, P1624, DOI 10.1109/TCSVT.2021.3073718
   Li H, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107614
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Liao Y., 2020, P IEEE CVF C COMP VI, P10877, DOI 10.24963/ijcai.2018/155
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C, 2020, P IEEECVF C COMPUTER, p10 918
   Liu XH, 2019, PROC CVPR IEEE, P1950, DOI 10.1109/CVPR.2019.00205
   Liu XJ, 2019, IEEE I CONF COMP VIS, P2611, DOI 10.1109/ICCV.2019.00270
   Liu XJ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P539, DOI 10.1145/3343031.3351074
   Long Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10797, DOI 10.1109/CVPR42600.2020.01081
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Mao J., 2019, INT C LEARN REPRESEN, P1
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mingjie Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10788, DOI 10.1109/CVPR42600.2020.01080
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren S., 2015, ADV NEURAL INFORM PR, V28, P91
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Ruixue Tang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P437, DOI 10.1007/978-3-030-58529-7_26
   Sammani F, 2020, PROC CVPR IEEE, P4807, DOI 10.1109/CVPR42600.2020.00486
   Sangineto E, 2019, IEEE T PATTERN ANAL, V41, P712, DOI 10.1109/TPAMI.2018.2804907
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Sun MJ, 2021, PROC CVPR IEEE, P14055, DOI 10.1109/CVPR46437.2021.01384
   Sun MJ, 2021, IEEE T PATTERN ANAL, V43, P4189, DOI 10.1109/TPAMI.2021.3058684
   Tang YX, 2017, IEEE T MULTIMEDIA, V19, P393, DOI 10.1109/TMM.2016.2614862
   Thao Minh Le, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9969, DOI 10.1109/CVPR42600.2020.00999
   Tianlang Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P549, DOI 10.1007/978-3-030-58601-0_33
   Tran Alasdair, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13032, DOI 10.1109/CVPR42600.2020.01305
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang X., 2020, P IEEE CVF C COMP VI, P10126
   Yang ZY, 2019, IEEE I CONF COMP VIS, P4682, DOI 10.1109/ICCV.2019.00478
   Yi KX, 2018, ADV NEUR IN, V31
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zhang BF, 2020, AAAI CONF ARTIF INTE, V34, P12765
   Zhang D., 2021, P ADV NEUR INF PROC, P1
   Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4
   Zhang DW, 2017, PROC CVPR IEEE, P5340, DOI 10.1109/CVPR.2017.567
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zhang SW, 2020, IEEE T MULTIMEDIA, V22, P2610, DOI 10.1109/TMM.2019.2959425
   Zhang TY, 2019, IEEE T MULTIMEDIA, V21, P2930, DOI 10.1109/TMM.2019.2914870
   Zhou YAN, 2020, PROC CVPR IEEE, P4776, DOI 10.1109/CVPR42600.2020.00483
NR 64
TC 10
Z9 10
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 1611
EP 1621
DI 10.1109/TMM.2021.3139467
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA J1QV6
UT WOS:001007432100002
DA 2024-07-18
ER

PT J
AU Tang, ZH
   Li, J
   Hao, YB
   Hong, RC
AF Tang, Zhenhua
   Li, Jia
   Hao, Yanbin
   Hong, Richang
TI MLP-JCG: Multi-Layer Perceptron With Joint-Coordinate Gating for
   Efficient 3D Human Pose Estimation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Three-dimensional displays; Pose estimation; Solid modeling; Task
   analysis; Logic gates; Computational modeling; Transformers; 3D human
   pose estimation; multi-layer perceptron; self-gating unit; selective
   gating unit
ID NETWORK; FUSION
AB Various structural relations/dependencies exist among human body joints, which makes it possible to estimate 3D poses from 2D sources. The current research on 3D human pose estimation (3D-HPE for short) mainly focuses on structural information from a specific perspective. However, this information cannot facilitate 2D-to-3D pose lifting. This paper presents a novel and efficient multi-layer perceptron with a joint-coordinate gating (MLP-JCG) model, exploring and utilizing both the local and global structural information to perform 3D pose estimations. Specifically, MLP-JCG contains two independent MLP blocks, i.e., joint-mixing MLP and coordinate-mixing MLP, which solely act on the joint and coordinate axes in modelling their local structural information. For the global structural information, we first explore two kinds of global statistics from the pose matrix embeddings, which are referred to as the dynamics aggregated along the joint/coordinate axis. Then, we propose two kinds of gating units to elementwisely contextualize the features learned from MLP blocks. All the model components are designed based on MLP, making the MLP-JCG easy to implement and train. We conduct experiments on three 3D-HPE benchmarks, and the results demonstrate the superior effectiveness and efficiency of the proposed approach.
C1 [Tang, Zhenhua; Li, Jia; Hong, Richang] Hefei Univ Technol, Sch Comp & Informat, Hefei 188065, Peoples R China.
   [Hao, Yanbin] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; University
   of Science & Technology of China, CAS
RP Li, J; Hong, RC (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 188065, Peoples R China.
EM zhenhuat@foxmail.com; jiali@hfut.edu.cn; haoyanbin@hotmail.com;
   hongrc.hfut@gmail.com
RI Hao, Yanbin/AAC-8050-2019
OI Hao, Yanbin/0000-0002-0695-1566
FU National Natural Science Foundation of China
FX No Statement Available
CR Ailing Zeng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P507, DOI 10.1007/978-3-030-58568-6_30
   Biggs Benjamin, 2020, Advances in Neural Information Processing Systems, V33, P20496
   Chen S, 2022, KNOWL-BASED SYST, V255, DOI 10.1016/j.knosys.2022.109691
   Chen TL, 2022, IEEE T CIRC SYST VID, V32, P198, DOI 10.1109/TCSVT.2021.3057267
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Ci H, 2022, IEEE T PATTERN ANAL, V44, P1429, DOI 10.1109/TPAMI.2020.3019139
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   Ding X., 2021, arXiv
   Fan ZX, 2019, IEEE T MULTIMEDIA, V21, P363, DOI 10.1109/TMM.2018.2859620
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Gong KH, 2021, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR46437.2021.00847
   Hao YB, 2022, IEEE T CIRC SYST VID, V32, P7120, DOI 10.1109/TCSVT.2022.3169842
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang MX, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108965
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Katona J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062646
   Kenkun Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P318, DOI 10.1007/978-3-030-58607-2_19
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li MP, 2019, IEEE T MULTIMEDIA, V21, P2653, DOI 10.1109/TMM.2019.2903455
   Li SC, 2020, PROC CVPR IEEE, P6172, DOI 10.1109/CVPR42600.2020.00621
   Li WH, 2022, Arxiv, DOI arXiv:2103.14304
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Liu Hanxiao, 2021, ADV NEURAL INFORM PR, V34, P9204, DOI DOI 10.48550/ARXIV.2105.08050
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Liu SY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P782
   Liu ZG, 2023, IEEE T PATTERN ANAL, V45, P681, DOI 10.1109/TPAMI.2021.3139918
   Liu ZG, 2021, PROC CVPR IEEE, P525, DOI 10.1109/CVPR46437.2021.00059
   Liu ZG, 2021, AAAI CONF ARTIF INTE, V35, P2225
   Liu Zhenguang, 2022, arXiv
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Park J., 2018, P BRIT MACH VIS C
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Sharma S, 2019, IEEE I CONF COMP VIS, P2325, DOI 10.1109/ICCV.2019.00241
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tang Z., 2019, P AS C MACH LEARN, P48
   Tolstikhin O., 2021, P ADV NEAAL INF PROC, P24261
   Touvron H., 2021, IEEE T PATTERN ANAL
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Zhicai, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P6288, DOI 10.1145/3503161.3547953
   Wehrbein T., 2021, ICCV, P11199
   Wen YH, 2016, Arxiv, DOI arXiv:1607.00450
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HP, 2020, AAAI CONF ARTIF INTE, V34, P12378
   Wu YP, 2022, NEUROCOMPUTING, V487, P243, DOI 10.1016/j.neucom.2021.11.007
   Xia HL, 2020, IEEE ACCESS, V8, P206198, DOI 10.1109/ACCESS.2020.3037829
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Xu YL, 2022, IEEE T PATTERN ANAL, V44, P6327, DOI 10.1109/TPAMI.2021.3087695
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P2701, DOI 10.1109/TMM.2019.2912121
   Zhang H, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P5773, DOI 10.1145/3503161.3547908
   Zhang H, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P917, DOI 10.1145/3474085.3475272
   Zhang L, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.4.040502
   Zhang XY, 2019, PATTERN RECOGN LETT, V125, P404, DOI 10.1016/j.patrec.2019.05.020
   Zhang XY, 2022, IEEE T MULTIMEDIA, V24, P166, DOI 10.1109/TMM.2020.3047552
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhou S., 2020, P AS C COMP VIZ, P136
   Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097
   Zhou XW, 2015, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2015.7299074
   Zou L, 2021, COMPUT GRAPH-UK, V95, P115, DOI 10.1016/j.cag.2021.01.010
NR 69
TC 2
Z9 2
U1 6
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 8712
EP 8724
DI 10.1109/TMM.2023.3240455
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CN3Z4
UT WOS:001125902000030
DA 2024-07-18
ER

PT J
AU Wang, C
   Ma, BP
   Chang, H
   Shan, SG
   Chen, XL
AF Wang, Cheng
   Ma, Bingpeng
   Chang, Hong
   Shan, Shiguang
   Chen, Xilin
TI Person Search by a Bi-Directional Task-Consistent Learning Model
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Task analysis; Detectors; Training; Robustness; Proposals; Feature
   extraction; Cameras; Deep neural networks; Person search
ID NETWORK; REIDENTIFICATION
AB Two-stage person search methods achieve the state-of-the-art performance by separate detection and re-ID stages, but neglect the consistency needs between these two stages. The re-ID stage needs more accurate query bounding boxes and fewer boxes of distractors; The detection stage needs the re-ID stage to have robustness against unavailable detection errors. In this paper, we introduce a novel Bi-directional Task-Consistent Learning (BTCL) person search framework, including a Target-Specific Detector (TSD) and a re-ID model with Dynamic Adaptive Learning Structure (DALS). For the former consistency need, we add a verification head for predicting the similarity scores between query and proposals in parallel with the existing heads for bounding box recognition. Thus, TSD generates accurate boxes for the query-like pedestrians, which are suitable for the re-ID stage. For the re-ID robustness need, DALS dynamically generates a large number of possible detection results in line with the real distribution. By training the re-ID model on data with different types of detection errors, DLAS improves the model robustness to detection inputs. Experimental results show our framework achieves state-of-the-art performance on two widely-used person search datasets.
C1 [Wang, Cheng; Ma, Bingpeng] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China.
   [Chang, Hong; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, CAS, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Chang, Hong; Shan, Shiguang; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Shan, Shiguang] CAS Ctr Excellence Brain Sci & Intelligence Techno, Shanghai 200031, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS
RP Ma, BP (corresponding author), Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China.
EM wangcheng18@mails.ucas.ac.cn; bpma@ucas.ac.cn; changhong@ict.ac.cn;
   sgshan@ict.ac.cn; xlchen@ict.ac.cn
RI ; Chen, Xilin/I-4153-2014
OI Shan, Shiguang/0000-0002-8348-392X; wang, cheng/0000-0002-6506-1221;
   Chen, Xilin/0000-0003-3024-4404
FU Natural Science Foundation of China (NSFC) [61876171, 61976203]
FX This work was supported by the Natural Science Foundation of China
   (NSFC) under Grants 61876171 and 61976203.The Associate Editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Zhu Liu
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2017, P IEEE C COMP VIS PA
   Bao LQ, 2019, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2019.00191
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chang XJ, 2018, LECT NOTES COMPUT SC, V11213, P86, DOI 10.1007/978-3-030-01240-3_6
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Chen WC, 2019, LECT NOTES COMPUT SC, V11363, P200, DOI 10.1007/978-3-030-20893-6_13
   Chen YT, 2018, AAAI CONF ARTIF INTE, P2852
   Cheng Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11949, DOI 10.1109/CVPR42600.2020.01197
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Di Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12612, DOI 10.1109/CVPR42600.2020.01263
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Dong WK, 2020, PROC CVPR IEEE, P2836, DOI 10.1109/CVPR42600.2020.00291
   Dong WK, 2020, PROC CVPR IEEE, P2582, DOI 10.1109/CVPR42600.2020.00266
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Furlanello T, 2018, PR MACH LEARN RES, V80
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo AX, 2017, CHIN AUTOM CONGR, P1364, DOI 10.1109/CAC.2017.8242979
   Han CC, 2019, IEEE I CONF COMP VIS, P9813, DOI 10.1109/ICCV.2019.00991
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hinton G., 2015, COMPUT SCI, V2
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiao JN, 2018, AAAI CONF ARTIF INTE, P6967
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li ZJ, 2021, AAAI CONF ARTIF INTE, V35, P2011
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Liu HM, 2021, NEUROCOMPUTING, V423, P57, DOI 10.1016/j.neucom.2020.10.019
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo P, 2016, AAAI CONF ARTIF INTE, P3560
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Urban G., 2017, PROC INT C LEARN REP
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wei L., 2014, PROC ACM INT C MULTI, P937
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Xiao JM, 2019, PATTERN RECOGN, V87, P332, DOI 10.1016/j.patcog.2018.10.028
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu JL, 2019, IEEE INT CONF ROBOT, P2379, DOI [10.1109/icra.2019.8793743, 10.1109/ICRA.2019.8793743]
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yan YC, 2021, PROC CVPR IEEE, P7686, DOI 10.1109/CVPR46437.2021.00760
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Zagoruyko S., 2017, PROC INT C MACH LEAR
   Zeng ZL, 2020, IEEE T MULTIMEDIA, V22, P3064, DOI 10.1109/TMM.2020.2969782
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhao XY, 2018, LECT NOTES COMPUT SC, V11205, P415, DOI 10.1007/978-3-030-01246-5_25
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zhong YJ, 2020, PROC CVPR IEEE, P6826, DOI 10.1109/CVPR42600.2020.00686
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
NR 72
TC 2
Z9 2
U1 4
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 1190
EP 1203
DI 10.1109/TMM.2021.3140025
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA D7WI3
UT WOS:000970791100013
DA 2024-07-18
ER

PT J
AU Wang, FY
   Gao, XY
   Chen, ZY
   Lyu, L
AF Wang, Fuyun
   Gao, Xingyu
   Chen, Zhenyu
   Lyu, Lei
TI Contrastive Multi-Level Graph Neural Networks for Session-Based
   Recommendation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Session-based recommendation; contrastive learning; graph neural
   networks
AB Session-based recommendation (SBR) aims to predict the next item at a certain time point based on anonymous user behavior sequences. Existing methods typically model session representation based on simple item transition information. However, since session-based data consists of limited users' short-term interactions, modeling session representation by capturing fixed item transition information from a single dimension suffers from data sparsity. In this paper, we propose a novel contrastive multi-level graph neural networks (CM-GNN) to better exploit complex and high-order item transition information. Specifically, CM-GNN applies local-level graph convolutional network (L-GCN) and global-level graph convolutional network (G-GCN) on the current session and all the sessions respectively, to effectively capture pairwise relations over all the sessions by aggregation strategy. Meanwhile, CM-GNN applies hyper-level graph convolutional network (H-GCN) to capture high-order information among all the item transitions. CM-GNN further introduces an attention-based fusion module to learn pairwise relation-based session representation by fusing the item representations generated by L-GCN and G-GCN. CM-GNN averages the item representations obtained by H-GCN to obtain high-order relation-based session representation. Moreover, to convert the high-order item transition information into the pairwise relation-based session representation, CM-GNN maximizes the mutual information between the representations derived from the fusion module and the average pool layer by contrastive learning paradigm. We conduct extensive experiments on several widely used benchmark datasets to validate the efficacy of the proposed method. The encouraging results demonstrate that our proposed method outperforms the state-of-the-art SBR techniques.
C1 [Wang, Fuyun; Lyu, Lei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.
   [Wang, Fuyun; Lyu, Lei] Shandong Prov Key Lab Novel Distributed Comp Soft, Jinan 250358, Peoples R China.
   [Gao, Xingyu] Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.
   [Chen, Zhenyu] State Grid Corp China, Big Data Ctr, Beijing 100031, Peoples R China.
   [Chen, Zhenyu] China Elect Power Res Inst, Beijing 100192, Peoples R China.
C3 Shandong Normal University; Chinese Academy of Sciences; Institute of
   Microelectronics, CAS; State Grid Corporation of China
RP Lyu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.; Gao, XY (corresponding author), Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.
EM fuyunwang2021@gmail.com; gxy9910@gmail.com; czy9907@gmail.com;
   lvlei@sdnu.edu.cn
RI Gao, Xingyu/AAL-3288-2021; Chen, Zhenyu/AAA-6776-2022
OI Gao, Xingyu/0000-0002-4660-8092; 
FU Science and Technology Innovation
FX No Statement Available
CR Arora S., 2019, 36th International Conference on Machine Learning, P9904
   Bachman P, 2019, ADV NEUR IN, V32
   Chen TW, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1172, DOI 10.1145/3394486.3403170
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen XS, 2021, IEEE T MULTIMEDIA, V23, P484, DOI 10.1109/TMM.2020.2978618
   Chen YH, 2022, IEEE T IND INFORM, V18, P1458, DOI 10.1109/TII.2021.3091435
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fang H., 2020, CoRR
   Feng YF, 2019, AAAI CONF ARTIF INTE, P3558
   Gao XY, 2020, IEEE T MULTIMEDIA, V22, P1647, DOI 10.1109/TMM.2019.2945180
   Hassani K, 2020, PR MACH LEARN RES, V119
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   He RN, 2016, IEEE DATA MINING, P191, DOI [10.1109/ICDM.2016.88, 10.1109/ICDM.2016.0030]
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Hjelm R.D., 2019, P 7 INT C LEARNING R
   Iter Dan, 2020, P 58 ANN M ASS COMPU, P4859, DOI [DOI 10.18653/V1/2020.ACL-MAIN.439, 10.18653/v1/2020.acl-main.439]
   Jannach D, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P306, DOI 10.1145/3109859.3109872
   Ji X, 2019, IEEE I CONF COMP VIS, P9864, DOI 10.1109/ICCV.2019.00996
   Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Li JC, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P322, DOI 10.1145/3336191.3371786
   Li J, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1419, DOI 10.1145/3132847.3132926
   Liu Q, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1831, DOI 10.1145/3219819.3219950
   Ma S., 2021, P 9 INT C LEARN REPR
   Min WQ, 2020, IEEE T MULTIMEDIA, V22, P2659, DOI 10.1109/TMM.2019.2958761
   Pan ZQ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1195, DOI 10.1145/3340531.3412014
   Qiu RH, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P579, DOI 10.1145/3357384.3358010
   Quintanilla E, 2021, IEEE T MULTIMEDIA, V23, P1083, DOI 10.1109/TMM.2020.2992941
   Ren RY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P89, DOI 10.1145/3397271.3401111
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Sang L, 2021, IEEE T MULTIMEDIA, V23, P2019, DOI 10.1109/TMM.2020.3007330
   Sankar A, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1279, DOI 10.1145/3397271.3401116
   Sermanet P, 2018, IEEE INT CONF ROBOT, P1134
   Shani G, 2005, J MACH LEARN RES, V6, P1265
   Subakan C, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P21, DOI 10.1109/ICASSP39728.2021.9413901
   Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Trinh T. H., 2019, VOLABS190602940 CORR
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Wang HZ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3698
   Wang JL, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1101, DOI 10.1145/3397271.3401133
   Wang MR, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P345, DOI 10.1145/3331184.3331210
   Wang SP, 2022, ACTA BIOCH BIOPH SIN, V54, P952, DOI [10.3724/abbs.2022077, 10.1145/3465401]
   Wang SJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6332
   Wang ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P169, DOI 10.1145/3397271.3401142
   Wu CY, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P495, DOI 10.1145/3018661.3018689
   Wu JC, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P726, DOI 10.1145/3404835.3462862
   Wu L., 2021, VOLABS210507342 CORR
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xia X, 2021, AAAI CONF ARTIF INTE, V35, P4503
   Xin X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P931, DOI 10.1145/3397271.3401147
   Xu CF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3940
   Yadati N, 2019, ADV NEUR IN, V32
   Ye M, 2019, PROC CVPR IEEE, P6203, DOI 10.1109/CVPR.2019.00637
   Ye R, 2020, INT CONF DAT MIN WOR, P220, DOI 10.1109/ICDMW51313.2020.00039
   Yu F, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P729, DOI 10.1145/2911451.2914683
   Yu JL, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2084, DOI 10.1145/3447548.3467340
   Yu JL, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P413, DOI 10.1145/3442381.3449844
   Zangerle E., 2014, P 1 ACM INT WORKSH I, P21
   Zhou K, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1893, DOI 10.1145/3340531.3411954
   Zimdars A., 2013, VOLABS13012320 CORR
NR 64
TC 2
Z9 2
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 9278
EP 9289
DI 10.1109/TMM.2023.3250087
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DP7K5
UT WOS:001133324200022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, J
   Li, XY
   Zhang, ZC
   Song, W
   Guo, WQ
AF Wang, Jian
   Li, Xinyue
   Zhang, Zhichao
   Song, Wei
   Guo, Weiqi
TI Ranked Similarity Weighting and Top-nk Sampling in Deep Metric Learning
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Deep metric learning; image retrieval; sample weighting; sampling method
AB Deep metric learning has been widely used in many visual tasks. Its key idea is to increase the similarity of positive samples and decrease the similarity of negative samples through network training. To achieve this purpose, many studies excessively extend the distance between the query sample and hard negative samples. This may compress the distance between similar samples of other classes, causing these samples to cluster together. We call this phenomenon Negative Sample Aggregation. To address this problem, first, we propose a weighting method based on the Ranking Similarity of sample pairs, short for RS. The proposed weighting method can not only enlarge the distance between the query sample and hard negative samples, but also maintain the embedding distribution of proximal negative samples. Second, we propose a Top-nk sampling method, which can dynamically adjust the sampling strategy according to the distribution of a dataset. It solves the problem that the descent direction of the network gradient is inconsistent with the optimization target. The effectiveness of our methods is evaluated by extensive experiments on four public datasets and compared with that of other state-of-the-art methods. The results show that the proposed method obtains excellent performance, reaching 67.8% on CUB-200-2011 and 85.2% on Cars-196 at Recall@1.
C1 [Wang, Jian; Li, Xinyue; Zhang, Zhichao; Song, Wei] Shanghai Ocean Univ, Inst Digital Ocean, Shanghai 201306, Peoples R China.
   [Guo, Weiqi] Design & Res Inst, East Sea Oceanog Engn Invest, Shanghai 200137, Peoples R China.
C3 Shanghai Ocean University
RP Song, W (corresponding author), Shanghai Ocean Univ, Inst Digital Ocean, Shanghai 201306, Peoples R China.
EM wsong@shou.edu.cn; 784367529@qq.com; 781991395@qq.com;
   13963430703@163.com; guo_weiqi@163.com
RI Song, wei/KHX-7140-2024
OI Song, wei/0000-0002-0604-5563; Zhang, Zhichao/0000-0003-1466-6383
FU National Natural Science Foundation of China [61972240]; Science and
   Technology Commission of Shanghai Municipality [20050501900]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61972240, and in part by the Science and
   Technology Commission of Shanghai Municipality under Grant 20050501900.
CR Bai S, 2021, IEEE T PATTERN ANAL, V43, P2119, DOI 10.1109/TPAMI.2020.3031625
   Bai S, 2017, PROC CVPR IEEE, P3356, DOI 10.1109/CVPR.2017.358
   Bhattacharya J, 2020, SOFT COMPUT, V24, P15519, DOI 10.1007/s00500-020-04880-1
   Brown Andrew, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P677, DOI 10.1007/978-3-030-58545-7_39
   Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Chang HS, 2017, ADV NEUR IN, V30
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Duan YQ, 2020, IEEE T IMAGE PROCESS, V29, P2037, DOI 10.1109/TIP.2019.2948472
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Harwood B, 2017, IEEE I CONF COMP VIS, P2840, DOI 10.1109/ICCV.2017.307
   He GQ, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107889
   Jiang Z, 2020, IEEE T MULTIMEDIA, V22, P540, DOI 10.1109/TMM.2019.2929957
   Kim S, 2020, PROC CVPR IEEE, P3235, DOI 10.1109/CVPR42600.2020.00330
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P760, DOI 10.1007/978-3-030-01246-5_45
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lu J, 2019, IEEE I CONF COMP VIS, P7960, DOI 10.1109/ICCV.2019.00805
   Min WQ, 2020, IEEE T MULTIMEDIA, V22, P3128, DOI 10.1109/TMM.2020.2974326
   Ming ZH, 2017, IEEE INT CONF COMP V, P1656, DOI 10.1109/ICCVW.2017.194
   Mohan D., 2020, Moving in the right direction: A regularization for deep metric learning, p14 579
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Opitz M, 2020, IEEE T PATTERN ANAL, V42, P276, DOI 10.1109/TPAMI.2018.2848925
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Ustinova E, 2016, ADV NEUR IN, V29
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang J, 2017, IEEE I CONF COMP VIS, P2612, DOI [10.1109/ICCV.2017.283, 10.1109/ICCV.2017.65]
   Wang XS, 2019, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR.2019.00535
   Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu BS, 2019, IEEE I CONF COMP VIS, P6499, DOI 10.1109/ICCV.2019.00659
   Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94
   Zhao CR, 2021, IEEE T IMAGE PROCESS, V30, P7776, DOI 10.1109/TIP.2021.3109508
   Zhao CR, 2020, IEEE T MULTIMEDIA, V22, P3180, DOI 10.1109/TMM.2020.2972125
   Zheng AH, 2022, IEEE T MULTIMEDIA, V24, P338, DOI 10.1109/TMM.2021.3050089
   Zheng WZ, 2019, PROC CVPR IEEE, P72, DOI 10.1109/CVPR.2019.00016
NR 45
TC 1
Z9 1
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 7726
EP 7735
DI 10.1109/TMM.2022.3225738
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AV4K5
UT WOS:001121212400009
DA 2024-07-18
ER

PT J
AU Wei, X
   Yao, YY
   Wang, HY
   Zhou, L
AF Wei, Xin
   Yao, Yuyuan
   Wang, Haoyu
   Zhou, Liang
TI Perception-Aware Cross-Modal Signal Reconstruction: From Audio-Haptic to
   Visual
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Visualization; Haptic interfaces; Redundancy; Signal reconstruction;
   Signal restoration; Correlation; Streaming media; Audio-haptic
   redundancy elimination; cross-modal communications; perception; visual
   signal reconstruction
ID MULTIMEDIA; MASKING
AB Cross-modal communications, devoting to collaboratively delivering and processing audio, visual, and haptic signals, have gradually become the supporting technology for the emerging multi-modal services. However, the inevitable resource competitions among different modality signals as well as the unexpected packet loss and latency during transmission seriously affect quality of the received signals and end user's immersive experience (especially visual experience). To overcome these dilemmas, this paper proposes a cross-modal signal reconstruction strategy from the perspective of human's perceptual facts. It tries to guarantee visual signal quality by considering potential correlations among modalities when processing audio and haptic signals. On the one hand, a time-frequency masking-based audio-haptic redundancy elimination mechanism is designed by resorting to the similarity of audio-haptic characteristics and human's masking effects. On the other hand, based on the fact that non-visual perception can assist to form and enhance visual perception, an audio-haptic fused visual signal restoration (AHFVR) approach for handling the impaired and delayed visual signals is proposed. Experiments on a standard multi-modal database and a constructed practical platform evaluate the performance of the proposed perception-aware cross-modal signal reconstruction strategy.
C1 [Wei, Xin; Yao, Yuyuan; Wang, Haoyu; Zhou, Liang] Nanjing Univ Posts & Telecommun, Sch Commun & Informat Engn, Minist Educ, Nanjing 210003, Peoples R China.
   [Wei, Xin; Yao, Yuyuan; Wang, Haoyu; Zhou, Liang] Nanjing Univ Posts & Telecommun, Key Lab Broadband Wireless Commun & Sensor Network, Minist Educ, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications
RP Zhou, L (corresponding author), Nanjing Univ Posts & Telecommun, Sch Commun & Informat Engn, Minist Educ, Nanjing 210003, Peoples R China.; Zhou, L (corresponding author), Nanjing Univ Posts & Telecommun, Key Lab Broadband Wireless Commun & Sensor Network, Minist Educ, Nanjing 210003, Peoples R China.
EM xwei@njupt.edu.cn; 1019010631@njupt.edu.cn; 1221014002@njupt.edu.cn;
   liang.zhou@njupt.edu.cn
FU National Natural Science Foundation of China [62071254]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62071254 and in part by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions.
CR Chaudhariu R, 2015, IEEE J-STSP, V9, P462, DOI 10.1109/JSTSP.2014.2374574
   Chen RM, 2017, IEEE T NUCL SCI, V64, P2098, DOI 10.1109/TNS.2017.2711034
   Cheng H, 2024, IEEE T MULTIMEDIA, V26, P4110, DOI 10.1109/TMM.2021.3118287
   Cizmeci B, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3063594
   Deshpande I, 2019, PROC CVPR IEEE, P10640, DOI 10.1109/CVPR.2019.01090
   Eid M, 2012, IEEE ACM DIS SIM, P118, DOI 10.1109/DS-RT.2012.23
   Elbamby MS, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700268
   Hassen R, 2021, IEEE T MULTIMEDIA, V23, P4455, DOI 10.1109/TMM.2020.3042674
   Hossan T, 2019, IEEE COMMUN MAG, V57, P26, DOI 10.1109/MCOM.2018.1800527
   Jin Z, 2020, IEEE T MULTIMEDIA, V22, P1055, DOI 10.1109/TMM.2019.2938340
   Lee JT, 2019, IEEE INT CONF ROBOT, P4276, DOI 10.1109/ICRA.2019.8793763
   Li B, 2019, IEEE T MOBILE COMPUT, V18, P702, DOI 10.1109/TMC.2018.2842751
   Lin TL, 2018, IEEE SENS J, V18, P9792, DOI 10.1109/JSEN.2018.2865916
   Liu HP, 2019, IEEE T AUTOM SCI ENG, V16, P781, DOI 10.1109/TASE.2018.2865000
   Madmoni L, 2021, IEEE-ACM T AUDIO SPE, V29, P2037, DOI 10.1109/TASLP.2021.3084742
   Niu ST, 2022, ACM TRANS MANAG INF, V13, DOI 10.1145/3464324
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Siddiqui MS, 2009, IEEE T CONSUM ELECTR, V55, P527, DOI 10.1109/TCE.2009.5174417
   Strese M, 2017, IEEE T HAPTICS, V10, P226, DOI 10.1109/TOH.2016.2625787
   Tang XW, 2020, IEEE T VEH TECHNOL, V69, P9896, DOI 10.1109/TVT.2020.3003478
   Wang CY, 2019, IEEE T EVOLUT COMPUT, V23, P921, DOI 10.1109/TEVC.2019.2895748
   Wei X, 2022, IEEE T CIRC SYST VID, V32, P3991, DOI 10.1109/TCSVT.2021.3105130
   Wei X, 2021, IEEE WIREL COMMUN, V28, P182, DOI 10.1109/MWC.001.2000448
   Xie HH, 2016, IEEE T VEH TECHNOL, V65, P923, DOI 10.1109/TVT.2015.2397862
   Yang JC, 2021, IEEE T IND INFORM, V17, P2204, DOI 10.1109/TII.2020.2998818
   Yang ZC, 2019, IEEE T IMAGE PROCESS, V28, P2898, DOI 10.1109/TIP.2019.2891935
   Yi XW, 2019, IEEE T INF FOREN SEC, V14, P2217, DOI 10.1109/TIFS.2019.2895200
   Yin JL, 2018, IEEE T MULTIMEDIA, V20, P3045, DOI 10.1109/TMM.2018.2820910
   Yuan GZ, 2019, IEEE T PATTERN ANAL, V41, P352, DOI 10.1109/TPAMI.2017.2783936
   Yuan MK, 2020, IEEE T MULTIMEDIA, V22, P1955, DOI 10.1109/TMM.2019.2951463
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P104, DOI 10.1109/TMM.2014.2371240
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhou L, 2021, IEEE J SEL AREA COMM, V39, P426, DOI 10.1109/JSAC.2020.3021543
   Zhou L, 2020, IEEE WIREL COMMUN, V27, P112, DOI 10.1109/MWC.001.1900201
   Zhu WW, 2020, IEEE T MULTIMEDIA, V22, P1823, DOI 10.1109/TMM.2020.2969791
   Zou S, 2018, IEEE T CIRC SYST VID, V28, P158, DOI 10.1109/TCSVT.2016.2601962
NR 37
TC 3
Z9 3
U1 4
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 5527
EP 5538
DI 10.1109/TMM.2022.3194309
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA X3FI3
UT WOS:001097340300064
DA 2024-07-18
ER

PT J
AU Xu, YH
   He, FX
   Du, B
   Tao, DC
   Zhang, LP
AF Xu, Yonghao
   He, Fengxiang
   Du, Bo
   Tao, Dacheng
   Zhang, Liangpei
TI Self-Ensembling GAN for Cross-Domain Semantic Segmentation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Deep learning; domain adaptation; semantic segmentation; adversarial
   learning
AB Deep neural networks (DNNs) have greatly contributed to the performance gains in semantic segmentation. Nevertheless, training DNNs generally requires large amounts of pixel-level labeled data, which is expensive and time-consuming to collect in practice. To mitigate the annotation burden, this paper proposes a self-ensembling generative adversarial network (SE-GAN) exploiting cross-domain data for semantic segmentation. In SE-GAN, a teacher network and a student network constitute a self-ensembling model for generating semantic segmentation maps, which together with a discriminator, forms a GAN. Despite its simplicity, we find SE-GAN can significantly boost the performance of adversarial training and enhance the stability of the model, the latter of which is a common barrier shared by most adversarial training-based methods. We theoretically analyze SE-GAN and provide an O(1/root N) generalization bound (N is the training sample size), which suggests controlling the discriminator's hypothesis complexity to enhance the generalizability. Accordingly, we choose a simple network as the discriminator. Extensive and systematic experiments in two standard settings demonstrate that the proposed method significantly outperforms current state-of-the-art approaches.
C1 [Xu, Yonghao; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Xu, Yonghao] Inst Adv Res Artificial Intelligence IARAI, A-1030 Vienna, Austria.
   [He, Fengxiang; Tao, Dacheng] JDcom Inc, JD Explore Acad, Beijing, Peoples R China.
   [Du, Bo] Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Inst Artificial Intelligence, Wuhan 430079, Peoples R China.
   [Du, Bo] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University
RP Zhang, LP (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.; Du, B (corresponding author), Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Inst Artificial Intelligence, Wuhan 430079, Peoples R China.; Du, B (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430079, Peoples R China.
EM yonghaoxu@ieee.org; hefengxiang@jd.com; gunspace@163.com;
   taodacheng@jd.com; zlp62@whu.edu.cn
RI Tao, Dacheng/A-5449-2012
OI Tao, Dacheng/0000-0001-7225-5449; Xu, Yonghao/0000-0002-6857-0152
FU National Key Research and Development Program of China [41871243,
   62225113, 41820104006, 61871299, 2018AAA0101100]; Major Science and
   Technology Innovation 2030 Key Projects, New Generation Artificial
   Intelligence [2021ZD0111700]; Science and Technology Major Project of
   Hubei Province Next-Generation AI Technologies [2019AEA170]
FX This work was supported in part by theNationalNatural Science Foundation
   of China, under Grants 41871243, 62225113, 41820104006, and 61871299, in
   part by the Major Science and Technology Innovation 2030 Key Projects,
   New Generation Artificial Intelligence under Grant 2021ZD0111700, in
   part by the National Key Research and Development Program of China,
   under Grant 2018AAA0101100, and in part by the Science and Technology
   Major Project of Hubei Province Next-Generation AI Technologies, under
   Grant 2019AEA170.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bartlett PL, 2017, 31 ANN C NEURAL INFO, V30
   Chang WL, 2019, PROC CVPR IEEE, P1900, DOI 10.1109/CVPR.2019.00200
   Chen BK, 2019, IEEE T INTELL TRANSP, V20, P137, DOI 10.1109/TITS.2018.2801309
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen MH, 2019, IEEE I CONF COMP VIS, P2090, DOI 10.1109/ICCV.2019.00218
   Chen YH, 2019, PROC CVPR IEEE, P1841, DOI 10.1109/CVPR.2019.00194
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Choi J, 2019, IEEE I CONF COMP VIS, P6829, DOI 10.1109/ICCV.2019.00693
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du L, 2019, IEEE I CONF COMP VIS, P982, DOI 10.1109/ICCV.2019.00107
   Fang CW, 2022, PROC CVPR IEEE, P20645, DOI 10.1109/CVPR52688.2022.02002
   French G., 2018, INT C LEARN REPR ICL
   Ganin Y, 2016, J MACH LEARN RES, V17
   Guan DY, 2022, IEEE T MULTIMEDIA, V24, P2502, DOI 10.1109/TMM.2021.3082687
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hoffman J, 2016, Arxiv, DOI arXiv:1612.02649
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang B, 2018, IEEE T MULTIMEDIA, V20, P2478, DOI 10.1109/TMM.2018.2798282
   Kingma D. P., 2014, arXiv
   Laine S, 2017, Arxiv, DOI [arXiv:1610.02242, DOI 10.48550/ARXIV.1610.02242]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Luo YW, 2019, IEEE I CONF COMP VIS, P6777, DOI 10.1109/ICCV.2019.00688
   Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Muller A, 1997, ADV APPL PROBAB, V29, P429, DOI 10.2307/1428011
   Mumtaz F, 2018, BIOMED PHARMACOTHER, V105, P1205, DOI 10.1016/j.biopha.2018.05.086
   Pan F, 2020, PROC CVPR IEEE, P3763, DOI 10.1109/CVPR42600.2020.00382
   Pan JW, 2022, INT J COMPUT VISION, V130, P1181, DOI 10.1007/s11263-022-01590-z
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LC, 2020, IEEE T IMAGE PROCESS, V29, P6452, DOI 10.1109/TIP.2020.2989100
   Subhani M. N., 2020, P EUR C COMP VIS, P290
   Tarvainen A, 2017, ADV NEUR IN, V30
   Tommasi T, 2016, LECT NOTES COMPUT SC, V9915, P475, DOI 10.1007/978-3-319-49409-8_39
   Tsai YH, 2019, IEEE I CONF COMP VIS, P1456, DOI 10.1109/ICCV.2019.00154
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Vu TH, 2019, IEEE I CONF COMP VIS, P7363, DOI 10.1109/ICCV.2019.00746
   Wang R, 2023, IEEE T MULTIMEDIA, V25, P1665, DOI 10.1109/TMM.2022.3146744
   Wu ZX, 2018, LECT NOTES COMPUT SC, V11209, P535, DOI 10.1007/978-3-030-01228-1_32
   Xu YH, 2019, AAAI CONF ARTIF INTE, P5581
   Yao Y, 2020, AAAI CONF ARTIF INTE, V34, P12669
   Zhang D., 2020, Adv. Neural Info. Process. Syst., V33, P12236
   Zhang P., 2018, PROC INT C LEARN REP
   Zhang QM, 2019, ADV NEUR IN, V32
   Zhang TY, 2019, IEEE T MULTIMEDIA, V21, P2930, DOI 10.1109/TMM.2019.2914870
   Zhang Y, 2020, IEEE T PATTERN ANAL, V42, P1823, DOI 10.1109/TPAMI.2019.2903401
   Zhang YH, 2018, PROC CVPR IEEE, P6810, DOI 10.1109/CVPR.2018.00712
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao S., 2019, P ADV NEUR INF PROC, P7285
   Zhou L, 2021, IEEE T MULTIMEDIA, V23, P1035, DOI 10.1109/TMM.2020.2991592
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 64
TC 3
Z9 4
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 7837
EP 7850
DI 10.1109/TMM.2022.3229976
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AV4K5
UT WOS:001121212400018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yoo, JS
   Kim, DW
   Lu, YC
   Jung, SW
AF Yoo, Jun-Sang
   Kim, Dong-Wook
   Lu, Yucheng
   Jung, Seung-Won
TI RZSR: Reference-Based Zero-Shot Super-Resolution With Depth Guided
   Self-Exemplars
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Deep learning; image super-resolution; reference-based super-resolution;
   zero-shot super-resolution
ID IMAGE SUPERRESOLUTION
AB Recent methods for single image super-resolution (SISR) have demonstrated outstanding performance in generating high-resolution (HR) images from low-resolution (LR) images. However, most of these methods show their superiority using synthetically generated LR images, and their generalizability to real-world images is often not satisfactory. In this paper, we pay attention to two well-known strategies developed for robust super-resolution (SR), i.e., reference-based SR (RefSR) and zero-shot SR (ZSSR), and propose an integrated solution, called reference-based zero-shot SR (RZSR). Following the principle of ZSSR, we train an image-specific SR network at test time using training samples extracted only from the input image itself. To advance ZSSR, we obtain reference image patches with rich textures and high-frequency details which are also extracted only from the input image using cross-scale matching. To this end, we construct an internal reference dataset and retrieve reference image patches from the dataset using depth information. Using LR patches and their corresponding HR reference patches, we train a RefSR network that is embodied with a non-local attention module. Experimental results demonstrate the superiority of the proposed RZSR compared to the previous ZSSR methods and robustness to unseen images compared to other fully supervised SISR methods.
C1 [Yoo, Jun-Sang; Kim, Dong-Wook; Jung, Seung-Won] Korea Univ, Dept Elect & Elect Engn, Seoul 02841, South Korea.
   [Lu, Yucheng] Korea Univ, Educ & Res Ctr Socialware IT, Seoul 02841, South Korea.
C3 Korea University; Korea University
RP Jung, SW (corresponding author), Korea Univ, Dept Elect & Elect Engn, Seoul 02841, South Korea.
EM junsang7777@naver.com; spnova12@gmail.com; yucheng.l@outlook.com;
   swjung83@korea.ac.kr
RI Kim, Dong Wook/JCE-1975-2023
OI Jung, Seung-Won/0000-0002-0319-4467; Lu, Yucheng/0000-0003-2990-5252;
   Yoo, Jun-Sang/0000-0001-9053-699X
FU National Research Foundation of Korea (NRF) through Korea government
   (MSIT) [2020R1A4A4079705]
FX This work was supported by the National Research Foundation of Korea
   (NRF) through Korea government (MSIT) under Grant 2020R1A4A4079705.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Bell-Kligler S, 2019, ADV NEUR IN, V32
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bhat SF, 2021, PROC CVPR IEEE, P4008, DOI 10.1109/CVPR46437.2021.00400
   Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Chantas G, 2021, IEEE T IMAGE PROCESS, V30, P838, DOI 10.1109/TIP.2020.3038521
   Chen HG, 2017, IEEE T MULTIMEDIA, V19, P1702, DOI 10.1109/TMM.2017.2688920
   Cornillère V, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356575
   cvnote.ddlee, Historical image dataset
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Emad M, 2021, IEEE WINT CONF APPL, P1629, DOI 10.1109/WACV48630.2021.00167
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JJ, 2019, PROC CVPR IEEE, P1604, DOI 10.1109/CVPR.2019.00170
   Gyumin Shim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8422, DOI 10.1109/CVPR42600.2020.00845
   He ZW, 2020, IEEE T MULTIMEDIA, V22, P1042, DOI 10.1109/TMM.2019.2937688
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   Kingma D. P, 2015, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1412.6980
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C, 2011, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2011.5995614
   mathworks, Matlab image resize library
   Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   pytorch, PyTorch library
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soh JW, 2020, PROC CVPR IEEE, P3513, DOI 10.1109/CVPR42600.2020.00357
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Verma VK, 2020, AAAI CONF ARTIF INTE, V34, P6062
   Wan RJ, 2018, IEEE T IMAGE PROCESS, V27, P2927, DOI 10.1109/TIP.2018.2808768
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Xi Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P265, DOI 10.1007/978-3-030-58520-4_16
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yan Xu, 2020, COMPUTER VISION ECCV, P52, DOI DOI 10.1007/978-3-030-58595-24
   Yanchun Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P230, DOI 10.1007/978-3-030-58548-8_14
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yue HJ, 2013, IEEE T IMAGE PROCESS, V22, P4865, DOI 10.1109/TIP.2013.2279315
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang XY, 2021, IEEE T MULTIMEDIA, V23, P1924, DOI 10.1109/TMM.2020.3005025
   Zhang ZF, 2019, PROC CVPR IEEE, P7974, DOI 10.1109/CVPR.2019.00817
   Zheng HT, 2018, LECT NOTES COMPUT SC, V11210, P87, DOI 10.1007/978-3-030-01231-1_6
   Zhou S., 2020, P ADV NEUR INF PROC, V33, P3499
NR 54
TC 2
Z9 2
U1 3
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 5972
EP 5983
DI 10.1109/TMM.2022.3202018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA X5KG5
UT WOS:001098831500024
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yu, YG
   Zhang, W
   Yang, FZ
   Li, G
AF Yu, Youguang
   Zhang, Wei
   Yang, Fuzheng
   Li, Ge
TI Rate-Distortion Optimized Geometry Compression for Spinning LiDAR Point
   Cloud
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE LiDAR point cloud; point cloud compression; geometry information;
   rate-distortion optimization
ID VISION
AB Point cloud is a major representation format of 3D objects and scenes. It has been increasingly applied in various applications due to the rapid advances in 3D sensing and rendering technologies. In the field of autonomous driving, point clouds captured by spinning Light Detection And Ranging (LiDAR) devices have become an informative data source for road environment perception and intelligent vehicle control. On the other hand, the massive data volume of point clouds also brings huge challenges to point cloud transmission and storage. Therefore, establishing compression frameworks and algorithms that conform to the characteristics of point cloud data has become an important research topic for both academia and industry. In this paper, a geometry compression method dedicated to spinning LiDAR point cloud was proposed taking advantage of the prior information of the LiDAR acquisition procedure. Rate-distortion optimizations were further integrated into the coding pipeline according to the characteristics of the prediction residuals. Experimental results obtained on different datasets show that the proposed method consistently outperforms the state-of-the-art G-PCC predictive geometry coding method with reduced runtime at both the encoder and decoder sides.
C1 [Yu, Youguang; Zhang, Wei; Yang, Fuzheng] Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
   [Zhang, Wei; Li, Ge] Artificial Intelligence Res Ctr, Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Li, Ge] Peking Univ, Sch Elect & Comp Engn, Shenzhen Grad Sch Shenzhen, Shenzhen 100871, Peoples R China.
C3 Xidian University; Peng Cheng Laboratory; Peking University
RP Zhang, W (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
EM ygyu@stu.xidian.edu.cn; wzhang@xidian.edu.cn;
   fzhyang@mail.xidian.edu.cn; geli@pku.edu.cn
FU National Natural Science Foundation of China [61801364]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61801364. The associate editor coordinating the review
   of this manuscript and approving it for publication was Dr. Vladan
   Velisavljevic.& nbsp;
CR Ahn JK, 2015, IEEE J-STSP, V9, P422, DOI 10.1109/JSTSP.2014.2370752
   Allen A. C., 2008, P SPIE, V6960, P19
   [Anonymous], 2019, document ISO/IEC JTC1/SC29/WG11 MPEG/N18709
   [Anonymous], 2008, BBC
   [Anonymous], 2018, JTC1SC29WG11 ISOIEC
   [Anonymous], 2019, M5010 AVS
   [Anonymous], 2020, JTC1SC29WG11 ISOIEC
   Bjontegaard G., 2001, Document VCEG-M33
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Chen ZG, 2018, COMPUT AIDED DESIGN, V102, P12, DOI 10.1016/j.cad.2018.04.010
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Cui MY, 2020, IEEE INTERNET THINGS, V7, P10535, DOI 10.1109/JIOT.2020.3001218
   Debray A., 2018, YOLE DEVELOPPEMENT
   Flynn D., 2020, JTC1SC29WG11 ISOIEC
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Guarda AFR, 2021, IEEE J-STSP, V15, P415, DOI 10.1109/JSTSP.2020.3047520
   Gumhold S., 2005, ACM SIGGRAPH 2005 SK, P137
   Huang LL, 2020, PROC CVPR IEEE, P1310, DOI 10.1109/CVPR42600.2020.00139
   Jang ES, 2019, IEEE SIGNAL PROC MAG, V36, P118, DOI 10.1109/MSP.2019.2900721
   Jayaweera N, 2020, 2020 2ND 6G WIRELESS SUMMIT (6G SUMMIT), DOI 10.1109/6gsummit49458.2020.9083914
   Kathariya B, 2018, IEEE INT CON MULTI
   Krivokuca M, 2020, IEEE T IMAGE PROCESS, V29, P2217, DOI 10.1109/TIP.2019.2957853
   Li L, 2021, IEEE T CIRC SYST VID, V31, P326, DOI 10.1109/TCSVT.2020.2966118
   Li L, 2020, IEEE T IMAGE PROCESS, V29, P6237, DOI 10.1109/TIP.2020.2989576
   Liu Q, 2021, IEEE T MULTIMEDIA, V23, P3278, DOI 10.1109/TMM.2020.3023294
   Luo CJ, 2018, COMPUT GRAPH FORUM, V37, P325, DOI 10.1111/cgf.13293
   Lv CL, 2021, IEEE T IMAGE PROCESS, V30, P7241, DOI 10.1109/TIP.2021.3104174
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   mpegfs.int-evry, MPEG DAT
   Pandey G, 2011, INT J ROBOT RES, V30, P1543, DOI 10.1177/0278364911400640
   Pereira F, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115862
   Schnabel R., 2006, S POINT BAS GRAPH 20, P111
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Sun XB, 2019, IEEE ROBOT AUTOM LET, V4, P2132, DOI 10.1109/LRA.2019.2900747
   Tian D, 2017, IEEE IMAGE PROC, P3460, DOI 10.1109/ICIP.2017.8296925
   Tu CX, 2017, IEEE INT VEH SYM, P1744, DOI 10.1109/IVS.2017.7995959
   Wang JQ, 2021, IEEE T CIRC SYST VID, V31, P4909, DOI 10.1109/TCSVT.2021.3051377
   Wang JQ, 2021, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC50243.2021.00015
   Wen X., 2020, PROC IEEE INT C MULT, P1
   Xu Yiqun, 2017, P IEEE VIS COMM IM P, P1
   Zhang X, 2020, IEEE DATA COMPR CONF, P406, DOI 10.1109/DCC47342.2020.00082
NR 41
TC 6
Z9 6
U1 5
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 2993
EP 3005
DI 10.1109/TMM.2022.3154160
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA O7RP6
UT WOS:001045742200004
DA 2024-07-18
ER

PT J
AU Zhao, JQ
   Wang, HZ
   Zhou, Y
   Yao, R
   Chen, SL
   Saddik, AE
AF Zhao, Jiaqi
   Wang, Hanzheng
   Zhou, Yong
   Yao, Rui
   Chen, Silin
   Saddik, Abdulmotaleb El
TI Spatial-Channel Enhanced Transformer for Visible-Infrared Person
   Re-Identification
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cross-modality person re-identification; visual Transformer; image
   retrieval; deep learning
AB Visible-infrared person re-identification (VI-ReID) is a challenging task in computer vision, aiming at matching people across images from visible and infrared modalities. The widely used VI-ReID framework consists of a convolution neural backbone network that extracts the visual features, and a feature embedding network to project heterogeneous features to the same feature space. However, many studies based on the existing pre-trained models neglect potential correlations between different locations and channels within a single sample during the feature extraction. Inspired by the success of the Transformer in computer vision, we extend it to enhance feature representation for VI-ReID. In this paper, we propose a discriminative feature learning network based on a visual Transformer (DFLN-ViT) for VI-ReID. Firstly, to capture long-term dependencies between different locations, we propose a spatial feature awareness module (SAM), which utilizes a single-layer Transformer with a novel patch-embedding strategy to encode location information. Secondly, to refine the representation at each channel, we design a channel feature enhancement module (CEM). The CEM treats the features of each channel as a sequence of Transformer inputs, taking advantage of the Transformer's ability to model long-term dependencies. Finally, we propose a Triplet-aided Hetero-Center (THC) loss to learn more discriminative feature representation by balancing the cross-modality distance and intra-modality distance of the center. The experimental results on two datasets show that our method can significantly improve the VI-ReID performance, outperforming most state-of-the-art methods.
C1 [Zhao, Jiaqi] China Univ Min & Technol, Innovat Res Ctr Disaster Intelligent Prevent & Eme, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
   [Wang, Hanzheng; Zhou, Yong; Yao, Rui; Chen, Silin] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Saddik, Abdulmotaleb El] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 5N6, Canada.
C3 China University of Mining & Technology; China University of Mining &
   Technology; University of Ottawa
RP Zhou, Y (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM jiaqizhao@cumt.edu.cn; hzwang@cumt.edu.cn; yzhou@cumt.edu.cn;
   ruiyao@cumt.edu.cn; silin.chen@cumt.edu.cn; elsaddik@uottawa.ca
RI Liu, Donghua/KEJ-1974-2024; /D-4159-2009
OI Liu, Donghua/0000-0002-5830-9540; Yao, Rui/0000-0003-2734-915X;
   /0000-0002-7690-8547; Wang, Hanzheng/0000-0001-7276-3216
FU National Natural Science Foundation of China [61806206, 62172417];
   Natural Science Foundation of Jiangsu Province [61973305, BK20201346];
   Six Talent Peaks Project in Jiangsu Province [BK20180639,
   2015-DZXX-010];  [2018-XYDXX-044]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61806206, 62172417, and 61973305, in
   part by the Natural Science Foundation of Jiangsu Province under Grants
   BK20201346 and BK20180639, and in part by the Six Talent Peaks Project
   in Jiangsu Province under Grants 2015-DZXX-010 and 2018-XYDXX-044.&
   nbsp;
CR Basaran E, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115933
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen Z, 2018, PR MACH LEARN RES, V80
   Choi S., 2020, P C COMP VIS PATT RE, p10 257
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Han K, 2021, ADV NEUR IN
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang YW, 2021, IEEE T CIRC SYST VID, V31, P1790, DOI 10.1109/TCSVT.2020.3014167
   Lei Ba J., 2016, arXiv
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li YW, 2021, Arxiv, DOI arXiv:2104.05707
   Lian SC, 2021, IEEE T CIRC SYST VID, V31, P3140, DOI 10.1109/TCSVT.2020.3037179
   Liu HJ, 2021, IEEE T MULTIMEDIA, V23, P4414, DOI 10.1109/TMM.2020.3042080
   Liu HJ, 2020, NEUROCOMPUTING, V398, P11, DOI 10.1016/j.neucom.2020.01.089
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu Y., 2020, P C COMP VIS PATT RE, p13 379
   Meinhardt T, 2022, Arxiv, DOI arXiv:2101.02702
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.15460
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang PY, 2021, IEEE T MULTIMEDIA, V23, P1474, DOI 10.1109/TMM.2020.2999180
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Xie J., 2021, arXiv
   Xu WJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9961, DOI 10.1109/ICCV48922.2021.00983
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2021, IEEE T INF FOREN SEC, V16, P728, DOI 10.1109/TIFS.2020.3001665
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Zhu YX, 2020, NEUROCOMPUTING, V386, P97, DOI 10.1016/j.neucom.2019.12.100
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zhu X., 2020, INT C LEARN REPR
NR 41
TC 29
Z9 29
U1 17
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 3668
EP 3680
DI 10.1109/TMM.2022.3163847
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA S2QI4
UT WOS:001069663600003
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Zheng, JH
   Zhang, S
   Wang, ZL
   Wang, XP
   Zeng, ZG
AF Zheng, Jiahao
   Zhang, Sen
   Wang, Zilu
   Wang, Xiaoping
   Zeng, Zhigang
TI Multi-Channel Weight-Sharing Autoencoder Based on Cascade Multi-Head
   Attention for Multimodal Emotion Recognition
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Multimodal emotion recognition (MER); autoencoder; multi-head attention
   mechanism
ID NETWORK
AB Multimodal Emotion Recognition is challenging because of the heterogeneity gap among different modalities. Due to the powerful ability of feature abstraction, Deep Neural Networks (DNNs) have exhibited significant success in bridging the heterogeneity gap in cross-modal retrieval and generation tasks. In this work, a DNNs-based Multi-channel Weight-sharing Autoencoder with Cascade Multi-head Attention (MCWSA-CMHA) is proposed to generically address the affective heterogeneity gap in MER. Specifically, multimodal heterogeneity features are extracted by multiple independent encoders, and then a scalable heterogeneous feature fusion module (CMHA) is realized by connecting multiple multi-head attention modules in series. The core of the proposed algorithm is to reduce the heterogeneity between the output features of different encoders through the unsupervised training of MCWSA, and then to model the affective interactions between different modal features through the supervised training of CMHA. Experimental results demonstrate that the proposed MCWSA-CMHA achieves outperformance on two publicly available datasets compared with the state-of-the-art techniques. In addition, visualization experiments and approximation experiments are used to verify the effectiveness of each module in the proposed algorithm, and the experimental results show that the proposed MCWSA-CMHA can mine more emotion-related information among multimodal features compared with other fusion methods.
C1 [Zheng, Jiahao; Zhang, Sen; Wang, Zilu; Wang, Xiaoping; Zeng, Zhigang] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
   [Zheng, Jiahao; Zhang, Sen; Wang, Zilu; Wang, Xiaoping; Zeng, Zhigang] Huazhong Univ Sci & Technol, Key Lab Image Proc & Intelligent Control, Educ Minist China, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Wang, ZL (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.; Wang, ZL (corresponding author), Huazhong Univ Sci & Technol, Key Lab Image Proc & Intelligent Control, Educ Minist China, Wuhan 430074, Peoples R China.
EM jhzheng@hust.edu.cn; senzhang91@hust.edu.cn; wangzilu@hust.edu.cn;
   wangxiaoping@hust.edu.cn; zgzeng@hust.edu.cn
RI xiaoping, wang/GRX-3807-2022; wang, zilu/HCH-2274-2022; Zeng,
   Zhigang/A-2816-2011
OI xiaoping, wang/0000-0002-6620-0334; Zeng, Zhigang/0000-0003-4587-3588;
   Wang, Zilu/0000-0001-5638-4574; Zhang, Sen/0000-0002-9265-1876
FU National Natural Science Foundation of China [61876209, 61936004,
   U1913602]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61876209, 61936004, and U1913602.
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2015, P BRIT MACH VIS
   [Anonymous], 2008, Advances in neural information processing systems
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Belghazi MI, 2018, PR MACH LEARN RES, V80
   Burkhardt F, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1053
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chorowski J, 2015, ADV NEUR IN, V28
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Dai WL, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P269
   Deng J, 2018, IEEE-ACM T AUDIO SPE, V26, P31, DOI 10.1109/TASLP.2017.2759338
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding H, 2018, AAAI CONF ARTIF INTE, P6781
   Du ZY, 2021, IEEE T AFFECT COMPUT, V12, P565, DOI 10.1109/TAFFC.2019.2940224
   Dumpala SH, 2019, 32 C NEURAL INFORM P, P1
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   Gideon J, 2017, INTERSPEECH, P1098, DOI 10.21437/Interspeech.2017-1637
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Han MJ, 2013, IEEE T CYBERNETICS, V43, P1290, DOI 10.1109/TSMCB.2012.2228851
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hotelling H., 1992, Relations Between Two Sets of Variates, P162, DOI [DOI 10.1007/978-1-4612-4380-9, DOI 10.1007/978-1-4612-4380-914]
   Huang J, 2020, INT CONF ACOUST SPEE, P3507, DOI [10.1109/icassp40776.2020.9053762, 10.1109/ICASSP40776.2020.9053762]
   Huang ZC, 2019, INT CONF ACOUST SPEE, P5856, DOI 10.1109/ICASSP.2019.8682916
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Latif S, 2022, IEEE T AFFECT COMPUT, V13, P992, DOI 10.1109/TAFFC.2020.2983669
   Latif S, 2019, INTERSPEECH, P3920, DOI 10.21437/Interspeech.2019-3252
   Latif S, 2018, INTERSPEECH, P3107, DOI 10.21437/Interspeech.2018-1568
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li RN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5060
   Liang JJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2852, DOI 10.1145/3394171.3413579
   Liu W, 2019, Arxiv, DOI arXiv:1908.05349
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Pham H, 2019, AAAI CONF ARTIF INTE, P6892
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Sahu G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3156
   Sarkar P, 2022, IEEE T AFFECT COMPUT, V13, P1541, DOI 10.1109/TAFFC.2020.3014842
   Silberer C, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P721
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan T, 2018, IEEE-ACM T AUDIO SPE, V26, P1393, DOI 10.1109/TASLP.2018.2825432
   Tao J., 2009, Affective Information Processing
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291
   Wang P, 2017, IEEE T CIRC SYST VID, V27, P2613, DOI 10.1109/TCSVT.2016.2576761
   Wang ZL, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2514, DOI 10.1145/3366423.3380000
   Xiao YF, 2020, IEEE T EM TOP COMP I, V4, P480, DOI 10.1109/TETCI.2020.2972926
   Yu ZS, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4846
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5642
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhou HS, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P562, DOI 10.1145/3340555.3355713
NR 63
TC 17
Z9 17
U1 7
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2023
VL 25
BP 2213
EP 2225
DI 10.1109/TMM.2022.3144885
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA J1QV6
UT WOS:001007432100048
DA 2024-07-18
ER

PT J
AU Chen, YY
   Jiang, GY
   Jiang, ZD
   Yu, M
   Ho, YS
AF Chen, Yeyao
   Jiang, Gangyi
   Jiang, Zhidi
   Yu, Mei
   Ho, Yo-Sung
TI Deep Light Field Super-Resolution Using Frequency Domain Analysis and
   Semantic Prior
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Three-dimensional displays; Frequency-domain analysis; Superresolution;
   Semantics; Estimation; Light fields; Image restoration; Light field
   super-resolution; frequency domain transformation; semantic prior;
   convolutional neural network
ID IMAGE SUPERRESOLUTION; RESOLUTION; NETWORK; FUSION
AB Light field (LF) camera can simultaneously capture the intensity and direction information of light rays, which has been widely concerned. However, limited by the size of the imaging sensor, the captured LF image (LFI) has a trade-off between spatial and angular resolutions. To this end, this paper proposes a new LF super-resolution method using frequency domain analysis and semantic prior, which designs a two-stage learning framework to enhance the spatial and angular resolutions of LFI. Specifically, the proposed method first decomposes the spatial and angular information to explore the 4D structure of LFI by using frequency domain transformation, and formulates the LF super-resolution as a frequency restoration process. Then, the decomposed frequency components are recovered in a progressive restoration manner, with new cascaded 2D and 3D convolutional neural networks. To further improve the quality of the reconstructed LFI, especially at the object boundary, the semantic prior is incorporated into the designed network to enhance its representation ability. Finally, the super-resolved LFI is reconstructed by inverse frequency domain transformation. Experimental results show that the proposed method can effectively generate high-resolution LFI, and outperforms other state-of-the-art methods in terms of both subjective visual perception and objective quality evaluation. Moreover, the proposed method can enhance the performance of LF applications such as depth estimation.
C1 [Chen, Yeyao; Jiang, Gangyi; Jiang, Zhidi; Yu, Mei] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Ho, Yo-Sung] Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju 61005, South Korea.
C3 Ningbo University; Gwangju Institute of Science & Technology (GIST)
RP Jiang, GY; Yu, M (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM cyy941027@126.com; jianggangyi@nbr.edu.cn; jiangzhidi@nbu.edu.cn;
   yumei2@126.com; hoyo@gist.ac.kr
RI jiang, gang/KII-8233-2024
OI HO, YO-SUNG/0000-0002-7220-1034
FU Natural Science Foundation of China [62071266, 61871247, 61671258,
   61931022]; Natural Science Foundation of Ningbo [202003N4088]; K. C.
   Wong Magna Fund at Ningbo University
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 62071266, 61871247, 61671258, and 61931022, in part
   by the Natural Science Foundation of Ningbo under Grant 202003N4088, and
   in part by K. C. Wong Magna Fund at Ningbo University.
CR Alain M, 2018, IEEE IMAGE PROC, P2501, DOI 10.1109/ICIP.2018.8451162
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168
   Cheng Z, 2020, IEEE T CIRC SYST VID, V30, P2604, DOI 10.1109/TCSVT.2019.2921660
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Egiazarian K, 2015, EUR SIGNAL PR CONF, P2849, DOI 10.1109/EUSIPCO.2015.7362905
   Farrugia RA, 2020, IEEE T PATTERN ANAL, V42, P1162, DOI 10.1109/TPAMI.2019.2893666
   Farrugia RA, 2017, IEEE J-STSP, V11, P1058, DOI 10.1109/JSTSP.2017.2747127
   Ghassab VK, 2020, IEEE T MULTIMEDIA, V22, P1447, DOI 10.1109/TMM.2019.2946094
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gul MSK, 2018, IEEE T IMAGE PROCESS, V27, P2146, DOI 10.1109/TIP.2018.2794181
   Jayaweera SS, 2021, IEEE SIGNAL PROC LET, V28, P31, DOI 10.1109/LSP.2020.3043990
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Jin J, 2020, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR42600.2020.00233
   Jung H, 2020, IEEE T MULTIMEDIA, V22, P980, DOI 10.1109/TMM.2019.2934819
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]
   Kingma D. P., 2014, arXiv
   Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Le Pendu M, 2018, IEEE T IMAGE PROCESS, V27, P1981, DOI 10.1109/TIP.2018.2791864
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   lightfield, Lytro Illum Lytro Support Articles
   Lin GS, 2020, IEEE T PATTERN ANAL, V42, P1228, DOI 10.1109/TPAMI.2019.2893630
   Lin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P86, DOI 10.1007/978-3-030-58601-0_6
   Liu Ce, 2009, THESIS
   Liu CL, 2020, IEEE T IMAGE PROCESS, V29, P6630, DOI 10.1109/TIP.2020.2992354
   Ma DZ, 2020, IEEE IMAGE PROC, P2970, DOI 10.1109/ICIP40778.2020.9190751
   Meng N, 2020, AAAI CONF ARTIF INTE, V34, P11757
   Meng N, 2021, IEEE T PATTERN ANAL, V43, P873, DOI 10.1109/TPAMI.2019.2945027
   Mitra K., 2012, P IEEE COMP SOC C CO, P22
   Raj A. S., Stanford lytro light field archive
   Rerabek M., 2016, P 8 INT C QUAL MUL E
   Rossi M, 2018, IEEE T IMAGE PROCESS, V27, P4207, DOI 10.1109/TIP.2018.2828983
   Sepas-Moghaddam A, 2021, IEEE T INF FOREN SEC, V16, P1365, DOI 10.1109/TIFS.2020.3036242
   Shi JL, 2020, PROC CVPR IEEE, P2552, DOI 10.1109/CVPR42600.2020.00263
   Shidanshidi H, 2015, IEEE T MULTIMEDIA, V17, P1677, DOI 10.1109/TMM.2015.2447274
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Vagharshakyan S, 2018, IEEE T PATTERN ANAL, V40, P133, DOI 10.1109/TPAMI.2017.2653101
   Verhack R, 2020, IEEE T MULTIMEDIA, V22, P579, DOI 10.1109/TMM.2019.2932614
   Wang YQ, 2021, IEEE T IMAGE PROCESS, V30, P1057, DOI 10.1109/TIP.2020.3042059
   Wang YL, 2018, LECT NOTES COMPUT SC, V11206, P340, DOI 10.1007/978-3-030-01216-8_21
   Wang YL, 2018, IEEE T IMAGE PROCESS, V27, P4274, DOI 10.1109/TIP.2018.2834819
   Wanner S., 2013, INT S VIS MOD VIS, P225
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178
   Wu GC, 2019, IEEE T IMAGE PROCESS, V28, P3261, DOI 10.1109/TIP.2019.2895463
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Wu XY, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902987
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P328, DOI 10.1109/TMM.2018.2863602
   Yeung HWF, 2019, IEEE T IMAGE PROCESS, V28, P2319, DOI 10.1109/TIP.2018.2885236
   Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9
   Yingqian Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P290, DOI 10.1007/978-3-030-58592-1_18
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Yuan Y, 2018, IEEE SIGNAL PROC LET, V25, P1359, DOI 10.1109/LSP.2018.2856619
   Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329
   Zhang S, 2019, PROC CVPR IEEE, P11038, DOI 10.1109/CVPR.2019.01130
   Zhang ZT, 2015, PROC CVPR IEEE, P3800, DOI 10.1109/CVPR.2015.7299004
NR 57
TC 11
Z9 11
U1 2
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 3722
EP 3737
DI 10.1109/TMM.2021.3106775
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 3R1UG
UT WOS:000838704400005
DA 2024-07-18
ER

PT J
AU He, ZY
   Jin, Z
   Zhao, Y
AF He, Zongyao
   Jin, Zhi
   Zhao, Yao
TI SRDRL: A Blind Super-Resolution Framework With Degradation
   Reconstruction Loss
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Degradation; Kernel; Image reconstruction; Feature extraction; Noise
   level; Mathematical model; Training; Blind image super-resolution;
   degradation reconstruction loss; degradation simulator; without prior
   knowledge; multiple degradations
ID SINGLE-IMAGE SUPERRESOLUTION; NETWORK
AB Recent years have witnessed the remarkable success of deep learning-based single image super-resolution (SISR) methods. However, most of the existing SISR methods assume that low-resolution (LR) images are purely bicubic downsampled from high-resolution (HR) images. Once the actual degradation is not bicubic, their outstanding performance is hard to maintain. Since the real-world image degradation process can be modeled by a combination of downsampling, blurring, and noise, several SR methods have been proposed to super-resolve LR images with multiple blur kernels and noise levels. However, these SR methods require prior knowledge of the degradation process, which is difficult to obtain in practical applications. To address these issues, we propose a degradation reconstruction loss (DRL), which captures the degradation-wise differences between SR images and HR images via a degradation simulator. Empowered by the degradation simulator, the proposed loss, and an efficient SR network, a blind SR framework (SRDRL) without prior knowledge that can handle multiple degradations is formed. Extensive experimental results demonstrate that the proposed SRDRL outperforms the state-of-the-art blind SR methods and denosing+SR methods on multi-degraded datasets. The degradation reconstruction loss can be a plug-and-play loss for existing SR methods to handle multiple degradations. The source code can be found at https://github.com/FVL2020/SRDRL.
C1 [He, Zongyao; Jin, Zhi] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518107, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Robot & Digital Intelliget, Guangzhou 510535, Peoples R China.
   [Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Zhao, Yao] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Sun Yat Sen University; Beijing Jiaotong University; Beijing Jiaotong
   University
RP Jin, Z (corresponding author), Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518107, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Robot & Digital Intelliget, Guangzhou 510535, Peoples R China.
EM hezy28@mail2.sysu.edu.cn; jinzh26@mail.sysu.edu.cn; yzhao@bjtu.edu.cn
RI Jin, Zhi/AAB-2440-2022; He, Zongyao/KFS-4114-2024
OI Jin, Zhi/0000-0001-9670-7366; Zhao, Yao/0000-0002-8581-9554
FU National Key Research and Development of China [2018AAA0102100];
   National Natural Science Foundation of China [U1936212, 62071500,
   61701313]
FX This work was supported in part by the National Key Research and
   Development of China under Grant 2018AAA0102100, in part by the National
   Natural Science Foundation of China under Grants U1936212, 62071500, and
   61701313.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bruna J., 2016, ICLR, P1
   Bulat A, 2018, LECT NOTES COMPUT SC, V11210, P187, DOI 10.1007/978-3-030-01231-1_12
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JJ, 2019, PROC CVPR IEEE, P1604, DOI 10.1109/CVPR.2019.00170
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang Y., 2020, ADV NEURIPS, V33
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jin Z, 2021, IEEE T CIRC SYST VID, V31, P467, DOI 10.1109/TCSVT.2020.2982174
   Jin Z, 2020, IEEE T MULTIMEDIA, V22, P1055, DOI 10.1109/TMM.2019.2938340
   Johnson, 2012, MATRIX ANAL
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lugmayr A, 2020, IEEE COMPUT SOC CONF, P2058, DOI 10.1109/CVPRW50498.2020.00255
   Ma JY, 2020, IEEE T IND ELECTRON, V67, P5687, DOI 10.1109/TIE.2019.2934071
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Simonyan K., 2014, 14091556 ARXIV
   Singh A, 2014, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2014.364
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yi P, 2022, IEEE T PATTERN ANAL, V44, P2264, DOI 10.1109/TPAMI.2020.3042298
   Yuan Y, 2018, IEEE COMPUT SOC CONF, P814, DOI 10.1109/CVPRW.2018.00113
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HR, 2021, IEEE J-STSP, V15, P253, DOI 10.1109/JSTSP.2020.3045282
   Zhang HR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2113, DOI 10.1145/3394171.3413664
   Zhang K, 2019, PROC CVPR IEEE, P1671, DOI 10.1109/CVPR.2019.00177
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang W, 2018, IEEE CONF COMPUT
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 42
TC 9
Z9 9
U1 4
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 2877
EP 2889
DI 10.1109/TMM.2021.3090166
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 2A3LX
UT WOS:000809408000015
DA 2024-07-18
ER

PT J
AU Ngo, LM
   Karaoglu, S
   Gevers, T
AF Le Minh Ngo
   Karaoglu, Sezer
   Gevers, Theo
TI Self-Supervised Face Image Manipulation by Conditioning GAN on Face
   Decomposition
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Faces; Lighting; Training; Generative adversarial networks; Image
   reconstruction; Gallium nitride; Face recognition; Deep learning; face;
   generative adversarial networks; neural networks
AB We present a novel architecture for manipulating facial expressions, head poses, and lighting conditions from a single monocular image. Recent methods based on Generative Adversarial Networks show promising results in expression manipulation. However, the variation is either defined by a limited number of classes or not well suitable for explicit manipulation of different attributes such as pose and lighting conditions. Besides, state-of-the-art methods are mostly focused on frontal faces. Therefore, in this paper, a new Generative Adversarial Network architecture is proposed by explicitly conditioning on the appearance image space which is the product of direct manipulation of facial expressions, light and pose conditions of the face model in 3D space. In addition, the method only requires video sequences for training. Therefore, it is self-supervised. Unlike other face manipulation methods, the proposed method does not require target specific training. Large scale experiments show that our method outperforms state-of-the-art methods for different scenarios.
C1 [Le Minh Ngo; Karaoglu, Sezer; Gevers, Theo] Univ Amsterdam, Comp Vis Lab, NL-1098 XH Amsterdam, Netherlands.
   [Le Minh Ngo; Karaoglu, Sezer; Gevers, Theo] 3DUniversum, NL-1098 XH Amsterdam, Netherlands.
C3 University of Amsterdam
RP Ngo, LM (corresponding author), Univ Amsterdam, Comp Vis Lab, NL-1098 XH Amsterdam, Netherlands.; Ngo, LM (corresponding author), 3DUniversum, NL-1098 XH Amsterdam, Netherlands.
EM l.m.ngo@uva.nl; s.karaoglu@uva.nl; th.gevers@uva.nl
OI Ngo, Minh/0000-0002-3810-1136
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2018, The gan landscape: Losses, architectures, regularization, and normalization
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Baltrusaitis T, 2015, IEEE INT CONF AUTOMA
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen HJ, 2019, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR.2019.01028
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chrysos GG, 2018, INT J COMPUT VISION, V126, P198, DOI 10.1007/s11263-017-0999-5
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Diamant N, 2019, IEEE IMAGE PROC, P739, DOI [10.1109/icip.2019.8803807, 10.1109/ICIP.2019.8803807]
   Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Han XJ, 2020, IEEE T MULTIMEDIA, V22, P1619, DOI 10.1109/TMM.2019.2945197
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Heusel M., 2017, ADV NEURAL INFORM PR, P6626
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim H, 2018, PROC CVPR IEEE, P4625, DOI 10.1109/CVPR.2018.00486
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D.P., 2014, ARXIV14126980
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lettry L, 2018, IEEE WINT CONF APPL, P1359, DOI 10.1109/WACV.2018.00153
   Li C, 2019, IEEE T PATTERN ANAL, V41, P1455, DOI 10.1109/TPAMI.2018.2832059
   Lim J. H., 2017, Geometric gan
   Liu Y., 2019, ABS191106531 ARXIV
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mahajan D, 2018, J MACH LEARN RES, V19
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T, 2018, INT C LEARN REPR
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Pumarola A, 2018, PROC CVPR IEEE, P8620, DOI 10.1109/CVPR.2018.00899
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Sanchez E, 2020, IEEE INT CONF AUTOMA, P53, DOI 10.1109/FG47880.2020.00015
   Siarohin A, 2019, ADV NEUR IN, V32
   Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270
   Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wu WN, 2018, LECT NOTES COMPUT SC, V11205, P622, DOI 10.1007/978-3-030-01246-5_37
   Xu WJ, 2019, IEEE T MULTIMEDIA, V21, P2387, DOI 10.1109/TMM.2019.2898777
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zakharov Egor, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P524, DOI 10.1007/978-3-030-58610-2_31
   Zhou YF, 2019, IEEE T MULTIMEDIA, V21, P3136, DOI 10.1109/TMM.2019.2920613
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 54
TC 16
Z9 17
U1 2
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 377
EP 385
DI 10.1109/TMM.2021.3050672
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA YK9LD
UT WOS:000745524300029
DA 2024-07-18
ER

PT J
AU Parvaneh, A
   Abbasnejad, E
   Wu, Q
   Shi, JQ
   van den Hengel, A
AF Parvaneh, Amin
   Abbasnejad, Ehsan
   Wu, Qi
   Shi, Javen Qinfeng
   van den Hengel, Anton
TI Show, Price and Negotiate: A Negotiator With Online Value Look-Ahead
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Visualization; Decoding; Australia; Task analysis; Neural networks;
   History; Estimation; Goal-oriented dialogue system; modular deep neural
   networks; online value estimation; reinforcement learning; visual
   negotiation
ID SEEKING SPOKEN DIALOGUE; SYSTEMS
AB Negotiation, as an essential and complicated aspect of online shopping, is still challenging for an intelligent agent. To that end, we propose the Price Negotiator, a modular deep neural network that addresses the unsolved problems in recent studies by (1) considering images of the items as a crucial, though neglected, source of information in a negotiation, (2) heuristically finding the most similar items from an external online source to predict the potential value and an acceptable agreement price, (3) predicting a general price-based "action" at each turn which is fed into the language generator to output the supporting natural language, and (4) adjusting the prices based on the predicted actions. Empirically, we show that our model, that is trained in both supervised and reinforcement learning setting, significantly improves negotiation on the CraigslistBargain dataset, in terms of the agreement price, price consistency, and dialogue quality.
C1 [Parvaneh, Amin; Abbasnejad, Ehsan; Wu, Qi; Shi, Javen Qinfeng; van den Hengel, Anton] Univ Adelaide, Australian Inst Machine Learning, Adelaide, SA 5005, Australia.
C3 University of Adelaide
RP Parvaneh, A (corresponding author), Univ Adelaide, Australian Inst Machine Learning, Adelaide, SA 5005, Australia.
EM amin.parvaneh@adelaide.edu.au; ehsan.abbasnejad@adelaide.edu.au;
   qi.wu01@adelaide.edu.au; javen.shi@adelaide.edu.au;
   anton.vandenhengel@adelaide.edu.au
RI Wu, Qi/ABD-6304-2021
OI Wu, Qi/0000-0003-3631-256X; van den Hengel, Anton/0000-0003-3027-8364;
   Shi, Javen Qinfeng/0000-0002-9126-2107
CR Abbasnejad E, 2019, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2019.00428
   Ammicht E, 2007, IEEE T MULTIMEDIA, V9, P532, DOI 10.1109/TMM.2006.888011
   [Anonymous], 2017, P INT C LEARN REPR
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/D15-1166, DOI 10.48550/ARXIV.1508.04025]
   Cuayahuitl H., 2015, ARXIV151108099V1
   Das A, 2017, IEEE I CONF COMP VIS, P2970, DOI 10.1109/ICCV.2017.321
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475
   de Vries Harm, 2018, Talk the walk: Navigating grids in new york city through grounded dialogue
   Devlin J., 2018, BERT PRE TRAINING DE
   Dhingra B, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P484, DOI 10.18653/v1/P17-1045
   Dusek O., 2016, P 17 ANN M SPEC INT, P185
   El Asri L, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017)
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   He H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2333
   He H, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1766, DOI 10.18653/v1/P17-1162
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Jooyoung Lee SeunghyunCho., 2019, ICLR
   Kottur S., 2019, NAACL HLT
   Lee SW, 2018, ADV NEUR IN, V31
   Lewis M., 2017, P EMNLP
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Li X., 2017, P 8 INT JOINT C NAT, V1, P733
   Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P801, DOI 10.1145/3240508.3240605
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Potamianos A, 2007, IEEE T MULTIMEDIA, V9, P550, DOI 10.1109/TMM.2006.887999
   Reddy S., 2018, ARXIV180807042V1
   Saha A, 2018, AAAI CONF ARTIF INTE, P696
   Sordoni Alessandro, 2015, A hierarchical recurrent encoder-decoder for generative context-aware query suggestion, P553
   Sukhbaatar S, 2015, ADV NEURAL INFORM PR, V28, P2440
   Tang JH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5624
   Tsai TJ, 2015, IEEE T MULTIMEDIA, V17, P1550, DOI 10.1109/TMM.2015.2454332
   Wang XW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5635
   Wei W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3844
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xing C., 2018, P AAAI C ART INT
   Xu L, 2019, AAAI CONF ARTIF INTE, P7346
   Zue VW, 2000, P IEEE, V88, P1166, DOI 10.1109/5.880078
NR 43
TC 1
Z9 1
U1 2
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 1426
EP 1434
DI 10.1109/TMM.2021.3065169
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 0D8GN
UT WOS:000776227200015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, SK
   Gan, T
   Liu, Y
   Zhang, L
   Wu, JL
   Nie, LQ
AF Wang, Shaokun
   Gan, Tian
   Liu, Yuan
   Zhang, Li
   Wu, JianLong
   Nie, Liqiang
TI Discover Micro-Influencers for Brands via Better Understanding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Social networking (online); Semantics; Task analysis; Media; Cameras;
   Visualization; Bidirectional control; Influencer marketing;
   interpretable recommendation; multimodal
AB With the rapid development of the influencer marketing industry in recent years, the cooperation between brands and micro-influencers on marketing has achieved much attention. As a key sub-task of influencer marketing, micro-influencer recommendation is gaining momentum. However, in influencer marketing campaigns, it is not enough to only consider marketing effectiveness. Towards this end, we propose a concept-based micro-influencer ranking framework, to address the problems of marketing effectiveness and self-development needs for the task of micro-influencer recommendation. Marketing effectiveness is improved by concept-based social media account representation and a micro-influencer ranking function. We conduct social media account representation from the perspective of historical activities and marketing direction. And two adaptive learned metrics, endorsement effect score and micro-influencer influence score, are defined to learn the micro-influencer ranking function. To meet self-development needs, we design a bi-directional concept attention mechanism to focus on brands' and micro-influencers' marketing direction over social media concepts. Interpretable concept-based parameters are utilized to help brands and micro-influencers make marketing decisions. Extensive experiments conducted on a real-world dataset demonstrate the advantage of our proposed method compared with the state-of-the-art methods.
C1 [Wang, Shaokun; Gan, Tian; Liu, Yuan; Zhang, Li; Wu, JianLong; Nie, Liqiang] Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Peoples R China.
C3 Shandong University
RP Gan, T (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Peoples R China.
EM shaokunwang.sdu@gmail.com; gantian@sdu.edu.cn;
   lizhang.nus2010@gmail.com; lizhang.nus@gmail.com; jlwu1992@pku.edu.cn;
   nieliqiang@gmail.com
RI wang, shaokun/KIE-8291-2024
OI Wang, Shaokun/0000-0001-8945-1200
FU National Natural Science Foundation of China [U1936203]
FX This work was supported by the National Natural Science Foundation of
   China, under Grant U1936203. The associate editor coordinating the
   review of this manuscript and approving it for publicationwas Prof.
   Abderrahim Benslimane.
CR Anger Isabel, 2011, P 11 INT C KNOWL MAN, P1
   [Anonymous], 2016, INFLUENCER MARKETING
   Ashley C, 2015, PSYCHOL MARKET, V32, P15, DOI 10.1002/mar.20761
   Bonomo M., 2019, ARXIV190701326
   Cha M., 2010, P INT AAAI C WEB SOC, V4, P10, DOI DOI 10.1145/2897659.2897663
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cossu JV, 2015, SECOND EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2015), P83, DOI 10.1109/ENIC.2015.20
   Dolan R, 2016, J STRATEG MARK, V24, P261, DOI 10.1080/0965254X.2015.1095222
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P2281, DOI 10.1109/TMM.2015.2491019
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P1031, DOI 10.1109/TMM.2015.2430819
   Fang Q, 2014, IEEE T MULTIMEDIA, V16, P796, DOI 10.1109/TMM.2014.2298216
   Felix R, 2017, J BUS RES, V70, P118, DOI 10.1016/j.jbusres.2016.05.001
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gan T, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1933, DOI 10.1145/3343031.3351080
   Gao JY, 2019, AAAI CONF ARTIF INTE, P3622
   Gao YF, 2019, AAAI CONF ARTIF INTE, P6415
   Gelli F, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P465, DOI 10.1145/3240508.3240689
   Gilbert L. G., 2020, CHANCELLORS HONORS P
   Gilpin Leilani H, 2018, ARXIV180600069
   Han XJ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P785, DOI 10.1145/3331184.3331245
   Hollebeek LD, 2019, J ACAD MARKET SCI, V47, P161, DOI 10.1007/s11747-016-0494-5
   Hou M, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4681
   Hui Chen, 2019, MM '19: Proceedings of the 27th ACM International Conference on Multimedia, P1749, DOI 10.1145/3343031.3351055
   Hussain Z, 2017, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2017.123
   I. M. Hub, 2019, STATE INFLUENCER MAR
   Li YM, 2011, INFORM SCIENCES, V181, P5143, DOI 10.1016/j.ins.2011.07.023
   Luo XS, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P313, DOI 10.1145/3318464.3386132
   Michaelidou N, 2011, IND MARKET MANAG, V40, P1153, DOI 10.1016/j.indmarman.2011.09.009
   Narassiguin Anil, 2019, ARXIV190605911
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peake G, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2060, DOI 10.1145/3219819.3220072
   Rao A, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2282, DOI 10.1109/BigData.2015.7364017
   Ren M., 2015, Proc Adv Neural Inf Process Syst, V1, P5
   Ribeiro M.T., 2016, ARXIV
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Segev N, 2018, ACM/SIGIR PROCEEDINGS 2018, P1009, DOI 10.1145/3209978.3210134
   Sweet Taylor, 2019, ARXIV190105949
   Woods S., 2016, CHANCELLORS HONORS P
   Wu HZ, 2020, AAAI CONF ARTIF INTE, V34, P254
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhang YF, 2020, FOUND TRENDS INF RET, V14, P1, DOI 10.1561/1500000066
NR 42
TC 6
Z9 6
U1 12
U2 72
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 2595
EP 2605
DI 10.1109/TMM.2021.3087038
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 1D5KQ
UT WOS:000793839600027
DA 2024-07-18
ER

PT J
AU Wu, S
   Xu, Y
   Zhang, B
   Yang, J
   Zhang, D
AF Wu, Shuai
   Xu, Yong
   Zhang, Bob
   Yang, Jian
   Zhang, David
TI Deformable Template Network (DTN) for Object Detection
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE object detection; deformable template; part matching; deformation cost
ID JOINT DEEP; TRACKING
AB Objects often have different appearances because of viewpoint changes or part deformation. How to reasonably model these variations is still a big challenge for object detection. In this paper, we propose a novel Deformable Template Network (DTN), which exploits the pictorial structure to model possible variations of an object. DTN represents an object by virtue of a generated template in a deformable way. It has two key modules: the template generating module and the part matching module. The template generating module produces a template for a given object which defines the anchor positions of the k X k parts. Based on such a template, the part matching module aims to perform part alignment around the anchor positions. In terms of each part, the matching process makes a trade-off between maximizing the detection score and minimizing the deformation cost relative to the anchor position. Moreover, DTN is a fully convolutional network which means it is competitive in terms of detection efficiency. We evaluate DTN on both the PASCAL VOC and MSCOCO datasets, achieving the state-of-the-art results, an accuracy of 82.7% for PASCAL VOC and of 44.9% for MSCOCO.
C1 [Wu, Shuai; Xu, Yong] Harbin Inst Technol, Biocomp Res Ctr, Shenzhen 518055, Peoples R China.
   [Xu, Yong] Shen Zhen Key Lab Visual Object Detect & Recog, Shenzhen, Peoples R China.
   [Zhang, Bob] Univ Macau, PAMI Res Grp, Taipa 999078, Madhya Pradesh, Peoples R China.
   [Yang, Jian] Nan Jing Univ Sci & Technol, Coll Comp Sci & Technol, Nanjing 210094, Peoples R China.
   [Zhang, David] Chinese Univ Hong Kong Shen Zhen, Sch Sci & Engn, Shenzhen 518172, Peoples R China.
   [Zhang, David] Shen Zhen Res Inst Big Data, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; University of Macau; Nanjing University
   of Science & Technology; The Chinese University of Hong Kong, Shenzhen
RP Xu, Y (corresponding author), Harbin Inst Technol, Biocomp Res Ctr, Shenzhen 518055, Peoples R China.
EM shuaiwu9@gmail.com; yongxu@ymail.com; bobzhang@um.edu.mo;
   csjyang@mail.njust.edu.cn; davidzhang@cuhk.edu.cn
RI Zhang, Bob/ABD-5926-2021; Zhang, David D/O-9396-2016; Zhang,
   David/AEM-1699-2022; Zhang, Bob/HIR-3656-2022
OI Zhang, Bob/0000-0003-2497-9519; Zhang, David D/0000-0002-5027-5286;
   Zhang, Bob/0000-0001-6512-0474
FU National Natural Science Foundation of China [61876051]; Fundamental
   Research Foundation of ShenZhen [JCYJ20180306172101694]; University of
   Macau [MYRG2018-00053-FST]
FX The work was supported in part by the National Natural Science
   Foundation of China under Grant 61876051, and in part by the Fundamental
   Research Foundation of ShenZhen underGrant JCYJ20180306172101694, and in
   part the University of Macau under Grant MYRG2018-00053-FST.
CR [Anonymous], 2014, P EUR C COMP VIS PAR
   [Anonymous], 2016, ARXIV161203897
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chen CL, 2019, IEEE T MULTIMEDIA, V21, P3205, DOI 10.1109/TMM.2019.2916104
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Henaff G., 2017, P BRIT MACH VIS C
   Hu HW, 2019, IEEE T MULTIMEDIA, V21, P510, DOI 10.1109/TMM.2018.2859831
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang GL, 2017, IEEE ICC
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jin Z, 2020, IEEE T MULTIMEDIA, V22, P1055, DOI 10.1109/TMM.2019.2938340
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li J, 2019, IEEE T MULTIMEDIA, V21, P2531, DOI 10.1109/TMM.2019.2908350
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Luo WJ, 2016, ADV NEUR IN, V29
   Lyu F, 2019, IEEE T MULTIMEDIA, V21, P1971, DOI 10.1109/TMM.2019.2894964
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan JH, 2019, IEEE T MULTIMEDIA, V21, P2686, DOI 10.1109/TMM.2019.2904878
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wan L, 2015, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2015.7298686
   Wang H, 2018, PROC CVPR IEEE, P1248, DOI 10.1109/CVPR.2018.00136
   Wen J, 2019, IEEE T CYBERNETICS, V49, P1279, DOI 10.1109/TCYB.2018.2799862
   Wu S, 2020, IEEE T CIRC SYST VID, V30, P2057, DOI 10.1109/TCSVT.2019.2905373
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang M, 2019, IEEE T MULTIMEDIA, V21, P1047, DOI 10.1109/TMM.2018.2869276
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 59
TC 17
Z9 17
U1 2
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 2058
EP 2068
DI 10.1109/TMM.2021.3075323
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 0H8DA
UT WOS:000778959200022
DA 2024-07-18
ER

PT J
AU Yin, YF
   Zhang, Y
   Liu, ZG
   Wang, S
   Shah, RR
   Zimmermann, R
AF Yin, Yifang
   Zhang, Ying
   Liu, Zhenguang
   Wang, Sheng
   Shah, Rajiv Ratn
   Zimmermann, Roger
TI GPS2Vec: Pre-Trained Semantic Embeddings for Worldwide GPS Coordinates
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Global Positioning System; Encoding; Semantics; Feature extraction;
   Visualization; Real-time systems; Neural networks; GPS; geo-aware
   applications; neural networks; semantic embedding
ID FEATURES; CLASSIFICATION
AB GPS coordinates are fine-grained location indicators that are difficult to be effectively utilized by classifiers in geo-aware applications. Previous GPS encoding methods concentrate on generating hand-crafted features for small areas of interest. However, many real world applications require a machine learning model, analogous to the pre-trained ImageNet model for images, that can efficiently generate semantically-enriched features for planet-scale GPS coordinates. To address this issue, we propose a novel two-level grid-based framework, termed GPS2Vec, which is able to extract geo-aware features in real-time for locations worldwide. The Earth's surface is first discretized by the Universal Transverse Mercator (UTM) coordinate system. Each UTM zone is then considered as a local area of interest that is further divided into fine-grained cells to perform the initial GPS encoding. We train a neural network in each UTM zone to learn the semantic embeddings from the initial GPS encoding. The training labels can be automatically derived from large-scale geotagged documents such as tweets, check-ins, and images that are available from social sharing platforms. We conducted comprehensive experiments on three geo-aware applications, namely place semantic annotation, geotagged image classification, and next location prediction. Experimental results demonstrate the effectiveness of our approach, as prediction accuracy improves significantly based on a simple multi-feature early fusion strategy with deep neural networks, including both CNNs and RNNs.
C1 [Yin, Yifang; Wang, Sheng; Zimmermann, Roger] Natl Univ Singapore, Singapore 117602, Singapore.
   [Zhang, Ying] Northwestern Polytech Univ, Xian 710072, Peoples R China.
   [Liu, Zhenguang] Zhejiang Gongshang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Sheng] Alibaba Grp, Singapore 068811, Singapore.
   [Shah, Rajiv Ratn] IIT Delhi, Delhi 110020, India.
C3 National University of Singapore; Northwestern Polytechnical University;
   Zhejiang Gongshang University; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Delhi
RP Liu, ZG (corresponding author), Zhejiang Gongshang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
EM idsyin@nus.edu.sg; yingz118@gmail.com; liuzhenguang2008@gmail.com;
   sh.wang@alibaba-inc.com; rajivratn@iiitd.ac.in; rogerz@comp.nus.edu.sg
RI Zimmermann, Roger/D-7944-2015
OI Zimmermann, Roger/0000-0002-7410-2590
FU Singapore Ministry of Education Academic Research Fund Tier 2 under MOEs
   official [MOE2018-T2-1-103]
FX This work was supported by Singapore Ministry of Education Academic
   Research Fund Tier 2 under MOEs official under Grant MOE2018-T2-1-103.
CR [Anonymous], 2009, P ACM INT C IM VID R
   Christie G, 2018, PROC CVPR IEEE, P6172, DOI 10.1109/CVPR.2018.00646
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Dalal N, 2005, P CVPR, P01
   Dolatshah M., 2015, ARXIV151100628
   Joshi D., 2008, P INT C CONTENT BASE, P37
   KeSSler C., 2009, Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, P91
   Krumm J, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P163
   Liao S, 2015, IEEE T MULTIMEDIA, V17, P1058, DOI 10.1109/TMM.2015.2436057
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu Q, 2016, AAAI CONF ARTIF INTE, P194
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maji S, 2008, PROC CVPR IEEE, P2245
   Mathew W, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P911
   Mousselly-Sergieh H., 2014, PROC MMSYS, P47, DOI DOI 10.1145/2557642.2563673
   Moxley Emily., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, P24
   Nghia DT, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1973, DOI 10.1145/2983323.2983887
   Park E, 2016, IEEE WINT CONF APPL
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Salem T., 2020, CVPR, P12435
   Shah RR, 2016, KNOWL-BASED SYST, V108, P102, DOI 10.1016/j.knosys.2016.05.022
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders A. W. M., 2012, PACIFIC ASIA C KNOWL
   Spruyt V, 2018, Loc2vec: Learning location embeddings with triplet-loss networks
   Tang K, 2015, IEEE I CONF COMP VIS, P1008, DOI 10.1109/ICCV.2015.121
   Wang DF, 2016, ACTA ASTRONAUT, V118, P218, DOI 10.1016/j.actaastro.2015.10.012
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Wang H., 2013, P 21 ACM SIGSPATIAL, P364
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Workman S, 2015, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2015.451
   Wu XZ, 2017, PR MACH LEARN RES, V70
   Yan B, 2017, 25TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2017), DOI 10.1145/3139958.3140054
   Yang DQ, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2814575
   Yang DQ, 2015, J NETW COMPUT APPL, V55, P170, DOI 10.1016/j.jnca.2015.05.010
   Yao D, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2411, DOI 10.1145/3132847.3133056
   Ye M., 2011, P 17 ACM SIGKDD INT, P520
   Yin Y, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), P416, DOI 10.1145/3347146.3359067
   Yin YF, 2017, IEEE INT CON MULTI, P1015, DOI 10.1109/ICME.2017.8019376
   Yin YF, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700287
   Zhang C, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1305, DOI 10.1145/2939672.2939793
   Zhang C, 2014, PROC VLDB ENDOW, V7, P769, DOI 10.14778/2732939.2732949
   Zhang Y, 2016, IEEE T MULTIMEDIA, V18, P418, DOI 10.1109/TMM.2016.2520827
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zubiaga A, 2017, IEEE T KNOWL DATA EN, V29, P2053, DOI 10.1109/TKDE.2017.2698463
NR 45
TC 3
Z9 3
U1 1
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 890
EP 903
DI 10.1109/TMM.2021.3060951
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA YW5XZ
UT WOS:000753488100029
DA 2024-07-18
ER

PT J
AU Zhang, PF
   Li, Y
   Huang, Z
   Xu, XS
AF Zhang, Peng-Fei
   Li, Yang
   Huang, Zi
   Xu, Xin-Shun
TI Aggregation-Based Graph Convolutional Hashing for Unsupervised
   Cross-Modal Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Semantics; Convolutional codes; Binary codes; Convolution; Measurement;
   Feature extraction; Sparse matrices; Multimodal; unsupervised hashing;
   cross-modal search; graph convolutional networks
ID BINARY-CODES; ROBUST
AB Cross-modal hashing has sparked much attention in large-scale information retrieval for its storage and query efficiency. Despite the great success achieved by supervised approaches, existing unsupervised hashing methods still suffer from the lack of reliable learning guidance and cross-modal discrepancy. In this paper, we propose Aggregation-based Graph Convolutional Hashing (AGCH) to tackle these obstacles. First, considering that a single similarity metric can hardly represent data relationships comprehensively, we develop an efficient aggregation strategy that utilises multiple metrics to construct a more precise affinity matrix for learning. Specifically, we apply various similarity measures to exploit the structural information of multiple modalities from different perspectives and then aggregate the obtained information to produce a joint similarity matrix. Furthermore, a novel deep model is designed to learn unified binary codes across different modalities, where the key components include modality-specific encoders, Graph Convolutional Networks (GCNs) and a fusion module. The modality-specific encoders are tasked to learn feature embeddings for each individual modality. On this basis, we leverage GCNs to further excavate the semantic structure of data, along with a fusion module to correlate different modalities. Extensive experiments on three real-world datasets demonstrate that the proposed method significantly outperforms the state-of-the-art competitors.
C1 [Zhang, Peng-Fei; Li, Yang; Huang, Zi] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
   [Xu, Xin-Shun] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
C3 University of Queensland; Shandong University
RP Huang, Z (corresponding author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
EM mima.zpf@gmail.com; yang.li@uq.edu.au; huang@itee.uq.edu.au;
   xuxinshun@sdu.edu.cn
OI Zhang, Peng-Fei/0000-0002-6790-2098; HUANG, ZI/0000-0002-9738-4949
FU Australian Research Council [ARC DP190102353]; China Scholarship Council
FX This work was supported in part by Australian Research Council Discovery
   Project ARC DP190102353 and in part by China Scholarship Council. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Prof. Lamberto Ballan.
CR [Anonymous], 2012, NIPS
   [Anonymous], 2012, NEURIPS
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2012, P INT C NEUR INF PRO
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hu D, 2019, IEEE T MULTIMEDIA, V21, P973, DOI 10.1109/TMM.2018.2866771
   Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144
   Hu P, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P635, DOI 10.1145/3331184.3331213
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Kipf TN, 2016, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li C, 2018, DES AUT CON, DOI 10.1145/3195970.3196091
   Li WJ, 2016, IJCAI, P1711
   Lin MB, 2020, IEEE T IMAGE PROCESS, V29, P5289, DOI 10.1109/TIP.2020.2981879
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Luo X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2518
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Mu Y, 2017, AAAI CONF ARTIF INTE, P2380
   Ng WWY, 2019, IEEE T CYBERNETICS, V49, P3844, DOI 10.1109/TCYB.2018.2846760
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205
   Shen HT, 2021, IEEE T KNOWL DATA EN, V33, P3351, DOI [10.1109/TKDE.2020.2970050, 10.1109/TNNLS.2020.2995708]
   Shen HT, 2009, VLDB J, V18, P329, DOI 10.1007/s00778-008-0101-6
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song JK, 2014, IEEE T CYBERNETICS, V44, P1225, DOI 10.1109/TCYB.2013.2289351
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Su SP, 2019, IEEE I CONF COMP VIS, P3027, DOI 10.1109/ICCV.2019.00312
   Velikoli, 2017, ARXIV171010903
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291
   Wang D, 2018, IEEE T CIRC SYST VID, V28, P2703, DOI 10.1109/TCSVT.2017.2723302
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang XC, 2011, IEEE T IMAGE PROCESS, V20, P2627, DOI 10.1109/TIP.2011.2114354
   Wang ZJ, 2021, IEEE T MULTIMEDIA, V23, P1274, DOI 10.1109/TMM.2020.2995267
   Wang ZJ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P905, DOI 10.1145/3331184.3331275
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Wu BT, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3946
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2854
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Xu RQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P982
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Yang Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1286, DOI 10.1145/2964284.2964319
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang Z, 2019, AAAI CONF ARTIF INTE, P5853
   Zhang Z, 2019, IEEE T IMAGE PROCESS, V28, P4803, DOI 10.1109/TIP.2019.2912290
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhou X, 2020, IEEE T CYBERNETICS, V50, P1460, DOI 10.1109/TCYB.2018.2883970
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
NR 73
TC 67
Z9 70
U1 6
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 466
EP 479
DI 10.1109/TMM.2021.3053766
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA YK9LD
UT WOS:000745524300036
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Zhu, B
   Ngo, CW
   Chan, WK
AF Zhu, Bin
   Ngo, Chong-Wah
   Chan, Wing-Kwong
TI Learning From Web Recipe-Image Pairs for Food Recognition: Problem,
   Baselines and Performance
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image recognition; Training; Generative adversarial networks; Feature
   extraction; Visualization; Data models; Context modeling; Food
   recognition; image-to-recipe retrieval; image-to-image retrieval
AB Cross-modal recipe retrieval has recently been explored for food recognition and understanding. Text-rich recipe provides not only visual content information (e.g., ingredients, dish presentation) but also procedure of food preparation (cutting and cooking styles). The paired data is leveraged to train deep models to retrieve recipes for food images. Most recipes on the Web include sample pictures as the references. The paired multimedia data is not noise-free, due to errors such as pairing of images containing partially prepared dishes with recipes. The content of recipes and food images are not always consistent due to free-style writing and preparation of food in different environments. As a consequence, the effectiveness of learning cross-modal deep models from such noisy web data is questionable. This paper conducts an empirical study to provide insights whether the features learnt with noisy pair data are resilient and could capture the modality correspondence between visual and text.
C1 [Zhu, Bin; Chan, Wing-Kwong] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Ngo, Chong-Wah] Singapore Management Univ, Sch Comp & Informat Syst, Singapore 178902, Singapore.
C3 City University of Hong Kong; Singapore Management University
RP Zhu, B (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM andrewzhu1216@gmail.com; cwngo@smu.edu.sg; wkchan@cityu.edu.hk
RI Chan, Wah Kheong/AGA-6636-2022
OI Chan, Wah Kheong/0000-0002-9105-5837; Chan, Wing
   Kwong/0000-0001-7726-6235; ZHU, Bin/0000-0002-9213-2611
FU Research grants Council of the Hong Kong Special Administrative Region,
   China [CityU 11203517]; CityU MF_EXT [9678180]
FX This work was supported by a grant from the Research grants Council of
   the Hong Kong Special Administrative Region, China, under Grant CityU
   11203517 and in part by CityU MF_EXT under Project 9678180. The
   associate editor coordinating the reviewof this manuscript and approving
   it for publication was Dr. Hua, Xian-Sheng.
CR Aguilar E, 2018, IEEE T MULTIMEDIA, V20, P3266, DOI 10.1109/TMM.2018.2831627
   Aizawa K, 2013, IEEE T MULTIMEDIA, V15, P2176, DOI 10.1109/TMM.2013.2271474
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beijbom O, 2015, IEEE WINT CONF APPL, P844, DOI 10.1109/WACV.2015.117
   Bolaños M, 2017, LECT NOTES COMPUT SC, V10590, P394, DOI 10.1007/978-3-319-70742-6_37
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Breiman L., 2001, Mach. Learn., V45, P5
   Caplan P., 2013, Food, health and identity
   Carvalho M, 2018, ACM/SIGIR PROCEEDINGS 2018, P35, DOI 10.1145/3209978.3210036
   Chen JJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1020, DOI 10.1145/3240508.3240627
   Chen JJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1771, DOI 10.1145/3123266.3123428
   Chen JJ, 2020, AAAI CONF ARTIF INTE, V34, P10542
   Chen JJ, 2021, IEEE T IMAGE PROCESS, V30, P1514, DOI 10.1109/TIP.2020.3045639
   Chen JJ, 2017, LECT NOTES COMPUT SC, V10132, P588, DOI 10.1007/978-3-319-51811-4_48
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen M, 2009, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2009.5413511
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fieldhouse Paul., 2013, FOOD NUTR CUSTOMS CU
   Fu H., 2020, PROC IEEECVF C COMPU, p14 570
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2017, IEEE T MULTIMEDIA, V19, P430, DOI 10.1109/TMM.2016.2614861
   Horiguchi S, 2018, IEEE T MULTIMEDIA, V20, P2836, DOI 10.1109/TMM.2018.2814339
   Jiang SQ, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3391624
   Kawano Y, 2015, LECT NOTES COMPUT SC, V8927, P3, DOI 10.1007/978-3-319-16199-0_1
   Kawano Y, 2013, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW.2013.5
   Kingma D.P., 2014, ARXIV14126980
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Loring PA, 2009, ENVIRON SCI POLICY, V12, P466, DOI 10.1016/j.envsci.2008.10.006
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   McKeith G, 2006, YOU ARE WHAT YOU EAT
   Min WQ, 2020, IEEE T MULTIMEDIA, V22, P2659, DOI 10.1109/TMM.2019.2958761
   Min WQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1331, DOI 10.1145/3343031.3350948
   Min WQ, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329168
   Min WQ, 2018, IEEE T MULTIMEDIA, V20, P950, DOI 10.1109/TMM.2017.2759499
   Ming ZY, 2018, LECT NOTES COMPUT SC, V10705, P129, DOI 10.1007/978-3-319-73600-6_12
   Newman B.M., 2017, DEV LIFE PSYCHOSOCIA, V13th
   Paszke A, 2019, ADV NEUR IN, V32
   Radford A., 2016, ICLR
   Radford A, 2021, PR MACH LEARN RES, V139
   Sahoo D, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2260, DOI 10.1145/3292500.3330734
   Salvador A., 2021, PROC IEEECVF C COMPU, p15 475
   Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Vapnik V., 1995, NATURE STAT LEARNING
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H., 2019, P IEEE C COMP VIS PA, P572
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang H., 2021, PROC 29 ACM INT C MU
   Zhu B, 2020, PROC CVPR IEEE, P5518, DOI 10.1109/CVPR42600.2020.00556
   Zhu B, 2019, PROC CVPR IEEE, P11469, DOI 10.1109/CVPR.2019.01174
   Zhu Bin, 2020, P 28 ACM INT C MULT, P3762
NR 57
TC 3
Z9 3
U1 4
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2022
VL 24
BP 1175
EP 1185
DI 10.1109/TMM.2021.3123474
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA ZN1SD
UT WOS:000764821800014
DA 2024-07-18
ER

PT J
AU Xia, W
   Wang, QQ
   Gao, QX
   Zhang, XD
   Gao, XB
AF Xia, Wei
   Wang, Qianqian
   Gao, Quanxue
   Zhang, Xiangdong
   Gao, Xinbo
TI Self-Supervised Graph Convolutional Network for Multi-View Clustering
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Feature extraction; Decoding; Transforms; Task analysis; Clustering
   methods; Social networking (online); Correlation; Node clustering; graph
   representation learning; multi-view learning; subspace clustering;
   self-supervision
ID SCALE
AB Despite the promising preliminary results, existing graph convolutional network (GCN) based multi-view learning methods directly use the graph structure as view descriptor, which may inhibit the ability of multi-view learning for multimedia data. The major reason is that, in real multimedia applications, the graph structure may contain outliers. Moreover, they fail to take advantage of the information embedded in the inaccurate clustering labels obtained from their proposed methods, resulting in inferior clustering results. These observations motivate us to study whether there is a better alternative GCN based framework for multi-view clustering. To this end, in this paper, we propose an end-to-end self-supervised graph convolutional network for multi-view clustering (SGCMC). Specifically, SGCMC constructs a new view descriptor for graph-structured data by mapping the raw node content into the complex space via Euler transformation, which not only suppresses outliers but also reveals non-linear patterns embedded in data. Meanwhile, the proposed SGCMC uses the clustering labels to guide the learning of the latent representation and coefficient matrix, and the latter in turn is used to conduct the subsequent node clustering. By this way, clustering and representation learning are seamlessly connected, with the aim to achieve better clustering results. Extensive experimental results indicate that the proposed SGCMC outperforms the state-of-the-art methods.
C1 [Xia, Wei; Wang, Qianqian; Zhang, Xiangdong] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
   [Gao, Quanxue] Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.
   [Gao, Quanxue] Xidian Ningbo Informat Technol Inst, Ningbo 315000, Peoples R China.
   [Gao, Xinbo] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
C3 Xidian University; Xidian University; Chongqing University of Posts &
   Telecommunications
RP Gao, QX (corresponding author), Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.
EM xdweixia@gmail.com; qianqian174@foxmail.com; qxgao@xidian.edu.cn;
   578653865@qq.com; xbgao@mail.xidian.edu.cn
RI Wang, Qianqian/AHC-6753-2022
OI Wang, Qianqian/0000-0001-8011-171X
FU National Natural Science Foundation of China [61773302, 62036007,
   62050175]; Natural Science Basic Research Plan in Shaanxi Province
   [2020JZ-19]; Fundamental Research Funds for the Central Universities;
   Innovation Fund of Xidian University; Natural Science Foundation of
   Ningbo [2018A610049]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61773302, 62036007, and 62050175, in
   part by Natural Science Basic Research Plan in Shaanxi Province under
   Grant 2020JZ-19, in part by the Fundamental Research Funds for the
   Central Universities, the Innovation Fund of Xidian University, in part
   by the Natural Science Foundation of Ningbo under Grant 2018A610049.
CR Andrew G., 2013, P ICML, P1247
   Bo DY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1400, DOI 10.1145/3366423.3380214
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   Cavallari S, 2019, IEEE COMPUT INTELL M, V14, P39, DOI 10.1109/MCI.2019.2919396
   Cavallari S, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P377, DOI 10.1145/3132847.3132925
   Chen YY, 2020, IEEE T MULTIMEDIA, V22, P1985, DOI 10.1109/TMM.2019.2952984
   Fan SH, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P3070, DOI 10.1145/3366423.3380079
   Gao QX, 2020, AAAI CONF ARTIF INTE, V34, P3930
   Giles C. L., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P89, DOI 10.1145/276675.276685
   Tran HN, 2018, J SUPERCOMPUT, V74, P2086, DOI 10.1007/s11227-017-2225-1
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Kingma D. P., 2014, arXiv
   Kipf T.N., 2017, P INT C LEARN REPR S
   Kipf T. N., 2016, PROC NIPS WORKSHOP B, P1
   Li S, 2020, AAAI CONF ARTIF INTE, V34, P4691
   Li YF, 2021, AAAI CONF ARTIF INTE, V35, P8547
   Liao SL, 2018, IEEE T IMAGE PROCESS, V27, P5668, DOI 10.1109/TIP.2018.2859589
   Liwicki S, 2013, INT J COMPUT VISION, V101, P498, DOI 10.1007/s11263-012-0558-z
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pan SR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2609
   Pan SR, 2020, IEEE T CYBERNETICS, V50, P2475, DOI 10.1109/TCYB.2019.2932096
   Park J, 2019, IEEE I CONF COMP VIS, P6518, DOI 10.1109/ICCV.2019.00662
   Peng W, 2020, AAAI CONF ARTIF INTE, V34, P2669
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Qiu ZW, 2020, AAAI CONF ARTIF INTE, V34, P11924
   Salehi A, 2020, PROC INT C TOOLS ART, P989, DOI 10.1109/ICTAI50040.2020.00154
   Shen XB, 2018, IEEE T NEUR NET LEAR, V29, P4324, DOI 10.1109/TNNLS.2017.2763967
   Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Stisen A, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P127, DOI 10.1145/2809695.2809718
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P1724, DOI 10.1109/TMM.2018.2889560
   Tang J, 2018, IEEE T MULTIMEDIA, V20, P1008, DOI 10.1109/TMM.2017.2760627
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Velickovic Petar, 2019, ICLR
   Velickovic Petar, 2018, INT C LEARN REPR
   Wang C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3670
   Wang C, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P889, DOI 10.1145/3132847.3132967
   Wang QQ, 2021, IEEE T MULTIMEDIA, V23, P3483, DOI 10.1109/TMM.2020.3025666
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Wu YJ, 2020, AAAI CONF ARTIF INTE, V34, P1054
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xia W, 2021, NEUROCOMPUTING, V448, P324, DOI 10.1016/j.neucom.2021.03.031
   Xia W, 2022, IEEE T CYBERNETICS, V52, P8962, DOI 10.1109/TCYB.2021.3052352
   Xie DY, 2020, IEEE T CYBERNETICS, V50, P4848, DOI 10.1109/TCYB.2019.2922042
   Xie Y, 2020, IEEE T CYBERNETICS, V50, P572, DOI 10.1109/TCYB.2018.2869789
   Xu L, 2019, IEEE T MULTIMEDIA, V21, P591, DOI 10.1109/TMM.2018.2887019
   Xue F, 2020, IEEE T MULTIMEDIA, V22, P2098, DOI 10.1109/TMM.2019.2951194
   Yang C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2111
   Yang XJ, 2020, PATTERN RECOGN LETT, V130, P345, DOI 10.1016/j.patrec.2018.06.024
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   You Y, 2020, PROC NEURIPS
   Zhan K, 2021, FUTURE GENER COMP SY, V115, P837, DOI 10.1016/j.future.2020.10.016
   Zhang CQ, 2020, IEEE T PATTERN ANAL, V42, P86, DOI 10.1109/TPAMI.2018.2877660
   Zhang JJ, 2019, PROC CVPR IEEE, P5468, DOI 10.1109/CVPR.2019.00562
   Zhou P, 2019, IEEE T MULTIMEDIA, V21, P539, DOI 10.1109/TMM.2018.2885509
NR 60
TC 50
Z9 51
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL 2
PY 2021
VL 24
BP 3182
EP 3192
DI 10.1109/TMM.2021.3094296
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 2W7NN
UT WOS:000824707200001
DA 2024-07-18
ER

PT J
AU Dutta, T
   Singh, A
   Biswas, S
AF Dutta, Titir
   Singh, Anurag
   Biswas, Soma
TI StyleGuide: Zero-Shot Sketch-Based Image Retrieval Using Style-Guided
   Image Generation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Protocols; Image retrieval; Training; Feature extraction; Loss
   measurement; Image reconstruction; Sketch-based retrieval; generalized
   ZS-SBIR; content-style decomposition; novelty detection
ID NETWORKS
AB The goal of zero-shot sketch-based image retrieval is to retrieve relevant images from a search set against a hand-drawn sketch query, which belongs to a class, previously unseen by the model. The knowledge gap between such unseen and seen classes along with the domain-gap between the query and search-set makes the problem extremely challenging. In this work, we address this problem by proposing a novel retrieval methodology, StyleGuide using style-guided fake-image generation. In addition, we further study the scenario of generalized zero-shot sketch-based image retrieval, where the search set contains images from both seen and unseen categories. Specifically, we propose a detection approach for unseen class samples in the search-set, based on pre-computed seen class-prototypes, to obtain a refined search-set for a particular unseen-class query. Thus, the query sketch needs to be compared only to those image data which are more likely to belong to the unseen classes, resulting in improved retrieval performance. Extensive experiments on two large-scale sketch-image datasets, Sketchy extended and TU-Berlin show that the proposed approach performs better or comparable to the state-of-the-art for ZS-SBIR and gives significant improvements over the state-of-the-art for generalized ZS-SBIR.
C1 [Dutta, Titir; Singh, Anurag; Biswas, Soma] Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Biswas, S (corresponding author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
EM titird@iisc.ac.in; anuragsingh2@iisc.ac.in; somabiswas@iisc.ac.in
RI Bueno, Regis Cortez/AAG-3852-2020
OI Bueno, Regis Cortez/0000-0002-2923-4930
FU SERB, Department of Science and Technology, Government of India
FX Manuscript received December 5, 2019; revised May 7, 2020 and June 30,
   2020; accepted August 3, 2020. Date of publication August 19, 2020; date
   of current version August 24, 2021. This work was partly supported by a
   grant from SERB, Department of Science and Technology, Government of
   India. The associate editor coordinating the review of this manuscript
   and approving it for publication was Dr. Meng Wang. (Corresponding
   author: Soma Biswas).
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2467315
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173
   Bhattacharjee S, 2019, IEEE IMAGE PROC, P3646, DOI [10.1109/icip.2019.8803562, 10.1109/ICIP.2019.8803562]
   Bui T, 2018, COMPUT GRAPH-UK, V71, P77, DOI 10.1016/j.cag.2017.12.006
   Chen X, 2016, ADV NEUR IN, V29
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Collomosse J, 2017, IEEE I CONF COMP VIS, P2679, DOI 10.1109/ICCV.2017.290
   Dey S, 2019, PROC CVPR IEEE, P2174, DOI 10.1109/CVPR.2019.00228
   Dutta A, 2019, PROC CVPR IEEE, P5084, DOI 10.1109/CVPR.2019.00523
   Dutta T., 2019, BMVC, V2, P9, DOI 10.1109/NMDC47361.2019.9084010
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Felix R., 2018, P EUR C COMP VIS
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gune O., 2019, BMVC, P213
   Hadad N, 2018, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2018.00087
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Kautz Jan, 2018, LECT NOTES COMPUT SC, DOI [DOI 10.1007/978-3-030-01219-9_11, 10.1007/978-3-030-01219-9_11]
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Li Y., 2014, BMVC
   Liu L, 2017, PROC CVPR IEEE, P2298, DOI 10.1109/CVPR.2017.247
   Liu MY, 2017, ADV NEUR IN, V30
   Long Y, 2017, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2017.653
   Mandal D, 2019, PROC CVPR IEEE, P9977, DOI 10.1109/CVPR.2019.01022
   Mishra A, 2018, IEEE COMPUT SOC CONF, P2269, DOI 10.1109/CVPRW.2018.00294
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saavedra J. M., 2015, BRIT MACH VIS C, P7
   Salakhutdinov R., 2016, P INT C MACH LEARN, P2763
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Song JF, 2017, IEEE I CONF COMP VIS, P5552, DOI 10.1109/ICCV.2017.592
   Wang M, 2015, PROC VLDB ENDOW, V8, P998, DOI 10.14778/2794367.2794370
   Wang Wenlin., 2018, AAAI
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xu D, 2018, IEEE T IMAGE PROCESS, V27, P4410, DOI 10.1109/TIP.2018.2837381
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Yu Q, 2017, INT J COMPUT VISION, V122, P411, DOI 10.1007/s11263-016-0932-3
   Yu Q, 2019, IEEE I CONF COMP VIS, P9517, DOI 10.1109/ICCV.2019.00961
   Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19
   Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649
NR 49
TC 20
Z9 21
U1 7
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 2833
EP 2842
DI 10.1109/TMM.2020.3017918
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UE9PT
UT WOS:000688215600023
DA 2024-07-18
ER

PT J
AU Khalid, A
   Zahran, AH
   Sreenan, CJ
AF Khalid, Ahmed
   Zahran, Ahmed H.
   Sreenan, Cormac J.
TI Optimizing Video QoE for Mobile eMBMS Users in Cellular Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Streaming media; Quality of experience; Bit rate; Resource management;
   Unicast; Optimization; Cellular networks; Mobile communication;
   multicast; multimedia broadcasting; quality of experience; resource
   utilization
AB Evolved Multimedia Broadcast Multicast Service (eMBMS) is used in cellular networks to improve the utilization of scarce wireless resources in high user density service areas. However, eMBMS configuration involves interwoven decisions including which base stations (eNB) to synchronize to form Single Frequency Networks (SFN), which video qualities to be serviced, and how to distribute resources among different videos. These decisions should accommodate disparate channel conditions for eMBMS users, and the impact of eNB's unicast-load in the service area. In this paper, we formulate eMBMS configuration as an optimization problem that maximizes the video QoE for users. Additionally, we present NIMBLE as an eMBMS configuration heuristic, guided by our optimization framework, to solve the problem in realtime. Furthermore, NIMBLE's design integrates elements to accommodate the dynamic nature of cellular networks resulting from changes in both user, and network state over time. We developed a simulation testbed, and performed extensive experiments to show that, in comparison to state-of-the-art schemes, NIMBLE can increase the average user throughput by 150%, and reduce the bitrate switches by 75%.
C1 [Khalid, Ahmed; Zahran, Ahmed H.; Sreenan, Cormac J.] Univ Coll Cork, Sch Comp Sci, Cork T12 XF62, Ireland.
C3 University College Cork
RP Khalid, A (corresponding author), Univ Coll Cork, Sch Comp Sci, Cork T12 XF62, Ireland.
EM ahmedkhalid.nust@gmail.com; a.zahran@cs.ucc.ie; cjs@cs.ucc.ie
OI Khalid, Ahmed/0000-0002-6778-5661; Zahran, Ahmed/0000-0003-3405-0324
FU Science Foundation Ireland [13/IA/1892]; European Regional Development
   Fund [13/RC/2077]; Science Foundation Ireland (SFI) [13/IA/1892] Funding
   Source: Science Foundation Ireland (SFI)
FX This work was supported in part by the Science Foundation Ireland under
   Grant 13/IA/1892 and in part by European Regional Development Fund under
   Grant 13/RC/2077. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Raouf Hamzaoui.
CR 3GPP, 2015, 23246 3GPP MBMS
   3GPP, 2015, 26346 3GPP MBMS
   Almowuena S, 2016, IEEE T MULTIMEDIA, V18, P102, DOI 10.1109/TMM.2015.2502067
   [Anonymous], 2014, WORKSHOP DESIGN QUAL
   Argyriou A, 2015, IEEE T MULTIMEDIA, V17, P736, DOI 10.1109/TMM.2015.2408254
   Bejerano Y, 2017, IEEE INFOCOM SER
   Chang HS, 2018, IEEE T MULTIMEDIA, V20, P3337, DOI 10.1109/TMM.2018.2831639
   Cisco, 2020, ANN INT REP 2018 202
   Cranley N, 2006, INT J HUM-COMPUT ST, V64, P637, DOI 10.1016/j.ijhcs.2005.12.002
   Duanmu ZF, 2018, IEEE T BROADCAST, V64, P474, DOI 10.1109/TBC.2018.2822870
   EBU, 2014, Tech. Rep. TR 027
   Eltobgy O, 2020, IEEE T MULTIMEDIA, V22, P3139, DOI 10.1109/TMM.2020.2973855
   *ER, 2019, ERICSSON MOBILITY RE
   Gomez-Barquero D, 2019, IEEE T BROADCAST, V65, P351, DOI 10.1109/TBC.2019.2914866
   Hosseini M, 2007, IEEE COMMUN SURV TUT, V9, P58, DOI 10.1109/COMST.2007.4317616
   Hossfeld T, 2017, IEEE COMMUN LETT, V21, P184, DOI 10.1109/LCOMM.2016.2616342
   Hou F., 2009, IEEE T WIRELESS COMM, V8
   Ikuno JC, 2010, VEH TECHNOL CONFE
   ITU-T, 2017, P10G100 ITU
   Jain R., 1999, ATM FOR CONTR, V99, P4
   Jiasi Chen, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1266, DOI 10.1109/INFOCOM.2015.7218502
   Kelly F, 1997, EUR T TELECOMMUN, V8, P33, DOI 10.1002/ett.4460080106
   Khalid A, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P121, DOI 10.1145/3304109.3306229
   Khalid A, 2019, IEEE INFOCOM SER, P433, DOI [10.1109/INFOCOM.2019.8737643, 10.1109/infocom.2019.8737643]
   Liu Y, 2015, IEEE T BROADCAST, V61, P651, DOI 10.1109/TBC.2015.2460611
   Maltz D., 1998, P ACM MOBICOM, V114
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Quinlan JJ, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P386, DOI 10.1145/2910017.2910625
   Sivaraj R, 2017, I C NETWORK PROTOCOL
   Song W, 2014, IEEE T MULTIMEDIA, V16, P738, DOI 10.1109/TMM.2014.2298217
   Won H., 2009, IEEE T WIRELESS COMM, V8
   Wu JY, 2018, IEEE T MULTIMEDIA, V20, P457, DOI 10.1109/TMM.2017.2741425
   Wu JY, 2017, IEEE J SEL AREA COMM, V35, P30, DOI 10.1109/JSAC.2016.2632599
   Wu JY, 2016, IEEE T MOBILE COMPUT, V15, P2345, DOI 10.1109/TMC.2015.2497238
   Yoon J, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P209
   Zahran AH, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P13, DOI 10.1145/3083187.3083199
NR 36
TC 1
Z9 1
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 3166
EP 3178
DI 10.1109/TMM.2020.3021229
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UU6IS
UT WOS:000698902000017
OA Green Published
DA 2024-07-18
ER

PT J
AU Song, D
   Li, TB
   Li, WH
   Nie, WZ
   Liu, W
   Liu, AA
AF Song, Dan
   Li, Tian-Bao
   Li, Wen-Hui
   Nie, Wei-Zhi
   Liu, Wu
   Liu, An-An
TI Universal Cross-Domain 3D Model Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Three-dimensional displays; Solid modeling; Adaptation models; Two
   dimensional displays; Computational modeling; Data models; Feature
   extraction; 3D data management; 3D model retrieval; domain adaptation
ID OBJECT RETRIEVAL
AB Recent advances in 3D modeling technologies such as 3D scanning, reconstruction and printing produce an explosive increasing of 3D models, consequently 3D model management becomes urgent to facilitate related applications such as CAD, VR/AR and autonomous driving. However, we usually lack the labels of the recently emerging 3D models and even have no prior knowledge toward the label set relationship between new datasets and existing labeled datasets, which makes the management challenging. In this paper, a universal cross-domain 3D model retrieval framework is proposed for utilizing the labeled 2D images or 3D models to manage unlabeled 3D models with no prior knowledge about label sets. Specifically, a sample-level weighting mechanism is adopted to automatically detect the samples from the common label set for both domains. Then, both the domain-level and class-level alignments are performed for domain adaptation. Finally, the adapted features are used for 3D model retrieval. We conduct experiments on the cross-domain 3D model retrieval dataset NTU-PSB (PSB-NTU) and image-based 3D model retrieval dataset MI3DOR, and the results validate the superiority and effectiveness of the proposed method.
C1 [Song, Dan; Li, Tian-Bao; Li, Wen-Hui; Nie, Wei-Zhi; Liu, An-An] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Liu, Wu] JD AI Res, Beijing 100105, Peoples R China.
C3 Tianjin University
RP Nie, WZ; Liu, AA (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM dan.song@tju.edu.cn; litianbao@tju.edu.cn; liwenhui@tju.edu.cn;
   weizhinie@tju.edu.cn; liuwu@live.cn; anan0422@gmail.com
RI LI, Wenhui/JCD-9947-2023; Zeng, Yun/JFK-6190-2023; Lu,
   Wang/JVO-0416-2024; Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Nature Science Foundation of China [61902277, 61772359,
   61872267, 61702471]; Grant of 2019 Tianjin New Generation Artificial
   Intelligence Major Program [19ZXZNGX00110]; grant of 2018 Tianjin New
   Generation Artificial Intelligence Major Program [18ZXZNGX00150]; Open
   Project Program of the State Key Lab of CAD AMP; CG, Zhejiang University
   [A2005, A2012]; grant of Elite Scholar Program of Tianjin University
   [2019XRX-0035]
FX This work was supported in part by the National Nature Science
   Foundation of China under Grants 61902277, 61772359, 61872267, and
   61702471, in part by the Grant of 2019 Tianjin New Generation Artificial
   Intelligence Major Program under Grant 19ZXZNGX00110, the grant of 2018
   Tianjin New Generation Artificial Intelligence Major Program under Grant
   18ZXZNGX00150, in part by the Open Project Program of the State Key Lab
   of CAD & CG, Zhejiang University underGrants (A2005, A2012), and in part
   by the grant of Elite Scholar Program of Tianjin University underGrant
   2019XRX-0035.
CR Abdul-Rashid Hameed, 2018, 11 EUROGRAPHICS WORK, P37
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Cao ZJ, 2018, LECT NOTES COMPUT SC, V11212, P139, DOI 10.1007/978-3-030-01237-3_9
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Guo H, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P859, DOI 10.1145/2733373.2806349
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Li B, 2014, EUR WORKSH 3D OBJ RE, P121
   Li W., 2019, P 12 EUR WORKSH 3D O, P1
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Long M., 2016, Advances in neural information processing systems, V29
   Long M., 2017, Proc Mach Learn Res, V70, P2208
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lu Yijuan, 2019, 12 EUROGRAPHICS WORK, P41
   Ma XH, 2019, IEEE T MULTIMEDIA, V21, P2419, DOI 10.1109/TMM.2019.2902100
   Nie WZ, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3344684
   Nie WZ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P908, DOI 10.1145/3343031.3351009
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Saito K., 2018, EUR C COMP VIS, P153
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Su YT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P913
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vranic DV, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P757
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Wang Q, 2020, AAAI CONF ARTIF INTE, V34, P6243
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie J, 2017, IEEE T MULTIMEDIA, V19, P2463, DOI 10.1109/TMM.2017.2698200
   Xu J., 2019, IEEE ACCESS, V7, p156 694
   You KC, 2019, PROC CVPR IEEE, P2715, DOI 10.1109/CVPR.2019.00283
   Yuan J., 2019, P EUR WORKSH 3D OBJ, P33, DOI DOI 10.2312/3DOR.20191059
   Yuan J., 2018, Eurographics Workshop on 3D Object Retrieval, P29
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
NR 49
TC 12
Z9 13
U1 9
U2 67
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 2721
EP 2731
DI 10.1109/TMM.2020.3015554
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UE9PT
UT WOS:000688215600014
DA 2024-07-18
ER

PT J
AU Toffa, OK
   Mignotte, M
AF Toffa, Ohini Kafui
   Mignotte, Max
TI Environmental Sound Classification Using Local Binary Pattern and Audio
   Features Collaboration
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Environmental sound classification; local binary pattern; local phase
   quantization; machine learning; ESC-50 audio; signal spectrogram; SVM;
   random forest; kNN
ID TEXTURE CLASSIFICATION; SCALE
AB This paper presents a new approach to classify environmental sounds using a texture feature local binary pattern (LBP) and audio features collaboration. To our knowledge, this is the first time that the LBP (or its variants), which has a proven track record in the field of image recognition and classification, has been generalized for 1D and combined with audio features for an environmental sound classification task. To this end, we have generalized and defined LBP-1D and local phase quantization (LPQ)-1D on the 1-dimensional (1D) audio signal and have applied the original LBP, the variance LBP (VARLBP) and the extended LBP (ELBP) thus generated to the spectrogram of the audio signal in order to model the sound texture. We have also extensively compared these new LBP-based features to the classical audio descriptors commonly used in environmental sound classification, such as MFCC, GFCC, CQT, chromagram, STE and ZCR. We have evaluated our algorithm on ESC-10 and ESC-50 datasets using classicalmachine learning algorithms, such as support vector machines (SVM), random forest and k-nearest neighbor (kNN). The results showed that the LBP features outperform the classical audio features. We mix theLBPfeatures with the audio descriptors, and our best mixed model achieves state-of-the-art results for environmental sound classification: 88.5% on ESC-10 and 64.6% on ESC-50. Those results outperform the results of methods that used handcrafted features with classical machine learning algorithms and are similar to some convolutional neural networkbased methods. Although our method is not the cutting edge of the state-of-the-art methods, it is faster than any convolutional neural networkmethods and represents a better choice when there is data scarcity or minimal computing power.
C1 [Toffa, Ohini Kafui; Mignotte, Max] Univ Montreal, Fac Arts & Sci, Vis Lab, Dept Informat & Rech Operat DIRO, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal
RP Toffa, OK (corresponding author), Univ Montreal, Fac Arts & Sci, Vis Lab, Dept Informat & Rech Operat DIRO, Montreal, PQ H3C 3J7, Canada.
EM ohinfa@yahoo.fr; mignotte@iro.umontreal.ca
RI Mignotte, Max/F-7014-2015
OI Toffa, ohini kafui/0000-0002-6646-6001
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdoli S, 2019, EXPERT SYST APPL, V136, P252, DOI 10.1016/j.eswa.2019.06.040
   Ahonen T, 2008, INT C PATT RECOG, P2779
   Almaadeed N, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061858
   Aytar Y, 2016, ADV NEUR IN, V29
   Boddapatia V., 2017, P INT C KNOWL BAS IN, P6
   Chachada S., 2013, Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2013, P1, DOI [10.1109/APSIPA.2013.6694338, DOI 10.1109/APSIPA.2013.6694338]
   Chandrakala S, 2020, IEEE T MULTIMEDIA, V22, P3, DOI 10.1109/TMM.2019.2925956
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   Dai W, 2017, INT CONF ACOUST SPEE, P421, DOI 10.1109/ICASSP.2017.7952190
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Huzaifah M., 2017, ARXIV PREPRINT ARXIV
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Joshi A, 2015, INT CONF BIOMETR, P177, DOI 10.1109/ICB.2015.7139049
   Kim MJ, 2012, IEEE T MULTIMEDIA, V14, P1390, DOI 10.1109/TMM.2012.2195481
   Kobayashi Takumi, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3052, DOI 10.1109/ICASSP.2014.6854161
   Král P, 2019, LECT NOTES ARTIF INT, V11509, P27, DOI 10.1007/978-3-030-20915-5_3
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei Z, 2012, PATTERN RECOGN LETT, V33, P1761, DOI 10.1016/j.patrec.2012.06.005
   Li XY, 2019, INTERSPEECH, P3604, DOI 10.21437/Interspeech.2019-3019
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Logan Beth, 2000, ISMIR, V270, P1
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   Muhammad G., 2010, Proceedings of the Fifth International Conference on Digital Telecommunications (ICDT 2010), P11, DOI 10.1109/ICDT.2010.10
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Ren JF, 2017, IEEE T MULTIMEDIA, V19, P447, DOI 10.1109/TMM.2016.2618218
   Sailor HB, 2017, INTERSPEECH, P3107, DOI 10.21437/Interspeech.2017-831
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Schrkhuber C., 2010, P 7 SOUND MUS COMP
   Sehili MA, 2012, EUR SIGNAL PR CONF, P1673, DOI 10.5281/zenodo.43299
   Sharma J., 2019, P INT 2020 AUG, P1186
   SHEPARD RN, 1964, J ACOUST SOC AM, V36, P2346, DOI 10.1121/1.1919362
   Slaney M., 1993, An efficient implementation of the patterson-holdsworth auditory filterbank, V35
   Tokozume Y., 2018, ICLR
   Tokozume Y, 2017, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.2017.7952651
   Valero X, 2012, IEEE T MULTIMEDIA, V14, P1684, DOI 10.1109/TMM.2012.2199972
   Wang JC, 2014, IEEE T AUTOM SCI ENG, V11, P607, DOI 10.1109/TASE.2013.2285131
   Wang JC, 2006, IEEE IJCNN, P1731
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
NR 46
TC 20
Z9 20
U1 0
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 3978
EP 3985
DI 10.1109/TMM.2020.3035275
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA XA2YU
UT WOS:000720519900005
DA 2024-07-18
ER

PT J
AU Wang, T
   Ji, ZX
   Yang, J
   Sun, QS
   Fu, P
AF Wang, Tao
   Ji, Zexuan
   Yang, Jian
   Sun, Quansen
   Fu, Peng
TI Global Manifold Learning for Interactive Image Segmentation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image segmentation; Manifolds; Estimation; Tensile stress; Sun;
   Probabilistic logic; Geometry; Interactive image segmentation; global
   effects; manifold learning; label propagation
ID LABEL PROPAGATION; DIFFUSION; GRABCUT
AB This paper presents an interactive image segmen-tation algorithm, in which the segmentation problem is formulated as a global manifold learning process. Based on the principle that the label of each element depends on the influence of all the elements in the image, we extend the conventional local neighborhood or the long range regional relationships to the global relationships over the whole image. A probabilistic framework is established to measure the global effect of each element on all other elements. Based on two different manifold learning styles, the semi-global manifold learning (SGML) and the fully-global manifold learning (FGML) algorithms are proposed to capture the global geometry structure of the data manifold. SGML learns the intrinsic effects of each element separately, equivalent to a matrix diffusion process on an affinity graph. FGML learns the intrinsic effects of all elements together, equivalent to a label pair diffusion process on a higher-order tensor product graph. The global manifold learning helps to overcome the low contrast, weak boundary and texture problems. Extensive experiments on three public interactive segmentation datasets demonstrate the superior performance of the proposed algorithms both in accuracy and efficiency.
C1 [Wang, Tao; Ji, Zexuan; Yang, Jian; Sun, Quansen; Fu, Peng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Sun, QS (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM wangtaoatnjust@163.com; jizexuan@njust.edu.cn; csjyang@njust.edu.cn;
   sunquansen@njust.edu.cn; fupeng@njust.edu.cn
RI fu, peng/JER-6786-2023
FU Natural Science Foundation of Jiangsu Province, China [BK20180458];
   National Science Foundation of China [61802188, 61673220, U1713208,
   61801222]
FX This work was supported in part by the Natural Science Foundation of
   Jiangsu Province, China, under Grant BK20180458, in part by the National
   Science Foundation of China under Grants 61802188, 61673220, U1713208,
   and 61801222. The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Elisa Ricci.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   Bai JJ, 2014, PROC CVPR IEEE, P392, DOI 10.1109/CVPR.2014.57
   Bai S, 2017, AAAI CONF ARTIF INTE, P3967
   Bai XF, 2007, IEEE IC COMP COM NET, P1
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P35, DOI 10.1109/TIP.2016.2621663
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Casaca W, 2014, PROC CVPR IEEE, P384, DOI 10.1109/CVPR.2014.56
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   Nguyen DT, 2018, IEEE T VIS COMPUT GR, V24, P3005, DOI 10.1109/TVCG.2017.2772238
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fu KR, 2019, IEEE T MULTIMEDIA, V21, P457, DOI 10.1109/TMM.2018.2859746
   Fuller AR, 2007, IEEE T VIS COMPUT GR, V13, P1719, DOI 10.1109/TVCG.2007.70590
   Gong C, 2016, AAAI CONF ARTIF INTE, P1610
   Grady L, 2004, LECT NOTES COMPUT SC, V3117, P230
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Guo Y, 2018, IEEE T CYBERNETICS, V48, P1513, DOI 10.1109/TCYB.2017.2705227
   Han SD, 2009, IEEE T IMAGE PROCESS, V18, P2289, DOI 10.1109/TIP.2009.2025560
   Heimowitz A, 2016, IEEE T IMAGE PROCESS, V25, P4743, DOI 10.1109/TIP.2016.2590832
   Hua KL, 2018, IEEE T CYBERNETICS, V48, P423, DOI 10.1109/TCYB.2016.2640288
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Ji ZX, 2014, PATTERN RECOGN, V47, P2454, DOI 10.1016/j.patcog.2014.01.017
   Jian M, 2016, IEEE T IMAGE PROCESS, V25, P1301, DOI 10.1109/TIP.2016.2518480
   Kim KI, 2015, IEEE I CONF COMP VIS, P2776, DOI 10.1109/ICCV.2015.318
   Kim K, 2018, IEEE T MULTIMEDIA, V20, P208, DOI 10.1109/TMM.2017.2728318
   Kim TH, 2010, PROC CVPR IEEE, P3201, DOI 10.1109/CVPR.2010.5540078
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Li XL, 2016, IEEE T CYBERNETICS, V46, P2144, DOI 10.1109/TCYB.2015.2466437
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Liu GG, 2018, IEEE T MULTIMEDIA, V20, P2949, DOI 10.1109/TMM.2018.2844685
   Liu MM, 2020, IEEE T VIS COMPUT GR, V26, P1702, DOI 10.1109/TVCG.2018.2880737
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma C, 2017, IEEE T MULTIMEDIA, V19, P2415, DOI 10.1109/TMM.2017.2694219
   Meng FM, 2018, IEEE T MULTIMEDIA, V20, P310, DOI 10.1109/TMM.2017.2739919
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Santner J, 2011, LECT NOTES COMPUT SC, V6492, P397, DOI 10.1007/978-3-642-19315-6_31
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Sinop AK, 2007, IEEE I CONF COMP VIS, P1016, DOI 10.1109/iccv.2007.4408927
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   Wang B, 2013, IEEE I CONF COMP VIS, P425, DOI 10.1109/ICCV.2013.60
   Wang B, 2012, PROC CVPR IEEE, P2312, DOI 10.1109/CVPR.2012.6247942
   Wang LJ, 2018, IEEE T CYBERNETICS, V48, P1030, DOI 10.1109/TCYB.2017.2675910
   Wang T, 2021, IEEE T IND INFORM, V17, P135, DOI 10.1109/TII.2020.2982995
   Wang T, 2019, IEEE T IMAGE PROCESS, V28, P330, DOI 10.1109/TIP.2018.2867941
   Wang T, 2018, PATTERN RECOGN, V79, P440, DOI 10.1016/j.patcog.2018.02.023
   Wang T, 2016, IEEE T MULTIMEDIA, V18, P2358, DOI 10.1109/TMM.2016.2600441
   Wang T, 2016, INFORM SCIENCES, V358, P92, DOI 10.1016/j.ins.2016.04.017
   Wang T, 2016, PATTERN RECOGN, V55, P28, DOI 10.1016/j.patcog.2016.01.018
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173
   Wang XF, 2015, IEEE T IMAGE PROCESS, V24, P1399, DOI 10.1109/TIP.2015.2397313
   Xia GY, 2018, IEEE T IMAGE PROCESS, V27, P135, DOI 10.1109/TIP.2017.2738562
   Xu N, 2016, PROC CVPR IEEE, P373, DOI 10.1109/CVPR.2016.47
   Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611
   Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
   Zemene E, 2016, LECT NOTES COMPUT SC, V9912, P278, DOI 10.1007/978-3-319-46484-8_17
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou HL, 2013, PATTERN RECOGN, V46, P1719, DOI 10.1016/j.patcog.2012.12.005
NR 64
TC 12
Z9 12
U1 1
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 3239
EP 3249
DI 10.1109/TMM.2020.3021979
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UU6IS
UT WOS:000698902000023
DA 2024-07-18
ER

PT J
AU Wei, WL
   Lin, JC
   Liu, TL
   Tyan, HR
   Wang, HM
   Liao, HYM
AF Wei, Wen-Li
   Lin, Jen-Chun
   Liu, Tyng-Luh
   Tyan, Hsiao-Rong
   Wang, Hsin-Min
   Liao, Hong-Yuan Mark
TI Learning to Visualize Music Through Shot Sequence for Automatic Concert
   Video Mashup
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Visualization; Mashups; Music; Head; Recurrent neural networks;
   Knowledge engineering; Task analysis; Types of shots; visual
   storytelling; live concert; video mashup; recurrent neural networks;
   knowledge distillation
AB An experienced director usually switches among different types of shots to make visual storytelling more touching. When filming a musical performance, appropriate switching shots can produce some special effects, such as enhancing the expression of emotion or heating up the atmosphere. However, while the visual storytelling technique is often used in making professional recordings of a live concert, amateur recordings of audiences often lack such storytelling concepts and skills when filming the same event. Thus a versatile system that can perform video mashup to create a refined high-quality video from such amateur clips is desirable. To this end, we aim at translating the music into an attractive shot (type) sequence by learning the relation between music and visual storytelling of shots. The resulting shot sequence can then be used to better portray the visual storytelling of a song and guide the concert video mashup process. To achieve the task, we first introduces a novel probabilistic-based fusion approach, named as multi-resolution fused recurrent neural networks (MF-RNNs) with film-language, which integrates multi-resolution fused RNNs and a film-language model for boosting the translation performance. We then distill the knowledge in MF-RNNs with film-language into a lightweight RNN, which is more efficient and easier to deploy. The results from objective and subjective experiments demonstrate that both MF-RNNs with film-language and lightweight RNN can generate attractive shot sequences for music, thereby enhancing the viewing and listening experience.
C1 [Wei, Wen-Li; Lin, Jen-Chun; Liu, Tyng-Luh; Wang, Hsin-Min; Liao, Hong-Yuan Mark] Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan.
   [Tyan, Hsiao-Rong] Chung Yuan Christian Univ, Informat & Comp Engn, Taoyuan 32023, Taiwan.
C3 Academia Sinica - Taiwan; Chung Yuan Christian University
RP Lin, JC (corresponding author), Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan.
EM lilijinjin@gmail.com; jenchunlin@gmail.com; liutyng@iis.sinica.edu.tw;
   tyan@ice.cycu.edu.tw; whm@iis.sinica.edu.tw; liao@iis.sinica.edu.tw
RI Wang, Hsin-Min/ABA-8747-2020; Lin, Jen-Chun/AAQ-3701-2021
OI Wang, Hsin-Min/0000-0003-3599-5071; Lin, Jen-Chun/0000-0002-9237-4119;
   Wei, Wen-Li/0000-0002-6753-2824
FU MOST [109-2634-F-001-011, 109-2634-F-001-012, 107-2218-E-001-010-MY2]
FX This work was supported by MOST under Grants 109-2634-F-001-011,
   109-2634-F-001-012, and 107-2218-E-001-010-MY2.
CR [Anonymous], 2012, LECT 6 OVERVIEW MINI
   [Anonymous], 2015, P N AM CHAPT ASS COM
   [Anonymous], 2011, DIGITAL OVERDRIVE CO
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535
   Chen JW, 2019, AAAI CONF ARTIF INTE, P8167
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Hart John., 2008, The Art of the Storyboard - A Filmmaker's Introduction
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton Geoffrey, 2014, NIPS DEEP LEARN WORK
   Hochreiter S., 1997, NEURAL COMPUT, V9, P1735
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Law E., 2009, Proc. Int. Conf. Music Inf. Retrieval, P387
   Li Y, 2018, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2018.00782
   Lin JC, 2018, IEEE T MULTIMEDIA, V20, P3123, DOI 10.1109/TMM.2018.2820904
   Liu JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1048, DOI 10.1145/2964284.2964292
   Liu Y, 2017, AAAI CONF ARTIF INTE, P1445
   Mercado G., 2010, The Filmmaker's Eye: Learning (and Breaking) the Rules of Cinematic Composition
   Pan H, 2001, PATTERN RECOGN LETT, V22, P1431, DOI 10.1016/S0167-8655(01)00080-0
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Park C. C., 2015, Advances in neural information processing systems, P73
   Saini M.K., 2012, Proceedings of the 20th International Conference on Multimedia, P139, DOI DOI 10.1145/2393347.2393373
   Shi YY, 2019, INT CONF ACOUST SPEE, P7230, DOI 10.1109/ICASSP.2019.8683533
   Shrestha P., 2010, Proceedings of the international conference on Multimedia (MM '10), P541, DOI DOI 10.1145/1873951.1874023
   Teerapittayanon S, 2016, INT C PATT RECOG, P2464, DOI 10.1109/ICPR.2016.7900006
   Thoma A., 2015, The International Journal of New Media, Technology and the Arts, V10, P17
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wei W.-L., 2018, PROC 8 INT C IMAGE P, P1
   Wei WL, 2017, INT CONF ACOUST SPEE, P1383, DOI 10.1109/ICASSP.2017.7952383
   Wijitha Senadeera Wijitha Senadeera, 2006, International Journal of Food Engineering, V2, P7
   Wu CH, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.11
   Wu Y, 2016, IEEE T MULTIMEDIA, V18, P2206, DOI 10.1109/TMM.2016.2614185
   Wu Y, 2015, IEEE T CIRC SYST VID, V25, P1941, DOI 10.1109/TCSVT.2015.2416554
   Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhao N, 2017, IEEE T MULTIMEDIA, V19, P2080, DOI 10.1109/TMM.2017.2722687
NR 43
TC 3
Z9 3
U1 0
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 1731
EP 1743
DI 10.1109/TMM.2020.3003631
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA SJ9EZ
UT WOS:000655830300020
DA 2024-07-18
ER

PT J
AU Xie, QK
   Zhou, WG
   Qi, GJ
   Tian, Q
   Li, HQ
AF Xie, Qiaokang
   Zhou, Wengang
   Qi, Guo-Jun
   Tian, Qi
   Li, Houqiang
TI Progressive Unsupervised Person Re-Identification by Tracklet
   Association With Spatio-Temporal Regularization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cameras; Training; Feature extraction; Data models; Training data;
   Machine learning; UHDTV; Unsupervised person re-identification;
   Spatio-temporal regularization; Tracklet association
ID NETWORK; ATTENTION
AB Existing methods for person re-identification (Re-ID) are mostly based on supervised learning which requires numerous manually labeled samples across all camera views for training. Such a paradigm suffers the scalability issue since in real-world Re-ID application, it is difficult to exhaustively label abundant identities over multiple disjoint camera views. To this end, we propose a progressive deep learning method for unsupervised person Re-ID in the wild by Tracklet Association with Spatio-Temporal Regularization (TASTR). In our approach, we first collect tracklet data within each camera by automatic person detection and tracking. Then, an initial Re-ID model is trained based on within-camera triplet construction for person representation learning. After that, based on the person visual feature and spatio-temporal constraint, we associate cross-camera tracklets to generate cross-camera triplets and update the Re-ID model. Lastly, with the refined Re-ID model, better visual feature of person can be extracted, which further promote the association of cross-camera tracklets. The last two steps are iterated multiple times to progressively upgrade the Re-ID model. To facilitate the study, we have collected a new 4K UHD video dataset named Campus4K with full frames and full spatio-temporal information. Experimental results show that with the spatio-temporal constraint in the training phase, the proposed approach outperforms the state-of-the-art unsupervised methods by notable margins on DukeMTMC-reID, and achieves competitive performance to fully supervised methods on both DukeMTMC-reID and Campus4K datasets.
C1 [Xie, Qiaokang; Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.
   [Qi, Guo-Jun] Futurewei Technol, Santa Clara, CA 95050 USA.
   [Tian, Qi] Huawei Technol Co Ltd, Huawei Noahs Ark Lab, Shenzhen 518129, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Huawei Technologies; Huawei Technologies
RP Zhou, WG; Li, HQ (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.
EM xieqiaok@mail.ustc.edu.cn; zhwg@ustc.edu.cn; guojunq@gmail.com;
   tian.qi1@huawei.com; lihq@ustc.edu.cn
RI Li, Houqiang Li/B-6259-2013; Qi, Guo-Jun/AAH-8294-2019
OI Xie, Qiaokang/0000-0002-4877-2224
FU National Key RAMP;D Program of China [2018YFB1402600]; National Natural
   Science Foundation of China [61822208, 61632019]; Youth Innovation
   Promotion Association CAS [2018497]; NSFC [61836011]
FX The work of W. Zhou was supported in part by the National Key R&D
   Program of China under Contract 2018YFB1402600, in part by the National
   Natural Science Foundation of China under Contracts 61822208 and
   61632019, and in part by Youth Innovation Promotion Association CAS
   2018497. The work of H. Li was supported by NSFC under Contract
   61836011.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2016, ARXIV
   [Anonymous], 2017, IEEE T CYBERNETICS, DOI DOI 10.1109/TCYB.2016.2568264
   [Anonymous], IN PRESS, DOI DOI 10.1109/TPAMI.2019.2903058
   Cho YJ, 2019, COMPUT VIS IMAGE UND, V180, P34, DOI 10.1016/j.cviu.2019.01.003
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang ZL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1888, DOI 10.1145/3343031.3351027
   King DB, 2015, ACS SYM SER, V1214, P1
   Kodirov E., 2015, BMVC, DOI DOI 10.5244/C.29.44
   Kodirov E, 2016, LECT NOTES COMPUT SC, V9905, P178, DOI 10.1007/978-3-319-46448-0_11
   Lai J., 2019, P AAAI CONC ART INT
   Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Leibe B., 2017, ARXIV170307737CS
   Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lisanti G, 2017, IEEE I CONF COMP VIS, P2468, DOI 10.1109/ICCV.2017.268
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Liu YH, 2019, AAAI CONF ARTIF INTE, P8786
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Lu C., 2018, P BRIT MACH VIS C
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma XL, 2017, PATTERN RECOGN, V65, P197, DOI 10.1016/j.patcog.2016.11.018
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun YF, 2021, IEEE T PATTERN ANAL, V43, P902, DOI 10.1109/TPAMI.2019.2938523
   Wang HX, 2016, IEEE IMAGE PROC, P769, DOI 10.1109/ICIP.2016.7532461
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang Z, 2020, IEEE T IMAGE PROCESS, V29, P2013, DOI 10.1109/TIP.2019.2946975
   Wang Z, 2019, IEEE T MULTIMEDIA, V21, P2376, DOI 10.1109/TMM.2019.2898753
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wenxin Huang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P174, DOI 10.1007/978-3-319-27671-7_15
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P2042, DOI 10.1109/TIP.2017.2672440
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou SP, 2018, IEEE T MULTIMEDIA, V20, P593, DOI 10.1109/TMM.2017.2755983
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 70
TC 24
Z9 25
U1 1
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 597
EP 610
DI 10.1109/TMM.2020.2985525
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA QI9PL
UT WOS:000619321200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, Y
   Liu, XL
   Wang, BS
   Tao, RS
   Xia, K
   Cao, XB
AF Xu, Yi
   Liu, Xianglong
   Wang, Binshuai
   Tao, Renshuai
   Xia, Ke
   Cao, Xianbin
TI Fast Nearest Subspace Search via Random Angular Hashing
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Large-scale search; nearest subspace search; locality-sensitive hash;
   linear subspace; subspace hashing
ID QUANTIZATION; ALGORITHMS; MODELS; CODES
AB Subspaces frequently offer powerful representation in many tasks including recognition, retrieval, and optimization. In these tasks, the nearest subspaces (i.e., subspace-to-subspace search) often inevitably arise. Several studies in the literature have attempted to address this hard problem using techniques such as locality-sensitive hashing. Unfortunately, these subspace hashing methods are severely affected by poor scaling, with consequently high computational cost or unsatisfying accuracy, when the subspaces originally distribute with arbitrary dimensions. Accordingly, in this paper, we propose random angular hashing, a new and efficient type of locality-sensitive hashing, for linear subspaces of arbitrary dimension. The method we proposed preserves the angular distances among subspaces by randomly projecting their orthonormal basis and then encoding them with binary codes, meanwhile not only achieving fast computation but also maintaining a powerful collision probability. Moreover, its flexibility to easily get a balance between efficiency and accuracy in terms of performance. The extensive experimental results on tasks of face recognition, video de-duplication, and gesture recognition demonstrate that the proposed approach performs better than the state-of-the-art methods heavily, in terms of both accuracy and efficiency (up to 16x speedup).
C1 [Xu, Yi; Liu, Xianglong; Wang, Binshuai; Tao, Renshuai; Xia, Ke] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Xu, Yi; Liu, Xianglong; Wang, Binshuai; Tao, Renshuai; Xia, Ke] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Cao, Xianbin] Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Liu, XL (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM xuyi@nlsde.buaa.edu.cn; xlliu@nlsde.buaa.edu.cn; binshuaiw@gmail.com;
   rstao@buaa.edu.cn; xiake@nlsde.buaa.edu.cn; xbcao@buaa.edu.cn
RI WANG, BINSHUAI/HOF-3778-2023
OI Tao, Renshuai/0000-0001-5695-2009; Liu, Xianglong/0000-0002-7618-3275
FU National Natural Science Foundation of China [61872021, 61690202];
   Beijing Nova Program of Science and Technology [Z191100001119050]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61872021 and 61690202 and in part by
   Beijing Nova Program of Science and Technology under Grant
   Z191100001119050. The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Jingdong Wang.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.553
   Basri R, 2011, IEEE T PATTERN ANAL, V33, P266, DOI 10.1109/TPAMI.2010.110
   Charikar M., 2002, P THIRY 4 ANN ACM S, P380
   Chen SK, 2013, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2013.65
   Chen WC, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P422, DOI 10.1109/PACRIM.2011.6032930
   Cheng J, 2014, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2014.8
   Cherian A, 2014, LECT NOTES COMPUT SC, V8691, P299, DOI 10.1007/978-3-319-10578-9_20
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Harandi MT, 2014, LECT NOTES COMPUT SC, V8695, P408, DOI 10.1007/978-3-319-10584-0_27
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jain P., 2010, NIPS, P928
   Ji JQ, 2015, IEEE T IMAGE PROCESS, V24, P4372, DOI 10.1109/TIP.2015.2451173
   Kim HJ, 2014, LECT NOTES COMPUT SC, V8690, P251, DOI 10.1007/978-3-319-10605-2_17
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Kise K, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P672, DOI 10.1109/ACPR.2011.6166651
   Knyazev AV, 2002, SIAM J SCI COMPUT, V23, P2008, DOI 10.1137/S1064827500377332
   Li J, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107037
   Li K, 2017, IEEE T PATTERN ANAL, V39, P1825, DOI 10.1109/TPAMI.2016.2610969
   Li Q., 2014, P 6 INT C INT MULT C, P148
   Liu SY, 2014, INFO THEOR WORKSH, P636, DOI 10.1109/ITW.2014.6970909
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Liu XL, 2020, IEEE T NEUR NET LEAR, V31, P5312, DOI 10.1109/TNNLS.2020.2965992
   Liu XL, 2017, IEEE T IMAGE PROCESS, V26, P5324, DOI 10.1109/TIP.2017.2729896
   Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275
   Lu YJ, 2009, IEEE T MULTIMEDIA, V11, P1289, DOI 10.1109/TMM.2009.2030632
   Luo CZ, 2016, IEEE T MULTIMEDIA, V18, P40, DOI 10.1109/TMM.2015.2495248
   Marques M, 2009, IEEE I CONF COMP VIS, P1288, DOI 10.1109/ICCV.2009.5459318
   Mu YD, 2014, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2014.130
   Ou MD, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P895, DOI 10.1145/2783258.2783283
   Ou MD, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P230
   Peng C, 2017, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2017.80
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P1724, DOI 10.1109/TMM.2018.2889560
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   Wang BS, 2018, LECT NOTES COMPUT SC, V11164, P15, DOI 10.1007/978-3-030-00776-8_2
   Wang C, 2014, IEEE T MULTIMEDIA, V16, P903, DOI 10.1109/TMM.2014.2306393
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang LW, 2006, PATTERN RECOGN, V39, P456, DOI 10.1016/j.patcog.2005.08.015
   Wang X, 2013, IEEE I CONF COMP VIS, P2776, DOI 10.1109/ICCV.2013.345
   Wang ZH, 2014, LECT NOTES COMPUT SC, V8695, P94, DOI 10.1007/978-3-319-10584-0_7
   Wu F, 2012, INT J MULTIMED INF R, V1, P3, DOI 10.1007/s13735-012-0001-9
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Xu XZ, 2019, IEEE T MULTIMEDIA, V21, P795, DOI 10.1109/TMM.2018.2865834
   Yang B, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON MANAGEMENT INNOVATION AND PUBLIC POLICY (ICMIPP 2012), VOLS 1-6, P1
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Zhang F., 2011, Matrix Theory: Basic Results and Techniques, DOI 10.1007/978-1-4614-1099-7
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
   Zhou L, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107040
   Zhou LW, 2018, MYCOKEYS, P1, DOI 10.3897/mycokeys.29.21250
NR 62
TC 5
Z9 5
U1 1
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 342
EP 352
DI 10.1109/TMM.2020.2977459
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA PJ6LW
UT WOS:000601877600027
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Gao, P
   Liu, SXY
   Zhao, KY
   Li, GT
   Yin, LG
   Chen, CW
AF Zhang, Xinyan
   Gao, Peng
   Liu, Sunxiangyu
   Zhao, Kongya
   Li, Guitao
   Yin, Liuguo
   Chen, Chang Wen
TI Accurate and Efficient Image Super-Resolution via Global-Local Adjusting
   Dense Network
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Feature extraction; Image reconstruction; Computational modeling; Task
   analysis; Computational efficiency; Data mining; Image super-resolution;
   global-local adjusting; separable pyramid upsampling; refinement
   structure
AB Convolutional neural network-based (CNN-based) method has shown its superior performance on the image super-resolution (SR) task. However, several researches have shown that obtaining a better reconstruction result often leads to the significant increase in parameters and computation. To alleviate the burden in computational needs, we propose a novel global-local adjusting dense super-resolution network (GLADSR) to build a powerful yet lightweight CNN-based SR model. To enhance the network capacity, we present a global-local adjusting module (GLAM) which can adaptively reallocate the processing resources with local selective block (LSB) and global guided block (GGB). The GLAMs are linked with nested dense connections to make better use of the global-local adjusted features. In addition, we also introduce a separable pyramid upsampling (SPU) module to replace the regular upsampling operation, which thus brings a substantial reduction of its parameters and obtains better results. Furthermore, we show that the proposed refinement structure is capable of reducing image artifacts in SR processing. Extensive experiments on benchmark datasets show that the proposed GLADSR outperforms the state-of-the-art methods with much fewer parameters and much less computational cost.
C1 [Zhang, Xinyan; Liu, Sunxiangyu; Zhao, Kongya; Li, Guitao] Tsinghua Univ, Sch Aerosp Engn, Beijing 100084, Peoples R China.
   [Zhang, Xinyan; Liu, Sunxiangyu; Zhao, Kongya; Li, Guitao; Yin, Liuguo] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Gao, Peng] Coll Engn, Beijing 100871, Peoples R China.
   [Chen, Chang Wen] Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen 518172, Peoples R China.
   [Chen, Chang Wen] Univ Buffalo State Univ New York, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
C3 Tsinghua University; Tsinghua University; The Chinese University of Hong
   Kong, Shenzhen; State University of New York (SUNY) System; State
   University of New York (SUNY) Buffalo
RP Li, GT (corresponding author), Tsinghua Univ, Sch Aerosp Engn, Beijing 100084, Peoples R China.; Gao, P (corresponding author), Coll Engn, Beijing 100871, Peoples R China.
EM zhangxinyan2016@gmail.com; gaopeng1982@pku.edu.cn;
   lsxy14@mails.tsinghua.edu.cn; zhaoky15@mails.tsinghua.edu.cn;
   ligt@mail.tsinghua.edu.cn; yinlg@tsinghua.edu.cn; chencw@buffalo.edu
RI ; Yin, Liuguo/Y-8434-2018
OI gao, peng/0000-0002-7353-3137; Yin, Liuguo/0000-0002-4441-9490; Chen,
   Chang Wen/0000-0002-6720-234X
FU National Key Research and Development Program of China [2018YFD1100303];
   National Natural Science Foundation of China [91538203, 61871257]
FX Manuscript received December 20, 2019; revised April 8, 2020; accepted
   June 17, 2020. Date of publication June 25, 2020; date of current
   version June 25, 2021. This work was supported in part by the National
   Key Research and Development Program of China under Grant
   2018YFD1100303, and in part by the National Natural Science Foundation
   of China under Grants 91538203 and 61871257. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. J. M. Ascenso.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   [Anonymous], IN PRESS, DOI DOI 10.1109/TMM.2019.2960586
   [Anonymous], IN PRESS, DOI DOI 10.1109/TCSVT.2019.2925844
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cai JR, 2019, IEEE I CONF COMP VIS, P3086, DOI 10.1109/ICCV.2019.00318
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Han D, 2015, PROC CVPR IEEE, P5016, DOI 10.1109/CVPR.2015.7299136
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang K, 2019, IEEE T GEOSCI REMOTE, V57, P5799, DOI 10.1109/TGRS.2019.2902431
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Kumar N, 2016, IEEE T MULTIMEDIA, V18, P1504, DOI 10.1109/TMM.2016.2571625
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Shao ZF, 2019, IEEE J-STARS, V12, P2663, DOI 10.1109/JSTARS.2019.2925456
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi Y, 2017, IEEE T MULTIMEDIA, V19, P2804, DOI 10.1109/TMM.2017.2711263
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vu T, 2019, LECT NOTES COMPUT SC, V11133, P243, DOI 10.1007/978-3-030-11021-5_16
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2019, IEEE T IMAGE PROCESS, V28, P2530, DOI 10.1109/TIP.2018.2887017
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P328, DOI 10.1109/TMM.2018.2863602
   Yu J., 2018, P IEEE C COMPUTER VI
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang Yang, 2019, INT C LEARN REPR
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang ZF, 2019, PROC CVPR IEEE, P7974, DOI 10.1109/CVPR.2019.00817
   Zhou LG, 2019, IEEE T NEUR NET LEAR, V30, P3275, DOI 10.1109/TNNLS.2018.2890550
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
NR 58
TC 21
Z9 22
U1 0
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 1924
EP 1937
DI 10.1109/TMM.2020.3005025
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA TC8FT
UT WOS:000668875100008
DA 2024-07-18
ER

PT J
AU Zhao, C
   Gao, W
   Nie, FP
AF Zhao, Chen
   Gao, Wu
   Nie, Feiping
TI A Resource-Efficient Parallel Connected Component Labeling Algorithm and
   Its Hardware Implementation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Hardware; Labeling; Random access memory; Memory management;
   System-on-chip; Registers; Feature extraction; Connected component
   labeling (CCL); embedded system; parallel; resource-efficient;
   single-scan
ID VLSI ARCHITECTURE; DESIGN
AB Connected Component labeling (CCL) is usually time-consuming, so a dedicated hardware accelerator of CCL is essential in the embedded vision and multimedia system. In this paper, we propose a single-scan resource-efficient parallel CCL algorithm. Our CCL method scans two adjacent rows simultaneously to extract runs and detect equivalent runs; an equivalent label set is used to resolve equivalences. After each row scan, the finished objects are output in time, and the freed memory resources are reused to reduce memory requirements. Both pixel-based labeled image (PLI) and run-based labeled image (RLI) can be generated by our CCL method. In addition, the steps of our CCL method are executed concurrently to improve labeling performance. The hardware architecture based on our CCL method is implemented with Verilog. The evaluation results illustrate that our CCL architecture can label more than 40 2048 x 1536 benchmark images per second on average, and outperforms previous CCL architectures in terms of labeling performance or memory resource consumption.
C1 [Zhao, Chen; Gao, Wu; Nie, Feiping] Northwestern Polytech Univ, Sch Comp, Xian 710129, Peoples R China.
C3 Northwestern Polytechnical University
RP Zhao, C (corresponding author), Northwestern Polytech Univ, Sch Comp, Xian 710129, Peoples R China.
EM chenzhao@nwpu.edu.cn; gaowu@nwpu.edu.cn; feipingnie@gmail.com
RI Nie, Feiping/B-3039-2012
OI Nie, Feiping/0000-0002-0871-6519
FU Fundamental Research Funds for the Central Universities [G2018KY0304]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities under Grant G2018KY0304. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Chang-Su Kim. (Corresponding author: Chen Zhao.)
   The authors are with the School of Computer, Northwestern Polytechnical
   University, Xi'an 710129, China
CR Allegretti S, 2020, IEEE T PARALL DISTR, V31, P423, DOI 10.1109/TPDS.2019.2934683
   [Anonymous], 2020, USC SIPI IMAGE DATAB
   Appiah K, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, P177, DOI 10.1109/FPT.2008.4762381
   Asad P, 2019, IEEE T IMAGE PROCESS, V28, P17, DOI 10.1109/TIP.2018.2851445
   Bailey DG, 2008, I C FIELD PROG LOGIC, P678
   Bolelli F, 2020, J REAL-TIME IMAGE PR, V17, P229, DOI 10.1007/s11554-018-0756-1
   Chang F, 2004, COMPUT VIS IMAGE UND, V93, P206, DOI 10.1016/j.cviu.2003.09.002
   Chang WY, 2015, SENSORS-BASEL, V15, P23763, DOI 10.3390/s150923763
   Dae Ro Lee, 2007, 2007 International Conference on Control, Automation and Systems - ICCAS '07, P2313
   Eusse JF, 2014, DES AUT TEST EUROPE
   Flatt H, 2008, IEEE INT CONF ASAP, P144, DOI 10.1109/ASAP.2008.4580169
   Grana C, 2010, IEEE T IMAGE PROCESS, V19, P1596, DOI 10.1109/TIP.2010.2044963
   He LF, 2008, IEEE T IMAGE PROCESS, V17, P749, DOI 10.1109/TIP.2008.919369
   He LF, 2017, PATTERN RECOGN, V70, P25, DOI 10.1016/j.patcog.2017.04.018
   He LF, 2015, IEEE T IMAGE PROCESS, V24, P2725, DOI 10.1109/TIP.2015.2425540
   He LF, 2014, IEEE T IMAGE PROCESS, V23, P943, DOI 10.1109/TIP.2013.2289968
   Hedberg H, 2007, IEEE INT SYMP CIRC S, P1101, DOI 10.1109/ISCAS.2007.378202
   Trinh H, 2018, IEEE T MULTIMEDIA, V20, P2562, DOI 10.1109/TMM.2018.2865661
   Johnston CT, 2008, DELTA 2008: FOURTH IEEE INTERNATIONAL SYMPOSIUM ON ELECTRONIC DESIGN, TEST AND APPLICATIONS, PROCEEDINGS, P228, DOI 10.1109/DELTA.2008.21
   Klaiber M, 2012, 2012 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT'12), P159, DOI 10.1109/FPT.2012.6412129
   Klaiber MJ, 2016, IEEE T CIRC SYST VID, V26, P1334, DOI 10.1109/TCSVT.2015.2450371
   Klaiber MJ, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P302, DOI 10.1109/FPT.2013.6718372
   Kumar VS, 2010, IEEE COMP SOC ANN, P116, DOI 10.1109/ISVLSI.2010.89
   Li B., 2017, J REAL TIME IMAGE PR, P1
   Lin CY, 2010, IEEE IMAGE PROC, P3753, DOI 10.1109/ICIP.2010.5653457
   Long CC, 2018, IEEE T MULTIMEDIA, V20, P1126, DOI 10.1109/TMM.2017.2764330
   Ma N, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, P185, DOI 10.1109/FPT.2008.4762382
   Martín-Herrero J, 2007, MACH VISION APPL, V18, P1, DOI 10.1007/s00138-006-0041-3
   Playne DP, 2018, IEEE T PARALL DISTR, V29, P1217, DOI 10.1109/TPDS.2018.2799216
   Ricardo A. A., 2016, SENSORS-BASEL, V16
   ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570
   Shen WW, 2016, IEEE T MULTIMEDIA, V18, P1022, DOI 10.1109/TMM.2016.2532606
   Spagnolo F., 2018, J LOW POWER ELECT AP, V8
   Sun HM, 2017, IEEE T MULTIMEDIA, V19, P2375, DOI 10.1109/TMM.2017.2700629
   Suzuki K, 2003, COMPUT VIS IMAGE UND, V89, P1, DOI 10.1016/S1077-3142(02)00030-9
   Tekleyohannes M, 2017, DES AUT TEST EUROPE, P734, DOI 10.23919/DATE.2017.7927085
   Weng HM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1120, DOI 10.1109/ICASSP.2018.8462298
   Yang SW, 2005, IEEE INT SYMP CIRC S, P2393
   Zhang B, 2018, IEEE T CIRC SYST VID, V28, P1434, DOI 10.1109/TCSVT.2017.2665489
   Zhao C, 2020, IEEE T CIRC SYST VID, V30, P3238, DOI 10.1109/TCSVT.2019.2937189
   Zhao C, 2017, J SIGNAL PROCESS SYS, V88, P55, DOI 10.1007/s11265-016-1126-5
   Zhao C, 2014, MICROPROCESS MICROSY, V38, P451, DOI 10.1016/j.micpro.2014.03.010
   Zhao F, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-21
   Zhao X, 2015, IEICE T INF SYST, VE98D, P2013, DOI 10.1587/transinf.2015EDL8135
NR 44
TC 0
Z9 0
U1 1
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 4184
EP 4197
DI 10.1109/TMM.2020.3037511
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA XA2YU
UT WOS:000720519900021
DA 2024-07-18
ER

PT J
AU Zhou, ML
   Wei, XK
   Kwong, S
   Jia, WJ
   Fang, B
AF Zhou, Mingliang
   Wei, Xuekai
   Kwong, Sam
   Jia, Weijia
   Fang, Bin
TI Rate Control Method Based on Deep Reinforcement Learning for Dynamic
   Video Sequences in HEVC
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Encoding; Video sequences; Heuristic algorithms; Distortion; Bit rate;
   Video coding; Optimization; Reinforcement learning; rate control;
   rate-distortion optimization; dynamically changing video
ID LEVEL RATE CONTROL; BIT ALLOCATION; GAME-THEORY; SCHEME; MODELS
AB Rate control (RC) plays a critical role in the transmission of high-quality video data under certain bandwidth restrictions in High Efficiency Video Coding (HEVC). Most current HEVC RC algorithms based on spatio-temporal information for rate-distortion (R-D) model parameters cannot effectively handle the cases with dynamic video sequences that contain fast moving objects, significant object occlusion or scene changes. In this paper, we propose an RC method based on deep reinforcement learning (DRL) for dynamic video sequences in HEVC to improve the coding efficiency. First, the rate control problem is formulated as a Markov decision process (MDP) problem. Second, with the MDP model, we develop a DRL-based algorithm to find the optimal quantization parameters (QPs) by training a deep neural network. The resulting intelligent agent selects the optimal RC strategy to reduce distortion, buffer and quality fluctuations by observing the current state of the encoder. The asynchronous advantage actor-critic (A3C) method is used to solve the MDP problem. Finally, the proposed DRL-based RC method is implemented in the newest video coding standard. Experimental results show that the proposed method offers substantially enhanced RC accuracy and consistently outperforms HEVC reference software and other state-of-the-art algorithms.
C1 [Zhou, Mingliang; Fang, Bin] Chongqing Univ, Sch Comp Sci, Chongqing 400044, Peoples R China.
   [Zhou, Mingliang; Jia, Weijia] Univ Macau, State Key Lab Internet Things Smart City, Taipa 999078, Macau, Peoples R China.
   [Wei, Xuekai; Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong 999077, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
   [Jia, Weijia] Beijing Normal Univ & UIC Zhuhai, BNU UIC Joint AI Res Inst, Zhuhai 519087, Guangdong, Peoples R China.
C3 Chongqing University; University of Macau; City University of Hong Kong;
   Shenzhen Research Institute, City University of Hong Kong; City
   University of Hong Kong
RP Zhou, ML (corresponding author), Chongqing Univ, Sch Comp Sci, Chongqing 400044, Peoples R China.; Kwong, S (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong 999077, Peoples R China.
EM mingliangzhou@cqu.edu.cn; xuekaiwei2-c@my.cityu.edu.hk;
   cssamk@cityu.edu.hk; jiawj@um.edu.mo; fb@cqu.edu.cn
RI ZHOU, MING/JVP-2920-2024; Zhou, Mingliang/HPC-0298-2023; Kwong,
   Sam/C-9319-2012
OI Kwong, Sam/0000-0001-7484-7261; WEI, Xuekai/0000-0002-3761-1759; Zhou,
   Mingliang/0000-0002-1874-3641
FU Key Project of Science and Technology Innovation 2030 - Ministry of
   Science and Technology of China [2018AAA0101301]; Natural Science
   Foundation of China [61871342, 61772344, 61672443, 61876026]; Hong Kong
   RGC General Research Funds [9042820, CityU 11219019, 9042489, CityU
   11206317, 9042322, CityU 11200116, 9048123, CityU 21211518]; Chongqing
   University [02160011044118]; Research on Key Technologies of Pedestrian
   Recognition for Different Resolution [qnsy2018006]; Research on Key
   Technologies of pedestrian recognition in complex scenes [CST_2019SN02];
   Research on pedestrian recognition for monitoring Qiannan Kehe
   discipline construction [7]
FX This work was supported in part by the Key Project of Science and
   Technology Innovation 2030 supported by the Ministry of Science and
   Technology of China under Grant 2018AAA0101301, in part by the Natural
   Science Foundation of China under Grants 61871342, 61772344, and
   61672443, in part by the Hong Kong RGC General Research Funds under
   Grants 9042820 (CityU 11219019), 9042489 (CityU 11206317), 9042322
   (CityU 11200116), and 9048123 (CityU 21211518), in part by the Chongqing
   University under Grant 02160011044118, in part by the Natural Science
   Foundation of China under Grant 61876026, in part by the Research on Key
   Technologies of Pedestrian Recognition for Different Resolution under
   Grant qnsy2018006, in part by the Research on Key Technologies of
   pedestrian recognition in complex scenes under Grant CST_2019SN02, and
   in part by the Research on pedestrian recognition for monitoring Qiannan
   Kehe discipline construction under Grant Zi(2018)No.7. The associate
   editor coordinating the review of this manuscript and approving it for
   publicationwas Dr. ChuanWu.
CR [Anonymous], 2013, PROC VIS COMMUN IMAG
   Bross B, 2012, P JOINT COLL TEAM VI
   Changuel N, 2010, INT CONF ACOUST SPEE, P914, DOI 10.1109/ICASSP.2010.5495280
   Dong JP, 2009, IEEE T CIRC SYST VID, V19, P1108, DOI 10.1109/TCSVT.2009.2020338
   Fang JT, 2013, I SYMP CONSUM ELECTR, P241
   Gao W, 2017, IEEE T IMAGE PROCESS, V26, P6074, DOI 10.1109/TIP.2017.2745099
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   He Y, P 4 INT C INF COMM S, V3, P1370
   He ZH, 2008, IEEE T MULTIMEDIA, V10, P1237, DOI 10.1109/TMM.2008.2004903
   Hu H.-M., J VISUAL COMMUN IMAG, V42, P46
   Hu JH, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351575
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Lee C, 2007, IEEE T CONSUM ELECTR, V53, P1084, DOI 10.1109/TCE.2007.4341589
   Lee CH, 2007, 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS APPLICATIONS TO POWER SYSTEMS, VOLS 1 AND 2, P87
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P1271, DOI 10.1109/TCSVT.2006.881856
   [李斌 Li Bin], 2013, [中药药理与临床, Pharmacology and Clinics of Chinese Materia Medica], V29, P1
   Li Bin, 2012, ITU-T SG16 Contribution, JCTVC-K0103, P1
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Li Y, 2018, P RAT CONTR IMPR VVC, P1
   Li ZG, 2004, IEEE IMAGE PROC, P745
   Lin WY, 2008, IEEE T CIRC SYST VID, V18, P1128, DOI 10.1109/TCSVT.2008.927111
   Mansour H, 2011, IEEE T MULTIMEDIA, V13, P165, DOI 10.1109/TMM.2010.2099648
   Mao HZ, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P197, DOI 10.1145/3098822.3098843
   Mukhopadhyay S, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P48, DOI 10.1109/ICMLA.2018.00015
   Sanz-Rodríguez S, 2011, IEEE T CIRC SYST VID, V21, P1263, DOI 10.1109/TCSVT.2011.2143330
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Si J., 2013, P VIS COMM IM PROC N, P1
   Soh Y. C., 2006, P IEEE INT C AC SPEE, V2, pII905
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang LM, 2000, SIGNAL PROCESS-IMAGE, V15, P493, DOI 10.1016/S0923-5965(99)00009-0
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wang TY, 2006, INT CONF SIGN PROCES, P101
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P4529, DOI 10.1109/TIP.2018.2837106
   Yan L, 2003, P INT C IM PROC SEP, V3
   Zhou M., 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, P1, DOI 10.1109/OCEANS.2014.7003239
   Zhou ML, 2019, IEEE T MULTIMEDIA, V21, P1921, DOI 10.1109/TMM.2019.2895281
   Zhou ML, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107616
NR 38
TC 33
Z9 33
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 1106
EP 1121
DI 10.1109/TMM.2020.2992968
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA QO8XK
UT WOS:000623420300022
DA 2024-07-18
ER

PT J
AU Zuo, XX
   Wang, S
   Zheng, JB
   Yu, WW
   Gong, ML
   Yang, RG
   Cheng, L
AF Zuo, Xinxin
   Wang, Sen
   Zheng, Jiangbin
   Yu, Weiwei
   Gong, Minglun
   Yang, Ruigang
   Cheng, Li
TI SparseFusion: Dynamic Human Avatar Modeling From Sparse RGBD Images
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image reconstruction; Three-dimensional displays; Shape; Biological
   system modeling; Solid modeling; Surface reconstruction; Tracking; RGBD;
   human body; non-rigid fusion
ID CAPTURE; MULTIVIEW; SHAPE; RECONSTRUCTION; TRACKING; OBJECTS
AB In this paper, we propose a novel approach to reconstruct 3D human body shapes based on a sparse set of RGBD frames using a single RGBD camera. We specifically focus on the realistic settings where human subjects move freely during the capture. The main challenge is how to robustly fuse these sparse frames into a canonical 3D model, under pose changes and surface occlusions. This is addressed by our new framework consisting of the following steps. First, based on a generative human template, for every two frames having sufficient overlap, an initial pairwise alignment is performed; It is followed by a global non-rigid registration procedure, in which partial results from RGBD frames are collected into a unified 3D shape, under the guidance of correspondences from the pairwise alignment; Finally, the texture map of the reconstructed human model is optimized to deliver a clear and spatially consistent texture. Empirical evaluations on synthetic and real datasets demonstrate both quantitatively and qualitatively the superior performance of our framework in reconstructing complete 3D human models with high fidelity. It is worth noting that our framework is flexible, with potential applications going beyond shape reconstruction. As an example, we showcase its use in reshaping and reposing to a new avatar.
C1 [Zuo, Xinxin; Wang, Sen; Zheng, Jiangbin; Yu, Weiwei] Northwestern Polytech Univ, Xian 710072, Peoples R China.
   [Zuo, Xinxin; Wang, Sen; Yang, Ruigang] Univ Kentucky, Lexington, KY 40508 USA.
   [Zuo, Xinxin; Wang, Sen; Cheng, Li] Univ Alberta, Edmonton, AB T6G 2R3, Canada.
   [Gong, Minglun] Univ Guelph, Guelph, ON N1G 2W1, Canada.
C3 Northwestern Polytechnical University; University of Kentucky;
   University of Alberta; University of Guelph
RP Zheng, JB (corresponding author), Northwestern Polytech Univ, Xian 710072, Peoples R China.; Cheng, L (corresponding author), Univ Alberta, Edmonton, AB T6G 2R3, Canada.
EM xinxin.zuo@uky.edu; wangsen1312@gmail.com; zhengjb@nwpu.edu.cn;
   yuweiwei@nwpu.edu.cn; minglun@uoguelph.ca; ryang@cs.uky.edu;
   lcheng5@ualberta.ca
RI Zuo, Xinxin/AAI-8439-2020; Gong, Minglun/AAU-3103-2020; Yu,
   Wei/GZL-3831-2022; Wang, Sen/AAM-1118-2020; YU, Wei/HTP-9667-2023
OI Zuo, Xinxin/0000-0002-7116-9634; Gong, Minglun/0000-0001-5820-5381;
   Wang, Sen/0000-0002-1808-5239; 
FU USDA [2018-67021-27416]; NSFC [61972321, 61603302]; NSERC
   [RGPIN-2019-04575]; University of Alberta-Huawei Joint Innovation
   Collaboration grants; Key R&D plan of Shaanxi Province [2019GY-120]; 111
   Project [B13044]
FX This work was supported in part by the USDA under Grant
   2018-67021-27416, in part by NSFC under Grants 61972321 and 61603302, in
   part by NSERC Discovery under Grant RGPIN-2019-04575, in part by
   University of Alberta-Huawei Joint Innovation Collaboration grants, in
   part by Key R&D plan of Shaanxi Province (No. 2019GY-120), and in part
   by the 111 Project under Grant B13044. The associate editor coordinating
   the review of this manuscript and approving it for publication was
   Sebastian Knorr.
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Alldieck T, 2018, INT CONF 3D VISION, P98, DOI 10.1109/3DV.2018.00022
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2017, ACM Transactions on Graphics (TOG), DOI DOI 10.1145/3083722
   [Anonymous], 2009, ACM T GRAPHIC
   Bogo F, 2015, IEEE I CONF COMP VIS, P2300, DOI 10.1109/ICCV.2015.265
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   CMU, CMU MOC DAT
   Cui Y., 2012, ACCV Workshops, P133
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Dou MS, 2015, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2015.7298647
   Dou MS, 2013, INT SYM MIX AUGMENT, P99, DOI 10.1109/ISMAR.2013.6671769
   Fechteler P, 2019, COMPUT GRAPH FORUM, V38, P91, DOI 10.1111/cgf.13608
   Gal R, 2010, COMPUT GRAPH FORUM, V29, P479, DOI 10.1111/j.1467-8659.2009.01617.x
   Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056
   Geman S., 1987, Bull. Internat. Statist. Inst., V4, P5
   Guo KW, 2015, IEEE I CONF COMP VIS, P3083, DOI 10.1109/ICCV.2015.353
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Hao L, 2013, ACM T GRAPHIC, V32
   Huang Z, 2018, P EUR C COMP VIS, P336
   Innmann M, 2016, LECT NOTES COMPUT SC, V9912, P362, DOI 10.1007/978-3-319-46484-8_22
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Liang JB, 2019, IEEE I CONF COMP VIS, P4351, DOI 10.1109/ICCV.2019.00445
   Lin S, 2016, VISUAL COMPUT, V32, P681, DOI 10.1007/s00371-016-1245-9
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mao AH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051113
   METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Poser, POS SOFTW
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Shapiro A, 2014, COMPUT ANIMAT VIRT W, V25, P201, DOI 10.1002/cav.1579
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Tang SC, 2019, IEEE I CONF COMP VIS, P7749, DOI 10.1109/ICCV.2019.00784
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Tung HYF, 2017, ADV NEUR IN, V30
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Wang S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030886
   Wu CL, 2011, IEEE T VIS COMPUT GR, V17, P1082, DOI [10.1109/TVCG.2010.224, 10.1109/TPDS.2010.224]
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Yu T, 2019, PROC CVPR IEEE, P5499, DOI 10.1109/CVPR.2019.00565
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Yu T, 2017, IEEE I CONF COMP VIS, P910, DOI 10.1109/ICCV.2017.104
   Zhang Q, 2014, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2014.92
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhu H, 2019, PROC CVPR IEEE, P4486, DOI 10.1109/CVPR.2019.00462
   Zhu H, 2017, IEEE T CIRC SYST VID, V27, P760, DOI 10.1109/TCSVT.2016.2596118
   Zollhöfer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165
NR 57
TC 9
Z9 9
U1 5
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PY 2021
VL 23
BP 1617
EP 1629
DI 10.1109/TMM.2020.3001506
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA SJ9EZ
UT WOS:000655830300011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gao, JY
   Xu, CS
AF Gao, Junyu
   Xu, Changsheng
TI CI-GNN: Building a Category-Instance Graph for Zero-Shot Video
   Classification
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Semantics; Task analysis; Visualization; Training; Message passing;
   Pattern recognition; Neural networks; Zero-shot video classification;
   graph neural network; zero-shot learning
ID LEARNING FRAMEWORK; NEURAL-NETWORK
AB With the ever-growing video categories, Zero-Shot Learning (ZSL) in video classification has drawn considerable attention in recent years. To transfer the learned knowledge from seen categories to unseen categories, most existing methods resort to an implicit model that learns a projection between visual features and semantic category-representations. However, such methods ignore the explicit relationships among video instances and categories, which impede the direct information propagation in a Category-Instance graph (CI-graph) consisting of both instances and categories. In fact, exploring the structure of the CI-graph can capture the invariances of the ZSL task with good generality for unseen instances. Inspired by these observations, we propose an end-to-end framework to directly and collectively model the relationships between category-instance, category-category, and instance-instance in the CI-graph. Specifically, to construct node features of this graph, we adopt object semantics as a bridge to generate unified representations for both videos and categories. Motivated by the favorable performance of Graph Neural Networks (GNNs), we design a Category-Instance GNN (CI-GNN) to adaptively model the structure of the CI-graph and propagate information among categories and videos. With the task-driven message passing process, the learned model is able to transfer label information from categories towards unseen videos. Extensive experiments on four video datasets demonstrate the favorable performance of the proposed framework.
C1 [Gao, Junyu; Xu, Changsheng] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
   [Gao, Junyu; Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
   [Gao, Junyu; Xu, Changsheng] PengCheng Lab, Shenzhen 518066, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Xu, CS (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.; Xu, CS (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
EM gaojunyu2015@ia.ac.cn; csxu@nlpr.ia.ac.cn
RI xu, cj/HJZ-3488-2023; Gao, Junyu/HDO-5516-2022; Xu, Chang/GQP-7280-2022
OI xu, chang sheng/0000-0001-8343-9665
FU National Natural Science Foundation of China [61720106006, 61721004,
   61832002, 61532009, U1705262, U1836220, 61702511]; Key Research Program
   of Frontier Sciences, CAS [QYZDJSSWJSC039]; Research Program of National
   Laboratory of Pattern Recognition [Z-2018007]
FX This work was supported in part by the National Natural Science
   Foundation of China underGrants 61720106006, 61721004, 61832002,
   61532009, U1705262, U1836220, and 61702511, in part by the Key Research
   Program of Frontier Sciences, CAS, under Grant QYZDJSSWJSC039, and in
   part by the Research Program of National Laboratory of Pattern
   Recognition under Grant Z-2018007. The associate editor coordinating the
   review of this manuscript and in part by the approving it for
   publication was Dr. G.-J. Qi.
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Alexiou I, 2016, IEEE IMAGE PROC, P4190, DOI 10.1109/ICIP.2016.7533149
   [Anonymous], MULTIMEDIA
   Baradel F, 2018, LECT NOTES COMPUT SC, V11217, P106, DOI 10.1007/978-3-030-01261-8_7
   Battaglia, 2018, ARXIV180601261
   Bruna J., 2014, P INT C LEARN REPR
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheng ZQ, 2017, IEEE T MULTIMEDIA, V19, P1170, DOI 10.1109/TMM.2016.2647386
   Defferrard Michael, 2016, ADV NEURAL INFORM PR, P3837, DOI DOI 10.5555/3157382.3157527
   Feng YA, 2019, IEEE T MULTIMEDIA, V21, P1762, DOI 10.1109/TMM.2018.2885237
   Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128
   Gan C, 2016, AAAI CONF ARTIF INTE, P3487
   Gan C, 2015, AAAI CONF ARTIF INTE, P3769
   Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Gao JY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P690, DOI 10.1145/3240508.3240566
   Gao JY, 2019, IEEE T IMAGE PROCESS, V28, P3923, DOI 10.1109/TIP.2019.2904434
   Gao JY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P127, DOI 10.1145/3123266.3123433
   Gao JY, 2018, IEEE T IMAGE PROCESS, V27, P3074, DOI 10.1109/TIP.2018.2813166
   Gao JY, 2017, IEEE T IMAGE PROCESS, V26, P1845, DOI 10.1109/TIP.2017.2656628
   Hamilton W., 2017, PROC NIPS
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Jain M, 2015, IEEE I CONF COMP VIS, P4588, DOI 10.1109/ICCV.2015.521
   Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Kim H, 2018, IEEE T MULTIMEDIA, V20, P2415, DOI 10.1109/TMM.2018.2806224
   Kingma D. P., 2014, arXiv
   Kipf TN, 2016, ARXIV
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170
   Li YN, 2019, RARE METALS, V38, P1051, DOI 10.1007/s12598-016-0765-9
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1209, DOI 10.1109/TMM.2016.2645404
   Liu J, 2011, 2011 AASRI CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INDUSTRY APPLICATION (AASRI-AIIA 2011), VOL 4, P333
   Liu SH, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P348, DOI 10.1109/ICISCE.2016.84
   Long Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P636, DOI 10.1145/3123266.3123323
   Ma CY, 2018, PROC CVPR IEEE, P6790, DOI 10.1109/CVPR.2018.00710
   Mandal D, 2019, PROC CVPR IEEE, P9977, DOI 10.1109/CVPR.2019.01022
   Marino K, 2017, PROC CVPR IEEE, P20, DOI 10.1109/CVPR.2017.10
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Mettes P, 2017, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2017.476
   Mettes P, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P175, DOI 10.1145/2911996.2912036
   Mikolov T., 2013, INT C LEARNING REPRE, P1
   Mishra A, 2018, IEEE WINT CONF APPL, P372, DOI 10.1109/WACV.2018.00047
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ni BB, 2014, PROC CVPR IEEE, P756, DOI 10.1109/CVPR.2014.102
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Norouzi M., 2014, ICLR
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qi GJ, 2011, PROC CVPR IEEE, P897, DOI 10.1109/CVPR.2011.5995312
   Qin J, 2017, PROC CVPR IEEE, P1042, DOI 10.1109/CVPR.2017.117
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Rohrbach M, 2016, INT J COMPUT VISION, V119, P346, DOI 10.1007/s11263-015-0851-8
   Satorras V.G., 2018, ICLR
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun LF, 2017, IEEE T MULTIMEDIA, V19, P609, DOI 10.1109/TMM.2016.2635589
   Sun Y, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P143, DOI 10.1109/DMIAF.2016.7574920
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Wang JZ, 2018, IEEE T MULTIMEDIA, V20, P2578, DOI 10.1109/TMM.2018.2855081
   Wang WG, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09389-2
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Wu JL, 2019, IEEE I CONF COMP VIS, P8320, DOI 10.1109/ICCV.2019.00841
   Wu JL, 2019, IEEE INT CON MULTI, P886, DOI 10.1109/ICME.2019.00157
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Wu ZX, 2016, PROC CVPR IEEE, P3112, DOI 10.1109/CVPR.2016.339
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Xu B., 2015, ARXIV150500853, V1505, P853
   Xu X, 2017, INT J COMPUT VISION, V123, P309, DOI 10.1007/s11263-016-0983-5
   Xu X, 2015, IEEE IMAGE PROC, P63, DOI 10.1109/ICIP.2015.7350760
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang XS, 2018, IEEE T MULTIMEDIA, V20, P2360, DOI 10.1109/TMM.2018.2807588
   Yang XS, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2962719
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Zhang CR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1128
   Zhang Zechen., 2018, ACM Trans. Graph, P11
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou J., 2018, AI Open, DOI DOI 10.1016/j.aiopen.2021.01.001
   Zhu Y, 2018, PROC CVPR IEEE, P9436, DOI 10.1109/CVPR.2018.00983
NR 89
TC 35
Z9 35
U1 5
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2020
VL 22
IS 12
BP 3088
EP 3100
DI 10.1109/TMM.2020.2969787
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA OU9BG
UT WOS:000591817700006
DA 2024-07-18
ER

PT J
AU Ma, XH
   Zhang, TZ
   Xu, CS
AF Ma, Xinhong
   Zhang, Tianzhu
   Xu, Changsheng
TI Multi-Level Correlation Adversarial Hashing for Cross-Modal Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Semantics; Correlation; Aircraft propulsion; Deep learning; Bridges;
   Aircraft; Task analysis; Cross-modal retrieval; adversarial hashing;
   multi-level correlation
ID REPRESENTATION; CODES; RANK
AB Cross-modal hashing (CMH) has been widely used for similarity search in multimedia retrieval applications, thanks to low storage cost and fast query speed. However, preserving the content similarities in finite-length hash codes between different data modalities is still challenging due to the existing heterogeneity gap. To further address the crucial bottleneck, we propose a Multi-Level Correlation Adversarial Hashing (MLCAH) algorithm to integrate the multi-level correlation information into hash codes. The proposed MLCAH model enjoys several merits. First, to the best of our knowledge, it is the early attempt of leveraging the multi-level correlation information for cross-modal hashing retrieval. Second, we propose global and local semantic alignment mechanisms, which can effectively encode multi-level correlation information, including global information, local information, and label information into hash codes. Third, a label-consistency attention mechanism with adversarial training is designed for exploiting the local cross-modality similarity from multi-modality data. Extensive evaluations on four benchmarks demonstrate that the proposed model brings significant improvements over several state-of-the-art cross-modal hashing methods.
C1 [Ma, Xinhong; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   [Ma, Xinhong; Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
   [Ma, Xinhong; Xu, Changsheng] Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Zhang, Tianzhu] Univ Sci & Technol China, Sch Informat Sci & Technol, Dept Automat, Hefei 230052, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Peng Cheng Laboratory; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS
RP Xu, CS (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.; Xu, CS (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
EM xinhong.ma@nlpr.ia.ac.cn; tzzhang10@gmail.com; csxu@nlpr.ia.ac.cn
RI Xu, Chang/GQP-7280-2022; xu, cj/HJZ-3488-2023; Xinhong,
   Ma/ACH-5160-2022; Zhang, Tianzhu/AGY-9389-2022
OI Zhang, Tianzhu/0000-0003-0764-6106; Ma, Xinhong/0000-0003-1200-2268; xu,
   chang sheng/0000-0001-8343-9665; zhang, tian zhu/0000-0003-1856-9564
FU National Natural Science Foundation of China [61720106006, 61721004,
   61832002, 61532009, U1705262, U1836220, 61702511, 61802053]; Key
   Research Program of Frontier Sciences, CAS [QYZDJSSWJSC039]; Research
   Program of National Laboratory of Pattern Recognition [Z-2018007]
FX This work was supported in part by the National Natural Science
   Foundation of China underGrants 61720106006, 61721004, 61832002,
   61532009, U1705262, U1836220, 61702511, and 61802053, in part by the Key
   Research Program of Frontier Sciences, CAS under Grant QYZDJSSWJSC039,
   and in part by the Research Program of National Laboratory of Pattern
   Recognition under Grant Z-2018007. The associate editor coordinating the
   review of this manuscript and approving it for publication was Dr.
   Ramazan S Aygun.
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2011, P ICML
   [Anonymous], 2012, Book A probabilistic model for multimodal hash function learning, DOI DOI 10.1145/2339530.2339678
   Bai B, 2010, INFORM RETRIEVAL, V13, P291, DOI 10.1007/s10791-009-9117-9
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen WC, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P422, DOI 10.1109/PACRIM.2011.6032930
   Cui LM, 2019, INT J MULTIMED INF R, V8, P47, DOI 10.1007/s13735-018-0164-0
   Deng C, 2019, IEEE T IMAGE PROCESS, V28, P4032, DOI 10.1109/TIP.2019.2903661
   Deng C, 2016, IEEE T MULTIMEDIA, V18, P208, DOI 10.1109/TMM.2015.2508146
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Ding K, 2017, IEEE T MULTIMEDIA, V19, P571, DOI 10.1109/TMM.2016.2625747
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   He SK, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P1, DOI [10.1109/ISI.2019.8823342, 10.1109/isi.2019.8823342]
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu D, 2019, IEEE T MULTIMEDIA, V21, P973, DOI 10.1109/TMM.2018.2866771
   Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144
   Hu Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P527, DOI 10.1145/2647868.2654906
   Huang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1893
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liong VE, 2017, IEEE I CONF COMP VIS, P4097, DOI 10.1109/ICCV.2017.439
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu XL, 2017, IEEE T IMAGE PROCESS, V26, P5324, DOI 10.1109/TIP.2017.2729896
   Liu XL, 2016, IEEE T CYBERNETICS, V46, P2252, DOI 10.1109/TCYB.2015.2474742
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P4514, DOI 10.1109/TIP.2016.2593344
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P907, DOI 10.1109/TIP.2015.2505180
   Mandal D, 2017, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2017.282
   Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Ou MD, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P230
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Qi JW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P892
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi YF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4767
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang K., 2016, ABS160706215 CORR
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214
   Xu X., 2015, P INT C MULT EXP, P1
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yang E, 2018, IEEE T NEUR NET LEAR, V29, P5292, DOI 10.1109/TNNLS.2018.2793863
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Ye ZD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P852, DOI 10.1145/3240508.3240560
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang J, 2018, AAAI CONF ARTIF INTE, P539
   Zhang X, 2018, LECT NOTES COMPUT SC, V11219, P614, DOI 10.1007/978-3-030-01267-0_36
   Zhang Y, 2018, LECT NOTES COMPUT SC, V11205, P707, DOI 10.1007/978-3-030-01246-5_42
   Zhen Y., 2012, P INT C NEUR INF PRO, P1376
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
NR 73
TC 62
Z9 65
U1 3
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2020
VL 22
IS 12
BP 3101
EP 3114
DI 10.1109/TMM.2020.2969792
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA OU9BG
UT WOS:000591817700007
DA 2024-07-18
ER

PT J
AU Tsai, TJ
   Yang, D
   Shan, MY
   Tanprasert, T
   Jenrungrot, T
AF Tsai, T. J.
   Yang, Daniel
   Shan, Mengyi
   Tanprasert, Thitaree
   Jenrungrot, Teerapat
TI Using Cell Phone Pictures of Sheet Music To Retrieve MIDI Passages
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cellular phones; Music; Runtime; Object detection; Training data; Image
   segmentation; Neural networks; Sheet music; MIDI; passage retrieval;
   cell phone; camera
ID RECOGNITION; IMAGE; NETWORK
AB This article investigates a cross-modal retrieval problem in which a user would like to retrieve a passage of music from a MIDI file by taking a cell phone picture of several lines of sheet music. This problem is challenging for two reasons: it has a significant runtime constraint since it is a user-facing application, and there is very little relevant training data containing cell phone images of sheet music. To solve this problem, we introduce a novel feature representation called a bootleg score which encodes the position of noteheads relative to staff lines in sheet music. The MIDI representation can be converted into a bootleg score using deterministic rules of Western musical notation, and the sheet music image can be converted into a bootleg score using classical computer vision techniques for detecting simple geometrical shapes. Once the MIDI and cell phone image have been converted into bootleg scores, we can estimate the alignment using dynamic programming. The most notable characteristic of our system is that it has no trainable weights at all - only a set of about 40 hyperparameters. With a training set of just 400 images, we show that our system generalizes well to a much larger set of 1600 test images from 160 unseen musical scores. Our system achieves a test F measure score of 0.89, has an average runtime of 0.90 seconds, and outperforms baseline systems based on music object detection and sheet-audio alignment. We provide extensive experimental validation and analysis of our system.
C1 [Tsai, T. J.] Harvey Mudd Coll, Dept Engn, Claremont, CA 91711 USA.
   [Yang, Daniel; Shan, Mengyi] Harvey Mudd Coll, Dept Comp Sci, Claremont, CA 91711 USA.
   [Tanprasert, Thitaree] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
   [Jenrungrot, Teerapat] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.
C3 Claremont Colleges; Harvey Mudd College; Claremont Colleges; Harvey Mudd
   College; University of British Columbia; University of Washington;
   University of Washington Seattle
RP Tsai, TJ (corresponding author), Harvey Mudd Coll, Dept Engn, Claremont, CA 91711 USA.
EM ttsai@g.hmc.edu; dhyang@g.hmc.edu; mshan@g.hmc.edu; tt1996@cs.ubc.ca;
   tjenrung@cs.washington.edu
OI Shan, Mengyi/0000-0002-1520-5979; Yang, Daniel/0000-0002-7684-9057;
   Jenrungrot, Teerapat/0000-0002-8562-7210
FU Brian Butler '89 Faculty Enhancement Fund
FX This work was supported by the Brian Butler '89 Faculty Enhancement
   Fund. The associate editor coordinating the review of this manuscript
   and approving it for publication was Professor Xiaochun Cao.
CR [Anonymous], 2018, ISMIR
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bui HN, 2014, INT C PATT RECOG, P2787, DOI 10.1109/ICPR.2014.480
   Calvo-Zaragoza J., 2018, P INT C MUS INF RETR, P23
   Calvo-Zaragoza J, 2019, PATTERN RECOGN LETT, V128, P115, DOI 10.1016/j.patrec.2019.08.021
   Damm D., 2008, ICMI 08 P 10 INT C M, P205, DOI [10.1145/1452392.1452436, DOI 10.1145/1452392.1452436]
   Damm D, 2012, INT J DIGIT LIBRARIE, V12, P53, DOI 10.1007/s00799-012-0087-y
   Dorfer M., 2018, Trans. Int. Soc. Music. Inf. (TISMIR), V1, P22, DOI DOI 10.5334/TISMIR.12
   Dorfer M., 2018, P INT C MUS INF RETR, P784
   Dorfer M., 2016, PROC LATE BREAKING D
   Dorfer Matthias, 2017, P INT SOC MUS INF RE, P115
   Dorfer Matthias, 2016, P 17 ISMIR C, P789, DOI [10.5281/zenodo.1415548, DOI 10.5281/ZENODO.1415548]
   Fremerey C., 2008, P C INT SOC MUSIC IN, P413
   Fremerey Christian, 2009, P INT C MUS INF RETR, P645
   Hajic J., 2018, 19 INT SOC MUSIC INF
   Hajic J, 2017, PROC INT CONF DOC, P39, DOI 10.1109/ICDAR.2017.16
   Hu D, 2019, IEEE T MULTIMEDIA, V21, P973, DOI 10.1109/TMM.2018.2866771
   Hu YT, 2018, IEEE T MULTIMEDIA, V20, P927, DOI 10.1109/TMM.2017.2760101
   Huang ZQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132645
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Izmirli Ozgur, 2012, P INT SOC MUS INF RE, P61
   Jing CC, 2019, IEEE T MULTIMEDIA, V21, P782, DOI 10.1109/TMM.2018.2866222
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kurth F., 2007, P ISMIR 8 INT SOC MU, P261
   Larsson M, 2012, SEX REPROD HEALTHC, V3, P1, DOI 10.1016/j.srhc.2012.01.001
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Min WQ, 2017, IEEE T MULTIMEDIA, V19, P1100, DOI 10.1109/TMM.2016.2639382
   Müller M, 2019, IEEE SIGNAL PROC MAG, V36, P52, DOI 10.1109/MSP.2018.2868887
   Muller M., 2015, FUNDAMENTALS MUSIC P
   Nagrani A, 2018, LECT NOTES COMPUT SC, V11217, P73, DOI 10.1007/978-3-030-01261-8_5
   Nikandish G, 2019, IEEE ACCESS, V7, P57138, DOI 10.1109/ACCESS.2019.2914563
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pacha A, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091488
   Pacha A, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P163, DOI 10.1109/DAS.2018.51
   Pacha Alexander., 2018, Proceedings of the 19th International Society for Music Information Retrieval Conference, P240, DOI [10.5281/zenodo.1492393, DOI 10.5281/ZENODO.1492393]
   Vo QN, 2016, PATTERN RECOGN LETT, V69, P88, DOI 10.1016/j.patrec.2015.10.017
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rico A, 2017, PROC INT CONF DOC, P27, DOI 10.1109/ICDAR.2017.261
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Singh G, 2019, ADV INTELL SYST, V748, P411, DOI 10.1007/978-981-13-0923-6_36
   Song G, 2019, IEEE T MULTIMEDIA, V21, P1261, DOI 10.1109/TMM.2018.2877122
   Tanprasert T., 2019, P INT SOC MUS INF RE, P91
   Tuggener L, 2018, INT C PATT RECOG, P3704, DOI 10.1109/ICPR.2018.8545307
   van der Wel E, 2017, ARXIV170704877
   Vo QN, 2014, INT C PATT RECOG, P2956, DOI 10.1109/ICPR.2014.510
   Wu XX, 2016, IEEE T MULTIMEDIA, V18, P1305, DOI 10.1109/TMM.2016.2557722
   Xu P, 2018, NEUROCOMPUTING, V278, P75, DOI 10.1016/j.neucom.2017.05.099
   Yang D., 2019, P INT SOC MUSIC INFO, P916
   Yu E, 2019, IEEE T MULTIMEDIA, V21, P1276, DOI 10.1109/TMM.2018.2877127
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
NR 57
TC 4
Z9 4
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2020
VL 22
IS 12
BP 3115
EP 3127
DI 10.1109/TMM.2020.2973831
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA OU9BG
UT WOS:000591817700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sun, JN
   Yang, WM
   Xue, JH
   Liao, QM
AF Sun, Jingna
   Yang, Wenming
   Xue, Jing-Hao
   Liao, Qingmin
TI An Equalized Margin Loss for Face Recognition
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Face recognition; Face; Data mining; Measurement; Training; Sun; Image
   recognition; Face recognition; equalized margin (EqM) loss; intra-class
   scope; inter-class margin; deep learning
ID SOFTMAX
AB In this paper, we propose a new loss function, termed the equalized margin (EqM) loss, which is designed to make both intra-class scopes and inter-class margins similar over all classes, such that all the classes can be evenly distributed on the hypersphere of the feature space. The EqM loss controls both the lower limit of intra-class similarity by exploiting hard-sample mining and the upper limit of inter-class similarity by assuring equalized margins. Therefore, using the EqM loss, we can not only obtain more discriminative features, but also overcome the negative impacts from the data imbalance on the inter-class margins. We also observe that the EqM loss is stable with the variation of the scale in normalized Softmax. Furthermore, by conducting extensive experiments on LFW, YTF, CFP, MegaFace and IJB-B, we are able to verify the effectiveness and superiority of the EqM loss, compared with other state-of-the-art loss functions for face recognition.
C1 [Sun, Jingna; Yang, Wenming; Liao, Qingmin] Tsinghua Univ, Shenzhen Key Lab Informat & Sci Technol, Shenzhen Engn Lab Informat Secur & Digital Conten, Grad Sch Shenzhen,Dept Elect Engn, Shenzhen 518055, Peoples R China.
   [Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   University of London; University College London
RP Yang, WM (corresponding author), Tsinghua Univ, Shenzhen Key Lab Informat & Sci Technol, Shenzhen Engn Lab Informat Secur & Digital Conten, Grad Sch Shenzhen,Dept Elect Engn, Shenzhen 518055, Peoples R China.
EM sunjn17@mails.tsinghua.edu.cn; yangelwm@163.com; jinghao.xue@ucl.ac.uk;
   liaoqm@sz.tsinghua.edu.cn
OI Yang, Wenming/0000-0002-2506-1286; Xue, Jing-Hao/0000-0003-1174-610X
FU Special Foundation for the Development of Strategic Emerging Industries
   of Shenzhennder [JCYJ20170817161845824]
FX This work was supported by the Special Foundation for the Development of
   Strategic Emerging Industries of Shenzhennder under Grant
   JCYJ20170817161845824.
CR [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2018, Arcface: Additive angular margin loss for deep face recognition
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Deng JK, 2017, IEEE COMPUT SOC CONF, P2006, DOI 10.1109/CVPRW.2017.251
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205
   Gao RQ, 2018, IEEE SIGNAL PROC LET, V25, P308, DOI 10.1109/LSP.2017.2789251
   Günther M, 2017, IEEE COMPUT SOC CONF, P573, DOI 10.1109/CVPRW.2017.85
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh CK, 2009, IEEE T MULTIMEDIA, V11, P600, DOI 10.1109/TMM.2009.2017606
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Leng B, 2017, NEUROCOMPUTING, V235, P10, DOI 10.1016/j.neucom.2016.12.013
   Li ZF, 2005, PROC CVPR IEEE, P961
   Li ZF, 2009, IEEE T PATTERN ANAL, V31, P755, DOI 10.1109/TPAMI.2008.174
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu WY, 2018, ADV NEUR IN, V31
   Liu WY, 2016, PR MACH LEARN RES, V48
   Lv JJ, 2017, NEUROCOMPUTING, V230, P184, DOI 10.1016/j.neucom.2016.12.025
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Ranjan Rajeev, 2017, L2-constrained softmax loss for discriminative face verification
   Raza A, 2017, EUR SIGNAL PR CONF, P395, DOI 10.23919/EUSIPCO.2017.8081236
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S, 2016, IEEE WINT CONF APPL
   Sun JN, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115636
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Wang Xiaobo, 2018, ARXIV181211317
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Xu ZS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P214, DOI 10.1109/CIAPP.2017.8167210
   Yang FW, 2018, IEEE SIGNAL PROC LET, V25, P388, DOI 10.1109/LSP.2017.2746658
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zheng YT, 2018, PROC CVPR IEEE, P5089, DOI 10.1109/CVPR.2018.00534
   Zhou B., 2014, CORR, V1412, P6856
NR 46
TC 11
Z9 11
U1 4
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2020
VL 22
IS 11
BP 2833
EP 2843
DI 10.1109/TMM.2020.2966863
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA OJ8YR
UT WOS:000584239900007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, HD
   Xu, XM
   He, H
   He, SF
   Han, GQ
   Qin, J
   Wu, DP
AF Zhang, Huaidong
   Xu, Xuemiao
   He, Hai
   He, Shengfeng
   Han, Guoqiang
   Qin, Jing
   Wu, Dapeng
TI Fast User-Guided Single Image Reflection Removal via Edge-Aware Cascaded
   Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image edge detection; Tools; Optimization; Image reconstruction;
   Pipelines; Image color analysis; Detectors; Reflection removal; user
   interaction; image refinement; convolutional neural network
ID QUALITY ASSESSMENT; SEPARATION; CLASSIFICATION
AB Taking photos through a glass window leads to glare or reflection, which might distract the viewer from the scene behind the window. In this paper, we involve user interaction to tackle the ill-posedness of the reflection removal problem. Users are allowed to draw strokes or lassos to indicate the background and reflection layers. Instead of designing hand-crafted features, we propose the edge-aware cascaded networks for reflection removal. The proposed network is a two-stage pipeline. The first stage takes the edge hints converted from user guidance and the image with reflection as input, and then separates the input image into the background and reflection layers. The second stage involves a refinement network to recover the missing details of the background layers. We simulate different types of user guidance, and the networks are trained on simulated data. The cascaded networks are end-to-end and perform with a single feed-forward pass, enabling fast editing. Extensive experimental evaluations demonstrate that the proposed used-guided reflection removal network yields better performance than the state-of-the-art methods on real-world scenarios. Furthermore, we show that novice users can easily generate reflection-free images, and large improvements in reflection removal quality can be obtained in just one minute.
C1 [Zhang, Huaidong; Xu, Xuemiao; He, Hai; He, Shengfeng; Han, Guoqiang] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.
   [Xu, Xuemiao] State Key Lab Subtrop Bldg Sci, Guangzhou, Guangdong, Peoples R China.
   [Xu, Xuemiao] Guangdong Prov Key Lab Computat Intelligence & Cy, Guangzhou, Guangdong, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Ctr Smart Hlth, Sch Nursing, Hong Kong, Peoples R China.
   [Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 South China University of Technology; Hong Kong Polytechnic University;
   State University System of Florida; University of Florida
RP Xu, XM (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.
EM xiaodomgdomg@gmail.com; xuemx@scut.edu.cn; hehai1224@gmail.com;
   hesfe@scut.edu.cn; csgqhan@scut.edu.cn; harry.qin@polyu.edu.hk;
   dpwu@ufl.edu
RI Qin, Jing/JMC-1371-2023; zhang, wilson/GRY-4539-2022; He,
   Shengfeng/E-5682-2016; Qin, Jing/J-9807-2016; Zhang,
   Huaidong/AAB-9269-2022
OI He, Shengfeng/0000-0002-3802-4644; Qin, Jing/0000-0002-7059-0929; Wu,
   Dapeng/0000-0003-1755-0183
FU National Natural Science Foundation of China [61772206, U1611461,
   61472145]; Guangdong R&D Key Project of China [2018B010107003];
   theGuangdong High-Level Personnel Program [2016TQ03X319]; Guangdong
   National Science Foundation [2017A030311027]; Guangzhou Key Project in
   Industrial Technology [201802010027]; CCF-Tencent Open Research Fund
   under Grant CCF-Tencent [RAGR20190112]
FX The work was supported in part by National Natural Science Foundation of
   China under Grants 61772206, U1611461, and 61472145, in part by the
   Guangdong R&D Key Project of China under Grant 2018B010107003, in part
   by theGuangdong High-Level Personnel Program under Grant 2016TQ03X319,
   in part by the Guangdong National Science Foundation under Grant
   2017A030311027, in part by the Guangzhou Key Project in Industrial
   Technology underGrant 201802010027, and in part by the CCF-Tencent Open
   Research Fund under Grant CCF-Tencent RAGR20190112. The associate editor
   coordinating the reviewof this manuscript and approving it for
   publication was Prof. S. Rahardja.
CR Arvanitopoulos N, 2017, PROC CVPR IEEE, P1752, DOI 10.1109/CVPR.2017.190
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan QN, 2017, IEEE I CONF COMP VIS, P3258, DOI 10.1109/ICCV.2017.351
   Galteri L, 2019, IEEE T MULTIMEDIA, V21, P2131, DOI 10.1109/TMM.2019.2895280
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo XJ, 2014, PROC CVPR IEEE, P2195, DOI 10.1109/CVPR.2014.281
   Han BJ, 2017, PROC CVPR IEEE, P3872, DOI 10.1109/CVPR.2017.412
   Heydecker D, 2019, IEEE T IMAGE PROCESS, V28, P6185, DOI 10.1109/TIP.2019.2923559
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang B, 2018, IEEE T MULTIMEDIA, V20, P2478, DOI 10.1109/TMM.2018.2798282
   Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106
   Li JA, 2018, IEEE T MULTIMEDIA, V20, P1645, DOI 10.1109/TMM.2017.2772796
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346
   Li Y, 2013, IEEE I CONF COMP VIS, P2432, DOI 10.1109/ICCV.2013.302
   Liu JY, 2018, IEEE T MULTIMEDIA, V20, P3252, DOI 10.1109/TMM.2018.2831636
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu F, 2019, IEEE T MULTIMEDIA, V21, P1971, DOI 10.1109/TMM.2019.2894964
   Nandoriya A, 2017, IEEE I CONF COMP VIS, P2430, DOI 10.1109/ICCV.2017.264
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schechner YY, 2000, INT J COMPUT VISION, V39, P25, DOI 10.1023/A:1008166017466
   Schmeing M, 2015, IEEE T MULTIMEDIA, V17, P2160, DOI 10.1109/TMM.2015.2476372
   Shi HC, 2018, IEEE T MULTIMEDIA, V20, P2670, DOI 10.1109/TMM.2018.2812600
   Shih YC, 2015, PROC CVPR IEEE, P3193, DOI 10.1109/CVPR.2015.7298939
   Sinha SN, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185596
   Springer O, 2017, IEEE IMAGE PROC, P1192, DOI 10.1109/ICIP.2017.8296470
   Sun SH, 2014, IEEE IMAGE PROC, P4482, DOI 10.1109/ICIP.2014.7025909
   Wan RJ, 2020, IEEE T PATTERN ANAL, V42, P2969, DOI 10.1109/TPAMI.2019.2921574
   Wan RJ, 2018, PROC CVPR IEEE, P4777, DOI 10.1109/CVPR.2018.00502
   Wan RJ, 2018, IEEE T IMAGE PROCESS, V27, P2927, DOI 10.1109/TIP.2018.2808768
   Wan RJ, 2017, IEEE I CONF COMP VIS, P3942, DOI 10.1109/ICCV.2017.423
   Wan RJ, 2016, IEEE IMAGE PROC, P21, DOI 10.1109/ICIP.2016.7532311
   Wang C, 2019, IEEE INT CON MULTI, P1276, DOI 10.1109/ICME.2019.00222
   Wang XL, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1174, DOI 10.1109/CompComm.2017.8322728
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen Q, 2019, PROC CVPR IEEE, P3766, DOI 10.1109/CVPR.2019.00389
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xue TF, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766940
   Yan B, 2019, IEEE T MULTIMEDIA, V21, P2957, DOI 10.1109/TMM.2019.2914883
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang X, 2018, PROC CVPR IEEE, P4786, DOI 10.1109/CVPR.2018.00503
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
NR 50
TC 11
Z9 11
U1 2
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2020
VL 22
IS 8
BP 2012
EP 2023
DI 10.1109/TMM.2019.2951461
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA MR2MS
UT WOS:000553424500008
DA 2024-07-18
ER

PT J
AU Wan, SH
   Xia, Y
   Qi, LY
   Yang, YH
   Atiquzzaman, M
AF Wan, Shaohua
   Xia, Yu
   Qi, Lianyong
   Yang, Yee-Hong
   Atiquzzaman, Mohammed
TI Automated Colorization of a Grayscale Image With Seed Points Propagation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image color analysis; Image segmentation; Feature extraction;
   Gray-scale; Training; Neural networks; Optimization; Neural network;
   Segmentation; Colorization; Optimization
ID COLOR
AB In this paper, we propose a fully automatic image colorization method for grayscale images using neural network and optimization. For a determined training set including the gray images and its corresponding color images, our method segments grayscale images into superpixels and then extracts features of particular points of interest in each superpixel. The obtained features and their RGB values are given as input for, the training colorization neural network of each pixel. To achieve a better image colorization effect in shorter running time, our method further propagates the resulting color points to neighboring pixels for improved colorization results. In the propagation of color, we present a cost function to formalize the premise that neighboring pixels should have the maximum positive similarity of intensities and colors; we then propose our solution to solving the optimization problem. At last, a guided image filter is employed to refine the colorized image. Experiments on a wide variety of images show that the proposed algorithms can achieve superior performance over the state-of-the-art algorithms.
C1 [Wan, Shaohua] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Peoples R China.
   [Xia, Yu] Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China.
   [Qi, Lianyong] Qufu Normal Univ, Sch Informat Sci & Engn, Rizhao 276826, Peoples R China.
   [Yang, Yee-Hong] Univ Alberta Edmonton, Dept Comp Sci, Edmonton, AB T6G 2R3, Canada.
   [Atiquzzaman, Mohammed] Univ Oklahoma, Sch Comp Sci, Norman, OK 73019 USA.
C3 Zhongnan University of Economics & Law; Northwestern Polytechnical
   University; Qufu Normal University; University of Oklahoma System;
   University of Oklahoma - Norman
RP Wan, SH (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Peoples R China.
EM shwanhust@gmail.com; charles@mail.nwpu.edu.cn; lianyongqi@gmail.com;
   yang@cs.ualberta.ca; atiq@ou.edu
RI Qi, Lianyong/AAO-2681-2020; Wan, Shaohua/L-8492-2019; Wan,
   Shaohua/B-9243-2014; Atiquzzaman, Mohammed/G-4059-2017
OI Wan, Shaohua/0000-0001-7013-9081; Atiquzzaman,
   Mohammed/0000-0001-9440-7669; Yang, Yee Hong/0000-0002-7194-3327
FU National Natural Science Foundation of China [61872219]; Natural Science
   Foundation of Shandong Province [ZR2019MF001]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61872219), and the Natural Science Foundation
   of Shandong Province (ZR2019MF001).
CR Achanta R., 2010, SLIC Superpixels
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2016, ACM T GRAPH
   Bai S, 2019, IEEE T IMAGE PROCESS, V28, P88, DOI 10.1109/TIP.2018.2863028
   Blanch M. G., 2019, 2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP), P1, DOI 10.1108/978-1-78973-159-020191001(accessed31.12.2020)
   Charpiat G, 2008, LECT NOTES COMPUT SC, V5304, P126, DOI 10.1007/978-3-540-88690-7_10
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Chiang TW, 2005, IEEE SYS MAN CYBERN, P351
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jack K., 2005, VIDEO DEMYSTIFIED, V4th
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liu SG, 2012, PATTERN RECOGN LETT, V33, P1673, DOI 10.1016/j.patrec.2012.06.001
   Liu XM, 2008, CATAL COMMUN, V9, P1, DOI 10.1016/j.catcom.2007.05.020
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luan Q., 2007, Proceedings of the 18th Eurographics conference on Rendering Techniques, P309
   Lucchi A, 2010, LECT NOTES COMPUT SC, V6362, P463
   Nazeri K., 2018, IEEE INT CONF COMP V
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Peng PX, 2018, IEEE T PATTERN ANAL, V40, P1625, DOI 10.1109/TPAMI.2017.2723882
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Sharma M., 2019, P IEEE C COMP VIS PA
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Smith AC, 2012, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE (PVP-2011), VOL 7, P369
   Tola E, 2008, PROC CVPR IEEE, P2578
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Xiang Y, 2009, PATTERN RECOGN LETT, V30, P682, DOI 10.1016/j.patrec.2009.01.004
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2002, PATTERN RECOGN, V35, P1997, DOI 10.1016/S0031-3203(02)00040-7
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 45
TC 118
Z9 119
U1 2
U2 69
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2020
VL 22
IS 7
BP 1756
EP 1768
DI 10.1109/TMM.2020.2976573
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA MG4GJ
UT WOS:000545990500009
DA 2024-07-18
ER

PT J
AU Li, SY
   Chen, ZX
   Li, X
   Lu, JW
   Zhou, J
AF Li, Shuyan
   Chen, Zhixiang
   Li, Xiu
   Lu, Jiwen
   Zhou, Jie
TI Unsupervised Variational Video Hashing With 1D-CNN-LSTM Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Binary codes; Hash functions; Probabilistic logic; Correlation;
   Decoding; Convolutional codes; Visualization; hashing; scalable video
   retrieval; unsupervised; variational
ID QUANTIZATION
AB Most existing unsupervised video hashing methods generate binary codes by using RNNs in a deterministic manner, which fails to capture the dominant latent variation of videos. In addition, RNN-based video hashing methods suffer the content forgetting of early input frames due to the sequential processing inherency of RNNs, which is detrimental to global information capturing. In this work, we propose an unsupervised variational video hashing (UVVH) method for scalable video retrieval. Our UVVH method aims to capture the salient and global information in a video. Specifically, we introduce a variational autoencoder to learn a probabilistic latent representation of the salient factors of video variations. To better exploit the global information of videos, we design a 1D-CNN-LSTM model. The 1D-CNN-LSTM model processes long frame sequences in a parallel and hierarchical way, and exploits the correlations between frames to reconstruct the frame-level features. As a consequence, the learned hash functions can produce reliable binary codes for video retrieval. We conduct extensive experiments on three widely used benchmark datasets, FCVID, ActivityNet and YFCC to validate the effectiveness of our proposed approach.
C1 [Li, Shuyan; Li, Xiu] Tsinghua Shenzhen Int Grad Sch, Shenzhen 518055, Peoples R China.
   [Chen, Zhixiang; Lu, Jiwen; Zhou, Jie] Tsinghua Univ, Beijing Res Ctr Informat Sci & Technol BNRist, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.
C3 Tsinghua Shenzhen International Graduate School; Tsinghua University
RP Li, X (corresponding author), Tsinghua Shenzhen Int Grad Sch, Shenzhen 518055, Peoples R China.
EM li-sy16@mails.tsinghua.edu.cn; zxchen@tsinghua.edu.cn;
   li.xiu@sz.tsinghua.edu.cn; lujiwen@tsinghua.edu.cn;
   jzhou@tsinghua.edu.cn
RI ; Lu, Jiwen/C-5291-2009
OI LI, SHUYAN/0000-0002-5107-0338; Lu, Jiwen/0000-0002-6121-5529; Chen,
   Zhixiang/0000-0002-5636-6082
FU National Key Research and Development Program of China [2017YFA0700802];
   National Natural Science Foundation of China [41876098, U1813218,
   61806110, 61822603, U1713214, 61672306, 61572271, 61527808]; National
   Postdoctoral Program for Innovative Talents [BX201700137]; China
   Postdoctoral Science Foundation [2018M630159]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFA0700802, in part by the
   National Natural Science Foundation of China under Grants 41876098,
   U1813218, 61806110, 61822603, U1713214, 61672306, 61572271, and
   61527808, in part by the National Postdoctoral Program for Innovative
   Talents under Grant BX201700137, and in part by China Postdoctoral
   Science Foundation under Grant 2018M630159.
CR [Anonymous], ECCV
   [Anonymous], P INT C LEARN REPR
   [Anonymous], 2016, P 29 C NEUR INF PROC
   [Anonymous], 2015, P CVPR
   [Anonymous], 2016, ARXIV
   [Anonymous], 2017, P 2017 C EMP METH NA, DOI DOI 10.18653/V1/D17-1254
   [Anonymous], WORKSH PART NOT PAP
   [Anonymous], 2014, 2 INT C LEARN REPR B
   [Anonymous], 2017, P 5 INT C LEARN REPR
   Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Chaidaroon S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P75, DOI 10.1145/3077136.3080816
   Chen WC, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P422, DOI 10.1109/PACRIM.2011.6032930
   Chen ZX, 2018, PROC CVPR IEEE, P6838, DOI 10.1109/CVPR.2018.00715
   Chou CL, 2015, IEEE T MULTIMEDIA, V17, P382, DOI 10.1109/TMM.2015.2391674
   Dai B, 2017, PR MACH LEARN RES, V70
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan LY, 2015, IEEE T MULTIMEDIA, V17, P828, DOI 10.1109/TMM.2015.2419973
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, PROC CVPR IEEE, P4857, DOI 10.1109/CVPR.2017.516
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Guo DS, 2018, IEEE T MULTIMEDIA, V20, P3428, DOI 10.1109/TMM.2018.2839534
   Guo YC, 2018, IEEE T IMAGE PROCESS, V27, P949, DOI 10.1109/TIP.2017.2766445
   Guo Z, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P357, DOI 10.1145/2964284.2967242
   Han-ping Gao, 2010, Proceedings 2010 International Symposium on Intelligence Information Processing and Trusted Computing (IPTC 2010), P689, DOI 10.1109/IPTC.2010.30
   Hao YB, 2017, IEEE T IMAGE PROCESS, V26, P5531, DOI 10.1109/TIP.2017.2737329
   Hao YB, 2017, IEEE T MULTIMEDIA, V19, P1, DOI 10.1109/TMM.2016.2610324
   He Junfeng, 2010, CVPR, P753
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Hubara I, 2018, J MACH LEARN RES, V18
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   Kaiser L., 2018, ARXIV180109797
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma D. P., 2015, P INT C LEARN REPR I, P1
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li C, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P9, DOI 10.1145/3132847.3133030
   Liong VE, 2017, IEEE IMAGE PROC, P3700, DOI 10.1109/ICIP.2017.8296973
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1209, DOI 10.1109/TMM.2016.2645404
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu MY, 2017, ADV NEUR IN, V30
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P4514, DOI 10.1109/TIP.2016.2593344
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lv YM, 2015, IEEE T MULTIMEDIA, V17, P1225, DOI 10.1109/TMM.2015.2437712
   Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Radford A, 2016, 4 INT C LEARNING REP
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sablayrolles A, 2017, INT CONF ACOUST SPEE, P1732, DOI 10.1109/ICASSP.2017.7952453
   Shen YM, 2019, INT J COMPUT VISION, V127, P1614, DOI 10.1007/s11263-019-01166-4
   SONG J, 2017, ARXIV170802478
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun Jiande, 2018, ICDIP, P82
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Walker J, 2016, LECT NOTES COMPUT SC, V9911, P835, DOI 10.1007/978-3-319-46478-7_51
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Wu GS, 2019, IEEE T IND ELECTRON, V66, P9868, DOI 10.1109/TIE.2018.2873547
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang ZC, 2017, P MACHINE LEARNING R, V70
   Ye GN, 2013, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2013.282
   Yu LT, 2016, IEEE T MULTIMEDIA, V18, P1590, DOI 10.1109/TMM.2016.2557059
   Zhang HW, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P781, DOI 10.1145/2964284.2964308
NR 79
TC 25
Z9 26
U1 1
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2020
VL 22
IS 6
BP 1542
EP 1554
DI 10.1109/TMM.2019.2946096
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA LU8YA
UT WOS:000538033100014
DA 2024-07-18
ER

PT J
AU Wang, MH
   Xiong, J
   Xu, L
   Xie, WY
   Ngan, KN
   Qin, J
AF Wang, Miaohui
   Xiong, Jian
   Xu, Long
   Xie, Wuyuan
   Ngan, King Ngi
   Qin, Jing
TI Rate Constrained Multiple-QP Optimization for HEVC
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Optimization; Quantization (signal); Encoding; High efficiency video
   coding; Complexity theory; Computational modeling; Multiple-QP
   optimization; block adaptive quantization; rate regulation; high
   efficiency video coding (HEVC)
ID RATE-DISTORTION OPTIMIZATION; ADAPTIVE QUANTIZATION; ALGORITHM;
   DECISION; ARCHITECTURE; TRANSFORM; MODEL
AB In High Efficiency Video Coding (HEVC), multiple-QP (quantization parameter) optimization can adapt to a local video content. However, the multiple-QP implementation in the HEVC reference software (HM 16.6) achieves the best QP value for each coding block with a large amount of computational complexity. To address this challenge, we propose a fast rate-constrained multiple-QP optimization approach for the HM platform. We first introduce a template-based transform coefficient selection method which can save the overall complexity of entropy coding. In addition, we model the multiple-QP determination as a new rate-constrained optimization problem, and finally, we get a feasible solution with a lower computation overhead. Experimental results show that our method dramatically reduces the average complexity under the all-intra, low-delay and random-access configuration.
C1 [Wang, Miaohui] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Guangdong Lab Artificial Intelligence & Digital E, Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen 518060, Peoples R China.
   [Wang, Miaohui] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.
   [Xiong, Jian] Nanjing Univ Posts & Telecommun, Coll Commun & Informat Technol, Nanjing 210003, Jiangsu, Peoples R China.
   [Xu, Long] Natl Astron Observ CAS, Key Lab Solar Act, Beijing 100101, Peoples R China.
   [Xie, Wuyuan] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Ngan, King Ngi] Univ Elect Sci & Technol China, Chengdu 610054, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Hong Kong, Peoples R China.
C3 Shenzhen Institute of Artificial Intelligence & Robotics for Society;
   Shenzhen University; Guangming Laboratory; Shenzhen University; Nanjing
   University of Posts & Telecommunications; Chinese Academy of Sciences;
   National Astronomical Observatory, CAS; Shenzhen University; University
   of Electronic Science & Technology of China; Hong Kong Polytechnic
   University
RP Xie, WY (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM wang.miaohui@gnuil.com; jxiong@njupt.edu.cn; lxu@nao.cas.cn;
   wyxie@gmail.com; knngan@ee.cuhk.edu.hk; harry.qin@polyu.edu.hk
RI Xu, Long/AAH-9908-2019; Qin, Jing/J-9807-2016; Qin, Jing/JMC-1371-2023;
   Ngan, N/E-8240-2014
OI Xu, Long/0000-0002-9286-2876; Qin, Jing/0000-0002-7059-0929; Ngan,
   N/0000-0003-1946-3235; Xiong, Jian/0000-0002-8346-178X; Xiong,
   Jian/0000-0002-4720-4102
FU National Natural Science Foundation of China [61701310, 61902251,
   61572461, 11790305]; Free Exploration Project for Basic Research of
   Shenzhen City [JCYJ20180305124209486, JCYJ20180305124325555]; Natural
   Science Foundation of SZU [2018080]; Innovation and Technology Fund of
   Hong Kong [ITS/319/17]; Natural Science Foundation of Guangdong
   [2019A1515010961]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61701310, Grant 61902251, Grant
   61572461, and Grant 11790305, in part by Free Exploration Project for
   Basic Research of Shenzhen City JCYJ20180305124209486 and
   JCYJ20180305124325555, in part by the Natural Science Foundation of SZU
   2018080, and in part by the Innovation and Technology Fund of Hong Kong
   under Project ITS/319/17, and in part by the Natural Science Foundation
   of Guangdong under Grant 2019A1515010961. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Manoranjan Paul.
CR [Anonymous], 2014, JCTVCS1002
   [Anonymous], 2011, JCTVC-E051
   [Anonymous], 2001, VCEGM33
   Boyd S., 2004, CONVEX OPTIMIZATION
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Flynn D, 2016, IEEE T CIRC SYST VID, V26, P4, DOI 10.1109/TCSVT.2015.2478707
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   Jia LH, 2019, IEEE T MULTIMEDIA, V21, P835, DOI 10.1109/TMM.2018.2866762
   Karczewicz M., 2008, RATE DISTORTION OPTI, V6
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Li B, 2013, IEEE INT SYMP CIRC S, P477, DOI 10.1109/ISCAS.2013.6571884
   Li L, 2016, IEEE T MULTIMEDIA, V18, P2023, DOI 10.1109/TMM.2016.2595264
   Li S, 2016, IEEE T CIRC SYST VID, V26, P117, DOI 10.1109/TCSVT.2015.2450131
   Lu X, 2017, J VIS COMMUN IMAGE R, V48, P205, DOI 10.1016/j.jvcir.2017.05.014
   Prangnell L, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P35, DOI 10.1109/PCS.2015.7170042
   Sheinin V, 2008, IEEE T MULTIMEDIA, V10, P1225, DOI 10.1109/TMM.2008.2004902
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen WW, 2016, IEEE T MULTIMEDIA, V18, P1022, DOI 10.1109/TMM.2016.2532606
   Sun HM, 2017, IEEE T MULTIMEDIA, V19, P2375, DOI 10.1109/TMM.2017.2700629
   Sze V., 2014, HIGH EFFICIENCY VIDE, P158
   Tanaka J., 2011, JCTVCE073 ITUT SG16
   Wang MH, 2019, IEEE ACCESS, V7, P62534, DOI 10.1109/ACCESS.2019.2917260
   Wang MH, 2016, IEEE T IMAGE PROCESS, V25, P2943, DOI 10.1109/TIP.2016.2552646
   Wang MH, 2015, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2015.7168682
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang MH, 2014, IEEE T MULTIMEDIA, V16, P933, DOI 10.1109/TMM.2014.2305579
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang GQ, 2018, MULTIMED TOOLS APPL, V77, P14817, DOI 10.1007/s11042-017-5064-4
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P2141, DOI 10.1109/TMM.2014.2356795
   Yin HB, 2015, IEEE T CIRC SYST VID, V25, P1362, DOI 10.1109/TCSVT.2014.2380232
   Yu X., 2010, JCTVCB035
NR 34
TC 4
Z9 4
U1 0
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2020
VL 22
IS 6
BP 1395
EP 1406
DI 10.1109/TMM.2019.2947351
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA LU8YA
UT WOS:000538033100002
DA 2024-07-18
ER

PT J
AU Li, YH
   Yao, T
   Pan, YW
   Chao, HY
   Mei, T
AF Li, Yehao
   Yao, Ting
   Pan, Yingwei
   Chao, Hongyang
   Mei, Tao
TI Deep Metric Learning With Density Adaptivity
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Measurement; Training; Neural networks; Task analysis; Testing; Image
   retrieval; Adaptation models; Deep Metric Learning; Density Adaptation;
   Image Retrieval
ID REPRESENTATION
AB The problem of distance metric learning is mostly considered from the perspective of learning an embedding space, where the distances between pairs of examples are in correspondence with a similarity metric. With the rise and success of Convolutional Neural Networks (CNN), deep metric learning (DML) involves training a network to learn a nonlinear transformation to the embedding space. Existing DML approaches often express the supervision through maximizing inter-class distance and minimizing intra-class variation. However, the results can suffer from overfitting problem, especially when the training examples of each class are embedded together tightly and the density of each class is very high. In this paper, we integrate density, i.e., the measure of data concentration in the representation, into the optimization of DML frameworks to adaptively balance inter-class similarity and intra-class variation by training the architecture in an end-to-end manner. Technically, the knowledge of density is employed as a regularizer, which is pluggable to any DML architecture with different objective functions such as contrastive loss, N-pair loss and triplet loss. Extensive experiments on three public datasets consistently demonstrate clear improvements by amending three types of embedding with the density adaptivity. More remarkably, our proposal increases Recall@1 from 67.95% to 77.62%, from 52.01% to 55.64% and from 68.20% to 70.56% on Cars196, CUB-200-2011 and Stanford Online Products dataset, respectively.
C1 [Li, Yehao; Chao, Hongyang] Sun Yat Sen Univ, Guangzhou 510275, Peoples R China.
   [Yao, Ting; Pan, Yingwei; Mei, Tao] JD AI Res, Beijing 100105, Peoples R China.
C3 Sun Yat Sen University
RP Yao, T (corresponding author), JD AI Res, Beijing 100105, Peoples R China.
EM yehaoli.sysu@gmail.com; tingyao.ustc@gmail.com; panyw.ustc@gmail.com;
   isschhy@mail.sysu.edu.cn; tmei@jd.com
RI Pan, Yingwei/T-7649-2019; Mei, Tao/GQZ-0596-2022
OI Pan, Yingwei/0000-0002-4344-8898; Mei, Tao/0000-0002-5990-7307; Yao,
   Ting/0000-0001-7587-101X
FU NSF of China [61672548, U1611461, 61173081]; Guangzhou Science and
   Technology Program, China [201510010165]
FX This work was supported in part by NSF of China under Grants 61672548,
   U1611461, and 61173081 and in part by the Guangzhou Science and
   Technology Program, China, under Grant 201510010165.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], P 29 INT C MACH LEAR
   [Anonymous], 2016, P INT JOINT C ARTIFI
   [Anonymous], 5 INT C LEARN REPR I
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], P INT C LEARN REPR S
   Bai Y, 2018, IEEE T MULTIMEDIA, V20, P2385, DOI 10.1109/TMM.2018.2796240
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cui P, 2018, IEEE T MULTIMEDIA, V20, P198, DOI 10.1109/TMM.2017.2724843
   Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Huang M, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1262, DOI 10.1109/ICISCE.2016.270
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim H, 2018, IEEE T MULTIMEDIA, V20, P2415, DOI 10.1109/TMM.2018.2806224
   King DB, 2015, ACS SYM SER, V1214, P1
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3328994
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Manning Christopher., 2010, Introduction to information retrieval, V16
   Melacci S, 2011, J MACH LEARN RES, V12, P1149
   Pan YW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P233, DOI 10.1145/2647868.2656404
   Pan YW, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P53, DOI 10.1145/2766462.2767725
   Qiu ZF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P225, DOI 10.1145/3077136.3080842
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Ustinova E, 2016, ADV NEUR IN, V29
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yao T, 2016, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2016.112
   Yao T, 2015, IEEE I CONF COMP VIS, P28, DOI 10.1109/ICCV.2015.12
   Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zhang X, 2017, IEEE I CONF COMP VIS, P4605, DOI 10.1109/ICCV.2017.492
   Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649
NR 51
TC 9
Z9 9
U1 1
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2020
VL 22
IS 5
BP 1285
EP 1297
DI 10.1109/TMM.2019.2939711
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA LJ3VZ
UT WOS:000530097200014
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Lou, JW
   Wang, YM
   Nduka, C
   Hamedi, M
   Mavridou, I
   Wang, FY
   Yu, H
AF Lou, Jianwen
   Wang, Yiming
   Nduka, Charles
   Hamedi, Mahyar
   Mavridou, Ifigeneia
   Wang, Fei-Yue
   Yu, Hui
TI Realistic Facial Expression Reconstruction for VR HMD Users
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Face; Sensors; Three-dimensional displays; Image reconstruction;
   Resists; Electromyography; Cameras; Facial expression reconstruction;
   head-mounted display; electromyogram; 3D face reconstruction; facial
   action unit
ID 3D FACE RECONSTRUCTION; RECOGNITION; PERCEPTION; FRAMEWORK; DATABASE;
   MACHINE
AB We present a system for sensing and reconstructing facial expressions of the virtual reality (VR) head-mounted display (HMD) user. The HMD occludes a large portion of the user's face, which makes most existing facial performance capturing techniques intractable. To tackle this problem, a novel hardware solution with electromyography (EMG) sensors being attached to the headset frame is applied to track facial muscle movements. For realistic facial expression recovery, we first reconstruct the user's 3D face from a single image and generate the personalized blendshapes associated with seven facial action units (AUs) on the most emotionally salient facial parts (ESFPs). We then utilize pre-processed EMG signals for measuring activations of AU-coded facial expressions to drive pre-built personalized blendshapes. Since facial expressions appear as important nonverbal cues of the subject's internal emotional states, we further investigate the relationship between six basic emotions - anger, disgust, fear, happiness, sadness and surprise, and detected AUs using a fern classifier. Experiments show the proposed system can accurately sense and reconstruct high-fidelity common facial expressions while providing useful information regarding the emotional state of the HMD user.
C1 [Lou, Jianwen; Wang, Yiming; Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth PO1 2DJ, Hants, England.
   [Nduka, Charles; Hamedi, Mahyar; Mavridou, Ifigeneia] Emteq Ltd, Sussex Innovat Ctr, Brighton BN1 9SB, E Sussex, England.
   [Wang, Fei-Yue] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
C3 University of Portsmouth; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Yu, H (corresponding author), Univ Portsmouth, Sch Creat Technol, Portsmouth PO1 2DJ, Hants, England.
EM jianwen.lou@port.ac.uk; yiming.wang@port.ac.uk; charles@emteq.net;
   mahyar@emteq.net; ifi@emteq.net; feiyue.wang@ia.ac.cn; hui.yu@port.ac.uk
RI Mavridou, Ifigeneia/AAV-5970-2021; Wang, Yiming/KTI-0022-2024; Yu,
   Hui/G-1115-2018
OI Mavridou, Ifigeneia/0000-0003-3800-6531; Wang,
   Yiming/0000-0002-4390-5796; Yu, Hui/0000-0002-7655-9228; Nduka,
   Charles/0000-0003-1315-0502
FU Engineering and Physical Sciences Research Council [EP/N025849/1]; Royal
   Academy of Engineering Grant [IFS1819\9]; Emteq Ltd.; EPSRC
   [EP/N025849/1] Funding Source: UKRI
FX This work was supported in part by Engineering and Physical Sciences
   Research Council Grant (EP/N025849/1) and in part by the Royal Academy
   of Engineering Grant (IFS1819\9) and Emteq Ltd.
CR Agarwal S, 2019, IEEE T MULTIMEDIA, V21, P902, DOI 10.1109/TMM.2018.2871417
   Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206
   [Anonymous], COMPUTATIONAL INTELL
   [Anonymous], P 28 BRIT MACH VIS C
   [Anonymous], 2011, International Journal of Wavelets Multiresolution and Information Processing, DOI DOI 10.1142/S021969130400041X
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cha JH, 2018, STAT PAP, V59, P199, DOI 10.1007/s00362-016-0759-6
   Cheng SY, 2018, PROC CVPR IEEE, P5117, DOI 10.1109/CVPR.2018.00537
   Dong XH, 2019, IEEE T IND ELECTRON, V66, P4777, DOI 10.1109/TIE.2018.2866043
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 1978, APA PsycTests, DOI DOI 10.1037/T27734-000
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Erol BA, 2020, IEEE T COMPUT SOC SY, V7, P234, DOI 10.1109/TCSS.2019.2922593
   Gruebler A, 2014, IEEE T AFFECT COMPUT, V5, P227, DOI 10.1109/TAFFC.2014.2313557
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Hamedi Mahyar, 2011, Journal of Computer Sciences, V7, P1407, DOI 10.3844/jcssp.2011.1407.1415
   Hamedi M, 2018, IEEE T AFFECT COMPUT, V9, P102, DOI 10.1109/TAFFC.2016.2569098
   Hamedi M, 2015, APPL SOFT COMPUT, V30, P83, DOI 10.1016/j.asoc.2015.01.034
   Hu LW, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3130800.3130887, 10.1145/3130800.31310887]
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Huynh L, 2018, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2018.00877
   Jiang L, 2018, IEEE T IMAGE PROCESS, V27, P4756, DOI 10.1109/TIP.2018.2845697
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li L, 2017, IEEE-CAA J AUTOMATIC, V4, P389, DOI 10.1109/JAS.2017.7510493
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Lu F, 2016, IEEE T MULTIMEDIA, V18, P1772, DOI 10.1109/TMM.2016.2576284
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Martinez Brais, 2019, IEEE Transactions on Affective Computing, V10, P325, DOI 10.1109/TAFFC.2017.2731763
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   McFarland DJ, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1941487.1941506
   Meng ZB, 2019, IEEE T AFFECT COMPUT, V10, P537, DOI 10.1109/TAFFC.2017.2749299
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Oskoei MA, 2007, BIOMED SIGNAL PROCES, V2, P275, DOI 10.1016/j.bspc.2007.07.009
   Ozuysal M., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383123
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Rezazadeh IM, 2011, AUSTRALAS PHYS ENG S, V34, P497, DOI 10.1007/s13246-011-0113-1
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Romdhani S, 2005, PROC CVPR IEEE, P986
   Saito S, 2017, PROC CVPR IEEE, P2326, DOI 10.1109/CVPR.2017.250
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Sengupta S, 2018, PROC CVPR IEEE, P6296, DOI 10.1109/CVPR.2018.00659
   Suzuki K, 2017, P IEEE VIRT REAL ANN, P177, DOI 10.1109/VR.2017.7892245
   Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270
   Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182644
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Valstar MF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P325, DOI 10.1109/ICME.2006.262464
   Velusamy S, 2011, INT CONF ACOUST SPEE, P2028
   Wang KF, 2017, ARTIF INTELL REV, V48, P299, DOI 10.1007/s10462-017-9569-z
   Weng RL, 2016, IEEE T MULTIMEDIA, V18, P2066, DOI 10.1109/TMM.2016.2591508
   Xie WC, 2017, IEEE T MULTIMEDIA, V19, P279, DOI 10.1109/TMM.2016.2614429
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yu H, 2015, MULTIMED TOOLS APPL, V74, P9427, DOI 10.1007/s11042-014-2125-9
   Yu H, 2014, IEEE T HUM-MACH SYST, V44, P386, DOI 10.1109/THMS.2014.2313912
   Yu H, 2012, COMPUT GRAPH-UK, V36, P152, DOI 10.1016/j.cag.2011.12.002
   Zheng LD, 2020, AUTOPHAGY, V16, P1366, DOI 10.1080/15548627.2019.1668228
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 67
TC 44
Z9 44
U1 5
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2020
VL 22
IS 3
BP 730
EP 743
DI 10.1109/TMM.2019.2933338
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA KU2ZL
UT WOS:000519576700013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, HJ
   Chai, XJ
   Chen, XL
AF Wang, Hanjie
   Chai, Xiujuan
   Chen, Xilin
TI A Novel Sign Language Recognition Framework Using Hierarchical Grassmann
   Covariance Matrix
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Covariance matrices; Hidden Markov models; Manifolds; Assistive
   technology; Feature extraction; Gesture recognition; Correlation; Sign
   language recognition; grassmann covariance matrix; grassmann manifold;
   belief propagation; sentence spotting
ID CLASSIFICATION; FEATURES
AB Visual sign language recognition is an interesting and challenging problem. To create a discriminative representation, a hierarchical Grassmann covariance matrix (HGCM) model is proposed for sign description. Furthermore, a multi-temporal belief propagation (MTBP) based segmentation approach is presented for continuous sequence spotting. Concretely speaking, a sign is represented by multiple covariance matrices, followed by evaluating and selecting their most significant singular vectors. These covariance matrices are transformed into a more compact and discriminative HGCM, which is formulated on the Grassmann manifold. Continuous sign sequences can be recognized frame by frame using the HGCM model, before being optimized by MTBP, which is a carefully designed graphic model. The proposed method is thoroughly evaluated on isolated and synthetic and real continuous sign datasets as well as on HDM05. Extensive experimental results convincingly show the effectiveness of our proposed framework.
C1 [Wang, Hanjie; Chai, Xiujuan; Chen, Xilin] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Wang, Hanjie; Chai, Xiujuan; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Chai, XJ (corresponding author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
EM hanjie.wang@vipl.ict.ac.cn; chaixiujuan@ict.ac.cn; xlchen@ict.ac.cn
FU 973 Program [2015CB351802, QYZDJ-SSW-JSC009]
FX This work was supported in part by the 973 Program under Contract no.
   2015CB351802, Frontier ScienceKeyResearch Project ofCASunderContract no.
   QYZDJ-SSW-JSC009. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. David Crandall.
CR Alashkar T, 2018, IEEE T AFFECT COMPUT, V9, P271, DOI 10.1109/TAFFC.2016.2623718
   Alashkar T, 2016, PATTERN RECOGN, V57, P21, DOI 10.1016/j.patcog.2016.03.013
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2011, Visual Analysis of Humans: Looking at People, DOI DOI 10.1007/978-0-85729-997-027
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Celebi Sait, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P620
   Cho K, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P122
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Elliott R., 2011, P SIGN LANG TRANSL A
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Liu Z, 2017, IEEE INT CONF COMP V, P3056, DOI 10.1109/ICCVW.2017.361
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470
   Muller M., 2016, CG20072 U BONN I INF
   Ong EJ, 2014, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2014.248
   Ong EJ, 2012, PROC CVPR IEEE, P2200, DOI 10.1109/CVPR.2012.6247928
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Pitsikalis V., 2011, Computer Vision and Pattern Recognition Workshops, P1, DOI DOI 10.1109/CVPRW.2011.5981681
   Pitsikalis V, 2015, J MACH LEARN RES, V16, P255
   Roussos A, 2013, J MACH LEARN RES, V14, P1627
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Tabia H, 2015, IEEE T MULTIMEDIA, V17, P1591, DOI 10.1109/TMM.2015.2457676
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vemulapalli R, 2013, PROC CVPR IEEE, P1782, DOI 10.1109/CVPR.2013.233
   Wang CL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/AFGR.2002.1004188
   Wang H., 2012, Trends and Topics in Computer Vision, P342
   Wang HJ, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2897735
   Wang LC, 2014, IEEE T MULTIMEDIA, V16, P751, DOI 10.1109/TMM.2014.2298382
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu JX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P453
   Wu PP, 2016, IEEE T MULTIMEDIA, V18, P326, DOI 10.1109/TMM.2016.2520091
   Xu CY, 2014, IEEE T NEUR NET LEAR, V25, P728, DOI 10.1109/TNNLS.2013.2280752
   Yang HD, 2013, PATTERN RECOGN LETT, V34, P2051, DOI 10.1016/j.patrec.2013.06.022
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang RD, 2010, IEEE T PATTERN ANAL, V32, P462, DOI 10.1109/TPAMI.2009.26
   Yang WW, 2016, PATTERN RECOGN LETT, V78, P28, DOI 10.1016/j.patrec.2016.03.030
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
   Zhang W, 2013, IEEE T MULTIMEDIA, V15, P1594, DOI 10.1109/TMM.2013.2265675
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 43
TC 19
Z9 22
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2019
VL 21
IS 11
BP 2806
EP 2814
DI 10.1109/TMM.2019.2915032
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA JJ7VX
UT WOS:000494363000009
DA 2024-07-18
ER

PT J
AU Kordopatis-Zilos, G
   Papadopoulos, S
   Patras, I
   Kompatsiaris, I
AF Kordopatis-Zilos, Giorgos
   Papadopoulos, Symeon
   Patras, Ioannis
   Kompatsiaris, Ioannis
TI FIVR: Fine-Grained Incident Video Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Incident video retrieval; near-duplicate videos; video retrieval; video
   dataset
ID IMAGE
AB This paper introduces the problem of Fine-grained Incident Video Retrieval (FIVR). Given a query video, the objective is to retrieve all associated videos, considering several types of associations that range from duplicate videos to videos from the same incident. FIVR offers a single framework that contains several retrieval tasks as special cases. To address the benchmarking needs of all such tasks, we construct and present a large-scale annotated video dataset, which we call FIVR-200K, and it comprises 225,960 videos. To create the dataset, we devise a process for the collection of YouTube videos based on major news events from recent years crawled from Wikipedia and deploy a retrieval pipeline for the automatic selection of query videos based on their estimated suitability as benchmarks. We also devise a protocol for the annotation of the dataset with respect to the four types of video associations defined by FIVR. Finally, we report the results of an experimental study on the dataset comparing five state-of-the-art methods developed based on a variety of visual descriptors, highlighting the challenges of the current problem.
C1 [Kordopatis-Zilos, Giorgos; Papadopoulos, Symeon; Kompatsiaris, Ioannis] Ctr Res & Technol Hellas, Inst Informat Technol, Thessaloniki 57001, Greece.
   [Kordopatis-Zilos, Giorgos; Patras, Ioannis] Queen Mary Univ London, London E1 4NS, England.
C3 Centre for Research & Technology Hellas; University of London; Queen
   Mary University London
RP Kordopatis-Zilos, G (corresponding author), Ctr Res & Technol Hellas, Inst Informat Technol, Thessaloniki 57001, Greece.
EM georgekordopatis@iti.gr; papadop@iti.gr; i.patras@qmul.ac.uk;
   ikom@iti.gr
RI Kordopatis-Zilos, Giorgos/JVO-5332-2024; Kompatsiaris,
   Ioannis/P-8594-2015; Papadopoulos, Symeon/AET-0683-2022
OI Kordopatis-Zilos, Giorgos/0000-0003-2297-4802; Kompatsiaris,
   Ioannis/0000-0001-6447-9020; Patras, Ioannis/0000-0003-3913-4738;
   Papadopoulos, Symeon/0000-0002-5441-7341
FU European Commission [687786, 825297]; InVID Project; WeVerify Project;
   H2020 - Industrial Leadership [825297] Funding Source: H2020 -
   Industrial Leadership; EPSRC [EP/R026424/1] Funding Source: UKRI
FX This work was supported by the InVID and WeVerify Projects, partially
   funded by the European Commission under Contracts 687786 and 825297,
   respectively.
CR [Anonymous], REPORTING LAS VEGAS
   [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], 2007, CIVR '07
   [Anonymous], FORENSIC ARCHITECTUR
   [Anonymous], 2013, Verification handbook
   [Anonymous], 2013, MULTIMEDIA INFORM RE
   [Anonymous], TREC VIDEO RETRIEVAL
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2011, ONLINE P TRECVID 201
   Baraldi L, 2018, PROC CVPR IEEE, P7804, DOI 10.1109/CVPR.2018.00814
   Basharat A, 2008, COMPUT VIS IMAGE UND, V110, P360, DOI 10.1016/j.cviu.2007.09.016
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bird Steven, 2009, NATURAL LANGUAGE PRO, DOI DOI 10.1007/S10579-010-9124-X
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen WC, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P422, DOI 10.1109/PACRIM.2011.6032930
   Chou CL, 2015, IEEE T MULTIMEDIA, V17, P382, DOI 10.1109/TMM.2015.2391674
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gao LL, 2017, AAAI CONF ARTIF INTE, P1323
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Hao YB, 2017, IEEE T MULTIMEDIA, V19, P1, DOI 10.1109/TMM.2016.2610324
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang YG, 2014, LECT NOTES COMPUT SC, V8692, P357, DOI 10.1007/978-3-319-10593-2_24
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kordopatis-Zilos G, 2017, IEEE INT CONF COMP V, P347, DOI 10.1109/ICCVW.2017.49
   Kordopatis-Zilos G, 2017, P IEEE, V105, P1971, DOI 10.1109/JPROC.2017.2688799
   Kordopatis-Zilos G, 2017, LECT NOTES COMPUT SC, V10132, P251, DOI 10.1007/978-3-319-51811-4_21
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Lipton A. J., 2004, Intelligent Distributed Surveillance Systems (IDSS-04), P56
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Revaud J, 2013, PROC CVPR IEEE, P2459, DOI 10.1109/CVPR.2013.318
   Sabeur Z, 2015, LECT NOTES COMPUT SC, V9474, P162, DOI 10.1007/978-3-319-27857-5_15
   Shang L., 2010, Proceedings of the International Conference on Multimedia, P531
   Shuyo N., 2010, Language detection library for java
   Simonyan K., 2014, 14091556 ARXIV
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tolias G., 2016, P INT C LEARNING REP
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Wu A. G., 2007, P ACM MM, P218
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Wu ZP, 2014, INT J MULTIMED INF R, V3, P1, DOI 10.1007/s13735-013-0049-1
   Yang Y, 2018, WIRELESS NETW-GER, P1, DOI 10.1007/978-3-319-61869-2_1
   Yu-Gang Jiang, 2016, IEEE Transactions on Big Data, V2, P32, DOI 10.1109/TBDATA.2016.2530714
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao WL, 2009, IEEE T IMAGE PROCESS, V18, P412, DOI 10.1109/TIP.2008.2008900
NR 52
TC 26
Z9 27
U1 3
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2019
VL 21
IS 10
BP 2638
EP 2652
DI 10.1109/TMM.2019.2905741
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA JD1IM
UT WOS:000489728400017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khelifi, L
   Mignotte, M
AF Khelifi, Lazhar
   Mignotte, Max
TI MC-SSM: Nonparametric Semantic Image Segmentation With the ICM Algorithm
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image processing; semantic image segmentation; energy minimization
   model; iterative conditional modes (ICM); global consistency error (GCE)
ID MULTICLASS OBJECT RECOGNITION; TEXTURE; COLOR; INFORMATION; PROPAGATION;
   TEXTONBOOST; CONTEXT; MODELS; LAYOUT
AB In the last few years, there has been considerable interest in scene parsing. This task consists of assigning a predefined class label to each pixel (or pre-segmented region) in an image. To best address the complexity challenge of this task, first, we propose a new geometric retrieval strategy to select nearest neighbors from a database containing fully segmented and annotated images. Then, we introduce a novel and simple energy-minimization model. The proposed cost function of this model combines efficiently different global nonparametric semantic likelihood energy terms. These terms are computed from the (pre-) segmented regions of the (query) image and their structural properties (location, texture, color, context, and shape). Different from the traditional approaches, we use a simple and local optimization procedure derived from the iterative conditional modes algorithm to optimize our energy-based model. Experimental results on two challenging datasets: 1) microsoft research Cambridge dataset and 2) Stanford background dataset demonstrate the feasibility and the success of the proposed approach. Compared to existing annotation methods that require training classifiers for each object and learning many parameters, our method is easy to implement, has a few parameters, and combines different criteria.
C1 [Khelifi, Lazhar; Mignotte, Max] Univ Montreal, Fac Arts & Sci, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal
RP Khelifi, L (corresponding author), Univ Montreal, Fac Arts & Sci, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada.
EM khelifil@iro.umontreal.ca; mignotte@iro.umontreal.ca
RI Mignotte, Max/F-7014-2015
FU National Science and Engineering Research Council of Canada (NSERC);
   Tunisia's Universitary Mission in North-America (MUTAN)
FX This work was supported in part by the National Science and Engineering
   Research Council of Canada (NSERC), and in part by the Tunisia's
   Universitary Mission in North-America (MUTAN). The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Jian Zhang. (Corresponding author: Lazhar
   Khelifi.)
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   An XY, 2016, NEUROCOMPUTING, V201, P92, DOI 10.1016/j.neucom.2016.03.034
   Andrade EL, 2005, IEEE T MULTIMEDIA, V7, P1084, DOI 10.1109/TMM.2005.854417
   Bassiouny A, 2014, IEEE IMAGE PROC, P981, DOI 10.1109/ICIP.2014.7025197
   Bertasius G., 2017, P IEEE COMP SOC C CO, P358
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Campbell NW, 1997, PATTERN RECOGN, V30, P555, DOI 10.1016/S0031-3203(96)00112-4
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen L, 2015, RSC SMART MATER, P1
   Csurka G, 2011, INT J COMPUT VISION, V95, P198, DOI 10.1007/s11263-010-0344-8
   Destrempes F, 2005, IEEE T IMAGE PROCESS, V14, P1096, DOI 10.1109/TIP.2005.851710
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fulkerson B, 2009, IEEE I CONF COMP VIS, P670
   Garcia-Herrero S, 2010, J ANDROL, P57
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   Gould S, 2014, COMMUN ACM, V57, P68, DOI 10.1145/2629637
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Gupta O, 2018, PATTERN RECOGN, V76, P25, DOI 10.1016/j.patcog.2017.10.017
   Haltakov V, 2016, COMPUT VIS IMAGE UND, V148, P164, DOI 10.1016/j.cviu.2015.11.008
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Joshi A, 2015, INT CONF BIOMETR, P177, DOI 10.1109/ICB.2015.7139049
   Kekec T., 2014, P BRIT MACH VIS C, P1
   Khelifi L, 2017, IEEE IMAGE PROC, P3080, DOI 10.1109/ICIP.2017.8296849
   Khelifi L, 2017, IEEE T SYST MAN CY-S, V47, P2489, DOI 10.1109/TSMC.2016.2531645
   Khelifi L, 2016, IEEE IMAGE PROC, P2574, DOI 10.1109/ICIP.2016.7532824
   Khoreva A., 2017, P IEEE COMP SOC C CO, P376
   Kim K, 2018, IEEE T MULTIMEDIA, V20, P208, DOI 10.1109/TMM.2017.2728318
   Ladicky L, 2014, IEEE T PATTERN ANAL, V36, P1056, DOI 10.1109/TPAMI.2013.165
   Li KQ, 2018, ZOOKEYS, P69, DOI 10.3897/zookeys.762.22163
   Li Q, 2014, IEEE T IMAGE PROCESS, V23, P4812, DOI 10.1109/TIP.2014.2358193
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Li Y, 2017, IEEE T SYST MAN CY-S, V47, P648, DOI 10.1109/TSMC.2016.2623683
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu C., 2016, DENSE IMAGE CORRES C, P207, DOI DOI 10.1007/978-3-319-23048-110
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu FY, 2018, IEEE T NEUR NET LEAR, V29, P2631, DOI 10.1109/TNNLS.2017.2690453
   LIU S, 2015, PROC CVPR IEEE, P1419, DOI DOI 10.1109/CVPR.2015.7298748
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mäenpää T, 2002, INT C PATT RECOG, P668, DOI 10.1109/ICPR.2002.1044840
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Meng FM, 2018, IEEE T MULTIMEDIA, V20, P310, DOI 10.1109/TMM.2017.2739919
   Narote SP, 2018, PATTERN RECOGN, V73, P216, DOI 10.1016/j.patcog.2017.08.014
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Qi GJ, 2016, PROC CVPR IEEE, P2267, DOI 10.1109/CVPR.2016.249
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shih F., 2010, Image Processing and Pattern Recognition: Fundamentals and Techniques
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Shotton Jamie., 2014, Computer Vision: A Reference Guide. Ed. by, P713
   Shuai B, 2016, IEEE T IMAGE PROCESS, V25, P2379, DOI 10.1109/TIP.2016.2533862
   Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Tung F, 2016, COMPUT VIS IMAGE UND, V143, P191, DOI 10.1016/j.cviu.2015.08.009
   Tung F, 2014, LECT NOTES COMPUT SC, V8694, P511, DOI 10.1007/978-3-319-10599-4_33
   Xie J, 2017, COGN COMPUT, V9, P168, DOI 10.1007/s12559-016-9441-5
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Yuan D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P82, DOI 10.1109/RCAR.2016.7784005
   Zand M, 2016, IEEE T IMAGE PROCESS, V25, P3233, DOI 10.1109/TIP.2016.2552401
   Zhang H, 2011, 2011 INTERNATIONAL CONFERENCE ON EDUCATION SCIENCE AND MANAGEMENT ENGINEERING (ESME 2011), VOLS 1-5, P2243
   Zhang L, 2010, IEEE T PATTERN ANAL, V32, P1406, DOI 10.1109/TPAMI.2009.145
NR 64
TC 4
Z9 4
U1 0
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2019
VL 21
IS 8
BP 1946
EP 1959
DI 10.1109/TMM.2019.2891418
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IK7YM
UT WOS:000476809700005
DA 2024-07-18
ER

PT J
AU Yang, JC
   Sim, K
   Lu, W
   Jiang, B
AF Yang, Jiachen
   Sim, Kyohoon
   Lu, Wen
   Jiang, Bin
TI Predicting Stereoscopic Image Quality via Stacked Auto-Encoders Based on
   Stereopsis Formation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Stereoscopic image quality assessment; stacked auto-encoders; deep
   feature; binocular summation and difference channels; cyclopean channel
ID INFORMATION; STATISTICS; NETWORK
AB Most previous 2-D and 3-D image quality evaluators were based on shallow architectures. Their shallow architectures cannot model phenomenon occurring in human visual systems sufficiently. Disparities between left and right views have been importantly used for 3-D image quality assessment (IQA), but single disparity, depth, or cyclopean maps made from the disparities cannot thoroughly reflect the depth sense. In this paper, we propose a blind stereoscopic image quality evaluator using stacked auto-encoders (SAE). The proposed method is based on two theories on initial stages of stereopsis. One is cyclopean channel theory and the other is binocular summation/difference channels theory. Especially, a cyclopean image that models the former theory is computed to consider binocular suppression, whereas summation and difference images that model the latter one are utilized to treat the depth sense. We train three SAEs for quality-aware features from the three images in an unsupervised manner. Through the SAEs, the features are transformed into more meaningful features, and they are used to train two regressors. The regressors are used to obtain a final predicted score. Experimental results conducted on popular 3-D IQA databases prove that the proposed algorithm outperforms state-of-the-art 3-D IQA methods.
C1 [Yang, Jiachen; Sim, Kyohoon; Jiang, Bin] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Lu, Wen] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Tianjin University; Xidian University
RP Lu, W (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM yangjiachen@tju.edu.cn; tlarygns0211@tju.edu.cn; luwen@xidian.edu.cn;
   jiang-bin@tju.edu.cn
RI Yang, Jiachen/ABH-5032-2020
OI Yang, Jiachen/0000-0003-2558-552X; SIM, Kyohoon/0000-0002-5214-7675
FU National Natural Science Foundation of China [61871283]; Foundation of
   Pre-Research on Equipment of China [61403120103]; Joint Foundation of
   Pre-Research on Equipment from Education Department of China
   [6141A02022336]
FX This work was supported in part by the National Natural Science
   Foundation of China (61871283), in part by the Foundation of
   Pre-Research on Equipment of China (61403120103), and in part by the
   Joint Foundation of Pre-Research on Equipment from Education Department
   of China (6141A02022336).
CR [Anonymous], 2016, PATTERN RECOGN, DOI DOI 10.1016/j.patcog.2016.01.034
   [Anonymous], 2000, FINAL REPORT VIDEO Q
   [Anonymous], 2012, PREDICTION CANDIDATE
   [Anonymous], EURASIP J IMAGE VIDE
   [Anonymous], P IEEE ADV INF MAN C
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Audhkhasi K, 2013, IEEE T PATTERN ANAL, V35, P769, DOI 10.1109/TPAMI.2012.139
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637
   Blake R, 2002, NAT REV NEUROSCI, V3, P13, DOI 10.1038/nrn701
   Chakraborty S, 2015, IEEE T NEUR NET LEAR, V26, P1747, DOI 10.1109/TNNLS.2014.2356470
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   CORMACK LK, 1991, VISION RES, V31, P2195, DOI 10.1016/0042-6989(91)90172-2
   Ding J, 2006, P NATL ACAD SCI USA, V103, P1141, DOI 10.1073/pnas.0509629103
   Ghadiyaram D, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P946, DOI 10.1109/GlobalSIP.2014.7032260
   Henriksen S, 2016, CURR BIOL, V26, pR500, DOI 10.1016/j.cub.2016.04.049
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Ko H, 2017, J VIS COMMUN IMAGE R, V45, P156, DOI 10.1016/j.jvcir.2017.02.014
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu TJ, 2017, IEEE T NEUR NET LEAR, V28, P107, DOI 10.1109/TNNLS.2015.2500268
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Ma L, 2011, IEEE T MULTIMEDIA, V13, P824, DOI 10.1109/TMM.2011.2109701
   Maalouf A, 2011, INT CONF ACOUST SPEE, P1161
   May KA, 2012, CURR BIOL, V22, P28, DOI 10.1016/j.cub.2011.11.025
   Md SK, 2015, IEEE SIGNAL PROC LET, V22, P1985, DOI 10.1109/LSP.2015.2449878
   Ming-Jun Chen, 2011, 2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis, P24, DOI 10.1109/IVMSPW.2011.5970349
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   PETTIGREW JD, 1972, SCI AM, V227, P84, DOI 10.1038/scientificamerican0872-84
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2016, IEEE T IMAGE PROCESS, V25, P2059, DOI 10.1109/TIP.2016.2538462
   Shao F, 2015, IEEE T BROADCAST, V61, P154, DOI 10.1109/TBC.2015.2402491
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Snowden Robert., 2006, BASIC VISION INTRO V
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Stuhlsatz A, 2012, IEEE T NEUR NET LEAR, V23, P596, DOI 10.1109/TNNLS.2012.2183645
   Su CC, 2015, IEEE T IMAGE PROCESS, V24, P1685, DOI 10.1109/TIP.2015.2409558
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
   You J, 2010, IEEE CONF WIREL MOB, P1, DOI 10.1109/WIMOB.2010.5644989
   Yu Qi, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6716, DOI 10.1109/ICASSP.2014.6854900
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P3810, DOI 10.1109/TIP.2015.2456414
   Zhou WJ, 2016, IEEE T MULTIMEDIA, V18, P1077, DOI 10.1109/TMM.2016.2542580
NR 60
TC 31
Z9 34
U1 0
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2019
VL 21
IS 7
BP 1750
EP 1761
DI 10.1109/TMM.2018.2889562
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IF6IF
UT WOS:000473183700011
DA 2024-07-18
ER

PT J
AU Zhou, H
   Chen, KJ
   Zhang, WM
   Yao, YZ
   Yu, NH
AF Zhou, Hang
   Chen, Kejiang
   Zhang, Weiming
   Yao, Yuanzhi
   Yu, Nenghai
TI Distortion Design for Secure Adaptive 3-D Mesh Steganography
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Mesh steganography; mesh steganalysis; vertex normal; least significant
   bit replacement
ID STEGANALYSIS; WATERMARKING; ALGORITHM
AB We propose a novel technique for steganography on 3-D meshes so as to resist steganalysis. The majority of existing methods modulate vertex coordinates to embed messages in a nonadaptive way. We take account of complexity of local regions as joint distortion of a triple unit (vertice) and coding method such as syndrome trellis codes to adaptively embed messages, which owns stronger security with respect to existing steganalysis. Key to the distortion is a novel formulation of adaptive steganography, which relies on some effective steganalytic features such as variation of vertex normal. We provide quantitative and qualitative comparisons of our method with several baselines against steganalytic features LFS64, LFS76, and ensemble classifiers, and show that it outperforms the current state of the art. Meanwhile, we proposed an attacking method on steganography proposed by Chao et al. (2009) with a high detection rate.
C1 [Zhou, Hang; Chen, Kejiang; Zhang, Weiming; Yao, Yuanzhi; Yu, Nenghai] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Anhui, Peoples R China.
EM zh2991@mail.ustc.edu.cn; chenkj@mail.ustc.edu.cn; zhangwm@ustc.edu.cn;
   yaoyz@mail.ustc.edu.cn; ynh@ustc.edu.cn
RI Zhou, Hang/AAI-5565-2021; Chen, Kejiang/ABD-7057-2020; Yao,
   Yuanzhi/JZS-9170-2024
OI Yao, Yuanzhi/0000-0003-1965-7670; Chen, Kejiang/0000-0002-9868-3414;
   Zhang, Weiming/0000-0001-5576-6108; Zhou, Hang/0000-0001-7860-8452
FU Natural Science Foundation of China [U1636201, 61572452]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants U1636201 and 61572452. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Balakrishnan Prabhakaran.
CR Amat P, 2010, SIGNAL PROCESS-IMAGE, V25, P400, DOI 10.1016/j.image.2010.05.002
   [Anonymous], P SEC STEG WAT MULT
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Centin M, 2018, IEEE T VIS COMPUT GR, V24, P2380, DOI 10.1109/TVCG.2017.2731771
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Chen KJ, 2016, IEEE INT WORKS INFOR
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Itier V, 2017, MULTIMED TOOLS APPL, V76, P26421, DOI 10.1007/s11042-016-4163-y
   Itier V, 2015, PROC SPIE, V9393, DOI 10.1117/12.2076763
   Jiang RQ, 2018, IEEE T MULTIMEDIA, V20, P55, DOI 10.1109/TMM.2017.2723244
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kim D, 2017, LECT NOTES ELECTR EN, V424, P358, DOI 10.1007/978-981-10-4154-9_42
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2010, PROC SPIE, V7541, DOI 10.1117/12.838768
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li NN, 2017, IEEE ACCESS, V5, P24457, DOI 10.1109/ACCESS.2017.2767072
   Li ZY, 2017, IEEE IMAGE PROC, P510, DOI 10.1109/ICIP.2017.8296333
   Li ZY, 2017, INFORM SCIENCES, V415, P85, DOI 10.1016/j.ins.2017.06.011
   Li ZY, 2016, INT CONF ACOUST SPEE, P2144, DOI 10.1109/ICASSP.2016.7472056
   Max N., 1999, Journal of Graphics Tools, V4, P1, DOI 10.1080/10867651.1999.10487501
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Rolland-Neviere Xavier, 2014, IEEE Transactions on Information Forensics and Security, V9, P1491, DOI 10.1109/TIFS.2014.2336376
   Rugis J, 2006, LECT NOTES COMPUT SC, V4319, P138
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Vasic B, 2013, IEEE T MULTIMEDIA, V15, P1532, DOI 10.1109/TMM.2013.2265673
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Yang Y, 2010, COMPUT GRAPH FORUM, V29, P1585, DOI 10.1111/j.1467-8659.2010.01767.x
   Yang Y, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2535555
   Yang Y, 2013, IEEE T VIS COMPUT GR, V19, P45, DOI 10.1109/TVCG.2012.106
NR 43
TC 23
Z9 25
U1 0
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2019
VL 21
IS 6
BP 1384
EP 1398
DI 10.1109/TMM.2018.2882088
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IA1QQ
UT WOS:000469337400004
DA 2024-07-18
ER

PT J
AU Elmadany, NE
   He, YF
   Guan, L
AF Elmadany, Nour El Din
   He, Yifeng
   Guan, Ling
TI Multimodal Learning for Human Action Recognition Via Bimodal/Multimodal
   Hybrid Centroid Canonical Correlation Analysis
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Human action recognition; multimodal learning; BHCCCA; MHCCCA
ID WEARABLE SENSORS; HISTOGRAMS; FUSION
AB In this paper, we study the problem of human action recognition from multiple feature modalities. We propose bimodal hybrid centroid canonical correlation analysis (BHCCCA) and multimodal hybrid centroid canonical correlation analysis (MHCCCA) to learn the discriminative and informative shared space, by considering the correlation among different classes across two modalities (BHCCCA) and three or more modalities (MHCCCA). We then introduce a new human action recognition framework by using BHCCCA/MHCCCA for fusing different modalities (RGB, depth, skeleton, and accelerometer data). Performance evaluation on four publicly accessible data sets (MSR Action3D, UTD-MHAD, UTD-MHAD-Kinect V2, and Berkeley MHAD) demonstrated the effectiveness of the proposed framework.
C1 [Elmadany, Nour El Din; He, Yifeng; Guan, Ling] Ryerson Univ, Elect & Comp Engn Dept, Toronto, ON M5B 2K3, Canada.
C3 Toronto Metropolitan University
RP Elmadany, NE (corresponding author), Ryerson Univ, Elect & Comp Engn Dept, Toronto, ON M5B 2K3, Canada.
EM elmadany@ryerson.ca; yhe@ee.ryerson.ca; lguan@ee.ryerson.ca
RI ARSLAN, Okan/AAA-3232-2020
OI elmadany, noureldin/0000-0002-8719-6733
CR [Anonymous], 2012, Tech. Rep. MSR-TR-2012-68
   [Anonymous], 2012, P ACM INT C MULT ACM
   [Anonymous], P INT C AC SPEECH SI
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], COMMUN STAT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2012, 2012 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2012.6239231
   [Anonymous], P IEEE WINT C APPL C
   [Anonymous], PROC INT WORKSHOP SP
   [Anonymous], 2020, MULTIOBJECTIVE MANAG
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 47 MIT
   Aranki D., 2014, Proceedings of the 9th International Conference on Body Area Networks, P135
   Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen J, 2005, P ANN INT IEEE EMBS, P3551, DOI 10.1109/IEMBS.2005.1617246
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   El Madany NE, 2015, IEEE INT WORKSH MULT
   Elhoushi M, 2016, IEEE T INSTRUM MEAS, V65, P208, DOI 10.1109/TIM.2015.2477159
   Ermes M, 2008, IEEE T INF TECHNOL B, V12, P20, DOI 10.1109/TITB.2007.899496
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hasan MA, 2009, P AMER CONTR CONF, P1280, DOI 10.1109/ACC.2009.5160592
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hussein, 2013, INT JOINT C ART INT
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Kaâniche MB, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P140, DOI 10.1109/AVSS.2009.26
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Nam Y, 2012, MULTIMED TOOLS APPL, V57, P315, DOI 10.1007/s11042-010-0677-x
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shahroudy A, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P73, DOI 10.1109/ISCCSP.2014.6877819
   Tran QD, 2013, PROCEEDINGS OF 2013 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES: RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P253, DOI 10.1109/RIVF.2013.6719903
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wu XX, 2013, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2013.81
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xinxiao Wu, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P444, DOI 10.1007/978-3-642-34778-8_41
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yeh YR, 2014, IEEE T IMAGE PROCESS, V23, P2009, DOI 10.1109/TIP.2014.2310992
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 58
TC 28
Z9 30
U1 1
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2019
VL 21
IS 5
BP 1317
EP 1331
DI 10.1109/TMM.2018.2875510
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HV8HY
UT WOS:000466223600019
DA 2024-07-18
ER

PT J
AU Shen, LH
   Zhao, YQ
   Peng, QN
   Chan, JCW
   Kong, SG
AF Shen, Linghao
   Zhao, Yongqiang
   Peng, Qunnie
   Chan, Jonathan Cheung-Wai
   Kong, Seong G.
TI An Iterative Image Dehazing Method With Polarization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Dehazing; polarization; iterative scheme; weighted regularization
AB This paper presents a joint dehazing and denoising scheme for an image taken in hazy conditions. Conventional image dehazing methods may amplify the noise depending on the distance and density of the haze. To suppress the noise and improve the dehazing performance, an imaging model is modified by adding the process of amplifying the noise in hazy conditions. This model offers depth-chromaticity compensation regularization for the transmission map and chromaticity-depth compensation regularization for dehazing the image. The proposed iterative image dehazing method with polarization uses these two joint regularization schemes and the relationship between the transmission map and dehazed image. The transmission map and irradiance image are used to promote each other. To verify the effectiveness of the algorithm, polarizing images of different scenes in different days are collected. Different algorithms are applied to the original images. Experimental results demonstrate that the proposed scheme increases visibility in extreme weather conditions without amplifying the noise.
C1 [Shen, Linghao; Zhao, Yongqiang] Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China.
   [Peng, Qunnie] Luoyang Inst Electroopt Equipment AVIC, Luoyang 471000, Peoples R China.
   [Chan, Jonathan Cheung-Wai] Vrije Univ Brussel, Dept Elect & Informat, B-1050 Brussels, Belgium.
   [Kong, Seong G.] Sejong Univ, Dept Comp Engn, Seoul 05006, South Korea.
C3 Northwestern Polytechnical University; Aviation Industry Corporation of
   China (AVIC); Vrije Universiteit Brussel; Sejong University
RP Zhao, YQ (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China.
EM 460855258@qq.com; zhaoyq@nwpu.edu.cn; pengqn1992@126.com;
   jcheungw@etrovub.be; skong@sejong.edu
RI Zhao, Yongqiang/X-8054-2019
OI Zhao, Yongqiang/0000-0002-6974-7327; Kong, Seong G/0000-0002-0335-6526
FU National Natural Science Foundation of China [61771391, 61371152,
   61511140292, NRF-2015K2A2A2000886]; Shenzhen Municipal Science and
   Technology Innovation Committee [JCYJ20170815162956949]; Korea National
   Research Foundation [61511140292, NRF-2015K2A2A2000886,
   NRF-2016R1D1A1B01008522]
FX This work was supported in part by the National Natural Science
   Foundation of China (61771391, 61371152); in part by the Shenzhen
   Municipal Science and Technology Innovation Committee
   (JCYJ20170815162956949); in part by the National Natural Science
   Foundation of China and Korea National Research Foundation Joint Funded
   Cooperation Program (61511140292, NRF-2015K2A2A2000886); and in part by
   the Korea National Research Foundation (NRF-2016R1D1A1B01008522).
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], P IEEE INT C PATT RE
   [Anonymous], PROC 27TH INT JOINT
   [Anonymous], P EUR C COMP VIS ECC
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fan X, 2017, IEEE T CIRC SYST VID, V27, P2505, DOI 10.1109/TCSVT.2016.2592328
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gibson KB, 2013, IEEE T IMAGE PROCESS, V22, P3982, DOI 10.1109/TIP.2013.2265884
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liang J, 2015, OPT EXPRESS, V23, P26146, DOI 10.1364/OE.23.026146
   Miyazaki D, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P852, DOI 10.1109/ICCVW.2013.117
   Qu YF, 2017, OPT EXPRESS, V25, P25004, DOI 10.1364/OE.25.025004
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Schaul L, 2009, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2009.5413700
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Tan R. T., 2008, P IEEE C COMP VIS PA, P1
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Wang JZ, 2016, IEEE T MULTIMEDIA, V18, P1000, DOI 10.1109/TMM.2016.2544099
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Yang JX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040305
   Zhao Y., 2016, Multi-band Polarization Imaging and Application, V1st
NR 31
TC 66
Z9 67
U1 15
U2 66
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2019
VL 21
IS 5
BP 1093
EP 1107
DI 10.1109/TMM.2018.2871955
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HV8HY
UT WOS:000466223600002
OA Bronze
DA 2024-07-18
ER

PT J
AU Luo, HC
   Gao, Y
   Wu, YH
   Liao, CY
   Yang, X
   Cheng, KT
AF Luo, Hongcheng
   Gao, Yang
   Wu, Yuhao
   Liao, Chunyuan
   Yang, Xin
   Cheng, Kwang-Ting
TI Real-Time Dense Monocular SLAM With Online Adapted Depth Prediction
   Network
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Monocular SLAM; dense mapping; convolutional neural network; fusion;
   online tuning
ID ACCURATE
AB Considerable advances have been achieved in estimating the depth map from a single image via convolutional neural networks (CNNs) during the past few years. Combining depth prediction from CNNs with conventional monocular simultaneous localization and mapping (SLAM) is promising for accurate and dense monocular reconstruction, in particular addressing the two long-standing challenges in conventional monocular SLAM: low map completeness and scale ambiguity. However, depth estimated by pretrained CNNs usually fails to achieve sufficient accuracy for environments of different types from the training data, which are common for certain applications such as obstacle avoidance of drones in unknown scenes. Additionally, inaccurate depth prediction of CNN could yield large tracking errors in monocular SLAM. In this paper, we present a real-time dense monocular SLAM system, which effectively fuses direct monocular SLAM with an online-adapted depth prediction network for achieving accurate depth prediction of scenes of different types from the training data and providing absolute scale information for tracking and mapping. Specifically, on one hand, tracking pose (i.e., translation and rotation) from direct SLAM is used for selecting a small set of highly effective and reliable training images, which acts as ground truth for tuning the depth prediction network on-the-fly toward better generalization ability for scenes of different types. A stage-wise Stochastic Gradient Descent algorithm with a selective update strategy is introduced for efficient convergence of the tuning process. On the other hand, the dense map produced by the adapted network is applied to address scale ambiguity of direct monocular SLAM which in turn improves the accuracy of both tracking and overall reconstruction. The system with assistance of both CPUs and GPUs, can achieve real-time performance with progressively improved reconstruction accuracy. Experimental results on public datasets and live application to obstacle avoidance of drones demonstrate that our method outperforms the state-of-the-art methods with greater map completeness and accuracy, and a smaller tracking error.
C1 [Luo, Hongcheng; Gao, Yang; Wu, Yuhao; Yang, Xin] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.
   [Liao, Chunyuan] HiScene Informat Technol Co Ltd, Pudong 201210, Peoples R China.
   [Cheng, Kwang-Ting] Hong Kong Univ Sci & Technol, Sch Engn, Hong Kong, Peoples R China.
C3 Huazhong University of Science & Technology; Hong Kong University of
   Science & Technology
RP Yang, X (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.
EM hongcheng@hust.edu.cn; 503913389@qq.com; 1628422844@qq.com;
   liaocy@hiscene.com; xinyang2014@hust.edu.cn; timcheng@ust.hk
OI Cheng, Kwang-Ting Tim/0000-0002-3885-4912
FU National Natural Science Foundation of China [61502188]; Wuhan Science
   and Technology Bureau [2017010201010111]; Program for HUST Acadamic
   Frontier Youth Team
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61502188, in part by the Wuhan Science
   and Technology Bureau under Award 2017010201010111, and in part by the
   Program for HUST Acadamic Frontier Youth Team. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Cha Zhang.
CR Alismail H., 2010, the 11th International Conference on Intelligent Autonomous Systems (IAS-11), V3, P2
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2018, MULTIMED TOOL APPL
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2001, PYRAMIDAL IMPLEMENTA
   Bipin K, 2015, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2015.7139308
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326
   Bloesch M, 2015, IEEE INT C INT ROBOT, P298, DOI 10.1109/IROS.2015.7353389
   Bodin B, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P57, DOI 10.1145/2967938.2967963
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203
   Chen J, 2016, IEEE INT CONF ROBOT, P1476, DOI 10.1109/ICRA.2016.7487283
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chhaya F, 2016, IEEE INT CONF ROBOT, P5758, DOI 10.1109/ICRA.2016.7487799
   Concha A, 2015, IEEE INT C INT ROBOT, P5686, DOI 10.1109/IROS.2015.7354184
   Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170
   Eigen D, 2014, ADV NEUR IN, V27
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Engel J, 2013, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2013.183
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Greene WN, 2016, IEEE INT CONF ROBOT, P833, DOI 10.1109/ICRA.2016.7487213
   Guo YL, 2014, IEEE T MULTIMEDIA, V16, P1377, DOI 10.1109/TMM.2014.2316145
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Klein George, 2007, P1
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Minguez J, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P588, DOI 10.1109/IRDS.2002.1041455
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Phan R, 2014, IEEE T MULTIMEDIA, V16, P122, DOI 10.1109/TMM.2013.2283451
   Pollefeys M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P496, DOI 10.1109/ICCV.1999.791262
   Sengupta S, 2015, IEEE INT CONF ROBOT, P1874, DOI 10.1109/ICRA.2015.7139442
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Wu PF, 2017, IEEE T MULTIMEDIA, V19, P266, DOI 10.1109/TMM.2016.2612761
   Xue TL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P510, DOI 10.1145/3123266.3123348
NR 45
TC 32
Z9 32
U1 2
U2 55
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2019
VL 21
IS 2
BP 470
EP 483
DI 10.1109/TMM.2018.2859034
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA HJ7GT
UT WOS:000457364400016
DA 2024-07-18
ER

PT J
AU Si, WX
   Qin, J
   Chen, ZC
   Liao, XY
   Wang, Q
   Heng, PA
AF Si, Weixin
   Qin, Jing
   Chen, Zhuchao
   Liao, Xiangyun
   Wang, Qiong
   Heng, Pheng-Ann
TI Thin-Feature-Aware Transport-Velocity Formulation for SPH-Based Liquid
   Animation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Fluid effect; liquid simulation; thin-feature-aware transport-velocity
   formulation; SPH
ID SMOOTHED PARTICLE HYDRODYNAMICS; BREAKUP; FLOWS
AB Realistic liquid animations with thin sheets or streams are crucial for creating fluid effects in digital media. However, it is challenging to simulate these appealing thin sheets or streams in the framework of smoothed particle hydrodynamics (SPH). The underlying reason for this challenge mainly lies in the inherent numerical instability of SPH due to inconsistent kernel interpolation, which is caused by the incomplete kernel support on the free surface and the particles' disorder dispersion within the simulation domain. To address this challenge, we propose a novel and effective approach to ensure the consistency of kernel interpolation at both internal flow and the free surface during the simulation such that these thin features can always be well maintained. First, we introduce a transport-velocity formulation to alleviate the disorder dispersion in the liquid domain. However, this formulation can only work in the internal flow, and it fails at the free surface because it cannot accurately estimate the density of particles there. To this end, we propose adaptively correcting the underestimated density caused by the incomplete kernel support of free-surface particles, which are identified by a geometry-aware anisotropic kernel, to counteract the inconsistent interpolation on the free surface. Then, we propose a novel scheme to further filter the background pressure to enhance the interactions between the internal flow and the free surface, as well as liquid and solid, such that the thin features generated from such interactions can be realistically simulated. The proposed approach can also achieve anticlumping and regularization effects in the entire simulation domain and, hence, further enhance the thin features in liquids. We evaluate our method on a variety of benchmark examples, and the results demonstrate that our method can achieve more appealing visual effects than state-of-the-art methods by realistically simulating more vivid thin features.
C1 [Si, Weixin; Chen, Zhuchao; Liao, Xiangyun; Wang, Qiong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen 518055, Peoples R China.
   [Si, Weixin; Qin, Jing] Hong Kong Polytech Univ, Sch Nursing, Hong Kong, Hong Kong, Peoples R China.
   [Heng, Pheng-Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Hong Kong Polytechnic University; Chinese University of Hong Kong
RP Liao, XY; Wang, Q (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen 518055, Peoples R China.
EM wxsics@gmail.com; harry.qin@polyu.edu.hk; chenzhuchao@126.com;
   xyunliao@gmail.com; wangqiong@siat.ac.cn; pheng@cse.cuhk.edu.hk
RI Qin, Jing/J-9807-2016; Qin, Jing/JMC-1371-2023
OI Qin, Jing/0000-0002-7059-0929; Heng, Pheng Ann/0000-0003-3055-5034
FU Hong Kong Research Grants Council under General Research Fund
   [14225616]; Innovation and Technology Fund of Hong Kong [ITS/026/17,
   ITS/304/16]; Hong Kong Polytechnic University [1-ZE8J]; Shenzhen Science
   and Technology Program [JCYJ20160429190300857, JCYJ20150925163244742,
   2017B010110004]; China Postdoctoral Science Foundation [2017M622831]
FX This work was supported in part by the Hong Kong Research Grants Council
   under General Research Fund (Project No. 14225616); in part by the
   Innovation and Technology Fund of Hong Kong under Grants ITS/026/17 and
   ITS/304/16; in part by the Hong Kong Polytechnic University under Grant
   1-ZE8J; in part by the Shenzhen Science and Technology Program under
   Grants JCYJ20160429190300857, JCYJ20150925163244742, and 2017B010110004;
   and in part by the China Postdoctoral Science Foundation under Grant
   2017M622831.
CR Adami S, 2013, J COMPUT PHYS, V241, P292, DOI 10.1016/j.jcp.2013.01.043
   Adami S, 2010, J COMPUT PHYS, V229, P1909, DOI 10.1016/j.jcp.2009.11.015
   Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2013, COMPUT ANIMAT VIRT W, V24, P195, DOI 10.1002/cav.1499
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Ando R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461982
   Ando R, 2012, IEEE T VIS COMPUT GR, V18, P1202, DOI 10.1109/TVCG.2012.87
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J., 2015, P 14 ACM SIGGRAPH EU, P147, DOI DOI 10.1145/2786784.2786796
   Cai XY, 2016, IEEE T MULTIMEDIA, V18, P141, DOI 10.1109/TMM.2015.2505089
   Colagrossi A, 2003, J COMPUT PHYS, V191, P448, DOI 10.1016/S0021-9991(03)00324-3
   Cummins SJ, 1999, J COMPUT PHYS, V152, P584, DOI 10.1006/jcph.1999.6246
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Eggers J, 1997, REV MOD PHYS, V69, P865, DOI 10.1103/RevModPhys.69.865
   Feldman J, 2007, INT J NUMER METH ENG, V72, P295, DOI 10.1002/nme.2010
   Ferrand M, 2013, INT J NUMER METH FL, V71, P446, DOI 10.1002/fld.3666
   Fujisawa M, 2015, COMPUT GRAPH FORUM, V34, P155, DOI 10.1111/cgf.12754
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Guo YA, 2016, IEEE T MULTIMEDIA, V18, P1977, DOI 10.1109/TMM.2016.2597007
   Haefner S, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8409
   He XW, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682630
   Hu XY, 2006, J COMPUT PHYS, V213, P844, DOI 10.1016/j.jcp.2005.09.001
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Jakob Wenzel, 2010, Mitsuba renderer
   Johnson GR, 1996, INT J NUMER METH ENG, V39, P2725, DOI 10.1002/(SICI)1097-0207(19960830)39:16<2725::AID-NME973>3.0.CO;2-9
   Kiara A., 2010, THESIS
   Kiara A, 2013, COMPUT FLUIDS, V86, P611, DOI 10.1016/j.compfluid.2013.05.023
   Kulasegaram S, 2004, COMPUT MECH, V33, P316, DOI 10.1007/s00466-003-0534-0
   Li SF, 1996, COMPUT METHOD APPL M, V139, P159, DOI 10.1016/S0045-7825(96)01082-1
   Liu WK, 1997, COMPUT METHOD APPL M, V143, P113, DOI 10.1016/S0045-7825(96)01132-2
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Marrone S, 2011, COMPUT METHOD APPL M, V200, P1526, DOI 10.1016/j.cma.2010.12.016
   Mayrhofer A, 2015, NUMER ALGORITHMS, V68, P15, DOI 10.1007/s11075-014-9835-y
   Mead-Hunter R, 2012, LANGMUIR, V28, P6731, DOI 10.1021/la300622h
   Monaghan JJ, 2011, EUR J MECH B-FLUID, V30, P360, DOI 10.1016/j.euromechflu.2011.04.002
   Monaghan J J, 2005, REP PROG PHYS, V68, P8
   MONAGHAN JJ, 1989, J COMPUT PHYS, V82, P1, DOI 10.1016/0021-9991(89)90032-6
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Monaghan JJ, 2000, J COMPUT PHYS, V159, P290, DOI 10.1006/jcph.2000.6439
   Morris J. P., 1996, THESIS
   PAPAGEORGIOU DT, 1995, PHYS FLUIDS, V7, P1529, DOI 10.1063/1.868540
   Qin M, 2016, IEEE T MULTIMEDIA, V18, P1283, DOI 10.1109/TMM.2016.2557729
   Randles PW, 1996, COMPUT METHOD APPL M, V139, P375, DOI 10.1016/S0045-7825(96)01090-0
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Sundaram H, 2002, IEEE T MULTIMEDIA, V4, P482, DOI 10.1109/TMM.2002.802017
   Tartakovsky AM, 2007, J COMPUT PHYS, V222, P654, DOI 10.1016/j.jcp.2006.08.013
   Wang ZL, 2017, IEEE T MULTIMEDIA, V19, P750, DOI 10.1109/TMM.2016.2636739
   Xu R, 2009, J COMPUT PHYS, V228, P6703, DOI 10.1016/j.jcp.2009.05.032
   Yuan ML, 2013, IEEE T MULTIMEDIA, V15, P1958, DOI 10.1109/TMM.2013.2280560
   Zheng CX, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531343
NR 54
TC 0
Z9 1
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2018
VL 20
IS 11
BP 3033
EP 3044
DI 10.1109/TMM.2018.2825888
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GX5WL
UT WOS:000447824800013
DA 2024-07-18
ER

PT J
AU Das Bhattacharjee, S
   Yuan, JS
   Huang, YC
   Meng, JJ
   Duan, LY
AF Das Bhattacharjee, Sreyasee
   Yuan, Junsong
   Huang, Yicheng
   Meng, Jingjing
   Duan, Lingyu
TI Query Adaptive Multiview Object Instance Search and Localization Using
   Sketches
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Sketch Based Search; object localization; object recognition; object
   retrieval; multi-view proposal selection; transductive clustering
ID IMAGE RETRIEVAL; RECOGNITION; HISTOGRAM
AB Sketch-based object search is a challenging problem mainly due to three difficulties: 1) how to match the primary sketch query with the colorful image; 2) how to locate the small object in a big image that is similar to the sketch query; and 3) given the large image database, how to ensure an efficient search scheme that is reasonably scalable. To address the above challenges, we propose leveraging object proposals for object search and localization. However, instead of purely relying on sketch features, we propose fully utilizing the appearance features of object proposals to resolve the ambiguities between the matching sketch query and object proposals. Our proposed query adaptive search is formulated as a subgraph selection problem, which can be solved by the maximum flow algorithm. By performing query expansion, it can accurately locate the small target objects in a cluttered background or densely drawn deformation-intensive cartoon (Manga like) images. To improve the computing efficiency of matching proposal candidates, the proposed Multi View Spatially Constrained Proposal Selection encodes each identified object proposal in terms of a small local basis of anchor objects. The results on benchmark datasets validate the advantages of utilizing both the sketch and appearance features for sketch-based search, while ensuring sufficient scalability at the same time.
C1 [Das Bhattacharjee, Sreyasee] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Yuan, Junsong; Meng, Jingjing] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
   [Huang, Yicheng; Duan, Lingyu] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100080, Peoples R China.
C3 University of North Carolina; University of North Carolina Charlotte;
   State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; Peking University
RP Das Bhattacharjee, S (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
EM sreya.iitm@gmail.com; jsyuan@ntu.edu.sg; anorange0409@gmail.com;
   jingjing.meng@ntu.edu.sg; lingyu@pku.edu.cn
RI Yuan, Junsong/R-4352-2019; Bhattacharjee, Sreyasee Das/AAU-2313-2020;
   meng, jingjing/HDM-6615-2022; Huang, Yicheng/AFV-4905-2022
OI meng, jingjing/0000-0002-8515-6893; Huang, Yicheng/0000-0002-0293-6844;
   Yuan, Junsong/0000-0002-7901-8793
FU National Natural Science Foundation of China [61661146005, U1611461];
   Key Research and Development Program of Beijing Municipal Science and
   Technology Commission [D171100003517002]; PKU-NTU Joint Research
   Institute through the Ng Teng Fong Charitable Foundation; University at
   Buffalo
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61661146005 and Grant U1611461, in part
   by the Key Research and Development Program of Beijing Municipal Science
   and Technology Commission (No. D171100003517002), and in part by the
   PKU-NTU Joint Research Institute through the Ng Teng Fong Charitable
   Foundation, and start-up grants of the University at Buffalo. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Tao Mei.
CR [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   Aramaki Y., 2014, P SIGGRAPH ACM T GRA, P2386
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Boykov Y, 2001, LECT NOTES COMPUT SC, V2134, P359
   Bozas K, 2015, INT CONF ACOUST SPEE, P1146, DOI 10.1109/ICASSP.2015.7178149
   Bui T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1012, DOI 10.1109/ICCVW.2015.133
   Cao XC, 2013, IEEE I CONF COMP VIS, P313, DOI 10.1109/ICCV.2013.46
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das Bhattacharjee S, 2016, IEEE T MULTIMEDIA, V18, P726, DOI 10.1109/TMM.2016.2532601
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Duan LY, 2016, IEEE T IMAGE PROCESS, V25, P179, DOI 10.1109/TIP.2015.2500034
   Duan LY, 2014, IEEE MULTIMEDIA, V21, P30, DOI 10.1109/MMUL.2013.66
   Eitz M., 2014, P SIGGRAPH ACM T GRA, V31
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Eitz Mathias., 2009, P 6 EUR S SKETCH BAS, P29
   Furuya Takahiko, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P37, DOI 10.1007/978-3-319-04114-8_4
   Guérin C, 2013, PROC INT CONF DOC, P1145, DOI 10.1109/ICDAR.2013.232
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoashi Keiichiro, 2011, P 19 ACM INT C MULT, P1489
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kopf J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366159
   Lin YL, 2013, IEEE I CONF COMP VIS, P3495, DOI 10.1109/ICCV.2013.434
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matsui Y, 2014, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2014.7025626
   Matsui Yusuke., 2015, CoRR
   Meng JJ, 2016, IEEE T MULTIMEDIA, V18, P116, DOI 10.1109/TMM.2015.2500734
   Pang XF, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1125, DOI 10.1145/2647868.2654990
   Paola G., 2014, SCI COMPUTING MATLAB
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Qian XM, 2016, IEEE T IMAGE PROCESS, V25, P195, DOI 10.1109/TIP.2015.2497145
   Qian Y., 2015, P BRIT MACH VIS C
   Qu Y., 2008, P SIGGRAPH ACM T GRA
   Rigaud C, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P267, DOI 10.1109/DAS.2014.70
   Rigaud C, 2013, PROC INT CONF DOC, P1240, DOI 10.1109/ICDAR.2013.251
   Saavedra J.M., 2015, P BRIT MACH VIS C 20
   Saavedra JM, 2017, MULTIMED TOOLS APPL, V76, P931, DOI 10.1007/s11042-015-3076-5
   Saavedra JM, 2014, IEEE IMAGE PROC, P2998, DOI 10.1109/ICIP.2014.7025606
   Saavedra JM, 2014, MULTIMED TOOLS APPL, V73, P2033, DOI 10.1007/s11042-013-1689-0
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sousa P, 2010, J VISUAL LANG COMPUT, V21, P69, DOI 10.1016/j.jvlc.2009.12.001
   Sun Xinghai., 2013, Proceedings of the International Conference On Multimedia (MM), P233
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P858, DOI 10.1109/TMM.2012.2187181
   Wang S, 2015, IEEE T MULTIMEDIA, V17, P1045, DOI 10.1109/TMM.2015.2431492
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yu T, 2017, AAAI CONF ARTIF INTE, P4320
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou C. J., 2007, P 24 INT C MACH LEAR, P1159, DOI DOI 10.1145/1273496.1273642
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 61
TC 10
Z9 11
U1 0
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2018
VL 20
IS 10
SI SI
BP 2761
EP 2773
DI 10.1109/TMM.2018.2814338
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GT9YH
UT WOS:000444903000018
DA 2024-07-18
ER

PT J
AU Zhang, F
   Moss, FM
   Baddeley, R
   Bull, DR
AF Zhang, Fan
   Moss, Felix Mercer
   Baddeley, Roland
   Bull, David R.
TI BVI-HD: A Video Quality Database for HEVC Compressed and Texture
   Synthesized Content
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Subjective quality assessment; BVI-HD video quality database; visual
   perception; HEVC; synthesis-based compression
ID STRUCTURAL SIMILARITY; CODING HEVC; IMAGES
AB This paper introduces a new high-definition video quality database, referred to as BVI-HD, which contains 32 reference and 384 distorted video sequences plus subjective scores. The reference material in this database was carefully selected to optimize the coverage range and distribution uniformity of five low-level video features, while the included 12 distortions, using both original high efficiency video coding (HEVC) and HEVC with synthesis mode, represent state-of-the-art approaches to compression. The range of quantization parameters included in the database for HEVC compression was determined by a subjective study, the results of which indicate that a wider range of QP values should be used than the current recommendation. The subjective opinion scores for all 384 distorted videos were collected from a total of 86 subjects, using a double stimulus test methodology. Based on these results, we compare the subjective quality between HEVC and synthesised content, and evaluate the performance of nine state-of-the-art, full-reference objective quality metrics. This database has now been made available online, representing a valuable resource to those concerned with compression performance evaluation and objective video quality assessment.
C1 [Zhang, Fan; Moss, Felix Mercer; Baddeley, Roland; Bull, David R.] Univ Bristol, Bristol Vis Inst, Bristol BS8 1TH, Avon, England.
C3 University of Bristol
RP Zhang, F (corresponding author), Univ Bristol, Bristol Vis Inst, Bristol BS8 1TH, Avon, England.
EM fan.zhang@bristol.ac.uk; f.mercermoss@bristol.ac.uk;
   roland.baddeley@bristol.ac.uk; dave.bull@bristol.ac.uk
OI Zhang, Fan/0000-0001-6623-9936
FU EPSRC [EP/J019291/1, EP/M000885/1]; BBC RD; EPSRC [EP/J019291/1,
   EP/M000885/1] Funding Source: UKRI
FX This work was supported in part by EPSRC under Grants EP/J019291/1 and
   EP/M000885/1 and in part by BBC R&D. The associate editor coordinating
   the review of this manuscript and approving it for publication was Prof.
   Yonghong Tian.
CR Afonso M., 2016, P PICT COD S
   [Anonymous], 2014, NONPARAMETRIC STAT S
   [Anonymous], 2007, BT1788 ITUR STAND
   [Anonymous], 2010, Tech. Rep.
   [Anonymous], 2002, BT50011 ITUR STAND
   [Anonymous], 2012, BT2020 ITUR
   [Anonymous], 2008, INT WORKSH IM MED QU
   Apostolopoulos JG, 2012, P IEEE, V100, P974, DOI 10.1109/JPROC.2011.2182069
   Armstrong M., 2008, BBC RES WHITE PAPER, P169
   Atkins R., 2009, U.S. Patent App, Patent No. [12/491 857, 12491857]
   Ballé J, 2011, IEEE J-STSP, V5, P1353, DOI 10.1109/JSTSP.2011.2166246
   Bosch M, 2011, IEEE J-STSP, V5, P1366, DOI 10.1109/JSTSP.2011.2164779
   Bossen F., 2013, JCTVCL1100ITUT ISOIE
   Bull DR, 2014, COMMUNICATING PICTURES: A COURSE IN IMAGE AND VIDEO CODING, P1
   Butterworth B., 2013, BBC INTERNET BLOG
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen Y, 2016, IEEE T MULTIMEDIA, V18, P576, DOI 10.1109/TMM.2016.2525010
   Cheon M., IEEE T CIRCUITS SYST
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cutting JE, 2011, I-PERCEPTION, V2, P569, DOI 10.1068/i0441aap
   Dong YY, 2016, IEEE T MULTIMEDIA, V18, P549, DOI 10.1109/TMM.2016.2522639
   Fröhlich P, 2012, INT WORK QUAL MULTIM, P242, DOI 10.1109/QoMEX.2012.6263851
   Gescheider G. A., 2013, Psychophysics: the fundamentals
   Hadizadeh H, 2018, IEEE T MULTIMEDIA, V20, P392, DOI 10.1109/TMM.2017.2740023
   ITU-T-RECOMMENDATION, 1999, SERIES P TELEPHONE T, P910
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Li Z., 2016, NETFLIX TECHNOL BLOG
   Mackin A, 2015, IEEE IMAGE PROC, P3407, DOI 10.1109/ICIP.2015.7351436
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Moss FJM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047870
   Moss FM, 2016, SIGNAL PROCESS-IMAGE, V48, P38, DOI 10.1016/j.image.2016.08.005
   Moss FM, 2016, IEEE T CIRC SYST VID, V26, P1977, DOI 10.1109/TCSVT.2015.2461971
   MOSS FM, 2016, P IEEE INT C IM PROC, P2425
   Ndjiki-Nya P, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1447
   Ou YF, 2008, IEEE IMAGE PROC, P689, DOI 10.1109/ICIP.2008.4711848
   Papadopoulos MA, 2015, IEEE IMAGE PROC, P2781, DOI 10.1109/ICIP.2015.7351309
   Pinson MH, 2013, IEEE SIGNAL PROC MAG, V30, P171, DOI 10.1109/MSP.2013.2258265
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Ribeiro FML, 2018, IEEE T MULTIMEDIA, V20, P1, DOI 10.1109/TMM.2017.2714425
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sharman K., 2016, JCTVCX1100ITUT ISOIE
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Silva AF, 2016, IEEE T MULTIMEDIA, V18, P2446, DOI 10.1109/TMM.2016.2601027
   Simone F. D., 2009, EPFL POLIMI VIDEO QU
   Sullivan G., 2017, JVETG1002 ITUT VCEG
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Thakur US, 2015, INT CONF SYST SIGNAL, P204, DOI 10.1109/IWSSIP.2015.7314212
   Tokimoto Toyotaro, 2013, 2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE), P83, DOI 10.1109/GCCE.2013.6664933
   Upenik E., 2017, P 9 INT C QUAL MULT
   Video Quality Experts Group, 2000, COM980E VQEG
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Vu PV, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013016
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Yeh CH, 2015, IEEE T MULTIMEDIA, V17, P1508, DOI 10.1109/TMM.2015.2449659
   Zhang F., 2009, IVP Subjective Quality Video Database
   Zhang F., 2017, P IEEE INT C IM PROC, P300
   Zhang F, 2016, IEEE T CIRC SYST VID, V26, P1017, DOI 10.1109/TCSVT.2015.2428551
   Zhang F, 2013, IEEE IMAGE PROC, P39, DOI 10.1109/ICIP.2013.6738009
   Zhang F, 2011, IEEE J-STSP, V5, P1378, DOI 10.1109/JSTSP.2011.2165201
   Zhu YL, 2016, AER ADV ENG RES, V103, P1, DOI 10.1109/INFOCOM.2006.322
NR 66
TC 33
Z9 34
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2018
VL 20
IS 10
SI SI
BP 2620
EP 2630
DI 10.1109/TMM.2018.2817070
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GT9YH
UT WOS:000444903000007
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Fan, BJ
   Cong, Y
   Tang, YD
AF Fan, Baojie
   Cong, Yang
   Tang, Yandong
TI Dual Graph Regularized Discriminative Multitask Tracker
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Multi-task tracker; discriminative low rank learning; geometric
   structure information; graph regularization; collaborate metric
ID OBJECT TRACKING; VISUAL TRACKING; LOW-RANK; REPRESENTATION
AB Multitask and low-rank learning methods have attracted increasing attention for visual tracking. However, most trackers only focus on learning appearance subspace basis or the sparse low rankness of representation and, thus, do not make full use of the structure information among and inside target candidates (or samples). In this paper, we propose a dual-graph regularized discriminative low-rank learning for a multitask tracker, which integrates the discriminative subspace and intrinsic geometric structures among tasks. By constructing dual-graph regulations from two views of multitask observation, the developed model not only exploits the intrinsic relationship among tasks, and preserves the spatial layout structure among the local patches inside each candidate, but also learns the salient features of the target samples. This operation has the benefit of having good target representation and improving the performance of the tracker. Moreover, our developed tracker is a collaborate multitask tracking model and learns the discriminative subspace with adaptive dimension and optimal classifier simultaneously. Then, a collaborate metric is developed to find the best candidate, which integrates both classification reliability and representation accuracy. Encouraging experimental results on a large set of public video sequences justify that our tracker performs favorably against many other state-of-the-art trackers.
C1 [Fan, Baojie] Nanjing Univ Posts & Telecommun, Nanjing 210023, Jiangsu, Peoples R China.
   [Cong, Yang; Tang, Yandong] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Beijing 100049, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Chinese Academy of
   Sciences; Shenyang Institute of Automation, CAS
RP Fan, BJ (corresponding author), Nanjing Univ Posts & Telecommun, Nanjing 210023, Jiangsu, Peoples R China.
EM jobfbj@gmail.com; congyang@sia.cn; ytang@sia.cn
OI Tang, Yandong/0000-0003-3805-7654
FU China Postdoctoral Science Foundation [2015M571785, 2016T90484]; Jiangsu
   Postdoctoral Science Foundation [1402085C]; Foundation for the Talent of
   Nanjing University of Tele. and Com. [NY215148, NY217061]; National
   Nature Science Foundation [61722311, U1613214, 51775284]; Natural
   Science Foundation of Jiangsu Province [BK20151505]
FX This work was supported in part by the China Postdoctoral Science
   Foundation under Grant 2015M571785 and Grant 2016T90484, in part by the
   Jiangsu Postdoctoral Science Foundation under Grant 1402085C, in part by
   the Foundation for the Talent of Nanjing University of Tele. and Com.
   under Grant NY215148 and Grant NY217061, in part by the National Nature
   Science Foundation under Grant 61722311, Grant U1613214, and Grant
   51775284, and in part by the Natural Science Foundation of Jiangsu
   Province under Grant BK20151505.
CR [Anonymous], 2015, MACH LEARN, DOI DOI 10.1007/s10994-014-5469-5
   [Anonymous], 2016, CVPR
   Bai YC, 2014, IEEE SIGNAL PROC LET, V21, P909, DOI 10.1109/LSP.2014.2320291
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Danelljan M., 2016, P IEEE C COMP VIS PA, P21
   Danelljan M., 2014, P BRIT MACH VIS C
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fan BJ, 2014, PATTERN RECOGN, V47, P3828, DOI 10.1016/j.patcog.2014.06.015
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Liu RS, 2012, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2012.6247726
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mei X, 2015, IEEE T NEUR NET LEAR, V26, P2874, DOI 10.1109/TNNLS.2015.2399233
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sui Y, 2015, IEEE I CONF COMP VIS, P3002, DOI 10.1109/ICCV.2015.344
   Sui Y, 2015, IEEE T IMAGE PROCESS, V24, P4686, DOI 10.1109/TIP.2015.2462076
   Tao M, 2011, SIAM J OPTIMIZ, V21, P57, DOI 10.1137/100781894
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang D, 2012, IEEE SIGNAL PROC LET, V19, P711, DOI 10.1109/LSP.2012.2215320
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xie Y, 2014, IEEE T CYBERNETICS, V44, P539, DOI 10.1109/TCYB.2013.2259230
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Yin M, 2015, IEEE T IMAGE PROCESS, V24, P4918, DOI 10.1109/TIP.2015.2472277
   Yuan Y, 2015, IEEE T MULTIMEDIA, V17, P1125, DOI 10.1109/TMM.2015.2440996
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang SL, 2015, PATTERN RECOGN, V48, P3881, DOI 10.1016/j.patcog.2015.06.005
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhang TZ, 2016, IEEE T CYBERNETICS, V46, P51, DOI 10.1109/TCYB.2015.2393307
   Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhao LM, 2015, AAAI CONF ARTIF INTE, P3864
   Zheng YG, 2013, NEUROCOMPUTING, V122, P398, DOI 10.1016/j.neucom.2013.06.013
   Zhou X, 2016, IEEE T CYBERNETICS, V46, P1498, DOI 10.1109/TCYB.2015.2451100
   Zhuang LS, 2015, IEEE T IMAGE PROCESS, V24, P3717, DOI 10.1109/TIP.2015.2441632
NR 51
TC 4
Z9 4
U1 0
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2018
VL 20
IS 9
BP 2303
EP 2315
DI 10.1109/TMM.2018.2804762
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GR1ZX
UT WOS:000442358200006
DA 2024-07-18
ER

PT J
AU Fan, YY
   Liu, S
   Li, B
   Guo, Z
   Samal, A
   Wan, J
   Li, SZ
AF Fan, Yang-Yu
   Liu, Shu
   Li, Bo
   Guo, Zhe
   Samal, Ashok
   Wan, Jun
   Li, Stan Z.
TI Label Distribution-Based Facial Attractiveness Computation by Deep
   Residual Learning
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Facial attractiveness computation; deep residual network; label
   distribution; feature fusion; SCUT-FBP
ID BEAUTY; PREDICTION
AB Two key challenges lie in the facial attractiveness computation research: the lack of discriminative face representations, and the scarcity of sufficient and complete training data. Motivated by recent promising work in face recognition using deep neural networks to learn effective features, the first challenge is expected to be addressed from a deep learning point of view. A very deep residual network is utilized to enable automatic learning of hierarchical aesthetics representation. The inspiration to deal with the second challenge comes from the natural representation of the training data, where each training face can be associated with a label (score) distribution given by human raters rather than a single label (average score). This paper, therefore, recasts facial attractiveness computation as a label distribution learning problem. Integrating these two ideas, an end-to-end attractiveness learning framework is established. We also perform feature-level fusion by incorporating the low-level geometric features to further improve the computational performance. Extensive experiments are conducted on a standard benchmark, the SCUT-FBP dataset, where our approach shows significant advantages over the other state-of-the-art work.
C1 [Fan, Yang-Yu; Liu, Shu; Li, Bo; Guo, Zhe] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Samal, Ashok] Univ Nebraska, Dept Comp Sci & Engn, Lincoln, NE 68588 USA.
   [Wan, Jun; Li, Stan Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, Beijing 100190, Peoples R China.
   [Wan, Jun; Li, Stan Z.] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
C3 Northwestern Polytechnical University; University of Nebraska System;
   University of Nebraska Lincoln; Chinese Academy of Sciences; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Liu, S (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
EM fan_yangyu@nwpm.edu.cn; liushu0922@mail.nwpu.edu.cn; libo.npu@gmail.com;
   guozhe@nwpu.edu.cn; samal@cse.unl.edu; jun.wan@nlpr.ia.ac.cn;
   szli@nlpr.ia.ac.cn
RI Li, Ye/JBS-2949-2023; Li, SY/JPK-3839-2023; wu, jd/IST-2336-2023; Li,
   bo/IWL-9318-2023
OI Li, SY/0009-0000-9254-7115; wan, jun/0000-0002-4735-2885; Li,
   Bo/0009-0003-4088-1578
FU National Natural Science Foundation of China [61402371, 61461025,
   61702462, 61502491]; Science and Technology Innovation Engineering Plan
   in Shaanxi Province of China [2013SZS15-K02]; Natural Science Basic
   Research Plan in Shaanxi Province of China [2017JM6008]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61402371, Grant 61461025, Grant
   61702462, and Grant 61502491, in part by the Science and Technology
   Innovation Engineering Plan in Shaanxi Province of China under Grant
   2013SZS15-K02, and in part by the Natural Science Basic Research Plan in
   Shaanxi Province of China under Grant 2017JM6008. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Hatice Gunes.
CR [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], 2006, P 19 INT C NEUR INF
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2008, 2008 8 IEEE INT C
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], C P IEEE INT C SYST
   Bashour M, 2006, PLAST RECONSTR SURG, V118, P741, DOI 10.1097/01.prs.0000233051.61512.65
   Bottino Andrea, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P59, DOI 10.1007/978-3-642-33275-3_7
   Calder A., 2011, Oxford handbook of face perception
   Chen FM, 2018, IEEE T AFFECT COMPUT, V9, P205, DOI 10.1109/TAFFC.2016.2599534
   Davis BC, 2008, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2008.4711703
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Efroymson M.A., 1960, MATH METHODS DIGITAL, P191
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   Fan JT, 2012, PATTERN RECOGN, V45, P2326, DOI 10.1016/j.patcog.2011.11.024
   Gan JY, 2014, NEUROCOMPUTING, V144, P295, DOI 10.1016/j.neucom.2014.05.028
   Geng X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3511
   Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Gray D, 2010, LECT NOTES COMPUT SC, V6316, P434, DOI 10.1007/978-3-642-15567-3_32
   Gunes H, 2006, INT J HUM-COMPUT ST, V64, P1184, DOI 10.1016/j.ijhcs.2006.07.004
   Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laurentini A, 2014, COMPUT VIS IMAGE UND, V125, P184, DOI 10.1016/j.cviu.2014.04.006
   Leyvand T., 2008, ACM T GRAPHICS SIGGR, V27, P55
   Liu LQ, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2659234
   Liu S, 2017, NEUROCOMPUTING, V238, P168, DOI 10.1016/j.neucom.2017.01.050
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P16633, DOI 10.1007/s11042-016-3830-3
   Liu S, 2015, LECT NOTES COMPUT SC, V9242, P564, DOI 10.1007/978-3-319-23989-7_57
   Lu X, 2015, IEEE T MULTIMEDIA, V17, P2021, DOI 10.1109/TMM.2015.2477040
   Melacci S, 2010, PATTERN ANAL APPL, V13, P289, DOI 10.1007/s10044-009-0155-0
   Mu YD, 2013, NEUROCOMPUTING, V99, P59, DOI 10.1016/j.neucom.2012.06.020
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Rothe R, 2016, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2016.599
   Schmid K, 2008, PATTERN RECOGN, V41, P2710, DOI 10.1016/j.patcog.2007.11.022
   Tang XO, 2013, IEEE T MULTIMEDIA, V15, P1930, DOI 10.1109/TMM.2013.2269899
   Wang SY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P805, DOI 10.1145/2647868.2654986
   Xie D., 2015, ARXIV PREPRINT ARXIV
   Xie DR, 2015, IEEE SYS MAN CYBERN, P1821, DOI 10.1109/SMC.2015.319
   Yan HB, 2014, NEUROCOMPUTING, V129, P334, DOI 10.1016/j.neucom.2013.09.025
   Zhang D., 2016, COMPUTER MODELS FACI, V4
   Zhang ZX, 2015, NEUROCOMPUTING, V166, P151, DOI 10.1016/j.neucom.2015.03.083
NR 44
TC 39
Z9 39
U1 2
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2018
VL 20
IS 8
BP 2196
EP 2208
DI 10.1109/TMM.2017.2780762
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GN8BR
UT WOS:000439378600022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Stankiewicz, O
   Domanski, M
   Dziembowski, A
   Grzelka, A
   Mieloch, D
   Samelak, J
AF Stankiewicz, Olgierd
   Domanski, Marek
   Dziembowski, Adrian
   Grzelka, Adam
   Mieloch, Dawid
   Samelak, Jaroslaw
TI A Free-Viewpoint Television System for Horizontal Virtual Navigation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Free-viewpoint television; multiview video; view synthesis; virtual
   navigation
ID OPTIMAL CAMERA PLACEMENT; MULTIVIEW VIDEO
AB Free-viewpoint television (FTV) and virtual navigation appear to he hot research topics. In this paper, the authors study the practical development of free-viewpoint television systems that provide the functionality of virtual horizontal navigation around real scenes. The considerations are focused on practical systems that use purely optical depth estimation and might be employed in the next few years. The architectures of such systems are discussed in detail, including acquisition, preprocessing, depth estimation, compression, and presentation. In particular, the optimization of camera locations is discussed, and it is shown that video acquisition using camera pairs is advantageous for scenes with a substantial amount of occlusions. The theoretical considerations are supported by experimental results obtained for standard test multiview video sequences. Furthermore, the paper describes FTV video acquisition systems that consist of modules with pairs of cameras. The modules are sparsely located in arbitrary positions around a scene. Each camera module is equivalent to a video camera with a depth sensor. The hardware requirements, video processing algorithms, and experimental results are reported. In particular, for such systems, a compression technique is discussed that is more efficient than the new three-dimensional HEVC technology. The paper also describes new test video sequences that are obtained from the camera pairs sparsely distributed around scenes.
C1 [Stankiewicz, Olgierd; Domanski, Marek; Dziembowski, Adrian; Grzelka, Adam; Mieloch, Dawid; Samelak, Jaroslaw] Poznan Univ Tech, Chair Multimedia Telecommun & Microelect, PL-60965 Poznan, Poland.
C3 Poznan University of Technology
RP Domanski, M (corresponding author), Poznan Univ Tech, Chair Multimedia Telecommun & Microelect, PL-60965 Poznan, Poland.
EM ostank@multimedia.edu.pl; marek.domanski@put.poznan.pl;
   adziembowski@multimedia.edu.pl; agrzelka@multimedia.edu.pl;
   dmieloch@multimedia.edu; jsamelak@multimedia.edu.pl
RI Stankiewicz, Olgierd/A-4849-2016; Domanski, Marek/H-1211-2019;
   Dziembowski, Adrian/A-5530-2016; Mieloch, Dawid/J-1908-2015; Domanski,
   Marek/G-2075-2014
OI Domanski, Marek/0000-0002-9381-0293; Dziembowski,
   Adrian/0000-0001-7426-3362; Mieloch, Dawid/0000-0003-0709-812X; Grzelka,
   Adam/0000-0002-9122-5920
FU National Centre for Research and Development, Poland
   [TANGO1/266710/NCBR/2015]
FX This work was supported by the National Centre for Research and
   Development, Poland, under Project no. TANGO1/266710/NCBR/2015. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Prof. Winston Hsu.
CR Akin A, 2015, IEEE INT SYMP CIRC S, P2525, DOI 10.1109/ISCAS.2015.7169199
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2007, 154443 ISOIEC IS
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2015, 230082 ISOIEC IS
   [Anonymous], 2015, JTC1SC29WG11 ISOIEC
   [Anonymous], 2014, 1499610 ISOIEC IS
   Bjontegaard G., 2001, VCEGM33
   Bondarev E, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P687, DOI 10.1109/ICCE.2011.5722810
   Chen X, 2008, MACH VISION APPL, V19, P217, DOI 10.1007/s00138-007-0094-y
   Do L., 2011, 2011 IEEE INT S POW, P1
   Domanski M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P10, DOI 10.1109/PCS.2015.7170037
   Domanski M., 2014, P 3DTV C TRUE VIS CA, P1
   Domanski M., 2015, ISO IEC JTC1 SC29 WG
   Domanski M, 2016, IEEE INT CON MULTI, DOI 10.1109/ICME.2016.7552993
   Domanski M, 2016, INT CONF SIGNALS ELE, P118, DOI 10.1109/ICSES.2016.7593833
   Dziembowski A, 2016, PICT COD SYMP, DOI 10.1109/PCS.2016.7906380
   Fujihashi T, 2014, IEEE T MULTIMEDIA, V16, P228, DOI 10.1109/TMM.2013.2281588
   Gargallo P, 2007, IEEE I CONF COMP VIS, P1364
   Goorts P., 2014, JTC1SC29WG11 ISOIEC
   Goorts P, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P378
   Grzelka A., 2016, JTC1SC29WG11 ISOIEC
   Jerald J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P211, DOI 10.1109/VR.2009.4811025
   Jorissen L, 2015, P 3DTV C TRUE VIS CA, P1
   Jorissen L., 2014, P 3DTV C TRUE VIS CA, P1
   Kamarainen T., 2017, Proceedings of the 18th International Workshop on Mobile Computing Systems and Applications, P61, DOI DOI 10.1145/3032970.3032985
   Kim J.-W., 2014, Vehicular Technology Conference (VTC Spring), 2014 IEEE 79th, P1, DOI DOI 10.1109/CICC.2014.6946010
   Ku-Chu Wei, 2013, 2013 IEEE Third International Conference on Consumer Electronics - Berlin (ICCE-Berlin). Proceedings, P220, DOI 10.1109/ICCE-Berlin.2013.6698017
   Lafruit G., 2016, ELECT IMAGING, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.5.SDA-426
   Lee CC, 2015, APSIPA TRANS SIGNAL, V4, DOI 10.1017/ATSIP.2015.18
   Maugey T, 2013, IEEE T IMAGE PROCESS, V22, P3459, DOI 10.1109/TIP.2013.2270183
   Mieloch D, 2017, IEEE INT CON MULTI, P217, DOI 10.1109/ICME.2017.8019532
   Miller Gregor, 2006, 3rd European Conference on Visual Media Production (CVMP 2006). Part of the 2nd Multimedia Conference 2006, P153, DOI 10.1049/cp:20061937
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Muller K., 2014, 3 ITUT SG 16
   Olague G, 2002, PATTERN RECOGN, V35, P927, DOI 10.1016/S0031-3203(01)00076-0
   Qian N. Q., 2015, P 2015 INT C 3D IM L, P1
   Rahimian P, 2017, IEEE T VIS COMPUT GR, V23, P1209, DOI 10.1109/TVCG.2016.2637334
   Sandberg D., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P158, DOI 10.1109/DICTA.2011.33
   Senoh T., 2014, JTC1SC29WG11 ISOIEC
   Senoh T., 2015, JTC1SC29WG11 ISOIEC
   Shao F, 2014, IEEE J EM SEL TOP C, V4, P106, DOI 10.1109/JETCAS.2014.2298314
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Smolic A., 2005, 2005 13th European Signal Processing Conference, P1, DOI 10.1109/PTC.2005.4524468
   Stamos I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1435, DOI 10.1109/ROBOT.2000.844799
   Stankiewicz O., 2013, JTC1SC29WG11 ISOIEC
   Stankowski J, 2015, 3DTV CONF, DOI 10.1109/3DTV.2015.7169371
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sun ZZ, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY, P324, DOI 10.1109/CyberC.2015.97
   Tanimoto M., 2013, ISO IEC JTC1 SC29 WG
   Tanimoto M., 2008, JTC1SC29WG11 ISOIEC
   Tanimoto M., 2002, JTC1SC29WG11 ISOIEC
   Tanimoto M, 2012, P IEEE, V100, P905, DOI 10.1109/JPROC.2011.2182101
   Tanimoto M, 2009, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2009.5202803
   Toni L, 2015, IEEE IMAGE PROC, P4486, DOI 10.1109/ICIP.2015.7351655
   Wang RG, 2017, IEEE T MULTIMEDIA, V19, P1392, DOI 10.1109/TMM.2017.2654120
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wegner K., 2014, JTC1SC29WG11 ISOIEC
   Wegner K., 2015, JTC1SC29WG11 ISOIEC
   Wu PF, 2017, IEEE T MULTIMEDIA, V19, P266, DOI 10.1109/TMM.2016.2612761
   Würmlin S, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P325, DOI 10.1109/PCCGA.2002.1167876
   Xiu XY, 2012, IEEE T MULTIMEDIA, V14, P1109, DOI 10.1109/TMM.2012.2191267
   Yao C, 2016, IEEE T MULTIMEDIA, V18, P2015, DOI 10.1109/TMM.2016.2594145
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   Zilly F, 2014, J VIS COMMUN IMAGE R, V25, P632, DOI 10.1016/j.jvcir.2013.07.002
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 67
TC 51
Z9 53
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2018
VL 20
IS 8
BP 2182
EP 2195
DI 10.1109/TMM.2018.2790162
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GN8BR
UT WOS:000439378600021
DA 2024-07-18
ER

PT J
AU Zhang, L
   Wang, F
   Liu, JC
AF Zhang, Lei
   Wang, Feng
   Liu, Jiangchuan
TI Mobile Instant Video Clip Sharing With Screen Scrolling: Measurement and
   Enhancement
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Mobile; instant video; efficiency
ID DELIVERY
AB Today's multimedia content generation and sharing have been dramatically boosted by the deep penetration of broadband wireless accesses and the much improved processing power of smart mobile terminals. Mobile users can now instantly capture and share short video clips (usually of several seconds) anywhere and anytime, and consume them with convenient touch screen operations. The instant video clip sharing has emerged as a mainstream application; such pioneers as Twitter's Vine, Miaopai, Instagram, and Snapchat have seen great acceptance, particularly by the youth community. In this paper, we present an initial study on instant video clip sharing. Taking Twitter's Vine as a representative, we systematically investigate its distinct mobile interface, service framework, and user watching behaviors, revealing how this mainstream multimedia service type differentiates from its traditional counterparts. Our trace measurement and analysis demonstrate that instant mobile video clips have a much shorter lifespan and highly skewed popularity that quickly decays over time. This is further aggravated by the unique screen scrolling operation for video browsing. As such, the download-and-watch scheduling used by existing platforms can hardly achieve quality user experience and cast efficiency. We closely investigate and model the input user gestures for scrolling, including drag and fling, and analyze the scheduling policy, partitioning it into prefetching scheduling and watch-time download scheduling. We develop effective solutions toward both subproblems as well as their integration with screen scrolling. The superiority of our enhancement is demonstrated by extensive trace-driven evaluation.
C1 [Zhang, Lei; Liu, Jiangchuan] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   [Wang, Feng] Univ Mississippi, Dept Comp & Informat Sci, University, MS 38677 USA.
C3 Simon Fraser University; University of Mississippi
RP Liu, JC (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
EM lza70@cs.sfu.ca; fwang@cs.olemiss.edu; jcliu@cs.sfu.ca
FU Qatar National Research Fund (a member of Qatar Foundation) under NPRP
   [8-519-1-108]; Natural Sciences and Engineering Research Council of
   Canada
FX This work was supported in part by the Qatar National Research Fund (a
   member of Qatar Foundation) under NPRP Grant [8-519-1-108] and in part
   by the Natural Sciences and Engineering Research Council of Canada. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Prof. Balakrishnan Prabhakaran.
CR [Anonymous], 2011, P 21 INT WORKSH NETW, DOI DOI 10.1145/1989240.1989248
   Balasubramanian N, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P280
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Cheng X, 2013, IEEE INFOCOM SER, P45
   Cheng X, 2013, IEEE T MULTIMEDIA, V15, P1184, DOI 10.1109/TMM.2013.2265531
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   De Vleeschauwer D, 2013, IEEE INFOCOM SER, P989
   Gautam N., 2013, PROC ACM WORKSHOP MO, P7
   He DL, 2017, IEEE T MULTIMEDIA, V19, P1894, DOI 10.1109/TMM.2017.2686703
   Hong Lu, 2010, Proc. of the 8th ACM Conference on Embedded Networked Sensor Systems, P71, DOI DOI 10.1145/1869983.1869992
   Huang J., 2012, P 10 INT C MOB SYST, P225, DOI DOI 10.1145/2307636.2307658
   Jie Xu, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P2308, DOI 10.1109/INFOCOM.2015.7218618
   Li Haitao., 2012, P 22 INT WORKSHOP NE, P83
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Nath Suman., 2012, P 10 INT C MOBILE SY, P29, DOI DOI 10.1145/2307636.2307640
   Panta RK, 2015, IEEE INTERNET COMPUT, V19, P64, DOI 10.1109/MIC.2015.63
   Rodrigues Tiago., 2011, Proceedings of the 2011 ACM Special Interest Group on Data Communication Conference on Internet Measurement
   Roy A, 2015, IEEE COMMUN MAG, V53, P136, DOI 10.1109/MCOM.2015.7295475
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Shamma D. A., 2011, INT AAAI C WEBL SOC, P618, DOI DOI 10.1145/2527031.2527052
   Sun LF, 2017, IEEE T MULTIMEDIA, V19, P609, DOI 10.1109/TMM.2016.2635589
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Trestian R, 2012, IEEE IFIP NETW OPER, P444, DOI 10.1109/NOMS.2012.6211929
   Wang XF, 2013, IEEE T MULTIMEDIA, V15, P811, DOI 10.1109/TMM.2013.2239630
   Wang Z., 2016, IEEE T MOBILE COMPUT, V16, P1107
   Wang Z, 2016, IEEE T PARALL DISTR, V27, P735, DOI 10.1109/TPDS.2015.2414941
   Wang Z, 2012, IEEE INFOCOM SER, P2901, DOI 10.1109/INFCOM.2012.6195726
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   White RW, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P363, DOI 10.1145/1571941.1572005
   Xu YL, 2017, IEEE T MULTIMEDIA, V19, P2597, DOI 10.1109/TMM.2017.2700208
   Yang J., 2011, P 4 ACM INT C WEB SE, P177, DOI DOI 10.1145/1935826.1935863
   Yarosh S, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1423, DOI 10.1145/2818048.2819961
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P104, DOI 10.1109/TMM.2014.2371240
   Zhang L, 2016, Proceedings of the Eleventh European Conference on Computer Systems, P1, DOI DOI 10.1109/BMSB.2016.7521908
NR 35
TC 3
Z9 5
U1 0
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2018
VL 20
IS 8
BP 2022
EP 2034
DI 10.1109/TMM.2018.2794760
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GN8BR
UT WOS:000439378600009
DA 2024-07-18
ER

PT J
AU Abdulnabi, AH
   Shuai, B
   Zuo, Z
   Chau, LP
   Wang, G
AF Abdulnabi, Abrar H.
   Shuai, Bing
   Zuo, Zhen
   Chau, Lap-Pui
   Wang, Gang
TI Multimodal Recurrent Neural Networks With Information Transfer Layers
   for Indoor Scene Labeling
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Multimodal learning; RNNs; CNNs; RGB-D scene labeling
ID PHONEME CLASSIFICATION; BIDIRECTIONAL LSTM; TRACKING
AB This paper proposes a new method called multimodal recurrent neural networks (RNNs) for RGB-D scene semantic segmentation. It is optimized to classify image pixels given two input sources: RGB color channels and depth maps. It simultaneously performs training of two RNNs that are crossly connected through information transfer layers, which are learnt to adaptively extract relevant cross-modality features. Each RNN model learns its representations from its own previous hidden states and transferred patterns from the other RNNs previous hidden states; thus, both model-specific and cross-modality features are retained. We exploit the structure of quad-directional 2D-RNNs to model the short- and long-range contextual information in the 2D input image. We carefully designed various baselines to efficiently examine our proposed model structure. We test our multimodal RNNs method on popular RGB-D benchmarks and show how it outperforms previous methods significantly and achieves competitive results with other state-of-the-art works.
C1 [Abdulnabi, Abrar H.; Shuai, Bing; Zuo, Zhen] Nanyang Technol Univ, Sch Elect & Elect Engn, Rapid Rich Object Search ROSE Lab, Singapore 639798, Singapore.
   [Abdulnabi, Abrar H.] Illinois Singapore Pte Ltd, Adv Digital Sci Ctr, Singapore 138632, Singapore.
   [Chau, Lap-Pui; Wang, Gang] Nanyang Technol Univ, Dept Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Abdulnabi, AH (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Rapid Rich Object Search ROSE Lab, Singapore 639798, Singapore.
EM abrarham001@ntu.edu.sg; beinshuai@gmail.com; zzhen1990@gmail.com;
   elpchau@ntu.edu.sg; wanggang@ntu.edu.sg
RI Chau, Lap-Pui/A-5149-2011; ARSLAN, Okan/AAA-3232-2020
OI Chau, Lap-Pui/0000-0003-4932-0593; 
FU Singapore Ministry of Education Tier 2 [ARC28/14]; Singapore Agency for
   Science, Technology and Research (A*STAR); Science and Engineering
   Research Council [PSF1321202099]; A*STAR; National Research Foundation,
   Singapore, under its Interactive & Digital Media Strategic Research
   Programme
FX This work was supported in part by Singapore Ministry of Education Tier
   2 ARC28/14, in part by Singapore Agency for Science, Technology and
   Research (A*STAR), in part by the Science and Engineering Research
   Council PSF1321202099, and in part by the research grant for ADSC from
   A*STAR. The Rapid-Rich Object Search Laboratory was supported by the
   National Research Foundation, Singapore, under its Interactive & Digital
   Media Strategic Research Programme.
CR Abdulnabi AH, 2017, PROC CVPR IEEE, P6278, DOI 10.1109/CVPR.2017.665
   [Anonymous], P 31 INT C MACH LEAR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2012, Guide to OCR for Arabic Scripts
   [Anonymous], 2011, P ICML
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], ARXIV170605274
   [Anonymous], 2014, Advances in neural information processing systems
   [Anonymous], 2015, ARXIV14091556V6
   [Anonymous], 2012, ARXIV E PRINTS
   [Anonymous], 2013, P 30 INT C MACH LEAR
   [Anonymous], 2016, PROC 4 INT C LEARN R
   [Anonymous], ARXIV170705537
   Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349
   Byeon W, 2015, PROC CVPR IEEE, P3547, DOI 10.1109/CVPR.2015.7298977
   Cadena C, 2015, INT J ROBOT RES, V34, P582, DOI 10.1177/0278364914549488
   Couprie C., 2013, P 1 INT C LEARN REPR, P1
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Ess A., 2007, PROC INT C COMPUT VI, P1
   Farabet C., 2012, Proc. International Conference on Machine Learning (ICML), V1, P575
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Graves A, 2007, LECT NOTES COMPUT SC, V4668, P549
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309
   Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   He J., 2011, Conf. Machine, P25
   He XM, 2004, PROC CVPR IEEE, P695
   Hermans A, 2014, IEEE INT CONF ROBOT, P2631, DOI 10.1109/ICRA.2014.6907236
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA
   Hoi SCH, 2008, IEEE T MULTIMEDIA, V10, P607, DOI 10.1109/TMM.2008.921735
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Irsoy O, 2014, P 2014 C EMPIRICAL M, P720, DOI DOI 10.3115/V1/D14-1080
   Khan SH, 2014, LECT NOTES COMPUT SC, V8689, P679, DOI 10.1007/978-3-319-10590-1_44
   Kim Seyoung, 2010, ICML, P543
   Lee H., 2007, NIPS
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Leibe B., 2007, PROC IEEE C COMPUT V, P1
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Liu W, 2013, IEEE T CYBERNETICS, V43, P1442, DOI 10.1109/TCYB.2013.2272636
   Müller AC, 2014, IEEE INT CONF ROBOT, P6232, DOI 10.1109/ICRA.2014.6907778
   Mukherjee SS, 2015, IEEE T MULTIMEDIA, V17, P2094, DOI 10.1109/TMM.2015.2482819
   Pei Deli., 2013, The 2013 International Joint Conference on Neural Networks (IJCNN), P1
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Rapus Martin, 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P632, DOI 10.1109/IVS.2008.4621195
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rohrbach M, 2009, LECT NOTES COMPUT SC, V5748, P101, DOI 10.1007/978-3-642-03798-6_11
   Shuai B, 2015, IEEE SIGNAL PROC LET, V22, P1990, DOI 10.1109/LSP.2015.2441781
   Shuai Tang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P525, DOI 10.1007/978-3-642-37444-9_41
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Stückler J, 2015, J REAL-TIME IMAGE PR, V10, P599, DOI 10.1007/s11554-013-0379-5
   van der Mark W, 2006, IEEE T INTELL TRANSP, V7, P38, DOI 10.1109/TITS.2006.869625
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Wang AR, 2014, LECT NOTES COMPUT SC, V8693, P453, DOI 10.1007/978-3-319-10602-1_30
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang Wei, 2010, P 27 INT C MACH LEAR, P1135
   Wang Z, 2008, IEEE T PATTERN ANAL, V30, P348, DOI 10.1109/TPAMI.2007.70786
   Wolfgang H., 2007, APPL MULTIVARIATE ST
   Xu C., 2013, arXiv
   Zhen Zuo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301268
NR 71
TC 19
Z9 21
U1 3
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2018
VL 20
IS 7
BP 1656
EP 1671
DI 10.1109/TMM.2017.2774007
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA GJ7MC
UT WOS:000435570100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, H
   Ko, J
   Park, S
AF Kim, HyunMi
   Ko, JeongGil
   Park, Seongmo
TI An Efficient Architecture of In-Loop Filters for Multicore Scalable HEVC
   Hardware Decoders
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Multicore; HEVC; decoder; in-loop filter; deblocking filter; sample
   adaptive offset (SAO); architecture
ID DEBLOCKING FILTER
AB This paper proposes an efficient architecture of HEVC in-loop filters (ILFs) with the target of providing effective multicore utilization for ultra-high definition video applications. While HEVC allows for a high level of parallelization, the issue of data dependencies at the ILF leads to inefficient parallel processing performance. The novel memory organization and management techniques address the data dependence-related issues between multiple processing units and enable to filter the flexible area on multicore decoder. In addition, we introduce the adaptive deblocking filtering order (ADFO) to minimize the impact of bus congestion when multiple cores intemperate for processing very large data. Furthermore, we design the deblocking filter with skip mode pipelining to achieve the high performance minimizing the increased cost and the power consumption. For SAO, we apply the window-based parallel SAO filtering scheme. The resource sharing is considered throughout the entire architecture. Based on both experimental and analytical results, our proposed design can achieve more than 1.31 Gpixels/s and less than 2.6 Gpixels/s at maximum frequency 660 MHz in single core, and consumes 56.2 Kgates including 10.6 Kgates for memory management architecture, which supports multicore decoder, and about 20.8 mW power on average when synthesizing with the 28 nm CMOS library. Moreover, the skip modes of DF improve both the performance and the power dissipation. The ADFO improves the performance of similar to 9.17% when decoding 8 K sequence on octacore at 400 MHz frequency. TpG (Throughput per Cate) is the highest among the related works.
C1 [Kim, HyunMi; Park, Seongmo] Univ Sci & Technol, Dept Comp Software, Daejeon 34113, South Korea.
   [Kim, HyunMi; Park, Seongmo] Elect & Telecommun Res Inst, Intelligent SoC Res Dept, Daejeon 34129, South Korea.
   [Ko, JeongGil] Ajou Univ, Dept Software Convergence Technol, Suwon 16499, South Korea.
C3 University of Science & Technology (UST); Electronics &
   Telecommunications Research Institute - Korea (ETRI); Ajou University
RP Ko, J (corresponding author), Ajou Univ, Dept Software Convergence Technol, Suwon 16499, South Korea.
EM elissa78@gmail.com; jgko@ajou.com; smpark@etri.re.kr
RI Ko, JeongGil/CAF-8134-2022
FU ICT R&D program of MSIP/IITP [2017-0-00261]
FX This work was supported by the ICT R&D program of MSIP/IITP
   (2017-0-00261, Intelligent Many-Core Processor and SW based on Low-Power
   Hypervisor). The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Leonel Sousa.
CR Bross B., 2014, 1SC29WG11 ISOIEC JTC
   Chen TC, 2006, ASIA S PACIF DES AUT, P750
   Cheng W, 2015, IEEE INT SYMP CIRC S, P605
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   Cho S, 2015, IEEE T MULTIMEDIA, V17, P778, DOI 10.1109/TMM.2015.2418995
   Cho Y. C. P., 2011, 2011 International Conference on Field Programmable Logic and Applications, P311, DOI 10.1109/FPL.2011.63
   Duan YZ, 2014, IEEE T MULTIMEDIA, V16, P1915, DOI 10.1109/TMM.2014.2337834
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   Hautala I, 2015, IEEE T CIRC SYST VID, V25, P1217, DOI 10.1109/TCSVT.2014.2369744
   Juurlink Ben., 2012, SCALABLE PARALLEL PR
   Kim H., 2014, 2014 Intelligent User Interfaces Workshop on Sketch Recognition, P1
   Li M., 2012, P PAC RIM C MULT SIN, P273
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ozcan E, 2013, IEEE T CONSUM ELECTR, V59, P714, DOI 10.1109/TCE.2013.6626260
   Shen S, 2013, IEICE ELECTRON EXPR, V10, DOI 10.1587/elex.10.20130272
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Suzuki T., 2012, 1SC29WG11 ISOIEC JTC
   Tikekar M, 2014, IEEE J SOLID-ST CIRC, V49, P61, DOI 10.1109/JSSC.2013.2284362
   Wigc E., 2012, P PICT COD S, P82
   Zhang YD, 2012, IEEE T MULTIMEDIA, V14, P510, DOI 10.1109/TMM.2012.2190391
   Zhu JY, 2013, IEICE T FUND ELECTR, VE96A, P2612, DOI 10.1587/transfun.E96.A.2612
NR 22
TC 6
Z9 6
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2018
VL 20
IS 4
BP 810
EP 824
DI 10.1109/TMM.2017.2759506
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FZ5HM
UT WOS:000427623000004
DA 2024-07-18
ER

PT J
AU Zhou, SP
   Wang, JJ
   Shi, R
   Hou, QQ
   Gong, YH
   Zheng, NN
AF Zhou, Sanping
   Wang, Jinjun
   Shi, Rui
   Hou, Qiqi
   Gong, Yihong
   Zheng, Nanning
TI Large Margin Learning in Set-to-Set Similarity Comparison for Person
   Reidentification
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Person re-identification; set to set similarity comparison; metric
   learning; deep learning
ID RECOGNITION
AB Person reidentification aims at matching images of the same person across disjoint camera views, which is a challenging problem in multimedia analysis, multimedia editing, and content-based media retrieval communities. The major challenge lies in how to preserve similarity of the same person across video footages with large appearance variations, while discriminating different individuals. To address this problem, conventional methods usually consider the pairwise similarity between persons by only measuring the point-to-point distance. In this paper, we propose using a deep learning technique to model a novel set-to-set (S2S) distance, in which the underline objective focuses on preserving the compactness of intraclass samples for each camera view, while maximizing the margin between the intraclass set and interclass set. The S2S distance metric consists of three terms, namely, the class-identity term, the relative distance term, and the regularization term. The class-identity term keeps the intraclass samples within each camera view gathering together, the relative distance term maximizes the distance between the intraclass class set and interclass set across different camera views, and the regularization term smoothes the parameters of the deep convolutional neural network. As a result, the final learned deep model can effectively find out the matched target to the probe object among various candidates in the video gallery by learning discriminative and stable feature representations. Using the CUHK01, CUHK03, PRID2011, and Market1501 benchmark datasets, we extensively conducted comparative evaluations to demonstrate the advantages of our method over the state-of-the-art approaches.
C1 [Zhou, Sanping; Wang, Jinjun; Shi, Rui; Hou, Qiqi; Gong, Yihong; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Wang, JJ (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM sanpingzhou@stu.xjtu.edu.cn; jinjun@mail.xjtu.edu.cn;
   shirui922288@stu.xjtu.edu.cn; houqiqi@stu.xjtu.edu.cn;
   ygong@mail.xjtu.edu.cn; nnzheng@mail.xjtu.edu.cn
FU National Science Foundation of China [61473219]; National Key Research
   and Development Program of China [2016YFB1001004]
FX This work was supported in part by the National Science Foundation of
   China under Grant 61473219, and in part by the National Key Research and
   Development Program of China under Grant 2016YFB1001004.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2017, P CVPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2012, BRIT MACH VIS C
   [Anonymous], P ADV NEURAL INFORM
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Davis J. V., 2007, ICML, P209
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Gray Douglas, 2007, P IEEE INT WORKSH PE, V3, P1
   Nguyen HV, 2011, LECT NOTES COMPUT SC, V6493, P709
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin L, 2017, IEEE T PATTERN ANAL, V39, P1089, DOI 10.1109/TPAMI.2016.2567386
   Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Lu T, 2016, IEEE T GEOSCI REMOTE, V54, P7122, DOI 10.1109/TGRS.2016.2596260
   Mian A, 2013, IEEE T IMAGE PROCESS, V22, P5252, DOI 10.1109/TIP.2013.2282996
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Sanping Zhou, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P84, DOI 10.1007/978-3-319-48896-7_9
   Sunderrajan S, 2016, IEEE T MULTIMEDIA, V18, P51, DOI 10.1109/TMM.2015.2496139
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang R., 2008, PROC IEEE C COMPUT V, P1
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wu Y, 2012, LECT NOTES COMPUT SC, V7574, P497, DOI 10.1007/978-3-642-33712-3_36
   Wu ZY, 2015, IEEE T PATTERN ANAL, V37, P1095, DOI 10.1109/TPAMI.2014.2360373
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang M, 2017, IMAGE VISION COMPUT, V58, P47, DOI 10.1016/j.imavis.2016.07.008
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhu PF, 2013, IEEE I CONF COMP VIS, P2664, DOI 10.1109/ICCV.2013.331
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 59
TC 60
Z9 62
U1 0
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2018
VL 20
IS 3
BP 593
EP 604
DI 10.1109/TMM.2017.2755983
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FW5ZH
UT WOS:000425397500007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU He, SQ
   Zhou, ZH
   Farhat, F
   Wang, JZ
AF He, Siqiong
   Zhou, Zihan
   Farhat, Farshid
   Wang, James Z.
TI Discovering Triangles in Portraits for Supporting Photographic Creation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Portrait photography; photo composition; triangle
ID PHOTO; RECOMMENDATION
AB Incorporating the concept of triangles in photos is an effective composition technique used by professional photographers for making pictures more interesting or dynamic. Information on the locations of the embedded triangles is valuable for comparing the composition of portrait photos, which can be further leveraged by a retrieval system or used by the photographers. This paper presents a system to automatically detect embedded triangles in portrait photos. The problem is challenging because the triangles used in portraits are often not clearly defined by straight lines. The system first extracts a set of filtered line segments as candidate triangle sides, and then utilizes a modified random sample consensus algorithm to fit triangles onto the set of line segments. We propose two metrics, Continuity Ratio and Total Ratio, to evaluate the fitted triangles; those with high fitting scores are taken as detected triangles. Experimental results have demonstrated high accuracy in locating preeminent triangles in portraits without dependence on the camera or lens parameters. To demonstrate the benefits of our method to digital photography, we have developed two novel applications that aim to help users compose high-quality photos. In the first application, we develop a human position and pose recommendation system by retrieving and presenting compositionally similar photos taken by competent photographers. The second application is a novel sketch-based triangle retrieval system which searches for photos containing a specific triangular configuration. User studies have been conducted to validate the effectiveness of these approaches.
C1 [He, Siqiong; Zhou, Zihan; Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16801 USA.
   [Farhat, Farshid] Penn State Univ, Sch Elect Engn & Comp Sci, University Pk, PA 16801 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University; Pennsylvania State University -
   University Park
RP Wang, JZ (corresponding author), Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16801 USA.
EM hesiqiong@gmail.com; zzhou@ist.psu.edu; fuf111@cse.psu.edu;
   jwang@ist.psu.edu
RI Wang, James/JAD-0675-2023
OI Wang, James/0000-0003-4379-4173
CR [Anonymous], 2011, ACM International Conference on Multimedia MM
   [Anonymous], 2010, ACM MULTIMEDIA 2010
   [Anonymous], 2016, ARXIV PREPRINT
   [Anonymous], 2011, DIGITAL SLR HDB
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467
   Fang C, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1105, DOI 10.1145/2647868.2654979
   Hurter B., 2005, GROUP PORTRAIT PHOTO
   Jin X, 2010, LECT NOTES COMPUT SC, V6314, P101, DOI 10.1007/978-3-642-15561-1_8
   Lauer D.A., 2011, Design Basics, V8th
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Ma S, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1053, DOI 10.1145/2647868.2655053
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Obrador P., 2010, PROC 18 ACM INT C MU, P561
   Obrador P, 2010, IEEE IMAGE PROC, P3185, DOI 10.1109/ICIP.2010.5654231
   Orendovici R., 2010, P ACM INT C MULT, P1575
   Rawat Y. S., 2015, P T MULT COMP COMM A, V12
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redi M, 2012, LECT NOTES COMPUT SC, V7585, P446, DOI 10.1007/978-3-642-33885-4_45
   Smith J., 2011, Posing for portrait photography: A head-to-toe guide for digital photographers
   Su HH, 2012, IEEE T MULTIMEDIA, V14, P833, DOI 10.1109/TMM.2012.2186123
   Valenzuela R., 2012, Picture Perfect Practice: A Self-training Guide to Mastering the Challenges of Taking World-class Photographs
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang Y, 2016, IEEE T SMART GRID, V7, P510, DOI 10.1109/TSG.2015.2409121
   Xu PF, 2014, MULTIMED TOOLS APPL, V69, P3, DOI 10.1007/s11042-012-1343-2
   Yan JZ, 2015, INT J COMPUT VISION, V114, P74, DOI 10.1007/s11263-015-0801-5
   Yao L, 2012, INT J COMPUT VISION, V96, P353, DOI 10.1007/s11263-011-0478-3
   Yin WY, 2014, IEEE T MULTIMEDIA, V16, P184, DOI 10.1109/TMM.2013.2283468
   Zhang FL, 2013, IEEE T MULTIMEDIA, V15, P1480, DOI 10.1109/TMM.2013.2268051
   Zhang YH, 2012, IEEE IMAGE PROC, P2753
NR 36
TC 8
Z9 10
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2018
VL 20
IS 2
BP 496
EP 508
DI 10.1109/TMM.2017.2740026
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FT2ER
UT WOS:000422953200019
DA 2024-07-18
ER

PT J
AU Kumar, N
   Sethi, A
AF Kumar, Neeraj
   Sethi, Amit
TI Super Resolution by Comprehensively Exploiting Dependencies of Wavelet
   Coefficients
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Super resolution; wavelet transform; multiresolution analysis;
   supervised learning; hidden Markov models
ID IMAGE INTERPOLATION; SUPERRESOLUTION
AB We propose an algorithm for single image super resolution (SR) using wavelet decomposition and machine learning. Wavelets have been used for SR before due to their ability to capture scale invariant properties of natural images. However, previous techniques used only a subset of relationships that exist between multiscale wavelet coefficients. We present a first-of-its-kind analysis of the wavelet properties relevant to SR that leads to insights for a novel SR algorithm. In particular, we discovered that to estimate a desired finer scale detail coefficient, it is not enough to use only its parent detail coefficient at the coarser scale, as was done by the previous techniques. The estimation can be improved a lot by using certain additional coarser level detail coefficients and even finer scale approximation coefficients whose relative locations are suggested by our analysis. Additionally, the previous wavelet-based techniques used generative learning frameworks for SR. However, we show that SR is a type of problem on which discriminative frameworks excel. These improvements allowed our technique to far surpass the reconstruction accuracy of the previous wavelet based SR algorithms on a large set of images. Additionally, our algorithm also surpassed other state-of-the-art SR algorithms that are not based on wavelets in reconstruction quality, and training and testing speeds. We, thus, reestablish the utility of the wavelets for SR.
C1 [Kumar, Neeraj] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
   [Sethi, Amit] Indian Inst Technol Guwahati, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Kumar, N (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM neeraj.kumar@iitg.ac.in; amitsethi@iitg.ac.in
RI Kumar, Neeraj/AAD-4748-2020
FU National Cancer Institute [5R25-CA057699]
FX This work was supported in part by the National Cancer Institute under
   Grant 5R25-CA057699. The associate editor coordinating the review of
   this manuscript and approving it for publication was Prof. Liang Zhou.
   (Corresponding author: Neeraj Kumar.)
CR [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], COMP VIS PATT REC IE
   [Anonymous], 2012, The Royal College of Surgeons of England/The British Society for Disability and Oral Health, P1
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chan RH, 2003, SIAM J SCI COMPUT, V24, P1408, DOI 10.1137/S1064827500383123
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Huang JJ, 2015, IEEE T IMAGE PROCESS, V24, P3232, DOI 10.1109/TIP.2015.2440751
   Kang LW, 2015, IEEE T MULTIMEDIA, V17, P921, DOI 10.1109/TMM.2015.2434216
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kim SS, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1723
   Kinebuchi K, 2001, INT CONF ACOUST SPEE, P1957, DOI 10.1109/ICASSP.2001.941330
   Kumar N, 2016, IEEE T MULTIMEDIA, V18, P1504, DOI 10.1109/TMM.2016.2571625
   Lu XQ, 2014, IEEE T CYBERNETICS, V44, P366, DOI 10.1109/TCYB.2013.2256347
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Sethi A, 2012, ANNU IEEE IND CONF, P790
   Tang Y, 2015, IEEE T CYBERNETICS, V45, P2042, DOI 10.1109/TCYB.2014.2363882
   Tian J, 2011, EXPERT SYST APPL, V38, P12514, DOI 10.1016/j.eswa.2011.04.037
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo DH, 2004, IEEE IMAGE PROC, P1687
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang CY, 2011, LECT NOTES COMPUT SC, V6494, P497, DOI 10.1007/978-3-642-19318-7_39
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhou Q, 2016, PATTERN RECOGN, V59, P312, DOI 10.1016/j.patcog.2016.03.023
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 41
TC 6
Z9 6
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2018
VL 20
IS 2
BP 298
EP 309
DI 10.1109/TMM.2017.2729021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FT2ER
UT WOS:000422953200004
DA 2024-07-18
ER

PT J
AU Liu, FH
   Gong, C
   Zhou, T
   Fu, KR
   He, XJ
   Yang, J
AF Liu, Fanghui
   Gong, Chen
   Zhou, Tao
   Fu, Keren
   He, Xiangjian
   Yang, Jie
TI Visual Tracking via Nonnegative Multiple Coding
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Approximated locality-constrained linear coding; nonnegative constraint;
   occlusion detection; visual tracking
ID OBJECT TRACKING
AB It has been extensively observed that an accurate appearance model is critical to achieving satisfactory performance for robust object tracking. Most existing top-ranked methods rely on linear representation over a single dictionary, which brings about improper understanding on the target appearance. To address this problem, in this paper, we propose a novel appearance model named as "nonnegative multiple coding" (NMC) to accurately represent a target. First, a series of local dictionaries are created with different predefined numbers of nearest neighbors, and then the contributions of these dictionaries are automatically learned. As a result, this ensemble of dictionaries can comprehensively exploit the appearance information carried by all the constituted dictionaries. Second, the existing methods explicitly impose the nonnegative constraint to coefficient vectors, but in the proposed model, we directly deploy an efficient l(2) norm regularization to achieve the similar nonnegative purpose with theoretical guarantees. Moreover, an efficient occlusion detection scheme is designed to alleviate tracking drifts, which investigates whether negative templates are selected to represent the severely occluded target. Experimental results on two benchmarks demonstrate that our NMC tracker are able to achieve superior performance to state-of-the-art methods.
C1 [Liu, Fanghui; Zhou, Tao; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Gong, Chen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Fu, Keren] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
   [He, Xiangjian] Univ Technol Sydney, Sch Comp & Commun, Ultimo, NSW 2007, Australia.
C3 Shanghai Jiao Tong University; Nanjing University of Science &
   Technology; Sichuan University; University of Technology Sydney
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM lfhsgre@outlook.com; chen.gong@njust.edu.cn; zhou.tao@sjtu.edu.cn;
   fkrsuper@gmail.com; Xiangjian.He@uts.edu.au; jieyang@sjtu.edu.cn
RI Fu, Keren/HPG-4742-2023; He, Xiangjian/CAA-1461-2022; GONG,
   CHEN/JDW-5727-2023; Yang, Jie/JCD-9867-2023; Liu, Fanghui/AAG-7065-2019
OI Fu, Keren/0000-0002-3195-2077; Liu, Fanghui/0000-0003-4133-7921; He,
   Xiangjian/0000-0001-8962-540X
FU National Natural Science Foundation of China [61572315, 6151101179,
   61602246]; 863 Plan of China [2015AA042308]; China Postdoctoral Science
   Foundation [2016M601597]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61572315, Grant 6151101179, and Grant
   61602246, in part by 863 Plan of China under Grant 2015AA042308, and in
   part by the China Postdoctoral Science Foundation under Grant
   2016M601597. This associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Abdulmotaleb El
   Saddik. (Corresponding author: Jie Yang.)
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2009, P ADV NEUR INF PROC
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   CARSTENSEN C, 1991, NUMER MATH, V59, P349, DOI 10.1007/BF01385785
   Chen DP, 2014, LECT NOTES COMPUT SC, V8689, P345, DOI 10.1007/978-3-319-10590-1_23
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Gong C, 2017, IEEE T NEUR NET LEAR, V28, P1452, DOI 10.1109/TNNLS.2016.2514360
   Gong C, 2016, IEEE T IMAGE PROCESS, V25, P3249, DOI 10.1109/TIP.2016.2563981
   Gong C, 2014, IEEE T CYBERNETICS, V44, P882, DOI 10.1109/TCYB.2013.2274516
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Liu FH, 2017, PATTERN RECOGN LETT, V90, P72, DOI 10.1016/j.patrec.2017.03.019
   Liu FH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P912, DOI 10.1109/ICCVW.2015.121
   Long B., 2010, J INEQUAL APPL, V2010, P1
   Ma B, 2015, IEEE I CONF COMP VIS, P4400, DOI 10.1109/ICCV.2015.500
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   PARIKH N., 2014, FDN TRENDS OPTIM, V1, P3, DOI DOI 10.1561/2400000003
   Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang GF, 2015, IEEE T IMAGE PROCESS, V24, P3796, DOI 10.1109/TIP.2015.2445291
   Wang N, 2013, P ADV NEURAL INFORM
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yoon JH, 2016, IEEE T PATTERN ANAL, V38, P903, DOI 10.1109/TPAMI.2015.2473862
   Yuan Y, 2015, IEEE T MULTIMEDIA, V17, P1125, DOI 10.1109/TMM.2015.2440996
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
NR 50
TC 16
Z9 16
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2017
VL 19
IS 12
BP 2680
EP 2691
DI 10.1109/TMM.2017.2708424
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FN8HG
UT WOS:000416263200004
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhou, ZH
   Farhat, F
   Wang, JZ
AF Zhou, Zihan
   Farhat, Farshid
   Wang, James Z.
TI Detecting Dominant Vanishing Points in Natural Scenes with Application
   to Composition-Sensitive Image Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image retrieval; photo composition; vanishing point
ID RECOMMENDATION; PHOTOGRAPH
AB Linear perspective is widely used in landscape photography to create the impression of depth on a 2D photo. Automated understanding of linear perspective in landscape photography has several real-world applications, including aesthetics assessment, image retrieval, and on-site feedback for photo composition, yet adequate automated understanding has been elusive. We address this problem by detecting the dominant vanishing point and the associated line structures in a photo. However, natural landscape scenes pose great technical challenges because often the number of strong edges converging to the dominant vanishing point is inadequate. To overcome this difficulty, we propose a novel vanishing point detection method that exploits global structures in the scene via contour detection. We show that our method significantly outperforms state-of-the-art methods on a public ground truth landscape image dataset that we have created. Based on the detection results, we further demonstrate how our approach to linear perspective understanding provides on-site guidance to amateur photographers on their work through a novel viewpoint-specific image retrieval system.
C1 [Zhou, Zihan; Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16802 USA.
   [Farhat, Farshid] Penn State Univ, Sch Elect Engn & Comp Sci, State Coll, PA 16801 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania Commonwealth System of
   Higher Education (PCSHE); Pennsylvania State University
RP Zhou, ZH (corresponding author), Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16802 USA.
EM zzhou@ist.psu.edu; fuf111@cse.psu.edu; jwang@ist.psu.edu
RI Wang, James/JAD-0675-2023
OI Wang, James/0000-0003-4379-4173
CR Almansa A, 2003, IEEE T PATTERN ANAL, V25, P502, DOI 10.1109/TPAMI.2003.1190575
   Andaló FA, 2015, COMPUT VIS IMAGE UND, V138, P51, DOI 10.1016/j.cviu.2015.03.017
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1999, PROCEDINGS BRIT MACH
   [Anonymous], 2010, ACM MULTIMEDIA 2010
   Antunes M, 2013, PROC CVPR IEEE, P1336, DOI 10.1109/CVPR.2013.176
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6
   Bazin JC, 2012, PROC CVPR IEEE, P638, DOI 10.1109/CVPR.2012.6247731
   BRILLAULTOMAHONY B, 1991, CVGIP-IMAG UNDERSTAN, V54, P289, DOI 10.1016/1049-9660(91)90069-2
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Collins R. T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P400, DOI 10.1109/ICCV.1990.139560
   Coughlan JM, 2003, NEURAL COMPUT, V15, P1063, DOI 10.1162/089976603765202668
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   Fang C, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1105, DOI 10.1145/2647868.2654979
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Islam M. B., 2016, MULTIMEDIA TOOLS APP, P1
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kong H, 2009, PROC CVPR IEEE, P96, DOI 10.1109/CVPRW.2009.5206787
   Kosecká J, 2002, LECT NOTES COMPUT SC, V2353, P476
   Krages B., 2005, Photography: the art of composition
   Lauer D.A., 2011, Design Basics, V8th
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lezama J, 2014, PROC CVPR IEEE, P509, DOI 10.1109/CVPR.2014.72
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Ma S, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1053, DOI 10.1145/2647868.2655053
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   MCLEAN GF, 1995, IEEE T PATTERN ANAL, V17, P1090, DOI 10.1109/34.473236
   Mirzaei FM, 2011, IEEE I CONF COMP VIS, P2454, DOI 10.1109/ICCV.2011.6126530
   Moghadam P, 2012, IEEE T IMAGE PROCESS, V21, P425, DOI 10.1109/TIP.2011.2162422
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Parodi P, 1996, IEEE T PATTERN ANAL, V18, P211, DOI 10.1109/34.481545
   QUAN L, 1989, PATTERN RECOGN LETT, V9, P279, DOI 10.1016/0167-8655(89)90006-8
   Rasmussen C, 2004, PROC CVPR IEEE, P470
   Rawat YS, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808199
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Schindler G, 2004, PROC CVPR IEEE, P203
   Shrivastava A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024188
   Shufelt JA, 1999, IEEE T PATTERN ANAL, V21, P282, DOI 10.1109/34.754631
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su HH, 2012, IEEE T MULTIMEDIA, V14, P833, DOI 10.1109/TMM.2012.2186123
   Tardif Jean-Philippe, 2009, 2009 IEEE 12th International Conference on Computer Vision (ICCV), P1250, DOI 10.1109/ICCV.2009.5459328
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Tretyak E, 2012, INT J COMPUT VISION, V97, P305, DOI 10.1007/s11263-011-0488-1
   Tuytelaars T, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P736, DOI 10.1109/ICIP.1997.638601
   Vedaldi A, 2012, LECT NOTES COMPUT SC, V7573, P87, DOI 10.1007/978-3-642-33709-3_7
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wildenauer H, 2012, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2012.6248008
   Xu PF, 2014, MULTIMED TOOLS APPL, V69, P3, DOI 10.1007/s11042-012-1343-2
   Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181
   Yan JZ, 2015, INT J COMPUT VISION, V114, P74, DOI 10.1007/s11263-015-0801-5
   Yao L, 2012, INT J COMPUT VISION, V96, P353, DOI 10.1007/s11263-011-0478-3
   Yin WY, 2014, IEEE T MULTIMEDIA, V16, P184, DOI 10.1109/TMM.2013.2283468
   Zhai MH, 2016, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2016.610
   Zhang FL, 2013, IEEE T MULTIMEDIA, V15, P1480, DOI 10.1109/TMM.2013.2268051
   Zhou ZH, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P301, DOI 10.1145/2733373.2806248
NR 66
TC 27
Z9 30
U1 1
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2017
VL 19
IS 12
BP 2651
EP 2665
DI 10.1109/TMM.2017.2703954
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FN8HG
UT WOS:000416263200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yin, H
   Zhang, X
   Zhao, SY
   Luo, Y
   Tian, C
   Sekar, V
AF Yin, Hao
   Zhang, Xu
   Zhao, Shuoyao
   Luo, Yan
   Tian, Chen
   Sekar, Vyas
TI Tradeoffs Between Cost and Performance for CDN Provisioning Based on
   Coordinate Transformation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Clustering; decision support system; server provisioning; transform
ID PLACEMENT; DELIVERY; DISTANCE
AB Today's content delivery is characterized by key trends such as converged media delivery over HTTP, increasing volumes of multimedia content delivered over IP, and elevated user expectations on quality-of-experience. In this respect, server provisioning is a critical phase of CDN management, which affects both incumbent and entrant CDN operators as well as internet service providers. However, existing tools and approaches to solve server placement problems have serious shortcomings: they offer only coarse tuning knobs and limit servers to a set of candidate sites given a priori. Our conversations with CDN operators reveal that a new provisioning mechanism is necessary to take advantage of emerging opportunities such as faster speed to roll out new locations and more access networks. In this paper, we present the design of DISC, a decision support system to help CDN operators systematically investigate different design tradeoffs and evaluate what-if scenarios. The key enabler underlying DISC is a network coordinate-based data analysis workflow that can flexibly embed different cost, performance, and workload characteristics without sacrificing the fidelity. We describe practical use cases and experiences in applying DISC to a large country-wide deployment. The results show that DISC significantly reduces average latency, deployment cost, and interdomain traffic.
C1 [Yin, Hao; Zhang, Xu; Zhao, Shuoyao] Tsinghua Univ, Res Inst Informat Technol, Beijing 100084, Peoples R China.
   [Luo, Yan] Univ Massachusetts, Dept Elect & Comp Engn, Lowell, MA 01854 USA.
   [Tian, Chen] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210000, Jiangsu, Peoples R China.
   [Sekar, Vyas] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
C3 Tsinghua University; University of Massachusetts System; University of
   Massachusetts Lowell; Nanjing University; Carnegie Mellon University
RP Zhang, X (corresponding author), Tsinghua Univ, Res Inst Informat Technol, Beijing 100084, Peoples R China.
EM h-yin@mail.tsinghua.edu.cn; xzhang12@mails.tsinghua.edu.cn;
   zsyintl@126.com; yan_luo@uml.edu; tianchen@nju.edu.cn;
   vsekar@andrew.cmu.edu
RI Sui, Yanwei/AAH-9928-2021
OI Zhang, Xu/0000-0002-1882-736X
FU National Key Research and Development Program [2016YFB1000102]; National
   Natural Science Foundation of China [61672318, 61631013, 61602194];
   United States National Science Foundation [1547428, 1541434, 1440737,
   1450996]; European Seventh Framework Programme [PIRSES-GA-2012-318939];
   Tsinghua National Laboratory for Information Science and Technology;
   Intel Corporation
FX This work was supported in part by the National Key Research and
   Development Program under Grant 2016YFB1000102, in part by the National
   Natural Science Foundation of China under Grant 61672318, Grant
   61631013, and Grant 61602194, in part by the United States National
   Science Foundation under Grant 1547428, Grant 1541434, Grant 1440737,
   and Grant 1450996, in part by the European Seventh Framework Programme
   under Grant PIRSES-GA-2012-318939, in part by the projects of Tsinghua
   National Laboratory for Information Science and Technology, and in part
   by a grant from the Intel Corporation. The associate editor coordinating
   the review of this manuscript and approving it for publication was Prof.
   Zhu Li. (Corresponding author: Xu Zhang.)
CR Agarwal S, 2009, ACM SIGCOMM COMP COM, V39, P315, DOI 10.1145/1594977.1592605
   Ager B., P SIGCOMM, P163
   Anegekuh L, 2015, IEEE T MULTIMEDIA, V17, P1323, DOI 10.1109/TMM.2015.2444098
   [Anonymous], 2013, P INT MEAS C
   [Anonymous], 2014, CISCO VISUAL NETWORK
   [Anonymous], 2014, P 5 ACM MULTIMEDIA S, DOI DOI 10.1145/2557642.2579373
   Armitage G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2168996.2169000
   Ball N., 2008, P ACM CONEXT C, P77
   Bassett E.K., 2006, IMC 06 P 6 ACM SIGCO, P71
   Brandenburg R. V., 2015, 7336 RFC CDNI
   Cohen R, 2009, IEEE ACM T NETWORK, V17, P487, DOI 10.1109/TNET.2009.2014652
   Costa M, 2004, INT CON DISTR COMP S, P178, DOI 10.1109/ICDCS.2004.1281582
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Cronin E, 2002, IEEE J SEL AREA COMM, V20, P1369, DOI 10.1109/JSAC.2002.802066
   Dabek F, 2004, ACM SIGCOMM COMP COM, V34, P15, DOI 10.1145/1030194.1015471
   Guo CX, 2009, SIGCOMM 2009, P63
   Hasan Syed, 2014, IEEE INFOCOM 2014 - IEEE Conference on Computer Communications, P460, DOI 10.1109/INFOCOM.2014.6847969
   Huang C, 2008, IMC'08: PROCEEDINGS OF THE 2008 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P15
   Jamin S., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P295, DOI 10.1109/INFCOM.2000.832199
   Krishnamurthy B, 2001, IMW 2001: PROCEEDINGS OF THE FIRST ACM SIGCOMM INTERNET MEASUREMENT WORKSHOP, P169
   Krishnan P, 2000, IEEE ACM T NETWORK, V8, P568, DOI 10.1109/90.879344
   Li B, 1999, IEEE INFOCOM SER, P1282, DOI 10.1109/INFCOM.1999.752146
   Li ZY, 2015, IEEE T MULTIMEDIA, V17, P880, DOI 10.1109/TMM.2015.2417771
   Madhyastha HV, 2006, USENIX ASSOCIATION 7TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P367
   Ng ISE, 2002, IEEE INFOCOM SER, P170, DOI 10.1109/INFCOM.2002.1019258
   Qiu LL, 2001, IEEE INFOCOM SER, P1587, DOI 10.1109/INFCOM.2001.916655
   Qureshi A, 2009, ACM SIGCOMM COMP COM, V39, P123, DOI 10.1145/1594977.1592584
   Radoslavov P, 2002, COMPUT COMMUN, V25, P384, DOI 10.1016/S0140-3664(01)00410-8
   Song JR, 2016, IEEE T MULTIMEDIA, V18, P444, DOI 10.1109/TMM.2016.2520090
   Tang Liying, 2003, P 3 ACM SIGCOMM C IN, P143, DOI DOI 10.1145/948205.948223
   Valancius V., 2009, PROC CONEXT 09, P37, DOI DOI 10.1145/1658939.1658944
   Wang YA, 2011, IEEE INFOCOM SER, P2372, DOI 10.1109/INFCOM.2011.5935057
   Wang Z, 2015, IEEE T MULTIMEDIA, V17, P92, DOI 10.1109/TMM.2014.2365364
   Xu JL, 2002, IEEE J SEL AREA COMM, V20, P1383, DOI 10.1109/JSAC.2002.802068
   Yin H, 2013, IEEE T MULTIMEDIA, V15, P2114, DOI 10.1109/TMM.2013.2280557
   Yin H, 2010, IEEE NETWORK, V24, P52, DOI 10.1109/MNET.2010.5510919
   Zhang Y, 2012, INT C PAR DISTRIB SY, P588, DOI 10.1109/ICPADS.2012.85
NR 37
TC 11
Z9 12
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2017
VL 19
IS 11
BP 2583
EP 2596
DI 10.1109/TMM.2017.2696309
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FJ9CT
UT WOS:000413068200018
DA 2024-07-18
ER

PT J
AU Zhu, XF
   Li, XL
   Zhang, SC
   Xu, ZB
   Yu, LT
   Wang, C
AF Zhu, Xiaofeng
   Li, Xuelong
   Zhang, Shichao
   Xu, Zongben
   Yu, Litao
   Wang, Can
TI Graph PCA Hashing for Similarity Search
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Hashing; image retrieval; manifold learning; similarity search; spectral
   clustering
ID SPARSE
AB This paper proposes a new hashing framework to conduct similarity search via the following steps: first, employing linear clustering methods to obtain a set of representative data points and a set of landmarks of the big dataset; second, using the landmarks to generate a probability representation for each data point. The proposed probability representation method is further proved to preserve the neighborhood of each data point. Third, PCA is integrated with manifold learning to lean the hash functions using the probability representations of all representative data points. As a consequence, the proposed hashing method achieves efficient similarity search (with linear time complexity) and effective hashing performance and high generalization ability (simultaneously preserving two kinds of complementary similarity structures, i.e., local structures via manifold learning and global structures via PCA). Experimental results on four public datasets clearly demonstrate the advantages of our proposed method in terms of similarity search, compared to the state-of-the-art hashing methods.
C1 [Zhu, Xiaofeng; Zhang, Shichao] Guangxi Normal Univ, Guangxi Key Lab MIMS, Guilin 541004, Peoples R China.
   [Zhu, Xiaofeng; Zhang, Shichao] Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Peoples R China.
   [Li, Xuelong] Chinese Acad Sci, Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
   [Xu, Zongben] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.
   [Yu, Litao] Univ Queensland, Queensland Brain Inst, Queensland, Qld 4072, Australia.
   [Wang, Can] Griffith Univ, Sch Informat & Commun Technol, Southport, Qld 4215, Australia.
C3 Guangxi Normal University; Guangxi Normal University; Chinese Academy of
   Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS; Xi'an
   Jiaotong University; University of Queensland; Griffith University;
   Griffith University - Gold Coast Campus
RP Zhang, SC (corresponding author), Guangxi Normal Univ, Guangxi Key Lab MIMS, Guilin 541004, Peoples R China.; Zhang, SC (corresponding author), Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Peoples R China.; Xu, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.
EM xfzhu0011@hotmail.com; xuelong_li@opt.ac.cn;
   zhangsc@mailbox.gxnu.edu.cn; zbxu@mail.xjtu.edu.cn; l.yu4@uq.edu.au;
   canwang613@gmail.com
RI li, xiang/GWM-6319-2022; Li, Xuelong/Z-3785-2019; Zhang,
   Shichao/JXW-9650-2024; WANG, CAN/GWV-0969-2022; Zhu,
   Xiaofeng/HII-5291-2022; Zhang, Shichao/AAA-7608-2020; Li,
   Xuelong/ABF-3381-2020
OI Zhu, Xiaofeng/0000-0001-6840-0578; Wang, Can/0000-0002-2890-0057; Li,
   Xuelong/0000-0002-0019-4197
FU China Key Research Program [2016YFB1000905]; China 973 Program
   [2013CB329404]; China 1000-Plan National Distinguished Professorship;
   Nation Natural Science Foundation of China [61573270, 61761130079,
   61363009, 61672177]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011]; Guangxi High Institutions Program of Introducing
   100 High-Level Overseas Talents; Guangxi Collaborative Innovation Center
   of Multi-Source Information Integration and Intelligent Processing;
   Guangxi Key Lab of MIMS [16-A-01-01, 16-A-01-02]; Guangxi Bagui Teams
   for Innovation and Research
FX This work was supported in part by the China Key Research Program under
   Grant 2016YFB1000905, in part by the China 973 Program under Grant
   2013CB329404, in part by the China 1000-Plan National Distinguished
   Professorship, in part by the Nation Natural Science Foundation of China
   under Grant 61573270, Grant 61761130079, Grant 61363009, and Grant
   61672177, in part by the Guangxi Natural Science Foundation under Grant
   2015GXNSFCB139011, in part by the Guangxi High Institutions Program of
   Introducing 100 High-Level Overseas Talents, in part by the Guangxi
   Collaborative Innovation Center of Multi-Source Information Integration
   and Intelligent Processing, in part by the Research Fund of Guangxi Key
   Lab of MIMS (16-A-01-01 and 16-A-01-02), and in part by the Guangxi
   Bagui Teams for Innovation and Research. The guest editor coordinating
   the review of this manuscript and approving it for publication was Mr.
   Jingkuan Song. (Corresponding authors: Shichao Zhang and Zongben Xu.)
CR Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 2016, COMPUT RES REPOSITOR
   [Anonymous], 2004, P 20 ACM S COMP
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], CORR
   [Anonymous], 2009, NIPS
   [Anonymous], CVPR
   [Anonymous], 2016, CORR
   [Anonymous], 2009, NEURIPS
   [Anonymous], IEEE T CYBE IN PRESS
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Cai D, 2015, IEEE T CYBERNETICS, V45, P1669, DOI 10.1109/TCYB.2014.2358564
   Chen ZX, 2017, IEEE T MULTIMEDIA, V19, P123, DOI 10.1109/TMM.2016.2620604
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Conjeti S, 2016, MED IMAGE ANAL, V34, P13, DOI 10.1016/j.media.2016.05.010
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Goldberger J., 2004, Advances in Neural Information Processing Systems
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hao YB, 2017, IEEE T MULTIMEDIA, V19, P1, DOI 10.1109/TMM.2016.2610324
   Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Irie G, 2014, PROC CVPR IEEE, P2123, DOI 10.1109/CVPR.2014.272
   Jain H, 2016, LECT NOTES COMPUT SC, V9911, P681, DOI 10.1007/978-3-319-46478-7_42
   Kong W., 2012, P 26 AAAI C ART INT, P634, DOI DOI 10.5555/2900728.2900819
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Li WJ, 2016, IJCAI, P1711
   Li XL, 2017, AAAI CONF ARTIF INTE, P2203
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Mao XJ, 2017, IEEE T MULTIMEDIA, V19, P382, DOI 10.1109/TMM.2016.2614858
   Nie XS, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5528-6
   Norouzi M.E., 2011, ICML
   Peng X, 2017, IEEE T CYBERNETICS, V47, P1053, DOI 10.1109/TCYB.2016.2536752
   Peng X, 2016, IEEE T NEUR NET LEAR, V27, P2499, DOI 10.1109/TNNLS.2015.2490080
   Qu W, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0902-2
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen FM, 2015, IEEE T IMAGE PROCESS, V24, P1839, DOI 10.1109/TIP.2015.2405340
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14
   Torralba A., 2008, PROC IEEE C COMPUT V, P1
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wei Y, 2016, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2744204
   Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P106
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25
   Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76
   Ye RZ, 2016, IEEE T CYBERNETICS, V46, P718, DOI 10.1109/TCYB.2015.2414299
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang ST, 2016, MED IMAGE ANAL, V33, P98, DOI 10.1016/j.media.2016.06.010
   Zhen Y, 2016, IEEE T CYBERNETICS, V46, P27, DOI 10.1109/TCYB.2015.2392052
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2016, LECT NOTES COMPUT SC, V10019, P313, DOI 10.1007/978-3-319-47157-0_38
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zhu XF, 2013, IEEE T MULTIMEDIA, V15, P633, DOI 10.1109/TMM.2012.2233723
NR 67
TC 158
Z9 159
U1 3
U2 51
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2017
VL 19
IS 9
BP 2033
EP 2044
DI 10.1109/TMM.2017.2703636
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FH5XC
UT WOS:000411244200007
OA Green Published
DA 2024-07-18
ER

PT J
AU Pei, SC
   Shen, CT
AF Pei, Soo-Chang
   Shen, Chih-Tsung
TI Color Enhancement With Adaptive Illumination Estimation for
   Low-Backlighted Displays
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Adaptive illumination estimation; color saturation; image decomposition;
   low-backlighted display
ID RETINEX; IMAGE
AB In this paper, we propose an image enhancement system to maintain human visual perception for low-backlighted LCD or LED displays. Adopting the low-backlight mode can save electrical power and extend battery life. First, we examine the relationship between the image and backlight to maintain visual perceptual quality. Then, we use an adaptive illumination estimation to decompose the image intensity into an illumination layer and a reflectance layer with multiscale and parallel perspectives. We then refer to the given backlight level and our derived image-backlight relationship to compensate the illumination layer and meanwhile enhance the reflectance layer. Finally, we also boost the color saturation. Experiments using both numerical blind/referenceless image spatial quality evaluator and subjective mean opinion score demonstrate that our system outperforms existing systems.
C1 [Pei, Soo-Chang; Shen, Chih-Tsung] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
   [Pei, Soo-Chang] Natl Taiwan Univ, Dept Elect Engn, Taipei 10617, Taiwan.
   [Shen, Chih-Tsung] Ind Technol Res Inst, Hsinchu 31040, Taiwan.
C3 National Taiwan University; National Taiwan University; Industrial
   Technology Research Institute - Taiwan
RP Pei, SC (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.; Pei, SC (corresponding author), Natl Taiwan Univ, Dept Elect Engn, Taipei 10617, Taiwan.
EM peisc@ntu.edu.tw; ctshen@itri.org.tw
FU  [MOST 104-2221-E-002-096-MY3];  [MOST 105-2633-E-002-001]
FX This work was supported by MOST 104-2221-E-002-096-MY3 and MOST
   105-2633-E-002-001. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Leonel Sousa.
   (Corresponding author: Soo-Chang Pei.)
CR [Anonymous], P ACM SIGGRAPH AS TE
   Chang N, 2004, IEEE T VLSI SYST, V12, P837, DOI 10.1109/tvlsi.2004.831472
   Cheng WC, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P252, DOI 10.1109/DATE.2004.1268857
   Choi DH, 2007, IEEE INT SYMP CIRC S, P3948, DOI 10.1109/ISCAS.2007.378664
   Huang TH, 2013, IEEE T IMAGE PROCESS, V22, P4587, DOI 10.1109/TIP.2013.2272517
   Huang TH, 2008, IEEE IMAGE PROC, P1752, DOI 10.1109/ICIP.2008.4712114
   Iranli A, 2006, IEEE T VLSI SYST, V14, P1103, DOI 10.1109/TVLSI.2006.884151
   Jung C, 2015, IEEE IMAGE PROC, P3240, DOI 10.1109/ICIP.2015.7351402
   Kim Yong-Deok, 2016, INT C LEARNING REPRE
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pei SC, 2014, IEEE INT SYMP CIRC S, P2720, DOI 10.1109/ISCAS.2014.6865735
   Pei SC, 2012, IEEE SIGNAL PROC LET, V19, P813, DOI 10.1109/LSP.2012.2220352
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Saponara S, 2007, IEEE T CIRCUITS-II, V54, P596, DOI 10.1109/TCSII.2007.896778
   Shih KT, 2016, IEEE T MULTIMEDIA, V18, P300, DOI 10.1109/TMM.2015.2503918
   Tsai PS, 2009, IEEE T CIRC SYST VID, V19, P574, DOI 10.1109/TCSVT.2009.2014022
NR 20
TC 18
Z9 18
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2017
VL 19
IS 8
BP 1956
EP 1961
DI 10.1109/TMM.2017.2688924
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA FH5VV
UT WOS:000411240400022
DA 2024-07-18
ER

PT J
AU Fu, KR
   Gu, IYH
   Yang, J
AF Fu, Keren
   Gu, Irene Yu-Hua
   Yang, Jie
TI Saliency Detection by Fully Learning a Continuous Conditional Random
   Field
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Continuous conditional random field (C-CRF); feature integration;
   learning; saliency map; salient object detection; spatial ranges
ID OBJECT DETECTION; SEGMENTATION
AB Salient object detection is aimed at detecting and segmenting objects that human eyes are most focused on when viewing a scene. Recently, conditional random field (CRF) is drawn renewed interest, and is exploited in this field. However, when utilizing a CRF with unary and pairwise potentials having essential parameters, most existing methods only employ manually designed parameters, or learn parameters partly for the unary potentials. Observing that the saliency estimation is a continuous labeling issue, this paper proposes a novel data-driven scheme based on a special CRF framework, the so-called continuous CRF (C-CRF), where parameters for both unary and pairwise potentials are jointly learned. The proposed C-CRF learning provides an optimal way to integrate various unary saliency features with pairwise cues to discover salient objects. To the best of our knowledge, the proposed scheme is the first to completely learn a C-CRF for saliency detection. In addition, we propose a novel formulation of pairwise potentials that enables learning weights for different spatial ranges on a superpixel graph. The proposed C-CRF learning-based saliency model is tested on 6 benchmark datasets and compared with 11 existing methods. Our results and comparisons have provided further support to the proposed method in terms of precision-recall and F-measure. Furthermore, incorporating existing saliency models with pairwise cues through the C-CRF are shown to provide marked boosting performance over individual models.
C1 [Fu, Keren] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Fu, Keren] Chalmers Univ Technol, Dept Signals & Syst, S-41296 Gothenburg, Sweden.
   [Gu, Irene Yu-Hua] Chalmers Univ Technol, Dept Signals & Syst, S-41296 Gothenburg, Sweden.
   [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; Chalmers University of Technology;
   Chalmers University of Technology; Shanghai Jiao Tong University
RP Fu, KR (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM fkrshichaoren@qq.com; irenegu@chalmers.se; jieyang@sjtu.edu.cn
RI Fu, Keren/HPG-4742-2023; Yang, Jie/JCD-9867-2023; Gu, Irene
   Yu-Hua/D-4044-2018
OI Fu, Keren/0000-0002-3195-2077; Gu, Irene Yu-Hua/0000-0003-4759-7038
FU National Natural Science Foundation of China [61572315, 6151101179]; 863
   Plan of China [2015AA042308]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61572315 and Grant 6151101179, and in
   part by the 863 Plan of China under Grant 2015AA042308. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Dr. Judith Redi. (Corresponding authors: Jie Yang and
   Keren Fu.)
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], 2008, Proceedings of NIPS'08
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   Borji A., 2014, CoRR, Vabs/1411.5878
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fu KR, 2015, IEEE T IMAGE PROCESS, V24, P5671, DOI 10.1109/TIP.2015.2485782
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Khuwuthyakorn P, 2010, LECT NOTES COMPUT SC, V6312, P636, DOI 10.1007/978-3-642-15552-9_46
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kolesnikov A, 2014, LECT NOTES COMPUT SC, V8691, P550, DOI 10.1007/978-3-319-10578-9_36
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Liu Z, 2013, OPT LETT, V38, P700, DOI 10.1364/OL.38.000700
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   MAI L, 2013, PROC CVPR IEEE, P1131, DOI DOI 10.1109/CVPR.2013.150
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mehrani Paria., 2010, BMVC, P1
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Petersen K., 2008, THE MATRIX COOKBOOK
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Stentiford F., 2007, Proceedings of the International Conference on Computer Vision Systems, P1
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wang X., 2014, Advances in Neural Information Processing Systems, V27, P523
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang YT, 2016, IEEE T MULTIMEDIA, V18, P1604, DOI 10.1109/TMM.2016.2568138
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 66
TC 31
Z9 37
U1 2
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2017
VL 19
IS 7
BP 1531
EP 1544
DI 10.1109/TMM.2017.2679898
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5ZN
UT WOS:000404061800011
DA 2024-07-18
ER

PT J
AU Wang, SP
   Guo, WZ
AF Wang, Shiping
   Guo, Wenzhong
TI Sparse Multigraph Embedding for Multimodal Feature Representation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Feature fusion; graph embedding; machine learning; multimodal data;
   sparse representation
ID DECISION-LEVEL FUSION; FACE RECOGNITION
AB Data fusion is used to integrate features from heterogenous data sources into a consistent and accurate representation for certain learning tasks. As an effective technique for data fusion, unsupervised multimodal feature representation aims to learn discriminative features, indicating the improvement of classification and clustering performance of learning algorithms. However, it is a challenging issue since varying modality favors different structural learning. In this paper, we propose an efficient feature learning method to represent multimodal images as a sparse multigraph structure embedding problem. First, an effective algorithm is proposed to learn a sparse multigraph construction from multimodal data, where each modality corresponds to one regularized graph structure. Second, incorporating the learned multigraph structure, the feature learning problem for multimodal images is formulated as a form of matrix factorization. An efficient corresponding algorithm is developed to optimize the problem and its convergence is also proved. Finally, the proposed method is compared with several state-of-the-art single-modal and multimodal feature learning techniques in eight publicly available face image datasets. Comprehensive experimental results demonstrate that the proposed method outperforms the existing ones in terms of clustering performance for all tested datasets.
C1 [Wang, Shiping; Guo, Wenzhong] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Peoples R China.
   [Wang, Shiping; Guo, Wenzhong] Fuzhou Univ, Fujian Prov Key Lab Network Comp & Intelligent In, Fuzhou 350116, Peoples R China.
   [Wang, Shiping; Guo, Wenzhong] Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou 350003, Peoples R China.
C3 Fuzhou University; Fuzhou University
RP Wang, SP (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Peoples R China.
EM shipingwangphd@163.com; guowenzhong@fzu.edu.cn
FU National Natural Science Foundation of China [61502104, 61672159];
   Fujian Collaborative Innovation Center for Big Data Application in
   Governments; Technology Innovation Platform Project of Fujian Province
   [2014H2005]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61502104 and Grant 61672159, in part by
   the Fujian Collaborative Innovation Center for Big Data Application in
   Governments, and in part by the Technology Innovation Platform Project
   of Fujian Province under Grant 2014H2005. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Winston Hsu.
CR Agrafiotis DK, 2003, J COMPUT CHEM, V24, P1215, DOI 10.1002/jcc.10234
   [Anonymous], 2008, P 2008 INT C CONTENT, DOI DOI 10.1145/1386352.1386373
   Balasubramanian M, 2002, SCIENCE, V295
   Batrinca L, 2016, IEEE T MULTIMEDIA, V18, P659, DOI 10.1109/TMM.2016.2522763
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bowyer KW, 2006, P IEEE, V94, P2000, DOI 10.1109/JPROC.2006.885134
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cai X., 2013, 23 INT JOINT C ART I, P2598
   Chatzis V, 1999, IEEE T SYST MAN CY A, V29, P674, DOI 10.1109/3468.798073
   Chiranjeevi P, 2014, IEEE T IMAGE PROCESS, V23, P645, DOI 10.1109/TIP.2013.2285598
   Collins LM, 2002, INT GEOSCI REMOTE SE, P1556, DOI 10.1109/IGARSS.2002.1026180
   Gray RM, 2011, ENTROPY AND INFORMATION THEORY , SECOND EDITION, P395, DOI 10.1007/978-1-4419-7970-4
   Gunatilaka AH, 2001, IEEE T PATTERN ANAL, V23, P577, DOI 10.1109/34.927459
   Hao S, 2009, IEEE I CONF COMP VIS, P213, DOI 10.1109/ICCV.2009.5459168
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Jiang BH, 2014, INT C PATT RECOG, P1776, DOI 10.1109/ICPR.2014.312
   Kakadiaris IA, 2005, PROC CVPR IEEE, P1022
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li XY, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P897
   Lovasz L., 2009, Matching theory
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Pei Deli., 2013, The 2013 International Joint Conference on Neural Networks (IJCNN), P1
   Perakis P, 2014, PATTERN RECOGN, V47, P2783, DOI 10.1016/j.patcog.2014.03.007
   Romberg S, 2012, INT J MULTIMED INF R, V1, P31, DOI 10.1007/s13735-012-0006-4
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Wang DH, 2013, IMAGE VISION COMPUT, V31, P895, DOI 10.1016/j.imavis.2013.10.002
   Wang H, 2013, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2013.398
   Wang SP, 2018, IEEE T SYST MAN CY-S, V48, P329, DOI 10.1109/TSMC.2016.2605132
   Wang SP, 2015, PATTERN RECOGN, V48, P10, DOI 10.1016/j.patcog.2014.08.004
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wu O, 2016, IEEE T MULTIMEDIA, V18, P1062, DOI 10.1109/TMM.2016.2538722
   Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
NR 42
TC 66
Z9 67
U1 0
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2017
VL 19
IS 7
BP 1454
EP 1466
DI 10.1109/TMM.2017.2663324
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5ZN
UT WOS:000404061800005
DA 2024-07-18
ER

PT J
AU Yamagishi, K
   Hayashi, T
AF Yamagishi, Kazuhisa
   Hayashi, Takanori
TI Parametric Quality-Estimation Model for Adaptive-Bitrate-Streaming
   Services
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Adaptive-bitrate streaming; compression; monitoring; quality; stalling
ID VIDEO-QUALITY; PREDICTION
AB The use of adaptive-bitrate-streaming services over networks has been increasing in recent years. The quality of adaptive-bitrate-streaming services is primarily affected by the video resolution, the audio and video bitrate, bitrate adaptation, stalling due to a lack of playout buffer, and the content length. Therefore, service providers should monitor quality in real time to confirm the normality of their services. To accurately monitor quality, a model that can be used for quality estimation should be developed. To develop such a model, we first conducted extensive subjective quality assessment tests. We then developed a model using the subjective data obtained in the tests. Finally, we verified the performance of the proposed model by applying it to unknown datasets (different from the training datasets used to develop the model) and confirmed its high quality-estimation accuracy.
C1 [Yamagishi, Kazuhisa; Hayashi, Takanori] NTT Corp, NTT Network Technol Labs, Tokyo 1808585, Japan.
C3 Nippon Telegraph & Telephone Corporation
RP Yamagishi, K (corresponding author), NTT Corp, NTT Network Technol Labs, Tokyo 1808585, Japan.
EM yamagishi.kazuhisa@lab.ntt.co.jp; t.hayashi@lab.ntt.co.jp
RI Yamagishi, Kazuhisa/JXY-6414-2024
OI Yamagishi, Kazuhisa/0000-0001-9219-6351
CR Anegekuh L, 2015, IEEE T MULTIMEDIA, V17, P1323, DOI 10.1109/TMM.2015.2444098
   [Anonymous], 2013, PAR NON BITSTR ASS V
   [Anonymous], 2014, 2300912014 ISOIEC
   [Anonymous], 2012, PAR NON ASS AUD MED
   [Anonymous], 2012, ITU T REC P 1201
   [Anonymous], 2011, OBJ PERC MULT VID QU, P341
   [Anonymous], 2008, PERC AUD QUAL MEAS T
   [Anonymous], 2013, AM 2 NEW APP 3 US IT
   [Anonymous], 2016, ADV VID COD GEN AUD
   [Anonymous], 2003, REQ OBJ PERC MULT QU
   [Anonymous], 2012, PAR NON BITSTR ASS V
   [Anonymous], 2004, J144 ITUT INT STAND
   [Anonymous], IEEE ICIP 2005 SEPT
   [Anonymous], 2008, Subjective video quality assessment methods for multimedia applications. Recommendation P.910
   da Silva APC, 2008, IEEE ICC, P22, DOI 10.1109/ICC.2008.13
   Garcia M. N., 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P129, DOI 10.1109/QoMEX.2014.6982308
   Garcia MN, 2013, IEEE INT WORKSH MULT, P482, DOI 10.1109/MMSP.2013.6659336
   Gustafsson J, 2008, IEEE IMAGE PROC, P405, DOI 10.1109/ICIP.2008.4711777
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hayashi T, 2006, IEICE T COMMUN, VE89B, P297, DOI 10.1093/ietcom/e89-b.2.297
   International Telecommunication Union, 2008, OBJ PERC MULT VID QU
   ITU-T, 2016, METH SUBJ ASS VID QU
   ITU-T, 2015, ITU-T Rec. H.265
   Joskowicz J., 2010, IEEE INT WORKSH TECH, P1, DOI DOI 10.1109/CQR.2010.5619912
   Le Callet P, 2006, IEICE T COMMUN, VE89B, P289, DOI 10.1093/ietcom/e89-b.2.289
   Lee SO, 2010, IEEE T CONSUM ELECTR, V56, P1071, DOI 10.1109/TCE.2010.5506041
   Liu Y, 2013, ADV MATH PHYS, V2013, DOI 10.1155/2013/787891
   Liu Y, 2015, IEEE T BROADCAST, V61, P651, DOI 10.1109/TBC.2015.2460611
   Oyman O, 2012, IEEE COMMUN MAG, V50, P20, DOI 10.1109/MCOM.2012.6178830
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Raake A, 2008, INT CONF ACOUST SPEE, P1149, DOI 10.1109/ICASSP.2008.4517818
   Robinson WH., 2015, Proceedings in Research in Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), P1, DOI DOI 10.1109/RESPECT.2015.7296500
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shen Y, 2014, IEEE INT CONF COMM, P551, DOI 10.1109/ICCW.2014.6881256
   Singh KD, 2012, CONSUM COMM NETWORK, P127, DOI 10.1109/CCNC.2012.6181070
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Verscheure O, 1998, IEEE NETWORK, V12, P12, DOI 10.1109/65.752641
   Watanabe K, 2008, IEEE IMAGE PROC, P2060, DOI 10.1109/ICIP.2008.4712191
   Winkler S, 2006, IEEE T MULTIMEDIA, V8, P973, DOI 10.1109/TMM.2006.879871
   Xue YY, 2015, IEEE T MULTIMEDIA, V17, P134, DOI 10.1109/TMM.2014.2368272
   Yamada T, 2009, IEICE T FUND ELECTR, VE92A, P3284, DOI 10.1587/transfun.E92.A.3284
   Yamagishi K, 2013, IEEE INT WORKSH MULT, P464, DOI 10.1109/MMSP.2013.6659333
   Yamagishi K, 2009, IEICE T FUND ELECTR, VE92A, P3297, DOI 10.1587/transfun.E92.A.3297
   Yang FZ, 2005, IEEE SIGNAL PROC LET, V12, P685, DOI 10.1109/LSP.2005.855553
NR 44
TC 40
Z9 42
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2017
VL 19
IS 7
BP 1545
EP 1557
DI 10.1109/TMM.2017.2669859
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5ZN
UT WOS:000404061800012
DA 2024-07-18
ER

PT J
AU Yuan, H
   Guo, C
   Liu, J
   Wang, X
   Kwong, S
AF Yuan, Hui
   Guo, Chenglin
   Liu, Ju
   Wang, Xu
   Kwong, Sam
TI Motion-Homogeneous-Based Fast Transcoding Method From H.264/AVC to HEVC
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE H.264/advanced video coding (AVC); high-efficiency video coding (HEVC);
   low complexity video coding; motion-homogeneous bloc; video transcoding
ID VIDEO TRANSCODER; COMPLEXITY
AB With the popularity of high-efficiency video coding (HEVC) standard, a video server usually transcodes a video stream to HEVC for its higher compression ratio. In this paper, a fast H.264/advanced video coding (AVC) to HEVC transcoding method is proposed. In the HEVC encoding procedure, a coding unit (CU), which is a motion-homogeneous block, is first checked based on the analysis of the decoded information from H.264/AVC bit stream. Then, for motion-homogeneous blocks, CU depth and the corresponding prediction unit (PU) mode's early termination strategies are proposed based on the CU size and corresponding prior statistical knowledge. For non-motion-homogeneous blocks, a corresponding PU mode's early termination strategy is also proposed. Experimental results demonstrate the effectiveness of the proposed method.
C1 [Yuan, Hui; Guo, Chenglin; Liu, Ju] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
   [Wang, Xu] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Shandong University; Shenzhen University; City University of Hong Kong
RP Yuan, H (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
EM huiyuan@sdu.edu.cn; chenglinguo1990@gmail.com; juliu@sdu.edu.cn;
   wangxu@szu.edu.cn; cssamk@cityu.edu.hk
RI Yuan, Hui/HDO-3699-2022; Kwong, Sam/C-9319-2012
OI Yuan, Hui/0000-0001-5212-3393; Kwong, Sam/0000-0001-7484-7261
FU National Natural Science Foundation of China [61571274, 61501299];
   Shandong Natural Science Funds for Distinguished Young Scholar
   [JQ201614]; Young Scholars Program of Shandong University [2015WLJH39]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61571274 and Grant 61501299, in part by
   the Shandong Natural Science Funds for Distinguished Young Scholar under
   Grant JQ201614, and in part by the Young Scholars Program of Shandong
   University under Grant 2015WLJH39. The associate editor coordinating the
   review of this manuscript and approving it for publication was Dr. Ivan
   V. Bajic.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   Bjontegaard G., 2001, P VCEG M JAN
   Bossen F., 2012, P 9 M JCT VC MAY
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chen L, 2015, IEEE T MULTIMEDIA, V17, P485, DOI 10.1109/TMM.2015.2405343
   Chen YS, 2013, IEEE T MULTIMEDIA, V15, P2087, DOI 10.1109/TMM.2013.2280123
   Chen YC, 2015, IEEE T CIRC SYST VID, V25, P1423, DOI 10.1109/TCSVT.2014.2380231
   Choi K., 2011, P 6 M JCT VC JUL
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   De Cock J, 2009, IEEE T MULTIMEDIA, V11, P1209, DOI 10.1109/TMM.2009.2030606
   Dong Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P651, DOI 10.1109/ICME.2012.112
   Feller C., 2014, P INT C CONS EL OCT, P57
   Fernández-Escribano G, 2010, IEEE T CIRC SYST VID, V20, P763, DOI 10.1109/TCSVT.2010.2045914
   Franche JF, 2015, IEEE IMAGE PROC, P477, DOI 10.1109/ICIP.2015.7350844
   Fung KT, 2004, IEEE T MULTIMEDIA, V6, P31, DOI 10.1109/TMM.2003.819761
   Díaz-Honrubia AJ, 2016, IEEE T CIRC SYST VID, V26, P154, DOI 10.1109/TCSVT.2015.2473299
   Jiang W, 2013, ELECTRON LETT, V49, DOI 10.1049/el.2013.0329
   Jiang W, 2014, MULTIMED TOOLS APPL, V73, P2179, DOI 10.1007/s11042-013-1675-6
   Jung H, 2014, PROC CVPR IEEE, P1210, DOI 10.1109/CVPR.2014.158
   Kunzelmann P, 2007, IEEE ICCE, P133
   Van LP, 2016, IEEE T MULTIMEDIA, V18, P364, DOI 10.1109/TMM.2015.2512231
   Ma S., 2014, P IEEE INT C IM PROC, P1500
   Peixoto E, 2014, IEEE IMAGE PROC, P2532, DOI 10.1109/ICIP.2014.7025512
   Peixoto E, 2013, IEEE IMAGE PROC, P1972, DOI 10.1109/ICIP.2013.6738406
   Peixoto E., 2014, P IEEE INT C TEL S A, P2532
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   Peixoto E, 2012, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2012.6466965
   Rijkse K, 1996, IEEE COMMUN MAG, V34, P42, DOI 10.1109/35.556485
   Shanableh T, 2008, SIGNAL PROCESS-IMAGE, V23, P610, DOI 10.1016/j.image.2008.05.005
   Shanableh T, 2013, IEEE T CIRC SYST VID, V23, P1191, DOI 10.1109/TCSVT.2013.2241352
   Shen HF, 2008, IEEE T CIRC SYST VID, V18, P746, DOI 10.1109/TCSVT.2008.918783
   Shu HY, 2006, IEEE T CIRC SYST VID, V16, P540, DOI 10.1109/TCSVT.2006.871324
   Sikora T, 1997, IEEE SIGNAL PROC MAG, V14, P82, DOI 10.1109/79.618010
   Smith JR, 2007, IEEE MULTIMEDIA, V14, P88, DOI 10.1109/MMUL.2007.86
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wang XF, 2013, IEEE T MULTIMEDIA, V15, P811, DOI 10.1109/TMM.2013.2239630
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xing P., 2013, Visual Communications and Image Processing (VCIP), 2013, P1
   Xu D, 2009, IEEE IMAGE PROC, P3693, DOI 10.1109/ICIP.2009.5414225
   Zheng F., 2014, P IEEE INT C AUD LAN, P765
   Zhu LW, 2016, J VIS COMMUN IMAGE R, V38, P824, DOI 10.1016/j.jvcir.2016.04.020
   Zhu YM, 2014, SIGNAL PROCESS-IMAGE, V29, P875, DOI 10.1016/j.image.2014.06.005
NR 43
TC 25
Z9 27
U1 0
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2017
VL 19
IS 7
BP 1416
EP 1430
DI 10.1109/TMM.2017.2669858
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5ZN
UT WOS:000404061800002
DA 2024-07-18
ER

PT J
AU Kwak, CH
   Bajic, IV
AF Kwak, Choong-Hoon
   Bajic, Ivan V.
TI Online MoCap Data Coding With Bit Allocation, Rate Control, and
   Motion-Adaptive Post-Processing
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Bit allocation; low-delay compression; motion capture (MoCap);
   motion-adaptive filtering; rate control
ID COMPRESSION; REPRESENTATION; QUANTIZATION; MEMORYLESS; LATENCY
AB With the advancements in methods for capturing 3D object motion, motion capture (MoCap) data are starting to be used beyond their traditional realm of animation and gaming in areas such as the arts, rehabilitation, automotive industry, remote interactions, and so on. As the amount of MoCap data increase, compression becomes crucial for further expansion and adoption of these technologies. In this paper, we extend our previous work on low-delay MoCap data compression by introducing two improvements. The first improvement is the bit allocation to long-term and short-term reference MoCap frames, which provides a 10-15% reduction in coded bit rate at the same quality. The second improvement is the post-processing in the form of motion-adaptive temporal low-pass filtering, which is able to provide another 9-13% savings in the bit rate. The experimental results also indicate that the proposed online MoCap codec is competitive with several state-of-the-art offline codecs. Overall, the proposed techniques integrate into a highly effective online MoCap codec that is suitable for lowdelay applications, whose implementation is provided alongside this paper to aid further research in the field.
C1 [Kwak, Choong-Hoon; Bajic, Ivan V.] Simon Fraser Univ, Sch Engn Sci, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Kwak, CH (corresponding author), Simon Fraser Univ, Sch Engn Sci, Burnaby, BC V5A 1S6, Canada.
EM cka21@sfu.ca; ibajic@ensc.sfu.ca
RI Bajic, Ivan/I-1241-2013
OI Bajic, Ivan/0000-0003-3154-5743
CR Andreadis Anthousis, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P148, DOI 10.1109/PCI.2010.14
   [Anonymous], 2012, ITU-R BT.500-13
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 1977, DISCRETE TIME SIGNAL
   [Anonymous], 2001, ITU T VCEG M AUST TE
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Azuma R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P401, DOI 10.1145/218380.218496
   Beaudoin Philippe, 2007, Proceedings Graphics Interface 2007, P313, DOI 10.1145/1268517.1268568
   Chattopadhyay S, 2007, IEEE T VIS COMPUT GR, V13, P5, DOI 10.1109/TVCG.2007.13
   Cheng I, 2015, COMPUT GRAPH-UK, V51, P1, DOI 10.1016/j.cag.2015.05.002
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Dobrian C., 2003, Proceedings of the 2003 Conference on New Interfaces for Musical Expression, P161, DOI [10.5555/1085714.1085753, DOI 10.5555/1085714.1085753]
   Firouzmanesh A, 2011, IEEE T MULTIMEDIA, V13, P829, DOI 10.1109/TMM.2011.2129497
   Gersho A., 2003, Vector Quantization and Signal Compression
   Hou JH, 2016, COMPUT AIDED GEOM D, V43, P211, DOI 10.1016/j.cagd.2016.02.002
   Hou JH, 2015, IEEE T VIS COMPUT GR, V21, P848, DOI 10.1109/TVCG.2015.2403328
   Hou JH, 2014, IEEE SIGNAL PROC LET, V21, P255, DOI 10.1109/LSP.2014.2299284
   HULSKEN F, 2007, INT J VIRTUAL REALIT, V6, P11
   IFEACHOR E.C., 1993, Digital Signal Processing - A Pratical Approach
   Jovanova Blagica, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P101, DOI 10.1109/3DTV.2008.4547818
   Kao JY, 2014, IEEE IMAGE PROC, P2061, DOI 10.1109/ICIP.2014.7025413
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Kwak C.-H., 2011, IEEE INT C AC SPEECH, P1
   Kwak C.-H., 2011, P IEEE INT C MULT EX, P1
   Kwak CH, 2013, INT CONF ACOUST SPEE, P3741, DOI 10.1109/ICASSP.2013.6638357
   Lee CH, 2008, LECT NOTES COMPUT SC, V5358, P75
   Li SY, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/693427
   Lin IC, 2011, IEEE T VIS COMPUT GR, V17, P527, DOI 10.1109/TVCG.2010.87
   Mokaya F, 2012, P 10 ACM C EMB NETW, P385, DOI [10.1145/2426656.2426721, DOI 10.1145/2426656.2426721]
   Preda M, 2007, WEB3D 2007 - 12TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, PROCEEDINGS, P181
   Raaen K., 2014, 2014 13th Annual Workshop on Network and Systems Support for Games, P1
   Servais M., 2004, RANGE CODING MATLAB
   SHEININ V, 2006, INT CONF ACOUST SPEE, P217
   Sheinin V., 2006, P IEEE INT C AC SPEE, pIV
   Sheinin V, 2006, IEEE IMAGE PROC, P793, DOI 10.1109/ICIP.2006.312521
   Stark H., 2012, Probability, Statistics, and Random processes for engineers, V4th
   Tournier M, 2009, COMPUT GRAPH FORUM, V28, P355, DOI 10.1111/j.1467-8659.2009.01375.x
   Vása L, 2014, COMPUT GRAPH FORUM, V33, P283, DOI 10.1111/cgf.12326
   Wade E., 2009, 2009 3 INT C PERV CO, P1
   Wu Q., 2010, P 2010 ACM WORKSH SU, P3, DOI [10.1145/1878083.1878087, DOI 10.1145/1878083.1878087]
NR 40
TC 4
Z9 4
U1 1
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2017
VL 19
IS 6
BP 1127
EP 1141
DI 10.1109/TMM.2017.2655423
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5YS
UT WOS:000404059400002
OA Green Published
DA 2024-07-18
ER

PT J
AU Pourashraf, P
   Safaei, F
AF Pourashraf, Pedram
   Safaei, Farzad
TI Perceptual Pruning: A Context-Aware Transcoder for Immersive Video
   Conferencing Systems
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Immersive video conferencing (IVC); video compression; scalable video
   coding; video transmission; video conferencing; discrete cosine
   transform (DCT) masking
ID QUALITY; TREES
AB This paper proposes the concept of perceptual pruning to improve the scalability of immersive video conferencing (IVC) systems. The aim of perceptual pruning is to enable servers to dynamically reduce the bit rate of videos on-the-fly in response to changes in virtual distance and orientation of videos with respect to the receiving client. It is shown that the video of each participant will have to undergo varying degrees of texture to pixel mapping before it is rendered by the client. By reducing the resolution of the video at the scale of each transform block in response to nuances of this mapping, the video bit rate could be reduced without any noticeable degradation of quality. This paper presents the results of experimental tests and also real-world scalability tests to quantify the impact of perceptual pruning. It is concluded that perceptual pruning will be of significant benefit, especially in those situations when the number of videos in the client's viewpoint is large.
C1 [Pourashraf, Pedram; Safaei, Farzad] Univ Wollongong, Informat & Commun Technol Res Inst, Wollongong, NSW 2522, Australia.
C3 University of Wollongong
RP Pourashraf, P (corresponding author), Univ Wollongong, Informat & Commun Technol Res Inst, Wollongong, NSW 2522, Australia.
EM pedram.pourashraf@gmail.com; farzad@uow.edu.au
OI Safaei, Farzad/0000-0002-4322-4448
FU Smart Services Cooperative Research Center, Sydney, NSW, Australia
FX This work was supported by the Smart Services Cooperative Research
   Center, Sydney, NSW, Australia. The guest editor coordinating the review
   of this manuscript and approving it for publication was Dr. Sanjeev
   Mehrotra.
CR Akyol E., 2005, P IEEE INT C IM PROC, V3
   [Anonymous], 2016, P PICT COD S PCS
   [Anonymous], 2016, VID SIM SMALL M
   [Anonymous], 2016, ISEE REC EV 56 PART
   [Anonymous], 2016, THE PRUN VID
   [Anonymous], 2015, ISEE ENG PITCH VID
   Belyaev E, 2013, IEEE T MULTIMEDIA, V15, P1786, DOI 10.1109/TMM.2013.2269315
   Civanlar M. R., 1992, Proceedings of the SPIE - The International Society for Optical Engineering, V1818, P1124, DOI 10.1117/12.131384
   Eeckhaut H, 2007, IEEE T MULTIMEDIA, V9, P1508, DOI 10.1109/TMM.2007.906606
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   Khelifi F, 2008, IEEE T MULTIMEDIA, V10, P316, DOI 10.1109/TMM.2008.917357
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Lan T.-h., 2006, U.S. Patent, Patent No. [7 020 672, 7020672]
   Mattavelli M, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P330, DOI 10.1109/ICIP.1997.647773
   Naman A. T., 2007, P IEEE INT C IM PROC, V5
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Parisot C, 2003, EURASIP J APPL SIG P, V2003, P56, DOI 10.1155/S1110865703210064
   Pearlman WA, 1998, SPRING INT SER ENG C, V450, P397
   Ponec M, 2009, IEEE INT CON MULTI, P1406, DOI 10.1109/ICME.2009.5202767
   Pourashraf P., IEEE J SEL IN PRESS
   Pourashraf P, 2014, IEEE INT CON MULTI, DOI 10.1109/ICME.2014.6890152
   Pourashraf P, 2012, IEEE INT CONF MULTI, P139, DOI 10.1109/ICMEW.2012.31
   Safaei F, 2014, IEEE COMMUN MAG, V52, P66, DOI 10.1109/MCOM.2014.6871672
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Zrida H.K., 2011, RECENT ADV VIDEO COD
NR 27
TC 2
Z9 3
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2017
VL 19
IS 6
BP 1327
EP 1338
DI 10.1109/TMM.2017.2652860
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5YS
UT WOS:000404059400017
DA 2024-07-18
ER

PT J
AU Li, JN
   Wei, YC
   Liang, XD
   Dong, J
   Xu, TF
   Feng, JS
   Yan, SC
AF Li, Jianan
   Wei, Yunchao
   Liang, Xiaodan
   Dong, Jian
   Xu, Tingfa
   Feng, Jiashi
   Yan, Shuicheng
TI Attentive Contexts for Object Detection
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Context; neural networks; object detection
AB Modern deep neural network-based object detection methods typically classify candidate proposals using their interior features. However, global and local surrounding contexts that are believed to be valuable for object detection are not fully exploited by existing methods yet. In this work, we take a step towards understanding what is a robust practice to extract and utilize contextual information to facilitate object detection in practice. Specifically, we consider the following two questions: "how to identify useful global contextual information for detecting a certain object?" and "how to exploit local context surrounding a proposal for better inferring its contents?" We provide preliminary answers to these questions through developing a novel attention to context convolution neural network (AC-CNN)-based object detection model. AC-CNN effectively incorporates global and local contextual information into the region-based CNN (e.g., fast R-CNN and faster R-CNN) detection framework and provides better object detection performance. It consists of one attention-based global contextualized (AGC) subnetwork and one multi-scale local contextualized (MLC) subnetwork. To capture global context, the AGC subnetwork recurrently generates an attention map for an input image to highlight useful global contextual locations, through multiple stacked long short-term memory layers. For capturing surrounding local context, the MLC subnetwork exploits both the inside and outside contextual information of each specific proposal at multiple scales. The global and local context are then fused together for making the final decision for detection. Extensive experiments on PASCAL VOC 2007 and VOC 2012 well demonstrate the superiority of the proposed AC-CNN over well-established baselines.
C1 [Li, Jianan; Xu, Tingfa] Beijing Inst Technol, Sch Opt Engn, Beijing 100081, Peoples R China.
   [Wei, Yunchao] Beijing Jiaotong Univ, Beijing 100044, Peoples R China.
   [Liang, Xiaodan] Sun Yat Sen Univ, Guangzhou 510006, Guangdong, Peoples R China.
   [Dong, Jian; Feng, Jiashi; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore.
C3 Beijing Institute of Technology; Beijing Jiaotong University; Sun Yat
   Sen University; National University of Singapore
RP Xu, TF (corresponding author), Beijing Inst Technol, Sch Opt Engn, Beijing 100081, Peoples R China.
EM 20090964@bit.edu.cn; wychao1987@gmail.com; xdliang328@gmail.com;
   timeflydj@gmail.com; 15210538723@163.com; jshfeng@gmail.com;
   eleyans@nus.edu.sg
RI Dong, Jian/AAR-8670-2021; Feng, Jiashi/AGX-6209-2022; Yan,
   Shuicheng/HCI-1431-2022
FU China Scholarship Council [201506030045]
FX This work was supported in part by the China Scholarship Council under
   Grant 201506030045. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Shu-Ching Chen.
   (Corresponding author: Tingfa Xu.)
CR [Anonymous], CORR
   [Anonymous], 2007, 2007 IEEE 11 INT C C
   [Anonymous], 2015, CORR ABS150602640
   [Anonymous], 2015, CORR
   [Anonymous], 2015, P ICLR
   [Anonymous], CORR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2013, CoRR
   [Anonymous], 2015, CORR
   [Anonymous], CORR
   [Anonymous], 2015, CORR
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Bell S., 2015, CoRR
   Chen Q, 2015, IEEE T PATTERN ANAL, V37, P13, DOI 10.1109/TPAMI.2014.2343217
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Qi GJ, 2010, IEEE T MULTIMEDIA, V12, P278, DOI 10.1109/TMM.2010.2046270
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Simonyan K., 2014, CORR
   Stewart Russell., 2015, CoRR
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Venugopalan S., 2014, CoRR, Vabs/1412.4729
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Xu K., 2015, COMPUTER SCI, P2048
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhu YK, 2014, IEEE T MULTIMEDIA, V16, P1585, DOI 10.1109/TMM.2014.2321534
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 39
TC 163
Z9 176
U1 6
U2 72
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2017
VL 19
IS 5
BP 944
EP 954
DI 10.1109/TMM.2016.2642789
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EY5XS
UT WOS:000404056000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU de Souza, DF
   Ilic, A
   Roma, N
   Sousa, L
AF de Souza, Diego F.
   Ilic, Aleksandar
   Roma, Nuno
   Sousa, Leonel
TI GHEVC: An Efficient HEVC Decoder for Graphics Processing Units
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Graphics processor units (GPUs); high efficiency video coding (HEVC);
   parallel processing; real-time; video decoding
ID IMPLEMENTATION
AB The high compression efficiency that is provided by the high efficiency video coding (HEVC) standard comes at the cost of a significant increase of the computational load at the decoder. Such an increased burden is a limiting factor to accomplish realtime decoding, specially for high definition video sequences (e.g., Ultra HD 4K). In this scenario, a highly parallel HEVC decoder for the state-of-the-art graphics processor units (GPUs) is presented, i. e., GHEVC. Contrasting to our previous contributions, the dataparallel GHEVC decoder integrates the whole decompression pipeline (except for the entropy decoding), both for intra-and interframes. Furthermore, its processing efficiency was highly optimized by keeping the decompressed frames in the GPU memory for subsequent inter frame prediction. The proposed GHEVC decoder is fully compliant with the HEVC standard, where explicit synchronization points ensure the correct HEVC module execution order. Moreover, the GPU-based HEVC decoder is experimentally evaluated for different GPU devices, an extensive range of recommendedHEVC configurations and video sequences, where an average frame rate of 145, 318, and 605 frames per second for Ultra HD 4K, WQXGA, and Full HD, respectively, was obtained in the Random Access configuration with the NVIDIA GeForce GTX TITAN X GPU.
C1 [de Souza, Diego F.; Ilic, Aleksandar; Roma, Nuno; Sousa, Leonel] Univ Lisbon, Inst Super Tecn, INESC ID, P-1000029 Lisbon, Portugal.
C3 INESC-ID; Universidade de Lisboa
RP de Souza, DF (corresponding author), Univ Lisbon, Inst Super Tecn, INESC ID, P-1000029 Lisbon, Portugal.
EM difs@sips.inesc-id.pt; ilic@sips.inesc-id.pt; nuno.roma@inesc-id.pt;
   las@inesc-id.pt
RI Roma, Nuno/AAD-1997-2022; Ilic, Aleksandar/AAF-3831-2021; Sousa,
   Leonel/B-2749-2009
OI Roma, Nuno/0000-0003-2491-4977; Ilic, Aleksandar/0000-0002-8594-3539;
   Sousa, Leonel/0000-0002-8066-221X
FU National Funds through Fundacao para a Ciencia e a Tecnologia (FCT)
   [PTDC/EEI-ELC/3152/2012, UID/CEC/50021/2013]; FCT [SFRH/BD/76285/2011];
   Fundação para a Ciência e a Tecnologia [PTDC/EEI-ELC/3152/2012,
   SFRH/BD/76285/2011] Funding Source: FCT
FX This work was supported by the National Funds through Fundacao para a
   Ciencia e a Tecnologia (FCT) under Project PTDC/EEI-ELC/3152/2012 and
   Project UID/CEC/50021/2013. The work of D. F. de Souza was supported by
   the FCT under the Ph.D. scholarship SFRH/BD/76285/2011.
CR Abeydeera M, 2016, IEEE T CIRC SYST VID, V26, P236, DOI 10.1109/TCSVT.2015.2469113
   [Anonymous], 230082 JCTVC ISOIEC
   [Anonymous], NVIDIA VID DEC NVDEC
   [Anonymous], 2015, P IEEE INT C MULT EX
   [Anonymous], NVIDIA COMP UN DEV A
   [Anonymous], 2006, SVT HIGH DEFINITION
   [Anonymous], 2014, SUBV REP HEVC TEST M
   [Anonymous], 2013, Technical Report JCTVC-L1100
   [Anonymous], OP SOURC HEVC DEC OP
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chavarrías M, 2015, IEEE T CONSUM ELECTR, V61, P236, DOI 10.1109/TCE.2015.7150599
   Chi CC, 2015, IEEE T CIRC SYST VID, V25, P841, DOI 10.1109/TCSVT.2014.2364413
   de Souza Diego F., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4993, DOI 10.1109/ICASSP.2014.6854552
   de Souza DF, 2016, J REAL-TIME IMAGE PR, V12, P531, DOI 10.1007/s11554-015-0519-1
   de Souza DF, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1245, DOI 10.1109/GlobalSIP.2015.7418397
   Souza DF, 2014, EUR SIGNAL PR CONF, P755
   Duan YZ, 2014, IEEE T MULTIMEDIA, V16, P1915, DOI 10.1109/TMM.2014.2337834
   Eldeken AF, 2015, IEEE IMAGE PROC, P1538, DOI 10.1109/ICIP.2015.7351058
   Engelhardt D, 2014, IEEE T CONSUM ELECTR, V60, P476, DOI 10.1109/TCE.2014.6937333
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   He LP, 2014, I S INTELL SIG PROC, P211, DOI 10.1109/ISPACS.2014.7024454
   Jiang WB, 2016, CONCURR COMP-PRACT E, V28, P4264, DOI 10.1002/cpe.3751
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Liu TM, 2015, IEEE INT CON MULTI
   Momcilovic S, 2014, IEEE T MULTIMEDIA, V16, P108, DOI 10.1109/TMM.2013.2284892
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tikekar M, 2014, IEEE J SOLID-ST CIRC, V49, P61, DOI 10.1109/JSSC.2013.2284362
   Xiao W, 2015, IEEE T CIRC SYST VID, V25, P1830, DOI 10.1109/TCSVT.2015.2406199
NR 31
TC 20
Z9 20
U1 1
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2017
VL 19
IS 3
BP 459
EP 474
DI 10.1109/TMM.2016.2625261
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EN2VW
UT WOS:000395869400004
DA 2024-07-18
ER

PT J
AU Silva, PM
   Pappas, TN
   Atkins, J
   West, JE
AF Silva, Pubudu Madhawa
   Pappas, Thrasyvoulos N.
   Atkins, Joshua
   West, James E.
TI Perceiving Graphical and Pictorial Information via Hearing and Touch
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Acoustic-tactile representation of visual signals; semantic mapping;
   sensory substitution; user interface
ID ARTIFICIAL VISION; SOUND; LOCALIZATION; RECOGNITION; DISPLAYS; SYSTEM
AB We propose a dynamic interactive system for conveying visual information via hearing and touch to blind and visually impaired people. The system is implemented with a touch screen that allows the user to actively explore a two-dimensional layout consisting of one or more objects with the finger while listening to auditory feedback. Sound is used as the primary source of information for object localization, identification, and shape, while touch is used for pointing and kinesthetic feedback. A static overlay of raised-dot tactile patterns can also be added. The head-related transfer function is used for rendering sound directionality, and variations of sound intensity or other features are used for rendering proximity. The main focus is on conveying the shape of an object, but the rendering of a simple scene layout, that consists of objects in a linear arrangement, each with a distinct tapping sound, is also considered and compared to a "virtual cane." We consider a number of acoustic-tactile configurations and use empirical studies with visually blocked sighted participants to compare their effectiveness. Our findings demonstrate the advantages of spatial sound (directionality and proximity cues) for dynamic display of information (localization, identification, shape), while raised-dot patterns provide the best static shape rendition. We also show that the proposed configurations outperform existing techniques. The proposed approach is also expected to impact other applications where vision cannot be used.
C1 [Silva, Pubudu Madhawa] Intel Corp, Hillsboro, OR 97124 USA.
   [Pappas, Thrasyvoulos N.] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
   [Atkins, Joshua] Apple Inc, Culver City, CA 90232 USA.
   [West, James E.] Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA.
C3 Intel Corporation; Northwestern University; Apple Inc; Johns Hopkins
   University
RP Silva, PM (corresponding author), Intel Corp, Hillsboro, OR 97124 USA.
EM pubudu@u.northwestern.edu; pappas@eecs.northwestern.edu;
   joshatkins@gmail.com; jimwest@jhu.edu
RI Pappas, Thrasyvoulos N/GWV-5517-2022; Pappas, Thrasyvoulos N/B-7261-2009
OI Pappas, Thrasyvoulos N/0000-0002-4598-2197; 
CR Algazi VR, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P99, DOI 10.1109/ASPAA.2001.969552
   [Anonymous], 1998, P CONTENT VISUALIZAT
   [Anonymous], 1994, P 1 ANN C ASS TECHN, DOI DOI 10.1145/191028.191051
   [Anonymous], 2011, THESIS
   [Anonymous], 1988, PROC 2 INT S MAPS GR
   Aysal TC, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P469
   Bach-y-Rita P., 2002, U.S. Patent, Patent No. [6430450, 6,430,450]
   BACHYRITA P, 1972, BRAIN MECHANISMS SEN, P1
   Bau O., 2010, P 23 ANN ACM S US IN, P283, DOI DOI 10.1145/1866029.1866074
   Blauert J., 1997, SPATIAL HEARING PSYC
   Blenkhorn P., 1994, P 9 INT C TECHN PERS, P24
   Chader GJ, 2009, PROG BRAIN RES, V175, P317, DOI 10.1016/S0079-6123(09)17522-2
   Chen JQ, 2005, IEEE T IMAGE PROCESS, V14, P1524, DOI 10.1109/TIP.2005.852204
   Chubb EC, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P18, DOI 10.1109/WHC.2009.4810861
   DOBELLE WH, 1974, SCIENCE, V183, P440, DOI 10.1126/science.183.4123.440
   Doel K., 2004, P 10 M INT C AUD DIP, P1
   Downing D., 2010, BARRONS ED SERIES
   FISHER H G, 1968, Journal of Auditory Research, V8, P15
   Giudice N. A., 2012, P 14 INT ACM SIGACCE, P103, DOI [DOI 10.1145/2384916.2384935, 10.1145/2384916.2384935]
   Gourgey K., 2006, COMMUNICATION
   Henderson JM, 2003, TRENDS COGN SCI, V7, P498, DOI 10.1016/j.tics.2003.09.006
   Hernandez SergioE., 2000, ACM SIGACCESS Conference on Computers and Accessibility, P26
   Ihlefeld A, 2011, J ACOUST SOC AM, V130, P324, DOI 10.1121/1.3596476
   Israr A., 2012, P 2012 ACM ANN C EXT, P1571, DOI DOI 10.1145/2212776.2223674
   Kajomoto H., 2006, P INT C EUR, P75
   KLATZKY RL, 1993, PERCEPT PSYCHOPHYS, V54, P170, DOI 10.3758/BF03211752
   Klatzky RL, 2014, MULTISENS RES, V27, P359, DOI 10.1163/22134808-00002447
   LAMBERT RM, 1974, J ACOUST SOC AM, V56, P165, DOI 10.1121/1.1903248
   Landau S., 2003, EUROHAPTICS 03, VVolume 3, P414
   Lederman SJ, 2011, IEEE T HAPTICS, V4, P273, DOI 10.1109/ToH.2011.2
   Loomis J.M., 2012, Assistive Technology for Blindness and Low Vision
   Loomis JM, 2005, J VISUAL IMPAIR BLIN, V99, P219, DOI 10.1177/0145482x0509900404
   LOOMIS JM, 1991, PERCEPTION, V20, P167, DOI 10.1068/p200167
   LOOMIS JM, 1981, PERCEPTION, V10, P5, DOI 10.1068/p100005
   Marchuk Nicholas D., 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P317, DOI 10.1109/HAPTIC.2010.5444636
   MEIJER PBL, 1992, IEEE T BIO-MED ENG, V39, P112, DOI 10.1109/10.121642
   Nayak A, 2004, IEEE T NEUR SYS REH, V12, P216, DOI 10.1109/TNSRE.2003.819885
   O'Modhrain S, 2015, IEEE T HAPTICS, V8, P248, DOI 10.1109/TOH.2015.2466231
   Palani H.P., 2014, P 16 INT ACM SIGACCE, DOI [10.1145/2661334.2661336, DOI 10.1145/2661334.2661336]
   PAPPAS TN, 1992, IEEE T SIGNAL PROCES, V40, P901, DOI 10.1109/78.127962
   Parente P., 2003, ACM S E C ACMSE MAR, P11
   Poppinga B., 2011, P 13 INT C HUM COMP, P545, DOI [DOI 10.1145/2037373.2037458, 10.1145/2037373.2037458]
   RAKERD B, 1985, J ACOUST SOC AM, V78, P524, DOI 10.1121/1.392474
   Reedstrom R. J., TREMOLO EFFECT
   Ribeiro F, 2012, IEEE INT WORKSH MULT, P319, DOI 10.1109/MMSP.2012.6343462
   Hernández AFR, 2009, PROCEEDINGS OF THE 8TH WSEAS INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, MAN-MACHINE SYSTEMS AND CYBERNETICS (CIMMACS '09), P134
   Sanders AFJ, 2007, PERCEPTION, V36, P1682, DOI 10.1068/p5638
   Steinberg W.J., 2011, Statistics alive, V2nd
   Su J, 2010, INT CONF COMPUT AUTO, P177, DOI 10.1109/ICCAE.2010.5452046
   Tartter V. C., 2008, COMMUNICATION
   Thompson LJ, 2003, PERCEPTION, V32, P887, DOI 10.1068/p5020
   Tran TV, 2000, ERGONOMICS, V43, P807, DOI 10.1080/001401300404760
   v d Doel K., 2003, Proceedings of the 2003 International Conference on Auditory Display, P303
   Wijntjes MWA, 2008, ACTA PSYCHOL, V128, P255, DOI 10.1016/j.actpsy.2008.01.006
   Wijntjes MWA, 2008, PERCEPTION, V37, P602, DOI 10.1068/p5714
   Winfield L, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P421
   Xu C., 2011, P 2011 ANN C EXTENDE, P317, DOI DOI 10.1145/1979742.1979705
   ZWICKER E, 1952, ACUSTICA, V2, pAB125
NR 58
TC 6
Z9 8
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2016
VL 18
IS 12
BP 2432
EP 2445
DI 10.1109/TMM.2016.2601029
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA ED5VK
UT WOS:000388920200010
DA 2024-07-18
ER

PT J
AU Liang, LM
   Wei, MQ
   Szymczak, A
   Pang, WM
   Wang, M
AF Liang, Luming
   Wei, Mingqiang
   Szymczak, Andrzej
   Pang, Wai-Man
   Wang, Meng
TI Spin Contour
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Descriptor; rigid registration; shape matching; spin contour; spin image
ID REGISTRATION; RECOGNITION; IMAGES; RETRIEVAL; OBJECTS
AB Spin image is a powerful shape descriptor, useful in a point set or surface registration. However, the usage of spin images is hampered by issues such as sensitivity to noise and sampling rate and time-consuming matching process. We propose a novel spin-image-based local surface descriptor named spin contour to alleviate these problems. This descriptor is not an image but a 2-D point set. Comparisons showthat the spin contour is robust to noise and sampling differences. The matching time is also improved over spin images.
C1 [Liang, Luming; Szymczak, Andrzej] Colorado Sch Mines, Dept Elect Engn & Comp Sci, Golden, CO 80401 USA.
   [Wei, Mingqiang; Wang, Meng] Hefei Univ Technol, Sch Instrumental Sci & Optoelect Engn, Hefei 230009, Peoples R China.
   [Wei, Mingqiang; Wang, Meng] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China.
   [Pang, Wai-Man] Caritas Inst Higher Educ, Sch Comp & Informat Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Colorado School of Mines; Hefei University of Technology; Hefei
   University of Technology; Saint Francis University Hong Kong
RP Wei, MQ (corresponding author), Hefei Univ Technol, Sch Instrumental Sci & Optoelect Engn, Hefei 230009, Peoples R China.; Wei, MQ (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China.
EM llmpass@gmail.com; mingqiang.wei@gmail.com; acszymczak@gmail.com;
   wmpang@ieee.org; eric.mengwang@gmail.com
RI Liang, Luming/E-3371-2016; Wang, Meng/ITR-8699-2023
OI Liang, Luming/0000-0002-1127-2568; Wei, Mingqiang/0000-0003-0429-490X
FU National Natural Science Foundation of China [61322201, 61432019,
   61502137]; RGC of the HKSAR of China [UGC/FDS11/E03/14]; China
   Postdoctoral Science Foundation [2016M592047]; Open Project Program of
   the State Key Lab of CAD&CG, Zhejiang University [A1604]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61322201, Grant 61432019, and Grant
   61502137, by the RGC of the HKSAR of China under Grant UGC/FDS11/E03/14,
   by the China Postdoctoral Science Foundation under Grant 2016M592047,
   and by the Open Project Program of the State Key Lab of CAD&CG, Zhejiang
   University under Grant A1604. The guest editor coordinating the review
   of this manuscript and approving it for publication was Dr. Nan Cao.
   (Luming Liang and Mingqiang Wei contributed equally to this work.)
   (Corresponding author: Mingqiang Wei.)
CR [Anonymous], 2010, ANN: a library for approximate nearest neighbor searching
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P INT C REC ADV 3 D
   Assfalg J, 2007, IEEE T MULTIMEDIA, V9, P589, DOI 10.1109/TMM.2006.886271
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Bariya P, 2012, INT J COMPUT VISION, V99, P232, DOI 10.1007/s11263-012-0526-7
   Bariya P, 2010, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2010.5539774
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Campbell RJ, 2002, INT C PATT RECOG, P607, DOI 10.1109/ICPR.2002.1048012
   Carmichael O., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P358, DOI 10.1109/IM.1999.805366
   Chang W, 2009, COMPUT GRAPH FORUM, V28, P447, DOI 10.1111/j.1467-8659.2009.01384.x
   Chang W, 2008, COMPUT GRAPH FORUM, V27, P1459, DOI 10.1111/j.1467-8659.2008.01286.x
   Chang W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966405
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Dinh H.Q., 2006, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, V1, P863
   Guo YL, 2014, IEEE T MULTIMEDIA, V16, P1377, DOI 10.1109/TMM.2014.2316145
   Johnson AE, 1998, PROC CVPR IEEE, P671, DOI 10.1109/CVPR.1998.698676
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kolonias I, 2005, IEEE T MULTIMEDIA, V7, P114, DOI 10.1109/TMM.2004.840605
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Novatnack J., 2007, PROC IEEE 11 INT C C, P1
   Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33
   Raviv D, 2011, COMPUT GRAPH-UK, V35, P692, DOI 10.1016/j.cag.2011.03.030
   Raviv Dan., 2010, Proceedings of the ACM workshop on 3D object retrieval, P1704
   Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tabia H, 2015, IEEE T MULTIMEDIA, V17, P1591, DOI 10.1109/TMM.2015.2457676
   Tombari Federico., 2010, P 11 EUROPEAN C COMP, P352
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Zhang ZY, 2012, IEEE IMAGE PROC, P537, DOI 10.1109/ICIP.2012.6466915
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 35
TC 5
Z9 6
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2016
VL 18
IS 11
BP 2282
EP 2292
DI 10.1109/TMM.2016.2614219
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA EA9BX
UT WOS:000386936900015
DA 2024-07-18
ER

PT J
AU Lee, B
   Jung, J
   Kim, M
AF Lee, Bumshik
   Jung, Jaehong
   Kim, Munchurl
TI An All-Zero Block Detection Scheme for Low-Complexity HEVC Encoders
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE All-zero block (AZB) detection; discrete cosine transform (DCT);
   Hadamard transform; high-efficiency video coding (HEVC)
ID CU SIZE DECISION; QUANTIZED DCT COEFFICIENTS; MODE DECISION; VIDEO;
   ALGORITHM; H.264; PREDICTION; TRANSFORMS; STANDARD; LEVEL
AB In this paper, an all-zero block detection scheme is proposed prior to DCT to reduce the encoding complexity for high efficiency video coding (HEVC). Since many coding blocks tend to have all zero coefficients after DCT and quantization, it is worthwhile to detect all-zero-quantized blocks for input residual blocks before DCT so that subsequent transform and quantization can be skipped. Unlike previous coding standards, HEVC adopts large transform sizes such as 16 x 16 and 32 x 32 in addition to 4 x 4 and 8 x 8. It becomes more difficult to accurately detect all-zero blocks in HEVC because the large transform blocks contains more variety of content characteristics than smaller ones, thus making it ineffective the existing allzero block (AZB) detection schemes for large transform blocks in HEVC. In this paper, a novel AZB detection scheme is proposed for the case that Hadamard transform is used as a distortion metric for RDO in HEVC. Statistical upper bounds to be allzero blocks are derived using the relationship between Walsh Hadamard and DCT transform kernels. Then, a small number of quantized coefficients in a upper left corner of a transform block, which are obtained using the relations between Hadamard transform and DCT, are examined for AZB detection. For 32 x 32 blocks, DC coefficients of 8 x 8 sub-blocks are further examined for AZB detection. The experimental results demonstrate that the proposed scheme detects 87.79% of actual AZBs with 2.87% false alarm rate in average, outperforming the state-of-the-art method. Computational complexity to detect AZB is almost negligible compared to the conventional method.
C1 [Lee, Bumshik; Jung, Jaehong; Kim, Munchurl] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, B (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
EM lbs@kaist.ac.kr; jjh89@kaist.ac.kr; mkimee@kaist.ac.kr
RI Kim, Munchurl/AAQ-9591-2020; Kim, Munchurl/C-1759-2011
FU IT RAMP;D program of MOTIE/KEIT [10039214]
FX This work was supported by the IT R&D program of MOTIE/KEIT under Grant
   10039214, Video Codec SoC for Ultra High Definition. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Dr. Xiaokang Yang.
CR Ahmen N., 1975, ORTHOGONAL TRANSFORM
   Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   BJONTEGAARD G, 2001, ITU T VCEG M AUST TX
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Dong J, 2009, IEEE T CIRC SYST VID, V19, P1462, DOI 10.1109/TCSVT.2009.2026792
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Karczewicz M., 2009, P SOC PHOTO-OPT INS, V7443
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Lee B, 2011, IEEE T CIRC SYST VID, V21, P88, DOI 10.1109/TCSVT.2011.2106273
   Lee K, 2013, IEEE J-STSP, V7, P1124, DOI 10.1109/JSTSP.2013.2272772
   Liu ZY, 2008, IEEE T CIRC SYST VID, V18, P620, DOI 10.1109/TCSVT.2008.918844
   Moon YH, 2005, IEEE T CIRC SYST VID, V15, P1053, DOI 10.1109/TCSVT.2005.852411
   Nath V. K., 2012, INT J SIGNAL IMAGE P, V3, P75
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sousa LA, 2000, ELECTRON LETT, V36, P306, DOI 10.1049/el:20000272
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2005, PROC SPIE, V5960, P1041, DOI 10.1117/12.631550
   Tran TD, 2000, IEEE SIGNAL PROC LET, V7, P145, DOI 10.1109/97.844634
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P510, DOI 10.1109/TCSVT.2008.918553
   Wang HL, 2007, IEEE T MULTIMEDIA, V9, P728, DOI 10.1109/TMM.2007.893336
   Wang HL, 2014, J VIS COMMUN IMAGE R, V25, P1784, DOI 10.1016/j.jvcir.2014.08.007
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P547, DOI 10.1109/TCSVT.2006.871390
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 27
TC 25
Z9 26
U1 0
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2016
VL 18
IS 7
BP 1257
EP 1268
DI 10.1109/TMM.2016.2557075
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DR2RW
UT WOS:000379752600003
DA 2024-07-18
ER

PT J
AU Jin, YC
   Wen, YG
   Guan, K
AF Jin, Yichao
   Wen, Yonggang
   Guan, Kyle
TI Toward Cost-Efficient Content Placement in Media Cloud: Modeling and
   Analysis
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Content delivery; content placement; cost optimization; media cloud
ID REPLICA PLACEMENT; DESIGN
AB Cloud-centric media network (CCMN) was previously proposed to provide cost-effective content distribution services for user-generated contents (UGCs) based on media cloud. CCMN service providers orchestrate cloud resources to deliver UGCs in a pay-per-use style, with an objective to minimize the operational monetary cost. The monetary cost depends on the actual usage of cloud resources (e.g., computing, storage, and bandwidth), which in turn, is affected by the content placement strategy. In this paper, we investigate this cost-optimal content placement problem. Specifically, it is formulated into a constrained optimization problem, in which the objective is to minimize the total monetary cost, with respect to the resource capacity. We tackle this problem via a two-step strategy. The first step focuses on the placement for a single content, which is mapped into a k-center problem. Using a graph-theoretic approach, we derive and verify a logarithmic model between the optimal mean hop distance from viewers to contents, and the optimal number of content replicas. The second step leverages this analytical result to solve the cost optimization problem, via a feasible direction method. The analysis is substantiated via numerical simulations, using a set of data traces from a top content website. This investigation suggests that the optimal number of content replica for each title follows a power-law distribution in respect to its popularity rank. Moreover, it reveals a fundamental tradeoff between the storage and bandwidth cost. Finally, compared to existing heuristics, our proposed algorithm is able to obtain the optimal placement strategy, with lower computational complexity.
C1 [Jin, Yichao; Wen, Yonggang] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Guan, Kyle] Nokia, Bell Labs, Holmdel, NJ 07733 USA.
C3 Nanyang Technological University; AT&T; Nokia Corporation; Nokia Bell
   Labs
RP Jin, YC; Wen, YG (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.; Guan, K (corresponding author), Nokia, Bell Labs, Holmdel, NJ 07733 USA.
EM yjin3@ntu.edu.sg; ygwen@ntu.edu.sg; kyle.guan@nokia.com
RI Wen, Yonggang/P-9406-2017; Wen, Yonggang/B-8848-2011
OI Wen, Yonggang/0000-0002-2751-5114; 
FU Singapore MOE Tier-1 [RG11/17]; Cisco Systems, Inc.; Microsoft Research
   Asia; SMART Innovation Grant
FX This work was supported in part by Singapore MOE Tier-1 (RG11/17), in
   part by Cisco Systems, Inc., in part by Microsoft Research Asia, and in
   part by a SMART Innovation Grant.
CR [Anonymous], P 20 ANN JOINT C IEE
   [Anonymous], 2011, P 2011 IEEE INT C CO
   [Anonymous], 2013, 2013 IEEE INT C MULT, DOI DOI 10.1109/ICME.2013.6607582
   Bazaraa M. S., 2013, NONLINEAR PROGRAMMIN
   BOLLOBAS B, 1982, COMBINATORICA, V2, P125, DOI 10.1007/BF02579310
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Chen FF, 2012, IEEE INFOCOM SER, P433, DOI 10.1109/INFCOM.2012.6195782
   Crovella ME, 1998, PRACTICAL GUIDE TO HEAVY TAILS, P3
   Dai J, 2012, IEEE J SEL AREA COMM, V30, P458, DOI 10.1109/JSAC.2012.120226
   Guan K., 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P313, DOI 10.1109/INFCOMW.2011.5928830
   Guo L, 2008, PODC'08: PROCEEDINGS OF THE 27TH ANNUAL ACM SYMPOSIUM ON PRINCIPLES OF DISTRIBUTED COMPUTING, P283, DOI 10.1145/1400751.1400789
   Huang Q, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P167, DOI 10.1145/2517349.2522722
   Kangasharju J, 2002, COMPUT COMMUN, V25, P376, DOI 10.1016/S0140-3664(01)00409-1
   KARIV O, 1979, SIAM J APPL MATH, V37, P513, DOI 10.1137/0137040
   Karlsson M, 2004, INT CON DISTR COMP S, P350, DOI 10.1109/ICDCS.2004.1281600
   Krishnamurthy B, 2001, IMW 2001: PROCEEDINGS OF THE FIRST ACM SIGCOMM INTERNET MEASUREMENT WORKSHOP, P105
   Laoutaris N, 2007, IEEE INFOCOM SER, P2144, DOI 10.1109/INFCOM.2007.248
   Liu FM, 2013, IEEE J SEL AREA COMM, V31, P214, DOI 10.1109/JSAC.2013.SUP.0513019
   Liu FM, 2013, IEEE T COMPUT, V62, P351, DOI 10.1109/TC.2011.222
   Liu FM, 2012, IEEE T PARALL DISTR, V23, P1227, DOI 10.1109/TPDS.2011.283
   Liu ZY, 2012, IEEE INT CONF PEER, P261
   Nygren E., 2010, SIGOPS OPER SYST REV, V44, P2, DOI [10.1145/1842733.1842736, DOI 10.1145/1842733.1842736]
   Pallis G, 2006, COMMUN ACM, V49, P101, DOI 10.1145/1107458.1107462
   Qiu LL, 2001, IEEE INFOCOM SER, P1587, DOI 10.1109/INFCOM.2001.916655
   Tang JH, 2014, IEEE T MULTIMEDIA, V16, P1434, DOI 10.1109/TMM.2014.2308726
   Tang XY, 2005, IEEE T PARALL DISTR, V16, P921, DOI 10.1109/TPDS.2005.126
   Tian Y, 2012, IEEE INFOCOM SER, P2531, DOI 10.1109/INFCOM.2012.6195646
   Topiks D., 1967, J SIAM CONTROL, V5, P280
   Verna P., 2009, A Spotlight on UGC Participants Available at
   Wang Z, 2015, IEEE T MULTIMEDIA, V17, P92, DOI 10.1109/TMM.2014.2365364
   Wauters T, 2006, COMPUT COMMUN, V29, P3313, DOI 10.1016/j.comcom.2006.05.008
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   Yichao Jin, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P934, DOI 10.1109/ICCNC.2012.6167562
NR 34
TC 36
Z9 37
U1 0
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAY
PY 2016
VL 18
IS 5
SI SI
BP 807
EP 819
DI 10.1109/TMM.2016.2537199
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DK5YD
UT WOS:000374996200002
DA 2024-07-18
ER

PT J
AU Hameed, A
   Dai, R
   Balas, B
AF Hameed, Abdul
   Dai, Rui
   Balas, Benjamin
TI A Decision-Tree-Based Perceptual Video Quality Prediction Model and Its
   Application in FEC for Wireless Multimedia Communications
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Energy-efficiency; forward error correction (FEC); perceptual video
   quality; quality of experience (QoE); video coding; wireless multimedia
   communications
ID NETWORKED VIDEO; ALLOCATION
AB With the exponential growth of video traffic over wireless networked and embedded devices, mechanisms are needed to predict and control perceptual video quality to meet the quality of experience (QoE) requirements in an energy-efficient way. This paper proposes an energy-efficient QoE support framework for wireless video communications. It consists of two components: 1) a perceptual video quality model that allows the prediction of video quality in real-time and with low complexity, and 2) an application layer energy-efficient and content-aware forward error correction (FEC) scheme for preventing quality degradation caused by network packet losses. The perceptual video quality model characterizes factors related to video content as well as distortion caused by compression and transmission. Prediction of perceptual quality is achieved through a decision tree using a set of observable features from the compressed bitstream and the network. The proposed model can achieve prediction accuracy of 88.9% and 90.5% on two distinct testing sets. Based on the proposed quality model, a novel FEC scheme is introduced to protect video packets from losses during transmission. Given a user-defined perceptual quality requirement, the FEC scheme adjusts the level of protection for different components in a video stream to minimize network overhead. Simulation results show that the proposed FEC scheme can enhance the perceptual quality of videos. Compared to conventional FEC methods for video communications, the proposed FEC scheme can reduce network overhead by 41% on average.
C1 [Hameed, Abdul] COMSATS Inst Informat Technol, Dept Comp Sci, Islamabad 45550, Pakistan.
   [Dai, Rui] Univ Cincinnati, Dept Elect Engn & Comp Syst, Cincinnati, OH 45221 USA.
   [Balas, Benjamin] N Dakota State Univ, Dept Psychol, Fargo, ND 58108 USA.
C3 COMSATS University Islamabad (CUI); University System of Ohio;
   University of Cincinnati; North Dakota State University Fargo
RP Hameed, A (corresponding author), COMSATS Inst Informat Technol, Dept Comp Sci, Islamabad 45550, Pakistan.; Dai, R (corresponding author), Univ Cincinnati, Dept Elect Engn & Comp Syst, Cincinnati, OH 45221 USA.; Balas, B (corresponding author), N Dakota State Univ, Dept Psychol, Fargo, ND 58108 USA.
EM abdul_hameed@comsats.edu.pk; rui.dai@uc.edu; benjamin.balas@ndsu.edu
RI Balas, Ben/R-4003-2019; Hameed, Abdul/ABA-1923-2021
OI Dai, Rui/0000-0001-6620-7862
CR Aguiar E, 2012, CONSUM COMM NETWORK, P592, DOI 10.1109/CCNC.2012.6181017
   Anegekuh L, 2015, IEEE T MULTIMEDIA, V17, P1323, DOI 10.1109/TMM.2015.2444098
   [Anonymous], 2007, MULTIMEDIA OVER IP W
   [Anonymous], P SENS SIGN PROC DEF
   [Anonymous], P IEEE INT C COMM JU
   [Anonymous], 2013, P 28 ANN ACM S APPL
   Boulis A., 2009, CASTALIA SIMULATOR W
   Dayal P, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON RELIABILTY, OPTIMIZATION, & INFORMATION TECHNOLOGY (ICROIT 2014), P452, DOI 10.1109/ICROIT.2014.6798383
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   Hameed A, 2014, INT BLACK SEA CONF, P48, DOI 10.1109/BlackSeaCom.2014.6849002
   Hellge C, 2011, IEEE T MULTIMEDIA, V13, P551, DOI 10.1109/TMM.2011.2129499
   Jia Jan Ong, 2010, 2010 International Conference on Computer Applications and Industrial Electronics (ICCAIE), P356, DOI 10.1109/ICCAIE.2010.5735103
   Jiang TG, 2012, IEEE J SEL AREA COMM, V30, P1215, DOI 10.1109/JSAC.2012.120807
   Joskowicz J., 2012, PROC IEEE INT S BROA, P1
   Kawano T., 2010, 2010 18th International Packet Video Workshop (PV 2010), P158, DOI 10.1109/PV.2010.5706833
   Keimel C., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3325, DOI 10.1109/ICIP.2011.6116383
   Khan A, 2012, IEEE T MULTIMEDIA, V14, P431, DOI 10.1109/TMM.2011.2176324
   Lin TL, 2010, IEEE T IMAGE PROCESS, V19, P722, DOI 10.1109/TIP.2009.2038834
   Narwaria M, 2012, IEEE T MULTIMEDIA, V14, P525, DOI 10.1109/TMM.2012.2190589
   Oelbaum T, 2009, IEEE J-STSP, V3, P294, DOI 10.1109/JSTSP.2009.2015473
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Varga A., 2001, P EUR SIM MULT ESM 2, V9, P65
   Wu Huahui, 2005, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), V1, P315
   Xue YY, 2015, IEEE T MULTIMEDIA, V17, P134, DOI 10.1109/TMM.2014.2368272
   Yang FZ, 2012, IEEE COMMUN MAG, V50, P203, DOI 10.1109/MCOM.2012.6353702
   Zhongliang Zhao, 2012, 2012 IEEE 8th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob 2012), P689, DOI 10.1109/WiMOB.2012.6379150
   Zhou L, 2013, IEEE T WIREL COMMUN, V12, P3733, DOI 10.1109/TWC.2013.051413.120597
NR 27
TC 48
Z9 52
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2016
VL 18
IS 4
BP 764
EP 774
DI 10.1109/TMM.2016.2525862
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DH4XZ
UT WOS:000372790300017
DA 2024-07-18
ER

PT J
AU Jiménez-Moreno, A
   Martínez-Enríquez, E
   Díaz-de-María, F
AF Jimenez-Moreno, Amaya
   Martinez-Enriquez, Eduardo
   Diaz-de-Maria, Fernando
TI Complexity Control Based on a Fast Coding Unit Decision Method in the
   HEVC Video Coding Standard
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Complexity control (CC); fast coding unit decision; high efficiency
   video coding (HEVC); on the fly estimation
ID MODE DECISION; ALGORITHM; ALLOCATION; SELECTION
AB The emerging high-efficiency video coding standard achieves higher coding efficiency than previous standards by virtue of a set of new coding tools such as the quadtree coding structure. In this novel structure, the pixels are organized into coding units (CU), prediction units, and transform units, the sizes of which can be optimized at every level following a tree configuration. These tools allow highly flexible data representation; however, they incur a very high computational complexity. In this paper, we propose an effective complexity control (CC) algorithm based on a hierarchical approach. An early termination condition is defined at every CU size to determine whether subsequent CU sizes should be explored. The actual encoding times are also considered to satisfy the target complexity in real time. Moreover, all parameters of the algorithm are estimated on the fly to adapt its behavior to the video content, the encoding configuration, and the target complexity over time. The experimental results prove that our proposal is able to achieve a target complexity reduction of up to 60% with respect to full exploration, with notable accuracy and limited losses in coding performance. It was compared with a state-of-the-art CC method and shown to achieve a significantly better trade-off between coding complexity and efficiency as well as higher accuracy in reaching the target complexity. Furthermore, a comparison with a state-of-the-art complexity reduction method highlights the advantages of our CC framework. Finally, we show that the proposed method performs well when the target complexity varies over time.
C1 [Jimenez-Moreno, Amaya; Diaz-de-Maria, Fernando] Univ Carlos III Madrid, Dept Signal Theory & Commun, Madrid 28911, Spain.
   [Martinez-Enriquez, Eduardo] Consejo Super Invest Cientif, Inst Opt, Madrid 28006, Spain.
C3 Universidad Carlos III de Madrid; Consejo Superior de Investigaciones
   Cientificas (CSIC); CSIC - Instituto de Optica (Daza de Valdes)
RP Jiménez-Moreno, A; Díaz-de-María, F (corresponding author), Univ Carlos III Madrid, Dept Signal Theory & Commun, Madrid 28911, Spain.; Martínez-Enríquez, E (corresponding author), Consejo Super Invest Cientif, Inst Opt, Madrid 28006, Spain.
EM ajimenez@tsc.uc3m.es; eduardo.martinez@io.cfmac.csic.es;
   fdiaz@tsc.uc3m.es
RI Martinez, Eduardo/ISS-3584-2023; de María, Fernando Díaz/E-8048-2011;
   Jimenez-Moreno, Amaya/AAA-7450-2021; Martinez-Enriquez,
   Eduardo/L-8332-2014
OI de María, Fernando Díaz/0000-0002-6437-914X; Martinez-Enriquez,
   Eduardo/0000-0001-7097-8846
FU Spanish Ministry of Economy and Competitiveness [TEC2014-53390-P]
FX This work was supported in part by the National Grant TEC2014-53390-P of
   the Spanish Ministry of Economy and Competitiveness. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Prof. Zhu Li.
CR [Anonymous], 2001, ITU T VCEG M AUST TE
   Blasi SG, 2013, INT CONF ACOUST SPEE, P1709, DOI 10.1109/ICASSP.2013.6637944
   Bossen F., 2011, 5 M JOINT COLL TEAM
   Choi K., 2011, 5 M JOINT COLL TEAM
   Choi K, 2012, ELECTRON LETT, V48, P689, DOI 10.1049/el.2012.0277
   Correa G, 2013, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2013.12
   Corrêa G, 2011, IEEE T CONSUM ELECTR, V57, P1866, DOI 10.1109/TCE.2011.6131165
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Grellert M, 2013, IEEE IMAGE PROC, P1850, DOI 10.1109/ICIP.2013.6738381
   Gweon R. H., 2011, 5 M JOINT COLL TEAM
   Jie Leng, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P56, DOI 10.1109/CMSP.2011.167
   Jiménez-Moreno A, 2013, IEEE T MULTIMEDIA, V15, P1094, DOI 10.1109/TMM.2013.2241414
   Kim J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P449, DOI 10.1109/PCS.2012.6213251
   Martínez-Enríquez E, 2010, IEEE T CONSUM ELECTR, V56, P826, DOI 10.1109/TCE.2010.5506008
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan HL, 2012, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.2012.6288011
   Teng S.-W., 2011, VISUAL COMMUNICATION, P1
   Ukhanova A, 2013, IEEE IMAGE PROC, P1995, DOI 10.1109/ICIP.2013.6738411
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Zhang YF, 2013, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2013.13
   Zhao TS, 2013, IEEE J-STSP, V7, P1135, DOI 10.1109/JSTSP.2013.2271421
NR 24
TC 35
Z9 35
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2016
VL 18
IS 4
BP 563
EP 575
DI 10.1109/TMM.2016.2524995
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DH4XZ
UT WOS:000372790300002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Gu, K
   Wang, SQ
   Zhai, GT
   Ma, SW
   Yang, XK
   Lin, WS
   Zhang, WJ
   Gao, W
AF Gu, Ke
   Wang, Shiqi
   Zhai, Guangtao
   Ma, Siwei
   Yang, Xiaokang
   Lin, Weisi
   Zhang, Wenjun
   Gao, Wen
TI Blind Quality Assessment of Tone-Mapped Images Via Analysis of
   Information, Naturalness, and Structure
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE High dynamic range; image quality assessment (IQA); information entropy;
   no-reference (NR); statistical naturalness; structural preservation;
   tone mapping
ID CONTRAST; STATISTICS; VISIBILITY
AB High dynamic range (HDR) imaging techniques have been working constantly, actively, and validly in the fault detection and disease diagnosis in the astronomical and medical fields, and currently they have also gained much more attention from digital image processing and computer vision communities. While HDR imaging devices are starting to have friendly prices, HDR display devices are still out of reach of typical consumers. Due to the limited availability of HDR display devices, in most cases tone mapping operators (TMOs) are used to convert HDR images to standard low dynamic range (LDR) images for visualization. But existing TMOs cannot work effectively for all kinds of HDR images, with their performance largely depending on brightness, contrast, and structure properties of a scene. To accurately measure and compare the performance of distinct TMOs, in this paper develop an effective and efficient no-reference objective quality metric which can automatically assess LDR images created by different TMOs without access to the original HDR images. Our model is shown to be statistically superior to recent full-and no-reference quality measures on the existing tone-mapped image database and a new relevant database built in this work.
C1 [Gu, Ke; Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Gu, Ke] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
   [Zhai, Guangtao; Yang, Xiaokang; Zhang, Wenjun] Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
   [Wang, Shiqi; Ma, Siwei; Gao, Wen] Peking Univ, Sch Elect Engn & Comp Sci, Inst Digital Media, Beijing 100871, Peoples R China.
C3 Nanyang Technological University; Shanghai Jiao Tong University;
   Shanghai Jiao Tong University; Peking University
RP Gu, K; Lin, WS (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.; Zhai, GT; Yang, XK; Zhang, WJ (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.; Wang, SQ; Ma, SW; Gao, W (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Inst Digital Media, Beijing 100871, Peoples R China.
EM guke.doctor@gmail.com; sqwang1986@pku.edu.cn; zhaiguangtao@sjtu.edu.cn;
   swma@pku.edu.cn; xkyang@sjtu.edu.cn; wslin@ntu.edu.sg;
   zhangwenjun@sjtu.edu.cn; wgao@pku.edu.cn
RI Zhang, Wenjun/GNH-2095-2022; Lin, Weisi/A-8011-2012; Yang,
   Xiaokang/C-6137-2009; Gu, Ke/AAJ-9684-2021; Zhai, Guangtao/X-5949-2019;
   Lin, Weisi/A-3696-2011
OI Zhang, Wenjun/0000-0002-5282-3725; Yang, Xiaokang/0000-0003-4029-3322;
   Zhai, Guangtao/0000-0001-8165-9322; Lin, Weisi/0000-0001-9866-1947;
   Wang, Shiqi/0000-0002-3583-959X
FU Singapore MoE Tier 1 Project [M4011379, RG141/14]; National Science
   Foundation of China [61025005, 61371146, 61221001, 61390514]
FX This work was supported in part by the Singapore MoE Tier 1 Project
   under Grant M4011379 and Grant RG141/14, and in part by the National
   Science Foundation of China under Grant 61025005, Grant 61371146, Grant
   61221001, and Grant 61390514. The associate editor coordinating the
   review of this manuscript and approving it for publication was Prof.
   Christian Timmerer.
CR [Anonymous], 2012, Recommendation BT.500-13
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   Cadík M, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P920, DOI 10.1109/IV.2005.126
   Cadik M., 2010, EVALUATION TONE MAPP
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gowacz A, 2010, ANN TELECOMMUN, V65, P3, DOI 10.1007/s12243-009-0146-6
   Gu K, 2014, IEEE IMAGE PROC, P506, DOI 10.1109/ICIP.2014.7025101
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T BROADCAST, V61, P520, DOI 10.1109/TBC.2015.2459851
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2014, IEEE INT SYMP CIRC S, P518, DOI 10.1109/ISCAS.2014.6865186
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2013, IEEE INT SYMP CIRC S, P1095, DOI 10.1109/ISCAS.2013.6572041
   Janowski L, 2009, INT WORK QUAL MULTIM, P35, DOI 10.1109/QOMEX.2009.5246979
   Johnson D.H., 2001, IEEE Trans. Inf. Theory, V1, P1
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Ma K., 2014, Power Electronics, IEEE Transactions on, VPP,, P1
   Mai ZC, 2011, IEEE T IMAGE PROCESS, V20, P1558, DOI 10.1109/TIP.2010.2095866
   Mante V, 2005, NAT NEUROSCI, V8, P1690, DOI 10.1038/nn1556
   Mantiuk R, 2005, PROC SPIE, V5666, P204, DOI 10.1117/12.586757
   Mantiuk R, 2006, ACM T GRAPHIC, V25, P713, DOI 10.1145/1141911.1141946
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Samanta S, 2014, IEEE T MULTIMEDIA, V16, P1525, DOI 10.1109/TMM.2014.2326734
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Su YC, 2014, IEEE T MULTIMEDIA, V16, P1645, DOI 10.1109/TMM.2014.2322337
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZJ, 2011, IEEE SIGNAL PROC MAG, V28, P2, DOI 10.1109/MSP.2011.940297
   Wu HR, 2013, P IEEE, V101, P2025, DOI 10.1109/JPROC.2013.2262911
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
NR 48
TC 172
Z9 173
U1 2
U2 54
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2016
VL 18
IS 3
BP 432
EP 443
DI 10.1109/TMM.2016.2518868
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DG2WP
UT WOS:000371931600010
DA 2024-07-18
ER

PT J
AU Wang, BT
   Lin, DH
   Xiong, HK
   Zheng, YF
AF Wang, Botao
   Lin, Dahua
   Xiong, Hongkai
   Zheng, Y. F.
TI Joint Inference of Objects and Scenes With Efficient Learning of
   Text-Object-Scene Relations
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Conditional random field; object classification; object localization;
   scene classification
ID CLASSIFICATION
AB The rapid growth of web images presents new challenges as well as opportunities to the task of image understanding. Conventional approaches rely heavily on fine-grained annotations, such as bounding boxes and semantic segmentations, which are not available for web-scale images. In general, images over the Internet are accompanied with descriptive texts, which are relevant to their contents. To bridge the gap between textual and visual analysis for image understanding, this paper presents an algorithm to learn the relations between scenes, objects, and texts with the help of image-level annotations. In particular, the relation between the texts and objects is modeled as the matching probability between the nouns and the object classes, which can be solved via a constrained bipartite matching problem. On the other hand, the relations between the scenes and objects/texts are modeled as the conditional distributions of their co-occurrence. Built upon the learned cross-domain relations, an integrated model brings together scenes, objects, and texts for joint image understanding, including scene classification, object classification and localization, and the prediction of object cardinalities. The proposed cross-domain learning algorithm and the integrated model elevate the performance of image understanding for web images in the context of textual descriptions. Experimental results show that the proposed algorithm significantly outperforms conventional methods in various computer vision tasks.
C1 [Wang, Botao; Xiong, Hongkai] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
   [Lin, Dahua] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.
   [Zheng, Y. F.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
C3 Shanghai Jiao Tong University; Chinese University of Hong Kong;
   University System of Ohio; Ohio State University
RP Wang, BT; Xiong, HK (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.; Lin, DH (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.; Zheng, YF (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
EM botaowang@sjtu.edu.cn; dhlin@ie.cuhk.edu.hk; xionghongkai@sjtu.edu.cn;
   zheng@ece.osu.edu
RI Lin, Dahua/W-6576-2019; zheng, yuan/JCN-7781-2023
OI Lin, Dahua/0000-0002-8865-7896; Xiong, Hongkai/0000-0003-4552-0029
FU NSFC [61425011, U1201255, 61271218, 61529101, 61472234, 61271211]; Shu
   Guanga Project [13SG13]
FX This work was supported in part by the NSFC under Grant 61425011, Grant
   U1201255, Grant 61271218, Grant 61529101, Grant 61472234, and Grant
   61271211, and by the Shu Guanga Project 13SG13. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Martha Larson.
CR [Anonymous], P NIPS VANC BC CAN
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2010, P NIPS
   [Anonymous], PROC CVPR IEEE
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Benavent X, 2013, IEEE T MULTIMEDIA, V15, P2009, DOI 10.1109/TMM.2013.2267726
   Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Cheng E, 2009, IEEE T IMAGE PROCESS, V18, P1350, DOI 10.1109/TIP.2009.2017128
   Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fidler S, 2013, PROC CVPR IEEE, P1995, DOI 10.1109/CVPR.2013.260
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Gupta A, 2008, LECT NOTES COMPUT SC, V5302, P16, DOI 10.1007/978-3-540-88682-2_3
   Iyengar G., 2005, 13th Annual ACM International Conference on Multimedia, P21, DOI 10.1145/1101149.1101154
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Karpathy A, 2014, ADV NEUR IN, V27
   Katsurai M, 2014, IEEE T MULTIMEDIA, V16, P1059, DOI 10.1109/TMM.2014.2306655
   Klein D, 2002, ADV NEUR IN, V14, P35
   Larochelle H., 2012, ADV NEURAL INFORM PR, P2708
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li YP, 2009, IEEE I CONF COMP VIS, P1957, DOI 10.1109/ICCV.2009.5459432
   Lu WT, 2013, IEEE T MULTIMEDIA, V15, P1920, DOI 10.1109/TMM.2013.2280895
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Niu ZX, 2014, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2014.539
   Ordonez V, 2013, IEEE I CONF COMP VIS, P2768, DOI 10.1109/ICCV.2013.344
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371
   Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yeh YR, 2014, IEEE T IMAGE PROCESS, V23, P2009, DOI 10.1109/TIP.2014.2310992
NR 40
TC 6
Z9 7
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2016
VL 18
IS 3
BP 507
EP 520
DI 10.1109/TMM.2016.2520087
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA DG2WP
UT WOS:000371931600016
DA 2024-07-18
ER

PT J
AU Khalek, AA
   Caramanis, C
   Heath, RW
AF Khalek, Amin Abdel
   Caramanis, Constantine
   Heath, Robert W.
TI Loss Visibility Optimized Real-Time Video Transmission Over MIMO Systems
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Limited feedback; loss visibility; multiple-input multiple-output
   (MIMO); packet loss; unequal error protection; video signal processing
ID UNEQUAL ERROR PROTECTION; PACKET-LOSS VISIBILITY; SPATIAL MULTIPLEXING
   SYSTEMS; SNR-SCALABLE VIDEO; WIRELESS SYSTEMS; CODING HEVC; STANDARD;
   EFFICIENCY; SELECTION; CHANNELS
AB The structured nature of video data motivates introducing video-aware decisions that make use of this structure for improved video transmission over wireless networks. In this paper, we introduce an architecture for real-time video transmission over multiple-input multiple-output (MIMO) wireless communication systems using loss visibility side information. We quantify the perceptual importance of a packet through the packet loss visibility and use the loss visibility distribution to provide a notion of relative packet importance. To jointly achieve high video quality and low latency, we define the optimization objective function as the throughput weighted by the loss visibility of each packet, a proxy for the total perceptual value of successful packets per unit of time. We solve the problem of mapping video packets to MIMO subchannels and adapting per-stream rates to maximize the proposed objective. We show that the solution enables jointly reaping gains in terms of improved video quality and lower latency. Optimized packet-stream mapping enables transmission of more relevant packets over more reliable streams while unequal modulation opportunistically increases the transmission rate on the stronger streams to enable low latency delivery of high priority packets. Tested on H. 264-encoded video sequences, for a 4 x 4 MIMO system with three spatial streams, the proposed architecture achieves 8 dB power reduction for the same video quality and supports 2.4x higher throughput due to unequal modulation. Furthermore, the gains are achieved at the expense of few bits of cross-layer overhead rather than a complex cross-layer design.
C1 [Khalek, Amin Abdel; Caramanis, Constantine; Heath, Robert W.] Univ Texas Austin, Dept Elect & Comp Engn, Wireless Networking & Commun Grp, Austin, TX 78712 USA.
C3 University of Texas System; University of Texas Austin
RP Khalek, AA (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Wireless Networking & Commun Grp, Austin, TX 78712 USA.
EM akhalek@utexas.edu; constantine@utexas.edu; rheath@utexas.edu
RI Heath, Robert/AAY-4148-2020
OI Heath, Robert/0000-0002-4666-5628; Caramanis,
   Constantine/0000-0001-9939-8378
FU Intel-Cisco Video Aware Wireless Networks (VAWN) Program
FX This work was supported by the Intel-Cisco Video Aware Wireless Networks
   (VAWN) Program. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Yap-Peng Tan.
CR [Anonymous], 2010, YUV VID SEQ
   [Anonymous], IEEE COMPUTER COMMUN
   Gallant M, 2001, IEEE T CIRC SYST VID, V11, P357, DOI 10.1109/76.911161
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Goldsmith A., 2005, WIRELESS COMMUNICATI
   Heath RW, 2001, IEEE COMMUN LETT, V5, P142, DOI 10.1109/4234.917094
   Hormis R, 2009, IEEE T SIGNAL PROCES, V57, P3624, DOI 10.1109/TSP.2009.2020051
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kanumuri S, 2006, IEEE IMAGE PROC, P2245, DOI 10.1109/ICIP.2006.312809
   Khalek AA, 2012, CONF REC ASILOMAR C, P925, DOI 10.1109/ACSSC.2012.6489151
   Khalek AA, 2012, EUR SIGNAL PR CONF, P1905
   Khalek AA, 2012, IEEE J SEL AREA COMM, V30, P1157, DOI 10.1109/JSAC.2012.120802
   Khalifa A., 2011, Proceedings of IEEE Power and Energy Society General Meeting, P1
   Kim J, 2003, IEEE T IMAGE PROCESS, V12, P121, DOI 10.1109/TIP.2003.809006
   Kondi LP, 2002, IEEE T IMAGE PROCESS, V11, P1043, DOI 10.1109/TIP.2002.802507
   Lin TL, 2010, IEEE T IMAGE PROCESS, V19, P722, DOI 10.1109/TIP.2009.2038834
   Love DJ, 2005, IEEE T SIGNAL PROCES, V53, P3674, DOI 10.1109/TSP.2005.855107
   Love DJ, 2005, IEEE T INFORM THEORY, V51, P2967, DOI 10.1109/TIT.2005.850152
   Luo HY, 2010, IEEE COMMUN MAG, V48, P102, DOI 10.1109/MCOM.2010.5402671
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Oyman O., 2010, P INT S PERS IND MOB, P387
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Scott D., 1992, MULTIVARIATE DENSITY, V139
   Song D, 2007, IEEE T CIRC SYST VID, V17, P1218, DOI 10.1109/TCSVT.2007.905531
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Telatar E, 1999, EUR T TELECOMMUN, V10, P585, DOI 10.1002/ett.4460100604
   Toni L., 2011, P IEEE INT C MULT EX, P1
   van der Schaar M, 2007, IEEE T MULTIMEDIA, V9, P185, DOI 10.1109/TMM.2006.886384
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu J, 2010, IEEE J SEL AREA COMM, V28, P456, DOI 10.1109/JSAC.2010.100416
   Zhang Q, 2004, IEEE T CIRC SYST VID, V14, P1049, DOI 10.1109/TCSVT.2004.831966
   Zhang Y, 2007, IEEE T MULTIMEDIA, V9, P445, DOI 10.1109/TMM.2006.887989
NR 32
TC 7
Z9 7
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2015
VL 17
IS 10
BP 1802
EP 1817
DI 10.1109/TMM.2015.2468196
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CR9OD
UT WOS:000361685400010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Deng, R
   Liu, GZ
   Yang, J
AF Deng, Rui
   Liu, Guizhong
   Yang, Jian
TI Utility-Based Optimized Cross-Layer Scheme for Real-Time Video
   Transmission Over HSDPA
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cross-layer; distortion; dynamic programming; greedy policy; H.264;
   HSDPA; packet utility; video
ID DISTORTION; CHANNEL
AB In this paper we first build an accurate and general transmission distortion model for H.264/AVC video streams to estimate the importance of each packet. Then, a utility-based optimized cross-layer resource allocation, MCS selection, and packet scheduling algorithm for real-time video transmission over HSDPA is studied. The utility here refers to the packet utility which is defined as a function of the packet urgency and the packet importance. Transmitting the packets with greater utility values firstly in each TTI can provide a higher level of video quality for the users. Thus, we formulate an optimization problem with the objective of maximizing the aggregate packet utility over all the users under the HSDPA physical resource constraints. In order to obtain an optimal transmission strategy, a dynamic programming-based cross-layer algorithm (DPCLA) is proposed. In view of its high complexity, we further develop a greedy-based cross-layer algorithm (GCLA) to find a suboptimal solution. Simulation results show that the proposed utility-based optimized cross-layer scheme, including the proposed transmission distortion model and the algorithms of DPCLA and GCLA, can provide higher received video quality than the existing ones for video transmission over HSDPA.
C1 [Deng, Rui; Liu, Guizhong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Yang, Jian] Huawei Technol Co Ltd, Xian 710075, Peoples R China.
C3 Xi'an Jiaotong University; Huawei Technologies
RP Deng, R (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM dengrui618@stu.xjtu.edu.cn; liugz@xjtu.edu.cn;
   yangjian529@stu.xjtu.edu.cn
FU National Natural Science Foundation of China [61173110]
FX This work was supported by the National Natural Science Foundation of
   China under Project 61173110. The associate editor coordinating the
   review of this manuscript and approving it for publication was Prof.
   Tommaso Melodia.
CR Ameigeiras P, 2004, VTC2004-FALL: 2004 IEEE 60TH VEHICULAR TECHNOLOGY CONFERENCE, VOLS 1-7, P999
   Aniba G., 2004, Canadian Conference on Electrical and Computer Engineering 2004 (IEEE Cat. No.04CH37513), P2243, DOI 10.1109/CCECE.2004.1347692
   [Anonymous], 2003, 25308 3GPP TS
   [Anonymous], 2010, 25214 3GPP TS
   [Anonymous], 2003, document ITUT Rec. H.264 and ISO/IEC 14496-10, (AVC)
   [Anonymous], 2001, TR25848 3GPP
   Brouwer F., 2004, Eighth IEEE International Symposium on Spread Spectrum Techniques and Applications - Programme and Book of Abstracts (IEEE Cat. No.04TH8738), P844, DOI 10.1109/ISSSTA.2004.1371820
   Chen LS, 2007, LECT NOTES COMPUT SC, V4810, P510
   Chen ZF, 2012, IEEE T IMAGE PROCESS, V21, P1123, DOI 10.1109/TIP.2011.2168411
   Dani JU, 2005, GLOB TELECOMM CONF, P2425
   Deng R., 2014, P IEEE 23 INT C COMP, P1
   Deng R., 2013, 2013 IEEE POW EN SOC, P1
   Dua A, 2010, IEEE T WIREL COMMUN, V9, P1001, DOI 10.1109/TWC.2010.03.070120
   Gang Sun, 2008, 2008 Third International Conference on Communications and Networking in China (CHINACOM), P820, DOI 10.1109/CHINACOM.2008.4685150
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Jalali A, 2000, 2000 IEEE 51ST VEHICULAR TECHNOLOGY CONFERENCE, PROCEEDINGS, VOLS 1-3, P1854, DOI 10.1109/VETECS.2000.851593
   Li F, 2010, IET COMMUN, V4, P1012, DOI 10.1049/iet-com.2009.0618
   Li F, 2009, IEEE T CIRC SYST VID, V19, P1908, DOI 10.1109/TCSVT.2009.2031457
   Pahalawatta P, 2007, IEEE J SEL AREA COMM, V25, P749, DOI 10.1109/JSAC.2007.070511
   Singhal D., 2009, 1 INT C COMM SYST NE, P1
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Wang QL, 2014, MULTIMED TOOLS APPL, V72, P3105, DOI 10.1007/s11042-013-1596-4
   Wang Y, 2006, IEEE T CIRC SYST VID, V16, P716, DOI 10.1109/TCSVT.2006.875203
   Wrulich M, 2008, IEEE VTS VEH TECHNOL, P2056, DOI 10.1109/VETECS.2008.462
   Zhang YF, 2010, IEEE T MULTIMEDIA, V12, P1, DOI 10.1109/TMM.2009.2036290
NR 25
TC 6
Z9 6
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2015
VL 17
IS 9
SI SI
BP 1495
EP 1507
DI 10.1109/TMM.2015.2456506
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CP0RN
UT WOS:000359583000010
DA 2024-07-18
ER

PT J
AU Wang, Z
   Sun, LF
   Wu, C
   Zhu, WW
   Zhuang, QD
   Yang, SQ
AF Wang, Zhi
   Sun, Lifeng
   Wu, Chuan
   Zhu, Wenwu
   Zhuang, Qidong
   Yang, Shiqiang
TI A Joint Online Transcoding and Delivery Approach for Dynamic Adaptive
   Streaming
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Network measurement; quality of experience; video content delivery;
   video transcoding
AB Dynamic adaptive streaming has emerged as a popular approach for video services in today's Internet. To date, the two important components in dynamic adaptive streaming, video transcoding that generates the adaptive bitrates of a video and video delivery that streams the videos to users, have been separately studied, resulting in a huge waste of computation and storage resource due to producing and caching different versions of videos regardless of their demands. We conduct extensive measurement studies of video sharing systems, including an IPTV service which streams regular, professionally made videos and an instant video clip sharing service which provides extremely short user-generated videos, as well as the availability of computation resource in conventional content delivery networks (CDNs). Based on the measurement insights, we propose an online joint transcoding and delivery approach for adaptive video streaming. We formulate optimization problems to enable high streaming quality for the users, and low computation and replication costs for the system. In particular, our strategy connects video transcoding and video delivery based on users' preferences of CDN regions and regional preferences of video versions. We analyze hardness of these problems and design distributed solutions. Extensive trace-driven experiments further demonstrate the superiority of our design.
C1 [Wang, Zhi] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.
   [Sun, Lifeng; Zhu, Wenwu; Yang, Shiqiang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing Key Lab Networked Multimedia, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Wu, Chuan] Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Zhuang, Qidong] Tencent, Shenzhen 518057, Peoples R China.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   Tsinghua University; University of Hong Kong; Tencent
RP Wang, Z (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.
EM wangzhi@sz.tsinghua.edu.cn; sunlf@tsinghua.edu.cn; cwu@cs.hku.hk;
   wwzhu@tsinghua.edu.cn; qzhuang@ust.hk; yangshq@tsinghua.edu.cn
RI yang, qiang/GYJ-0971-2022; Wu, Chuan/E-9919-2010
OI Wu, Chuan/0000-0002-3144-4398; Yang, Qiang/0000-0001-5059-8360
FU National Basic Research Program of China [2015CB352300]; National
   Natural Science Foundation of China [61402247, 61472204, 61210008];
   SZSTI [JCYJ20140417115840259]; Hong Kong RGC [HKU 717812E];
   Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology
FX This work was supported in part by the National Basic Research Program
   of China under Grant 2015CB352300, by the National Natural Science
   Foundation of China under Grant 61402247, Grant 61472204, and Grant
   61210008, by the SZSTI under Grant JCYJ20140417115840259, by the Hong
   Kong RGC (HKU 717812E), and by the research fund of Tsinghua-Tencent
   Joint Laboratory for Internet Innovation Technology. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Prof. Pal Halvorsen.
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   [Anonymous], 2012, 2300912014 ISOIEC
   ANTONIADES D, 2006, P PASS ACT MEAS C PA, P61
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Cheng B, 2007, IEEE ICC, P1698, DOI 10.1109/ICC.2007.284
   Cohen J, 2010, P INT C LARG INST SY, P1
   Feng Lao, 2012, 2012 IEEE International Symposium on Circuits and Systems - ISCAS 2012, P2905, DOI 10.1109/ISCAS.2012.6271923
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   Huang ZX, 2011, IEEE INFOCOM SER, P201, DOI 10.1109/INFCOM.2011.5935009
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Li Z., 2012, Proc. of ACM Workshop on Network and Operating System Support for Digital Audio and Video (NOSSDAV), P33, DOI DOI 10.1145/2229087.2229097
   Liang L., 2012, P IEEE INT C IM AN S, P1
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Pallis G, 2006, COMMUN ACM, V49, P101, DOI 10.1145/1107458.1107462
   Peng G., 2004, CS0411069 ARXIV
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Vakali A, 2003, IEEE INTERNET COMPUT, V7, P68, DOI 10.1109/MIC.2003.1250586
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wang Z, 2014, IEEE INFOCOM SER, P91, DOI 10.1109/INFOCOM.2014.6847928
   Wu N., 2009, P 17 ACM INT C MULT, P371
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
   Zheng C., 2005, PROC ACM WORKSHOP AD, P29
NR 22
TC 28
Z9 29
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2015
VL 17
IS 6
BP 867
EP 879
DI 10.1109/TMM.2015.2425216
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CI1TM
UT WOS:000354527500009
DA 2024-07-18
ER

PT J
AU Chen, L
   Zhou, YP
   Chiu, DM
AF Chen, Liang
   Zhou, Yipeng
   Chiu, Dah Ming
TI Smart Streaming for Online Video Services
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Quality of experience (QoE); streaming strategy; user behavior;
   video-on-demand (VoD) service
ID DYNAMICS; IMPACT; QOE
AB Bandwidth cost is a significant concern for online video service providers. Today's video streaming systems mostly use HTTP streaming, with users accessing video segments as HTTP requests. A frequently used strategy is to serve all user requests as fast as possible, as if the user is downloading a file. The downloading rate can often far exceed the playback rate, when the system is below the peak load. This is known as progressive downloading. Since users may quit before viewing the complete video, however, much of the downloaded video can be "wasted." By studying and exploiting the predictability of users' departure behavior, the authors developed a smart streaming strategy that can significantly improve overall streaming service quality under given server bandwidth. The improvement is achieved by avoiding the waste based on predicted user departure behavior. The proposed smart streaming technique is evaluated by modeling, analysis, and simulation, as well as experimentation using a prototype implementation.
C1 [Chen, Liang] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
   [Zhou, Yipeng] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Chiu, Dah Ming] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Shenzhen University; Shenzhen University; Chinese University of Hong
   Kong
RP Zhou, YP (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM lchen@szu.edu.cn; ypzhou@szu.edu.cn; dmchiu@ie.cuhk.edu.hk
RI Chiu, Dah Ming/F-1885-2011
OI Zhou, Yipeng/0000-0003-1533-0865
FU Shenzhen Key Lab of Advanced Communications and Information Processing
   [CXB201105060068A]; Natural Science Foundation of China [61402297]; Hong
   Kong RGC under GRF [14201814]
FX This work was supported by the Shenzhen Key Lab of Advanced
   Communications and Information Processing under Grant CXB201105060068A,
   in part by the Natural Science Foundation of China under Grant 61402297,
   and in part by the Hong Kong RGC under GRF Grant 14201814. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Dr. Yiannis Andreopoulos. (Corresponding author: Yipeng
   Zhou.)
CR Acharya S, 2000, P SOC PHOTO-OPT INS, V3969, P130
   Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   Adobe Systems Inc, 2012, AD REAL TIM MESS PRO
   Alcock S, 2011, ACM SIGCOMM COMP COM, V41, P25, DOI 10.1145/1971162.1971166
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   Chen Lu Chen Lu, 2013, China Vegetables, P1
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Finamore A., 2011, ACM IMC, P345, DOI DOI 10.1145/2068816.2068849
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Kuschnig R., 2010, MMSYS, P157
   Lederer S., 2012, P 3 MULT SYST C, P89
   Lin CL, 2013, IEEE NANOTECHNOL MAT, P1, DOI [10.1109/NMDC.2013.6707460, 10.1109/PLASMA.2013.6633193]
   Liu X, 2012, ACM SIGCOMM COMP COM, V42, P359, DOI 10.1145/2377677.2377752
   Lohmar T., 2012, 22nd ACM Workshop on Network and Operating System Support for Digital Audio and Video (NOSSDAV), P21
   Luan TH, 2010, IEEE T MULTIMEDIA, V12, P64, DOI 10.1109/TMM.2009.2036294
   Mongy S, 2007, INT J PARALLEL EMERG, V22, P163, DOI 10.1080/17445760601125376
   ParandehGheibi A, 2011, IEEE J SEL AREA COMM, V29, P1064, DOI 10.1109/JSAC.2011.110516
   Plissonneau L., 2012, ACM MMSys'12, P203
   Qiu F., 2010, Proceedings of the International Workshop on Very-Large-Scale Multimedia Corpus, Mining and Retrieval, P49, DOI DOI 10.1145/1878137.1878149
   Rao A., 2011, Em: Proceedings of the Seventh COnference on emerging Networking EXperiments and Technologies, P1, DOI DOI 10.1145/2079296.2079321
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Stockhammer T, 2004, IEEE T MULTIMEDIA, V6, P268, DOI 10.1109/TMM.2003.822795
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Wang B., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P908
   Xu YD, 2012, LECT NOTES COMPUT SC, V7290, P343, DOI 10.1007/978-3-642-30054-7_27
   Xu YD, 2013, IEEE INFOCOM SER, P2715
   Xu YD, 2012, IEEE INFOCOM SER, P1826, DOI 10.1109/INFCOM.2012.6195557
NR 28
TC 26
Z9 31
U1 0
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2015
VL 17
IS 4
BP 485
EP 497
DI 10.1109/TMM.2015.2405343
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CE1QH
UT WOS:000351586300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fiandrotti, A
   Gaeta, R
   Grangetto, M
AF Fiandrotti, Attilio
   Gaeta, Rossano
   Grangetto, Marco
TI Simple Countermeasures to Mitigate the Effect of Pollution Attack in
   Network Coding-Based Peer-to-Peer Live Streaming
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Continuity index; measurements; network coding; peer to peer (P2P);
   pollution attack
ID MALICIOUS NODES; CODES; IDENTIFICATION; SCHEME
AB Network coding (NC)-based peer-to-peer (P2P) streaming represents an effective solution to aggregate user capacities and to increase system throughput in live multimedia streaming. Nonetheless, such systems are vulnerable to pollution attacks where a handful of malicious peers can disrupt the communication by transmitting just a few bogus packets which are then recombined and relayed by unaware honest nodes, further spreading the pollution over the network. Whereas previous research focused on malicious nodes identification schemes and pollution-resilient coding, in this paper we show pollution countermeasures which make a standard NC scheme resilient to pollution attacks. Thanks to a simple yet effective analytical model of a reference node collecting packets by malicious and honest neighbors, we demonstrate that: i) packets received earlier are less likely to be polluted, and ii) short generations increase the likelihood to recover a clean generation. Therefore, we propose a recombination scheme where nodes draw packets to be recombined according to their age in the input queue, paired with a decoding scheme able to detect the reception of polluted packets early in the decoding process and short generations. The effectiveness of our approach is experimentally evaluated in a real system we developed and deployed on hundreds to thousands of peers. Experimental evidence shows that, thanks to our simple countermeasures, the effect of a pollution attack is almost canceled and the video quality experienced by the peers is comparable to pre-attack levels.
C1 [Fiandrotti, Attilio] Sisvel Technol, I-10060 None Torinese, Italy.
   [Gaeta, Rossano; Grangetto, Marco] Univ Turin, Dept Comp Sci, I-10149 Turin, Italy.
C3 University of Turin
RP Fiandrotti, A (corresponding author), Sisvel Technol, I-10060 None Torinese, Italy.
EM attilio.fiandrotti@sisveltech.com; rossano.gaeta@unito.it;
   marco.grangetto@unito.it
RI Grangetto, Marco/D-1222-2010; GAETA, Rossano/C-6256-2011
OI Fiandrotti, Attilio/0000-0002-9991-6822; GAETA,
   Rossano/0000-0002-6521-403X
CR Bioglio V, 2009, IEEE COMMUN LETT, V13, P953, DOI 10.1109/LCOMM.2009.12.091824
   Charles D., 2006, Proceedings of the Conference in Information Sciences and Systems, V1, P3
   Dhungel P., 2007, P2P TV PROC WORKSHOP, P323
   Fiandrotti A, 2014, IEEE T MULTIMEDIA, V16, P521, DOI 10.1109/TMM.2013.2285518
   Fiandrotti A, 2012, EUR SIGNAL PR CONF, P1529
   Gaeta R, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2568223
   Gaeta R, 2013, IEEE T PARALL DISTR, V24, P1994, DOI 10.1109/TPDS.2012.342
   Gkantsidis C, 2006, IEEE INFOCOM SER, P1749, DOI 10.1109/infocom.2006.233
   Grangetto M, 2009, IEEE INT CON MULTI, P1500, DOI 10.1109/ICME.2009.5202788
   Ho T, 2008, IEEE T INFORM THEORY, V54, P2798, DOI 10.1109/TIT.2008.921894
   Huang G., 2007, P ACM SIGCOMM WORKSH, P22
   Jaggi S, 2008, IEEE T INFORM THEORY, V54, P2596, DOI 10.1109/TIT.2008.921711
   Jin X, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671965
   Kehdi E, 2009, IEEE INFOCOM SER, P1224, DOI 10.1109/INFCOM.2009.5062036
   Kötter R, 2008, IEEE T INFORM THEORY, V54, P3579, DOI 10.1109/TIT.2008.926449
   Krohn MN, 2004, P IEEE S SECUR PRIV, P226
   Li Q., 2006, P WORKSH MULT SEC, P158
   Li YK, 2010, PERFORM EVALUATION, V67, P1273, DOI 10.1016/j.peva.2010.08.005
   Liang J, 2005, IEEE INFOCOM SER, P1174
   Mirshokraie S., 2010, Proc. ACM Multimedia Syst. Conf. Scottsdale, P123
   Wang M, 2007, IEEE T MULTIMEDIA, V9, P1554, DOI 10.1109/TMM.2007.907460
   Wang Q, 2011, PSYCHOL MED, V41, P1690, DOI 10.1017/S0033291710002412
   Yu Z, 2008, IEEE INFOCOM SER, P2083
   Yu Z, 2009, IEEE INFOCOM SER, P406, DOI 10.1109/INFCOM.2009.5061945
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 25
TC 14
Z9 15
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2015
VL 17
IS 4
BP 562
EP 573
DI 10.1109/TMM.2015.2402516
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CE1QH
UT WOS:000351586300009
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Gao, Y
   Shi, MJ
   Tao, DC
   Xu, C
AF Gao, Yuan
   Shi, Miaojing
   Tao, Dacheng
   Xu, Chao
TI Database Saliency for Fast Image Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Bag-of-visual-words (BoW); bottom-up saliency; database saliency; image
   retrieval; top-down saliency
ID SUPPORT VECTOR MACHINES; OBJECT RETRIEVAL; LOCALIZATION; SIMILARITY;
   FEATURES
AB The bag-of-visual-words (BoW) model is effective for representing images and videos in many computer vision problems, and achieves promising performance in image retrieval. Nevertheless, the level of retrieval efficiency in a large-scale database is not acceptable for practical usage. Considering that the relevant images in the database of a given query are more likely to be distinctive than ambiguous, this paper defines "database saliency" as the distinctiveness score calculated for every image to measure its overall "saliency" in the database. By taking advantage of database saliency, we propose a saliency-inspired fast image retrieval scheme, S-sim, which significantly improves efficiency while retains state-of-the-art accuracy in image retrieval. There are two stages in S-sim: the bottom-up saliency mechanism computes the database saliency value of each image by hierarchically decomposing a posterior probability into local patches and visual words, the concurrent information of visual words is then bottom-up propagated to estimate the distinctiveness, and the top-down saliency mechanism discriminatively expands the query via a very low-dimensional linear SVM trained on the top-ranked images after initial search, ranking images are then sorted on their distances to the decision boundary as well as the database saliency values. We comprehensively evaluate S-sim on common retrieval benchmarks, e.g., Oxford and Paris datasets. Thorough experiments suggest that, because of the offline database saliency computation and online low-dimensional SVM, our approach significantly speeds up online retrieval and outperforms the state-of-the-art BoW-based image retrieval schemes.
C1 [Gao, Yuan; Shi, Miaojing; Xu, Chao] Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China.
   [Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia.
   [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.
C3 Peking University; University of Technology Sydney; University of
   Technology Sydney
RP Gao, Y (corresponding author), Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China.
EM yuangaopkucis@gmail.con; shimj@cis.pku.edu.cn; dacheng.tao@uts.edu.au;
   xuchao@cis.pku.edu.cn
RI Tao, Dacheng/A-5449-2012; cheng, cheng/JBR-8359-2023
OI Tao, Dacheng/0000-0001-7225-5449; 
FU NBRPC [2011CB302400]; NSFC [61375026]; JCYJ [20120614152136201];
   Australian Research Council [DP-140102164, FT- 130101457, LP-140100569];
    [2015BAF15B00]
FX This work was supported by NBRPC 2011CB302400, NSFC 61375026,
   2015BAF15B00, JCYJ 20120614152136201, and the Australian Research
   Council under Project DP-140102164, Project FT- 130101457, and Project
   LP-140100569. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. K. Selcuk Candan.
   (Yuan Gao and Miaojing Shi contributed equally to this work.)
CR [Anonymous], 2011, RR7656 INRIA
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], 2012, P 20 ACM INT C MULTI
   ARANDJELOVIC R, 2012, PROC CVPR IEEE, P2911, DOI DOI 10.1109/CVPR.2012.6248018
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chen L, 2012, IEEE T MULTIMEDIA, V14, P1057, DOI 10.1109/TMM.2012.2187435
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng J, 2011, IEEE I CONF COMP VIS, P1028, DOI 10.1109/ICCV.2011.6126348
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/CVPRW.2009.5206587
   Jain V., 2011, International Conference on World Wide Web, P277, DOI DOI 10.1145/1963405.1963447
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Khan FS, 2009, IEEE I CONF COMP VIS, P979, DOI 10.1109/ICCV.2009.5459362
   Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026
   Krapac J, 2010, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR.2010.5540092
   Li YX, 2012, IEEE T MULTIMEDIA, V14, P1618, DOI 10.1109/TMM.2012.2199292
   Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Platt JC, 2000, ADV NEUR IN, P61
   Qin DF, 2013, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2013.211
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Shi M., 2012, P 20 ACM INT C MULT, P69
   Shi MJ, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2641576
   Shi MJ, 2013, IEEE T IMAGE PROCESS, V22, P1209, DOI 10.1109/TIP.2012.2228494
   Sollich P, 2002, MACH LEARN, V46, P21, DOI 10.1023/A:1012489924661
   Tang W., 2011, P 19 ACM INT C MULT, P503
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tian XM, 2012, IEEE T MULTIMEDIA, V14, P951, DOI 10.1109/TMM.2011.2177647
   Verma N, 2012, PROC CVPR IEEE, P2280, DOI 10.1109/CVPR.2012.6247938
   Xu R., 2011, P IEEE C MULT EXP JU, P262
   Zha Z.-J., 2009, P ACM INT C MULT, P5
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
   Zheng L, 2013, PROC CVPR IEEE, P1626, DOI 10.1109/CVPR.2013.213
NR 44
TC 91
Z9 100
U1 1
U2 36
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD MAR
PY 2015
VL 17
IS 3
BP 359
EP 369
DI 10.1109/TMM.2015.2389616
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA CE1QB
UT WOS:000351585700008
OA Green Published
DA 2024-07-18
ER

PT J
AU Korus, P
   Bialas, J
   Dziech, A
AF Korus, Pawel
   Bialas, Jaroslaw
   Dziech, Andrzej
TI Towards Practical Self-Embedding for JPEG-Compressed Digital Images
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Content authentication; content reconstruction; digital watermarking;
   self-embedding
ID WATERMARKING; AUTHENTICATION
AB This paper deals with the design of a practical self-recovery mechanism for lossy compressed JPEG images. We extend a recently proposed model of the content reconstruction problem based on digital fountain codes to take into account the impact of emerging watermark extraction and block classification errors. In contrast to existing methods, our scheme guarantees a high and stable level of reconstruction quality. Instead of introducing reconstruction artifacts, emerging watermark extraction errors penalize the achievable tampering rates. We introduce new mechanisms that allow for handling high-resolution and color images efficiently. In order to analyze the behavior of our scheme, we derive an improved model to calculate the reconstruction success probability. We introduce a new hybrid mechanism for spreading the reference information over the entire image, which allows to find a good balance between the achievable tampering rates and the computational complexity. Such an approach reduced the watermark embedding time from the order of several minutes to the order of single seconds, even on mobile devices.
C1 [Korus, Pawel; Bialas, Jaroslaw; Dziech, Andrzej] AGH Univ Sci & Technol, Dept Telecommun, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Korus, P (corresponding author), AGH Univ Sci & Technol, Dept Telecommun, PL-30059 Krakow, Poland.
EM pkorus@agh.edu.pl; bialas@kt.agh.edu.pl; dziech@kt.agh.edu.pl
RI Dziech, Andrzej/M-4483-2016; Korus, Pawel/J-7454-2012
OI Korus, Pawel/0000-0002-4230-9853
FU European Regional Development Fund under INSIGMA Project
   [POIG.01.01.02-00-062/09]
FX This work was supported by the European Regional Development Fund under
   INSIGMA Project POIG.01.01.02-00-062/09. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Jing-Ming Guo.
CR [Anonymous], P 9 ACM INT C MULT O
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Blythe Paul, 2004, P DIG FOR RES WORKSH, P1
   Brent RP, 2003, SIAM J DISCRETE MATH, V16, P276, DOI 10.1137/S089548010139388X
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2324, DOI 10.1016/j.sigpro.2009.02.001
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Fridrich J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P792, DOI 10.1109/ICIP.1999.817228
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Hui Wang, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P72, DOI 10.1007/978-3-642-32205-1_8
   Korus P., 2013, P EUR SIGN PROC C MA, P1
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Lee J, 1999, ELECTRON LETT, V35, P886, DOI 10.1049/el:19990642
   MacKay DJC, 2005, IEE P-COMMUN, V152, P1062, DOI 10.1049/ip-com:20050237
   Mendoza-Noriega JA, 2010, MIDWEST SYMP CIRCUIT, P612, DOI 10.1109/MWSCAS.2010.5548902
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilson EB, 1927, J AM STAT ASSOC, V22, P209, DOI 10.2307/2276774
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 19
TC 26
Z9 27
U1 0
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2015
VL 17
IS 2
BP 157
EP 170
DI 10.1109/TMM.2014.2368696
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AZ4RN
UT WOS:000348210500002
DA 2024-07-18
ER

PT J
AU Lee, Z
   Nguyen, TQ
AF Lee, Zucheul
   Nguyen, Truong Q.
TI Multi-Array Camera Disparity Enhancement
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cross-filling; depth estimation; multi-array camera; total variation;
   Tikhonov
ID RECOVERY
AB Multi-array camera systems have greater potential for 3-D depth-based application development compared with stereo camera systems. However, there are very few research results on multi-array-based disparity enhancement, extending standard stereo matchings to multi-array systems. In this paper, we propose to alternately use local and global fusion of multi-array disparities to maximize the disparity enhancement in array camera systems. We propose a new cascade regularization based approach, which can restore diagonal structures better than conventional techniques. The detailed analysis and experimental results verify that the cascade approach better regularizes the diagonal variations and in turn yields better image enhancement. We adapt total variation for regularization to the multi-array camera systems in order to globally combine multiple disparity estimates. A local multiple cross-filling algorithm is proposed to achieve cross consistency between array disparity estimates by effectively filling the mismatches. Experimental results show that the proposed multi-array disparity enhancement algorithm can improve the accuracy of the initial array disparity estimates up to 65% while alleviating memory limitation.
C1 [Lee, Zucheul; Nguyen, Truong Q.] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
C3 University of California System; University of California San Diego
RP Lee, Z (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
EM z1lee@ucsd.edu; tqn001@ucsd.edu
RI Nguyen, Truong/JXN-9786-2024
FU National Science Foundation [CCF-1065305]; Industrial Technology
   Innovation Program [10048100]
FX This work was supported in part by the National Science Foundation under
   Grant CCF-1065305 and by the Industrial Technology Innovation Program
   under Grant 10048100. The associate editor coordinating the review of
   this manuscript and approving it for publication was Prof. Pal
   Halvorsen.
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2006.207
   [Anonymous], 2002, COMPUTATIONAL METHOD
   [Anonymous], TR0812 CAAM RIC U
   Beck A, 2006, SIAM J OPTIMIZ, V17, P98, DOI 10.1137/050624418
   Bertero M., 1998, Introduction to Inverse Problems in Imaging
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   COCHRAN SD, 1992, IEEE T PATTERN ANAL, V14, P981, DOI 10.1109/34.159902
   Davis PJ., 1994, Circulant matrices, V2nd
   Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   Golub G.H., 1989, MATRIX COMPUTATION
   HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926
   Lee Z, 2013, IEEE T MULTIMEDIA, V15, P1855, DOI 10.1109/TMM.2013.2270456
   Lu J., 2008, P SPIE IS T ELECT IM, V6812, P68120
   Maitre M., 2008, Proc. IEEE CVPR, P1
   Mei X, 2011, PROC CVPR IEEE, P1257
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Scharstein D., 2010, Middlebury stereo evaluation version 2
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Shechtman E, 2005, IEEE T PATTERN ANAL, V27, P531, DOI 10.1109/TPAMI.2005.85
   Szlam A, 2010, IEEE IMAGE PROC, P1917, DOI 10.1109/ICIP.2010.5651881
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Wanner S., 2013, INT S VIS MOD VIS, P225
   Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Yamada K, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P772, DOI 10.1109/ICIP.2000.899823
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhang L, 2009, PROC CVPR IEEE, P1542, DOI 10.1109/CVPRW.2009.5206836
NR 36
TC 10
Z9 12
U1 3
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2014
VL 16
IS 8
BP 2168
EP 2177
DI 10.1109/TMM.2014.2355131
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AU4HL
UT WOS:000345571300008
DA 2024-07-18
ER

PT J
AU Kofler, C
   Yang, LJ
   Larson, M
   Mei, T
   Hanjalic, A
   Li, SP
AF Kofler, Christoph
   Yang, Linjun
   Larson, Martha
   Mei, Tao
   Hanjalic, Alan
   Li, Shipeng
TI Predicting Failing Queries in Video Search
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Query failure; query performance prediction; transaction log analysis;
   video search; visual consistency
ID RETRIEVAL
AB The ability to predict when a video search query is not likely to deliver satisfying search results is expected to enable more effective search results optimizations and improved search experience for users. In this paper, we propose a novel context-aware query failure prediction approach that predicts whether a particular query submitted in a user's search session is likely to fail. The approach builds on the well-known concept of query performance prediction introduced in conventional text-based Web search to estimate the query's retrieval performance, but extends this concept with two novel characteristics, user indicators and engine indicators. User indicators are derived from transaction logs, capture the patterns of user interactions with the video search engine, and exploit the context in which a particular query was submitted. Engine indicators are derived from the search results list and measure the consistency of visual search results at the level of visual concepts and textual metadata associated with videos. Extensive evaluation of the approach on a test set containing over one million video search queries shows its effectiveness and demonstrates a significant improvement over traditional and state-of-the-art baseline approaches.
C1 [Kofler, Christoph; Larson, Martha; Hanjalic, Alan] Delft Univ Technol, Delft, Netherlands.
   [Yang, Linjun] Microsoft Res, Redmond, WA 98052 USA.
   [Mei, Tao; Li, Shipeng] Microsoft Res, Beijing, Peoples R China.
C3 Delft University of Technology; Microsoft; Microsoft
RP Kofler, C (corresponding author), Delft Univ Technol, Delft, Netherlands.
EM c.kofler@tudelft.nl
RI Li, Shipeng/AAA-3374-2020; Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307; Li, Shipeng/0000-0001-5368-4256; Hanjalic,
   Alan/0000-0002-5771-2549
FU Google Europe Doctoral Fellowship in Video Search
FX The work of C. Kofler was supported by a Google Europe Doctoral
   Fellowship in Video Search. The associate editor coordinating the review
   of this manuscript and approving it for publication was Dr. Shin'ichi
   Satoh.
CR [Anonymous], 2007, CIVR '07
   [Anonymous], 2009, P 18 ACM C INF KNOWL
   Cronen-Townsend S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P299
   Fox S, 2005, ACM T INFORM SYST, V23, P147, DOI 10.1145/1059981.1059982
   Guo Q., 2010, Adaptivity, Personalization and Fusion of Heterogeneous Information, RIAO '10, P198
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hanjalic Alan., 2012, P 20 ACM INT C MULT, P1239
   Hassan A., 2010, Proceedings of the Third ACM International Conference on Web Search and Data Mining (WSDM '10), P221
   Hauff C., 2008, P 17 ACM C INF KNOWL, P439
   He B, 2004, LECT NOTES COMPUT SC, V3246, P43
   Hollink V., 2011, P INT WORKSH US AN W
   Imran H., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P867, DOI 10.1109/ICDMW.2010.81
   Jansen B., 2004, J WEB ENG, V3, P182
   Jansen BJ, 2009, J AM SOC INF SCI TEC, V60, P1358, DOI 10.1002/asi.21071
   Jeonghyun Kim, 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P1697, DOI 10.1109/HICSS.2012.150
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kim Y, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P193, DOI 10.1145/2556195.2556220
   Kofler C, 2011, LECT NOTES COMPUT SC, V6611, P611, DOI 10.1007/978-3-642-20161-5_61
   Kofler Christoph, 2012, P 20 ACM INT C MULT, P319, DOI 10.1145/2393347.2393395
   Kotov A, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P5
   Li YX, 2012, NEUROCOMPUTING, V95, P48, DOI 10.1016/j.neucom.2011.08.042
   Mast A. W., 2011, AER C 2011 IEEE, P1
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Pu HT, 2008, J INF SCI, V34, P275, DOI 10.1177/0165551507084140
   Rose D.E., 2004, P 13 INT C WORLD WID, P13, DOI [DOI 10.1145/988672.988675, 10.1145/988672.988675]
   Rudinac S, 2012, INT J MULTIMED INF R, V1, P263, DOI 10.1007/s13735-012-0018-0
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Tjondronegoro D, 2009, J AM SOC INF SCI TEC, V60, P1756, DOI 10.1002/asi.21094
   Tonta Y., 1992, PUBLIC ACCESS COMPUT, V3, P4
   Xiang BA, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P451
   Xing X, 2010, LECT NOTES COMPUT SC, V5993, P581, DOI 10.1007/978-3-642-12275-0_52
   Yom-Tov E., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P512, DOI 10.1145/1076034.1076121
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zhao Y, 2008, LECT NOTES COMPUT SC, V4956, P52
NR 37
TC 4
Z9 4
U1 0
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2014
VL 16
IS 7
BP 1973
EP 1985
DI 10.1109/TMM.2014.2347937
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AT1UX
UT WOS:000344720300015
DA 2024-07-18
ER

PT J
AU Kofler, C
   Larson, M
   Hanjalic, A
AF Kofler, Christoph
   Larson, Martha
   Hanjalic, Alan
TI Intent-Aware Video Search Result Optimization
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Result optimization; user intent; video search
AB Video search engines are relatively successful at returning search results that users find to be on topic. These results do not, however, completely satisfy the user's information need unless they also fulfill the user's intent, i.e., the immediate goal a user seeks to accomplish with video search. Satisfying a user's information need to its full extent poses a particular challenge to video search engines because user intent is often not explicitly reflected in the query. In this paper, we propose a multimodal approach that addresses this challenge by refining the results lists returned by a mainstream video search engine in order to optimally capture user intent. Our approach is based on the insight that the results lists returned by video search engines do contain videos that satisfy user's intent, but that videos with the highest potential for satisfaction are often buried within or scattered over the results list. The proposed approach consists of three steps. In the first step, it analyzes the initial results list to determine the intent distribution pattern. On the basis of this pattern, in the second step, it refines the video search results list such that the top of the list better reveals intent. The third step further improves this refinement by visual reranking, exploiting intent-sensitive lightweight visual features extracted from thumbnails. Extensive evaluation of the approach includes a user study carried out on a crowdsourcing platform and a system-oriented evaluation. Evaluation results demonstrate that our approach leads to a substantial improvement of the information need satisfaction at users.
C1 [Kofler, Christoph] Delft Univ Technol, Delft, Netherlands.
   [Larson, Martha] Delft Univ Technol, Multimedia Informat Retrieval Lab, Delft, Netherlands.
   [Hanjalic, Alan] Delft Univ Technol, Multimedia Comp Grp, Delft, Netherlands.
C3 Delft University of Technology; Delft University of Technology; Delft
   University of Technology
RP Kofler, C (corresponding author), Delft Univ Technol, Delft, Netherlands.
EM c.kofler@tudelft.nl
OI Hanjalic, Alan/0000-0002-5771-2549
FU Google Fellowship; Dutch national program COMMIT
FX This work was supported in part by a Google Fellowship and in part by
   the Dutch national program COMMIT. The associate editor coordinating the
   review of this manuscript and approving it for publication was Dr. Jiebo
   Luo.
CR Agrawal Rakesh, 2009, P 2 ACM INT C WEB SE, P5, DOI DOI 10.1145/1498759.1498766
   Alonso Omar, 2008, SIGIR Forum, V42, P9, DOI 10.1145/1480506.1480508
   Alonso O., SIGIR 09 WORKS F
   [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   [Anonymous], 2013, MMSYS
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], 2010, P ACM INT C MULT
   Azar Y, 2009, ACM S THEORY COMPUT, P669
   Blanco R, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P923
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552
   Cao HH, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P3, DOI 10.1145/1571941.1571945
   Chandar P., 2011, DDR ECIR 11
   Cronen-Townsend S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P299
   Cui J., 2008, MM 08, P997
   Eickhoff Carsten, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P38, DOI 10.1007/978-3-642-36973-5_4
   Fox S, 2005, ACM T INFORM SYST, V23, P147, DOI 10.1145/1059981.1059982
   Hanjalic Alan., 2012, P 20 ACM INT C MULT, P1239
   Hsu W. H., 2006, MULTIMEDIA '06, P35
   Hsu WinstonH., 2007, ACM MM
   Jansen B., 2004, J WEB ENG, V3, P182
   Jansen BJ, 2008, INFORM PROCESS MANAG, V44, P1251, DOI 10.1016/j.ipm.2007.07.015
   Kennedy L. S., 2005, 13th Annual ACM International Conference on Multimedia, P882, DOI 10.1145/1101149.1101339
   KOFLER C, 2009, P 17 ACM INT C MULT, P1117
   Kofler C, 2011, LECT NOTES COMPUT SC, V6611, P611, DOI 10.1007/978-3-642-20161-5_61
   Lee U., 2005, Proceedings of the 14th international conference on World Wide Web, WWW '05, P391, DOI DOI 10.1145/1060745.1060804
   Li YX, 2012, NEUROCOMPUTING, V95, P48, DOI 10.1016/j.neucom.2011.08.042
   Liu Y, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P297, DOI 10.1109/ICME.2008.4607430
   Liu YA, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P500, DOI 10.1145/1571941.1572027
   Mei T, 2007, IEEE T MULTIMEDIA, V9, P66, DOI 10.1109/TMM.2006.886357
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Rose D.E., 2004, P 13 INT C WORLD WID, P13, DOI [DOI 10.1145/988672.988675, 10.1145/988672.988675]
   Santos RLT, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P595
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Tian X., 2008, ACM INT C MULTIMEDIA, P131, DOI DOI 10.1145/1459359.1459378.ISBN
   Tjondronegoro D, 2009, J AM SOC INF SCI TEC, V60, P1756, DOI 10.1002/asi.21094
   Wu S., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P648, DOI 10.1145/584792.584908
   Yan R, 2003, LECT NOTES COMPUT SC, V2728, P238
   Yan R., 2004, PROC ACM INT C MULTI, P548
   Yang YH, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P285, DOI [10.1109/ICNNSP.2008.4590357, 10.1109/ICME.2008.4607427]
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
NR 42
TC 11
Z9 11
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2014
VL 16
IS 5
BP 1421
EP 1433
DI 10.1109/TMM.2014.2315777
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AN0SZ
UT WOS:000340295600022
DA 2024-07-18
ER

PT J
AU Liu, NH
AF Liu, Ning-Han
TI Effective Results Ranking for Mobile Query by Singing/Humming Using a
   Hybrid Recommendation Mechanism
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Genetic algorithm; music database; music recommendation; query by
   humming; query ranking
ID MUSIC; SYSTEM; USAGE
AB When a user cannot remember the title of a song, or its related details, the most direct and convenient method to search for the song is by humming a section of it. This search method is particularly important when a user does not have access to operate the audio device. The design methodology used in conventional search mechanisms that query by singing/humming, commonly emphasize signal processing or music comparison. The background of the user often influences the genres of the songs being searched, and this is an area of research seldom studied. In our study, we use the information from a user's search history, as well as the properties of genres common to users with similar backgrounds, to estimate the genre or style the current user may be interested in based on a probability calculation. The accuracy from querying by singing/humming is improved. Our method can be divided into two phases. In the first phase, we find the possible search results. This is similar to the conventional singing/humming query process. During the second phase, the musical preference of the user is utilized to rank the possible search results again. Songs that are most likely to be queried would be positioned at the front of the list in the search results. Through our experiments, significant improvement is demonstrated with our method.
C1 Natl Pingtung Univ Sci & Technol, Dept Management Informat Syst, Pingtung, Taiwan.
C3 National Pingtung University Science & Technology
RP Liu, NH (corresponding author), Natl Pingtung Univ Sci & Technol, Dept Management Informat Syst, Pingtung, Taiwan.
EM gregliu@mail.npust.edu.tw
FU NSC in Taiwan [NSC102-2218-E-020-002]
FX This work was supported in part by the NSC in Taiwan under the contact
   number NSC102-2218-E-020-002. The associate editor coordinating the
   review of this manuscript and approving it for publication was Dr. Cees
   G. M. Snoek.
CR [Anonymous], 2011, P ISMIR
   [Anonymous], VASA, DOI DOI 10.1002/1521-3773(20010316)40:63.3.CO;2-C
   Bellman R., 1957, Dynamic programming
   Bogdanov D, 2013, INFORM PROCESS MANAG, V49, P13, DOI 10.1016/j.ipm.2012.06.004
   Bogdanov Dmitry., 2011, 12th International Society for Music Information Retrieval Conference, number ISMIR 2011, P97
   Celma O., 2008, THESIS U POMPEU FABR
   Cho YH, 2004, EXPERT SYST APPL, V26, P233, DOI 10.1016/S0957-4174(03)00138-6
   Chung-Che Wang, 2012, 2012 41st International Conference on Parallel Processing Workshops (ICPPW 2012), P561, DOI 10.1109/ICPPW.2012.76
   Colorni A., 1991, Distributed optimization by ant colonies, V142, P134
   Cornelis O, 2010, SIGNAL PROCESS, V90, P1008, DOI 10.1016/j.sigpro.2009.06.020
   Crochemore M., 1994, TEXT ALGORITHMS
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Domingues MA, 2013, INT J MULTIMED INF R, V2, P3, DOI 10.1007/s13735-012-0025-1
   Doraisamy S, 2003, J INTELL INF SYST, V21, P53, DOI 10.1023/A:1023553801115
   Ghias A., 1995, P READ MULT COMP NET, P216
   Hanna P, 2007, J NEW MUSIC RES, V36, P267, DOI 10.1080/09298210801927861
   Jang JSR, 2008, IEEE T AUDIO SPEECH, V16, P350, DOI 10.1109/TASL.2007.913035
   Jin Li, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P3349, DOI 10.1109/ICNC.2010.5583648
   Jing Qin, 2011, Journal of Software, V6, P2416, DOI 10.4304/jsw.6.12.2416-2420
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Lai S., 2011, KDD CUP
   Lee SK, 2010, INFORM SCIENCES, V180, P2142, DOI 10.1016/j.ins.2010.02.004
   Lemström K, 2010, INFORM RETRIEVAL, V13, P1, DOI 10.1007/s10791-009-9097-9
   Li Q, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P33
   Liu NH, 2009, INT J COMPUT SCI NET, V9, P219
   Liu NH, 2013, APPL INTELL, V38, P160, DOI 10.1007/s10489-012-0363-y
   McFee B, 2012, P 21 INT C WORLD WID, P909, DOI [DOI 10.1145/2187980, 10.1145/2187980.2188222]
   McLeod Philip, 2005, ICMC
   McNab R. J., 1996, Proceedings of the 1st ACM International Conference on Digital Libraries, P11, DOI 10.1145/226931.226934
   Nanopoulos A, 2010, IEEE T AUDIO SPEECH, V18, P407, DOI 10.1109/TASL.2009.2033973
   Noll A. M., 1970, Proceedings of the symposium on computer processing in communications, P779
   NOLL AM, 1967, J ACOUST SOC AM, V41, P293, DOI 10.1121/1.1910339
   Oord A.V., 2013, P NEUR INF PROC SYST
   Rentfrow PJ, 2009, GROUP PROCESS INTERG, V12, P329, DOI 10.1177/1368430209102845
   Schedl M, 2011, INFORM PROCESS MANAG, V47, P426, DOI 10.1016/j.ipm.2010.09.002
   Schein A. I., 2001, P SIGIR WORKSH REC S, V6, P253
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Slaney M, 2011, IEEE MULTIMEDIA, V18, P12, DOI 10.1109/MMUL.2011.34
   Typke R., 2004, P 12 ANN ACM INT C M, P128, DOI DOI 10.1145/1027527.1027551
   Tzeng Y. S., 2004, P IASTED C INT MULT
   Urbano J., 2010, INT S COMP MUS MOD R, P385
   Urbano J., 2013, MIREX 2013SYMBOLIC M
   Yang XH, 2010, LECT NOTES COMPUT SC, V6059, P544, DOI 10.1007/978-3-642-13577-4_49
   Yoshii K., 2006, ISMIR, P296
   Yu HM, 2008, IEEE T MULTIMEDIA, V10, P1626, DOI 10.1109/TMM.2008.2007345
   Zahorian SA, 2008, J ACOUST SOC AM, V123, P4559, DOI 10.1121/1.2916590
NR 47
TC 3
Z9 3
U1 1
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2014
VL 16
IS 5
BP 1407
EP 1420
DI 10.1109/TMM.2014.2311326
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AN0SZ
UT WOS:000340295600021
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, H
   Wu, XX
   Jia, YD
AF Wang, Han
   Wu, Xinxiao
   Jia, Yunde
TI Video Annotation via Image Groups from the Web
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Concept-specific group; domain adaptation; event-specific group; video
   annotation
ID DOMAIN; RECOGNITION; FEATURES
AB Searching desirable events in uncontrolled videos is a challenging task. Current researches mainly focus on obtaining concepts from numerous labeled videos. But it is time consuming and labor expensive to collect a large amount of required labeled videos for training event models under various circumstances. To alleviate this problem, we propose to leverage abundant Web images for videos since Web images contain a rich source of information with many events roughly annotated and taken under various conditions. However, knowledge from the Web is noisy and diverse, brute force knowledge transfer of images may hurt the video annotation performance. Therefore, we propose a novel Group-based Domain Adaptation (GDA) learning framework to leverage different groups of knowledge (source domain) queried from the Web image search engine to consumer videos (target domain). Different from traditional methods using multiple source domains of images, our method organizes the Web images according to their intrinsic semantic relationships instead of their sources. Specifically, two different types of groups (i.e., event-specific groups and concept-specific groups) are exploited to respectively describe the event-level and concept-level semantic meanings of target-domain videos. Under this framework, we assign different weights to different image groups according to the relevances between the source groups and the target domain, and each group weight represents how contributive the corresponding source image group is to the knowledge transferred to the target video. In order to make the group weights and group classifiers mutually beneficial and reciprocal, a joint optimization algorithm is presented for simultaneously learning the weights and classifiers, using two novel data-dependent regularizers. Experimental results on three challenging video datasets (i.e., CCV, Kodak, and YouTube) demonstrate the effectiveness of leveraging grouped knowledge gained from Web images for video annotation.
C1 [Wang, Han; Wu, Xinxiao; Jia, Yunde] Beijing Inst Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
   [Wang, Han; Wu, Xinxiao; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology
RP Wu, XX (corresponding author), Beijing Inst Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM wanghan@bit.edu.cn; wuxinxiao@bit.edu.cn; jiayunde@bit.edu.cn
FU Natural Science Foundation of China (NSFC) [61203274]; Specialized
   Research Fund for the Doctoral Program of Higher Education of China
   [20121101120029]; Specialized Fund for Joint Building Program of Beijing
   Municipal Education Commission; Excellent Young Scholars Research Fund
   of BIT
FX This work was supported in part by the Natural Science Foundation of
   China (NSFC) under Grant No. 61203274, the Specialized Research Fund for
   the Doctoral Program of Higher Education of China (20121101120029), the
   Specialized Fund for Joint Building Program of Beijing Municipal
   Education Commission, and the Excellent Young Scholars Research Fund of
   BIT (2013). The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Vasileios Mezaris.
CR [Anonymous], P 2009 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2009.5206557
   [Anonymous], P 2 ACM INT C MULT R
   [Anonymous], P ICCV
   [Anonymous], 2007, P CVPR
   [Anonymous], P CVPR
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], P ICPR
   [Anonymous], P ICMR
   [Anonymous], P CVPR
   [Anonymous], P NIPS
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Chattopadhyay R, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382582
   Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556
   Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gupta A., 2007, P CVPR, P1
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Ikizler-Cinbis N, 2009, IEEE I CONF COMP VIS, P995, DOI 10.1109/ICCV.2009.5459368
   Jiang Yu-Gang., 2012, IJMIR, P1
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Loui Alexander., 2007, MIR 07, P245
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo P., 2008, P 17 ACM C INF KNOWL, P103, DOI DOI 10.1145/1458082.1458099
   Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4
   Naphade MilindR., 2004, P 12 ANN ACM INT C M, P660, DOI DOI 10.1145/1027527.1027680
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ryoo M.S., 2007, IEEE C COMPUTER VISI, P1
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sun Z, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P331, DOI 10.1109/ICMLA.2008.53
   Tang Kevin, 2012, P INT C NEUR INF PRO, P647
   Wang P, 2008, IEEE DATA MINING, P1085, DOI 10.1109/ICDM.2008.136
   Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891
   Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234
NR 37
TC 18
Z9 22
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2014
VL 16
IS 5
BP 1282
EP 1291
DI 10.1109/TMM.2014.2312251
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA AN0SZ
UT WOS:000340295600010
DA 2024-07-18
ER

PT J
AU Tang, NC
   Hsu, CT
   Weng, MF
   Lin, TY
   Liao, HYM
AF Tang, Nick C.
   Hsu, Chiou-Ting
   Weng, Ming-Fang
   Lin, Tsung-Yi
   Liao, Hong-Yuan Mark
TI Example-Based Human Motion Extrapolation and Motion Repairing Using
   Contour Manifold
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Contour manifold; motion synthesis; motion transfer
AB We propose a human motion extrapolation algorithm that synthesizes new motions of a human object in a still image from a given reference motion sequence. The algorithm is implemented in two major steps: contour manifold construction and object motion synthesis. Contour manifold construction searches for low-dimensional manifolds that represent the temporal-domain deformation of the reference motion sequence. Since the derived manifolds capture the motion information of the reference sequence, the representation is more robust to variations in shape and size. With this compact representation, we can easily modify and manipulate human motions through interpolation or extrapolation in the contour manifold space. In the object motion synthesis step, the proposed algorithm generates a sequence of new shapes of the input human object in the contour manifold space and then renders the textures of those shapes to synthesize a new motion sequence. We demonstrate the efficacy of the algorithm on different types of practical applications, namely, motion extrapolation and motion repair.
C1 [Tang, Nick C.; Weng, Ming-Fang; Liao, Hong-Yuan Mark] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   [Hsu, Chiou-Ting] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Lin, Tsung-Yi] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
   [Liao, Hong-Yuan Mark] Natl Chiao Tung Univ, Hsinchu 300, Taiwan.
C3 Academia Sinica - Taiwan; National Tsing Hua University; University of
   California System; University of California San Diego; National Yang
   Ming Chiao Tung University
RP Tang, NC (corresponding author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
EM nickctang@iis.sinica.edu.tw; cthsu@cs.nthu.edu.tw;
   mfueng@iis.sinica.edu.tw; tsl008@ucsd.edu; liao@iis.sinica.edu.tw
RI mingfang, weng/HSG-7737-2023; Liao, Hong-Yuan Mark/AAQ-5514-2021
OI mingfang, weng/0000-0003-1636-4717; Hsu, Chiou-Ting/0000-0001-8857-2481
FU Taiwan E-learning and Digital Archives Program (TELDAP); National
   Science Council of Taiwan under NSC [NSC99-2631-H-001-020]
FX This work was supported in part by the Taiwan E-learning and Digital
   Archives Program (TELDAP) and the National Science Council of Taiwan
   under NSC Grant NSC99-2631-H-001-020. The associate editor coordinating
   the review of this manuscript and approving it for publication was Prof.
   Ebroul Izquierdo.
CR [Anonymous], ACM TRANS GRAPH
   [Anonymous], ACM SIGGRAPH SKETCHE
   [Anonymous], P 19 ACM INT C MULT
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bookstein F., 1997, MORPHOMETRIC TOOLS L
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Ding T., 2007, PROC IEEE 11 INT C C, P1
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Gleicher M., 2001, P 2001 S INTERACTIVE, P195
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Hsieh JW, 2008, IEEE T MULTIMEDIA, V10, P372, DOI 10.1109/TMM.2008.917403
   Igarashi Takeo, 2009, Journal of Graphics Tools, V14, P17
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   Kobayashi Jun, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P487, DOI 10.1109/PSIVT.2010.88
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee CS, 2012, MACH VISION APPL, V23, P461, DOI 10.1007/s00138-010-0303-y
   Liang YM, 2009, IEEE INT SYMP CIRC S, P2605, DOI 10.1109/ISCAS.2009.5118335
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Shewchuk J. R., 1996, Applied Computational Geometry. Towards Geometric Engineering. FCRC'96 Workshop, WACG'96. Selected Papers, P203, DOI 10.1007/BFb0014497
   Shin HJ, 2006, COMPUT ANIMAT VIRT W, V17, P219, DOI 10.1002/cav.125
   Tang NC, 2011, IEEE T MULTIMEDIA, V13, P602, DOI 10.1109/TMM.2011.2112642
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Xu XM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409070
NR 30
TC 9
Z9 10
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JAN
PY 2014
VL 16
IS 1
BP 47
EP 59
DI 10.1109/TMM.2013.2283844
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 279GJ
UT WOS:000328948100005
DA 2024-07-18
ER

PT J
AU Li, HL
   Meng, FM
   Ngan, KN
AF Li, Hongliang
   Meng, Fanman
   Ngan, King Ngi
TI Co-Salient Object Detection From Multiple Images
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Attention model; co-saliency; minimum spanning tree; similarity.
ID VISUAL-ATTENTION; SEGMENTATION; MODEL; COSEGMENTATION
AB In this paper, we propose a novel method to discover co-salient objects from a group of images, which is modeled as a linear fusion of an intra-image saliency (IaIS) map and an inter-image saliency (IrIS) map. The first term is to measure the salient objects from each image using multiscale segmentation voting. The second term is designed to detect the co-salient objects from a group of images. To compute the IrIS map, we perform the pairwise similarity ranking based on an image pyramid representation. A minimum spanning tree is then constructed to determine the image matching order. For each region in an image, we design three types of visual descriptors, which are extracted from the local appearance, e. g., color, color co-occurrence and shape properties. The final region matching problem between the images is formulated as an assignment problem that can be optimized by linear programming. Experimental evaluation on a number of images demonstrates the good performance of the proposed method on co-salient object detection.
C1 [Li, Hongliang; Meng, Fanman; Ngan, King Ngi] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610073, Peoples R China.
   [Ngan, King Ngi] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 University of Electronic Science & Technology of China; Chinese
   University of Hong Kong
RP Li, HL (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610073, Peoples R China.
EM hlli@uestc.edu.cn; fanmanmeng@yahoo.com; knngan@ee.cuhk.edu.hk
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235; Li, Hongliang/0000-0002-7481-095X
FU NSFC [61271289]; National High Technology Research and Development
   Program of China (863 Program) [2012AA011503]; Ph.D. Programs Foundation
   of Ministry of Education of China [20110185110002]
FX This work was supported in part by NSFC (No. 61271289), National High
   Technology Research and Development Program of China (863 Program, No.
   2012AA011503), and The Ph.D. Programs Foundation of Ministry of
   Education of China (No. 20110185110002).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587420
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Ballard DH, 1997, BEHAV BRAIN SCI, V20, P723, DOI 10.1017/S0140525X97001611
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cho MS, 2008, LECT NOTES COMPUT SC, V5305, P144
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Franconeri SL, 2005, PSYCHOL SCI, V16, P275, DOI 10.1111/j.0956-7976.2005.01528.x
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2007, IEEE T CIRC SYST VID, V17, P1742, DOI 10.1109/TCSVT.2007.903326
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Mukherjee Lopamudra, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P1881, DOI 10.1109/CVPR.2011.5995420
   Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652
   Rother C., 2004, P SIGGRAPH 2004 LOS
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Tan HK, 2005, IEEE I CONF COMP VIS, P1222
   Toshev A., 2007, IEEE C COMPUTER VISI, P1
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34
   Wang M, 2011, PROC CVPR IEEE, P417, DOI 10.1109/CVPR.2011.5995743
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Yuan JS, 2007, IEEE I CONF COMP VIS, P321
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 48
TC 90
Z9 97
U1 0
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2013
VL 15
IS 8
BP 1896
EP 1909
DI 10.1109/TMM.2013.2271476
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 257OI
UT WOS:000327393900014
DA 2024-07-18
ER

PT J
AU Chu, CT
   Hwang, JN
   Pai, HI
   Lan, KM
AF Chu, Chun-Te
   Hwang, Jenq-Neng
   Pai, Hung-I
   Lan, Kung-Ming
TI Tracking Human Under Occlusion Based on Adaptive Multiple Kernels With
   Projected Gradients
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Kalman filter; kernel-based tracking; mean shift; projected gradient
ID MEAN-SHIFT; OBJECT TRACKING; COLOR
AB Kernel based trackers have been proven to be a promising approach for video object tracking. The use of a single kernel often suffers from occlusion since the available visual information is not sufficient for kernel usage. In order to provide more robust tracking performance, multiple inter-related kernels have thus been utilized for tracking in complicated scenarios. This paper presents an innovative method, which uses projected gradient to facilitate multiple kernels, in finding the best match during tracking under predefined constraints. The adaptive weights are applied to the kernels in order to efficiently compensate the adverse effect introduced by occlusion. An effective scheme is also incorporated to deal with the scale change issue during the object tracking. Moreover, we embed the multiple-kernel tracking into a Kalman filtering-based tracking system to enable fully automatic tracking. Several simulation results have been done to show the robustness of the proposed multiple-kernel tracking and also demonstrate that the overall system can successfully track the video objects under occlusion.
C1 [Chu, Chun-Te] Univ Washington, Dept Elect Engn, Informat Proc Lab, Seattle, WA 98195 USA.
   [Hwang, Jenq-Neng] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   [Pai, Hung-I; Lan, Kung-Ming] Triple Domain Vis Co Ltd, Hsinchu, Taiwan.
C3 University of Washington; University of Washington Seattle; University
   of Washington; University of Washington Seattle
RP Chu, CT (corresponding author), Univ Washington, Dept Elect Engn, Informat Proc Lab, Seattle, WA 98195 USA.
EM ctchu@uw.edu; hwang@uw.edu; hipai@tdv.com.tw; blue@tdv.com.tw
CR [Anonymous], 2008, IM LIB INT DET SYST
   [Anonymous], PRACTICAL MATH OPTIM
   [Anonymous], 2006, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2006.215
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chu CT, 2011, INT CONF ACOUST SPEE, P1421
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888
   Fan ZM, 2005, PROC CVPR IEEE, P502
   Fang JX, 2011, AEU-INT J ELECTRON C, V65, P915, DOI 10.1016/j.aeue.2011.02.013
   Fashing M, 2005, IEEE T PATTERN ANAL, V27, P471, DOI 10.1109/TPAMI.2005.59
   Hager GD, 2004, PROC CVPR IEEE, P790
   Kembhavi A, 2009, IEEE I CONF COMP VIS, P638, DOI 10.1109/ICCV.2009.5459179
   Leichter I, 2009, IEEE T PATTERN ANAL, V31, P164, DOI 10.1109/TPAMI.2008.194
   Martìnez B, 2006, IEEE IMAGE PROC, P2785, DOI 10.1109/ICIP.2006.313125
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   PARAMESWARAN V, 2006, P IEEE C COMP VIS PA, V2, P2179
   Porikli F., 2005, IEEE Intl. Conf. Multimedia and Expo, P1234
   RAKOTOMAMONJY A, 2007, P ICML
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374
   Wang S, 2011, IEEE ICC
   WU NQ, 2011, IEEE INT CONF ROBOT, pNI738
   YANG V, 2005, P IEEE C COMP VIS PA, V1, P176
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yilmaz A, 2007, PROC CVPR IEEE, P140
   Zhang HH, 2005, PROC CVPR IEEE, P293
   Zhou XZ, 2012, IEEE T IMAGE PROCESS, V21, P789, DOI 10.1109/TIP.2011.2168414
   2010, PETS 2010
NR 30
TC 49
Z9 59
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2013
VL 15
IS 7
BP 1602
EP 1615
DI 10.1109/TMM.2013.2266634
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 236PQ
UT WOS:000325811800012
DA 2024-07-18
ER

PT J
AU Fu, JJ
   Miao, D
   Yu, WR
   Wang, SQ
   Lu, Y
   Li, SP
AF Fu, Jingjing
   Miao, Dan
   Yu, Weiren
   Wang, Shiqi
   Lu, Yan
   Li, Shipeng
TI Kinect-Like Depth Data Compression
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE 2D+T prediction; denoising; depth volume; Kinect-like depth; lossy
   compression; padding
AB Unlike traditional RGB video, Kinect-like depth is characterized by its large variation range and instability. As a result, traditional video compression algorithms cannot be directly applied to Kinect-like depth compression with respect to coding efficiency. In this paper, we propose a lossy Kinect-like depth compression framework based on the existing codecs, aiming to enhance the coding efficiency while preserving the depth features for further applications. In the proposed framework, the Kinect-like depth is reformed first by divisive normalized bilateral filter (DNBL) to suppress the depth noises caused by disparity normalization, and then block-level depth padding is implemented for invalid depth region compensation in collaboration with mask coding to eliminate the sharp variation caused by depth measurement failures. Before the traditional video coding, the inter-frame correlation of reformed depth is explored by proposed 2D+T prediction, in which depth volume is developed to simulate 3D volume to generate pseudo 3D prediction reference for depth uniqueness detection. The unique depth region, called active region is fed into the video encoder for traditional intra and inter prediction with residual coding, while the inactive region is skipped during depth coding. The experimental results demonstrate that our compression scheme can save 55%-85% in terms of bit cost and reduce coding complexity by 20%-65% in comparison with the traditional video compression algorithms. The visual quality of the 3D reconstruction is also improved after employing our compression scheme.
C1 [Fu, Jingjing; Lu, Yan; Li, Shipeng] Microsoft Res Asia, Media Comp Grp, Beijing, Peoples R China.
   [Miao, Dan] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Peoples R China.
   [Yu, Weiren] Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Wang, Shiqi] Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
C3 Microsoft; Microsoft Research Asia; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS; Beihang University;
   Peking University
RP Fu, JJ (corresponding author), Microsoft Res Asia, Media Comp Grp, Beijing, Peoples R China.
EM jifu@microsoft.com; miaodan@mail.ustc.edu.cn; yuweiren@act.buaa.edu.cn;
   sqwang@jdl.ac.cn; yanlu@microsoft.com; spli@microsoft.com
RI Li, Shipeng/AAA-3374-2020; fu, jingjing/HLW-1028-2023
OI Li, Shipeng/0000-0001-5368-4256; Wang, Shiqi/0000-0002-3583-959X
CR Advanced Video Coding (AVC), 2004, 1449610 ISOIEC JVT
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   Chai BB, 2004, PATTERN RECOGN LETT, V25, P755, DOI 10.1016/j.patrec.2004.01.002
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Frankowski G, 2000, P SOC PHOTO-OPT INS, V3958, P90, DOI 10.1117/12.380051
   Fu JJ, 2012, IEEE INT SYMP CIRC S, P512, DOI 10.1109/ISCAS.2012.6272078
   Generic Coding of Moving Pictures and Associated Audio (MPEG-2), 1995, 11138182 ISOIEC JTC
   Gokturk S. B., 2004, P CVPR
   Grewatsch S., 2004, P 49 SPIES ANN M
   Grewatsch S., 2005, VIS IM IM PROC, P66
   Gumhold S., 2005, P SIGGRAPH 05 ACM SI
   Kammerl J., DEV EVALUATION POINT
   KANADE T, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1088, DOI 10.1109/ROBOT.1991.131738
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Khoshelham K., P ISPRS WORKSH 2011
   Liu SJ, 2011, IEEE T BROADCAST, V57, P551, DOI 10.1109/TBC.2011.2120750
   Maitre M, 2010, J VIS COMMUN IMAGE R, V21, P513, DOI 10.1016/j.jvcir.2010.03.005
   MAMOU K, FAMC MPEG 4 STANDARD
   Marshall G.F., 2004, Handbook of optical and laser scanning
   Mehrotra S., 2011, P MMSP IEEE OCT
   Milani S, 2010, IEEE SIGNAL PROC LET, V17, P51, DOI 10.1109/LSP.2010.2051619
   Morvan Y., 2007, P IEEE ICIP
   Murat A. T., FACE 2 DMESH ANIMATI
   Schnabel R., 2006, P S POINT BAS GRAPH, P147
   Shen G., 2010, P PICT COD S PCS NAG
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Weise T., 2011, P ACM SIGGRAPH
NR 32
TC 34
Z9 41
U1 0
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2013
VL 15
IS 6
BP 1340
EP 1352
DI 10.1109/TMM.2013.2247584
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 222XH
UT WOS:000324765400011
DA 2024-07-18
ER

PT J
AU Xie, LX
   Natsev, A
   He, XM
   Kender, JR
   Hill, M
   Smith, JR
AF Xie, Lexing
   Natsev, Apostol
   He, Xuming
   Kender, John R.
   Hill, Matthew
   Smith, John R.
TI Tracking Large-Scale Video Remix in Real-World Events
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image databases; YouTube; social networks
AB Content sharing networks, such as YouTube, contain traces of both explicit online interactions (such as likes, comments, or subscriptions), as well as latent interactions (such as quoting, or remixing, parts of a video). We propose visual memes, or frequently re-posted short video segments, for detecting and monitoring such latent video interactions at scale. Visual memes are extracted by scalable detection algorithms that we develop, with high accuracy. We further augment visual memes with text, via a statistical model of latent topics. We model content interactions on YouTube with visual memes, defining several measures of influence and building predictive models for meme popularity. Experiments are carried out with over 2 million video shots from more than 40,000 videos on two prominent news events in 2009: the election in Iran and the swine flu epidemic. In these two events, a high percentage of videos contain remixed content, and it is apparent that traditional news media and citizen journalists have different roles in disseminating remixed content. We perform two quantitative evaluations for annotating visual memes and predicting their popularity. The proposed joint statistical model of visual memes and words outperforms an alternative concurrence model, with an average error of 2% for predicting meme volume and 17% for predicting meme lifespan.
C1 [Xie, Lexing; He, Xuming] Australian Natl Univ, Canberra, ACT 0200, Australia.
   [Xie, Lexing; He, Xuming] Natl ICT Australia NICTA, Canberra, ACT 0200, Australia.
   [Natsev, Apostol] Google Res, Mountain View, CA 94043 USA.
   [Kender, John R.] Columbia Univ, New York, NY 10027 USA.
   [Hill, Matthew; Smith, John R.] IBM Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 Australian National University; NICTA; Google Incorporated; Columbia
   University; International Business Machines (IBM)
RP Xie, LX (corresponding author), Australian Natl Univ, GPO Box 4, Canberra, ACT 0200, Australia.
RI Smith, John/GYJ-1302-2022; Smith, John/HJB-2300-2022; Smith,
   John/Y-2316-2019
OI Smith, John/0000-0001-6885-1117; Xie, Lexing/0000-0001-8319-0118
FU Australian Government; Research Council through the ICT Centre of
   Excellence program; US Air Force Research Laboratory [FA2386-12-1-4041]
FX Manuscript received September 18, 2012; revised January 31, 2013 and
   April 24, 2013; accepted April 29, 2013. Date of publication May 29,
   2013; date of current version September 13, 2013. NICTA is funded by the
   Australian Government as represented by the Department of Broadband,
   Communications and the Digital Economy and the Australian Research
   Council through the ICT Centre of Excellence program. This work was
   supported in part by the US Air Force Research Laboratory, under
   agreement number FA2386-12-1-4041. The views and conclusions contained
   herein are those of the authors and should not be interpreted as
   necessarily representing the official policies or endorsements, either
   expressed or implied, of the Air Force Research Laboratory or the U.S.
   Government. This work was done while L. Xie, A. Natsev, and J. R. Kender
   were with IBM Research. The associate editor coordinating the review of
   this manuscript and approving it for publication was Dr. Daniel
   Gatica-Perez.
CR [Anonymous], INT C MULT
   Atkinson K., OFFICIAL 12 DICTS PA
   Bakshy E., 2011, P 4 ACM INT C WEB SE, P65
   Bakshy E, 2009, 10TH ACM CONFERENCE ON ELECTRONIC COMMERCE - EC 2009, P325
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Benevenuto F, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596994
   Biel J.-I., 2010, P AAAI ICWSM, V5
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borghol Y., 2012, ACM SIGKDD International Knowledge Discovery and Data Mining, P1186, DOI [DOI 10.1145/2339530.2339717, 10.1145/2339530.2339717]
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Burgess J., 2009, YouTube: Online video and participatory culture
   Cha M., 2010, P INT AAAI C WEB SOC, V4, P10, DOI DOI 10.1145/2897659.2897663
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Choudhury M.D., 2009, Proceedings of the 18th international conference on World wide web (WWW '09), P331, DOI DOI 10.1145/1526709.1526754
   Crane R, 2008, P NATL ACAD SCI USA, V105, P15649, DOI 10.1073/pnas.0803685105
   GALLER BA, 1964, COMMUN ACM, V7, P301, DOI 10.1145/364099.364331
   Ginsberg J, 2009, NATURE, V457, P1012, DOI 10.1038/nature07634
   Gladwell M., 2000, TIPPING POINT, P102
   Hong Richang, 2011, ACM T MULTIMEDIA COM
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kennedy L., 2008, P ACM MULT
   Kwak Haewoon, 2010, P INT C WORLD WID WE, DOI DOI 10.1145/1772690.1772751
   Leskovec J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P497
   Liu T., 2007, P IEEE WACV
   Machin D., 2006, Visual Communication, V5, P345, DOI DOI 10.1177/1470357206068464
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Natsev A., 2010, P ICME WORKSH
   Romero Daniel M, 2011, P 20 INT C WORLD WID, P695, DOI [10.1145/1963405.1963503, DOI 10.1145/1963405.1963503]
   Saez-Trumper D., 2012, P 18 ACM SIGKDD INT, P1014
   Schmitz P., 2006, P ACM MULT, P178
   Snickars Pelle., 2010, YOUTUBE READER
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Tan H.-K., 2008, P ACM INT C MULT, P861, DOI DOI 10.1145/1459359.1459506
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Xie L, 2011, P 19 ACM INT C MULT, P53, DOI DOI 10.1145/2072298.2072307
   Yang J., 2011, P 4 ACM INT C WEB SE, P177, DOI DOI 10.1145/1935826.1935863
   Yang J, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 2, P593, DOI 10.1109/ICCSIT.2010.5564008
   Yang L., 2012, P 21 INT C WORLD WID, P261, DOI DOI 10.1145/2187836.2187872
NR 41
TC 6
Z9 7
U1 0
U2 68
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2013
VL 15
IS 6
BP 1244
EP 1254
DI 10.1109/TMM.2013.2264929
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 222XH
UT WOS:000324765400003
OA Bronze, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Xiong, ZW
   Xu, D
   Sun, XY
   Wu, F
AF Xiong, Zhiwei
   Xu, Dong
   Sun, Xiaoyan
   Wu, Feng
TI Example-Based Super-Resolution With Soft Information and Decision
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Factor graph; message passing; parametric distribution; statistical
   learning; super-resolution
AB The one-to-one correspondence between co-occurrence image patches of two different resolutions is extensively used in example-based super-resolution (SR). Due to the dimensionality gap between low resolution (LR) and high resolution (HR) spaces, however, an LR patch may correspond to a number of HR patches in practice. This ambiguity is difficult to be overcome with examples representing a deterministic mapping. In this paper, we propose a statistical method for exploiting the one-to-many correspondence between LR and HR patches, which we call soft information and decision. Soft information means an LR patch is mapped to a pixel-wise distribution of all its possible HR counterparts, rather than a single or a limited set of HR candidates. Relying on the soft information, example-based SR is then regarded as an optimization problem to best preserve the local consistency in the recovered HR image. This problem is solved with an efficient message passing algorithm with a factor graph model. The final decision on the HR pixel value is made upon the maximum a posteriori estimation and is called a soft decision. Experimental results demonstrate the superiority of the proposed method compared with the state-of-the-art methods, in terms of both the subjective and objective quality of synthesized HR images.
C1 [Xiong, Zhiwei; Sun, Xiaoyan; Wu, Feng] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Xu, Dong] Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Microsoft Research Asia; Microsoft; Nanyang Technological University
RP Xiong, ZW (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM zhxiong@microsoft.com; dongxu@ntu.edu.sg; xysun@microsoft.com;
   fengwu@microsoft.com
RI Xu, Dong/A-3694-2011; Wu, Feng/KCY-3017-2024
CR [Anonymous], 2008, ACM T GRAPH
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], ACM T GRAPH
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   GLASNER D, 2009, P INT C COMP VIS
   Hennings-Yeomans P. H., 2008, P COMP VIS PATT REC
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572
   Mount D. M., 1997, ACM T MATH SOFTWARE, V2, P2
   Richardson TJ, 2001, IEEE T INFORM THEORY, V47, P599, DOI 10.1109/18.910577
   Siegler M. A., 1997, P DARPA SPEECH REC W
   Sun J., 2010, P COMP VIS PATT REC
   Tang Y, 2011, INT J MACH LEARN CYB, V2, P15, DOI 10.1007/s13042-011-0011-6
   Weissman T, 2005, IEEE T INFORM THEORY, V51, P5, DOI 10.1109/TIT.2004.839518
   Wu F., 2008, P DAT COMPR C
   Xiong R., 2010, P DAT COMPR C
   Xiong Z., 2009, P COMP VIS PATT REC
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P2017, DOI 10.1109/TIP.2010.2045707
NR 21
TC 48
Z9 53
U1 0
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2013
VL 15
IS 6
BP 1458
EP 1465
DI 10.1109/TMM.2013.2264654
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 222XH
UT WOS:000324765400020
DA 2024-07-18
ER

PT J
AU de Rooij, O
   Worring, M
AF de Rooij, Ork
   Worring, Marcel
TI Active Bucket Categorization for High Recall Video Retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Active learning; interactive video retrieval; multi class
   categorization; relevance feedback; user evaluation; video retrieval
AB There are large amounts of digital video available. High recall retrieval of these requires going beyond the ranked results, which is the common target in high precision retrieval. To aid high recall retrieval, we propose Active Bucket Categorization, which is a multicategory interactive learning strategy which extends MediaTable [1], our multimedia categorization tool. MediaTable allows users to place video shots into buckets: user-assigned subsets of the collection. Our Active Bucket Categorization approach augments this by unobtrusively expanding these buckets with related footage from the whole collection. In this paper, we propose an architecture for active bucket-based video retrieval, evaluate two different learning strategies, and show its use in video retrieval with an evaluation using three groups of nonexpert users. One baseline group uses only the categorization features of MediaTable such as sorting and filtering on concepts and fast grid preview, but no online learning mechanisms. One group uses on-demand passive buckets. The last group uses fully automatic active buckets which autonomously add content to buckets. Results indicate a significant increase in the number of relevant items found for the two groups of users using bucket expansions, yielding the best results with fully automatic bucket expansions, thereby aiding high recall video retrieval significantly.
C1 [de Rooij, Ork; Worring, Marcel] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 SJ Amsterdam, Netherlands.
C3 University of Amsterdam
RP de Rooij, O (corresponding author), Univ Amsterdam, Intelligent Syst Lab Amsterdam, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.
EM orooij@uva.nl; m.worring@uva.nl
RI Worring, Marcel/JRW-7059-2023
OI Worring, Marcel/0000-0003-4097-4136
CR Adcock J., 2007, P ACM INT C IM VID R, P644
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P INT WORKSH MULT IN
   [Anonymous], P ACM INT C MULT AUG
   [Anonymous], P 6 ACM INT C IM VID
   [Anonymous], P 6 TRECVID WORKSH G
   Cao Jinwei., 2009, Proceedings of The 15th Americas Conference on Information Systems(AMCIS), P1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cord M, 2007, IMAGE VISION COMPUT, V25, P14, DOI 10.1016/j.imavis.2006.01.004
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   De Rooij O., 2008, P ACM INT C IM VID R, P485
   de Rooij O, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.66
   de Rooij O, 2010, IEEE T MULTIMEDIA, V12, P121, DOI 10.1109/TMM.2009.2037388
   Goh K., 2004, PROC ACM INT C MULTI, P564
   Gosselin P., 2004, Proceedings of the 1st international workshop on Computer vision meets databases, P51
   Hauptmann A.G., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P385, DOI DOI 10.1145/1180639.1180721
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Ming-yu Chen, 2005, 13th Annual ACM International Conference on Multimedia, P902, DOI 10.1145/1101149.1101342
   Natsev A., 2005, 13th Annual ACM International Conference on Multimedia, P598, DOI 10.1145/1101149.1101288
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P280, DOI 10.1109/TMM.2006.886275
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Yan R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P516
   Zavesky E., Proceedings of the 2008 International Conference on Content-based Image and Video Retrieval, ser. CIVR '08. New York, NY, USA: ACM, P617, DOI [10.1145/1386352.1386442, DOI 10.1145/1386352.1386442]
NR 25
TC 15
Z9 15
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2013
VL 15
IS 4
BP 898
EP 907
DI 10.1109/TMM.2013.2237894
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 148FK
UT WOS:000319228500017
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Alexiadis, DS
   Zarpalas, D
   Daras, P
AF Alexiadis, Dimitrios S.
   Zarpalas, Dimitrios
   Daras, Petros
TI Real-Time, Full 3-D Reconstruction of Moving Foreground Objects From
   Multiple Consumer Depth Cameras
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE 3-D reconstruction; CUDA; Kinect sensor; mesh zippering; real-time;
   tele-immersive applications
ID MULTIVIEW STEREO RECONSTRUCTION; SHAPE; SILHOUETTE; FUSION; ROBUST
AB The problem of robust, realistic and especially fast 3-D reconstruction of objects, although extensively studied, is still a challenging research task. Most of the state-of-the-art approaches that target real-time applications, such as immersive reality, address mainly the problem of synthesizing intermediate views for given view-points, rather than generating a single complete 3-D surface. In this paper, we present a multiple-Kinect capturing system and a novel methodology for the creation of accurate, realistic, full 3-D reconstructions of moving foreground objects, e.g., humans, to be exploited in real-time applications. The proposed method generates multiple textured meshes from multiple RGB-Depth streams, applies a coarse-to-fine registration algorithm and finally merges the separate meshes into a single 3-D surface. Although the Kinect sensor has attracted the attention of many researchers and home enthusiasts and has already appeared in many applications over the Internet, none of the already presented works can produce full 3-D models of moving objects from multiple Kinect streams in real-time. We present the capturing setup, the methodology for its calibration and the details of the proposed algorithm for real-time fusion of multiple meshes. The presented experimental results verify the effectiveness of the approach with respect to the 3-D reconstruction quality, as well as the achieved frame rates.
C1 [Alexiadis, Dimitrios S.; Zarpalas, Dimitrios; Daras, Petros] Ctr Res & Technol Hellas, Inst Informat Technol, GR-57001 Thessaloniki, Greece.
C3 Centre for Research & Technology Hellas
RP Alexiadis, DS (corresponding author), Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km Charilaou Thermi, GR-57001 Thessaloniki, Greece.
EM dalexiad@iti.gr; zarpalas@iti.gr; daras@iti.gr
RI Daras, Petros/F-5284-2012
OI Daras, Petros/0000-0003-3814-6710
FU EU [287723]
FX Manuscript received October 25, 2011; revised April 25, 2012; accepted
   July 05, 2012. Date of publication November 21, 2012; date of current
   version January 15, 2013. This work was supported by the EU funded IP
   project REVERIE under contract 287723. The associate editor coordinating
   the review of this manuscript and approving it for publication was
   Samson Cheung.
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1997, Modern multidimensional scaling: Theory and applications
   [Anonymous], 1998, P ICCV
   [Anonymous], 2001, P 3 INT C 3D DIG IM
   Crosilla F, 2002, ISPRS J PHOTOGRAMM, V56, P195, DOI 10.1016/S0924-2716(02)00043-6
   Culbertson W., 1999, Workshop on Vision Algorithms, P100
   De Berg M., 2008, Computational Geometry: Algorithms and Applications, V17
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   Franco JS, 2009, IEEE T PATTERN ANAL, V31, P414, DOI 10.1109/TPAMI.2008.104
   Franco JS, 2005, IEEE I CONF COMP VIS, P1747
   Furukawa Y, 2009, INT J COMPUT VISION, V81, P53, DOI 10.1007/s11263-008-0134-8
   Hasenfratz J.-M., 2004, Proceedings of the Tenth Eurographics Conference on Virtual Environments, EGVE'04, (Aire-la-Ville, Switzerland, Switzerland), P147
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Hornung A, 2006, LECT NOTES COMPUT SC, V3952, P179
   Izadi S., 2011, P ACM SIGGRAPH 2011
   Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7
   KANADE T, 1999, MIXED REALITY MERGIN
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1
   Kurillo G, 2008, P 2 ACM IEEE INT C D
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Lourakis M. I.A., 2004, TR3402004 FORTHICS
   Matsuyama T, 2004, IEEE T CIRC SYST VID, V14, P357, DOI 10.1109/TCSVT.2004.823396
   Paris S, 2006, INT J COMPUT VISION, V66, P141, DOI 10.1007/s11263-005-3953-x
   Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5
   Slabaugh GG, 2004, INT J COMPUT VISION, V57, P179, DOI 10.1023/B:VISI.0000013093.45070.3b
   SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Vasudevan R, 2011, IEEE T MULTIMEDIA, V13, P573, DOI 10.1109/TMM.2011.2123871
   Vogiatzis G., 2005, P IEEE C COMP VIS PA
   Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712
   Zeng G, 2007, IEEE T PATTERN ANAL, V29, P141, DOI 10.1109/TPAMI.2007.250605
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zollhöfer M, 2011, COMPUT ANIMAT VIRT W, V22, P195, DOI 10.1002/cav.405
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 52
TC 132
Z9 150
U1 0
U2 81
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2013
VL 15
IS 2
BP 339
EP 358
DI 10.1109/TMM.2012.2229264
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 075HN
UT WOS:000313875500010
DA 2024-07-18
ER

PT J
AU Tkalcic, M
   Odic, A
   Kosir, A
   Tasic, J
AF Tkalcic, Marko
   Odic, Ante
   Kosir, Andrej
   Tasic, Jurij
TI Affective Labeling in a Content-Based Recommender System for Images
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Affective labeling; affective user modeling; content-based recommender
   system; emotion detection; facial expressions
ID OPTIMIZATION
AB Affective labeling of multimedia content has proved to be useful in recommender systems. In this paper we present a methodology for the implicit acquisition of affective labels for images. It is based on an emotion detection technique that takes as input the video sequences of the users' facial expressions. It extracts Gabor low level features from the video frames and employs a k nearest neighbors machine learning technique to generate affective labels in the valence-arousal-dominance space. We performed a comparative study of the performance of a content-based recommender (CBR) system for images that uses three types of metadata to model the users and the items: (i) generic metadata, (ii) explicitly acquired affective labels and (iii) implicitly acquired affective labels with the proposed methodology. The results show that the CBR performs best when explicit labels are used. However, implicitly acquired labels yield a significantly better performance of the CBR than generic metadata while being an unobtrusive feedback tool.
C1 [Tkalcic, Marko] Univ Ljubljana, Fac Elect Engn UL FE, Ljubljana, Slovenia.
   [Odic, Ante; Kosir, Andrej] Univ Ljubljana, Fac Elect Engn, Ljubljana, Slovenia.
C3 University of Ljubljana; University of Ljubljana
RP Tkalcic, M (corresponding author), Univ Ljubljana, Fac Elect Engn UL FE, Ljubljana, Slovenia.
EM marko.tkalcic@fe.uni-lj.si
RI Tkalcic, Marko/L-9767-2016; Tkalcic, Marko/E-7419-2010
OI Tkalcic, Marko/0000-0002-0831-5512; 
FU European Commission [FP6-27312]; Slovenian Research Agency (ARRS)
   [P2-0246]
FX Manuscript received December 12, 2011; revised April 09, 2012 and July
   05, 2012; accepted July 10, 2012. Date of publication November 27, 2012;
   date of current version January 15, 2013. This work was supported in
   part by the European Commission under the grant FP6-27312 and in part by
   the Slovenian Research Agency (ARRS) under the grant P2-0246. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Francesco G. B. De Natale.
CR Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], P 3 INT C AFF COMP I
   [Anonymous], MULTIMEDIA TOOLS APP
   Arapakis I, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P371
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Austermann A, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P317
   Cowie R, 2000, SPEECH EMOTION
   Ekman P., 1999, HDB COGNITION EMOTIO, V98, P16
   González G, 2007, I C DATA ENGIN WORKS, P845, DOI 10.1109/ICDEW.2007.4401075
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jiang JM, 2011, IEEE T BROADCAST, V57, P646, DOI 10.1109/TBC.2011.2158252
   Jiao J., 2010, P 2 INT WORKSH SOC S, P59
   Joho H., 2009, Proceedings of the ACM international conference on image and video retrieval, page, P31
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kierkels J. J. M, 2009, P 3 INT C AFF COMP I
   Kierkels JJM, 2009, IEEE INT CON MULTI, P1436, DOI 10.1109/ICME.2009.5202772
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Kunaver M, 2007, AEU-INT J ELECTRON C, V61, P433, DOI 10.1016/j.aeue.2007.04.003
   Lang Peter J., 2005, International affective picture system (IAPS): Affective ratings of pictures and instruction manual. (Technical Report A-6.)
   LEHMANN E. L., 2006, Springer Texts in Statistics
   Nicolaou Mihalis A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P16, DOI 10.1109/FG.2011.5771396
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Odic A, 2010, P ERK 2010
   Pantic M, 2009, IEEE SIGNAL PROC MAG, V26, P173, DOI 10.1109/MSP.2009.934186
   Petridis S, 2009, IEEE INT CON MULTI, P1444, DOI 10.1109/ICME.2009.5202774
   Pogacnik M, 2005, USER MODEL USER-ADAP, V15, P425, DOI 10.1007/s11257-005-4065-6
   Rudovic O, 2011, IEEE I CONF COMP VIS, P1495, DOI 10.1109/ICCV.2011.6126407
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Soleymani M, 2009, INT J SEMANT COMPUT, V3, P235, DOI 10.1142/S1793351X09000744
   Tkalcic M, 2010, USER MODEL USER-ADAP, V20, P279, DOI 10.1007/s11257-010-9079-z
   Tkalcic Marko., 2011, Proc. The RecSys 2011 Workshop on Human Decision Making in Recommender Systems, P9
   Tkaloia M, 2009, P MULT CORP ADV CAPT, P111
   Torre F. D, 2011, VISUAL ANAL HUMANS, P1
   Tzimiropoulos G, 2011, IEEE I CONF COMP VIS, P1847, DOI 10.1109/ICCV.2011.6126452
   Valenti R, 2009, PROC CVPR IEEE, P612, DOI 10.1109/CVPRW.2009.5206640
   Vrochidis S, 2011, ADV MULTIMED, V2011, DOI 10.1155/2011/310762
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
   Zhi RC, 2008, NEUROCOMPUTING, V71, P1730, DOI 10.1016/j.neucom.2007.12.002
NR 45
TC 55
Z9 58
U1 0
U2 40
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2013
VL 15
IS 2
BP 391
EP 400
DI 10.1109/TMM.2012.2229970
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 075HN
UT WOS:000313875500014
DA 2024-07-18
ER

PT J
AU Duan, XH
   Lin, L
   Chao, HY
AF Duan, Xiaohua
   Lin, Liang
   Chao, Hongyang
TI Discovering Video Shot Categories by Unsupervised Stochastic Graph
   Partition
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Category discovery; graph partition; unsupervised categorization; video
   shot
ID CLASSIFICATION; MODEL
AB Video shots are often treated as the basic elements for retrieving information from videos. In recent years, video shot categorization has received increasing attention, but most of the methods involve a procedure of supervised learning, i.e., training a multi-class predictor (classifier) on the labeled data. In this paper, we study a general framework to unsupervisedly discover video shot categories. The contributions are three-fold in feature, representation, and inference: (1) A new feature is proposed to capture local information in videos, defined with small video patches (e. g., 11 x 11 x 5 pixels). A dictionary of video words can be thus clustered off-line, characterizing both appearance and motion dynamics. (2) We pose the problem of categorization as an automated graph partition task, in that each graph vertex represents a video shot, and a partitioned sub-graph consisting of connected graph vertices represents a clustered category. The model of each video shot category can be analytically calculated by a projection pursuit type of learning process. (3) An MCMC-based cluster sampling algorithm, namely Swendsen-Wang cuts, is adopted to efficiently solve the graph partition. Unlike traditional graph partition techniques, this algorithm is able to explore the nearly global optimal solution and eliminate the need for good initialization. We apply our method on a wide variety of 1600 video shots collected from Internet as well as a subset of TRECVID 2010 data, and two benchmark metrics, i.e., Purity and Conditional Entropy, are adopted for evaluating performance. The experimental results demonstrate superior performance of our method over other popular state-of-the-art methods.
C1 [Duan, Xiaohua; Lin, Liang; Chao, Hongyang] Sun Yat Sen Univ, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Duan, XH (corresponding author), Sun Yat Sen Univ, Guangzhou 510006, Guangdong, Peoples R China.
EM linliang@ieee.org
RI LU, LU/JEZ-4760-2023; l, j/HNC-5728-2023; Lin, L/HKO-8213-2023; L,
   J/JEF-9564-2023; l, j/JVZ-8480-2024
FU National Natural Science Foundation of China [61173082, 61173081];
   Hi-Tech Research and Development Program of China (National 863 Program)
   [2012AA011504]; Guangdong Natural Science Foundation [S2011020001215,
   S2011010001378]; Guangdong Science and Technology Program
   [2010A040307003, 2011B040300029]; State Key Laboratory of Virtual
   Reality Technology and Systems, Beihang University [BUAA-VR-12KF-06]
FX The work was supported by the National Natural Science Foundation of
   China (Grant No. 61173082 and No. 61173081), the Hi-Tech Research and
   Development Program of China (National 863 Program, Grant No.
   2012AA011504), the Guangdong Natural Science Foundation (Grant No.
   S2011020001215 and No. S2011010001378), and the Guangdong Science and
   Technology Program (Grant No. 2010A040307003 and No. 2011B040300029).
   This work is also supported by the open funding project of State Key
   Laboratory of Virtual Reality Technology and Systems, Beihang University
   (Grant No. BUAA-VR-12KF-06). The corresponding author is L. Lin. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Xian-Sheng Hua.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2001, IEEE COMP SOC C COMP
   [Anonymous], 2005, THESIS J GUTENBERG U
   Barbu A, 2007, J COMPUT GRAPH STAT, V16, P877, DOI 10.1198/106186007X255144
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Dai D., 2010, P IEEE C COMP VIS PA
   Dalal N., CVPR, P886, DOI [DOI 10.1109/CVPR.2005.177, 10.1109/CVPR.2005.177]
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Fan J, 2007, IEEE T MULTIMEDIA, V9, P939, DOI 10.1109/TMM.2007.900143
   Fan JP, 2004, IEEE T MULTIMEDIA, V6, P70, DOI 10.1109/TMM.2003.819583
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711
   Gupta P, 2009, IEEE I CONF COMP VIS, P1655, DOI 10.1109/ICCV.2009.5459373
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li CH, 2011, IEEE T FUZZY SYST, V19, P152, DOI 10.1109/TFUZZ.2010.2089631
   Lin L, 2012, PATTERN RECOGN, V45, P3648, DOI 10.1016/j.patcog.2012.03.017
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Liu X., 2009, P IEEE C COMP VIS PA
   Liu XB, 2011, IEEE T CIRC SYST VID, V21, P1588, DOI 10.1109/TCSVT.2011.2129410
   Liu YA, 2009, MULTIMED TOOLS APPL, V41, P93, DOI 10.1007/s11042-008-0220-5
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marszalk M., 2009, P IEEE C COMP VIS PA
   Ngo CW, 2002, IEEE T MULTIMEDIA, V4, P446, DOI 10.1109/TMM.2002.802022
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Wang P, 2007, SOFT COMPUT, V11, P355, DOI 10.1007/s00500-006-0089-z
   Xi Z., 2008, P ACM C MULT
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P1141, DOI 10.1109/TIP.2010.2076820
   Zhao Y., 2010, P IEEE AS C COMP VIS
   Zhao Y., 2009, P IEEE INT C PATT RE
   Zhou A. K., 2010, P ACM C MULT
   Zhu G., 2009, P ACM C MULT
   Zhu SC, 2010, PATTERN RECOGN LETT, V31, P667, DOI 10.1016/j.patrec.2009.07.020
NR 46
TC 8
Z9 8
U1 1
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JAN
PY 2013
VL 15
IS 1
BP 167
EP 180
DI 10.1109/TMM.2012.2225029
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 058PS
UT WOS:000312646600014
DA 2024-07-18
ER

PT J
AU Ballan, L
   Bertini, M
   Del Bimbo, A
   Seidenari, L
   Serra, G
AF Ballan, Lamberto
   Bertini, Marco
   Del Bimbo, Alberto
   Seidenari, Lorenzo
   Serra, Giuseppe
TI Effective Codebooks for Human Action Representation and Classification
   in Unconstrained Videos
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Human action categorization; spatio-temporal local descriptors; visual
   codebooks
ID RECOGNITION; CATEGORIES; DENSE
AB Recognition and classification of human actions for annotation of unconstrained video sequences has proven to be challenging because of the variations in the environment, appearance of actors, modalities in which the same action is performed by different persons, speed and duration, and points of view from which the event is observed. This variability reflects in the difficulty of defining effective descriptors and deriving appropriate and effective codebooks for action categorization. In this paper, we propose a novel and effective solution to classify human actions in unconstrained videos. It improves on previous contributions through the definition of a novel local descriptor that uses image gradient and optic flow to respectively model the appearance and motion of human actions at interest point regions. In the formation of the codebook, we employ radius-based clustering with soft assignment in order to create a rich vocabulary that may account for the high variability of human actions. We show that our solution scores very good performance with no need of parameter tuning. We also show that a strong reduction of computation time can be obtained by applying codebook size reduction with Deep Belief Networks with little loss of accuracy.
C1 [Ballan, Lamberto; Bertini, Marco; Del Bimbo, Alberto; Seidenari, Lorenzo; Serra, Giuseppe] Univ Florence, Media Integrat & Commun Ctr, I-50139 Florence, Italy.
C3 University of Florence
RP Ballan, L (corresponding author), Univ Florence, Media Integrat & Commun Ctr, I-50139 Florence, Italy.
EM ballan@dsi.unifi.it; bertini@dsi.unifi.it; delbimbo@dsi.unifi.it;
   seidenari@dsi.unifi.it; serra@dsi.unifi.it
RI Ballan, Lamberto/B-3450-2008; Bertini, Marco/X-1325-2019; Seidenari,
   Lorenzo/H-4240-2013; Seidenari, Lorenzo/AAA-1848-2020; Serra,
   Giuseppe/M-3572-2015
OI Ballan, Lamberto/0000-0003-0819-851X; Bertini,
   Marco/0000-0002-1364-218X; Seidenari, Lorenzo/0000-0003-4816-0268; DEL
   BIMBO, ALBERTO/0000-0002-1052-8322; Serra, Giuseppe/0000-0002-4269-4501
FU EU [FP7-226248]
FX This work was supported in part by the EU "euTV" Project under Contract
   FP7-226248. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Pascal Frossard.
CR [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], 2009, MOSIFT RECOGNIZING H
   [Anonymous], ARTIFICIAL INTELLIGE
   [Anonymous], 2009, P BRIT MACH VIS C
   Ballan Lamberto, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P506, DOI 10.1109/ICCVW.2009.5457658
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gao Z, 2010, LECT NOTES COMPUT SC, V6219, P88
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Hauptmann AG, 2008, P IEEE, V96, P602, DOI 10.1109/JPROC.2008.916355
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kong Y, 2011, PATTERN RECOGN LETT, V32, P1178, DOI 10.1016/j.patrec.2011.03.006
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE I CONF COMP VIS, P1792
   Mikolajczyk K., 2008, P CVPR, P1
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rapantzikos K, 2009, PROC CVPR IEEE, P1454, DOI 10.1109/CVPRW.2009.5206525
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shao L., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, P477
   Shao L, 2011, NEUROCOMPUTING, V74, P962, DOI 10.1016/j.neucom.2010.11.013
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   van der Maaten L., 2009, J Mach Learn Res, V10, P7
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wang Y, 2009, PROC CVPR IEEE, P872, DOI 10.1109/CVPRW.2009.5206709
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong S.-F., 2007, P ICCV, P1
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Yu G, 2011, IEEE T MULTIMEDIA, V13, P507, DOI 10.1109/TMM.2011.2128301
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 55
TC 34
Z9 38
U1 1
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2012
VL 14
IS 4
BP 1234
EP 1245
DI 10.1109/TMM.2012.2191268
PN 2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 976QM
UT WOS:000306599400010
DA 2024-07-18
ER

PT J
AU Xiao, JM
   Tillo, T
   Lin, CY
   Zhao, Y
AF Xiao, Jimin
   Tillo, Tammam
   Lin, Chunyu
   Zhao, Yao
TI Dynamic Sub-GOP Forward Error Correction Code for Real-Time Video
   Applications
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Dynamic Sub-GOP; error resilience; H.264/AVC; real-time transmission;
   systematic Reed-Solomon
ID H.264/AVC
AB Reed-Solomon erasure codes are commonly studied as a method to protect the video streams when transmitted over unreliable networks. As a block-based error correcting code, on one hand, enlarging the block size can enhance the performance of the Reed-Solomon codes; on the other hand, large block size leads to long delay which is not tolerable for real-time video applications. In this paper a novel Dynamic Sub-GOP FEC (DSGF) approach is proposed to improve the performance of Reed-Solomon codes for video applications. With the proposed approach, the Sub-GOP, which contains more than one video frame, is dynamically tuned and used as the RS coding block, yet no delay is introduced. For a fixed number of extra introduced packets, for protection, the length of the Sub-GOP and the redundancy devoted to each Sub-GOP becomes a constrained optimization problem. To solve this problem, a fast greedy algorithm is proposed. Experimental results show that the proposed approach outperforms other real-time error resilient video coding technologies.
C1 [Xiao, Jimin] Univ Liverpool, Dept Elect Engn & Elect, Liverpool L69 3GJ, Merseyside, England.
   [Xiao, Jimin; Tillo, Tammam] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, Suzhou, Peoples R China.
   [Lin, Chunyu; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network Techno, Beijing, Peoples R China.
C3 University of Liverpool; Xi'an Jiaotong-Liverpool University; Beijing
   Jiaotong University
RP Xiao, JM (corresponding author), Univ Liverpool, Dept Elect Engn & Elect, Liverpool L69 3GJ, Merseyside, England.
EM jimin.xiao@liverpool.ac.uk; tammam.tillo@xjtlu.edu.cn;
   yuailian@gmail.com; yzhao@bjtu.edu.cn
RI Lin, Chunyu/AAI-5185-2021
OI Lin, Chunyu/0000-0003-2847-0349
FU National Natural Science Foundation of China [60972085]; Sino-Singapore
   JRP [2010DFA11010]; National Science Foundation of China for
   Distinguished Young Scholars [61025013]; National Basic Research Program
   of China [2012CB316400]
FX This work was supported by the National Natural Science Foundation of
   China (No. 60972085), the Sino-Singapore JRP (No. 2010DFA11010), the
   National Science Foundation of China for Distinguished Young Scholars
   (No. 61025013), and the National Basic Research Program of China (Grant
   No. 2012CB316400). The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Zhihai (Henry) He.
CR Baccaglini E, 2008, IEEE SIGNAL PROC LET, V15, P581, DOI 10.1109/LSP.2008.2001565
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   Farber N., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P550, DOI 10.1109/ICIP.1999.822956
   Frossard P, 2001, IEEE COMMUN LETT, V5, P122, DOI 10.1109/4234.913160
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   Heng BA, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/32592
   HHI Fraunhofer Institute, H 264 AVC REF SOFTW
   Lin S., 2001, Proceedings of IEEE International Conference on Multimedia and Expo, P96
   Loguinov D, 2002, IEEE INFOCOM SER, P723, DOI 10.1109/INFCOM.2002.1019318
   Radulovic I, 2010, IEEE T CIRC SYST VID, V20, P144, DOI 10.1109/TCSVT.2009.2026815
   SCHULZRINNE H, 2003, 3550 RFC INT ENG TAS
   Soltani S, 2009, IEEE T MULTIMEDIA, V11, P742, DOI 10.1109/TMM.2009.2017622
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Thomos N, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P593, DOI 10.1109/ICME.2006.262478
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Y.-K., 2005, P206 JVT
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiao Jiaxi., 2011, Information Sciences and Systems (CISS), 2011 45th Annual Conference on, P1
   Yang XK, 2005, IEEE T MULTIMEDIA, V7, P753, DOI 10.1109/TMM.2005.846782
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang Y, 2007, IEEE T MULTIMEDIA, V9, P445, DOI 10.1109/TMM.2006.887989
   Zhu CB, 2009, IEEE T CIRC SYST VID, V19, P3, DOI 10.1109/TCSVT.2008.2005802
NR 24
TC 33
Z9 39
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2012
VL 14
IS 4
BP 1298
EP 1308
DI 10.1109/TMM.2012.2194274
PN 2
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 976QM
UT WOS:000306599400015
DA 2024-07-18
ER

PT J
AU Kuo, HC
   Lin, YL
AF Kuo, Huang-Chih
   Lin, Youn-Long
TI A Hybrid Algorithm for Effective Lossless Compression of Video Display
   Frames
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Multimedia and Expo (ICME)
CY JUL 11-15, 2011
CL Univ Ramon Llull, La Salle, Barcelona, SPAIN
SP IEEE, IEEE Signal Proc Soc, IEEE Circuits & Syst Soc, IEEE Comp Soc, IEEE Commun Soc
HO Univ Ramon Llull, La Salle
DE Compression; dictionary coding; display frame; Huffman coding
ID MOTION COMPENSATION; DATA REUSE; SCHEME; RECOMPRESSION; CONTROLLER;
   REDUCTION; POWER
AB We propose a simple and effective lossless compression algorithm for video display frames. It combines the dictionary coding, the Huffman coding, and three proposed innovative schemes to achieve a high compression ratio. We quantitatively analyze the characteristics of display frame data for designing the algorithm. We first propose a two-stage classification scheme to classify all pixels into three categories. Then we employ the dictionary coding and propose an adaptive prefix bit truncation scheme to generate codewords for video pixels in each category. We subsequently employ the Huffman coding scheme to assign bit values to the codewords. Finally, we propose a head code compression scheme to further reduce the size of the codeword bits. Experimental results show that the proposed algorithm achieves 22% more reduction than prior arts.
C1 [Kuo, Huang-Chih; Lin, Youn-Long] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Kuo, HC (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
EM d9562813@oz.nthu.edu.tw; ylin@cs.nthu.edu.tw
CR [Anonymous], 2011, REF SOFTW 11 0
   [Anonymous], P INT C DIG TEL
   [Anonymous], 2006, ESSENTIAL ISSUES SOC
   Bao XN, 2010, IEEE INT SYMP CIRC S, P677, DOI 10.1109/ISCAS.2010.5537495
   Chao P, 2008, IEEE INT SYMP CIRC S, P256, DOI 10.1109/ISCAS.2008.4541403
   Chen CY, 2006, IEEE T CIRC SYST VID, V16, P553, DOI 10.1109/TCSVT.2006.871388
   Chen WY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P825, DOI 10.1109/ICME.2008.4607562
   Dikbas S, 2010, SIGNAL PROCESS-IMAGE, V25, P345, DOI 10.1016/j.image.2010.02.004
   Gupte AD, 2011, IEEE T CIRC SYST VID, V21, P225, DOI 10.1109/TCSVT.2011.2105599
   Heithecker S, 2005, DES AUT CON, P575
   Hongqi H, 2007, IEEE WRK SIG PRO SYS, P373, DOI 10.1109/SIPS.2007.4387575
   Hu Hongqi, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P2132, DOI 10.1109/ICIEA.2009.5138526
   Kim H, 2001, IEEE T CIRC SYST VID, V11, P1160, DOI 10.1109/76.964782
   Kim J, 2010, IEEE T CIRC SYST VID, V20, P848, DOI 10.1109/TCSVT.2010.2045923
   Kim J, 2009, IEEE INT CON MULTI, P193, DOI 10.1109/ICME.2009.5202469
   Kuo HC, 2009, 2009 IEEE/ACM/IFIP 7TH WORKSHOP ON EMBEDDED SYSTEMS FOR REAL-TIME MULTIMEDIA, P1, DOI 10.1109/ESTMED.2009.5336823
   Lee KB, 2005, IEEE T CIRC SYST VID, V15, P620, DOI 10.1109/TCSVT.2005.846412
   Lee SH, 2009, IEEE T CONSUM ELECTR, V55, P2105, DOI 10.1109/TCE.2009.5373775
   Lee YJ, 2007, IEEE INT SYMP CIRC S, P1621, DOI 10.1109/ISCAS.2007.378829
   Lei JM, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P894
   Merhav N, 2000, IEEE T INFORM THEORY, V46, P121, DOI 10.1109/18.817513
   Merhav N, 2000, IEEE T INFORM THEORY, V46, P229, DOI 10.1109/18.817520
   Shao J, 2007, INT S HIGH PERF COMP, P285
   Son CH, 2010, IEEE T CONSUM ELECTR, V56, P2421, DOI 10.1109/TCE.2010.5681123
   Song L, 2010, IEEE INT SYMP CIRC S, P401, DOI 10.1109/ISCAS.2010.5537728
   Song T, 2007, IEICE ELECTRON EXPR, V4, P121, DOI 10.1587/elex.4.121
   Tsai C. Y., 2005, P 48 MIDW S CIRC SYS, P1119
   Tuan JC, 2002, IEEE T CIRC SYST VID, V12, P61, DOI 10.1109/76.981846
   Wang TH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P699
   Yang HT, 2009, 2009 IEEE/ACM/IFIP 7TH WORKSHOP ON EMBEDDED SYSTEMS FOR REAL-TIME MULTIMEDIA, P28, DOI 10.1109/ESTMED.2009.5336820
   Yng TLB, 2008, IEEE T CONSUM ELECTR, V54, P1453, DOI 10.1109/TCE.2008.4637640
   Yu GS, 2007, IEEE WRK SIG PRO SYS, P505, DOI 10.1109/SIPS.2007.4387599
   Zhu JH, 2004, 2004: 7TH INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUITS TECHNOLOGY, VOLS 1- 3, PROCEEDINGS, P1621
   Zhu JY, 2008, IEEE INT SYMP CIRC S, P3518, DOI 10.1109/ISCAS.2008.4542218
NR 34
TC 22
Z9 22
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2012
VL 14
IS 3
BP 500
EP 509
DI 10.1109/TMM.2012.2191945
PN 1
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 943ZG
UT WOS:000304166300002
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Yan, CG
   Dai, F
   Ma, YK
AF Zhang, Yongdong
   Yan, Chenggang
   Dai, Feng
   Ma, Yike
TI Efficient Parallel Framework for H.264/AVC Deblocking Filter on
   Many-Core Platform
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Multimedia and Expo (ICME)
CY JUL 11-15, 2011
CL Univ Ramon Llull, La Salle, Barcelona, SPAIN
SP IEEE, IEEE Signal Proc Soc, IEEE Circuits & Syst Soc, IEEE Comp Soc, IEEE Commun Soc
HO Univ Ramon Llull, La Salle
DE Deblocking filter; H.264/AVC; load imbalance; many-core platform;
   parallel framework; parallelism; synchronization
ID ENCODER
AB The H. 264/AVC deblocking filter is becoming the performance bottleneck of H. 264/AVC parallelization on many-core platform. Efficient parallelization of the deblocking filter on a many-core platform is challenging, because the deblocking filter has complicated data dependencies, which provide insufficient parallelism for so many cores. Furthermore, parallelization may have significant synchronization and load imbalance overhead. At present, research on the parallelizing deblocking filter on a many-core platform is rare and focuses on data-level parallelization. In this paper, we propose a three-step framework considering task-level segmentation and data-level parallelization to efficiently parallelize the deblocking filter. First, we review the entire deblocking filter process in 4 4 block edge-level and divide it into two parts: 1) boundary strength computation (BSC) and 2) edge discrimination and filtering (EDF), which increases the parallelism. Then, we apply the Markov empirical transition probability matrix and Huffman tree (METPMHT) to the BSC, which alleviate the load imbalance problem. Finally, we use an independent pixel connected area parallelization (IPCAP) for the EDF, which increases the parallelism and reduces the synchronization. In experiments, we apply our parallel method to the deblocking filter of the H. 264/AVC reference software JM15.1 on the Tile64 platform without any Tile64 platform-based optimizations. Compared to the well-known 2D-wavefront method, the proposed method achieves on average 14.85, 17.83, and 10.60 times speed-up for QCIF, CIF, and HD videos using 62 cores, respectively.
C1 [Zhang, Yongdong; Yan, Chenggang; Dai, Feng; Ma, Yike] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Adv Comp Res Lab, Beijing 100190, Peoples R China.
   [Yan, Chenggang] Chinese Acad Sci, Dept Grad Univ, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences
RP Zhang, YD (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Adv Comp Res Lab, Beijing 100190, Peoples R China.
EM yanchenggang@ict.ac.cn
CR Allignol A, 2011, J STAT SOFTW, V38, P1
   Alvarez-Mesa M., 2012, P 37 INT C AC SPEECH
   [Anonymous], P INT C SUP
   [Anonymous], 2008, Solid-State Circuits Conference, DOI DOI 10.1109/ISSCC.2008.4523070
   [Anonymous], 2003, JVTG050DOC ISOIEC MP
   Azevedo A, 2009, LECT NOTES COMPUT SC, V5409, P404
   Bini E, 2011, IEEE MICRO, V31, P72, DOI 10.1109/MM.2011.1
   Chen SG, 2010, IEEE T CIRC SYST VID, V20, P920, DOI 10.1109/TCSVT.2010.2045831
   Cheung N.-M., 2009, IEEE T CIRCUITS SYST, V19, P1792
   Cheung NM, 2009, IEEE IMAGE PROC, P2309, DOI 10.1109/ICIP.2009.5414475
   Cheung NM, 2010, IEEE SIGNAL PROC MAG, V27, P79, DOI 10.1109/MSP.2009.935416
   Chi Ching Chi, 2010, 24th ACM International Conference on Supercomputing 2010, P105
   Chiou B.-R., 2010, P ACM C MULT, P1207
   Cho Y., 2010, Proceedings of the tenth ACM international conference on Embedded software, EMSOFT '10, P49
   Ebrahimi E., 2011, P INT S HIGH PERF CO, P38
   Gang He, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P450, DOI 10.1109/PCS.2010.5702533
   Guan H, 2009, PROCEEDINGS OF 2009 2ND IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY, P500, DOI 10.1109/ICBNMT.2009.5348537
   Gurhanli Ahmet, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P627, DOI 10.1109/ICSPS.2010.5555416
   Huang Y.-L., 2009, P 17 INT C MULTIMEDI, P361
   Jo SH, 2010, IEEE T CONSUM ELECTR, V56, P1963, DOI 10.1109/TCE.2010.5606353
   Ju Ren, 2010, Proceedings of the 2010 Fifth International Conference on Frontier of Computer Science and Technology (FCST 2010), P154, DOI 10.1109/FCST.2010.104
   Kim M, 2010, IEEE IMAGE PROC, P3749, DOI 10.1109/ICIP.2010.5653439
   Kim WJ, 2011, IEEE T CONSUM ELECTR, V57, P897, DOI 10.1109/TCE.2011.5955238
   Kim WJ, 2010, IEEE T CONSUM ELECTR, V56, P1088, DOI 10.1109/TCE.2010.5506043
   Lee JY, 2010, IET CIRC DEVICE SYST, V4, P147, DOI 10.1049/iet-cds.2009.0038
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Lou J, 2009, IEEE T CIRC SYST VID, V19, P1178, DOI 10.1109/TCSVT.2009.2020262
   Madani N, 2011, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND EVALUATION, P291
   Marth E., 2010, P ACM SIGGRAPH, P72
   Mesa Mauricio Alvarez, 2009, Proceedings of the 2009 IEEE 15th International Conference on Parallel and Distributed Systems (ICPADS 2009), P236, DOI 10.1109/ICPADS.2009.124
   Pai Y.-S., 2010, Proceedings of the international conference on Multimedia, P1211
   Rodriguez R., 2010, P INT C CONSUMER ELE, P463
   Schwalb M, 2009, IEEE T MULTIMEDIA, V11, P1, DOI 10.1109/TMM.2008.2008873
   Shen YC, 2011, IEEE DATA COMPR CONF, P476, DOI 10.1109/DCC.2011.80
   Shin SH, 2010, SIGNAL PROCESS-IMAGE, V25, P255, DOI 10.1016/j.image.2010.01.005
   Sihn KH, 2009, INT CONF ACOUST SPEE, P2017, DOI 10.1109/ICASSP.2009.4960009
   Spiteri Trevor, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P695, DOI 10.1109/ACSSC.2009.5469937
   Sze V, 2009, IEEE IMAGE PROC, P773, DOI 10.1109/ICIP.2009.5414245
   Taibo J, 2011, P ACM 21 INT WORKSH, P75
   Wang SW, 2009, J SIGNAL PROCESS SYS, V57, P195, DOI 10.1007/s11265-008-0321-4
   Wang WY, 2010, IEEE INT CON MULTI, P890, DOI 10.1109/ICME.2010.5582930
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiao ZB, 2011, IEEE T CIRC SYST VID, V21, P890, DOI 10.1109/TCSVT.2011.2133290
   Xie H., 2010, P EUR C COMP VIS WOR
   Xie HT, 2010, INT CONF ACOUST SPEE, P2494, DOI 10.1109/ICASSP.2010.5494898
   Yan C., 2011, P INT C MULT MOD, P51
   Yan CG, 2011, IEEE INT CON MULTI, DOI 10.1109/ICME.2011.6011904
   Yang SS, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1858
   Zhang JQ, 2010, EUR J OPER RES, V200, P557, DOI 10.1016/j.ejor.2009.01.020
   Zrida HK, 2009, DES AUT TEST EUROPE, P940
NR 50
TC 39
Z9 44
U1 0
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2012
VL 14
IS 3
BP 510
EP 524
DI 10.1109/TMM.2012.2190391
PN 1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA 943ZG
UT WOS:000304166300003
DA 2024-07-18
ER

PT J
AU Deng, CW
   Lin, WS
   Lee, BS
   Lau, CT
AF Deng, Chenwei
   Lin, Weisi
   Lee, Bu-Sung
   Lau, Chiew Tong
TI Robust Image Coding Based Upon Compressive Sensing
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Compressive sensing (CS); error resilience; image transmission; multiple
   description coding (MDC); packet loss; robust image compression
ID TRANSMISSION; CHANNELS; JPEG2000; SCHEME
AB Multiple description coding (MDC) is one of the widely used mechanisms to combat packet-loss in non-feedback systems. However, the number of descriptions in the existing MDC schemes is very small (typically 2). With the number of descriptions increasing, the coding complexity increases drastically and many decoders would be required. In this paper, the compressive sensing (CS) principles are studied and an alternative coding paradigm with a number of descriptions is proposed based upon CS for high packet loss transmission. Two-dimentional discrete wavelet transform (DWT) is applied for sparse representation. Unlike the typical wavelet coders (e.g., JPEG 2000), DWT coefficients here are not directly encoded, but re-sampled towards equal importance of information instead. At the decoder side, by fully exploiting the intra-scale and inter-scale correlation of multiscale DWT, two different CS recovery algorithms are developed for the low-frequency subband and high-frequency subbands, respectively. The recovery quality only depends on the number of received CS measurements (not on which of the measurements that are received). Experimental results show that the proposed CS-based codec is much more robust against lossy channels, while achieving higher rate-distortion (R-D) performance compared with conventional wavelet-based MDC methods and relevant existing CS-based coding schemes.
C1 [Deng, Chenwei; Lin, Weisi; Lee, Bu-Sung; Lau, Chiew Tong] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Deng, CW (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM cwdeng@ntu.edu.sg; wslin@ntu.edu.sg; ebslee@ntu.edu.sg;
   asctlau@ntu.edu.sg
RI Lee, Francis BS/G-9323-2014; Liu, Kai/IST-6808-2023; Lin,
   Weisi/A-3696-2011; Lin, Weisi/A-8011-2012
OI Lee, Francis BS/0000-0001-7828-7900; Lin, Weisi/0000-0001-9866-1947; 
FU MoE AcRF, Singapore [T208B1218]
FX Manuscript received November 03, 2010; revised April 03, 2011 and
   September 07, 2011; accepted December 05, 2011. Date of publication
   December 23, 2011; date of current version March 21, 2012. This work was
   supported by MoE AcRF Tire 2, Singapore, Grant Number: T208B1218. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Zicheng Liu.
CR [Anonymous], ADAPTIVE COMPRESSED
   [Anonymous], 2000, 144921 IEEE ISOIEC
   [Anonymous], 2004, 1449610 IEEE ISOIEC
   [Anonymous], 1992, 109181 IEEE ISOIEC
   Bai HH, 2007, IEEE T CIRC SYST VID, V17, P912, DOI 10.1109/TCSVT.2007.898646
   Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candes EJ, 2008, IEEE INFORM THEORY S, V58, P20
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chanda V., 2010, NEGATIVE RESULT EXPL
   Chang CL, 2010, IEEE T IMAGE PROCESS, V19, P1740, DOI 10.1109/TIP.2010.2044964
   Dai W, 2009, QUANTIZED COMPRESSIV
   Davenport M.A., 2009, A simple proof that random matrices are democratic
   Deng C. W., 2010, P IEEE INT C MULT EX, P462
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2008, INT CONF ACOUST SPEE, P5137, DOI 10.1109/ICASSP.2008.4518815
   Dunn P., 2005, MEASUREMENT DATA ANA
   ELGAMAL AA, 1982, IEEE T INFORM THEORY, V28, P851, DOI 10.1109/TIT.1982.1056588
   Feng WW, 2009, 2009 INTERNATIONAL FORUM ON COMPUTER SCIENCE-TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P113, DOI 10.1109/DCC.2009.24
   Fletcher AK, 2007, INT CONF ACOUST SPEE, P885
   Gao DH, 2010, LECT NOTES ARTIF INT, V6216, P334
   Goyal VK, 2008, IEEE SIGNAL PROC MAG, V25, P48, DOI 10.1109/MSP.2007.915001
   Han B, 2010, J VIS COMMUN IMAGE R, V21, P325, DOI 10.1016/j.jvcir.2010.02.007
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Ishwaran H, 2005, ANN STAT, V33, P730, DOI 10.1214/009053604000001147
   Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345
   La Chinh, 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V5914, P1, DOI 10.1117/12.621064
   Liangjun Wang, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P445, DOI 10.1109/MMSP.2008.4665120
   Lu T. L., 2008, P IEEE INT C SIGN PR, P1223
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   OZAROW L, 1980, BELL SYST TECH J, V59, P1909, DOI 10.1002/j.1538-7305.1980.tb03344.x
   Robert Christian P., 2004, Springer Texts in Statistics, Vsecond
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Servetto SD, 2000, IEEE T IMAGE PROCESS, V9, P813, DOI 10.1109/83.841528
   Taubman DS, 2002, P IEEE, V90, P1336, DOI 10.1109/JPROC.2002.800725
   Tillo T, 2004, IEEE SIGNAL PROC LET, V11, P908, DOI 10.1109/LSP.2004.836949
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Venkatraman D, 2009, INT CONF ACOUST SPEE, P3513, DOI 10.1109/ICASSP.2009.4960383
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Wu F. F., 2009, P IEEE WORKSH MULT S, P1, DOI DOI 10.1109/ICBBE.2009.5163379
   Xiaolin Wu, 2009, 2009 Data Compression Conference. DCC 2009, P123, DOI 10.1109/DCC.2009.69
   Yang SH, 2007, IEEE T CIRC SYST VID, V17, P558, DOI 10.1109/TCSVT.2007.895343
   Zadeh H. Y., 1999, IEEE J SEL TOP QUANT, V2, P569
   ZEEVI YY, 1997, SIGNAL IMAGE REPRESE
   Zeng B, 2008, IEEE T CIRC SYST VID, V18, P305, DOI 10.1109/TCSVT.2008.918455
   Zhao J, 2003, P 1 INT C EMB NETW S, P1, DOI [DOI 10.1145/958491.958493, 10.1145/958491.958493]
NR 49
TC 64
Z9 72
U1 0
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2012
VL 14
IS 2
BP 278
EP 290
DI 10.1109/TMM.2011.2181491
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 924OZ
UT WOS:000302702500004
DA 2024-07-18
ER

PT J
AU Kesorn, K
   Poslad, S
AF Kesorn, Kraisak
   Poslad, Stefan
TI An Enhanced Bag-of-Visual Word Vector Space Model to Represent Visual
   Content in Athletics Images
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Bag-of-visual words; non-informative visual words discovery; ontology
   model; visual content representation; visual words disambiguation
AB Images that have a different visual appearance may be semantically related using a higher level conceptualization. However, image classification and retrieval systems tend to rely only on the low-level visual structure within images. This paper presents a framework to deal with this semantic gap limitation by exploiting the well-known bag-of-visual words (BVW) to represent visual content. The novelty of this paper is threefold. First, the quality of visual words is improved by constructing visual words from representative keypoints. Second, domain specific "non-informative visual words" are detected which are useless to represent the content of visual data but which can degrade the categorization capability. Distinct from existing frameworks, two main characteristics for non-informative visual words are defined: a high document frequency (DF) and a small statistical association with all the concepts in the collection. The third contribution in this paper is that a novel method is used to restructure the vector space model of visual words with respect to a structural ontology model in order to resolve visual synonym and polysemy problems. The experimental results show that our method can disambiguate visual word senses effectively and can significantly improve classification, interpretation, and retrieval performance for the athletics images.
C1 [Kesorn, Kraisak] Naresuan Univ, Fac Sci, Comp Sci & Informat Technol Dept, Phitsanulok 65000, Thailand.
   [Poslad, Stefan] Queen Mary Univ London, Sch Elect & Elect Engn & Comp Sci, London E1 4NS, England.
C3 Naresuan University; University of London; Queen Mary University London
RP Kesorn, K (corresponding author), Naresuan Univ, Fac Sci, Comp Sci & Informat Technol Dept, Phitsanulok 65000, Thailand.
EM kraisakk@nu.ac.th; stefan@eecs.qmul.ac.uk
RI Kesorn, Kraisak/AAE-8562-2020; Kesorn, Kraisak/AAU-2475-2020; Poslad,
   Stefan/N-5446-2014
OI Kesorn, Kraisak/0000-0002-5195-8038; Poslad, Stefan/0000-0002-3156-9609
FU Naresuan University; CSTS, Coordinating Center for Thai Government
   Science and Technology Scholarship Students, National Science and
   Technology Development Agency, Thailand
FX This work was supported by Naresuan University and A New Researcher
   Scholarship of CSTS, Coordinating Center for Thai Government Science and
   Technology Scholarship Students, National Science and Technology
   Development Agency, Thailand. The associate editor coordinating the
   review of this manuscript and approving it for publication was Prof.
   Ming-Ting Sun.
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   [Anonymous], 2000, Icml, DOI DOI 10.1007/3-540-44491-2_3
   [Anonymous], P ACM WORKSH LSMRM
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   [Anonymous], 2008, P VIS COMP SCI BCS I
   Chen X, 2009, LECT NOTES ARTIF INT, V5476, P867, DOI 10.1007/978-3-642-01307-2_90
   Cullen P. B., 1992, Proceedings of the Eighth Conference on Artificial Intelligence for Applications (Cat. No.92CH3122-9), P127, DOI 10.1109/CAIA.1992.200020
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jamshy S, 2009, LECT NOTES COMPUT SC, V5716, P113, DOI 10.1007/978-3-642-04146-4_14
   Jiang YG, 2009, COMPUT VIS IMAGE UND, V113, P405, DOI 10.1016/j.cviu.2008.10.002
   Ke Yan, 2004, CVPR, V2
   Kesorn Kraisak, 2009, Journal of Multimedia, V4, P284, DOI 10.4304/jmm.4.5.284-297
   Lee Y, 2005, LECT NOTES COMPUT SC, V3546, P219
   Lili Hao, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P718, DOI 10.1109/CSSE.2008.829
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   McLachlan G.J., 1988, Statistics: Textbooks and Monographs
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moller R., 2008, SEMANTIC MULTIMEDIA, P55
   Nagypal G., 2007, POSSIBLY IMPERFECT O
   Nister David, 2006, CVPR
   Obdr?zalek S., 2005, PROC 16 BRIT MACHINE, V1, P1
   Popova E., 2008, ENCY STAT QUALITY RE
   Poslad S., 2009, Ubiquitous Computing
   Quack T, 2006, LECT NOTES COMPUT SC, V4071, P360
   Rudinac M., 2009, P IAPR C MACH VIS AP, P191
   Russakovsky O., 2010, LNCS, P1, DOI DOI 10.1007/978-3-642-35749-7_1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Walter B, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P81, DOI 10.1109/RT.2008.4634626
   Wang LH, 2009, LECT NOTES COMPUT SC, V5702, P766, DOI 10.1007/978-3-642-03767-2_93
   Yang YM, 1996, J AM SOC INFORM SCI, V47, P357, DOI 10.1002/(SICI)1097-4571(199605)47:5<357::AID-ASI3>3.0.CO;2-V
   Yuan J, 2007, PROC CVPR IEEE, P1930, DOI 10.1109/CVPR.2007.383222
   Yuan JS, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P864, DOI 10.1145/1281192.1281284
   Zheng YT, 2009, VISUAL COMPUT, V25, P13, DOI 10.1007/s00371-008-0294-0
NR 39
TC 48
Z9 60
U1 0
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2012
VL 14
IS 1
BP 211
EP 222
DI 10.1109/TMM.2011.2170665
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 924OL
UT WOS:000302701100020
DA 2024-07-18
ER

PT J
AU You, JY
   Korhonen, J
   Perkis, A
   Ebrahimi, T
AF You, Junyong
   Korhonen, Jari
   Perkis, Andrew
   Ebrahimi, Touradj
TI Balancing Attended and Global Stimuli in Perceived Video Quality
   Assessment
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Attended stimulus; human visual system; temporal pooling; video quality
   assessment; visual attention
ID VISUAL-ATTENTION; MODEL; SENSITIVITY; SALIENCY; REGIONS
AB The visual attention mechanism plays a key role in the human perception system and it has a significant impact on our assessment of perceived video quality. In spite of receiving less attention from the viewers, unattended stimuli can still contribute to the understanding of the visual content. This paper proposes a quality model based on the late attention selection theory, assuming that the video quality is perceived via two mechanisms: global and local quality assessment. First we model several visual features influencing the visual attention in quality assessment scenarios to derive an attention map using appropriate fusion techniques. The global quality assessment as based on the assumption that viewers allocate their attention equally to the entire visual scene, is modeled by four carefully designed quality features. By employing these same quality features, the local quality model tuned by the attention map considers the degradations on the significantly attended stimuli. To generate the overall video quality score, global and local quality features are combined by a content adaptive linear fusion method and pooled over time, taking the temporal quality variation into consideration. The experimental results have been compared to results from appropriate eye tracking and video quality assessment experiments, demonstrating promising performance.
C1 [You, Junyong; Perkis, Andrew; Ebrahimi, Touradj] Norwegian Univ Sci & Technol NTNU, Ctr Quantifiable Qual, Serv Commun Syst, Trondheim, Norway.
   [Korhonen, Jari] Tech Univ Denmark DTU, Dept Photon Engn, Lyngby, Denmark.
   [Ebrahimi, Touradj] Swiss Fed Inst Technol, Multimedia Signal Proc Grp, CH-1015 Lausanne, Switzerland.
   [Ebrahimi, Touradj] Norwegian Univ Sci & Technol NTNU, Ctr Quantifiable Qual Serv, Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU); Technical
   University of Denmark; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne; Norwegian University of
   Science & Technology (NTNU)
RP You, JY (corresponding author), Norwegian Univ Sci & Technol NTNU, Ctr Quantifiable Qual, Serv Commun Syst, Trondheim, Norway.
EM junyong.you@ieee.org; jark@fotonik.dtu.dk; andrew@iet.ntnu.no;
   touradj.ebrahimi@epfl.ch
RI Perkis, Andrew/AAI-4792-2020; Korhonen, Jari/I-3033-2016; Korhonen,
   Jari/AAA-7906-2022
OI Perkis, Andrew/0000-0003-1414-2870; Korhonen, Jari/0000-0003-4354-5310;
   Korhonen, Jari/0000-0003-4354-5310; Ebrahimi,
   Touradj/0000-0002-9900-3687
CR [Anonymous], 2008, J247 ITUT
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   Boulier F., 2009, P AS S COMP MATH ASC, P1
   Broadbent DE, 2013, PERCEPTION COMMUNICA
   Daly S, 1998, P SOC PHOTO-OPT INS, V3299, P180, DOI 10.1117/12.320110
   De Simone F, 2010, INT CONF ACOUST SPEE, P2430, DOI 10.1109/ICASSP.2010.5496296
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Engelke U., 2010, P SPIE VISUAL COMMUN, V7744
   Engleke U., 2010, THESIS BLEKINGE I TE
   Girod Bernd, 1993, P207
   Henderson JM, 2003, TRENDS COGN SCI, V7, P498, DOI 10.1016/j.tics.2003.09.006
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   James W., 1890, The Principles of Psychology, V1
   JONIDES J, 1983, B PSYCHONOMIC SOC, V21, P247
   Junyong You, 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P177, DOI 10.1109/EUVIP.2010.5699102
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Le Meur O, 2010, SIGNAL PROCESS-IMAGE, V25, P547, DOI 10.1016/j.image.2010.05.006
   Le Meur O, 2010, SIGNAL PROCESS-IMAGE, V25, P597, DOI 10.1016/j.image.2010.05.008
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Lee S, 2002, IEEE T MULTIMEDIA, V4, P129, DOI 10.1109/6046.985561
   Liu HT, 2009, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2009.5414466
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Luck SJ, 2000, TRENDS COGN SCI, V4, P432, DOI 10.1016/S1364-6613(00)01545-X
   LUKAS FXJ, 1982, IEEE T COMMUN, V30, P1679, DOI 10.1109/TCOM.1982.1095616
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Ninassi A., 2006, P EUR C SIGN PROC FL
   Ninassi A, 2009, IEEE J-STSP, V3, P253, DOI 10.1109/JSTSP.2009.2014806
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Osberger W, 2001, PROC SPIE, V4299, P361, DOI 10.1117/12.429506
   OSBERGER W, 1999, THESIS QUEENSLAND U
   Pashler H, 1998, PSYCHOL ATTENTION
   Pinson M, 2003, P SOC PHOTO-OPT INS, V5150, P583, DOI 10.1117/12.509909
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Rao RPN, 2005, NEUROREPORT, V16, P1843, DOI 10.1097/01.wnr.0000183900.92901.fc
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Seshadrinathan L., 2010, P SPIE HUMAN VISION, V7527
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   TEO PC, 1994, IEEE IMAGE PROC, P982, DOI 10.1109/ICIP.1994.413502
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Vu CT, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P73, DOI 10.1109/SSIAI.2008.4512288
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Wooding DS, 2002, BEHAV RES METH INS C, V34, P518, DOI 10.3758/BF03195481
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yee H, 2001, ACM T GRAPHIC, V20, P39, DOI 10.1145/383745.383748
   You J., 2009, Proceedings of the 17th ACM International Conference on Multimedia (ACM MM), P561
   You J., 2011, P ACM INT C MULT SCO
   You J., 2011, P IEEE INT C MULT EX
   You JY, 2007, APPL MATH COMPUT, V185, P963, DOI 10.1016/j.amc.2006.07.023
   You JY, 2010, IEEE INT CON MULTI, P914, DOI 10.1109/ICME.2010.5583037
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   Zink M, 2003, LECT NOTES COMPUT SC, V2707, P137
NR 59
TC 23
Z9 25
U1 1
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2011
VL 13
IS 6
BP 1269
EP 1285
DI 10.1109/TMM.2011.2172591
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 852GD
UT WOS:000297343400008
DA 2024-07-18
ER

PT J
AU Wang, P
   Dai, R
   Akyildiz, IF
AF Wang, Pu
   Dai, Rui
   Akyildiz, Ian F.
TI A Spatial Correlation-Based Image Compression Framework for Wireless
   Multimedia Sensor Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Clustered coding; image compression; spatial correlation; wireless
   multimedia sensor networks
ID ENERGY-EFFICIENT; INFORMATION
AB Data redundancy caused by correlation has motivated the application of collaborative multimedia in-network processing for data filtering and compression in wireless multimedia sensor networks (WMSNs). This paper proposes an information theoretic image compression framework with an objective to maximize the overall compression of the visual information gathered in a WMSN. The novelty of this framework relies on its independence of specific image types and coding algorithms, thereby providing a generic mechanism for image compression under different coding solutions. The proposed framework consists of two components. First, an entropy-based divergence measure (EDM) scheme is proposed to predict the compression efficiency of performing joint coding on the images collected by spatially correlated cameras. The EDM only takes camera settings as inputs without requiring statistics of real images. Utilizing the predicted results from EDM, a distributed multi-cluster coding protocol (DMCP) is then proposed to construct a compression-oriented coding hierarchy. The DMCP aims to partition the entire network into a set of coding clusters such that the global coding gain is maximized. Moreover, in order to enhance decoding reliability at data sink, the DMCP also guarantees that each sensor camera is covered by at least two different coding clusters. Experiments on H.264 standards show that the proposed EDM can effectively predict the joint coding efficiency from multiple sources. Further simulations demonstrate that the proposed compression framework can reduce 10%-23% total coding rate compared with the individual coding scheme, i.e., each camera sensor compresses its own image independently.
C1 [Wang, Pu; Dai, Rui; Akyildiz, Ian F.] Georgia Inst Technol, Broadband Wireless Networking Lab, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Wang, P (corresponding author), Georgia Inst Technol, Broadband Wireless Networking Lab, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM pwang40@ece.gatech.edu; aprildai@ece.gatech.edu; ian@ece.gatech.edu
RI Akyildiz, Ian/ABD-5310-2021; Akyildiz, Ian F/G-7136-2011; Wang,
   Pu/ABD-6654-2021
OI Wang, Pu/0000-0003-1988-5016; Dai, Rui/0000-0001-6620-7862
FU U.S. National Science Foundation (NSF) [ECCS-0701559]
FX This work was supported by the U.S. National Science Foundation (NSF)
   under Grant No. ECCS-0701559. The preliminary version was presented at
   the 29th IEEE International Conference on Computer Communications
   (INFOCOM 2010). The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Francesco G. B. De
   Natale.
CR Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], GNU COMP COLL
   [Anonymous], JVT REFERENCE SOFTWA
   [Anonymous], JMVC REFERENCE SOFTW
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Dai R, 2009, IEEE T MULTIMEDIA, V11, P1148, DOI 10.1109/TMM.2009.2026100
   Devarajan D, 2008, P IEEE, V96, P1625, DOI 10.1109/JPROC.2008.928759
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Lu Q, 2008, COMPUT NETW, V52, P2594, DOI 10.1016/j.comnet.2008.05.006
   Ma H, 2005, 2005 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS, COMMUNICATIONS AND MOBILE COMPUTING, VOLS 1 AND 2, P987
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Rajagopalan S., 1999, SIAM J COMPUT, V28
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Wagner R, 2003, IEEE IMAGE PROC, P597
   Wang P., 2010, P IEEE INFOCOM MAR
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu HM, 2005, COMPUT COMMUN, V28, P1658, DOI 10.1016/j.comcom.2005.02.018
   Wu M, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/70481
   Younis O, 2004, IEEE T MOBILE COMPUT, V3, P366, DOI 10.1109/TMC.2004.41
NR 21
TC 40
Z9 49
U1 0
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2011
VL 13
IS 2
BP 388
EP 401
DI 10.1109/TMM.2010.2100374
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 738SG
UT WOS:000288661800019
DA 2024-07-18
ER

PT J
AU Denis, L
   Satti, SM
   Munteanu, A
   Cornelis, J
   Schelkens, P
AF Denis, Leon
   Satti, Shahid M.
   Munteanu, Adrian
   Cornelis, Jan
   Schelkens, Peter
TI Scalable Intraband and Composite Wavelet-Based Coding of Semiregular
   Meshes
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Information theoretic analysis; intraband and composite coding;
   lifting-based wavelet transform; octree coding; scalable mesh coding;
   zerotree coding
ID MULTIRESOLUTION ANALYSIS; LOSSLESS COMPRESSION; SCHEME
AB This paper proposes novel scalable mesh coding designs exploiting the intraband or composite statistical dependencies between the wavelet coefficients. A Laplacian mixture model is proposed to approximate the distribution of the wavelet coefficients. This model proves to be more accurate when compared to commonly employed single Laplacian or generalized Gaussian distribution models. Using the mixture model, we determine theoretically the optimal embedded quantizers to be used in scalable wavelet-based coding of semiregular meshes. In this sense, it is shown that the commonly employed successive approximation quantization is an acceptable, but in general, not an optimal solution. Novel scalable intraband and composite mesh coding systems are proposed, following an information-theoretic analysis of the statistical dependencies between the coefficients. The wavelet subbands are independently encoded using octree-based coding techniques. Furthermore, context-based entropy coding employing either intraband or composite models is applied. The proposed codecs provide both resolution and quality scalability. This lies in contrast to the state-of-the-art interband zerotree-based semiregular mesh coding technique, which supports only quality scalability. Additionally, the experimental results show that, on average, the proposed codecs outperform the interband state-of-the-art for both normal and nonnormal meshes. Finally, compared with a zerotree coding system, the proposed coding schemes are better suited for software/hardware parallelism, due to the independent processing of wavelet subbands.
C1 [Denis, Leon; Satti, Shahid M.; Munteanu, Adrian; Cornelis, Jan; Schelkens, Peter] Vrije Univ Brussel, Dept Elect & Informat, B-1050 Brussels, Belgium.
C3 Vrije Universiteit Brussel
RP Denis, L (corresponding author), Vrije Univ Brussel, Dept Elect & Informat, B-1050 Brussels, Belgium.
EM ldenis@etro.vub.ac.be; smsatti@etro.vub.ac.be; acmuntea@etro.vub.ac.be
RI Schelkens, Peter/B-7831-2008; Cornelis, Jan/ABI-6396-2020; Munteanu,
   Adrian/HKO-9955-2023
OI Schelkens, Peter/0000-0003-0908-1655; Cornelis, Jan/0000-0002-1180-1968;
   Munteanu, Adrian/0000-0001-7290-0428; DENIS, LEON/0000-0001-7564-5549
CR [Anonymous], P IS T SPIE SAN JOS
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   AVILES M, 2005, P PAC RIM C MULT NOV, P61
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Eck M, 1995, P 22 ANN C COMP GRAP, P173, DOI DOI 10.1145/218380.218440
   Fraysse A, 2008, INT CONF ACOUST SPEE, P3753, DOI 10.1109/ICASSP.2008.4518469
   Garland M., 1997, PROC 24 C COMPUTER G, P209, DOI DOI 10.1145/258734.258849
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Guskov I, 2007, GRAPH MODELS, V69, P1, DOI 10.1016/j.gmod.2006.05.001
   Hsiang ST, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL III, P662, DOI 10.1109/ISCAS.2000.856147
   Khodakovsky A, 2004, MATH VISUAL, P189
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   LEE AWF, 1998, ACM SIGGRAPH, P95
   Li JK, 1998, P IEEE, V86, P1052, DOI 10.1109/5.687829
   Liu J, 2001, IEEE T IMAGE PROCESS, V10, P1647, DOI 10.1109/83.967393
   Loop C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618497
   Lounsbery M, 1997, ACM T GRAPHIC, V16, P34, DOI 10.1145/237748.237750
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Munteanu A, 1999, IEEE Trans Inf Technol Biomed, V3, P176, DOI 10.1109/4233.788579
   Munteanu A, 1999, INT J IMAG SYST TECH, V10, P76, DOI 10.1002/(SICI)1098-1098(1999)10:1<76::AID-IMA9>3.0.CO;2-0
   Munteanu A, 1999, IEEE T MED IMAGING, V18, P272, DOI 10.1109/42.764904
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Payan F, 2006, IEEE T VIS COMPUT GR, V12, P649, DOI 10.1109/TVCG.2006.73
   Payan F, 2005, COMPUT AIDED GEOM D, V22, P466, DOI 10.1016/j.cagd.2005.04.001
   Payan F, 2003, IEEE IMAGE PROC, P785
   Payan F, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P245
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Rossignac J., 1993, Geometric Modeling in Computer Graphics, P455
   Roufard R, 1996, COMPUT GRAPH FORUM, V15, pC67
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schruder P., 1995, Proc. 22nd Ann. Conf. Comput. Graphics Interactive Techniques (SIGGRAPH'95), P161
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Soucy M, 1996, COMPUT VIS IMAGE UND, V63, P1, DOI 10.1006/cviu.1996.0001
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   TAUBIN G, 1998, P SIGGRAPH 98, P123
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Taubman D.S., 2001, JPEG 2000: Image Compression Fundamentals, Standards and Practice
   Thomas J.A., 1991, Elements of information theory, V2nd
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P113, DOI 10.1109/TVCG.2004.1260763
   Valette S., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P171, DOI 10.1109/ICIP.1999.821589
   Wu X., 1997, P 31 ASILOMAR C SIGN, V2, P1378, DOI DOI 10.1109/DCC.1997.582047
NR 45
TC 20
Z9 21
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2010
VL 12
IS 8
BP 773
EP 789
DI 10.1109/TMM.2010.2058094
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 681ZW
UT WOS:000284365100001
DA 2024-07-18
ER

PT J
AU Mokhtarian, K
   Hefeeda, M
AF Mokhtarian, Kianoosh
   Hefeeda, Mohamed
TI Authentication of Scalable Video Streams With Low Communication Overhead
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Multimedia authentication; multimedia streaming; scalable video streams
ID H.264/AVC; ENCRYPTION; EXTENSION; SCHEME
AB The large prevalence of multimedia systems in recent years makes the security of multimedia communications an important and critical issue. We study the problem of securing the delivery of scalable video streams so that receivers can ensure the authenticity of the video content. Our focus is on recent scalable video coding (SVC) techniques, such as H.264/SVC, which can provide three scalability types at the same time: temporal, spatial, and visual quality. This three-dimensional scalability offers a great flexibility that enables customizing video streams for a wide range of heterogeneous receivers and network conditions. This flexibility, however, is not supported by current stream authentication schemes in the literature. We propose an efficient and secure authentication scheme that accounts for the full scalability of video streams, and enables verification of all possible substreams that can be extracted from the original stream. In addition, we propose an algorithm for minimizing the amount of authentication information that need to be attached to streams. The proposed authentication scheme supports end-to-end authentication, in which any third-party entity involved in the content delivery process, such as stream adaptation proxies and caches, does not have to understand the authentication mechanism. Our simulation study with real video traces shows that the proposed authentication scheme is robust against packet losses, incurs low computational cost for receivers, has short delay, and adds low communication overhead. Finally, we implement the proposed authentication scheme as an open source library called svcAuth, which can be used as a transparent add-on by any multimedia streaming application.
C1 [Mokhtarian, Kianoosh] Mobidia Inc, Richmond, BC V6X 2W8, Canada.
   [Hefeeda, Mohamed] Simon Fraser Univ, Sch Comp Sci, Surrey V3T 0A3, England.
RP Mokhtarian, K (corresponding author), Mobidia Inc, Richmond, BC V6X 2W8, Canada.
EM kianoosh@cs.sfu.ca; mhefeeda@cs.sfu.ca
CR Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   [Anonymous], 2003, NDSS
   Apostolopoulos JG, 2006, IEEE IMAGE PROC, P729, DOI 10.1109/ICIP.2006.312444
   Atrey PK, 2007, MULTIMED TOOLS APPL, V34, P107, DOI 10.1007/s11042-006-0074-7
   Gentry C, 2005, IEEE J SEL AREA COMM, V23, P464, DOI 10.1109/JSAC.2004.839391
   HEFEEDA M, 2009, ACM T MULTIMEDIA COM
   Iqbal R, 2008, IEEE MULTIMEDIA, V15, P38, DOI 10.1109/MMUL.2008.23
   Jung Min Park, 2003, ACM Transactions on Information and Systems Security, V6, P258, DOI 10.1145/762476.762480
   Kaced R., 2006, P INT C DIG TEL ICDT
   LIANG C, 2007, P C INT INF HID MULT, V1, P225
   MOKHTARIAN K, 2009, P 19 INT WORKSH NETW, P79
   Park SW, 2008, STUD COMPUT INTELL, V142, P351
   *R I R SOL, 2006, GLOB IPTV MARK ANAL
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Skraparlis D, 2003, IEEE T CONSUM ELECTR, V49, P417, DOI 10.1109/TCE.2003.1209535
   *T I R CORP, 2006, STREAM MED IPTV BROA
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wenger S, 2007, IEEE T CIRC SYST VID, V17, P1164, DOI 10.1109/TCSVT.2007.905523
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WIEGAND T, 2007, JVTX201
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Wu YD, 2006, IEEE T MULTIMEDIA, V8, P152, DOI 10.1109/TMM.2005.861283
   YU H, 2004, P IEEE INT C COMM IC, V4, P1912
   ZHANG Y, 2001, P ACM SIGCOMM WORKSH
NR 25
TC 16
Z9 18
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2010
VL 12
IS 7
BP 730
EP 742
DI 10.1109/TMM.2010.2051410
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 670SV
UT WOS:000283448500010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hwangbo, W
   Kyung, CM
AF Hwangbo, Woong
   Kyung, Chong-Min
TI A Multitransform Architecture for H.264/AVC High-Profile Coders
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE DCT; H.264/AVC; Hadamard transform; IDCT; integer transform; VLSI design
ID TRANSFORM; ALGORITHM; DESIGN
AB This paper presents a high-throughput, cost-effective implementation of six different integer transforms in the H.264/AVC high-profile coders, i.e., 4 x 4 forward, 4 x 4 inverse, forward Hadamard, inverse Hadamard, 8 x 8 forward, and 8 x 8 inverse transform, all integrated as a shared hardware. The 4 x 4 transform matrices are regularized by using permutation, partitioned into 2 x 2 blocks, and factored for maximal hardware sharing. By using two types of 4 x 4 transform matrices included in an 8 x 8 transform matrix, two different 8 x 8 transforms are both described as three steps and unified with minor modification. To improve throughput of the transform, two independent 4 x 4 transform blocks within the 8 x 8 transform block operate in parallel in the 4 x 4 transform mode, while the two-stage pipelined architecture is used in the 8 x 8 transform mode. Using 0.18-mu m CMOS technology, the maximum operating frequency of the proposed multitransform architecture is 200 MHz, which achieves 4.1 Gpixels/sec throughput rate with the hardware cost of 63618 gates. Compared with existing designs, the proposed design delivers at least 54% higher throughput at 38% higher throughput/area ratio in Adaptive Block-size Transform (ABT) mode.
C1 [Hwangbo, Woong; Kyung, Chong-Min] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Hwangbo, W (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea.
EM woonghb@vslab.kaist.ac.kr; kyung@ee.kaist.ac.kr
RI Kyung, Chong-Min/C-1864-2011
CR [Anonymous], 2007, H264 ITUT
   Chao YC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1914
   Chen KH, 2006, IEEE T CIRC SYST VID, V16, P472, DOI 10.1109/TCSVT.2006.872782
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Cheng Z. Y., 2004, P IEEE AS PAC C CIRC, P1141
   CHUNGAN P, 2007, P INT C ASIC OCT, P950
   Fan CP, 2006, IEICE T INF SYST, VE89D, P3006, DOI 10.1093/ietisy/e89-d.12.3006
   Fan CP, 2006, 2006 IEEE Asia Pacific Conference on Circuits and Systems, P776
   Fan CP, 2006, IEEE T CIRCUITS-II, V53, P174, DOI 10.1109/TCSII.2005.858748
   Huang CY, 2008, IEEE INT SYMP CIRC S, P21, DOI 10.1109/ISCAS.2008.4541344
   HWANGBO W, 2006, P IEEE INT S CIRC SY, P1613
   Kamaci N, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P345
   Li BB, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P962, DOI 10.1109/ICASIC.2007.4415792
   Li Y, 2008, J SIGNAL PROCESS SYS, V50, P19, DOI 10.1007/s11265-007-0111-4
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Marpe D., 2005, P IEEE INT C IM PROC, pI
   PASTUSZAK G, 2008, P IEEE COMP SOC ANN, P203
   Wang TC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P800
   WEI C, 2008, P IEEE INT C EL CIRC, P606
   Wien M, 2003, IEEE T CIRC SYST VID, V13, P604, DOI 10.1109/TCSVT.2003.815380
NR 20
TC 23
Z9 24
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2010
VL 12
IS 3
BP 157
EP 167
DI 10.1109/TMM.2010.2041099
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 570IN
UT WOS:000275666900001
DA 2024-07-18
ER

PT J
AU Milani, S
   Calvagno, G
AF Milani, Simone
   Calvagno, Giancarlo
TI A Low-Complexity Cross-Layer Optimization Algorithm for Video
   Communication Over Wireless Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Bit allocation; cross-layer optimization; cross-packet codes; DiffServ;
   H.264/AVC; IEEE 802.11; packet classification; video coding; video
   transmission
ID RATE-DISTORTION ANALYSIS; ERROR CONTROL; TRANSMISSION
AB Recent years have witnessed a rapid increment in video applications over wireless networks including on-demand video streaming and videophoning. This growth has also brought the need to find a good compromise in the conflict between resource limitations affecting mobile devices and the desire for high-quality multimedia services. It is possible to face this problem adopting a cross-layer strategy that jointly tunes the parameters of each layer in the network protocol stack. In this optimization strategy, complexity is one of the most significant issues because of the limited computational resources and power supply. The paper presents a low-complexity cross-layer algorithm that is able to jointly tune the parameters of different protocol layers by adopting simple but effective models. The quality of the reconstructed video sequence, the produced bit rate, and the service class associated to each packet are seen as functions of the percentage of null DCT coefficients. This modeling permits to find a closed-form solution to the joint optimization problem that can be computed with a limited number of operations and grants, at the same time, a good visual quality in the reconstructed sequence.
C1 [Milani, Simone; Calvagno, Giancarlo] Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.
C3 University of Padua
RP Milani, S (corresponding author), Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.
EM simone.milani@dei.unipd.it; cal-vagno@dei.unipd.it
OI Milani, Simone/0000-0001-8266-5839
FU Italian Ministry of University and Research (MiUR) [2005099247]
FX This work was supported in part by the Italian Ministry of University
   and Research ( MiUR) under the PRIN project prot. 2005099247.
CR [Anonymous], 2474 IETF RFC
   Blake S., 1998, 2475 IETF RFC
   Eisenberg Y, 2002, IEEE T CIRC SYST VID, V12, P411, DOI 10.1109/TCSVT.2002.800309
   Farber N., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P550, DOI 10.1109/ICIP.1999.822956
   GENNARI G, 2004, P 12 EUR SIGN PROC C, P649
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P1221, DOI 10.1109/76.974677
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Heinanen J., 1999, 2698 IETF RFC
   *IEEE, 2005, 80211D130 IEEE 11
   Katsaggelos AK, 2005, P IEEE, V93, P135, DOI 10.1109/JPROC.2004.839621
   Kawadia V, 2005, IEEE WIREL COMMUN, V12, P3, DOI 10.1109/MWC.2005.1404568
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   Leontaris A, 2004, IEEE T IMAGE PROCESS, V13, P885, DOI 10.1109/TIP.2004.828429
   Liebl G., 2004, RTP PAYLOAD FORMAT E
   Lin XJ, 2006, IEEE J SEL AREA COMM, V24, P1452, DOI 10.1109/JSAC.2006.879351
   LUNA CE, 2002, P IEEE INT PACK VID
   MILANI S, 2005, P 3 EUR SIGN PROC C
   Milani S, 2008, IEEE T CIRC SYST VID, V18, P257, DOI 10.1109/TCSVT.2007.913965
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Park H, 2007, IEEE T SIGNAL PROCES, V55, P3496, DOI 10.1109/TSP.2007.893755
   Qu Q., 2005, EURASIP Journal on Wireless Communications and Networking, V2005, P743, DOI 10.1155/WCN.2005.743
   Qu Q, 2006, IEEE T MULTIMEDIA, V8, P1033, DOI 10.1109/TMM.2006.879840
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   VANDERSCHAAR M, 2005, P IEEE INT S CIRC SY
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WARRIER A, 2007, P IEEE BROADN 2007 I
   Zhai F, 2006, IEEE T IMAGE PROCESS, V15, P40, DOI 10.1109/TIP.2005.860353
   Zhai F, 2005, IEEE T MULTIMEDIA, V7, P716, DOI 10.1109/TMM.2005.850989
   Zhai F, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P857
   Zhang Q, 2005, EURASIP J APPL SIG P, V2005, P207, DOI 10.1155/ASP.2005.207
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   2002, 4 M KLAG GERM JUL
NR 34
TC 9
Z9 9
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2009
VL 11
IS 5
BP 810
EP 821
DI 10.1109/TMM.2009.2021791
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 474KN
UT WOS:000268282300002
DA 2024-07-18
ER

PT J
AU He, YF
   Shen, GB
   Xiong, YQ
   Guan, L
AF He, Yifeng
   Shen, Guobin
   Xiong, Yongqiang
   Guan, Ling
TI Optimal Prefetching Scheme in P2P VoD Applications With Guided Seeks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Information aggregation; optimization; Peer-to-Peer (P2P)
   Video-on-Demand (VoD); prefetching scheme; seeking delay; sketch
AB Most existing Peer-to-Peer (P2P) Video-on-Demand (VoD) systems have been designed and optimized for the sequential playback. In practice, users often want to seek to the positions they are interested in. Such frequent seeks raise greater challenges to the design of the prefetching scheme. In this work, we first propose the concept of guided seeks. With the guidance, users can perform more efficient seeks to the desired positions. The guidance can be obtained from collective seeking statistics of other peers who have watched the same title in the previous and/or concurrent sessions. However, it is very challenging to aggregate the statistics efficiently, timely and in a completely distributed way. We design the hybrid sketches that not only capture the seeking statistics at significantly reduced space and time complexity, but also adapt to the popularity of the video. From the collected seeking statistics, we estimate the segment access probability, based on which we further develop an optimal prefetching scheme and an optimal cache replacement policy to minimize the expected seeking delay at every viewing position. Through extensive simulations, we demonstrate that the proposed prefetching framework significantly reduces the seeking delay compared to the sequential prefetching scheme.
C1 [He, Yifeng; Guan, Ling] Ryerson Univ, Toronto, ON M5B 2K3, Canada.
   [Shen, Guobin; Xiong, Yongqiang] Microsoft Res Asia, Beijing, Peoples R China.
C3 Toronto Metropolitan University; Microsoft; Microsoft Research Asia
RP He, YF (corresponding author), Ryerson Univ, Toronto, ON M5B 2K3, Canada.
EM yhe@ee.ryerson.ca; Jacky.Shen@microsoft.com;
   Yongqiang.Xiong@microsoft.com; lguan@ee.ryerson.ca
CR [Anonymous], ACM SIGMOBILE MOBILE
   [Anonymous], P IEEE ICC
   [Anonymous], P IPTPS FEB
   [Anonymous], 2001, Linear Programming: Foundations and extensions, Department of Operations Research and Financial Engineering
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Boyd S, 2005, IEEE INFOCOM SER, P1653
   CHEN B, 2007, P IPTPS FEB
   Cheng B, 2007, IEEE ICC, P1698, DOI 10.1109/ICC.2007.284
   Chi H., 2006, IEEE J SEL AREA COMM, V3, P1467
   Considine J, 2004, PROC INT CONF DATA, P449, DOI 10.1109/ICDE.2004.1320018
   Cormode G, 2005, J ALGORITHMS, V55, P58, DOI 10.1016/j.jalgor.2003.12.001
   Cormode G, 2007, PODC'07: PROCEEDINGS OF THE 26TH ANNUAL ACM SYMPOSIUM ON PRINCIPLES OF DISTRIBUTED COMPUTING, P215
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   Fan L, 2000, IEEE ACM T NETWORK, V8, P281, DOI 10.1109/90.851975
   FLAJOLET P, 1985, J COMPUT SYST SCI, V31, P182, DOI 10.1016/0022-0000(85)90041-8
   Gkantsidis C, 2004, IEEE INFOCOM SER, P120
   Heffeeda M., 2003, P ACM MULTIMEDIA, P45
   Kangasharju J, 2007, IEEE INFOCOM SER, P1973, DOI 10.1109/INFCOM.2007.229
   Kempe D, 2003, ANN IEEE SYMP FOUND, P482, DOI 10.1109/SFCS.2003.1238221
   Keshav S, 2006, ACM SIGCOMM COMP COM, V36, P69, DOI 10.1145/1111322.1111338
   Lee I, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P513
   Li J, 2005, Proceedings of the 3rd Annual Communication Networks and Services Research Conference, P197
   LI Z, 2006, P SHINE AUG
   Sharma A, 2005, IEEE INFOCOM SER, P1139
   Shen YM, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P817, DOI 10.1109/ICME.2006.262626
   Suh K, 2007, IEEE J SEL AREA COMM, V25, P1706, DOI 10.1109/JSAC.2007.071209
   Tuah NJ, 2002, IEEE T PARALL DISTR, V13, P471, DOI 10.1109/TPDS.2002.1003857
   Xu XF, 2004, IEEE IMAGE PROC, P1759
   Yiu WPK, 2007, IEEE J SEL AREA COMM, V25, P1717, DOI 10.1109/JSAC.2007.071210
   ZAHARIA MA, 2006, P IPTIPS FEB
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zheng C., 2005, PROC ACM WORKSHOP AD, P29
NR 32
TC 29
Z9 36
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JAN
PY 2009
VL 11
IS 1
BP 138
EP 151
DI 10.1109/TMM.2008.2008929
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 398EF
UT WOS:000262714700012
DA 2024-07-18
ER

PT J
AU Ma, M
   Au, OC
   Guo, L
   Chan, SHG
   Wong, PHW
AF Ma, Mengyao
   Au, Oscar C.
   Guo, Liwei
   Chan, S. -H. Gary
   Wong, Peter H. W.
TI Error Concealment for Frame Losses in MDC
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Error concealment; error propagation; error resilience; MDC;
   multihypothesis; temporal interpolation
AB Multiple description coding (MDC) is an effective error resilience (ER) technique for video coding. In case of frame loss, error concealment (EC) techniques can be used in MDC to reconstruct the lost frame, with error, from which subsequent frames can be decoded directly. With such direct decoding, the subsequent de coded frames will gradually recover from the frame loss, though slowly. In this paper we propose a novel algorithm using multihypothesis error concealment (MHC) to improve the error recovery rate of any EC in the temporal subsampling MDC. In MHC, the simultaneous temporal-interpolated frame is used as an additional hypothesis to improve the reconstructed video quality after the lost frame. Both subjective and objective results show that MHC can achieve significantly better video quality than direct decoding.
C1 [Ma, Mengyao; Au, Oscar C.; Guo, Liwei; Chan, S. -H. Gary; Wong, Peter H. W.] Hong Kong Univ Sci & Technol, MTrec, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Ma, M (corresponding author), Hong Kong Univ Sci & Technol, MTrec, Hong Kong, Hong Kong, Peoples R China.
EM myma@ust.hk; eeau@ust.hk; eeglw@ust.hk; gchan@ust.hk; eepeter@ust.hk
RI Wong, Peter/AAA-3481-2022
OI Wong, Peter/0000-0003-0373-933X; Chan, Gary Shueng
   Han/0000-0003-4207-764X
FU Innovation and Technology Commission [ITS/122/03, GHP/033/05]
FX Manuscript received August 27, 2007: revised May 26, 2008. Current
   version published December 10, 2008. This work was supported in part by
   the Innovation and Technology Commission (Projects ITS/122/03 and
   GHP/033/05) of the Hong Kong Special Administrative Region, China. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Baochun Li.
CR [Anonymous], JVT REFERENCE SOFTWA
   Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   Belfiore S, 2005, IEEE T MULTIMEDIA, V7, P316, DOI 10.1109/TMM.2005.843347
   Brown R., 2012, Introduction to Random Signals and Applied Kalman Filtering With MATLAB Exercises, V4th
   CHEN Y, 2004, PICT COD S DEC
   Dane G, 2006, IEEE T IMAGE PROCESS, V15, P978, DOI 10.1109/TIP.2005.863947
   Farber N., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P550, DOI 10.1109/ICIP.1999.822956
   Fu CM, 2005, INT CONF ACOUST SPEE, P305
   Girod B., 2000, COMPRESSED VIDEO NET
   Hsia SC, 2005, IEEE T MULTIMEDIA, V7, P860, DOI 10.1109/TMM.2005.854432
   Kumar S, 2006, J VIS COMMUN IMAGE R, V17, P425, DOI 10.1016/j.jvcir.2005.04.006
   Li XT, 2005, COMP SEMICOND INTEGR, P105
   Ma MY, 2006, IEEE INT SYMP CIRC S, P694
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P72, DOI 10.1109/MCOM.2008.4427233
   Tang CW, 1997, ISCAS '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I - IV, P1444, DOI 10.1109/ISCAS.1997.622187
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   WENGER S, 1999, Q15116RL ITUT SG16
   WONG CK, 1995, P SOC PHOTO-OPT INS, V2501, P1108, DOI 10.1117/12.206643
   Wu ZY, 2006, IEEE INT SYMP CIRC S, P4463
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P713, DOI 10.1109/76.728413
NR 22
TC 6
Z9 8
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2008
VL 10
IS 8
BP 1638
EP 1647
DI 10.1109/TMM.2008.2007282
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 390KS
UT WOS:000262163600018
OA Green Published
DA 2024-07-18
ER

PT J
AU Xie, G
   Swamy, MNS
   Ahmad, MO
AF Xie, Gui
   Swamy, M. N. S.
   Ahmad, M. Omair
TI Joint Optimal Multipath Routing and Rate Control for Multidescription
   Coded Video Streaming in <i>Ad Hoc</i> Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Ad hoc networks; multidescription (MID) coding; multipath routing;
   packet skipping; rate control; R-D hint; video streaming
ID SELECTION; TRANSPORT
AB This paper studies an important problem, namely, the joint multipath routing and rate control for multidescription coded (MD-coded) video streaming in wireless ad hoc networks. In addition to selecting a pair of paths to optimize the expected end-to-end video quality, we also explore an optimal packet skipping strategy for the rate control in order to minimize the impact of the skipped packets on the quality of the video. The R-D hint information, consisting of the size of the packets in bits and the importance of the packets for reconstructing the video, is used to characterize the packets in an R-D sense. Since searching for paths to minimize the expected end-to-end video distortion by simultaneously considering the skipped packets prior to the transmission and those dropped/delayed during the transmission is a highly complex problem and is expected to be NP-hard, we develop a heuristic greedy-relaxation-based routing solution that enables the system to efficiently select near-optimal paths. Extensive simulation studies have been conducted to compare the performance of the proposed algorithm with that of several existing algorithms, showing the superior performance of the proposed one. Such a joint rate control and multipath routing approach provides an important methodology for high-quality real-time video streaming applications over ad hoc wireless networks.
C1 [Xie, Gui] Matrox Video Inc, Montreal, PQ HG3 1M8, Canada.
   [Swamy, M. N. S.; Ahmad, M. Omair] Concordia Univ, Dept Elect & Comp Engn, Ctr Commun & Signal Proc, Montreal, PQ HG3 1M8, Canada.
C3 Concordia University - Canada
RP Xie, G (corresponding author), Matrox Video Inc, Montreal, PQ HG3 1M8, Canada.
EM rxie@matrox.com; swamy@encs.con-cordia.ca; omair@encs.concordia.ca
FU Natural Science and Engineering Research Council of Canada
FX Manuscript received April 12, 2007; revised June 02, 2008. Current
   version published December 10, 2008. This work was supported by the
   Natural Science and Engineering Research Council of Canada. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Prof. Ling Guan.
CR [Anonymous], 2003, Experimental
   [Anonymous], J ZHEJIANG U SCI A
   Apostolopoulos J, 2002, IEEE INFOCOM SER, P1736, DOI 10.1109/INFCOM.2002.1019427
   CHAKARESKI J, 2003, P 11 ACM INT C MULT, P422
   CHAKARESKI J, 2004, P IEEE ICME 2004 TAI
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Eppstein D, 1998, SIAM J COMPUT, V28, P652, DOI 10.1137/S0097539795290477
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   JOHNSON DB, 2003, DYN SOURC R IN PRESS
   Jurca D, 2007, IEEE T MULTIMEDIA, V9, P629, DOI 10.1109/TMM.2006.888017
   Kuipers F, 2002, IEEE COMMUN MAG, V40, P50, DOI 10.1109/MCOM.2002.1106159
   Li DJ, 2006, IEEE INT SYMP CIRC S, P698
   Mao SW, 2007, IEEE T WIREL COMMUN, V6, P338, DOI 10.1109/TWC.2007.05236
   Mao SW, 2006, IEEE T MULTIMEDIA, V8, P1063, DOI 10.1109/TMM.2006.879845
   Mao SW, 2006, IEEE T MULTIMEDIA, V8, P356, DOI 10.1109/TMM.2005.864347
   Mao SW, 2005, IEEE WIREL COMMUN, V12, P42, DOI 10.1109/MWC.2005.1497857
   Mao SW, 2003, IEEE J SEL AREA COMM, V21, P1721, DOI 10.1109/JSAC.2003.815965
   Nguyen T, 2003, IEEE INFOCOM SER, P663
   Ogier R., 2004, TOPOLOGY DISSEMINATI
   Papadimitratos P., 2002, SECURING MOBILE AD H, P1
   Papadopouli M., 2001, MobiHoc, P117, DOI DOI 10.1145/501416.501433]
   Setton E, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1619, DOI 10.1109/ICME.2004.1394560
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xie G, 2007, IEEE ICC, P1618, DOI 10.1109/ICC.2007.271
NR 25
TC 12
Z9 13
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2008
VL 10
IS 8
BP 1687
EP 1697
DI 10.1109/TMM.2008.2007291
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 390KS
UT WOS:000262163600022
DA 2024-07-18
ER

PT J
AU An, CH
   Nguyen, TQ
AF An, Cheolhong
   Nguyen, Truong Q.
TI Resource Allocation for TDMA Video Commtmmunication Over AWGN Using
   Cross-Layer Optimization Approach
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Cross-layer optimization; H.264; utility function; video; 802.11
ID DISTRIBUTED ALGORITHMS; DISTORTION; DECOMPOSITION; TRANSMISSION;
   DISTANCE; TRADEOFF
AB Cross-layer optimization approach is applied to allocate channel times of time-division multiple access (TDMA) to utility functions which send different video streams with different rate-distortion characteristics. Given a channel time, each utility function solves an optimization problem to obtain the optimal source code rate, channel code rate and media access control (MAC) frame size. In this paper, we derive mathematical models to represent end-to-end distortion of video streams and 802.11a-like MAC and PHV with automatic repeat reQuest (ARQ) and rate compatible punctured convolutional code (RCPC) over additive white Gaussian noise (AWGN) channel. These models are formulated as a convex optimization problem, and it is solved by the primal-dual decomposition method. In addition, coexistence among the proposed utility functions and conventional utility functions is discussed. Finally, numerical examples show that significant reduction of overall distortion of utility functions can be achieved.
C1 [An, Cheolhong; Nguyen, Truong Q.] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
C3 University of California System; University of California San Diego
RP An, CH (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
EM chan@ucsd.edu; nguyent@ece.ucsd.edu
RI Nguyen, Truong/JXN-9786-2024
CR AN C, 2007, P IEEE ICIP
   [Anonymous], 2016, IEEE Standard 802.11-2020
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 1999, IEEE Std. 802.11a
   Bertsekar D.P., 2003, NONLINEAR PROGRAMMIN, V2nd
   Boyd S., 2004, CONVEX OPTIMIZATION
   Bystrom M, 2000, IEEE J SEL AREA COMM, V18, P880, DOI 10.1109/49.848242
   Cheung G, 2000, IEEE T IMAGE PROCESS, V9, P340, DOI 10.1109/83.826773
   Chiang M, 2007, P IEEE, V95, P255, DOI 10.1109/JPROC.2006.887322
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   COSTELLO DJ, 1974, IEEE T INFORM THEORY, V20, P356, DOI 10.1109/TIT.1974.1055223
   Fowler P, 2002, IEEE MICROW MAG, V3, P49, DOI 10.1109/MMW.2002.1028362
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   Haratcherev I, 2006, IEEE COMMUN MAG, V44, P115, DOI 10.1109/MCOM.2006.1580941
   HARATCHEREV I, 2005, P IEEE ISCAS
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   *HHI, 2001, H 264 AVC REF SOFTW
   Hochwald B, 1997, IEEE T INFORM THEORY, V43, P1412, DOI 10.1109/18.623141
   *IEEE, 2003, 802153 IEEE
   *IEEE, 2005, WIR LAN MED ACC CONT
   *ITU T, 2003, H264 ITUT
   IZZAT I, 2005, P IEEE ICCE
   JOHANNESSON R, 2001, FUNDAMENTALS CONVOLU
   JOHANSSON B, 2005, P 16 IFAC WORLD C PR
   KALMAN M, 2005, P IEEE MMSP
   Kelly FP, 1998, J OPER RES SOC, V49, P237, DOI 10.2307/3010473
   Kim HM, 2003, IEEE T CIRC SYST VID, V13, P432, DOI 10.1109/TCSVT.2003.811606
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Lee JW, 2006, IEEE J SEL AREA COMM, V24, P962, DOI 10.1109/JSAC.2006.872877
   Li Z., 2003, P JOINT VID TEAM JVT
   Li ZG, 2003, IEEE T CIRC SYST VID, V13, P472, DOI 10.1109/TCSVT.2003.813420
   Lin S., 2004, Error Control Coding, Vsecond
   Palomar DP, 2007, IEEE T AUTOMAT CONTR, V52, P2254, DOI 10.1109/TAC.2007.910665
   Palomar DP, 2005, IEEE T SIGNAL PROCES, V53, P4661, DOI 10.1109/TSP.2005.859241
   Qiao Daji., 2001, P IEEE ICC
   Reichel J., 2007, JOINT SCALABLE VIDEO
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Takanohashi T, 2002, ENERG FUEL, V16, P6, DOI 10.1021/ef0101255
   Wang Y, 2006, IEEE T CIRC SYST VID, V16, P716, DOI 10.1109/TCSVT.2006.875203
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168
   WIEGAND T, 2001, P IEEE ICIP
NR 43
TC 0
Z9 0
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2008
VL 10
IS 7
BP 1406
EP 1418
DI 10.1109/TMM.2008.2004938
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 378HB
UT WOS:000261310700016
DA 2024-07-18
ER

PT J
AU Mademlis, A
   Daras, P
   Axenopoulos, A
   Tzovaras, D
   Strintzis, MG
AF Mademlis, Athanasios
   Daras, Petros
   Axenopoulos, Apostolos
   Tzovaras, Dimitrios
   Strintzis, Michael G.
TI Combining topological and geometrical features for global and partial
   3-D shape retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE 3-D shape retrieval; global matching; partial matching; topological
   matching
ID SEARCH; MODELS
AB This paper presents a novel framework for 3-D object content-based search and retrieval, appropriate for both partial and global matching applications. The framework is based on a graph representation of a 3-D object which is enhanced by local geometric features. The 3-D object is decomposed into meaningful parts and an attributed graph is constructed based on the connectivity of the parts. Every 3-D part is approximated with a suitable superellipsoid and a novel 3-D shape descriptor, called a 3-D distance field descriptor, is computed and associated to the corresponding graph nodes. The matching process used is based on attributed graph matching algorithm appropriate for this application. The proposed method not only provides successful retrieval results in terms of geometric similarity but also is invariant to rotation, translation and scaling of an object as well as to the different poses of articulated objects. Finally, it can be effectively used for partial and global 3-D object retrieval.
C1 [Mademlis, Athanasios; Strintzis, Michael G.] Aristotle Univ Thessaloniki, Dept Elect & Comp Engn, GR-54006 Thessaloniki, Greece.
   [Daras, Petros; Axenopoulos, Apostolos; Tzovaras, Dimitrios] Informat & Telemat Inst, GR-57001 Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Mademlis, A (corresponding author), Aristotle Univ Thessaloniki, Dept Elect & Comp Engn, GR-54006 Thessaloniki, Greece.
EM inademlis@iti.gr; daras@iti.gr; axenop@iti.gr;
   Dirritrios.Tzovaras@iti.gr; strintzi@eng.auth.gr
RI Daras, Petros/F-5284-2012; Tzovaras, Dimitrios/ABB-9576-2021
OI Daras, Petros/0000-0003-3814-6710; Tzovaras,
   Dimitrios/0000-0001-6915-6722
CR Amenta N, 2001, COMP GEOM-THEOR APPL, V20, P25, DOI 10.1016/S0925-7721(01)00033-5
   [Anonymous], P ASME DETC 03 23 CO
   [Anonymous], THESIS U LEIPZIG LEI
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   Canterakis N., 1999, P 11 SCAND C IM AN
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   CHEN DY, 2002, P COMP GRAPH WORKSH, P16
   Cornea ND, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P95
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   CORNEA ND, 2005, P INT C SHAP MOD APP
   Daras P, 2006, IEEE T MULTIMEDIA, V8, P101, DOI 10.1109/TMM.2005.861287
   FUNKHOUSER T, 2006, EUR S GEOM PROC SARD
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   IYER N, P TMCE 2004 TOOLS ME, V2, P1117
   Kadyrov A, 2001, IEEE T PATTERN ANAL, V23, P811, DOI 10.1109/34.946986
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kazhdan M., 2003, P EUR S GEOM PROC
   Kolonias I, 2005, IEEE T MULTIMEDIA, V7, P114, DOI 10.1109/TMM.2004.840605
   LOU K, 2003, P ASME DETC 03 23 CO
   MALANDAIN G, 1993, INT J COMPUT VISION, V10, P183, DOI 10.1007/BF01420736
   Moustakas K., 2005, P 1 INT WORKSH SEM V
   Moustakas K, 2007, IEEE T VIS COMPUT GR, V13, P80, DOI 10.1109/TVCG.2007.20
   *MPEG VID GROUP, ISO MPEG N3914 MPEG
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   NOVOTNI M, 2005, CG20052 F WILH U BON
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653
   Siddiqi K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P828, DOI 10.1109/ICCV.1999.790307
   SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tangelder J. W., 2004, SHAP MOD APPL 2004 P
   Tung T, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P157, DOI 10.1109/SMI.2004.1314503
   TYPKE R, 2006, P INT C MULT EXP ICM
   van Wyk BJ, 2004, IEEE T PATTERN ANAL, V26, P1526, DOI 10.1109/TPAMI.2004.95
   VANWYK BJ, 2003, THESIS U WITWATERSRA
   VELTKAMP RC, 2006, UUCS2006030 3D SHAP
   Vranic D.V., 2001, P EURASIP C DIG SIGN
   Vranic DV, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P177, DOI 10.1109/ICME.2002.1035747
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   ZARPALAS D, 2007, EURASIP J ADV SIG PR, V2007, P14
   ZHANG J, 2005, P INT WORKSH EN MIN
NR 42
TC 30
Z9 32
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2008
VL 10
IS 5
BP 819
EP 831
DI 10.1109/TMM.2008.922790
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 334LR
UT WOS:000258223800014
DA 2024-07-18
ER

PT J
AU Fan, JP
   Gao, YL
   Luo, HZ
   Jain, R
AF Fan, Jianping
   Gao, Yuli
   Luo, Hangzai
   Jain, Ramesh
TI Mining multilevel image semantics via hierarchical classification
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE adaptive EM algorithm; concept ontology; hyperbolic visualization; image
   classification; multitask learning; product of mixture-experts; salient
   objects; variational method
ID CONCEPT ONTOLOGY; RETRIEVAL; ANNOTATION
AB In this paper, we have proposed a novel framework for mining multilevel image semantics via hierarchical classification. To bridge the semantic gap more successfully, salient objects are used to characterize the intermediate image semantics effectively. The salient objects are defined as the connected image regions that capture the dominant visual properties linked to the corresponding physical objects in an image. To achieve a more reliable and tractable concept learning in high-dimensional feature space, a novel algorithm called product of mixture-experts (PoM) is proposed to reduce the size of training images and speed up concept learning. A novel hierarchical concept learning algorithm is proposed by incorporating concept ontology and multitask learning to enhance the discrimination power of the concept models and reduce the computational complexity for learning the concept models for large amount of image concepts, which may have huge intra-concept variations and inter-concept similarities on their visual properties. A hyperbolic image visualization algorithm has been developed for allowing users to specify their queries easily and assess the query results interactively. Our experiments on large-scale image collections have also obtained very positive results.
C1 [Fan, Jianping; Gao, Yuli; Luo, Hangzai] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Jain, Ramesh] Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA.
C3 University of North Carolina; University of North Carolina Charlotte;
   University of California System; University of California Irvine
RP Fan, JP (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
CR [Anonymous], 2005, 2005 IEEE COMP SOC C
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2001, IEEE COMP SOC C COMP
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Beal MJ, 2006, BAYESIAN ANAL, V1, P793, DOI 10.1214/06-BA126
   BENITEZ AB, 2000, P SPIE, V4210
   Boutell MR, 2007, IEEE T MULTIMEDIA, V9, P136, DOI 10.1109/TMM.2006.886372
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Crandall D, 2004, PROC CVPR IEEE, P379
   Evgeniou T, 2005, J MACH LEARN RES, V6, P615
   FAN J, 2007, ACM SIGIR, P111
   Fan J., 2004, ACM Multimedia
   FAN J, 2005, ACM SIGKDD
   Fan J, 2007, IEEE T MULTIMEDIA, V9, P939, DOI 10.1109/TMM.2007.900143
   Fan JP, 2005, PATTERN RECOGN, V38, P865, DOI 10.1016/j.patcog.2004.07.011
   FORSYTH D, 1997, P IEEE C COMP VIS PA
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gao Y., 2006, ACM Multimedia
   GAO Y, 2006, ACM MIR
   GRAUMAN K, 2006, MITCSAILTR200620
   HARE JS, 2006, P SPIE, V6073
   Huang J., 1998, ACM Multimedia
   JAAKOLA TS, 1997, THESIS MIT CAMBRIDGE
   JAIMES A, 2005, ACM MULT WORKSH MIR, P3
   JAIMES A, 1999, SPIE STORAGE RETRIEV
   Jeon J, 2004, LECT NOTES COMPUT SC, V3115, P24
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   JIANG W, 2007, P IEEE ICASSP
   KNUTH DE, 1978, SORTING SEARCHING, V3
   LAMPING J, 1996, J VIS LANG COMPUT
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   LI Y, 2005, P IEEE INT C COMP VI
   Lim JH, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1237548
   LIPSON P, 1997, P CVPR
   Lowe D.G., 2004, P IEEE INT C COMP VI
   MARON O, 1998, P NEUR INF PROC SYST
   McLachlan G., 2000, EM ALGORITHM EXTENSI
   MINKA TP, 1996, P IEEE C COMP VIS PA
   Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   NAPHADE M, 2003, P CIVR 2003 URB IL J, P196
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Thrun S, 1996, ADV NEUR IN, V8, P640
   TONG S, 2001, ACM MULTIMEDIA
   TORRALBA AB, 1999, P ICCV
   VAILAYA A, 1998, P SPIE, V3656
   Vapnik V., 1999, NATURE STAT LEARNING
   VASCONCELOS N, 1998, P IEEE C COMP VIS PA
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   YU K, 2003, P INT C UNC ART INT
   ZHANG B, 2004, PATTERN RECOG, V37
   ZHANG J, 2003, P ICML
   ZHANG Q, 2001, P NEUR INF PROC SYST
   ZHANG R, 2004, P IEEE C COMP VIS PA
   Zhang R., 2005, P IEEE INT C COMP VI
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 68
TC 63
Z9 70
U1 0
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2008
VL 10
IS 2
BP 167
EP 187
DI 10.1109/TMM.2007.911775
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 254HC
UT WOS:000252576700002
DA 2024-07-18
ER

PT J
AU Ahmad, I
   Kamruzzaman, J
AF Ahmad, Iftrkhar
   Kamruzzaman, Joarder
TI Preemption-aware instantaneous request call routing for networks with
   book-ahead reservation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE multimedia applications; quality of service; resource; reservation;
   routing
ID BANDWIDTH-GUARANTEED TUNNELS; QUALITY
AB This paper presents a new preemption-aware quality of service (QoS) routing algorithm for instantaneous request (111) call connections in a QoS-enabled network where resources are shared between IR and book-ahead (BA) call connections. BA reservation, which confirms the availability of resources in advance, is a highly attractive technique for time sensitive applications that require high amount of bandwidth with guaranteed QoS. One of the major concerns for the implementation of BA reservation is the need for preemption of on-going IR calls to accommodate BA calls when resource scarcity arises. Preemption disrupts service continuity of on-going calls which is considered as severely detrimental from users' perceived QoS definition found in recent studies. Existing QoS routing algorithms focus on resource conservation or load balancing as the key objective to attain in addition to guaranteed QoS. No works have yet focused on the preemption problem of on-going IR calls at routing stage in the presence of BA calls. We present a mathematical formulation to compute the preemption probability of an incoming IR call at routing stage based on the current IR and future BA load information. We propose a routing strategy by formulating a link cost function comprising of the calculated preemption probability of the incoming IR call and hop count. Simulation results confirm that QoS routing based on the proposed link cost function significantly outperforms widely recommended shortest path and widest path routing algorithms in terms of IR call preemption and blocking rate. The proposed approach also yields higher network utilization and IR effective throughput.
C1 Monash Univ, Gippsland Sch Comp & Informat Technol, Fac Informat Technol, Clayton, Vic 3842, Australia.
C3 Monash University; Federation University Australia
RP Ahmad, I (corresponding author), Monash Univ, Gippsland Sch Comp & Informat Technol, Fac Informat Technol, Clayton, Vic 3842, Australia.
EM i.ahmad@ecu.edu.au; Joarder.Kamruzzaman@infotech.monash.edu.au
OI Ahmad, Iftekhar/0000-0003-4441-9631; Kamruzzaman,
   Joarder/0000-0002-3748-0277
CR Ahmad I, 2005, GLOB TELECOMM CONF, P715
   Ahmad I, 2006, COMPUT COMMUN, V29, P1443, DOI 10.1016/j.comcom.2005.09.009
   [Anonymous], 1992, Data networks
   APOSTOLOPOULOS G, 1999, IEEE T NETW, V7, P350
   Awerbuch B., 1993, Proceedings. 34th Annual Symposium on Foundations of Computer Science (Cat. No.93CH3368-8), P32, DOI 10.1109/SFCS.1993.366884
   Banerje G, 2002, COMPUT NETW, V40, P149, DOI 10.1016/S1389-1286(02)00270-0
   CAMPANELLA M, QUALITY SERVICE DEFI
   CHEN VL, 2003, LSP PREEMPTION POLIC
   DEGERMARK M, 1995, P NOSSDAV 95 DURH NH
   Ferrari D., 1995, Proceedings of the 5th International Workshop on Network and Operating System Support for Digital Audio and Video, P15
   Greenberg AG, 1999, IEEE ACM T NETWORK, V7, P10, DOI 10.1109/90.759312
   Guerin R. A., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P118, DOI 10.1109/INFCOM.2000.832180
   HARDY WC, 2001, QOS MEASUREMENT EVAL, P169
   Hendling K, 2004, IEEE INT CONF NETWOR, P497
   Jha Sanjay., 2002, ENG INTERNET QOS
   Kamath A, 1996, PROCEEDINGS OF THE SEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P269
   Kar K, 2000, IEEE J SEL AREA COMM, V18, P2566, DOI 10.1109/49.898737
   Kodialam M, 2003, IEEE ACM T NETWORK, V11, P399, DOI 10.1109/TNET.2003.813044
   Kowalik K, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P213
   LEE WC, 1995, IEEE NETWORK, V9, P46, DOI 10.1109/65.397043
   LEWIS S, 2006, ARTICLES VELOCITY 20
   Lin YD, 2002, IEICE T COMMUN, VE85B, P278
   OLIVEIRA J, 2002, P IEEE INFOCOM 2002, V2, P695
   Pornavalai C, 1997, 1997 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS - PROCEEDINGS, P167, DOI 10.1109/ICNP.1997.643711
   RETVARI G, P IEEE INFOCOM 05, P260
   Schelén O, 1998, J HIGH SPEED NETW, V7, P213
   Shaikh A, 2001, IEEE ACM T NETWORK, V9, P162, DOI 10.1109/90.917073
   Wang BH, 2002, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON NONLINEAR MECHANICS, P1001
   Wischik D, 1998, IEEE INFOCOM SER, P873, DOI 10.1109/INFCOM.1998.665112
   ANCLES 2006
NR 30
TC 13
Z9 16
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2007
VL 9
IS 7
BP 1456
EP 1465
DI 10.1109/TMM.2007.906560
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 224LB
UT WOS:000250447400011
DA 2024-07-18
ER

PT J
AU Dumitrescu, S
   Wu, XL
   Wang, Z
AF Dumitrescu, Sorina
   wu, Xiaolin
   Wang, Zhe
TI Efficient algorithms for optimal uneven protection of single and
   multiple scalable code streams against packet erasures
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE joint source-channel coding; Monge property; multimedia streaming;
   rate-distortion optimization; uneven erasure; protection
ID ERROR; COMPRESSION
AB We study algorithmic approaches for rate-fidelity optimal packetization of a single and multiple scalable source code streams with uneven erasure protection (UEP). A new algorithm is developed to obtain the globally optimal solution for scalable source codes of convex rate-fidelity function and for a wide class of erasure channels, including channels for which the probability of losing n packets is monotonically nonincreasing in n, and independent erasure channels with packet erasure rate smaller than 0.5. This is achieved at linear space complexity and near-linear time complexity in the transmission budget, representing significant improvement over the known globally optimal algorithm. When applied to SPIHT compressed images, the results of the proposed algorithm are virtually the same as the global optima. The above success is also extended to UEP packetization of multiple scalable code streams. We improve the existing algorithms in both speed and performance.
C1 McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4K1, Canada.
C3 McMaster University
RP Dumitrescu, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4K1, Canada.
EM sorina@mail.ece.mcmaster.ca; xwu@mail.ece.mcmaster.ca;
   zwang@ece.mcmaster.ca
CR AGGARWAL A, 1987, ALGORITHMICA, V2, P195, DOI 10.1007/BF01840359
   AGGARWAL A, 1994, DISCRETE COMPUT GEOM, V12, P263, DOI 10.1007/BF02574380
   Dumitrescu S, 2004, IEEE T MULTIMEDIA, V6, P230, DOI 10.1109/TMM.2003.822793
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Fowler JE, 2000, P SOC PHOTO-OPT INS, V4115, P294, DOI 10.1117/12.411554
   Gan T, 2005, IEEE T IMAGE PROCESS, V14, P189, DOI 10.1109/TIP.2004.840692
   Ibaraki T., 1988, RESOURCE ALLOCATION
   Luenberger D. G., 1997, Optimization by Vector Space Methods
   Mohr AE, 2000, IEEE IMAGE PROC, P367, DOI 10.1109/ICIP.2000.900971
   Mohr AE, 1999, IEEE DATA COMPR CONF, P92, DOI 10.1109/DCC.1999.755658
   Puri R., 1999, Proceedings of the 33rd Asilomar Confe. Signals, Systems, V1, P342
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Stankovic V, 2004, IEEE T MULTIMEDIA, V6, P240, DOI 10.1109/TMM.2003.822789
   STOCKHAMMER T, 2001, P 11 INT PACK VID WO
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   WILBER R, 1988, J ALGORITHM, V9, P418, DOI 10.1016/0196-6774(88)90032-6
NR 16
TC 8
Z9 8
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2007
VL 9
IS 7
BP 1466
EP 1474
DI 10.1109/TMM.2007.906557
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 224LB
UT WOS:000250447400012
DA 2024-07-18
ER

PT J
AU Solachidis, V
   Pitas, L
AF Solachidis, Vassilios
   Pitas, Loannis
TI Watermarking digital 3-d volumes in the discrete Fourier transform
   domain
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE 3-D volume watermarking; Fourier transform; icosahedron
ID ROBUST IMAGE WATERMARKING; FEATURE POINTS; VIDEO; SCALE; MULTIMEDIA;
   ROTATION
AB In this paper, a robust blind watermarking method for 3-D volumes is presented. A bivalued watermark is embedded in the Fourier transform magnitude of the 3-D volume. The Fourier domain has been selected because of its scaling and rotation invariance. Furthermore, in order to decrease the detection time, a special symmetry of the watermark is exploited. The proposed method is proven to be resistant to 3-D lowpass filtering, noise addition, scaling, translation, cropping and rotation. Experimental results prove the robustness of this method against the above-mentioned attacks.
C1 Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Solachidis, V (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
RI Solachidis, Vassilios/C-3895-2013
OI Solachidis, Vassilios/0000-0002-0761-5396
CR Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   GUAN X, 2000, P INT C MULT MOD MMM, P153
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Kundur D, 1998, OPT EXPRESS, V3, P485, DOI 10.1364/OE.3.000485
   KUTTER M, 1999, P ICIP, V1
   KUTTER M, 1998, P SPIE BOST MA NOV
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   LOUIZIS G, 2002, P IEEE INT C MULT EX
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   PITAS I, 1998, IEEE T CIRCUITS SYST, V8
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Seo JS, 2004, PATTERN RECOGN, V37, P1365, DOI 10.1016/j.patcog.2003.12.013
   Simitopoulos D, 2003, IEEE T CIRC SYST VID, V13, P732, DOI 10.1109/TCSVT.2003.815947
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Stankovic S, 2001, IEEE T IMAGE PROCESS, V10, P650, DOI 10.1109/83.913599
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   TEFAS A, 2001, P 2001 IEEE INT C AC
   VOLOSHYNOVSKIY S, 2001, P ICIP, V3
   Voyatzis G, 1999, P IEEE, V87, P1197, DOI 10.1109/5.771072
   Voyatzis G, 1999, IEEE COMPUT GRAPH, V19, P18, DOI 10.1109/38.736465
   VOYATZIS G, 1998, COMPUT GRAPH, V22
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   WU YH, 2001, P COMP GRAPH INT CGI, P347
   Zhu WW, 1999, IEEE T CIRC SYST VID, V9, P545, DOI 10.1109/76.767121
   1998, IEEE J SEL AREAS COM, V16
   1999, P IEEE, V87
NR 31
TC 6
Z9 6
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855 USA
SN 1520-9210
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD NOV
PY 2007
VL 9
IS 7
BP 1373
EP 1383
DI 10.1109/TMM.2007.906637
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 224LB
UT WOS:000250447400004
DA 2024-07-18
ER

PT J
AU Singh, M
   Basu, A
   Mandal, M
AF Singh, Meghna
   Basu, Anup
   Mandal, Mrinal
TI Event dynamics based temporal registration
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE event dynamics; temporal registration and medical data visualization
ID PHASE-CONTRAST MRI; MOTION; ALIGNMENT
AB Temporal registration is the establishment of correspondence between two (or more) temporal frames of video sequences, or 3-D volume data. In this paper, we propose to use event dynamics, a property that is inherent to an event and is thus common to all acquisitions of the event, for both global and local temporal registration of video sequences in order to generate high temporal resolution video. We compare our approach to a widely used linear interpolation based temporal registration algorithm and demonstrate that in the case of low temporal acquisition rate, a global event dynamics based approach, such as ours, has smaller temporal registration error. We also present a unique application of our work in solving 3-D (2D + time) high temporal resolution medical data visualization problem.
C1 Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
   Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
C3 University of Alberta; University of Alberta
RP Singh, M (corresponding author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
EM meghna@ece.ualberta.ca; anup@cs.ualberta.ca; mandal@ece.ualberta.ca
CR Achenbach S, 2000, CIRCULATION, V102, P2823
   Anagnostara A, 2001, J MAGN RESON IMAGING, V14, P194, DOI 10.1002/jmri.1172
   BRUNO E, 2002, P INT C PATT REC ICR
   Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148
   CHEN W, 2000, P SPIE IS T STOR RET
   Davis J, 2000, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2000.855878
   Dekeyser F, 2000, IEEE IMAGE PROC, P208, DOI 10.1109/ICIP.2000.900931
   DEKEYSER F, 2000, P ICPR
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Divakaran A, 2000, IEEE T CONSUM ELECTR, V46, P637, DOI 10.1109/30.883424
   Dockstader SL, 2001, IEEE IMAGE PROC, P630, DOI 10.1109/ICIP.2001.959124
   Efros Alexei A., 2003, P IEEE INT C COMP VI
   Genc S., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P538, DOI 10.1109/ICIAP.1999.797651
   GIESE MA, 2001, J COMPUTER VISION, V38, P59
   Hegazy T, 2005, 2005 IEEE NETWORKING, SENSING AND CONTROL PROCEEDINGS, P383
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   LAUZON D, 1998, P ICASSP, V5, P2585
   LISTGARTEN SRJ, 2005, ADV NEURAL INFORM PR, V17
   Little J., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P235, DOI 10.1109/ISCV.1995.477007
   Ma YF, 2002, INT C PATT RECOG, P548, DOI 10.1109/ICPR.2002.1048361
   Ning HZ, 2002, P 4 IEEE INT C MULT
   Perperidis D, 2005, MED IMAGE ANAL, V9, P441, DOI 10.1016/j.media.2005.05.004
   PERPERIDIS D, 2004, P MICCAI, P911
   Piroddi R, 2006, IEEE SIGNAL PROC LET, V13, P421, DOI 10.1109/LSP.2006.873143
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Salgado L, 2001, IEEE T CIRC SYST VID, V11, P954, DOI 10.1109/76.937438
   Shechtman E, 2005, IEEE T PATTERN ANAL, V27, P531, DOI 10.1109/TPAMI.2005.85
   Singh M, 2002, IEEE T NUCL SCI, V49, P2284, DOI 10.1109/TNS.2002.803774
   SINGH M, 2006, P INT S VIS COMP ISV
   SINGH M, 2006, P INT C IM PROC ATL
   STILLER C, 1992, P INT S INF THEOR IT, P633
   STREHL A, 2000, P IEEE SW S IM AN IN
   Su C., 2005, P 7 ACM SIGMM INT WO
   Thompson RB, 2004, MAGNET RESON MED, V52, P598, DOI 10.1002/mrm.20187
   Thompson RB, 2002, MAGNET RESON MED, V47, P499, DOI 10.1002/mrm.10079
   TOURAPIS AM, 2001, P ICIP OCT, V3
   Vasconcelos N, 1998, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.1998.698631
   Wang KM, 1997, ANN STAT, V25, P1251
   Wechsler H, 2004, IEEE T PATTERN ANAL, V26, P466, DOI 10.1109/TPAMI.2004.1265862
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yang CS, 2002, SPEECH COMMUN, V38, P201, DOI 10.1016/S0167-6393(01)00053-X
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
NR 42
TC 10
Z9 12
U1 1
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD AUG
PY 2007
VL 9
IS 5
BP 1004
EP 1015
DI 10.1109/TMM.2007.898937
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 193ZX
UT WOS:000248314800010
DA 2024-07-18
ER

PT J
AU Yang, XF
   Tian, Q
   Xue, P
AF Yang, Xian-Feng
   Tian, Qi
   Xue, Ping
TI Efficient short video repeat identification with application to news
   video structure analysis
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE cascade detection; color fingerprint; video indexing; video repeats
   mining; video syntactical segmentation
AB This paper aims at repeat clip mining and knowledge discovery from video data. A unified approach is proposed to detect both unknown video repeats and known video clips of arbitrary length. Two detectors in a cascade structure are employed to achieve fast and accurate detection, and a reinforcement learning approach is adopted to efficiently maximize detection accuracy. In this approach very short video repeats (<1 s) and long ones can be detected by a single process, while overall accuracy remains high. Since video segmentation is essential for repeat detection, performance analysis is also conducted for several segmentation methods. Furthermore we propose a method to analyze video syntactical structure based on short video repeats detection. Experimental results on news videos demonstrate that identifying short video repeats is an effective way for video structure discovery and syntactical segmentation.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Media Technol Lab, Singapore 639798, Singapore.
   Inst Infocomm Res, Singapore 119613, Singapore.
C3 Nanyang Technological University; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Yang, XF (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Media Technol Lab, Singapore 639798, Singapore.
EM yangxianfeng@tsinghua.org.cn; tian@i2r.a-star.edu.sg; epxue@ntu.edu.sg
RI Xue, Ping/A-5155-2011
CR AGNIHOTRI L, 2003, P IEEE INT C COMP VI, P685
   Chaisorn L, 2003, WORLD WIDE WEB, V6, P187, DOI 10.1023/A:1023622605600
   CHEUNG SC, 2005, P IEEE INT C IM PROC, P181
   Cheung SCS, 2000, PROC SPIE, V3964, P34
   COOPER M, 2001, P IEEE INT C IM PROC, P452
   DUYGULU P, 2004, P IEEE ICME 04 TAIP, P27
   FOOTE J, 1999, P ACM MULT ORL FL, V99
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   HAMPAPUR A, 2001, P IEEE INT C MULT EX, P737
   Herley C, 2006, IEEE T MULTIMEDIA, V8, P115, DOI 10.1109/TMM.2005.861286
   HOASHI K, P TRECVID 04
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Kashino K, 2003, IEEE T MULTIMEDIA, V5, P348, DOI 10.1109/TMM.2003.813281
   KRAAIJ W, 2004, P TRECVID 04
   Lienhart R, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P509, DOI 10.1109/MMCS.1997.609763
   Mohan R, 1998, INT CONF ACOUST SPEE, P3697, DOI 10.1109/ICASSP.1998.679686
   OOSTVEEN JC, 2001, P SPIE, V24
   PAN H, 2002, P IEEE INT C AC SPEE
   Pua KM, 2004, COMPUT VIS IMAGE UND, V93, P310, DOI 10.1016/j.cviu.2003.10.005
   Rui Y, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P237, DOI 10.1109/MMCS.1998.693648
   Sánchez JM, 2002, MULTIMED TOOLS APPL, V18, P233, DOI 10.1023/A:1019996817159
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Yamagishi F, 2004, LECT NOTES COMPUT SC, V3332, P205
   YANG X, 2003, P IEEE PAC RIM C MUL, P1566
   YANG X, 2004, P ACM MULT 04
   YEUNG MM, 1996, P ICPR
   YUAN J, 2004, P ACM MULT MULT INF
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
NR 29
TC 11
Z9 15
U1 2
U2 45
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2007
VL 9
IS 3
BP 600
EP 609
DI 10.1109/TMM.2006.889352
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 148PW
UT WOS:000245088100014
DA 2024-07-18
ER

PT J
AU Snoek, CGM
   Worring, M
   Koelma, DC
   Smeulders, AWM
AF Snoek, Cees G. M.
   Worring, Marcel
   Koelma, Dennis C.
   Smeulders, Arnold W. M.
TI A learned lexicon-driven paradigm for interactive video retrieval
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE benchmarking; concept learning; content analysis and indexing;
   interactive systems; multimedia information systems; video retrieval
ID CLASSIFICATION; COLOR
AB Effective video retrieval is the result of an interplay between interactive query selection, advanced visualization of results, and a goal-oriented human user. Traditional interactive video retrieval approaches emphasize paradigms, such as query-by-keyword and query-by-example, to aid the user in the search for relevant footage. However, recent results in automatic indexing indicate that query-by-concept is becoming a viable resource for interactive retrieval also. We propose in this paper a new video retrieval paradigm. The core of the paradigm is formed by first detecting a large lexicon of semantic concepts. From there, we combine query-by-concept, query-by-example, query-by-keyword, and user interaction into the MediaMill semantic video search engine. To measure the impact of increasing lexicon size on interactive video retrieval performance, we performed two experiments against the 2004 and 2005 NIST TRECVID benchmarks, using lexicons containing 32 and 101 concepts, respectively. The results suggest that from all factors that play a role in interactive retrieval, a large lexicon of semantic concepts matters most. Indeed, by exploiting large lexicons, many video search questions are solvable without using query-by-keyword and query-by-example. In addition, we show that the lexicon-driven search engine outperforms all state-of-the-art video retrieval systems in both TRECVID 2004 and 2005.
C1 Univ Amsterdam, Intelligent Syst Lab Amsterdam, Inst Informat, NL-1098 SJ Amsterdam, Netherlands.
C3 University of Amsterdam
RP Snoek, CGM (corresponding author), Univ Amsterdam, Intelligent Syst Lab Amsterdam, Inst Informat, NL-1098 SJ Amsterdam, Netherlands.
EM cgmsnoek@science.uva.nl
RI Worring, Marcel/JRW-7059-2023
OI Worring, Marcel/0000-0003-4097-4136; Snoek, Cees/0000-0001-9092-1556
CR ADAMS WH, 2003, EURASIP JASP, V2, P170
   Adcock J, 2005, LECT NOTES COMPUT SC, V3568, P205
   AMIR A, 2003, P TRECVID WORKSH GAI
   [Anonymous], IEEE COMPUT
   [Anonymous], 1983, INTRO MODERN INFORM
   BENITEZ A, 2000, P SPIE C INT MULT MA, V4210
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Christel MG, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1032
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Fan JP, 2004, IEEE T IMAGE PROCESS, V13, P974, DOI 10.1109/TIP.2004.827232
   Fan JP, 2004, IEEE T MULTIMEDIA, V6, P70, DOI 10.1109/TMM.2003.819583
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Gauvain JL, 2002, SPEECH COMMUN, V37, P89, DOI 10.1016/S0167-6393(01)00061-9
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Gevers T., 2004, EMERGING TOPICS COMP
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Hauptmann A, 2005, LECT NOTES COMPUT SC, V3568, P215
   HAUPTMANN A, 2005, P TRECVID WORKSH
   HAUPTMANN A, 2003, P TRECVID WORKSH GAI
   Hauptmann AG, 2004, LECT NOTES COMPUT SC, V3115, P674
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   KATO T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P530, DOI 10.1109/ICPR.1992.201616
   KNIGHT K, 2005, P IEEE INT C AC SPEE, V5, P965
   Lee JH, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P267, DOI 10.1145/258525.258587
   Lee JS, 2002, MAR BIOTECHNOL, V4, P1, DOI 10.1007/s10126-001-0077-3
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   NAPHADE M, 2005, RC23612 J WATS RES C
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   PETERSOHN C., 2004, P TRECVID WORKSH
   Platt JC, 2000, ADV NEUR IN, P61
   QUENOT G, 2002, P 11 TEXT RETR C, V500
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SMEATON A, 2005, LNCS, V3568, P19
   SMEATON AF, 2004, ACM MULTIMEDIA
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith E, 1997, ENVIRON TOXICOL PHAR, V4, P3, DOI 10.1016/S1382-6689(97)10035-7
   SNOEK C, 2005, P TRECVID WORKSH GAI
   SNOEK C, 2004, P TRECVID WORKSH GAI
   Snoek CGM, 2006, ACM T MULTIM COMPUT, V2, P91, DOI 10.1145/1142020.1142021
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   SZUMMER M, 1998, IEEE ITN WORKSH CONT
   Taskiran C, 2004, IEEE T MULTIMEDIA, V6, P103, DOI 10.1109/TMM.2003.819783
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   VAPNIK V, 2000, NATURE STAT LEARNIN
   WACHTLAR H, 1999, IEEE COMPUT, V32, P66
   2006, GOOGLE VIDEO SEARCH
   2006, BLINKX VIDEO SEARCH
NR 52
TC 47
Z9 49
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD FEB
PY 2007
VL 9
IS 2
BP 280
EP 292
DI 10.1109/TMM.2006.886275
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 135CO
UT WOS:000244131900008
DA 2024-07-18
ER

PT J
AU Yu, CS
   Tai, SC
AF Yu, Chong-Shou
   Tai, Shen-Chuan
TI Adaptive double-layered initial search pattern for fast motion
   estimation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE divide and conquer strategy; motion estimation; video coding
ID HEXAGONAL SEARCH; ALGORITHM
AB Multimedia communication relies on data compression technology to reduce the data bits of transmission. Motion compensation is the key function in exploiting temporal redundancy for compression in most video coding standards. For example, fixed search pattern motion estimation algorithms such as hexagonal search (HEXBS) usually spend extra search steps to confirm near-zero motion vectors. Divide and conquer methods such as the efficient three-step search (EMS) are not optimized for the probability model of motion vectors. This paper proposes a pair of complementary double-layered (inner layer and outer layer) initial search patterns to reduce computational complexity. The inner-layer search is applied first and tests for small motion. Afterwards, the outer layer search serves as a guard line to catch large motion. It is used only when the inner search layer fails to find a good solution. Experimental results of motion estimation on various QCIF/CIF video sequences show that the proposed algorithm achieves image quality similar to diamond search but with the search point cost as low as cross-diamond-hexagonal search.
C1 Natl Cheng Kung Univ, Dept Elect Engn, Data Compress & Multimedia Commun Lab, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Yu, CS (corresponding author), Natl Cheng Kung Univ, Dept Elect Engn, Data Compress & Multimedia Commun Lab, Tainan 701, Taiwan.
EM ytz@lily.ee.ncku.edu.tw; sctai@mail.ncku.edu.tw
CR Banh XQ, 2004, IEEE T CONSUM ELECTR, V50, P766, DOI 10.1109/TCE.2004.1309460
   *CCITT SGXV, 1989, DESCR REF MOD 8 RM8
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   *ITU T ISO IEC JTC, 1994, GEN COD MOV PICT A 2
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Lu JH, 1997, IEEE T CIRC SYST VID, V7, P429, DOI 10.1109/76.564122
   Puri A., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1063
   TAI SC, 2005, P IPSI 2005 AM IT FE
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu C, 2004, IEEE T CIRC SYST VID, V14, P1210, DOI 10.1109/TCSVT.2004.833166
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   2000, JTC1SC29WG11
   1993, JCC1SC29WG11
NR 15
TC 11
Z9 12
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2006
VL 8
IS 6
BP 1109
EP 1116
DI 10.1109/TMM.2006.884635
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 109MG
UT WOS:000242311700001
DA 2024-07-18
ER

PT J
AU Liu, JC
   Xu, JL
   Chu, XW
AF Liu, Jiangchuan
   Xu, Jianliang
   Chu, Xiaowen
TI Fine-grained scalable video caching for heterogeneous clients
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE fine-grained scalable video; proxy caching; resource allocation;
   streaming media
ID INTERNET
AB Much research has focused on caching adaptive videos to improve system performance for heterogeneous clients with diverse access bandwidths. However, existing rate-adaptive caching systems, which are based on layered coding or transcoding, often suffer from a coarse adaptation and/or a high computation overhead. In this paper, we propose an innovative rate-adaptive caching framework that enables low-cost and fine-grained adaptation by using MPEG-4 fine-grained scalable videos. The proposed framework is both network-aware and media-adaptive; i.e., the clients can be of heterogeneous streaming rates, and the backbone bandwidth consumption can be adaptively controlled. We develop efficient cache management schemes to determine the best contents to cache and the optimal streaming rate to each client under the framework. We demonstrate via simulations that, compared to nonadaptive caching, the proposed framework with the optimal cache management not only achieves a significant reduction in the data transmission cost, but also enables a flexible utility assignment for the heterogeneous clients. Our results also show that the framework maintains a low computational overhead, which implies that it is practically deployable.
C1 Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   Hong Kong Baptist Univ, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Simon Fraser University; Hong Kong Baptist University
RP Liu, JC (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
EM jcliu@cs.sfu.ca; xujl@comp.hkbu.edu.hk; chxw@comp.hkbu.edu.hk
RI Chu, Xiaowen/AAF-2857-2020; Xu, Jianliang/A-5767-2010; Chu,
   Xiaowen/ISU-3161-2023
OI Chu, Xiaowen/0000-0001-9745-4372; Xu, Jianliang/0000-0001-9404-5848
CR ALMEIDA JM, 2001, P NOSSDAV 01 PORT JE
   CHEN S, 2004, P IEEE INFOCOM 04 HO
   DECUETOS P, 2003, RR03078
   DECUETOS P, 2001, P PACK VID WORKSH KY
   EAGER DL, 2000, PERFORM EVAL, V42
   GRUBER S, 2000, P WORLD WID WEB C MA
   HARTANTO F, 2002, P IEEE INT C MULT EX
   JIN S, 2002, P IEEE ICDCS 02 VIEN
   Kangasharju J, 2002, IEEE T COMPUT, V51, P622, DOI 10.1109/TC.2002.1009148
   KIM T, 2003, P IEEE INFOCOM 03 SA
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   LIU J, 2004, WORLD WIDE WEB, V7
   Liu JC, 2005, IEEE T CIRC SYST VID, V15, P402, DOI 10.1109/TCSVT.2004.825532
   Liu JC, 2004, IEEE COMMUN MAG, V42, P88, DOI 10.1109/MCOM.2004.1321397
   Liu JC, 2003, IEEE MULTIMEDIA, V10, P22, DOI 10.1109/MMUL.2003.1167919
   RADHA H, 2002, P PACK VID WORKSH PI
   REJAIE R, 2000, P IEEE INFOCOM 00 TE
   SCHOJER P, 2003, P WORLD WID WEB C
   SEN S, 1999, P IEEE INFOCOM 99 NE
   SHEN B, 2003, STREAMING MEDIA CACH
   TANG X, 2002, P 31 INT C PAR PROC
   WANG B, 2002, P IEEE INFOCOM 02 NE
   WANG Y, 1998, P IEEE INFOCOM 98 SA
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   WU F, 2001, IEEE T CIRCUITS SYST, V11, P306
   XU J, 2004, IEEE COMPUT SCI ENG, V6, P54
   Yeadon N, 1996, IEEE J SEL AREA COMM, V14, P1245, DOI 10.1109/49.536366
   Yu F, 2003, IEEE T CIRC SYST VID, V13, P257, DOI 10.1109/TCSVT.2003.809829
NR 28
TC 4
Z9 5
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2006
VL 8
IS 5
BP 1011
EP 1020
DI 10.1109/TMM.2006.879859
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 091TY
UT WOS:000241052400013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qu, Q
   Pei, Y
   Modestino, JW
AF Qu, Qi
   Pei, Yong
   Modestino, James W.
TI An adaptive motion-based unequal error protection approach for real-time
   video transport over wireless IP networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE FEC; H.264; intra-updating; motion-based adaptive; motion level; packet
   loss; video transmission
ID TRANSMISSION
AB In this work, we consider the delivery of digital video over future 3G wireless IP networks and we propose a low-complexity adaptive motion-based unequal error protection (UEP) video coding and transmission system which efficiently combines three existing error-resilience techniques by exploiting knowledge of the source material as well as the channel operating conditions. Given this information, the proposed system can adaptively adjust the operating parameters of the video source encoder and the forward error correction (FEC) channel encoder to maximize the delivered video quality based upon both application-layer video motion estimates and link-layer channel estimates. We demonstrate the efficacy of this approach using the ITU-T H.264 video source coder. The results indicate that a significant performance improvement can be achieved with enhanced resilience to inaccurate channel feedback information and with substantially reduced computational complexity compared to competing approaches.
C1 Univ Calif San Diego, Elect & Comp Engn Dept, La Jolla, CA 92093 USA.
   Univ Miami, Elect & Comp Engn Dept, Coral Gables, FL 33124 USA.
   Wright State Univ, Comp Sci & Engn Dept, Dayton, OH 45435 USA.
   Univ Miami, Elect & Comp Engn Dept, Coral Gables, FL 33124 USA.
C3 University of California System; University of California San Diego;
   University of Miami; University System of Ohio; Wright State University
   Dayton; University of Miami
RP Qu, Q (corresponding author), Univ Calif San Diego, Elect & Comp Engn Dept, La Jolla, CA 92093 USA.
EM qqu@ucsd.edu; ypei@cs.wright.edu; jmodestino@miami.edu
CR Bystrom M, 1999, IEEE T CIRC SYST VID, V9, P868, DOI 10.1109/76.785725
   Casner S., 1999, COMPRESSING IP UDP R
   CHAKARESKI J, 2004, P IEEE ICIP OCT, P2055
   Frossard P, 2001, IEEE T CIRC SYST VID, V11, P989, DOI 10.1109/76.946516
   GNAVI S, 2003, P IEEE ICME JUL BALT, V2, P517
   KUMWILAISAK W, 2001, PICT COD S, P219
   Liu Y., 2003, P IEEE ICASSP 2003 H, P764
   MA S, 2002, ISO IEC MPEG ITUT VC
   Ott J., 2002, Extended RTP Profile for RTCPBased Feedback (RTP-AVPF) Internet Draft
   Parthasarathy V, 1999, IEEE T IMAGE PROCESS, V8, P361, DOI 10.1109/83.748891
   Puri A, 1991, IEEE T CIRC SYST VID, V1, P351, DOI 10.1109/76.120774
   Qu Q, 2003, IEEE VTS VEH TECHNOL, P3395, DOI 10.1109/VETECF.2003.1286324
   QU Q, P IEEE MIL COMM C 20
   Rosenberg J., 1999, RFC 2733 RTP PAYLOAD
   SETTON E, 2004, P ICME 2004 TAIP TAI
   SHAN Y, 2004, P IEEE ICIP 04 SING, P3133
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   VARSA V, 2001, VCEG N80 JOINT VID T
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   WANG YK, 2003, P PACK VID WORKSH 20
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Xie B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1283, DOI 10.1109/ICC.2004.1312719
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 24
TC 34
Z9 40
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2006
VL 8
IS 5
BP 1033
EP 1044
DI 10.1109/TMM.2006.879840
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 091TY
UT WOS:000241052400015
DA 2024-07-18
ER

PT J
AU Winkler, S
   Faller, C
AF Winkler, Stefan
   Faller, Christof
TI Perceived audiovisual quality of low-bitrate multimedia content
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE audiovisual quality assessment; multimedia perception; subjective
   experiments
ID SUBJECTIVE VIDEO QUALITY
AB This paper studies the quality of multimedia content at very low bitrates. We carried out subjective experiments for assessing audiovisual, audio-only, and video-only quality. We selected content and encoding parameters that are typical of mobile applications. Our focus were the MPEG-4 AVC (a.k.a. H.264) and AAC coding standards. Based on these data, we first analyze the influence of video and audio coding parameters on quality. We investigate the optimal trade-off between bits allocated to audio and to video under global bitrate constraints. Finally, we explore models for the interactions between audio and video in terms of perceived audiovisual quality.
C1 Genista Corp, Singapore 068641, Singapore.
   Natl Univ Singapore, Singapore 117548, Singapore.
   Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
C3 National University of Singapore; Swiss Federal Institutes of Technology
   Domain; Ecole Polytechnique Federale de Lausanne
RP Winkler, S (corresponding author), Genista Corp, Singapore 068641, Singapore.
EM stefan.winkler@genista.com; christof.faller@epfl.ch
RI Winkler, Stefan/ACL-6097-2022; Winkler, Stefan/A-9073-2009
OI Winkler, Stefan/0000-0003-4305-8408; 
CR [Anonymous], 2001, P862 ITUT
   [Anonymous], J144 ITUT
   [Anonymous], 2003, BS15341 ITUR
   [Anonymous], 2002, BT50011 ITUR
   [Anonymous], BT1683 ITUR
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   [Anonymous], 2004, 144962 ISOIEC
   Beerends JG, 1999, J AUDIO ENG SOC, V47, P355
   BENNETT J, 2003, P INT BROADC CONV AM, P464
   BUDDENDICK H, 2003, P WORLD WIR C SAN FR
   DIETZ M, 2002, P AES C MUN GERM MAY
   Georganas ND, 1996, IEEE J SEL AREA COMM, V14, P1, DOI 10.1109/JSAC.1996.481690
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   ISO, 2004, 1449610 ISOIEC
   ISO/IEC, 2004, 144963 ISOIEC
   *ITUR, 2003, BS12841 ITUR
   *ITUR, 2001, BS13871 ITUR
   *ITUT, 1999, P910 ITUT
   *ITUT, 1998, H263 ITUT
   *ITUT, 1998, P911 ITUT
   *ITUT, 2003, H264 ITUT
   Joly A, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P438, DOI 10.1109/ISSPA.2001.950174
   Jones C, 1998, INT WORKSH QUAL SERV, P196, DOI 10.1109/IWQOS.1998.675239
   Kohlrausch A, 1999, P SOC PHOTO-OPT INS, V3644, P34, DOI 10.1117/12.348440
   KOZAMERENIK F, 2005, EBU TECH REV, V301
   PASTRANAVIDAL R, 2003, P CORESA WORKSH LYON
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Soulodre GA, 1998, J AUDIO ENG SOC, V46, P164
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang DM, 2003, P SOC PHOTO-OPT INS, V5150, P198, DOI 10.1117/12.501266
   Winkler S, 2005, PROC SPIE, V5666, P139, DOI 10.1117/12.596852
   WINKLER S, 2005, P WORKSH VID PROC QU
NR 32
TC 48
Z9 51
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2006
VL 8
IS 5
BP 973
EP 980
DI 10.1109/TMM.2006.879871
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 091TY
UT WOS:000241052400009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, JM
   Xiao, GQ
AF Jiang, Jianmin
   Xiao, Guoqiang
TI Adding lossless video compression to MPEGs
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE context tree; lossless video compression; statistics modeling
ID IMAGE; ALGORITHM
AB In this correspondence, we propose to add a lossless compression functionality into existing MPEGs by developing a new context tree to drive arithmetic coding for lossless video compression. In comparison with the existing work on context tree design, the proposed algorithm features in 1) prefix sequence matching to locate the statistics model at the internal node nearest to the stopping point, where successful match of context sequence is broken; 2) traversing the context tree along a fixed order of context structure with a maximum number of four motion compensated errors; and 3) context thresholding to quantize the higher end of error values into a single statistics cluster. As a result, the proposed algorithm is able to achieve competitive processing speed, low computational complexity and high compression performances, which bridges the gap between universal statistics modeling and practical compression techniques. Extensive experiments show that the proposed algorithm outperforms JPEG-LS by up to 24% and CALIC by up to 22%, yet the processing time ranges from less than 2 seconds per frame to 6 seconds per frame on a typical PC computing platform.
C1 SW China Univ, Fac Informat & Comp, Chongqing, Peoples R China.
   Univ Bradford, Sch Informat, Bradford BD7 1DP, W Yorkshire, England.
   SW China Univ, Fac Informat & Comp, Chongqing, Peoples R China.
C3 Southwest University - China; University of Bradford; Southwest
   University - China
RP Jiang, JM (corresponding author), SW China Univ, Fac Informat & Comp, Chongqing, Peoples R China.
EM j.jiang1@Bradford.ac.uk; gqxiao@swnu.edu.cn
CR Brunello D, 2003, IEEE T IMAGE PROCESS, V12, P132, DOI 10.1109/TIP.2002.807354
   Clunie DA, 2000, PROC SPIE, V3980, P74, DOI 10.1117/12.386389
   Jiang J, 1995, IEE P-COMPUT DIG T, V142, P419, DOI 10.1049/ip-cdt:19952275
   Jiang JM, 2000, IEEE T IMAGE PROCESS, V9, P543, DOI 10.1109/83.841932
   Martins B, 1998, IEEE DATA COMPR CONF, P560, DOI 10.1109/DCC.1998.672302
   Memon ND, 1996, IEEE T COMMUN, V44, P1340, DOI 10.1109/26.539775
   MEYER B, 2001, P DCC01          MAR
   NOHRE R, 1993, THESIS TU LINKOPING
   RISKIN EA, 1991, IEEE T INFORM THEORY, V37, P400, DOI 10.1109/18.75264
   RISSANEN J, 1983, IEEE T INFORM THEORY, V29, P656, DOI 10.1109/TIT.1983.1056741
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   Taskiran C, 2004, IEEE T MULTIMEDIA, V6, P103, DOI 10.1109/TMM.2003.819783
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weinberger MJ, 1996, IEEE T IMAGE PROCESS, V5, P575, DOI 10.1109/83.491334
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   XIA J, P VIE03 IEE INT C VI, P234
NR 16
TC 0
Z9 0
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN
PY 2006
VL 8
IS 3
BP 622
EP 625
DI 10.1109/TMM.2006.870721
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 046OX
UT WOS:000237822000018
DA 2024-07-18
ER

PT J
AU Chen, SQ
   Shen, B
   Yan, Y
   Basu, S
   Zhang, XD
AF Chen, SQ
   Shen, B
   Yan, Y
   Basu, S
   Zhang, XD
TI Fast proxy delivery of multiple streaming sessions in shared running
   buffers
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE patching; proxy caching; shared running buffer; streaming media;
   video-on-demand (VOD)
AB With the falling price of memory, an increasing number of multimedia servers and proxies are now equipped with a large memory space. Caching media objects in the memory of a proxy helps to reduce the network traffic, the disk 110 bandwidth requirement, and the data delivery latency. The running buffer approach and its alternatives are representative techniques to caching streaming data in the memory. There are two limits in the existing techniques. First, although multiple running buffers for the same media object co-exist in a given processing period, data sharing among multiple buffers is not considered. Second, user access patterns are not insightfully considered in the buffer management. In this paper, we propose two techniques based on shared running buffers in the proxy to address these limits. Considering user access patterns and characteristics of the requested media objects, our techniques adaptively allocate memory buffers to fully utilize the currently buffered data of streaming sessions, with the aim to reduce both the server load and the network traffic. Experimentally comparing with several existing techniques, we show that the proposed techniques achieve significant performance improvement by effectively using the shared running buffers.
C1 George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
   Hewlett Packard Labs, Mobile & Media Syst Lab, Palo Alto, CA 94304 USA.
   Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 George Mason University; Hewlett-Packard; University System of Ohio;
   Ohio State University
RP George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
EM sqchen@cs.gniu.edu; boshen@hpl.hp.com; basus@hpl.hp.com;
   zhang@cse.ohiostate.edu
CR AGGARWAL CC, 1996, P INT C MULT COMP SY
   ANDERSON D, 1992, ACM T COMPUT SYST, V10, P4
   [Anonymous], P IEEE INFOCOM
   Bommaiah E., 2000, P IEEE REAL TIM TECH
   BOWMAN C, 1994, CUCS73294
   Chae YS, 2002, IEEE J SEL AREA COMM, V20, P1328, DOI 10.1109/JSAC.2002.802062
   Chen S., 2004, P IEEE INFOCOM
   CHEN S, 2003, HPL200347
   CHEN S, 2003, P ACM WORKSH NETW OP
   Chen S, 2004, P 24 INT C DISTR COM
   Cherkasova L., 2002, P ACM NOSSDAV
   DAN A, 1993, 19347 IBM
   DAN A, 1994, P ACM MULTIMEDIA
   DAN A, 1996, P MULT COMP NETW
   FONSECA NLS, 2002, IEEE T MULTIMEDIA, V4, P114
   HUA KA, 1998, P ACM MULTIMEDIA
   Lee SJ, 2002, COMPUT COMMUN, V25, P424, DOI 10.1016/S0140-3664(01)00414-5
   SEN S, 1999, P ACM WORKSH NETW OP
   TOBAGI F, 1993, P ACM MULTIMEDIA
   WU K, 2001, P WWW AUTHOR PLS SUP
   [No title captured]
   [No title captured]
NR 22
TC 0
Z9 1
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2005
VL 7
IS 6
BP 1157
EP 1169
DI 10.1109/TMM.2005.858417
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 986SY
UT WOS:000233471200017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rasheed, Z
   Shah, M
AF Rasheed, Z
   Shah, M
TI Detection and representation of scenes in videos
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE graph partitioning; key-frames; normalized cuts; scene; shot; video
   segmentation
ID SEGMENTATION
AB This paper presents a method to perform a high-level segmentation of videos into scenes. A scene can be defined as a subdivision of a play in which either the setting is fixed, or when it presents continuous action in one place. We exploit this fact and propose a novel approach for clustering shots into scenes by transforming this task into a graph partitioning problem. This is achieved by constructing a weighted undirected graph called a shot similarity graph (SSG), where each node represents a shot and the edges between the shots are weighted by their similarity based on color and motion information. The SSG is then split into subgraphs by applying the normalized cuts for graph partitioning. The partitions so obtained represent individual scenes in the video. When clustering the shots, we consider the global similarities of shots rather than the individual shot pairs. We also propose a method to describe the content of each scene by selecting one representative image from the video as a scene key-frame. Recently, DVDs have become available with a chapter selection option where each chapter is represented by one image. Our algorithm automates this objective which is useful for applications such as video-on-demand, digital libraries, and the Internet. Experiments are presented with promising results on several Hollywood movies and one sitcom.
C1 ObjectVideo Inc, Reston, VA 20191 USA.
   Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP ObjectVideo Inc, Reston, VA 20191 USA.
EM zrasheed@objectvideo.com; shah@cs.ucf.edu
RI Sahoo, Sarat Kumar/J-8765-2014
OI Sahoo, Sarat Kumar/0000-0001-5734-6844; Shah,
   Mubarak/0000-0001-6172-5572
CR Aner A, 2002, LECT NOTES COMPUT SC, V2353, P388
   [Anonymous], 1976, Grammar of the film language
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   GRESELE PO, 1997, P INT C VIS INF SYST
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   HAERING N, 1999, THESIS U CENTRAL FLO
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Javed O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P532
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Lyman P., 2000, MUCH INFORM
   MENG J, 1995, SPIE, P14
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Odobez JM, 2003, LECT NOTES COMPUT SC, V2728, P310
   Rui Y, 1999, MULTIMEDIA SYST, V7, P359, DOI 10.1007/s005300050138
   Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Soundararajan P., 2001, WORKSH PERC ORG COMP
   SWANBERG D, 1993, SPIE, V1908, P13
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   *WEBS, WEBST DICT
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   ZHOU J, 2002, P INT WORKSH MULT DA, P299
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 26
TC 181
Z9 200
U1 0
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2005
VL 7
IS 6
BP 1097
EP 1105
DI 10.1109/TMM.2005.858392
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 986SY
UT WOS:000233471200010
DA 2024-07-18
ER

PT J
AU Tan, R
   Guan, SU
AF Tan, R
   Guan, SU
TI A dynamic Petri Net model for iterative and interactive distributed
   multimedia presentation
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE dynamic events; interactive multimedia; iterative multimedia playback;
   multimedia synchronization; Petri net
AB Object Composition Petri Nets, Priority Petri Nets, Dynamic OCPN, and Enhanced P-Nets have extended the original Petri Net to achieve the modeling of media synchronization and asynchronous user interactions during multimedia playback. The dynamic Petri Net (DPN) has been conceptualized to tackle existing problems in these two areas of modeling distributed multimedia systems. DPN features dynamic modeling elements which allows iteration and hence is able to reduce graph sizes of synchronous playback models while allowing greater details to be shown. DPN also introduces asynchronous event handling techniques that are powerful and effective. DPN was used in the design and modeling of a multimedia orchestration tool which is a typical representation of an application that works in a distributed multimedia system.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
C3 National University of Singapore
RP 1 Yishun Ave 7, Singapore 768923, Singapore.
EM roy-wk_tan@agilent.com; eleguans@nus.edu.sg
CR BRUNO G, 1995, MODEL BASED SOFTWARE, P63
   CHUNG SM, 1996, MULTIMEDIA INFORMATI, P303
   DIAZ M, 1993, P 1 INT C MULT MOD, P257
   FURTEK F, 1975, NEW APPROACH PETRI N
   Guan SU, 1998, IEEE T COMPUT, V47, P477, DOI 10.1109/12.675716
   GUAN SU, 1999, EPNET SYNCHRONIZATIO
   Huang CM, 1998, EUROMICRO CONF PROC, P506, DOI 10.1109/EURMIC.1998.708064
   JENSEN K, 1997, COLORED PETRINETS BA, V1, P2
   LITTLE TCD, 1990, IEEE J SEL AREA COMM, V4, P413
   LOUGHER P, 1993, COMPUT J, V36, P32, DOI 10.1093/comjnl/36.1.32
   MARSAN MA, 1996, MODELLING GEN STOCHA, P49
   Peterson J.L., 1981, Petri Net Theory and the Modeling of Systems
   PRABHAKARAN B, 1993, ACM MULT P, P157
   PRABHAT K, 1996, MULTIMEDIA SYSTEMS D, P421
   Qazi N. U., 1993, Proceedings ACM Multimedia 93, P147, DOI 10.1145/166266.166283
   TANENBAUM AF, 1996, COMPUTER NETWORK, P219
   Thimm H, 1996, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS, PROCEEDINGS, P152, DOI 10.1109/MMDBMS.1996.541866
   TSAI JJP, 1996, DISTRIBUTED REAL TIM, P247
   WOO M, 1994, IEEE NETWORK, V8, P52, DOI 10.1109/65.260079
   Yoon K, 1998, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS- PROCEEDINGS, P136, DOI 10.1109/MMDBMS.1998.709776
NR 20
TC 10
Z9 11
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD OCT
PY 2005
VL 7
IS 5
BP 869
EP 879
DI 10.1109/TMM.2005.854377
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 967IM
UT WOS:000232084900008
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Ko, BS
   Nishimura, R
   Suzuki, Y
AF Ko, BS
   Nishimura, R
   Suzuki, Y
TI Time-spread echo method for digital audio watermarkiing
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE audio watermarking; time-spread echo; PN sequence; talyor series;
   homomorphic process
AB Conventional watermarking techniques based on echo hiding provide many benefits, but also have several disadvantages, for example, a lenient decoding process, weakness against multiple encoding attacks, etc. In this paper, to improve the weak points of conventional echo hiding, we propose a time-spread echo as an alternative to the single echo in conventional echo hiding. Spreading an echo in the time domain is achieved by using pseudonoise (PN) sequences. By spreading the echo, the amplitude of each echo can be reduced, i.e., the energy of each echo becomes small, so that the distortion induced by watermarking is imperceptible to humans while the decoding performance of the embedded watermarks is better maintained as compared with the case of conventional echo hiding, as shown by computer simulations, in which several parameters, such as the amplitude and length of PN sequences and analysis window length, were varied. Robustness against typical signal processing was also evaluated in these Simulations and showed fair performance. Results of a listening test using some pieces of music showed good imperceptibility.
C1 Tohoku Univ, GSIS, RIEC, Sendai, Miyagi 9808577, Japan.
C3 Tohoku University
RP Tohoku Univ, GSIS, RIEC, Sendai, Miyagi 9808577, Japan.
EM kobs@ais.riec.tohoku.ac.jp; ryou@ais.riec.tohoku.ac.jp;
   yoh@ais.riec.tohoku.ac.jp
CR [Anonymous], 1988, SIGNAL DETECTION THE
   Bender W., 1996, IBM SYST J, V35, DOI DOI 10.1147/SJ.353.0313
   Boff KR., 1986, HDB PERCEPTION HUMAN, V1
   Boney L., 1996, P EUR SIGN PROC C TR
   Cox I. J., 9510 NEC RES I
   Cvejic N, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P227, DOI 10.1109/ASPAA.2001.969584
   CZERWINSKI S, 1999, 219 UCB IS
   FURUI S, 1992, DIGITAL SPEECH PROCE
   GARDNER WG, 1992, THESIS MIT CAMBRIDGE
   Gruhl D, 1996, PROCEEDING 1 INFOROM, P295
   Heeger D., 1997, SIGNAL DETECTION THE
   KATZENBEISSER S, 2000, INFORMATION HIDING T
   Ko B. -S., 1999, J ACOUST SOC KOREA, V18, P31
   KO BS, 2002, P ICASSP 2002 MAY
   KO BS, 2002, P 2002 SPRING M AC S, P535
   KUBIN G, 1995, P IEEE WORKSH NONL S, P141
   Lee SK, 2000, IEEE T CONSUM ELECTR, V46, P744, DOI 10.1109/30.883441
   Moore B. C. J., 1997, INTRO PSYCHOL HEARIN
   Nishimura R., 2001, P 17 INT C AC ROM IT
   Oh H. O., 2001, P ICASSP 2001 MAY
   Oppenheim A. V., 1989, Discrete -Time Signal Processing
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Proakis JG., 2001, Digital Communications
   Sklar B., 1988, Digital Communications Fundamentals and Applications, DOI DOI 10.1121/1.3598464
   SPIEGEL MR, 1990, SER SCHAUMS OUTLINE
   SUZUKI Y, 1995, J ACOUST SOC AM, V97, P1119, DOI 10.1121/1.412224
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Wickens T.D, 2010, Elementary signal detection theory
   Xu CS, 1999, J AUDIO ENG SOC, V47, P805
NR 29
TC 112
Z9 123
U1 0
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD APR
PY 2005
VL 7
IS 2
BP 212
EP 221
DI 10.1109/TMM.2005.843366
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 909OO
UT WOS:000227869400003
DA 2024-07-18
ER

PT J
AU Chang, CY
   Chen, MS
   Huang, PH
AF Chang, CY
   Chen, MS
   Huang, PH
TI An H.323 gatekeeper prototype: Design, implementation, and performance
   analysis
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE communication system signaling; ITU; protocol; teleconferencing; traffic
   control (communication)
ID INTERNET TELEPHONY; IP TELEPHONY; ARCHITECTURE; SERVICE
AB In recent years, Internet telephony or voice-over IP is attracting an increasing amount of attention for the reason that it has the potential to significantly reduce the cost of long-distance voice communication. To provide the interoperability between different manufacturers and vendors, ITU-T is actively drawing up the standard for the Internet telephony as ITU-T Recommendation H.323. While H.323 is continuously revised, there are, however, still many important issues needed to be further discussed. In particular, the bandwidth management, address translation, and intelligent call signaling/routing, which are the major functions of an H.323 gatekeeper, have not yet been fully addressed. In view of this, we develop in this paper an H.323 gatekeeper prototype which fully complies with the H.323 recommendation, and explicitly illustrate the usefulness of this prototype by devising two improved call-routing methods to deal with the load-balancing problem among the gatekeepers. As a matter of fact, the existing call-routing method used in the current version of the H.323 is very primitive and will cause the loads of the gatekeepers unbalanced. Using the gatekeeper prototype devised, two improved call-routing methods are proposed based on Multiple-Registration with Multicasted Location Request (MRML) and Multiple-Registration with Hierarchical Database (MRHD). To evaluate the performance improvement by these two load-balancing methods, we design an event-driven simulator and conduct some experiments on it. We focus on two performance metrics, call-blocking rate and channel utilization, which are both sensitive to the load distribution. The experimental results show that the call-blocking ratio and channel utilization are optimized with the proposed load-balancing methods. It is also observed from our empirical results that the call-blocking ratio is more sensitive to the traffic load whereas the channel utilization is more sensitive to the duration of a call.
C1 Natl Taiwan Univ, Dept Elect Engn, Taipei 10764, Taiwan.
C3 National Taiwan University
RP Chang, CY (corresponding author), Natl Taiwan Univ, Dept Elect Engn, Taipei 10764, Taiwan.
EM cychang@arbor.ee.ntu.edu.tw; mschen@cc.ee.ntu.edu.tw;
   bhhuang@arbor.ee.ntu.edu.tw
OI Chen, Ming-Syan/0000-0002-0711-8197
CR Anerousis N, 1999, IEEE J SEL AREA COMM, V17, P91, DOI 10.1109/49.743699
   CHANG CY, 2000, P IEEE INT C MULT EX
   Dalgic I, 1999, IEEE COMMUN MAG, V37, P96, DOI 10.1109/35.774887
   EYERS T, 2000, P 1 IP TEL WORKSH IP
   Goyal P, 1999, IEEE NETWORK, V13, P24, DOI 10.1109/65.767134
   HANDLEY M, 2543 RFC
   Hassan M, 2000, IEEE COMMUN MAG, V38, P96, DOI 10.1109/35.833564
   Huitema C, 1999, IEEE NETWORK, V13, P50, DOI 10.1109/65.767139
   KALMANEK CR, 2000, P 19 ANN JOINT C IEE
   LIAO WJ, 1999, P 18 ANN JOINT C IEE
   MOH M, 1999, P IEEE ICCN SAN JUAN
   Okubo S, 1997, IEEE J SEL AREA COMM, V15, P965, DOI 10.1109/49.611153
   PAGUREK B, 2000, P 19 ANN JOINT C IEE
   POLYZOIS CA, 1999, IEEE NETWORK, V3
   Rizzetto D, 1999, IEEE INTERNET COMPUT, V3, P53, DOI 10.1109/4236.769423
   ROSENBERG J, 2871 RFC
   SCHULRINNE H, 2326 RFC
   SCHULZRINNE H, 1998, P NETW OP SYST SUPP
   SCHULZRINNE H, 1889 RFC
   SCHULZRINNE H, 1999, COMPUT NETWORKS ISDN, V31
   SRINIVASAN A, 2000, P 19 ANN JOINT C IEE
   THOM GA, 1996, IEEE COMMUN MAG, P52
   WANG HJ, 2000, P 19 ANN JOINT C IEE
   Williams BA, 1997, COMBUST FLAME, V110, P1, DOI 10.1016/S0010-2180(97)00063-1
NR 24
TC 6
Z9 8
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2004
VL 6
IS 6
BP 936
EP 946
DI 10.1109/TMM.2004.834857
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 872QU
UT WOS:000225224200015
OA Green Published
DA 2024-07-18
ER

PT J
AU Tong, SR
   Lee, SC
AF Tong, SR
   Lee, SC
TI Delivery of compressed videos from video servers employing cycle-based
   data-block retrieval discipline
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE flow control; resource management; smoothing methods; video on demand
ID STORED VIDEO
AB The significant frame size variability exhibited in the compressed videos imposes a great challenge on network delivery. In this paper we propose an efficient flow control scheme, employed in the peer stations (i.e., servers and clients), for delivery of prestored compressed videos in a video-on-demand (VOD) system. This scheme resorts to an off-line analysis on the video frame sizes and server properties for figuring out the necessary buffer space and network bandwidth. The server platform of particular interest obeys a cycle-based data-block retrieval discipline, which is an essential technique to reduce the disk seek time for leveraging the disk throughput for supporting a large number of concurrent video accesses. Such a discipline is taken into account here to guarantee smooth delivery of variable-bit-rate videos. In run-time a server-driven control model is in use, where a server performs the primary nom, control task, without relying on any feedback from clients. The scheme has been implemented in our prototype VOD system to support both unicast- and multicast communication paradigms under an RSVP-enabled network. We evaluate the effectiveness of our scheme by conducting a series of experiments on four different styled video tracks under various system platforms and observe that the required resources are sensitive to a server's configuration and compressed videos' traffic characteristics. With proper arrangement, a near 100% network bandwidth utilization can normally be achieved with moderate buffer space (<1.4 MB in total) and a few seconds startup delay if a high video compression ratio is used.
C1 Natl Pingtung Univ Sci & Technol, Dept Management Informat Syst, Pingtung 91207, Taiwan.
C3 National Pingtung University Science & Technology
RP Tong, SR (corresponding author), Natl Pingtung Univ Sci & Technol, Dept Management Informat Syst, Pingtung 91207, Taiwan.
CR Berson S., 1995, Multimedia Tools and Applications, V1, P127, DOI 10.1007/BF01215935
   CHUA TS, 1996, ACM MULTIMEDIA, P297
   Feng WC, 1997, MULTIMEDIA SYST, V5, P297, DOI 10.1007/s005300050062
   GALL DL, 1991, COMMUN ACM, V34, P46
   GEMMELL DJ, 1995, IEEE COMPUTER    MAY, P40
   GHANDEHARIZADEH S, 1996, MULTIMEDIA INFORMATI
   KNIGHTLY E, 1995, IEEE INFOCOM BOST MA
   MACEDONIA MR, 1994, IEEE COMPUT MAG  APR, P30
   McManus JM, 1996, IEEE J SEL AREA COMM, V14, P1087, DOI 10.1109/49.508280
   OTT T, 1992, IEEE INFOCOM FLOR IT
   Rao SG, 1999, MULTIMEDIA SYST, V7, P222, DOI 10.1007/s005300050124
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   TONG SR, 1998, IEEE C MULT SYST AUS
   Tse PKC, 2000, MULTIMEDIA SYST, V8, P47, DOI 10.1007/s005300050004
   VOGT C, 1995, MULTIMEDIA SYST, V3, P66, DOI 10.1007/BF01219802
   WHITE P, 1997, IEEE COMMUNICATI MAY, P100
   Zhang H, 1997, MULTIMEDIA SYST, V5, P164, DOI 10.1007/s005300050053
   ZHANG L, 1993, IEEE NETWORK     SEP, P8
NR 18
TC 1
Z9 1
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855 USA
SN 1520-9210
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2003
VL 5
IS 3
BP 403
EP 415
DI 10.1109/TMM.2003.813272
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 714BM
UT WOS:000184892500012
DA 2024-07-18
ER

EF