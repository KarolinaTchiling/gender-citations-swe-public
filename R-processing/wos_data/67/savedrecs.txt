FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Darma, IWAS
   Suciati, N
   Siahaan, D
AF Darma, I. Wayan Agus Surya
   Suciati, Nanik
   Siahaan, Daniel
TI CARVING-DETC: A network scaling and NMS ensemble for Balinese carving
   motif detection method
SO VISUAL INFORMATICS
LA English
DT Article
DE Balinese carving; Object detection; Network scaling; Ensemble model;
   Non-maximum suppression
AB Balinese carvings are cultural objects that adorn sacred buildings. The carvings consist of several motifs, each representing the values adopted by the Balinese people. Detection of Balinese carving motifs is challenging due to the unavailability of a Balinese carving dataset for detection tasks, high variance, and tiny-size carving motifs. This research aims to improve carving motif detection performance on challenging Balinese carving motifs detection task through a modification of YOLOv5 to support a digital carving conservation system. We proposed CARVING-DETC, a deep learning-based Balinese carving detection method consisting of three steps. First, the data generation step performs data augmentation and annotation on Balinese carving images. Second, we proposed a network scaling strategy on the YOLOv5 model and performed non-maximum suppression (NMS) on the model ensemble to generate the most optimal predictions. The ensemble model utilizes NMS to produce higher performance by optimizing the detection results based on the highest confidence score and suppressing other overlap predictions with a lower confidence score. Third, performance evaluation on scaled-YOLOv5 versions and NMS ensemble models. The research findings are beneficial in conserving the cultural heritage and as a reference for other researchers. In addition, this study proposed a novel Balinese carving dataset through data collection, augmentation, and annotation. To our knowledge, it is the first Balinese carving dataset for the object detection task. Based on experimental results, CARVING-DETC achieved a detection performance of 98%, which outperforms the baseline model. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Darma, I. Wayan Agus Surya] Inst Bisnis & Teknol Indonesia, Fac Technol & Informat, Dept Informat, Denpasar 80225, Indonesia.
   [Suciati, Nanik; Siahaan, Daniel] Inst Teknol Sepuluh Nopember, Fac Intelligent Elect & Informat Technol, Dept Informat, Surabaya 60111, Indonesia.
C3 Institut Teknologi Sepuluh Nopember
RP Darma, IWAS (corresponding author), Inst Bisnis & Teknol Indonesia, Fac Technol & Informat, Dept Informat, Denpasar 80225, Indonesia.; Suciati, N (corresponding author), Inst Teknol Sepuluh Nopember, Fac Intelligent Elect & Informat Technol, Dept Informat, Surabaya 60111, Indonesia.
EM surya@instiki.ac.id; nanik@if.its.ac.id
RI Siahaan, Daniel/F-7506-2011
OI Siahaan, Daniel/0000-0001-6560-2975; Suciati, Nanik/0000-0002-1991-0464;
   Darma, I Wayan Agus Surya/0000-0002-3507-4654
FU Directorate General of Higher Education, Research, and Technology,
   Republic of Indonesia [3/E1/KP.PTNBH/2021]
FX This study is supported by the Directorate General of Higher Education,
   Research, and Technology, Republic of Indonesia under the grand number
   3/E1/KP.PTNBH/2021.
CR Aly GH, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105823
   Azimjonov J, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101393
   Casado-García A, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105751
   Cintas C, 2020, J CULT HERIT, V41, P106, DOI 10.1016/j.culher.2019.06.005
   Darma I W A S., 2020, International Journal of Intelligent Engineering Systems, V13, P349, DOI [DOI 10.22266/IJIES2020.1231.31, 10.22266/ijies2020.1231.31]
   Darma I. W. A. S., 2020, 2020 4 INT C INF COM, P1, DOI [10.1109/ICICoS51170.2020.9299021, DOI 10.1109/ICICOS51170.2020.9299021]
   Darma IWAS, 2019, PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON NEW MEDIA STUDIES (CONMEDIA 2019), P212, DOI [10.1109/CONMEDIA46929.2019.8981860, 10.1109/conmedia46929.2019.8981860]
   Gao CQ, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.107008
   Gao Y, 2021, EXPERT SYST APPL, V180, DOI 10.1016/j.eswa.2021.115037
   Guihui Shi, 2021, 2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML), P78, DOI 10.1109/PRML52754.2021.9520728
   Guo F, 2022, ADV ENG INFORM, V51, DOI 10.1016/j.aei.2021.101456
   Hatir ME, 2020, J CULT HERIT, V45, P193, DOI 10.1016/j.culher.2020.04.008
   Hu PF, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102689
   Hu XL, 2021, COMPUT ELECTRON AGR, V185, DOI 10.1016/j.compag.2021.106135
   Huang ZC, 2020, INFORM SCIENCES, V522, P241, DOI 10.1016/j.ins.2020.02.067
   Jiang N, 2021, PROCEDIA COMPUT SCI, V187, P52, DOI 10.1016/j.procs.2021.04.106
   Li JS, 2021, VIS INFORM, V5, P41, DOI 10.1016/j.visinf.2021.11.003
   Ma WT, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108213
   Made Avendias Mahawan I., 2017, P SOFT COMP DAT SCI, P43
   Monna F, 2021, J CULT HERIT, V52, P171, DOI 10.1016/j.culher.2021.10.004
   Prasetyo E, 2022, J KING SAUD UNIV-COM, V34, P5286, DOI 10.1016/j.jksuci.2021.05.015
   Psota ET, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105927
   Qaroush A, 2022, J KING SAUD UNIV-COM, V34, P3025, DOI 10.1016/j.jksuci.2020.10.001
   Rabby AKMSA, 2018, PROCEDIA COMPUT SCI, V143, P603, DOI 10.1016/j.procs.2018.10.437
   Rafalo M, 2022, ICT EXPRESS, V8, P183, DOI 10.1016/j.icte.2021.05.001
   Shi J, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105807
   Suciati N, 2022, IEEE ACCESS, V10, P14600, DOI 10.1109/ACCESS.2022.3147069
   Suciati N, 2015, PROCEEDINGS 5TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2015), P178, DOI 10.1109/ICCSCE.2015.7482180
   Suciati N, 2015, INT CONF INFORM COMM, P99, DOI 10.1109/ICTS.2015.7379879
   Sugianela Y., 2019, CommIT (Commun. Inform. Technol.) J., V13, P25, DOI [10.21512/COMMIT.V13I1.5330, DOI 10.21512/COMMIT.V13I1.5330]
   Sutramiani NP, 2021, ICT EXPRESS, V7, P521, DOI 10.1016/j.icte.2021.04.005
   Sutramiani Ni Putu, 2020, 2020 4 INT C INF COM, P1, DOI [10.1109/ICICoS51170.2020.9299030, DOI 10.1109/ICICOS51170.2020.9299030]
   Tamhankar Parag A., 2020, Procedia Computer Science, V171, P179, DOI 10.1016/j.procs.2020.04.019
   Wang Y, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107442
   Wu SH, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107503
   Xie ZC, 2019, NEUROCOMPUTING, V350, P271, DOI 10.1016/j.neucom.2019.04.001
   Ye XY, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103978
   Zhu LL, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183776
NR 38
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2023
VL 7
IS 3
BP 1
EP 10
DI 10.1016/j.visinf.2023.05.004
EA SEP 2023
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA U3SW6
UT WOS:001084039100001
OA gold
DA 2024-07-18
ER

PT J
AU Zhang, YH
   Li, G
   Shan, GH
AF Zhang, Yihan
   Li, Guan
   Shan, Guihua
TI Time analysis of regional structure of large-scale particle using an
   interactive visual system
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual analytics; Frame interpolation; Interactive; Particle region
   structure
ID OPTICAL-FLOW; SIMULATIONS; EVOLUTION; MODELS
AB N-body numerical simulation is an important tool in astronomy. Scientists used this method to simulate the formation of structure of the universe, which is key to understanding how the universe formed. As research on this subject further develops, astronomers require a more precise method that enables expansion of the simulation and an increase in the number of simulation particles. However, retaining all temporal information is infeasible due to a lack of computer storage. In the circumstances, astronomers reserve temporal data at intervals, merging rough and baffling animations of universal evolution. In this study, we propose a deep-learning-assisted interpolation application to analyze the structure formation of the universe. First, we evaluate the feasibility of applying interpolation to generate an animation of the universal evolution through an experiment. Then, we demonstrate the superiority of deep convolutional neural network (DCNN) method by comparing its quality and performance with the actual results together with the results generated by other popular interpolation algorithms. In addition, we present PRSVis, an interactive visual analytics system that supports global volume rendering, local area magnification, and temporal animation generation. PRSVis allows users to visualize a global volume rendering, interactively select one cubic region from the rendering and intelligently produce a time-series animation of the high-resolution region using the deep-learningassisted method. In summary, we propose an interactive visual system, integrated with the DCNN interpolation method that is validated through experiments, to help scientists easily understand the evolution of the particle region structure. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Zhang, Yihan; Li, Guan; Shan, Guihua] Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
   [Zhang, Yihan; Shan, Guihua] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Computer Network Information Center, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Shan, GH (corresponding author), Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
EM zhangyihan@cnic.cn; liguan@sccas.cn; sgh@sccas.cn
OI Li, Guan/0000-0001-6436-3650; Shan, Guihua/0000-0002-8283-2278
FU National Key Research and Development Program of China [2020YFB0204802]
FX Acknowledgment This work is supported by the National Key Research and
   Development Program of China (2020YFB0204802) .
CR Ahrens J, 2014, INT CONF HIGH PERFOR, P424, DOI 10.1109/SC.2014.40
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0
   Bertschinger E, 1998, ANNU REV ASTRON ASTR, V36, P599, DOI 10.1146/annurev.astro.36.1.599
   Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705
   Black MJ, 1996, IEEE T PATTERN ANAL, V18, P972, DOI 10.1109/34.541407
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Davis A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601119
   DAVIS M, 1985, ASTROPHYS J, V292, P371, DOI 10.1086/163168
   Einstein A, 1919, IDEAS OPINIONS
   GAMOW G, 1948, NATURE, V162, P680, DOI 10.1038/162680a0
   Glocker B., 2008, IEEE COMPUTER VISION, P1, DOI [DOI 10.1109/CVPR.2008.4587562, 10.1109/CVPR.2008.4587562]
   Halpern P., 2016, ADV ASTROPHYSICS, V1, P135
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Janai J, 2017, PROC CVPR IEEE, P1406, DOI 10.1109/CVPR.2017.154
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Jiang LH, 2021, NAT ASTRON, V5, P256, DOI 10.1038/s41550-020-01275-y
   Kaehler R, 2012, IEEE T VIS COMPUT GR, V18, P2078, DOI 10.1109/TVCG.2012.187
   Kageyama A, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.305
   Kuhlen M, 2012, PHYS DARK UNIVERSE, V1, P50, DOI 10.1016/j.dark.2012.10.002
   Lei C, 2009, IEEE I CONF COMP VIS, P1562, DOI 10.1109/ICCV.2009.5459253
   Lematre G., 1927, SCIENTIFIQUE BRUXELL, V47, P49, DOI DOI 10.1007/S10714-013-1548-3
   Lempitsky V., 2008, Proceedings of the 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'08), P1
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Lu QC, 2016, J DISP TECHNOL, V12, P45, DOI 10.1109/JDT.2015.2453252
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   MARKMAN E, 1979, PSYCCRITIQUES, V24
   Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747
   Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244
   Novikov I.D., 1983, Evolution of the universe
   Ratra B, 2008, PUBL ASTRON SOC PAC, V120, P235, DOI 10.1086/529495
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadek Rida, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P367
   Seitz SM, 2009, IEEE I CONF COMP VIS, P143, DOI 10.1109/ICCV.2009.5459155
   Somerville RS, 2015, ANNU REV ASTRON ASTR, V53, P51, DOI 10.1146/annurev-astro-082812-140951
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Springel V, 2005, MON NOT R ASTRON SOC, V364, P1105, DOI 10.1111/j.1365-2966.2005.09655.x
   Steinhardt PJ, 2002, PHYS REV D, V65, DOI 10.1103/PhysRevD.65.126003
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Trobin W, 2008, LECT NOTES COMPUT SC, V5096, P396, DOI 10.1007/978-3-540-69321-5_40
   Wadhwa N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461966
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Warren D.H., 1985, Electronic Spatial Sensing for the Blind: Contributions from Perception, Rehabilitation, and Computer Vision
   Wedel A., 2008, IVCNZ, P1
   Werlberger Manuel, 2011, INT WORKSH EN MIN ME, P273
   Yamaoka Y, 2019, PROCEEDINGS OF IN SITU INFRASTRUCTURES FOR ENABLING EXTREME-SCALE ANALYSIS AND VISUALIZATION (ISAV 2019), P12, DOI 10.1145/3364228.3364230
NR 50
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 14
EP 24
DI 10.1016/j.visinf.2022.03.004
EA MAY 2022
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2B9RT
UT WOS:000810519100001
OA gold
DA 2024-07-18
ER

PT J
AU Lu, KC
   Wang, CL
   Wu, KQ
   Gong, ML
   Wang, YH
AF Lu, Kecheng
   Wang, Chaoli
   Wu, Keqin
   Gong, Minglun
   Wang, Yunhai
TI A unified framework for exploring time-varying volumetric data based on
   block correspondence
SO VISUAL INFORMATICS
LA English
DT Article
DE Time-varying data visualization; Block correspondence; Feature
   extraction and tracking
AB Effective exploration of spatiotemporal volumetric data sets remains a key challenge in scientific visualization. Although great advances have been made over the years, existing solutions typically focus on only one or two aspects of data analysis and visualization. A streamlined workflow for analyzing time-varying data in a comprehensive and unified manner is still missing. Towards this goal, we present a novel approach for time-varying data visualization that encompasses keyframe identification, feature extraction and tracking under a single, unified framework. At the heart of our approach lies in the GPU-accelerated BlockMatch method, a dense block correspondence technique that extends the PatchMatch method from 2D pixels to 3D voxels. Based on the results of dense correspondence, we are able to identify keyframes from the time sequence using k-medoids clustering along with a bidirectional similarity measure. Furthermore, in conjunction with the graph cut algorithm, this framework enables us to perform fine-grained feature extraction and tracking. We tested our approach using several time-varying data sets to demonstrate its effectiveness and utility. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Lu, Kecheng; Wang, Yunhai] Shandong Univ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Wang, Chaoli] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA.
   [Wu, Keqin] NOAA, Washington, DC USA.
   [Gong, Minglun] Univ Guelph, Sch Comp Sci, Guelph, ON, Canada.
C3 Shandong University; University System of Maryland; University of
   Maryland Baltimore County; National Oceanic Atmospheric Admin (NOAA) -
   USA; University of Guelph
RP Lu, KC; Wang, YH (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
EM lukecheng0407@gmail.com; chaoli.wang@nd.edu; keqin.wu@noaa.gov;
   minglun@uoguelph.ca; cloudseawang@gmail.com
RI Wang, Chaoli/AAJ-5173-2020; Gong, Minglun/AAU-3103-2020
OI Wang, Chaoli/0000-0002-0859-3619; Gong, Minglun/0000-0001-5820-5381
FU  [BKBD-2017KF02]
FX This work is supported by the grants of BKBD-2017KF02.
CR Barnes C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778826
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Crawfis R. A., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P261, DOI 10.1109/VISUAL.1993.398877
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Dutta S, 2016, IEEE T VIS COMPUT GR, V22, P837, DOI 10.1109/TVCG.2015.2467436
   Frey S, 2017, COMPUT GRAPH FORUM, V36, P153, DOI 10.1111/cgf.13070
   Frey S, 2017, IEEE T VIS COMPUT GR, V23, P921, DOI 10.1109/TVCG.2016.2599042
   Glatter M, 2008, IEEE T VIS COMPUT GR, V14, P1467, DOI 10.1109/TVCG.2008.184
   Gu Y, 2013, IEEE PAC VIS SYMP, P137, DOI 10.1109/PacificVis.2013.6596138
   Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference, P405
   Lee TY, 2009, IEEE T VIS COMPUT GR, V15, P1359, DOI 10.1109/TVCG.2009.200
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461998
   Ma KL, 2003, COMPUT SCI ENG, V5, P34, DOI 10.1109/MCISE.2003.1182960
   Ozer S, 2014, IEEE T VIS COMPUT GR, V20, P377, DOI 10.1109/TVCG.2013.117
   Rong G., 2006, P 2006 S INTERACTIVE, P109, DOI DOI 10.1145/1111411.1111431
   SAMTANEY R, 1994, COMPUTER, V27, P20, DOI 10.1109/2.299407
   Silver D, 1997, IEEE T VIS COMPUT GR, V3, P129, DOI 10.1109/2945.597796
   Simakov D., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587842
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Wang CL, 2008, IEEE T VIS COMPUT GR, V14, P1547, DOI 10.1109/TVCG.2008.140
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Wang ZJ, 2016, IEEE T VIS COMPUT GR, V22, P807, DOI 10.1109/TVCG.2015.2467292
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Woodring J, 2009, COMPUT GRAPH FORUM, V28, P791, DOI 10.1111/j.1467-8659.2009.01472.x
   Woodring J, 2009, IEEE T VIS COMPUT GR, V15, P123, DOI 10.1109/TVCG.2008.69
   Xin Tong, 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P49, DOI 10.1109/LDAV.2012.6378975
NR 29
TC 2
Z9 3
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2019
VL 3
IS 4
BP 157
EP 165
DI 10.1016/j.visinf.2019.10.001
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YM
UT WOS:000658190500001
OA gold
DA 2024-07-18
ER

PT J
AU Xiang, JH
AF Xiang, Jianheng
TI On generated artistic styles: Image generation experiments with GAN
   algorithms
SO VISUAL INFORMATICS
LA English
DT Article
DE CG art; Virtual realistic; Image generation; Deep learning; Machine
   replication
AB As computer graphics technology supports pursuing a photorealistic style, replicated artworks with a photorealistic style overwhelmingly predominate in the computer-generated art circle. Along with the progression of generative technology, this trend may make generative art a virtual world of photorealistic fake, in which the single criterion of expressive style imperils art into the context of a single boring stereotype. This article focuses on the issue of style diversity and its technical feasibility by artistic experiments of generating flower images in StyleGAN. The author insisted that photo both technology and artistic style should not be confined merely for realistic purposes. This proposition was validated in the GAN generation experiment by changing the training materials.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Xiang, Jianheng] China Acad Art, Sch Design & Innovat, Hangzhou, Peoples R China.
C3 China Academy of Art
RP Xiang, JH (corresponding author), China Acad Art, Sch Design & Innovat, Hangzhou, Peoples R China.
EM 0100012@caa.edu.cn
CR [Anonymous], 2022, This person does not exist.com.
   Benjamin W., 1969, Media and Cultural Studies Keyworks, P48
   Cormen T.H., 2005, INTRO ALGORITHMS, V2nd
   Debord Guy., 2014, The Society of the Spectacle: Annotated Edition
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Karras T, 2020, Arxiv, DOI [arXiv:1912.04958, 10.48550/arXiv.1912.04958]
   Na R., 2010, Realisticity, Realisticness, and Real: A Discussion on the Truth View of Painting (Chinese Version)
   Situ L., 1994, New Art., P3
   Song L., 2020, Machine Vision and Machine Learning (Chinese Version)
NR 9
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 36
EP 40
DI 10.1016/j.visinf.2023.10.005
EA NOV 2023
PG 5
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CW3X9
UT WOS:001128244000001
OA gold
DA 2024-07-18
ER

PT J
AU Cai, SJ
   Hong, SH
   Xia, XB
   Liu, TL
   Huang, WD
AF Cai, Shijun
   Hong, Seok-Hee
   Xia, Xiaobo
   Liu, Tongliang
   Huang, Weidong
TI A machine learning approach for predicting human shortest path task
   performance
SO VISUAL INFORMATICS
LA English
DT Article
DE Graphdrawing; Machinelearning; Shortestpathtask; Qualitymetrics
ID GRAPH; VISUALIZATION
AB Finding a shortest path for a given pair of vertices in a graph drawing is one of the fundamental tasks for qualitative evaluation of graph drawings. In this paper, we present the first machine learning approach to predict human shortest path task performance, including accuracy, response time, and mental effort. To predict the shortest path task performance, we utilize correlated quality metrics and the ground truth data from the shortest path experiments. Specifically, we introduce path faithfulness metrics and show strong correlations with the shortest path task performance. Moreover, to mitigate the problem of insufficient ground truth training data, we use the transfer learning method to pre-train our deep model, exploiting the correlated quality metrics. Experimental results using the ground truth human shortest path experiment data show that our models can successfully predict the shortest path task performance. In particular, model MSP achieves the MSE (i.e., test mean square error) of 0.7243 (i.e., data range from -17.27 to 1.81) for prediction.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Cai, Shijun; Hong, Seok-Hee; Xia, Xiaobo; Liu, Tongliang] Univ Sydney, Camperdown, NSW, Australia.
   [Huang, Weidong] Univ Technol Sydney, Ultimo, NSW, Australia.
C3 University of Sydney; University of Technology Sydney
RP Cai, SJ (corresponding author), Univ Sydney, Camperdown, NSW, Australia.
EM scai5619@uni.sydney.edu.au; seokhee.hong@sydney.edu.au;
   xxia5420@uni.sydney.edu.au; tongliang.liu@sydney.edu.au;
   weidong.huang@uts.edu.au
RI Huang, Weidong/B-7504-2011; Liu, Tongliang/AAA-1506-2021
OI Liu, Tongliang/0000-0002-9640-6472; Huang, Weidong/0000-0002-5190-7839
FU ARC Linkage Project, Australia [LP160100935]; Oracle Research lab;
   Australian Research Council [LP160100935] Funding Source: Australian
   Research Council
FX Research supported by ARC Linkage Project, Australia (LP160100935) with
   Oracle Research lab.
CR Batagelj V, 2004, MATH VIS, P77
   Benesty J., 2009, Noise Reduction in Speech Processing
   Can SJ, 2021, IEEE PAC VIS SYMP, P6, DOI 10.1109/PacificVis52677.2021.00009
   Chimani M, 2014, LECT NOTES COMPUT SC, V8871, P523
   Di Battista G., 1999, Graph Drawing: Algorithms for the Visualization of Graphs, V357
   Eades P, 2015, LECT NOTES COMPUT SC, V9411, P502, DOI 10.1007/978-3-319-27261-0_41
   Fletcher C, 2019, IEEE PAC VIS SYMP, P77, DOI 10.1109/PacificVis.2019.00017
   Giovannangeli L, 2020, VIS INFORM, V4, P86, DOI 10.1016/j.visinf.2020.04.002
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang WD, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P41
   Huang WD, 2016, INFORM SCIENCES, V330, P444, DOI 10.1016/j.ins.2015.05.028
   Huang WD, 2014, J VISUAL LANG COMPUT, V25, P452, DOI 10.1016/j.jvlc.2014.03.001
   Huang WD, 2009, IEEE PAC VIS SYMP, P137, DOI 10.1109/PACIFICVIS.2009.4906848
   Klammler M, 2018, LECT NOTES COMPUT SC, V11282, P169, DOI 10.1007/978-3-030-04414-5_12
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Meidiana Amyra, 2020, Graph Drawing and Network Visualization. 28th International Symposium, GD 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12590), P450, DOI 10.1007/978-3-030-68766-3_35
   Meidiana A, 2020, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis48177.2020.1022
   Meidiana A, 2019, LECT NOTES COMPUT SC, V11904, P125, DOI 10.1007/978-3-030-35802-0_10
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Toussaint G.T, 2014, COMPUTATIONAL MORPHO
   Wang QW, 2021, Arxiv, DOI arXiv:2012.00467
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
NR 27
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 50
EP 61
DI 10.1016/j.visinf.2022.04.001
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 3D7JN
UT WOS:000829473700002
OA gold
DA 2024-07-18
ER

PT J
AU Li, JS
   Xu, N
   Nie, WZ
   Zhang, SY
AF Li, Jiesi
   Xu, Ning
   Nie, Weizhi
   Zhang, Shenyuan
TI Image Captioning with multi-level similarity-guided semantic matching
SO VISUAL INFORMATICS
LA English
DT Article
DE Image Captioning; Cross-modal semantic matching; Reinforcement learning
AB Image Captioning is a cross-modal task that needs to automatically generate coherent natural sentences to describe the image contents. Due to the large gap between vision and language modalities, most of the existing methods have the problem of inaccurate semantic matching between images and generated captions. To solve the problem, this paper proposes a novel multi-level similarity-guided semantic matching method for image captioning, which can fuse local and global semantic similarities to learn the latent semantic correlation between images and generated captions. Specifically, we extract the semantic units containing fine-grained semantic information of images and generated captions, respectively. Based on the comparison of the semantic units, we design a local semantic similarity evaluation mechanism. Meanwhile, we employ the CIDEr score to characterize the global semantic similarity. The local and global two-level similarities are finally fused using the reinforcement learning theory, to guide the model optimization to obtain better semantic matching. The quantitative and qualitative experiments on large-scale MSCOCO dataset illustrate the superiority of the proposed method, which can achieve fine-grained semantic matching of images and generated captions. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Li, Jiesi; Xu, Ning; Nie, Weizhi] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Zhang, Shenyuan] Peoples Daily, Beijing, Peoples R China.
C3 Tianjin University
RP Xu, N (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM lijs980211@tju.edu.cn; ningxu@tju.edu.cn; weizhinie@tju.edu.cn;
   zhangshenyuan0@gmail.com
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [62002257]; China
   Postdoctoral Science Foundation [2021M692395]
FX This work was supported in part by the National Natural Science
   Foundation of China (62002257), and the China Postdoctoral Science
   Foundation (2021M692395).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2016, P 24 ACM INT C MULT
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen XP, 2018, PROC CVPR IEEE, P7995, DOI 10.1109/CVPR.2018.00834
   Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334
   Dong X., ACM MM, P2615
   Gao JL, 2019, PROC CVPR IEEE, P6293, DOI 10.1109/CVPR.2019.00646
   Gu JX, 2019, IEEE I CONF COMP VIS, P10322, DOI 10.1109/ICCV.2019.01042
   Gu JX, 2017, IEEE I CONF COMP VIS, P1231, DOI 10.1109/ICCV.2017.138
   Herdade S, 2019, ADV NEUR IN, V32
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Honnibal M., 2017, IN PRESS, DOI DOI 10.3233/978-1-60750-588-4-1080
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Jiang WH, 2018, AAAI CONF ARTIF INTE, P6959
   Karaoglu S, 2017, IEEE T MULTIMEDIA, V19, P1063, DOI 10.1109/TMM.2016.2638622
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2015, INT C LEARNING REPRE
   Kong XY, 2017, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR.2017.748
   Krull A, 2017, PROC CVPR IEEE, P2566, DOI 10.1109/CVPR.2017.275
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu DQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1416, DOI 10.1145/3240508.3240632
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ranzato M, 2016, 4 INT C LEARN REPR I
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu SM, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1180, DOI 10.1145/2998181.2998364
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu N, 2020, IEEE T MULTIMEDIA, V22, P1372, DOI 10.1109/TMM.2019.2941820
   Yang L., IEEE T MULTIMEDIA, V23, P835
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang L, 2017, ARXIV PREPRINT ARXIV
   Zhou YAN, 2020, PROC CVPR IEEE, P4776, DOI 10.1109/CVPR42600.2020.00483
NR 44
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 41
EP 48
DI 10.1016/j.visinf.2021.11.003
EA DEC 2021
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500006
OA gold
DA 2024-07-18
ER

PT J
AU Xu, CQ
   Sun, GD
   Liang, RH
AF Xu, Chaoqing
   Sun, Guodao
   Liang, Ronghua
TI A survey of volume visualization techniques for feature enhancement
SO VISUAL INFORMATICS
LA English
DT Review
DE Visualization; Volume rendering; Feature enhancement
ID INTERACTIVE GLOBAL ILLUMINATION; EXPLORATION; SURFACES; DISPLAY; SPACE
AB Volume rendering techniques have been developed for decades and have been widely applied in many research fields, such as medical image visualization, geological exploration, scientific computing. etc. With the maturity of volume visualization techniques, one may have many choices to analyze volume data. However, facing different application requirements in specific cases, one may need pertinent methods to visualize volume data and highlight specific volume features. In this paper, we review and classify the existing literature on feature enhancement volume rendering. The classification is conducted based on the enhancement of four types of features (the external feature, the internal feature, the structure feature, and the ideographic feature) in volume data. Finally, we conclude this survey with future challenges in feature enhancement volume visualization. (C) 2021 The Author(s). Published by Elsevier B.V.
C1 [Xu, Chaoqing; Sun, Guodao; Liang, Ronghua] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Technology
RP Sun, GD (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
EM guodao@zjut.edu.cn
RI liang, ronghua/H-4463-2012
FU National Natural Science Foundation of China [61972356, 62036009];
   Zhejiang Provincial Natural Science Foundation of China [LY19F020026]
FX The work is partly supported by the National Natural Science Foundation
   of China (61972356, 62036009), Zhejiang Provincial Natural Science
   Foundation of China (LY19F020026).
CR Ament M, 2017, IEEE T VIS COMPUT GR, V23, P1767, DOI 10.1109/TVCG.2016.2569080
   Ament M, 2013, IEEE T VIS COMPUT GR, V19, P2936, DOI 10.1109/TVCG.2013.129
   Bemardon F. F., 2006, Journal of Graphics Tools, V11, P1
   Benilov P, 2015, NONPHOTOREALISTIC TE
   Boksansky J, 2017, EUROGRAPHICS S RENDE, V17, P31
   Borland D, 2006, PROC SPIE, V6060, DOI 10.1117/12.641497
   Bruckner S, 2007, COMPUT GRAPH FORUM, V26, P715, DOI 10.1111/j.1467-8659.2007.01095.x
   Bruckner S., Proceedings of the Seventh Joint Eurographics / IEEE VGTC Conference on Visualization, ser. EUROVIS'05. Aire-la-Ville, Switzerland, Switzerland: Eurographics Association, P69, DOI DOI 10.2312/VISSYM/EUROVIS05/069-076
   Bruckner S, 2007, IEEE T VIS COMPUT GR, V13, P1344, DOI 10.1109/TVCG.2007.70555
   Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1559, DOI 10.1109/TVCG.2006.96
   Bruckner S, 2009, COMPUT GRAPH FORUM, V28, P775, DOI 10.1111/j.1467-8659.2009.01474.x
   Caban JJ, 2008, IEEE T VIS COMPUT GR, V14, P1364, DOI 10.1109/TVCG.2008.169
   Carr H, 2015, COMPUT GRAPH FORUM, V34, P241, DOI 10.1111/cgf.12636
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Chen Weifeng, 2012, Journal of Computer Aided Design & Computer Graphics, V24, P1259
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P192, DOI 10.1109/TVCG.2010.35
   Dachille F., 1998, SIGGRAPHEUROGRAPHICS, P69
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Diaz J, 2010, IEEE EG S VOL GRAPH, DOI [10.2312/VG/VG10/093-100, DOI 10.2312/VG/VG10/093-100]
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Engel D., 2020, IEEE T VIS COMPUT GR, V27, P1268
   Engel Klaus, 2001, P ACM SIGGRAPH EUROG, P9, DOI [DOI 10.1145/383507.383515, 10.1145/383507.383515]
   Gerl M, 2012, COMPUT GRAPH-UK, V36, P201, DOI 10.1016/j.cag.2011.10.006
   Gooch A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P447, DOI 10.1145/280814.280950
   Guetat A, 2010, IEEE T VIS COMPUT GR, V16, P1487, DOI 10.1109/TVCG.2010.187
   Guo Hangi, 2012, Journal of Computer Aided Design & Computer Graphics, V24, P1249
   Guodao S., 2013, J COMPUT AIDED DES C, V11
   Heidrich W, 1995, VISUALIZATION '95 - PROCEEDINGS, P11, DOI 10.1109/VISUAL.1995.480790
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Jadhav S, 2019, IEEE T VIS COMPUT GR, V25, P2725, DOI 10.1109/TVCG.2018.2856744
   Jain S., 2017, P LARG SCAL DAT AN V
   Jönsson D, 2020, IEEE T VIS COMPUT GR, V26, P3241, DOI 10.1109/TVCG.2019.2920639
   Jönsson D, 2017, IEEE T VIS COMPUT GR, V23, P901, DOI 10.1109/TVCG.2016.2598430
   Jönsson D, 2014, COMPUT GRAPH FORUM, V33, P27, DOI 10.1111/cgf.12252
   Jönsson D, 2012, IEEE T VIS COMPUT GR, V18, P2364, DOI 10.1109/TVCG.2012.232
   Jung Y, 2018, COMPUT GRAPH FORUM, V37, P5, DOI 10.1111/cgf.13308
   Jung YH, 2017, IEEE J BIOMED HEALTH, V21, P1005, DOI 10.1109/JBHI.2016.2565502
   Jung Y, 2016, COMPUT MED IMAG GRAP, V51, P40, DOI 10.1016/j.compmedimag.2016.04.003
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   Kroes T., 2018, GPU PRO 360, P305
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Kumar M.P.P., 2019, Iran J. Comput. Sci, V2, P131, DOI [10.1007/s42044-019-00034-1, DOI 10.1007/S42044-019-00034-1]
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Liang RH, 2012, VISUAL COMPUT, V28, P625, DOI 10.1007/s00371-012-0680-5
   Liang Ronghua, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P1381
   Lum E.B, 2004, EUR IEEE VGTC S VIS
   Ma J, 2021, J VISUAL-JAPAN, V24, P545, DOI 10.1007/s12650-020-00724-0
   Maciejewski R, 2009, IEEE T VIS COMPUT GR, V15, P1473, DOI 10.1109/TVCG.2009.185
   Marchesin S, 2007, VG EUROGRAPHICS, P41
   Marchesin S, 2010, IEEE T VIS COMPUT GR, V16, P560, DOI 10.1109/TVCG.2010.30
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   MeiSSner M., 1999, P VISUALIZATION 1999, P207
   Mroz L, 2001, REAL TIME VOLUME VIS
   Nagy Z, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P429, DOI 10.1109/PCCGA.2003.1238289
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Northrup J. D., 2000, Proceedings of the 1st International Symposium on Non-photorealistic Animation and Rendering, P31, DOI DOI 10.1145/340916.340920
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Prassni JS, 2010, IEEE PAC VIS SYMP, P9, DOI 10.1109/PACIFICVIS.2010.5429624
   Rautek P, 2008, COMPUT GRAPH FORUM, V27, P847, DOI 10.1111/j.1467-8659.2008.01216.x
   Rautek P, 2007, IEEE T VIS COMPUT GR, V13, P1336, DOI 10.1109/TVCG.2007.70591
   Rezk-Salama C, 2006, COMPUT GRAPH FORUM, V25, P597, DOI 10.1111/j.1467-8659.2006.00979.x
   Rheingans P, 2001, IEEE T VIS COMPUT GR, V7, P253, DOI 10.1109/2945.942693
   Ruiz M, 2011, IEEE T VIS COMPUT GR, V17, P1932, DOI 10.1109/TVCG.2011.173
   Sato Y, 1998, J COMPUT ASSIST TOMO, V22, P912, DOI 10.1097/00004728-199811000-00014
   Sharma O, 2020, COMPUT GRAPH FORUM, V39, P76, DOI 10.1111/cgf.13663
   Shih M, 2018, HIGH END VOLUME VISU, P135
   Song H, 2017, IEEE T VIS COMPUT GR, V23, P311, DOI 10.1109/TVCG.2016.2598796
   Sun GD, 2013, J COMPUT SCI TECH-CH, V28, P852, DOI 10.1007/s11390-013-1383-8
   Svakhine NA, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P347, DOI 10.1109/PCCGA.2003.1238276
   Tkachev G, 2021, IEEE T VIS COMPUT GR, V27, P3091, DOI 10.1109/TVCG.2019.2961893
   Ulyanov D., 2017, Instance Normalization: The Missing Ingredient for Fast Stylization
   WALLIS JW, 1989, IEEE T MED IMAGING, V8, P297, DOI 10.1109/42.41482
   Wang F, 2019, IEEE T VIS COMPUT GR, V25, P1142, DOI 10.1109/TVCG.2018.2864850
   Wang YD, 2019, IEEE I CONF COMP VIS, P8607, DOI 10.1109/ICCV.2019.00870
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Wang YH, 2010, IEEE PAC VIS SYMP, P25, DOI 10.1109/PACIFICVIS.2010.5429612
   Woo I, 2012, IEEE T VIS COMPUT GR, V18, P1731, DOI 10.1109/TVCG.2012.24
   Wu Fuli, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P1810
   Xu ZL, 2020, COMPUT GRAPH FORUM, V39, P193, DOI 10.1111/cgf.14137
   Yubo Tao, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P418, DOI 10.1109/CAD/Graphics.2011.81
   [周芳芳 Zhou Fangfang], 2008, [中国图象图形学报, Journal of Image and Graphics], V13, P1034
   Zhou Zhi-Guang, 2011, Chinese Journal of Computers, V34, P517, DOI 10.3724/SP.J.1016.2011.00517
   Zhou ZG, 2015, MULTIMED TOOLS APPL, V74, P10243, DOI 10.1007/s11042-014-2162-4
   Zhou ZG, 2011, VISUAL COMPUT, V27, P677, DOI 10.1007/s00371-011-0570-2
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 89
TC 5
Z9 6
U1 2
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 70
EP 81
DI 10.1016/j.visinf.2021.08.001
EA SEP 2021
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200006
OA gold
DA 2024-07-18
ER

PT J
AU Edmond, C
   Bednarz, T
AF Edmond, Cameron
   Bednarz, Tomasz
TI Three trajectories for narrative visualisation
SO VISUAL INFORMATICS
LA English
DT Article
DE Visualisation; Narrative techniques; Communication; Storytelling;
   Interaction design
AB Narrative Visualisation (NarVis) is the pairing of data visualisation with narrative techniques. Due to its interdisciplinary applications and scholarship, NarVis presentations often feature vastly different interpretations of "narrative" and "visualisation", which is echoed in NarVis authoring tools. To map the morphology of how the narratives of NarVis manifest, we identify three different trajectories for the field. These trajectories are identified through an analysis of selected NarVis presentations and tools, with an emphasis on identifying how traditional narrative techniques are adopted, transposed or indeed challenged by NarVis examples. We then populate our categories with additional examples and tools, providing a foundational point of reference for NarVis scholars, authors and tool developers. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Edmond, Cameron; Bednarz, Tomasz] UNSW, Sch Art & Design, Expanded Percept & Interact Ctr EPICtr, Sydney, NSW, Australia.
   [Bednarz, Tomasz] CSIROs Data61, Sydney, NSW, Australia.
C3 University of New South Wales Sydney; Commonwealth Scientific &
   Industrial Research Organisation (CSIRO)
RP Edmond, C (corresponding author), UNSW, Sch Art & Design, Expanded Percept & Interact Ctr EPICtr, Sydney, NSW, Australia.
EM c.edmond@unsw.edu.au
RI Bednarz, Tomasz/AAQ-2605-2021
OI Bednarz, Tomasz/0000-0001-9240-0922; Edmond, Cameron/0000-0002-4670-6418
FU Australia's Defence Science and Technology (DST) [RG190540-A]
FX The authors wish to thank our EPICentre's senior software engineers
   Robert Lawther and Conan Bourke. This work was supported in part by
   funding from Australia's Defence Science and Technology (DST)
   [RG190540-A-Using Data Farming]. We also thank the reviewers for their
   thorough and helpful comments.
CR Abrams M.H., 2013, A Glossary of Literary Terms, VEleventh
   Allers Roger., 1994, THE LION KING
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2020, M OULIPO BOULG
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bartalesi V, 2017, COMM COM INF SC, V701, P112, DOI 10.1007/978-3-319-56300-8_11
   Beaudouin Valerie., 2017, ARTIST UNKNOWN
   Booth A, 2015, BLACKWELL COMPAN LIT, P177
   Brehmer M., 2019, COMPUTATION JOURNALI, P1
   Brindle L, 2013, EPISTOLARY ENCOUNTER
   Bryan C, 2020, VIS INFORM, V4, P41, DOI 10.1016/j.visinf.2020.08.001
   Cairo A., 2016, The truthful art: Data, charts, and maps for communication, New Riders
   Calvino Italo., 2010, The Complete Cosmicomics London
   Chatman Seymour., 1978, STORY DISCOURSE
   Choe E.K, 2020, CHARTACCENT
   Chun RS, 2020, VIS COMMUN Q, V27, P84, DOI 10.1080/15551393.2020.1749842
   D'Ignazio C, 2018, DIGIT HUMANITIES Q, V12
   DeuxPlusQuatre, 2017, MEL CLEM
   Diehm I, 2020, PUDDING
   Dykes J., 2018, IEEE T VIS COMPUT GR, V25, P568, DOI [10.1109/TVCG.2018.2865836, DOI 10.1109/TVCG.2018.2865836]
   Ericson M., 2011, NEW YORK TIMES
   Figueiras A, 2014, IEEE INT CONF INF VI, P46, DOI 10.1109/IV.2014.79
   Gapminder, 2015, GAPMINDER
   Garreta Anne F, 2017, ARTIST UNKNOWN
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Goldenberg R., 2018, PUDDING
   Gutierrez M, 2020, THE GUARDIAN
   Hall V., 2021, DO ANTIBODY POSITIVE, DOI [10.1101/2021.01.13.21249642, DOI 10.1101/2021.01.13.21249642]
   Howard A B., 2014, The Art and Science of Data-Driven Journalism, DOI DOI 10.7916/D8Q531V1
   Jiahui Liu, 2020, IOP Conference Series: Materials Science and Engineering, V768, DOI 10.1088/1757-899X/768/5/052039
   Kagkelidis K, 2021, J VISUAL-JAPAN, V24, P631, DOI 10.1007/s12650-020-00718-y
   Khadem A, 2012, NEOHELICON, V39, P409, DOI 10.1007/s11059-012-0152-y
   Kim Nam Wook, 2019, P 2019 CHI C HUMAN F, P1, DOI [DOI 10.1145/3290605.3300309, 10.1145/3290605.3300335, DOI 10.1145/3290605.3300335]
   Kirk Andy, 2016, Data Visualisation: A Handbook for Data Driven Design
   Krause RJ, 2020, PERS SOC PSYCHOL B, V46, P216, DOI 10.1177/0146167219853845
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   LI Q, 2020, VIS ANAL PROBL SOLVI, V39, DOI DOI 10.1111/CGF.13999
   Liu RC, 2021, BIOINFORMATICS, V37, P2033, DOI 10.1093/bioinformatics/btab052
   Mathison S, 2019, SALE BABY SHOES NEVE
   McCandless D, 2010, WHAT DOES CHINA CENS
   McCloud S., 1993, Understanding Comics: The Invisible Art
   McElroy J, 2014, PLUS
   Metilli D, 2019, INT J DIGIT LIBRARIE, V20, P417, DOI 10.1007/s00799-019-00266-3
   Metoyer R, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P503, DOI 10.1145/3172944.3173007
   Microsoft, 2020, TIM STOR
   Motte Jr W.F, 1986, OULIPO PRIMER POTENT
   Niederhoff B., 2013, The Living Handbook of Narratology
   O'Day Danton H, 2007, CBE Life Sci Educ, V6, P217, DOI 10.1187/cbe.07-01-0002
   Obie HO, 2020, J COMPUT LANG, V58, DOI 10.1016/j.cola.2020.100961
   Propp V., 1968, Morphology of the Folktale, V2nd ed.
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Richardson B, 2013, ENTHYMEMA, P119
   Riche NH, 2018, Data-Driven Storytelling
   Robins W.G., 1952, U TORONTO QUART, V21, P217, DOI [10.3138/ut/21.3.2171952, DOI 10.3138/UT/21.3.2171952]
   Rodrigues S, 2019, IEEE INT CON INF VIS, P44, DOI 10.1109/IV.2019.00017
   Roquin L, 2020, M METAIL
   Satyanarayan J., 2013, EUR C VIS EUROVIS, V33
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Selden R, 1995, CAMBRIDGE HIST LIT C
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   South L., 2020, DEBATEVIS VISUALIZAI, DOI [10.31219/osf.io/8bsf6, DOI 10.31219/OSF.IO/8BSF6]
   Stevens H., 2020, The Washington Post
   Sutter K., 2014, Sons of Anarchy
   The Guardian, 2011, THE GUARDIAN
   The Pudding, 2017, PUDDING, P2017
   The World Health Organisation, 2018, DEATH ROADS
   Thomas A, 2020, PUDDING
   Tong C., 2018, INF, V9
   Vandermeer P, 2020, M GRANGAUD
   Vassiliadis P, 2020, LECT NOTES COMPUTER, V12400
   Wang QW, 2019, IEEE T VIS COMPUT GR, V25, P779, DOI 10.1109/TVCG.2018.2865232
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zhao Z., 2015, DATA COMICS SEQUENTI
NR 75
TC 6
Z9 6
U1 3
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2021
VL 5
IS 2
BP 26
EP 40
DI 10.1016/j.visinf.2021.04.001
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LF
UT WOS:000658194200003
OA gold
DA 2024-07-18
ER

PT J
AU Mansoor, H
   Gerych, W
   Alajaji, A
   Buquicchio, L
   Chandrasekaran, K
   Agu, E
   Rundensteiner, E
   Rodriguez, AI
AF Mansoor, Hamid
   Gerych, Walter
   Alajaji, Abdulaziz
   Buquicchio, Luke
   Chandrasekaran, Kavin
   Agu, Emmanuel
   Rundensteiner, Elke
   Rodriguez, Angela Incollingo
TI INPHOVIS: Interactive visual analytics for smartphone-based digital
   phenotyping
SO VISUAL INFORMATICS
LA English
DT Article
DE Interactive visual analytics; Smartphone-sensed data; Digital
   phenotyping
ID SHIFT WORK; MENTAL-HEALTH; VISUALIZATION; SYSTEM; STATE; TOOL
AB Digital phenotyping is the characterization of human behavior patterns based on data from digital devices such as smartphones in order to gain insights into the users' state and especially to identify ailments. To support supervised machine learning, digital phenotyping requires gathering data from study participants' smartphones as they live their lives. Periodically, participants are then asked to provide ground truth labels about their health status. Analyzing such complex data is challenging due to limited contextual information and imperfect health/wellness labels. We propose INteractive PHOne-o-typing VISualization (INPHOVIS), an interactive visual framework for exploratory analysis of smartphone health data to study phone-o-types. Prior visualization work has focused on mobile health data with clear semantics such as steps or heart rate data collected using dedicated health devices and wearables such as smartwatches. However, unlike smartphones which are owned by over 85 percent of the US population, wearable devices are less prevalent thus reducing the number of people from whom such data can be collected. In contrast, the "low-level" sensor data (e.g., accelerometer or GPS data) supported by INPHOVIS can be easily collected using smartphones. Data visualizations are designed to provide the essential contextualization of such data and thus help analysts discover complex relationships between observed sensor values and health-predictive phone-o-types. To guide the design of INPHOVIS, we performed a hierarchical task analysis of phone-o-typing requirements with health domain experts. We then designed and implemented multiple innovative visualizations integral to INPHOVIS including stacked bar charts to show diurnal behavioral patterns, calendar views to visualize day-level data along with bar charts, and correlation views to visualize important wellness predictive data. We demonstrate the usefulness of INPHOVIS with walk-throughs of use cases. We also evaluated INPHOVIS with expert feedback and received encouraging responses.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Mansoor, Hamid; Gerych, Walter; Alajaji, Abdulaziz; Buquicchio, Luke; Chandrasekaran, Kavin; Agu, Emmanuel; Rundensteiner, Elke; Rodriguez, Angela Incollingo] Worcester Polytech Inst, Worcester, MA 01609 USA.
C3 Worcester Polytechnic Institute
RP Mansoor, H (corresponding author), Worcester Polytech Inst, Worcester, MA 01609 USA.
EM hmansoor@wpi.edu; wgerych@wpi.edu; asalajaji@wpi.edu;
   ljbuquicchio@wpi.edu; kchandrasekaran@wpi.edu; emmanuel@wpi.edu;
   rundenst@wpi.edu; acrodriguez@wpi.edu
OI Incollingo Rodriguez, Angela/0000-0003-1609-4163; Rundensteiner,
   Elke/0000-0001-5375-9254
FU DARPA, United States [FA8750-18-2-0077]
FX Acknowledgments This material is based on research sponsored by DARPA,
   United States under agreement number FA8750-18-2-0077. The U.S.
   Government is authorized to reproduce and distribute reprints for
   Governmental purposes not withstanding any copyright notation thereon.
   The views and conclusions contained herein are those of the authors and
   should not be interpreted as necessarily repre-senting the official
   policies or endorsements, either expressed or implied, of DARPA or the
   U.S. Government.
CR Abdullah Saeed., 2017, Mobile Health, P35, DOI DOI 10.1007/978-3-319-51394-2_3
   Aledavood T, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1043-y
   Barak-Corren Y, 2017, AM J PSYCHIAT, V174, P154, DOI 10.1176/appi.ajp.2016.16010077
   Barlacchi G, 2017, EPJ DATA SCI, V6, DOI 10.1140/epjds/s13688-017-0124-6
   Bernard J, 2015, IEEE COMPUT GRAPH, V35, P42
   Boukhechba M., 2018, Smart Health, V9-10, P192, DOI DOI 10.1016/J.SMHL.2018.07.005
   Boukhechba M, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10101
   Bringmann LF, 2021, QUAL LIFE RES, V30, P3179, DOI 10.1007/s11136-020-02701-4
   Caballero HSG, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13667
   Cao N, 2018, INFORM VISUAL, V17, P22, DOI 10.1177/1473871616686635
   Caprani N, 2015, BRITISH HCI 2015, P26, DOI 10.1145/2783446.2783564
   Cavallo M, 2018, COMPUT GRAPH FORUM, V37, P339, DOI 10.1111/cgf.13424
   Choe EK, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P121, DOI 10.1145/2750858.2804266
   Choe EK, 2015, IEEE COMPUT GRAPH, V35, P28, DOI 10.1109/MCG.2015.51
   Choe EK, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1143, DOI 10.1145/2556288.2557372
   Choe Eun Kyoung, 2017, P 11 EAI INT C PERV, P173, DOI [10.1145/3154862.3154881, DOI 10.1145/3154862.3154881.-182, DOI 10.1145/3154862.3154881]
   Cordeiro Felicia, 2014, P 2014 C DESIGNING I, P667, DOI [DOI 10.1145/2598510.2598558, 10.1145/2598510.2598558]
   Costa G, 2010, SAF HEALTH WORK, V1, P112, DOI 10.5491/SHAW.2010.1.2.112
   Di Matteo D., 2021, THESIS U TORONTO CAN
   Epstein DA, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P829, DOI 10.1145/2971648.2971656
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fischer D, 2016, SCI REP-UK, V6, DOI 10.1038/srep38601
   foursquare, ABOUT US
   Fulford D, 2021, J PSYCHIATR RES, V137, P613, DOI 10.1016/j.jpsychires.2020.11.002
   Gerych W, 2019, IEEE INT C SEMANT CO, P124, DOI 10.1109/ICOSC.2019.8665535
   Ghods A, 2019, IEEE J BIOMED HEALTH, V23, P1742, DOI 10.1109/JBHI.2018.2864287
   Gill S, 2015, CELL METAB, V22, P789, DOI 10.1016/j.cmet.2015.09.005
   Guimin Dong, 2021, CHIL '21: Proceedings of the Conference on Health, Inference, and Learning, P291, DOI 10.1145/3450439.3451880
   Gupta Ankit, 2020, PervasiveHealth '20: Proceedings of the 14th EAI International Conference on Pervasive Computing Technologies for Healthcare, P156, DOI 10.1145/3421937.3421991
   Gupta A., 2017, INT C HUMAN COMPUTER, P232
   Harari GM, 2016, PERSPECT PSYCHOL SCI, V11, P838, DOI 10.1177/1745691616650285
   Harrington JM, 2001, OCCUP ENVIRON MED, V58, P68, DOI 10.1136/oem.58.1.68
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Kay M, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P226
   Kettlewell N, 2020, SSM-POPUL HLTH, V10, DOI 10.1016/j.ssmph.2019.100533
   Kim Y, 2022, PUBLIC HEALTH NURS, V39, P472, DOI 10.1111/phn.12975
   Kurniawan S., 2004, Interaction Design: Beyond Human-Computer Interaction
   Levy-Fix G., 2020, THESIS COLUMBIA U
   Liang YJ, 2019, INFORM FUSION, V52, P290, DOI 10.1016/j.inffus.2019.04.001
   Liang ZL, 2016, PERS UBIQUIT COMPUT, V20, P985, DOI 10.1007/s00779-016-0960-6
   Lie Ming Tang, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090091
   Madan A, 2012, IEEE PERVAS COMPUT, V11, P36, DOI 10.1109/MPRV.2011.79
   Malik S., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10. 1145/2678025.2701407]
   Mansoor H., 2020, EUROVIS 2020 SHORT P, DOI [10.2312/evs.20201043, DOI 10.2312/EVS.20201043]
   Mansoor H, 2021, VIS INFORM, V5, P39, DOI 10.1016/j.visinf.2021.07.001
   Mansoor H, 2021, IVAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 3: IVAPP, P64, DOI 10.5220/0010204300640075
   Mansoor H, 2021, IEEE COMPUT GRAPH, V41, P96, DOI 10.1109/MCG.2021.3062474
   Mansoor H, 2020, IEEE INT CONF BIG DA, P4882, DOI 10.1109/BigData50022.2020.9378147
   Mansoor H, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P11, DOI [10.1109/vds48975.2019.8973382, 10.1109/VDS48975.2019.8973382]
   Melcher J, 2020, EVID-BASED MENT HEAL, V23, P161, DOI 10.1136/ebmental-2020-300180
   Mercier HW, 2020, AM J PHYS MED REHAB, V99, P1138, DOI 10.1097/PHM.0000000000001506
   Mueller SR, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93087-x
   NPR, US
   O'Brien A., 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P252, DOI 10.4108/icst.pervasivehealth.2012.248621
   Okuno A, 2020, UBICOMP/ISWC '20 ADJUNCT: PROCEEDINGS OF THE 2020 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2020 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P94, DOI 10.1145/3410530.3414377
   Onnela JP, 2016, NEUROPSYCHOPHARMACOL, V41, P1691, DOI 10.1038/npp.2016.7
   Paay Jeni., 2015, Proceedings of the 17th International Conference on HumanComputer Interaction with Mobile Devices and Services, P98, DOI DOI 10.1145/2785830.2785877
   Panda N., 2021, ANN SURG
   Panda N, 2020, JAMA SURG, V155, P123, DOI 10.1001/jamasurg.2019.4702
   Payandeh S, 2019, LECT NOTES COMPUT SC, V11542, P316, DOI 10.1007/978-3-030-22514-8_26
   PEW, ON IN 5 AM US SMART
   Polack PJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3152888
   Raj Shriti, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314409
   Rashid H, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411823
   Rooksby J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300655
   Saeb S, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4273
   Sartini C, 2015, BMC PUBLIC HEALTH, V15, DOI 10.1186/s12889-015-1976-y
   Sharmin M, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P505, DOI 10.1145/2750858.2807537
   Shen ZQ, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P175
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Singh VK, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P646, DOI 10.1145/2971648.2971755
   Snooks K., 2021, CONTEXT AWARE WEARAB
   Tong CX, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290734
   Torous J., 2019, Journal of Technology in Behavioral Science, V4, P73, DOI DOI 10.1007/S41347-019-00095-W
   Torquati L, 2019, AM J PUBLIC HEALTH, V109, pE13, DOI 10.2105/AJPH.2019.305278
   Vaizman Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174128
   Vaizman Y, 2017, IEEE PERVAS COMPUT, V16, P62, DOI 10.1109/MPRV.2017.3971131
   van Berkel N., 2020, HUMAN ACCURACY MOBIL
   Van Berkel N, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3123988
   Van Someren MW, 1994, AcademicPress
   Vaughn J, 2021, J AM MED INFORM ASSN, V28, P1518, DOI 10.1093/jamia/ocab037
   Vetter C, 2020, EUR J NEUROSCI, V51, P531, DOI 10.1111/ejn.14255
   Wagner M, 2019, IEEE T VIS COMPUT GR, V25, P1528, DOI 10.1109/TVCG.2017.2785271
   Wang R., 2017, MOBILE HLTH, P7, DOI DOI 10.1007/978-3-319-51394-2_2.
   Wang R, 2020, INT CONF PERVAS COMP, DOI 10.1109/percom45495.2020.9127365
   Wang R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P3, DOI 10.1145/2632048.2632054
   Waring OM, 2020, LEVERAGING DATA SCI, P251, DOI 10.1007/978-3-030-47994-7_15
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhao YB, 2017, J VISUAL-JAPAN, V20, P405, DOI 10.1007/s12650-016-0402-6
   Zhao YB, 2016, IET NETW, V5, P114, DOI 10.1049/iet-net.2015.0113
   Zhao YB, 2016, LECT NOTES COMPUT SC, V9654, P380, DOI 10.1007/978-3-319-40259-8_33
NR 91
TC 2
Z9 2
U1 3
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 13
EP 29
DI 10.1016/j.visinf.2023.01.002
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA M9OG0
UT WOS:001033427800001
OA gold
DA 2024-07-18
ER

PT J
AU Li, R
   Jia, XF
   Zhou, CL
   Zhang, JS
AF Li, Rui
   Jia, Xiaofei
   Zhou, Changle
   Zhang, Junsong
TI Reconfiguration of the brain during aesthetic experience on Chinese
   calligraphy-Using brain complex networks
SO VISUAL INFORMATICS
LA English
DT Article
DE Chinese calligraphy; Aesthetic experience; Electroencephalogram; Brain
   functional connectivity; Complex network
ID PREFRONTAL CORTEX; APPRECIATION; CONNECTIVITY; PERCEPTION; MEMORY;
   INTEGRATION; VALUATION; PAINTINGS; EMOTION; MUSIC
AB Chinese calligraphy, as a well-known performing art form, occupies an important role in the intangible cultural heritage of China. Previous studies focused on the psychophysiological benefits of Chinese calligraphy. Little attention has been paid to its aesthetic attributes and effectiveness on the cognitive process. To complement our understanding of Chinese calligraphy, this study investigated the aesthetic experience of Chinese cursive-style calligraphy using brain functional network analysis. Subjects stayed on the coach and rested for several minutes. Then, they were requested to appreciate artwork of cursive-style calligraphy. Results showed that (1) changes in functional connectivity between frontooccipital, fronto-parietal, bilateral parietal, and central-occipital areas are prominent for calligraphy condition, (2) brain functional network showed an increased normalized cluster coefficient for calligraphy condition in alpha2 and gamma bands. These results demonstrate that the brain functional network undergoes a dynamic reconfiguration during the aesthetic experience of Chinese calligraphy. Providing evidence that the aesthetic experience of Chinese calligraphy has several similarities with western art while retaining its unique characters as an eastern traditional art form. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Li, Rui] Cent China Normal Univ, Natl Engn Lab Educ Big Data, Wuhan, Hubei, Peoples R China.
   [Li, Rui; Jia, Xiaofei; Zhou, Changle; Zhang, Junsong] Xiamen Univ, Sch Informat, Dept Artificial Intelligence, Mind Art & Computat Grp, Xiamen, Peoples R China.
   [Zhou, Changle; Zhang, Junsong] Minist Culture & Tourism, Key Lab Digital Protect & Intelligent Proc Intang, Xiamen, Peoples R China.
   [Jia, Xiaofei] Qufu Normal Univ, Ctr Study Brain & Language, Rizhao, Peoples R China.
   [Jia, Xiaofei] Univ Haifa, Fac Educ, Edmond J Safra Brain Res Ctr Study Learning Disab, Haifa, Israel.
C3 Central China Normal University; Xiamen University; Qufu Normal
   University; University of Haifa
RP Zhang, JS (corresponding author), Xiamen Univ, Sch Informat, Dept Artificial Intelligence, Mind Art & Computat Grp, Xiamen, Peoples R China.
EM leerui@mail.ccnu.edu.cn; jxiaofei2008@126.com; dozero@xmu.edu.cn;
   zhangjs@xmu.edu.cn
RI Zhou, CL/G-4667-2010; Zhang, JunSong/HTQ-4981-2023; Zhang,
   Junsong/HKW-6976-2023
FU National Natural Science Foundation of China [61772440, 62007016]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61772440, Grant No. 62007016).
CR Avena-Koenigsberger A, 2018, NAT REV NEUROSCI, V19, P17, DOI 10.1038/nrn.2017.149
   Baihua Z, 2003, STROLLING AESTHETIC
   Bao Y, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01596
   Bhattacharya J, 2002, COGNITIVE BRAIN RES, V13, P179, DOI 10.1016/S0926-6410(01)00110-0
   Brieber D, 2015, ACTA PSYCHOL, V154, P36, DOI 10.1016/j.actpsy.2014.11.004
   Bullmore ET, 2012, NAT REV NEUROSCI, V13, P336, DOI 10.1038/nrn3214
   Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575
   Calvo-Merino B, 2008, CONSCIOUS COGN, V17, P911, DOI 10.1016/j.concog.2007.11.003
   Cattaneo Z, 2015, BRAIN COGNITION, V95, P44, DOI 10.1016/j.bandc.2015.01.008
   Cattaneo Z, 2014, NEUROIMAGE, V99, P443, DOI 10.1016/j.neuroimage.2014.05.037
   Cela-Conde CJ, 2013, P NATL ACAD SCI USA, V110, P10454, DOI 10.1073/pnas.1302855110
   Chan SCC, 2017, J ALZHEIMERS DIS, V58, P735, DOI 10.3233/JAD-170024
   Chatterjee A, 2016, ANN NY ACAD SCI, V1369, P172, DOI 10.1111/nyas.13035
   Chatterjee A, 2014, TRENDS COGN SCI, V18, P370, DOI 10.1016/j.tics.2014.03.003
   Chen W, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214917
   Chen W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170660
   Cheung MC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115112
   Chiang Y., 1973, Chinese calligraphy: An introduction to its aesthetic and technique, V60
   Chu KY, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-018-1611-4
   Deco G, 2015, NAT REV NEUROSCI, V16, P430, DOI 10.1038/nrn3963
   Di Dio C, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00705
   Dubal S, 2014, EMPIR STUD ARTS, V32, P27, DOI 10.2190/EM.32.1.EOV.4
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Ferrari C, 2017, SOC COGN AFFECT NEUR, V12, P707, DOI 10.1093/scan/nsx002
   Fillinger MG, 2020, EMPIR STUD ARTS, V38, P172, DOI 10.1177/0276237418805656
   Fong Wen C, 1999, MUSEUM PUA MUSEUM SA, P29
   Freedberg D, 2007, TRENDS COGN SCI, V11, P197, DOI 10.1016/j.tics.2007.02.003
   Gernot G, 2018, COGN PROCESS, V19, P147, DOI 10.1007/s10339-017-0800-2
   Gershoni S, 2011, I-PERCEPTION, V2, P508, DOI 10.1068/i0472aap
   Greene CM, 2014, COGN AFFECT BEHAV NE, V14, P1327, DOI 10.3758/s13415-014-0266-y
   Gunn RW, 2001, J RELIG HEALTH, V40, P129, DOI 10.1023/A:1012594508918
   Herrmann CS, 2004, TRENDS COGN SCI, V8, P347, DOI 10.1016/j.tics.2004.06.006
   Hoenen M, 2017, BIOL PSYCHOL, V124, P57, DOI 10.1016/j.biopsycho.2017.01.010
   Hutchison RM, 2013, NEUROIMAGE, V80, P360, DOI 10.1016/j.neuroimage.2013.05.079
   Jacobsen T, 2006, NEUROIMAGE, V29, P276, DOI 10.1016/j.neuroimage.2005.07.010
   Jacobsen T, 2017, NEW IDEAS PSYCHOL, V47, P97, DOI 10.1016/j.newideapsych.2017.03.008
   Kao HSR, 2006, INT J PSYCHOL, V41, P282, DOI 10.1080/00207590544000059
   Kao HSR, 2012, ASIA PAC J COUNS PSY, V3, P190, DOI 10.1080/21507686.2012.703443
   Katsuki F, 2012, NAT NEUROSCI, V15, P1160, DOI 10.1038/nn.3164
   Koyama MS, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00249
   Leder H, 2014, BRIT J PSYCHOL, V105, P443, DOI 10.1111/bjop.12084
   Li R, 2015, BRAIN RES, V1598, P57, DOI 10.1016/j.brainres.2014.11.055
   Mastandrea S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00739
   Nadal M, 2013, PROG BRAIN RES, V204, P135, DOI 10.1016/B978-0-444-63287-6.00007-5
   Nakata Y., 1973, ART JAPANESE CALLIGR
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Pantazatos SP, 2012, BRAIN CONNECT, V2, P164, DOI 10.1089/brain.2012.0072
   Redies C, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00218
   Sarasso P, 2020, NEUROPSYCHOLOGIA, V136, DOI 10.1016/j.neuropsychologia.2019.107282
   Shusterman R, 2018, ROUTL ADV THEATR PER, P83
   Stam CJ, 2002, PHYSICA D, V163, P236, DOI 10.1016/S0167-2789(01)00386-4
   Tan LH, 2005, HUM BRAIN MAPP, V25, P83, DOI 10.1002/hbm.20134
   Ticini LF., 2015, Aesthetics and the embodied mind: Beyond art theory and the Cartesian mind-body dichotomy, P103, DOI [DOI 10.1007/978-94-017-9379-7_7, 10.1007/978-94-017-9379-7_7]
   Umilta' MA, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00311
   Vartanian O, 2014, BRAIN COGNITION, V87, P52, DOI 10.1016/j.bandc.2014.03.004
   Volke HJ, 2002, J PSYCHOPHYSIOL, V16, P23, DOI 10.1027//0269-8803.16.1.23
   von Stein A, 2000, INT J PSYCHOPHYSIOL, V38, P301, DOI 10.1016/S0167-8760(00)00172-0
   Wang L, 2012, 2012 18 INT C VIRTUA, P87, DOI [10.1109/VSMM.2012.6365911, DOI 10.1109/VSMM.2012.6365911]
   Waskom ML, 2014, J NEUROSCI, V34, P10743, DOI 10.1523/JNEUROSCI.5282-13.2014
   Wilson D. J., 2012, CAVITY OPTOMECHANICS
   Wu J, 2013, NEUROSCIENCE, V250, P49, DOI 10.1016/j.neuroscience.2013.06.021
   Xu M, 2013, EVID-BASED COMPL ALT, V2013, DOI 10.1155/2013/975190
   Yu JH, 2005, COMPUT GRAPH-UK, V29, P145, DOI 10.1016/j.cag.2004.11.013
   Zamm A, 2013, NEUROIMAGE, V74, P359, DOI 10.1016/j.neuroimage.2013.02.024
   Zhang JX, 2012, CHINESE SCI BULL, V57, P1516, DOI 10.1007/s11434-011-4932-y
   Zhou AB, 2016, J NEUROLINGUIST, V39, P57, DOI 10.1016/j.jneuroling.2016.03.001
   Zhu YM, 2014, LEONARDO, V47, P294, DOI 10.1162/LEON_a_00785
NR 67
TC 5
Z9 5
U1 5
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 6
IS 1
BP 35
EP 46
DI 10.1016/j.visinf.2022.02.002
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2S0ZC
UT WOS:000821528800004
OA gold
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Yang, ZY
   Jiang, S
   Zhu, T
   Ma, SX
   Li, YH
   Zhuo, J
AF Zhou, Zeyang
   Yang, Zhiyong
   Jiang, Shan
   Zhu, Tao
   Ma, Shixing
   Li, Yuhua
   Zhuo, Jie
TI Design and validation of a navigation system of multimodal medical
   images for neurosurgery based on mixed reality
SO VISUAL INFORMATICS
LA English
DT Article
DE Augmented reality; Neurosurgery; Image-guided intervention; Multimodal
   images
ID CT ANGIOGRAPHY; BONE
AB Purpose: This paper aims to develop a navigation system based on mixed reality, which can display multimodal medical images in an immersive environment and help surgeons locate the target area and surrounding important tissues precisely.Methods: To be displayed properly in mixed reality, medical images are processed in this system. High-quality cerebral vessels and nerve fibers with proper colors are reconstructed and exported to mixed reality environment. Multimodal images and models are registered and fused, extracting their key information. The multiple processed images are fused with the real patient in the same coordinate system to guide the surgery.Results: The multimodal image system is designed and validated properly. In phantom experiments, the average error of preoperative registration is 1.003 mm and the standard deviation is 0.096 mm. The average proportion of well-registered areas is 94.9%. In patient experiments, the surgeons who participated in the experiments generally indicated that the system had excellent performance and great application prospect for neurosurgery.Conclusion: This article proposes a navigation system of multimodal images for neurosurgery based on mixed reality. Compared with other navigation methods, this system can help surgeons locate the target area and surrounding important tissues more precisely and rapidly.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Zhou, Zeyang; Yang, Zhiyong; Jiang, Shan; Zhu, Tao; Ma, Shixing; Li, Yuhua] Tianjin Univ, Sch Mech Engn, Tianjin 300350, Peoples R China.
   [Zhuo, Jie] Tianjin Huanhu Hosp, Dept Neurosurg, Tianjin 300200, Peoples R China.
   [Jiang, Shan] Tianjin Univ, Ctr Adv Mech & Robot, 135 Yaguan Rd,Jinnan Dist, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Jiang, S (corresponding author), Tianjin Univ, Ctr Adv Mech & Robot, 135 Yaguan Rd,Jinnan Dist, Tianjin, Peoples R China.
EM shanjmri@tju.edu.cn
RI Zhou, Zeyang/AAX-9853-2020
FU National Key R and D Program of China [2022YFB4702600, 2022YFB4702601];
   Inno-vation Foundation for Postgraduate of Tianjin, China [2022BKY063,
   2022SKY046]
FX Acknowledgments This work was supported by the National Key R and D
   Program of China (No. 2022YFB4702600, 2022YFB4702601) , and the
   Inno-vation Foundation for Postgraduate of Tianjin, China (Grant No.
   2022BKY063, No. 2022SKY046) .
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bova FJ, 2013, NEUROSURGERY, V73, P138, DOI 10.1227/NEU.0000000000000113
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Danilov G, 2020, STUD HEALTH TECHNOL, V270, P382, DOI 10.3233/SHTI200187
   Drouin S., 2017, INT
   Fan XY, 2015, J NEUROSURG, V123, P721, DOI 10.3171/2014.12.JNS141321
   Garyfallidis E, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00008
   Ghimire P, 2018, NEUROSURGERY, V83, P622, DOI 10.1093/neuros/nyx547
   Incekara F, 2018, WORLD NEUROSURG, V118, pE422, DOI 10.1016/j.wneu.2018.06.208
   Kiljae A., 2019, STUDY ARCHITECTURE M, P48
   Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616
   Kress BC, 2017, PROC SPIE, V10335, DOI 10.1117/12.2270017
   Lell M, 2006, EUR RADIOL, V16, P889, DOI 10.1007/s0330-005-0032-1
   Li K, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.608403
   Li YQ, 2021, TRANSL STROKE RES, V12, P1035, DOI 10.1007/s12975-021-00893-6
   Maruyama K, 2018, OPER NEUROSURG, V15, P551, DOI 10.1093/ons/opx279
   Mert A, 2012, NEUROSURGERY, V71, P286, DOI 10.1227/NEU.0b013e31826a8a75
   Mongen MA, 2019, ACTA NEUROCHIR, V161, P865, DOI 10.1007/s00701-019-03867-8
   Prada F, 2020, CLIN NEUROL NEUROSUR, V198, DOI 10.1016/j.clineuro.2020.106188
   Renfrow JJ, 2016, J NEUROSURG, V124, P834, DOI 10.3171/2015.3.JNS142313
   Schipmann-Miletic Stephanie, 2020, Recent Results Cancer Res, V216, P813, DOI 10.1007/978-3-030-42618-7_26
   Shamonin DP, 2014, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00050
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   van Straten M, 2004, MED PHYS, V31, P2924, DOI 10.1118/1.1797511
   William L., 1987, MARCHING CUBESA HIGH, V21, P163, DOI [10.1145/37402.37422, DOI 10.1145/37402.37422]
   Xu B, 2020, SPINE, V45, pE1627, DOI 10.1097/BRS.0000000000003666
   Zhou ZY, 2019, MED PHYS, V46, P3709, DOI 10.1002/mp.13645
NR 27
TC 0
Z9 0
U1 3
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 64
EP 71
DI 10.1016/j.visinf.2023.05.003
EA JUN 2023
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA M2XJ2
UT WOS:001028856800001
OA gold
DA 2024-07-18
ER

PT J
AU He, WB
   Wang, JP
   Guo, HQ
   Shen, HW
   Peterka, T
AF He, Wenbin
   Wang, Junpeng
   Guo, Hanqi
   Shen, Han-Wei
   Peterka, Tom
TI CECAV-DNN: Collective Ensemble Comparison and Visualization using Deep
   Neural Networks
SO VISUAL INFORMATICS
LA English
DT Article
DE Collective ensemble comparison; Ensemble data visualization; Deep neural
   networks
ID VISUAL ANALYSIS; UNCERTAINTY QUANTIFICATION; NONPARAMETRIC MODELS;
   VARIABILITY; PLOTS
AB We propose a deep learning approach to collectively compare two or multiple ensembles, each of which is a collection of simulation outputs. The purpose of collective comparison is to help scientists understand differences between simulation models by comparing their ensemble simulation outputs. However, the collective comparison is non-trivial because the spatiotemporal distributions of ensemble simulation outputs reside in a very high dimensional space. To this end, we choose to train a deep discriminative neural network to measure the dissimilarity between two given ensembles, and to identify when and where the two ensembles are different. We also design and develop a visualization system to help users understand the collective comparison results based on the discriminative network. We demonstrate the effectiveness of our approach with two real-world applications, including the ensemble comparison of the community atmosphere model (CAM) and the rapid radiative transfer model for general circulation models (RRTMG) for climate research, and the comparison of computational fluid dynamics (CFD) ensembles with different spatial resolutions. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [He, Wenbin; Shen, Han-Wei] Ohio State Univ, Columbus, OH 43210 USA.
   [Wang, Junpeng] Visa Res, Palo Alto, CA USA.
   [Guo, Hanqi; Peterka, Tom] Argonne Natl Lab, Lemont, IL USA.
C3 University System of Ohio; Ohio State University; United States
   Department of Energy (DOE); Argonne National Laboratory
RP He, WB (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM he.495@osu.edu; junpenwa@visa.com; hguo@anl.gov; shen.94@osu.edu;
   tpeterka@anl.gov
RI Guo, Hanqi/AAL-1929-2021; Shen, Han-wei/A-4710-2012
OI Guo, Hanqi/0000-0001-7776-1834; 
FU US Department of Energy Los Alamos National Laboratory [47145];
   UT-Battelle LLC [4000159447]
FX This work was supported in part by US Department of Energy Los Alamos
   National Laboratory contract 47145 and UT-Battelle LLC contract
   4000159447 program manager Laura Biven.
CR Alabi O.S., 2012, VISUALIZATION DATA A, V8294, P1
   [Anonymous], 2013, ANAL LONGITUDINAL DA
   [Anonymous], 2013, EUROVIS SHORT PAPERS
   Arjovsky M., 2017, WASSERSTEIN GAN
   Athawale T, 2016, IEEE T VIS COMPUT GR, V22, P777, DOI 10.1109/TVCG.2015.2467958
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Bensema K, 2016, IEEE T VIS COMPUT GR, V22, P2289, DOI 10.1109/TVCG.2015.2507569
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chen HD, 2015, IEEE T VIS COMPUT GR, V21, P1072, DOI 10.1109/TVCG.2015.2410278
   Chwialkowski Kacper, 2015, ADV NEURAL INFORM PR, P1981
   Demir I, 2016, IEEE PAC VIS SYMP, P204, DOI 10.1109/PACIFICVIS.2016.7465271
   Dutta S, 2017, IEEE PAC VIS SYMP, P111, DOI 10.1109/PACIFICVIS.2017.8031585
   Dutta S, 2017, IEEE T VIS COMPUT GR, V23, P811, DOI 10.1109/TVCG.2016.2598604
   Dutta S, 2016, IEEE T VIS COMPUT GR, V22, P837, DOI 10.1109/TVCG.2015.2467436
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gosink L, 2013, IEEE T VIS COMPUT GR, V19, P2703, DOI 10.1109/TVCG.2013.138
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Guo HQ, 2016, IEEE T VIS COMPUT GR, V22, P1672, DOI 10.1109/TVCG.2016.2534560
   Hazarika S, 2018, IEEE T VIS COMPUT GR, V24, P934, DOI 10.1109/TVCG.2017.2744099
   He WB, 2017, IEEE PAC VIS SYMP, P151, DOI 10.1109/PACIFICVIS.2017.8031589
   Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478
   Hlawatsch M, 2011, IEEE T VIS COMPUT GR, V17, P1949, DOI 10.1109/TVCG.2011.203
   Höllt T, 2014, IEEE T VIS COMPUT GR, V20, P1114, DOI 10.1109/TVCG.2014.2307892
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   Im D.J, 2018, P INT C LEARN REPR
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jarema M, 2015, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2015.7347634
   Jitkrittum W., 2016, Advances in Neural Information Processing Systems, P181
   Kehrer J, 2011, IEEE T VIS COMPUT GR, V17, P934, DOI 10.1109/TVCG.2010.111
   King DB, 2015, ACS SYM SER, V1214, P1
   Köthur P, 2015, COMPUT GRAPH FORUM, V34, P411, DOI 10.1111/cgf.12653
   Kumpf A, 2018, IEEE T VIS COMPUT GR, V24, P109, DOI 10.1109/TVCG.2017.2745178
   Lopez-Paz D, 2016, ARXIV PREPRINT ARXIV
   Lu KW, 2013, IEEE PAC VIS SYMP, P257, DOI 10.1109/PacificVis.2013.6596153
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Moon K.R, 2014, ARXIV PREPRINT ARXIV
   Muller A, 1997, ADV APPL PROBAB, V29, P429, DOI 10.2307/1428011
   Nguyen XL, 2010, IEEE T INFORM THEORY, V56, P5847, DOI 10.1109/TIT.2010.2068870
   Nowozin S., 2016, Advances in Neural Information Processing Systems, P271
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Phadke MN, 2012, PROC SPIE, V8294, DOI 10.1117/12.912419
   Poczos Barnabas, 2011, P 14 INT C ART INT S, P609
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Pöthkow K, 2011, IEEE T VIS COMPUT GR, V17, P1393, DOI 10.1109/TVCG.2010.247
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Radford A., 2015, ARXIV
   Raj M, 2016, IEEE COMPUT GRAPH, V36, P60, DOI 10.1109/MCG.2015.70
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Sakhaee E, 2017, IEEE T VIS COMPUT GR, V23, P2509, DOI 10.1109/TVCG.2016.2637333
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Schneider J.G., 2012, ARXIV PREPRINT ARXIV
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Sriperumbudur BK, 2010, IEEE INT SYMP INFO, P1428, DOI 10.1109/ISIT.2010.5513626
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wang Q, 2009, IEEE T INFORM THEORY, V55, P2392, DOI 10.1109/TIT.2009.2016060
   Wei TH, 2017, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2017.8031586
   Wei TH, 2015, COMPUT GRAPH FORUM, V34, P81, DOI 10.1111/cgf.12620
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Yang B, 2012, ATMOS CHEM PHYS, V12, P2409, DOI 10.5194/acp-12-2409-2012
NR 66
TC 7
Z9 9
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2020
VL 4
IS 2
SI SI
BP 109
EP 121
DI 10.1016/j.visinf.2020.04.004
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KK
UT WOS:000658192100005
OA gold
DA 2024-07-18
ER

PT J
AU Firat, EE
   Swallow, B
   Laramee, RS
AF Firat, Elif E.
   Swallow, Ben
   Laramee, Robert S.
TI PCP-Ed: Parallel coordinate plots for ensemble data
SO VISUAL INFORMATICS
LA English
DT Article
DE Parallel coordinates; Overplotting; Ensemble data
ID CLUTTER REDUCTION
AB The Parallel Coordinate Plot (PCP) is a complex visual design commonly used for the analysis of high-dimensional data. Increasing data size and complexity may make it challenging to decipher and uncover trends and outliers in a confined space. A dense PCP image resulting from overlapping edges may cause patterns to be covered. We develop techniques aimed at exploring the relationship between data dimensions to uncover trends in dense PCPs. We introduce correlation glyphs in the PCP view to reveal the strength of the correlation between adjacent axis pairs as well as an interactive glyph lens to uncover links between data dimensions by investigating dense areas of edge intersections. We also present a subtraction operator to identify differences between two similar multivariate data sets and relationship-guided dimensionality reduction by collapsing axis pairs. We finally present a case study of our techniques applied to ensemble data and provide feedback from a domain expert in epidemiology. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Firat, Elif E.; Laramee, Robert S.] Univ Nottingham, Nottingham, England.
   [Swallow, Ben] Univ Glasgow, Glasgow, Scotland.
C3 University of Nottingham; University of Glasgow
RP Firat, EE (corresponding author), Univ Nottingham, Nottingham, England.
EM elifemelfirat@gmail.com
RI Firat, Elif E/HKE-7954-2023; Swallow, Ben/B-8955-2017
OI Firat, Elif E/0000-0001-9497-7928; Swallow, Ben/0000-0002-0227-2160;
   Laramee, Robert S/0000-0002-3874-6145
FU EPSRC Grant EPSRC [EP/S01-0238/2]; Ministry of Education of the Turkish
   Republic; COVID [EP/V054236/1] Funding Source: UKRI
FX Acknowledgments This research was funded in part by EPSRC Grant EPSRC
   EP/S01-0238/2. We would also like to thank the Ministry of Education of
   the Turkish Republic for their financial support.
CR Andrienko G, 2004, SECOND INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P93
   Artero AO, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P81, DOI 10.1109/INFVIS.2004.68
   Blaas J, 2008, IEEE T VIS COMPUT GR, V14, P1436, DOI 10.1109/TVCG.2008.131
   Blumenschein M, 2020, COMPUT GRAPH FORUM, V39, P537, DOI 10.1111/cgf.14000
   BOLLEN KA, 1981, AM SOCIOL REV, V46, P232, DOI 10.2307/2094981
   Borgo R., 2013, EUROGRAPHICS STARS, P39, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Dasgupta A, 2012, COMPUT GRAPH FORUM, V31, P1015, DOI 10.1111/j.1467-8659.2012.03094.x
   Divino RSA, 2017, IEEE INT CON INF VIS, P90, DOI 10.1109/iV.2017.29
   EERA, 2022, COV 19 EERA MOD
   Ellis G, 2007, IEEE T VIS COMPUT GR, V13, P1216, DOI 10.1109/TVCG.2007.70535
   Ellis G, 2006, IEEE T VIS COMPUT GR, V12, P717, DOI 10.1109/TVCG.2006.138
   Firat EE, 2022, VIS INFORM, V6, P81, DOI 10.1016/j.visinf.2022.05.002
   Fuchs J, 2017, IEEE T VIS COMPUT GR, V23, P1863, DOI 10.1109/TVCG.2016.2549018
   Geng Z, 2011, IEEE T VIS COMPUT GR, V17, P2572, DOI 10.1109/TVCG.2011.166
   Heinrich Julian, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P594
   Heinrich J., 2013, EUROGRAPHICS 2013 ST, DOI DOI 10.2312/CONF/EG2013/STARS/095-116
   Hogan T, 2016, IEEE T VIS COMPUT GR, V22, P2579, DOI 10.1109/TVCG.2015.2511718
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Johansson J., 2006, Information Visualization, V5, P125, DOI 10.1057/palgrave.ivs.9500117
   Johansson J, 2016, IEEE T VIS COMPUT GR, V22, P579, DOI 10.1109/TVCG.2015.2466992
   Koc K, 2022, INFORM VISUAL, V21, P74, DOI 10.1177/14738716211050602
   Lhuillier A, 2017, COMPUT GRAPH FORUM, V36, P619, DOI 10.1111/cgf.13213
   Lind M, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P25, DOI 10.1109/IV.2009.43
   McDonnell KT, 2008, COMPUT GRAPH FORUM, V27, P1031, DOI 10.1111/j.1467-8659.2008.01239.x
   Palmas G., 2016, EUROVIS 2016 SHORT P, P61, DOI DOI 10.2312/EUROVISSHORT.20161162
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Pomerenke D, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P86, DOI [10.1109/visual.2019.8933706, 10.1109/VISUAL.2019.8933706]
   Raidou RG, 2016, IEEE T VIS COMPUT GR, V22, P589, DOI 10.1109/TVCG.2015.2467872
   RAMP, 2020, RAMP VIS VIS VIS AN
   Roberts RC., 2018, P C COMPUTER GRAPHIC, P135, DOI [10.2312cgvc.20181218, DOI 10.2312/CGVC.20181218]
   Roberts RC, 2019, IEEE T VIS COMPUT GR, V25, P1575, DOI 10.1109/TVCG.2018.2808969
   Rosenbaum R, 2012, IEEE PAC VIS SYMP, P25, DOI 10.1109/PacificVis.2012.6183570
   SCRC, 2022, SCOTT COV 19 RESP CO
   Siirtola H, 2000, IEEE INFOR VIS, P373, DOI 10.1109/IV.2000.859784
   Video, 2022, DEM VID
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wu HY, 2017, IEEE PAC VIS SYMP, P305, DOI 10.1109/PACIFICVIS.2017.8031609
   Ying-Huey Fua, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P43, DOI 10.1109/VISUAL.1999.809866
   Zhou H, 2008, COMPUT GRAPH FORUM, V27, P1047, DOI 10.1111/j.1467-8659.2008.01241.x
NR 39
TC 2
Z9 2
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2023
VL 7
IS 1
BP 56
EP 65
DI 10.1016/j.visinf.2022.10.003
EA APR 2023
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA F2LM7
UT WOS:000980711700001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Zhu, SY
   Wang, XJ
   Wang, M
   Wang, YC
   Wei, ZQ
   Yin, B
   Jin, XG
AF Zhu, Siyuan
   Wang, Xinjie
   Wang, Ming
   Wang, Yucheng
   Wei, Zhiqiang
   Yin, Bo
   Jin, Xiaogang
TI Example-based large-scale marine scene authoring using Wang Cubes
SO VISUAL INFORMATICS
LA English
DT Article
DE Wang Cubes; Marine scene authoring; Virtual environments
AB Virtual marine scene authoring plays an important role in generating large-scale 3D scenes and it has a wide range of applications in computer animation and simulation. Existing marine scene authoring methods either produce periodic patterns or generate unnatural group distributions when tiling marine entities such as schools of fish and groups of reefs. To this end, we propose a new large-scale marine scene authoring method based on real examples in order to create more natural and realistic results. Our method first extracts the distribution of multiple marine entities from real images to create Octahedral Blocks, and then we use a modified Wang Cubes algorithm to quickly tile the 3D marine scene. As a result, our method is able to generate aperiodic tiling results with diverse distributions of density and orientation of entities. We validate the effectiveness of our method through intensive comparative experiments. User study results show that our method can generate satisfactory results which are in accord with human preferences.
   (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by- nc- nd/4.0/).
C1 [Zhu, Siyuan; Wang, Xinjie; Wei, Zhiqiang; Yin, Bo] Ocean Univ China, Qingdao 266100, Shandong, Peoples R China.
   [Wang, Ming; Wang, Yucheng] Pilot Natl Lab Marine Sci & Technol Qingdao, Qingdao 266237, Shandong, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Ocean University of China; Laoshan Laboratory; Zhejiang University
RP Wang, XJ (corresponding author), Ocean Univ China, Qingdao 266100, Shandong, Peoples R China.
EM zhusiyuan@stu.ouc.edu.cn; wangxinjie@ouc.edu.cn; mwang@qnlm.ac;
   ycwang@qnlm.ac; weizhigiang@ouc.edu.cn; ybfirst@ouc.edu.cn;
   jin@zju.edu.cn
RI wei, zhiqiang/M-8868-2013
OI /0000-0003-3157-7358
FU Shandong Provincial Natural Science Foundation of China [ZR2021QF124];
   China Postdoctoral Science Foundation [2021M703031]; Qingdao
   Postdoctoral Applied Research Foundation, China; Open Project Program of
   the State Key Lab of CAD&CG, Zhejiang University [A2219]; National
   Natural Science Foundation of China [62036010]; National Key Research
   and Development Program of China [2020YFB0204804]
FX Xinjie Wang was supported by the Shandong Provincial Natural Science
   Foundation of China (Grant No. ZR2021QF124), China Postdoctoral Science
   Foundation (Grant No. 2021M703031), Qingdao Postdoctoral Applied
   Research Foundation, China, and the Open Project Program of the State
   Key Lab of CAD&CG (Grant No. A2219), Zhejiang University. Xiaogang Jin
   was supported by the National Natural Science Foundation of China (Grant
   No. 62036010). Yucheng Wang was supported by the National Key Research
   and Development Program of China (Grant No. 2020YFB0204804).
CR Alaliyat S., 2014, ECMS, P643
   Berger R, 1966, UNDECIDABILITY DOMIN, DOI [10.1007/978-3-030-57666-0_6, DOI 10.1007/978-3-030-57666-0_6]
   Bi H., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P149
   Chao QW, 2018, IEEE T VIS COMPUT GR, V24, P1167, DOI 10.1109/TVCG.2017.2648790
   Chao QW, 2013, GRAPH MODELS, V75, P305, DOI 10.1016/j.gmod.2013.07.003
   Chen Q, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1902
   Chen YR, 2022, PHYSICA A, V586, DOI 10.1016/j.physa.2021.126415
   Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265
   Culik K., 1996, J UCS J U COMPUT SCI, P675, DOI DOI 10.1007/978-3-642-80350-5_57
   Derouet-Jourdan A., 2016, MATH PROGR EXPRESSIV, V3, P71, DOI [10.1007/978-981-10-1076-7_9, DOI 10.1007/978-981-10-1076-7_9]
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Ginelli F, 2016, EUR PHYS J-SPEC TOP, V225, P2099, DOI 10.1140/epjst/e2016-60066-8
   Hartman C, 2006, COMPUT ANIMAT VIRT W, V17, P199, DOI 10.1002/cav.123
   Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108
   Iizuka H, 2018, 2018 CONFERENCE ON ARTIFICIAL LIFE (ALIFE 2018), P179
   Inomata Yoshinari, 2020, Traffic and Granular Flow 2019. Springer Proceedings in Physics (SPPHY 252), P373, DOI 10.1007/978-3-030-55973-1_46
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Kim S, 2016, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2016.7504685
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Li WZ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130847
   Lin XY, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P146, DOI 10.1109/ITNEC.2017.8284926
   Lu A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243985
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Paranjape AA, 2018, IEEE T ROBOT, V34, P901, DOI 10.1109/TRO.2018.2853610
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Ren JP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155698
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   [申晶晶 Shen Jingjing], 2014, [计算机学报, Chinese Journal of Computers], V37, P621
   Sibley P.G., 2004, P SIGGRAPH 04 ACM SI, P20, DOI DOI 10.1145/1186415.1186439
   Silva ARD., 2010, COMPUT ENTERTAIN, V7, P1, DOI DOI 10.1145/1658866.1658870
   Snape J, 2011, IEEE T ROBOT, V27, P696, DOI 10.1109/TRO.2011.2120810
   Stam Jos., 1997, APERIODIC TEXTURE MA
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
   VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226
   WANG H, 1961, AT&T TECH J, V40, P1
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Xiang W, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1957
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461968
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zhang SH, 2022, IEEE T VIS COMPUT GR, V28, P3082, DOI 10.1109/TVCG.2021.3050143
   Zhang SH, 2019, J COMPUT SCI TECH-CH, V34, P594, DOI 10.1007/s11390-019-1929-5
   Zhou Shu-bo, 2015, Journal of Guangdong University of Technology, V32, P99, DOI 10.3969/j.issn.1007-7162.2015.04.018
NR 44
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2022
VL 6
IS 3
BP 23
EP 34
DI 10.1016/j.visinf.2022.05.004
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6M5IA
UT WOS:000888899400003
OA gold
DA 2024-07-18
ER

PT J
AU Wang, L
   Sun, GD
   Wang, YC
   Ma, J
   Zhao, XM
   Liang, RH
AF Wang, Lei
   Sun, Guodao
   Wang, Yunchao
   Ma, Ji
   Zhao, Xiaomin
   Liang, Ronghua
TI AFExplorer: Visual analysis and interactive selection of audio features
SO VISUAL INFORMATICS
LA English
DT Article
DE Audio data; Interactive feature selection; Visual analytics;
   Visualization systems and tools
ID FEATURE-EXTRACTION
AB Acoustic quality detection is vital in the manufactured products quality control field since it represents the conditions of machines or products. Recent work employed machine learning models in manufactured audio data to detect anomalous patterns. A major challenge is how to select applicable audio features to meliorate model's accuracy and precision. To relax this challenge, we extract and analyze three audio feature types including Time Domain Feature, Frequency Domain Feature, and Cepstrum Feature to help identify the potential linear and non-linear relationships. In addition, we design a visual analysis system, namely AFExplorer, to assist data scientists in extracting audio features and selecting potential feature combinations. AFExplorer integrates four main views to present detailed distribution and relevance of the audio features, which helps users observe the impact of features visually in the feature selection. We perform the case study with AFExplore according to the ToyADMOS and MIMII Dataset to demonstrate the usability and effectiveness of the proposed system. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wang, Lei; Sun, Guodao; Wang, Yunchao; Ma, Ji; Zhao, Xiaomin; Liang, Ronghua] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Technology
RP Sun, GD (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
EM guodao@zjut.edu.cn
RI liang, ronghua/H-4463-2012
FU National Key Research and Development Program of China [2020YFB1707700];
   National Natural Science Foundation of China [61972356, 62036009];
   Fundamental Research Funds for the Provincial Universities of Zhejiang,
   China [RF-A2020001]
FX This work is partly supported by National Key Research and Development
   Program of China (2020YFB1707700), National Natural Science Foundation
   of China (61972356, 62036009), and Fundamental Research Funds for the
   Provincial Universities of Zhejiang, China (RF-A2020001).
CR Agostini G, 2003, EURASIP J APPL SIG P, V2003, P5, DOI 10.1155/S1110865703210118
   [Anonymous], 2007, MIR MATLAB
   Artur E, 2019, COMPUT GRAPH-UK, V84, P160, DOI 10.1016/j.cag.2019.08.015
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Bogdanov D., 2013, P 14 INT SOC MUS INF, P493, DOI DOI 10.1145/2502081.2502229
   Brossier PM, 2006, MIREX 2006, P1
   Bullock Jamie., 2007, INT COMPUTER MUSIC C, V2007
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chiang LH, 2004, J PROCESS CONTR, V14, P143, DOI 10.1016/S0959-1524(03)00029-5
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Friendly M, 2002, AM STAT, V56, P316, DOI 10.1198/000313002533
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Guo D., 2003, Information Visualization, V2, P232, DOI 10.1057/palgrave.ivs.9500053
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hamel P., 2010, ISMIR, P339
   Hancer E, 2018, INFORM SCIENCES, V422, P462, DOI 10.1016/j.ins.2017.09.028
   Janssens O, 2016, J SOUND VIB, V377, P331, DOI 10.1016/j.jsv.2016.05.027
   Johansson S, 2009, IEEE T VIS COMPUT GR, V15, P993, DOI 10.1109/TVCG.2009.153
   Ke GL, 2017, ADV NEUR IN, V30
   Khurana U, 2018, AAAI CONF ARTIF INTE, P3407
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Koizumi Y, 2019, IEEE WORK APPL SIG, P313, DOI [10.1109/WASPAA.2019.8937164, 10.1109/waspaa.2019.8937164]
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   LEWIS DD, 1992, SPEECH AND NATURAL LANGUAGE, P212
   Liu CF, 2021, MULTIMED TOOLS APPL, V80, P7313, DOI 10.1007/s11042-020-09643-6
   MacEachren A, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P31, DOI 10.1109/INFVIS.2003.1249006
   Michalak K., 2006, International Journal of Applied Mathematics and Computer Science, P503
   Mierswa I, 2005, MACH LEARN, V58, P127, DOI 10.1007/s10994-005-5824-7
   Moffat D, 2015, INT CONF DIGIT AUDIO, P277
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   O'Brien RM, 2007, QUAL QUANT, V41, P673, DOI 10.1007/s11135-006-9018-6
   Palaniappan R, 2013, BIOCYBERN BIOMED ENG, V33, P129, DOI 10.1016/j.bbe.2013.07.001
   Peeters G., 2004, CUIDADO 1 PROJECT RE
   Purohit H., 2019, PROC 4 WORKSHOP DETE
   Randall RB, 2017, MECH SYST SIGNAL PR, V97, P3, DOI 10.1016/j.ymssp.2016.12.026
   Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438
   Sanchez A, 2018, EXPERT SYST APPL, V100, P182, DOI 10.1016/j.eswa.2018.01.054
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Sindhwani V, 2004, IEEE T NEURAL NETWOR, V15, P937, DOI 10.1109/TNN.2004.828772
   Sousa R, 2019, INT J ADV MANUF TECH, V103, P2377, DOI 10.1007/s00170-019-03597-2
   Sun Guodao, 2021, IEEE T BIG DATA, V1
   Sun X, 2013, KNOWL-BASED SYST, V37, P541, DOI 10.1016/j.knosys.2012.10.001
   Turkay C, 2011, IEEE T VIS COMPUT GR, V17, P2591, DOI 10.1109/TVCG.2011.178
   Wang JJ, 2018, J MANUF SYST, V48, P144, DOI 10.1016/j.jmsy.2018.01.003
   Wang YH, 2017, COMPUT GRAPH FORUM, V36, P401, DOI 10.1111/cgf.13197
   Xinhui Zhou, 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P559, DOI 10.1109/ASRU.2011.6163888
   Yang Yi, 2011, 22 INT JOINT C ARTIF
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhao JQ, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P161, DOI [10.1109/VISUAL.2019.8933619, 10.1109/visual.2019.8933619]
   Zheng F, 2001, J COMPUT SCI TECHNOL, V16, P582, DOI 10.1007/BF02943243
NR 51
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 6
IS 1
BP 47
EP 55
DI 10.1016/j.visinf.2022.02.003
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2S0ZC
UT WOS:000821528800005
OA gold
DA 2024-07-18
ER

PT J
AU Maciejewski, R
   Ma, YX
   Lukasczyk, J
AF Maciejewski, Ross
   Ma, Yuxin
   Lukasczyk, Jonas
TI The Visual Analytics and Data Exploration Research Lab at Arizona State
   University
SO VISUAL INFORMATICS
LA English
DT Article
DE Visualization; Spatiotemporal; Explainable AI; Topology
ID ENERGY-WATER NEXUS; OF-THE-ART; SPACE-TIME; PHOENIX; IMPACT
AB This article describes the research agenda for the Visual Analytics and Data Exploration Research (VADER) Lab at Arizona State University. Over the past decade, the VADER Lab has focused on creating novel algorithms, tools and visualizations for spatiotemporal data. This article will highlight past success in spatiotemporal analysis, explainable AI, graph mining, and mathematical topology. While, at first, these topics seem largely disjoint, we will describe how the underpinnings of spatiotemporal analysis has informed the various research directions in the VADER Lab, and how this research agenda has served to form a network of strong international collaborations. Finally, we will outline a vision for the Lab's future research. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Maciejewski, Ross; Ma, Yuxin; Lukasczyk, Jonas] Arizona State Univ, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Maciejewski, R (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM rmacieje@asu.edu; yuxinma@asu.edu; jl@jluk.de
RI MA, Yuxin/AAG-8630-2020
FU National Science Foundation, United States of America [1639227, 1350573,
   1939725]; Skoll Foundation, United States of America; U.S.Department of
   Homeland Security [2017-ST-061-QA0001]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [1939725, 1350573]
   Funding Source: National Science Foundation
FX This work was supported by the National Science Foundation, United
   States of America (Award Numbers 1639227, 1350573, and 1939725), the
   National Academies and the Skoll Foundation, United States of America,
   and the U.S.Department of Homeland Security under Grant Award
   2017-ST-061-QA0001. The views and conclusions contained in this document
   are those of the authors and should not be interpreted as necessarily
   representing the official policies, either expressed or implied, of the
   U.S. Department of Homeland Security.
CR Andrienko G, 2017, IEEE T INTELL TRANSP, V18, P2232, DOI 10.1109/TITS.2017.2683539
   [Anonymous], 2019, IEEE T VIS COMPUT GR
   Anselin L, 2006, GEOGR ANAL, V38, P5, DOI 10.1111/j.0016-7363.2005.00671.x
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Crow M. M., 2015, Designing the New American University
   Dübel S, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P11, DOI 10.1109/3DVis.2014.7160094
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Fairfield AJ, 2014, PROC SPIE, V9035, DOI 10.1117/12.2043186
   Gatalsky P, 2004, IEEE INFOR VIS, P145, DOI 10.1109/IV.2004.1320137
   Gorko T., 2018, PROC HAWAII INT CONF
   Gu TL, 2018, IEEE T COMPUT SOC SY, V5, P1121, DOI 10.1109/TCSS.2018.2858439
   Guan X, 2020, SCI TOTAL ENVIRON, V701, DOI 10.1016/j.scitotenv.2019.134478
   Guo DS, 2006, IEEE T VIS COMPUT GR, V12, P1461, DOI 10.1109/TVCG.2006.84
   Huang ZS, 2020, IEEE T VIS COMPUT GR, V26, P2576, DOI 10.1109/TVCG.2019.2892483
   Kim S, 2018, IEEE T VIS COMPUT GR, V24, P1287, DOI 10.1109/TVCG.2017.2666146
   Kim S, 2013, IEEE T VIS COMPUT GR, V19, P1438, DOI 10.1109/TVCG.2013.66
   Landis ST, 2017, POLIT GEOGR, V56, P77, DOI 10.1016/j.polgeo.2016.10.002
   Lei T.L., 2015, P WORKSH VIS ENV SCI, P55
   Liu SX, 2014, VISUAL COMPUT, V30, P1373, DOI 10.1007/s00371-013-0892-3
   Liu XT, 2018, COMPUT GRAPH FORUM, V37, P7, DOI 10.1111/cgf.12526
   Lu YF, 2018, IEEE T VIS COMPUT GR, V24, P2501, DOI 10.1109/TVCG.2017.2752166
   Lu YF, 2017, COMPUT GRAPH FORUM, V36, P539, DOI 10.1111/cgf.13210
   Lu YF, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1211, DOI 10.1145/2740908.2741720
   Lu YF, 2014, IEEE CONF VIS ANAL, P193, DOI 10.1109/VAST.2014.7042495
   Lu YF, 2016, IEEE T VIS COMPUT GR, V22, P220, DOI 10.1109/TVCG.2015.2467991
   Lu YF, 2014, IEEE COMPUT GRAPH, V34, P58, DOI 10.1109/MCG.2014.61
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J., 2020, P IEEE S LARG DAT AN
   Lukasczyk J, P ACM SIGSPATIAL INT
   Lukasczyk J., IEEE T VIS COMPUT GR
   Lukasczyk J., 2015, P WORKSHOP VISUALIZA, P25, DOI [10.2312/envirvis.20151087, DOI 10.2312/ENVIRVIS.20151087]
   Lukasczyk J, 2020, IEEE T VIS COMPUT GR, V26, P249, DOI 10.1109/TVCG.2019.2934368
   Lukasczyk J, 2018, SYMP LARG DATA ANAL, P12, DOI 10.1109/LDAV.2018.8739204
   Lukasczyk J, 2017, COMPUT GRAPH FORUM, V36, P13, DOI 10.1111/cgf.13164
   Luo W, 2017, IEEE COMPUT GRAPH, V37, P40, DOI 10.1109/MCG.2017.3621222
   Ma Y, 2020, IEEE T VIS COMPUT GR
   Ma Y, IEEE T VIS COMPUT GR, P1
   Ma Y., 2020, IEEE COMPUT GRAPH
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Maciejewski R, 2010, PROC HAWAII INT CONF, P1
   Maciejewski R, 2011, IEEE T VIS COMPUT GR, V17, P440, DOI 10.1109/TVCG.2010.82
   Maciejewski R, 2010, IEEE T VIS COMPUT GR, V16, P205, DOI 10.1109/TVCG.2009.100
   Mack EA, 2015, TELECOMMUN POLICY, V39, P320, DOI 10.1016/j.telpol.2014.06.011
   Mack EA, 2014, J GEOGR SYST, V16, P183, DOI 10.1007/s10109-013-0193-4
   Malik A., 2010, 2010 IEEE International Conference on Technologies for Homeland Security (HST 2010), P222, DOI 10.1109/THS.2010.5655057
   Malik A., 2011, Proceedings of the Hawaii International Conference on System Sciences, P1
   Malik A, 2014, IEEE T VIS COMPUT GR, V20, P1863, DOI 10.1109/TVCG.2014.2346926
   Malik A, 2012, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2012.6400491
   Mathis B, 2019, IEEE COMPUT GRAPH
   Middel A, 2019, LANDSCAPE URBAN PLAN, V183, P122, DOI 10.1016/j.landurbplan.2018.12.001
   Middel A, 2018, URBAN CLIM, V25, P120, DOI 10.1016/j.uclim.2018.05.004
   Middel A, 2017, URBAN PLAN, V2, P19, DOI 10.17645/up.v2i1.855
   Opejin AK, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12031112
   Razip AMM, 2014, IEEE PAC VIS SYMP, P169, DOI 10.1109/PacificVis.2014.54
   Riveiro M, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1266
   Soni U, 2018, COMPUT GRAPH FORUM, V37, P169, DOI 10.1111/cgf.13410
   Steptoe M, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3162076
   Steptoe M, 2015, IEEE CONF VIS ANAL, P119
   Torres S. O., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P1855, DOI 10.1109/HICSS.2012.116
   Wang F, 2017, ANN AM ASSOC GEOGR, V107, P130, DOI 10.1080/24694452.2016.1222263
   Wang H, 2019, IEEE T VIS COMPUT GR, V25, P331, DOI 10.1109/TVCG.2018.2864844
   Whisner C, 2015, PERS VIS EXPL DAT EV
   White DD, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9122204
   Xie T, 2020, IEEE T VIS COMPUT GR
   Zhang JW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173611
   Zhang JW, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2940, DOI 10.1145/3025453.3025801
   Zhang Y, 2016, COMPUT GRAPH FORUM, V35, P101, DOI 10.1111/cgf.12886
   Zhang YF, 2017, IEEE T VIS COMPUT GR, V23, P371, DOI 10.1109/TVCG.2016.2598541
NR 70
TC 0
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2021
VL 5
IS 1
BP 14
EP 22
DI 10.1016/j.visinf.2020.12.001
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LE
UT WOS:000658194100002
OA gold
DA 2024-07-18
ER

PT J
AU Jansen, R
   Mendoza, FR
   Hurst, W
AF Jansen, Reint
   Mendoza, Frida Ruiz
   Hurst, William
TI Augmented reality for supporting geo-spatial planning: An open access
   review
SO VISUAL INFORMATICS
LA English
DT Review
DE Augmented reality; Systematic literature review; Participation;
   Planning; Geo-visualization
ID PARTICIPATION; ARCHITECTURE
AB Augmented reality is gaining traction across many domains. One of these is participation within geo-spatial planning projects. The interactive and three-dimensional nature of augmented reality is suitably placed to cater for a higher quality of communication and information exchange in planning processes. Thus, this research provides an overview of the use of AR in planning processes, specifically regarding the participation aspect, through an open-access systematic literature review, for which the investigation identifies 35 articles concerning the current state-of-the-art of augmented reality in planning. Findings indicate the rather limited use of augmented reality in the overall planning process due to technical limitations. Nonetheless, it shows to be a useful technology where it allows for higher user engagement and a clearer understanding among users in planning projects. Additionally, in participation, the technology offers a motivational solution and creates an overall higher acceptance and awareness of the plan, making the participants more engaged and represented in the planning process. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Jansen, Reint; Mendoza, Frida Ruiz] Wageningen Univ & Res, Lab Geoinformat Sci & Remote Sensing, Wageningen, Netherlands.
   [Hurst, William] Wageningen Univ & Res, Informat Technol Grp, Wageningen, Netherlands.
C3 Wageningen University & Research; Wageningen University & Research
RP Mendoza, FR (corresponding author), Wageningen Univ & Res, Lab Geoinformat Sci & Remote Sensing, Wageningen, Netherlands.
EM reint.jansen@wur.nl; frida.ruizmendoza@wur.nl; will.hurst@wur.nl
CR Afrooz A, 2018, ISPRS ANN PHOTO REM, V4-4, P5, DOI 10.5194/isprs-annals-IV-4-5-2018
   Allen M., 2011, P TEH 23 AUSTR COMPU
   [Anonymous], 2021, Open Science
   [Anonymous], 2011, The New Media Consortium and the EDUCAUSE Learning initiative
   Ara J., 2021, AR-based Modern Healthcare: A Review
   Arnstein SR, 2019, J AM PLANN ASSOC, V85, P24, DOI 10.1080/01944363.2018.1559388
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baker M, 2007, PLAN PRACT RES, V22, P79, DOI 10.1080/02697450601173371
   Bloemmen M.H.I., 2005, Report Literature Research Geo-Visualization and Participatory Spatial Planning
   Boulos MNK, 2017, INT J HEALTH GEOGR, V16, DOI 10.1186/s12942-017-0081-0
   Broschart D., 2015, Digit. Landsc. Archit, P11
   BUDIC ZD, 1994, J AM PLANN ASSOC, V60, P244
   Calil J., 2021, Water (Basel), P1
   Carbonell-Carrera C, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6090261
   Chalhoub J, 2019, MULTIMED TOOLS APPL, V78, P35075, DOI 10.1007/s11042-019-08063-5
   Cheng JH, 2019, LANDSC ARCHIT FRONT, V7, P132, DOI 10.15302/J-LAF-20190213
   Cirulis A, 2013, PROCEDIA COMPUT SCI, V25, P71, DOI 10.1016/j.procs.2013.11.009
   Däne S, 2007, MANSHOLT PUBL SER, V3, P33
   Devaux A, 2018, ISPRS ANN PHOTO REM, V4-4, P41, DOI 10.5194/isprs-annals-IV-4-41-2018
   Fadzli F.E., 2021, IOP Conf. Ser. Mater. Sci. Eng, P527
   Fenais A, 2019, INFRASTRUCTURES-BASE, V4, DOI 10.3390/infrastructures4040060
   Fonseca D, 2016, COMPUT HUM BEHAV, V55, P504, DOI 10.1016/j.chb.2015.05.032
   Geertman S., 2008, Planning Support Systems for Cities and Regions, P213
   Giunta L., 2020, P DESIGN SOC DESIGN, P131
   Gnat M, 2016, LECT NOTES COMPUT SC, V9787, P484, DOI 10.1007/978-3-319-42108-7_37
   Goudarznia Toomaj., 2017, J DIGIT LANDS ARCHI, V2, P244, DOI DOI 10.14627/537629025
   Grassi S, 2016, J PHYS CONF SER, V749, DOI 10.1088/1742-6596/749/1/012020
   Gutierrez Veronica, 2013, The Future Internet, P173, DOI 10.1007/978-3-642-38082-2_15
   Hansert Jonas, 2020, Virtual, Augmented and Mixed Reality. Design and Interaction. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12190), P50, DOI 10.1007/978-3-030-49695-1_4
   Huang JW, 2021, INT J GEOGR INF SCI, V35, P1155, DOI 10.1080/13658816.2020.1830997
   Hunter M, 2021, INTERACT DES ARCHIT, P75
   Imottesjo H., 2022, Appl. Sci, V12, P1
   Imottesjo H, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4020026
   Irvin RA, 2004, PUBLIC ADMIN REV, V64, P55, DOI 10.1111/j.1540-6210.2004.00346.x
   Jeon S, 2010, PERS UBIQUIT COMPUT, V14, P83, DOI 10.1007/s00779-009-0249-0
   Jiang S, 2023, CURR ISSUES TOUR, V26, P242, DOI 10.1080/13683500.2022.2026303
   Kitchenham B., 2004, ARXIV
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Klamert K, 2017, LECT NOTES COMPUT SC, V10429, P24, DOI 10.1007/978-3-319-64322-9_3
   Klippel A, 2020, J SPAT INT SCI, P33, DOI 10.5311/JOSIS.2020.21.722
   Marques L, 2017, ACE-ARCHIT CITY ENVI, V11, P117, DOI 10.5821/ace.11.33.4686
   Marzouki A., 2022, Gov. Inf. Q, P1
   McCall MK, 2012, GEOFORUM, V43, P81, DOI 10.1016/j.geoforum.2011.07.007
   Merino L, 2020, INT SYM MIX AUGMENT, P438, DOI 10.1109/ISMAR50242.2020.00069
   Nikolic DS, 2021, SAGE OPEN, V11, DOI 10.1177/2158244021994554
   OpenAIRE, 2022, What Is Open Science
   Panou C, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7120463
   Ros A., 2018, Participated planning of large water infrastructures through virtual prototyping technologies
   Rydvanskiy R, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020082
   Riera AS, 2015, UNIVERSAL ACCESS INF, V14, P363, DOI 10.1007/s10209-014-0362-3
   Sazmannshausen S.M., 2021, DESIGNING INTERACTIV
   Shih N.J., 2020, Sens. (Switzerland), P1
   Skov MB, 2013, PERVASIVE MOB COMPUT, V9, P216, DOI 10.1016/j.pmcj.2012.05.004
   St-Aubin B, 2010, INT ARCH PHOTOGRAMM, V38
   Suchita J., 2019, Int. J. Innov. Technol. Explor. Eng, P41
   Syahputra M.F., 2020, J. Phys. Conf. Ser, P1
   Tomkins A, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3020043
   Tummers J, 2019, COMPUT ELECTRON AGR, V157, P189, DOI 10.1016/j.compag.2018.12.044
   van den Brink A, 2007, MANSHOLT PUBL SER, V3, P23
   van Lammeren R, 2010, COMPUT ENVIRON URBAN, V34, P465, DOI 10.1016/j.compenvurbsys.2010.07.001
   Williams A.S., 2020, Design and Interaction, P256
   Wolf M., 2019, INT AUGMENTED VIRTUA, P125
NR 62
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 1
EP 12
DI 10.1016/j.visinf.2023.07.002
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA IH5X0
UT WOS:001165460400001
OA gold
DA 2024-07-18
ER

PT J
AU Goodwin, S
   Prouzeau, A
   Whitelock-Jones, R
   Hurter, C
   Lawrence, L
   Afzal, U
   Dwyer, T
AF Goodwin, Sarah
   Prouzeau, Arnaud
   Whitelock-Jones, Ryan
   Hurter, Christophe
   Lawrence, Lee
   Afzal, Umair
   Dwyer, Tim
TI VETA: Visual eye-tracking analytics for the exploration of gaze patterns
   and behaviours
SO VISUAL INFORMATICS
LA English
DT Article
DE Eye tracking; Visual analytics; Spatial-temporal visualisation
ID VISUALIZATION; MOVEMENTS
AB Eye tracking is growing in popularity for multiple application areas, yet analysing and exploring the large volume of complex data remains difficult for most users. We present a comprehensive eye tracking visual analytics system to enable the exploration and presentation of eye-tracking data across time and space in an efficient manner. The application allows the user to gain an overview of general patterns and perform deep visual analysis of local gaze exploration. The ability to link directly to the video of the underlying scene allows the visualisation insights to be verified on the fly. The system was motivated by the need to analyse eye-tracking data collected from an 'in the wild' study with energy network operators and has been further evaluated via interviews with 14 eye-tracking experts in multiple domains. Results suggest that, thanks to state-of-the-art visualisation techniques and by providing context with videos, our system could enable an improved analysis of eye-tracking data through interactive exploration, facilitating comparison between different participants or conditions, thus enhancing the presentation of complex data analysis to non-experts. This research paper provides four contributions: (1) analysis of a motivational use case demonstrating the need for rich visualanalytics workflow tools for eye-tracking data; (2) a highly dynamic system to visually explore and present complex eye-tracking data; (3) insights from our applied use case evaluation and interviews with experienced users demonstrating the potential for the system and visual analytics for the wider eye-tracking community. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Goodwin, Sarah; Prouzeau, Arnaud; Whitelock-Jones, Ryan; Lawrence, Lee; Afzal, Umair; Dwyer, Tim] Monash Univ, Clayton, Australia.
   [Prouzeau, Arnaud] Univ Bordeaux, Inria & LaBRI, CNRS, Bordeaux INP, Bordeaux, France.
   [Hurter, Christophe] Univ Toulouse, ENAC, Toulouse, France.
   [Afzal, Umair] Swinburne Univ Technol, Melbourne, Australia.
C3 Monash University; Universite de Bordeaux; Centre National de la
   Recherche Scientifique (CNRS); Universite Federale Toulouse
   Midi-Pyrenees (ComUE); Universite de Toulouse; Ecole Nationale de
   l'Aviation Civile (ENAC); Swinburne University of Technology
RP Prouzeau, A (corresponding author), Monash Univ, Clayton, Australia.; Prouzeau, A (corresponding author), Univ Bordeaux, Inria & LaBRI, CNRS, Bordeaux INP, Bordeaux, France.
EM arnaud.prouzeau@inria.fr
RI Prouzeau, Arnaud/AAU-3378-2021; Hurter, Christophe/IAM-1546-2023
OI Whitelock-Jones, Ryan/0000-0002-5954-5692; Hurter,
   Christophe/0000-0003-4318-6717; Lawrence, Lee/0000-0002-1336-9136;
   Prouzeau, Arnaud/0000-0003-3800-5870; Goodwin, Sarah/0000-0001-8894-8282
CR Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Andrienko G, 2012, IEEE T VIS COMPUT GR, V18, P2889, DOI 10.1109/TVCG.2012.276
   [Anonymous], 2020, ISO Stan-dard 15007:2020
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Blascheck T, 2017, COMPUT GRAPH FORUM, V36, P260, DOI 10.1111/cgf.13079
   Blascheck T., 2014, EUROGRAPHICS C VISUA
   Blascheck T, 2016, IEEE T VIS COMPUT GR, V22, P61, DOI 10.1109/TVCG.2015.2467871
   Bojko A, 2009, LECT NOTES COMPUT SC, V5610, P30, DOI 10.1007/978-3-642-02574-7_4
   Burch M, 2019, PROCEEDINGS OF THE 12TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION, VINCI 2019, DOI 10.1145/3356422.3356423
   Burch Michael, 2019, P 11 ACM S EYE TRACK, P1, DOI [10.1145/3317960.3321615, DOI 10.1145/3317960.3321615]
   Bykowski A, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3208331
   Chevalier N. H., 2016, P INT WORK C ADV VIS, P280
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Dehais F., 2012, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V56, P1639, DOI DOI 10.1177/1071181312561328
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Dunne C., 2012, P SIGCHI C HUM FACT, P1663, DOI [10.1145/2207676.2208293, DOI 10.1145/2207676.2208293]
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Fabian A., 2020, INTERACTIVE DATA VIS
   Ferreira A, 2022, BIG DATA RES, V27, DOI 10.1016/j.bdr.2021.100294
   Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584
   Fuhrmann A, 1998, VISUALIZATION '98, PROCEEDINGS, P305, DOI 10.1109/VISUAL.1998.745317
   Gasteiger R, 2011, IEEE T VIS COMPUT GR, V17, P2183, DOI 10.1109/TVCG.2011.243
   Goldberg JH, 1999, INT J IND ERGONOM, V24, P631, DOI 10.1016/S0169-8141(98)00068-7
   Holmqvist K, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P657, DOI 10.1016/B978-044451020-4/50035-9
   Holmqvist K., 2017, EYE TRACKING COMPREH
   Hurter C, 2014, IEEE PAC VIS SYMP, P225, DOI 10.1109/PacificVis.2014.61
   Hurter C, 2011, IEEE T VIS COMPUT GR, V17, P2600, DOI 10.1109/TVCG.2011.223
   Hurter C, 2009, IEEE T VIS COMPUT GR, V15, P1017, DOI 10.1109/TVCG.2009.145
   Kilingaru K, 2013, J INTELL FUZZY SYST, V24, P457, DOI 10.3233/IFS-2012-0566
   Kister U, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P139, DOI 10.1145/2992154.2992168
   Krueger R, 2016, PROCEEDINGS OF THE SECOND WORKSHOP ON EYE TRACKING AND VISUALIZATION (ETVIS 2016), P31, DOI 10.1109/ETVIS.2016.7851162
   Krüger R, 2013, COMPUT GRAPH FORUM, V32, P451, DOI 10.1111/cgf.12132
   Kurzhals K, 2020, ETRA'20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3379155.3391326
   Kurzhals K, 2013, IEEE T VIS COMPUT GR, V19, P2129, DOI 10.1109/TVCG.2013.194
   Lhuillier A, 2017, IEEE PAC VIS SYMP, P190, DOI 10.1109/PACIFICVIS.2017.8031594
   Mattausch O., 2003, P SPRING C COMPUTER, P213, DOI DOI 10.1145/984952.984987
   Muthumanickam PK, 2019, IEEE T VIS COMPUT GR, V25, P87, DOI 10.1109/TVCG.2018.2865042
   Panagiotidis A., 2011, Proceeding of Hawaii International Conference on System Sciences (HICSS). (Kauai, HI, P1
   Peysakhovich Vsevolod, 2018, J Eye Mov Res, V10, DOI 10.16910/jemr.10.5.9
   Pfeiffer T., 2012, P S EYE TRACKING RES, P29, DOI [10.1145/2168556.2168560, DOI 10.1145/2168556.2168560]
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Räïhä KJ, 2005, LECT NOTES COMPUT SC, V3585, P946, DOI 10.1007/11555261_76
   Sears M, 2021, AUTOMAT CONSTR, V132, DOI 10.1016/j.autcon.2021.103951
   Shanmugasundaram Maruthappan., 2008, AVI 08, P396
   Sharma C, 2016, COMPUT CHEM ENG, V85, P43, DOI 10.1016/j.compchemeng.2015.09.012
   Starke SD, 2017, APPL ERGON, V61, P79, DOI 10.1016/j.apergo.2017.01.006
   Stellmach S., 2010, ACM S EYE TRACKING R, P109, DOI DOI 10.1145/1743666.1743693
   Tominski C, 2017, COMPUT GRAPH FORUM, V36, P173, DOI 10.1111/cgf.12871
   Tominski C, 2006, INFORMATION VISUALIZATION-BOOK, P17
   Vosskühler A, 2008, BEHAV RES METHODS, V40, P1150, DOI [10.3758/BRM.40.4.1150, 10.3758/BRM.40.4.U50]
   Vrotsou K., 2020, EUROVIS WORKSHOP VIS, P55, DOI DOI 10.2312/EUROVA.20201087
   Wedel M, 2006, FOUND TRENDS MARKET, V1, P231, DOI 10.1561/1700000011
   Weibel Nadir., 2012, P S EYE TRACKING RES, P107, DOI DOI 10.1145/2168556.2168573
   Westin C., 2019, SESAR INNOVATION DAY
   Wilson WC, 1998, ENVIRON PLANN A, V30, P1017, DOI 10.1068/a301017
   Wong N, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P51, DOI 10.1109/INFVIS.2003.1249008
   Zhou H, 2013, TSINGHUA SCI TECHNOL, V18, P145, DOI 10.1109/TST.2013.6509098
NR 57
TC 5
Z9 5
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 1
EP 13
DI 10.1016/j.visinf.2022.02.004
EA MAY 2022
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 1M6RX
UT WOS:000800097600001
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Kui, XY
   Lv, HH
   Tang, ZL
   Zhou, HW
   Yang, W
   Li, JQ
   Guo, JL
   Xia, JZ
AF Kui, Xiaoyan
   Lv, Huihao
   Tang, Zhengliang
   Zhou, Haowen
   Yang, Wang
   Li, Jinqiu
   Guo, Jialin
   Xia, Jiazhi
TI TVseer: A visual analytics system for television ratings
SO VISUAL INFORMATICS
LA English
DT Article
DE Visualization in television; Ratings analysis; Time series data; Visual
   analytics
ID COMPETITION; AUDIENCE
AB The television ratings provide an effective way to analyze the popularity of TV programs and audiences' watching habits. Most previous studies have analyzed the ratings from a single perspective. Few efforts have integrated analysis from different perspectives and explored the reasons for changes in ratings. In this paper, we design a visual analysis system called TVseer to analyze audience ratings from three perspectives: TV channels, TV programs, and audiences. The system can help users explore the factors that affect ratings, and assist them in decisions about program productions and schedules. There are six linked views in TVseer: the channel ratings view and program ratings view show ratings change information from the perspective of TV channels and programs respectively; the overlapping program competition view and the same-type program competition view indicate the competitive relationships among programs; the audience transfer view shows how audiences are moving among different channels; the audience group view displays audience groups based on their watching behavior. Besides, we also construct case studies and expert interviews to prove our system is useful and effective. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Kui, Xiaoyan; Lv, Huihao; Zhou, Haowen; Yang, Wang; Li, Jinqiu; Guo, Jialin; Xia, Jiazhi] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Tang, Zhengliang] Cent South Univ, Sch Business, Changsha, Peoples R China.
C3 Central South University; Central South University
RP Xia, JZ (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
EM xiajiazhi@csu.edu.cn
OI TANG, ZHENGLIANG/0000-0002-9248-967X
FU Natural Science Foundation of Hunan Province, China [2019JJ40406,
   2015JJ4077]; National Natural Science Foundation of China [61872389,
   61502540]
FX This work is supported by the Natural Science Foundation of Hunan
   Province, China (Grant Nos. 2019JJ40406, 2015JJ4077) and the National
   Natural Science Foundation of China (Nos. 61872389, 61502540).
CR Bajaj P, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P252, DOI 10.1145/2964284.2967221
   Bhadury A, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P381, DOI 10.1145/2872427.2883046
   Chen HD, 2014, IEEE T VIS COMPUT GR, V20, P1683, DOI 10.1109/TVCG.2014.2346594
   Chen JF, 2018, PROC VLDB ENDOW, V11, P826, DOI 10.14778/3192965.3192972
   Chen W, 2016, IEEE T MULTIMEDIA, V18, P2247, DOI 10.1109/TMM.2016.2614221
   Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239
   Danaher P, 2012, INT J FORECASTING, V28, P607, DOI 10.1016/j.ijforecast.2012.02.008
   Danaher PJ, 2011, INT J FORECASTING, V27, P1215, DOI 10.1016/j.ijforecast.2010.08.002
   Dou WW, 2016, IEEE COMPUT GRAPH, V36, P8, DOI 10.1109/MCG.2016.73
   Dutta-Bergman MJ, 2004, J BROADCAST ELECTRON, V48, P41, DOI 10.1207/s15506878jobem4801_3
   Egebjerg NH, 2017, IEEE INT CONGR BIG, P81, DOI 10.1109/BigDataCongress.2017.20
   EHRENBERG ASC, 1987, J ADVERTISING RES, V27, P9
   Fukushima Y, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P279, DOI 10.1109/BigMM.2016.24
   Gao Z. J., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P1056, DOI 10.1109/ICDM.2011.148
   GENSCH D, 1980, J MARKETING RES, V17, P307, DOI 10.2307/3150528
   Gensch D., 1980, J ADVERTISING RES
   Goettler RL, 2001, RAND J ECON, V32, P624, DOI 10.2307/2696385
   HARTIGAN JA, 1984, AM STAT, V38, P32, DOI 10.2307/2683556
   HENRY MD, 1984, J ADVERTISING RES, V24, P9
   Hill W., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P194
   Hinami R, 2017, IEEE MULTIMEDIA, V24, P44, DOI 10.1109/MMUL.2017.25
   Hinami R, 2016, IEEE INT SYM MULTIM, P44, DOI [10.1109/ISM.2016.52, 10.1109/ISM.2016.0018]
   HOREN JH, 1980, MANAGE SCI, V26, P354, DOI 10.1287/mnsc.26.4.354
   Kelton CML, 1998, EUR J OPER RES, V104, P451, DOI 10.1016/S0377-2217(96)00369-4
   Kim E, 2011, IEEE T BROADCAST, V57, P674, DOI 10.1109/TBC.2011.2161409
   Kim T, 2016, IEEE T CONSUM ELECTR, V62, P310, DOI 10.1109/TCE.2016.7613198
   Kompatsiaris Y., 2012, TV content analysis: Techniques and applications, DOI DOI 10.1201/B11723
   Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101
   Ma N, 2019, MULTIMED TOOLS APPL, V78, P525, DOI 10.1007/s11042-017-5250-4
   Ma N, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P90, DOI 10.1109/FSKD.2015.7381921
   Napoli PM, 2001, J ADVERTISING, V30, P53, DOI 10.1080/00913367.2001.10673637
   Panova E, 2015, PROCEDIA COMPUT SCI, V66, P328, DOI 10.1016/j.procs.2015.11.038
   Patelis A, 2003, J COMPUT INFORM SYST, V43, P100
   Reddy SK, 1998, MANAGE SCI, V44, P83, DOI 10.1287/mnsc.44.1.83
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Shachar R, 2000, J MARKETING RES, V37, P173, DOI 10.1509/jmkr.37.2.173.18738
   Sotelo R, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P355, DOI 10.1109/ICCE.2011.5722624
   SPEARMAN C, 1987, AM J PSYCHOL, V100, P441, DOI 10.2307/1422689
   Sun GD, 2014, IEEE T VIS COMPUT GR, V20, P1753, DOI 10.1109/TVCG.2014.2346919
   Van Reeth D, 2019, INT J FORECASTING, V35, P810, DOI 10.1016/j.ijforecast.2018.06.003
   Véras D, 2015, EXPERT SYST APPL, V42, P9046, DOI 10.1016/j.eswa.2015.06.052
   Xie C, 2014, IEEE T VIS COMPUT GR, V20, P1743, DOI 10.1109/TVCG.2014.2346913
   Xu PP, 2013, IEEE T VIS COMPUT GR, V19, P2012, DOI 10.1109/TVCG.2013.221
   Yang C, 2018, IEEE ACCESS, V6, P50824, DOI 10.1109/ACCESS.2018.2869470
   Yu CG, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P147, DOI 10.1145/3083187.3083194
   ZHU JH, 1992, JOURNALISM QUART, V69, P825, DOI 10.1177/107769909206900403
NR 46
TC 5
Z9 5
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2020
VL 4
IS 3
BP 1
EP 11
DI 10.1016/j.visinf.2020.06.001
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KP
UT WOS:000658192600001
OA gold
DA 2024-07-18
ER

PT J
AU Wang, ZH
   Lin, HW
AF Wang Zihao
   Lin Hongwei
TI 3D shape retrieval based on Laplace operator and joint Bayesian model
SO VISUAL INFORMATICS
LA English
DT Article
DE Laplace-Beltrami operator; Joint Bayesian; Shape retrieval
ID DESCRIPTORS; WORDS
AB Feature analysis plays a significant role in computer vision and computer graphics. In the task of shape retrieval, shape descriptor is indispensable. In recent years, feature extraction based on deep learning becomes very popular, but the design of geometric shape descriptor is still meaningful due to the contained intrinsic information and interpretability. This paper proposes an effective and robust descriptor of 3D models. The descriptor is constructed based on the probability distribution of the normalized eigenfunctions of the Laplace-Beltrami operator on the surface, and a spectrum method for dimensionality reduction. The distance metric of the descriptor space is learned by utilizing the joint Bayesian model, and we introduce a matrix regularization in the training stage to re-estimate the covariance matrix. Finally, we apply the descriptor to 3D shape retrieval on a public benchmark. Experiments show that our method is robust and has good retrieval performance. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wang Zihao; Lin Hongwei] Zhejiang Univ, Sch Math, Hangzhou 310027, Peoples R China.
   [Lin Hongwei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Lin, HW (corresponding author), Zhejiang Univ, Sch Math, Hangzhou 310027, Peoples R China.
EM hwlin@zju.edu.cn
OI Lin, Hongwei/0000-0002-9337-9624
FU National Natural Science Foundation of China [61872316, 61932018]
FX This work is supported by the National Natural Science Foundation of
   China under Grant Nos. 61872316, 61932018.
CR Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Barra V, 2013, PATTERN RECOGN, V46, P2985, DOI 10.1016/j.patcog.2013.03.019
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bickel PJ, 2008, ANN STAT, V36, P2577, DOI 10.1214/08-AOS600
   Bobenko AI, 2007, DISCRETE COMPUT GEOM, V38, P740, DOI 10.1007/s00454-007-9006-1
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   FENG YY, 1984, SIAM J MATH ANAL, V15, P834, DOI 10.1137/0515063
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Furrer R, 2007, J MULTIVARIATE ANAL, V98, P227, DOI 10.1016/j.jmva.2006.08.003
   He SQ, 2015, COMPUT AIDED GEOM D, V39, P50, DOI 10.1016/j.cagd.2015.08.004
   Huang C, 2012, ACTA MATH SIN, V28, P105, DOI 10.1007/s10114-012-9424-8
   Kuang ZZ, 2019, IEEE T MULTIMEDIA, V21, P3164, DOI 10.1109/TMM.2019.2918729
   Lavoué G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Lian Z., 2015, PROC 8 EUROGRAPHICS, P107
   Lian ZH, 2013, MACH VISION APPL, V24, P1685, DOI 10.1007/s00138-013-0501-5
   Litman R, 2014, COMPUT GRAPH FORUM, V33, P127, DOI 10.1111/cgf.12438
   Melzi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3144454
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Smeets D, 2013, COMPUT VIS IMAGE UND, V117, P158, DOI 10.1016/j.cviu.2012.10.002
   Smeets D, 2009, LECT NOTES COMPUT SC, V5702, P757, DOI 10.1007/978-3-642-03767-2_92
   Song RX, 2008, LECT NOTES COMPUT SC, V4975, P563
   Song RX, 2007, COMMUN PUR APPL ANAL, V6, P853
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tabia H, 2014, PROC CVPR IEEE, P4185, DOI 10.1109/CVPR.2014.533
   Toldo R, 2010, VISUAL COMPUT, V26, P1257, DOI 10.1007/s00371-010-0519-x
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Xu C, 2019, IEEE I CONF COMP VIS, P3731, DOI 10.1109/ICCV.2019.00383
   Ying YM, 2012, J MACH LEARN RES, V13, P1
   ZHANG HAO., 2004, Proc. ofSIAM Conference on Geometric Design and Computing, P575
   Zhu ZT, 2016, NEUROCOMPUTING, V204, P41, DOI 10.1016/j.neucom.2015.08.127
NR 40
TC 4
Z9 6
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2020
VL 4
IS 3
BP 69
EP 76
DI 10.1016/j.visinf.2020.08.002
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KP
UT WOS:000658192600008
OA gold
DA 2024-07-18
ER

PT J
AU Li, YR
   Fujiwara, T
   Choi, YK
   Kim, KK
   Ma, KL
AF Li, Yiran
   Fujiwara, Takanori
   Choi, Yong K.
   Kim, Katherine K.
   Ma, Kwan-Liu
TI A visual analytics system for multi-model comparison on clinical data
   predictions
SO VISUAL INFORMATICS
LA English
DT Article
DE Clinical data; XAI; Tree-based machine learning models; Model
   consistency; Measures of dependence; Visual analytics
ID STABILITY; BOUNDS
AB There is a growing trend of applying machine learning methods to medical datasets in order to predict patients' future status. Although some of these methods achieve high performance, challenges still exist in comparing and evaluating different models through their interpretable information. Such analytics can help clinicians improve evidence-based medical decision making. In this work, we develop a visual analytics system that compares multiple models' prediction criteria and evaluates their consistency. With our system, users can generate knowledge on different models' inner criteria and how confidently we can rely on each model's prediction for a certain patient. Through a case study of a publicly available clinical dataset, we demonstrate the effectiveness of our visual analytics system to assist clinicians and researchers in comparing and quantitatively evaluating different machine learning methods. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Li, Yiran; Fujiwara, Takanori; Ma, Kwan-Liu] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Choi, Yong K.; Kim, Katherine K.] Univ Calif Davis, Betty Irene Moore Sch Nursing, Davis, CA 95616 USA.
   [Kim, Katherine K.] Univ Calif Davis, Sch Med, Davis, CA 95616 USA.
C3 University of California System; University of California Davis;
   University of California System; University of California Davis;
   University of California System; University of California Davis
RP Li, YR (corresponding author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
EM ranli@ucdavis.edu
RI Fujiwara, Takanori/AAY-5045-2020
OI Fujiwara, Takanori/0000-0002-6382-2752
FU U.S. National Science Foundation [IIS-1741536]; 2019 Seed Fund Award
   from CITRIS; Banatao Institute at the University of California
FX This research is sponsored in part by the U.S. National Science
   Foundation through grant IIS-1741536 and a 2019 Seed Fund Award from
   CITRIS and the Banatao Institute at the University of California.
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   [Anonymous], 1983, MACH LEARN
   [Anonymous], 2016, P INT C LEARN REPR
   Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704
   Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613
   Che ZP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24271-9
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Choi E, 2016, ADV NEUR IN, V29
   CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407
   Collaris D., 2018, ARXIVABS180607129 CO
   Cover T. M, 2006, Elements of Information Theory, V2nd
   DEVROYE L, 1991, NATO ADV SCI I C-MAT, V335, P31
   DEVROYE LP, 1979, IEEE T INFORM THEORY, V25, P601, DOI 10.1109/TIT.1979.1056087
   Dorogush A.V., 2018, ARXIVABS181011363 CO
   Fouad M., 2015, INT J ADV COMP RES, V3, P185
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Goldfarb-Rumyantzev AS, 2003, CLIN TRANSPLANT, V17, P485, DOI 10.1046/j.0902-0063.2003.00051.x
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Haussler D, 1995, PART 1 OVERVIEW PROB
   Jin Z., 2019, ACM T COMPUT HEALTHC
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Kawaler Emily, 2012, AMIA Annu Symp Proc, V2012, P436
   Ke GL, 2017, ADV NEUR IN, V30
   Kearns M, 1999, NEURAL COMPUT, V11, P1427, DOI 10.1162/089976699300016304
   Kearns M. J., 1994, An Introduction to Computational Learning Theory
   Koyner JL, 2018, CRIT CARE MED, V46, P1070, DOI 10.1097/CCM.0000000000003123
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   LUGOSI G, 1994, IEEE T INFORM THEORY, V40, P475, DOI 10.1109/18.312167
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mühlbacher T, 2018, IEEE T VIS COMPUT GR, V24, P174, DOI 10.1109/TVCG.2017.2745158
   Palczewska A., 2014, Integration of reusable systems, P193, DOI [DOI 10.1007/978-3-319-04717-1_9, 10.1007/978-3-319-04717-1_9]
   Pearson K., 1895, Proceedings of the Royal Society London, Vlviii, P240
   Policar P.G., 2019, OPENTSNE MODULAR PYT
   Reshef DN, 2018, ANN APPL STAT, V12, P123, DOI 10.1214/17-AOAS1093
   Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438
   Reshef YA, 2016, J MACH LEARN RES, V17, P1
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Romano S, 2018, MACH LEARN, V107, P509, DOI 10.1007/s10994-017-5664-2
   Saabas A, 2019, TREEINTERPRETER
   Shaikhina T, 2019, BIOMED SIGNAL PROCES, V52, P456, DOI 10.1016/j.bspc.2017.01.012
   Shortliffe EH, 2018, JAMA-J AM MED ASSOC, V320, P2199, DOI 10.1001/jama.2018.17163
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang C, 2018, IEEE INT CONF BIG DA, P1661, DOI 10.1109/BigData.2018.8622502
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zheng T, 2017, INT J MED INFORM, V97, P120, DOI 10.1016/j.ijmedinf.2016.09.014
NR 53
TC 16
Z9 18
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2020
VL 4
IS 2
SI SI
BP 122
EP 131
DI 10.1016/j.visinf.2020.04.005
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KK
UT WOS:000658192100006
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Lampropoulos, G
   Keramopoulos, E
   Diamantaras, K
AF Lampropoulos, Georgios
   Keramopoulos, Euclid
   Diamantaras, Konstantinos
TI Enhancing the functionality of augmented reality using deep learning,
   semantic web and knowledge graphs: A review
SO VISUAL INFORMATICS
LA English
DT Review
DE Augmented reality; Machine learning; Deep learning; Semantic web;
   Knowledge graph; Human computer interaction
ID PRINCIPLES; EDUCATION; DESIGN
AB The growth rates of today's societies and the rapid advances in technology have led to the need for access to dynamic, adaptive and personalized information in real time. Augmented reality provides prompt access to rapidly flowing information which becomes meaningful and ``alive'' as it is embedded in the appropriate spatial and time framework. Augmented reality provides new ways for users to interact with both the physical and digital world in real time. Furthermore, the digitization of everyday life has led to an exponential increase of data volume and consequently, not only have new requirements and challenges been created but also new opportunities and potentials have arisen. Knowledge graphs and semantic web technologies exploit the data increase and web content representation to provide semantically interconnected and interrelated information, while deep learning technology offers novel solutions and applications in various domains. The aim of this study is to present how augmented reality functions and services can be enhanced when integrating deep learning, semantic web and knowledge graphs and to showcase the potentials their combination can provide in developing contemporary, user-friendly and user-centered intelligent applications. Particularly, we briefly describe the concept of augmented reality and mixed reality and present deep learning, semantic web and knowledge graphs technologies. Moreover, based on our literature review, we present and analyze related studies regarding the development of augmented reality applications and systems that utilize these technologies. Finally, after discussing how the integration of deep learning, semantic web and knowledge graphs into augmented reality enhances the quality of experience and quality of service of augmented reality applications to facilitate and improve users' everyday life, conclusions and suggestions for future research and studies are given. (C) 2020 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Lampropoulos, Georgios; Keramopoulos, Euclid; Diamantaras, Konstantinos] Int Hellen Univ, Dept Informat & Elect Engn, Thessaloniki, Greece.
C3 International Hellenic University
RP Lampropoulos, G (corresponding author), Int Hellen Univ, Dept Informat & Elect Engn, Thessaloniki, Greece.
EM lamprop.geo@gmail.com
RI Diamantaras, Konstantinos/ABE-3902-2021; Keramopoulos,
   Euclid/HKE-5657-2023
OI Diamantaras, Konstantinos/0000-0003-1373-4022; Keramopoulos,
   Euclid/0000-0001-6566-6477; Lampropoulos, Georgios/0000-0002-5719-2125
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   ABDI L., 2017, P S APPL COMP APR, P131
   Abrahams S., 2016, TENSORFLOW MACHINE I
   Akgul O, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P47, DOI 10.1109/SITIS.2016.17
   Aliprantis J, 2018, LECT NOTES COMPUT SC, V10605, P79, DOI 10.1007/978-3-319-75826-8_7
   Amin Dhiraj, 2015, International Journal on Computational Science & Applications, V5, P11, DOI DOI 10.5121/IJCSA.2015.5102
   [Anonymous], 2018, WORKSH INFORM OPTICS
   [Anonymous], 1998, P INT VEH S STUTTG G
   Antoniou Grigoris, 2004, A Semantic Web Primer
   Apple Inc, 2019, ARKit
   ARmedia Inc, 2019, ARM
   ARToolworks Inc, 2019, ARTOOLKIT
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   Bennett, 2018, ARXIV181111190
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Boyer StuartA., 2009, SCADA SUPERVISORY CO
   Bradski G, 2000, DR DOBBS J, V25, P120
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   Contreras P, 2017, 2017 XLIII LATIN AMERICAN COMPUTER CONFERENCE (CLEI)
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Flores-Flores CD, 2019, STUD COMPUT INTELL, V815, P269, DOI 10.1007/978-3-030-06149-4_12
   Dean M., 2004, SWRL: a semantic web Rule Language combining OWL and RuleML
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   Dunleavy M, 2014, TECHTRENDS, V58, P28, DOI 10.1007/s11528-013-0717-2
   Ehrlinger Lisa, 2016, SEMANTiCS, V48, P2, DOI DOI 10.1016/J.STR.2015.04.004
   Enyedy N, 2015, INT J COMP-SUPP COLL, V10, P7, DOI 10.1007/s11412-015-9207-1
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Feilmayr C, 2016, DATA KNOWL ENG, V101, P1, DOI 10.1016/j.datak.2015.11.003
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Google Inc, 2019, ARCORE
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hegde V, 2010, W3C WORKSH AUGM REAL, V1
   Hervás R, 2013, J UNIVERS COMPUT SCI, V19, P1334
   Hogan A., 2019, KNOWLEDGE GRAPHS NEW, V8, P74
   Hong, 2017, KSII T INTERNET INF, V11
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Jetschni Jonas, 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P271, DOI 10.1109/INTELCIS.2017.8260074
   Jian Wu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5644, DOI 10.1109/ICRA.2017.7989663
   Johnson L., 2010, The 2010 Horizon Report
   Jung, 2019, 2019 IEEE AER C BIG, P1, DOI DOI 10.1109/AERO.2019.8741692
   Katsaros A, 2017, 2017 SOUTH EASTERN EUROPEAN DESIGN AUTOMATION, COMPUTER ENGINEERING, COMPUTER NETWORKS AND SOCIAL MEDIA CONFERENCE (SEEDA-CECNSM), P48
   Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kim H, 2017, MULTIMED TOOLS APPL, V76, P26001, DOI 10.1007/s11042-017-4868-6
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krötzsch M, 2016, LECT NOTES COMPUT SC, V9981, P376, DOI 10.1007/978-3-319-46523-4_23
   Krotzsch M., 2017, DESCRIPTION LOGICS
   Lampropoulos G., 2019, INT J ENTREPRENEURIA, V7, P4, DOI [DOI 10.37335/IJEK.V7I1.84, 10.2478/ijek-2019-0001, DOI 10.2478/IJEK-2019-0001]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Lepetit Vincent, 2008, International Symposium on Ubiquitous Virtual Reality - ISUVR 2008, P13, DOI 10.1109/ISUVR.2008.10
   Li ZY, 2018, NEUROINFORMATICS, V16, P339, DOI 10.1007/s12021-018-9361-5
   Limmer M, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1888, DOI 10.1109/ITSC.2016.7795862
   Lin CH, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P1075, DOI 10.1109/ICASI.2018.8394464
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Magic Leap Inc, 2019, MAG LEAP
   Makkonen P., 2019, P WORLD C E LEARN CO, P457
   Matuszka T., 2014, Int. J. Comput. Inf. Sci. Eng, V8, P32
   McGee M.K., 1999, THESIS VIRGINIA TECH
   McGuinness D. L., 2004, OWL WEB ONTOLOGY LAN, DOI DOI 10.2004-03
   Metavision Inc, 2019, MET 2
   Microsoft Inc, 2019, HOL
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Nowacki Pawel, 2020, Engineering in Dependability of Computer Systems and Networks. Proceedings of the Fourteenth International Conference on Dependability of Computer Systems DepCoS-RELCOMEX. Advances in Intelligent Systems and Computing (AISC 987), P358, DOI 10.1007/978-3-030-19501-4_36
   Paulheim H, 2017, SEMANT WEB, V8, P489, DOI 10.3233/SW-160218
   Planche B, 2017, INT CONF 3D VISION, P1, DOI 10.1109/3DV.2017.00011
   Polap Dawid, 2017, Sensors, V17, P1
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Rao JM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17091951
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ruiz J., 2019, ACM CHI, P281
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salampasis M, 2017, 8 INT C INF COMM TEC, P805
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Schroder M., 2017, ACM SIGGRAPH 2017 PO
   Schüle F, 2013, IEEE INT VEH SYM, P1233, DOI 10.1109/IVS.2013.6629635
   Scicluna, 2012, OTM CONF INT C MOV M, P863
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   Shvaiko P, 2013, IEEE T KNOWL DATA EN, V25, P158, DOI 10.1109/TKDE.2011.253
   Simonyan K., 2014, 14091556 ARXIV
   Singhal A., 2012, Introducing the knowledge graph: Things, not strings
   Soylu A, 2012, INTEGR COMPUT-AID E, V19, P93, DOI 10.3233/ICA-2012-0393
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   Suarez-Figueroa M.C., 2010, THESIS INFORMATICA
   Subakti H, 2018, P INT COMP SOFTW APP, P63, DOI 10.1109/COMPSAC.2018.10204
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan M., 2019, ARXIV190709595
   Taylor S, 2011, INT J COMPUT VISION, V94, P241, DOI 10.1007/s11263-011-0430-6
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   VANAART C, 2010, LECT NOTES ARTIF INT, P257
   Vert S, 2014, COMM COM INF SC, V465, P334
   Vert S, 2014, COMM COM INF SC, V465, P324
   Vuforia Inc, 2019, VUF
   Vuolle M., 2008, 10th International Conference on Human Computer Interaction with Mobile Devices and Services, P53, DOI DOI 10.1145/1409240.1409247
   Vuzix Inc, 2019, VUZ BLAD
   Wang RZ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SAFETY FOR ROBOTICS (ISR), P267, DOI 10.1109/IISR.2018.8535823
   Wasko C, 2013, TECHTRENDS, V57, P17, DOI 10.1007/s11528-013-0672-y
   Wikitude Inc, 2019, WIK
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yan JH, 2018, FRONT COMPUT SCI-CHI, V12, P55, DOI 10.1007/s11704-016-5228-9
   Zaklouta F, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2151, DOI 10.1109/IJCNN.2011.6033494
   Zhao H, 2018, APL MATER, V6, DOI 10.1063/1.5046839
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zoph B., 2016, INT C LEARN REPR
NR 133
TC 50
Z9 55
U1 6
U2 51
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2020
VL 4
IS 1
BP 32
EP 42
DI 10.1016/j.visinf.2020.01.001
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KB
UT WOS:000658191200004
OA gold
DA 2024-07-18
ER

PT J
AU Yuan, LP
   Li, BY
   Li, SQ
   Wong, KK
   Zhang, R
   Qu, HM
AF Yuan, Linping
   Li, Boyu
   Li, Siqi
   Wong, Kam Kwai
   Zhang, Rong
   Qu, Huamin
TI Tax-Scheduler: An interactive visualization system for staff shifting
   and scheduling at tax authorities
SO VISUAL INFORMATICS
LA English
DT Article
DE Staff scheduling; Tax service; Genetic algorithm; Time series prediction
ID MULTIOBJECTIVE OPTIMIZATION; GENETIC ALGORITHM
AB Given a large number of applications and complex processing procedures, how to efficiently shift and schedule tax officers to provide good services to taxpayers is now receiving more attention from tax authorities. The availability of historical application data makes it possible for tax managers to shift and schedule staff with data support, but it is unclear how to properly leverage the historical data. To investigate the problem, this study adopts a user-centered design approach. We first collect user requirements by conducting interviews with tax managers and characterize their requirements of shifting and scheduling into time series prediction and resource scheduling problems. Then, we propose Tax-Scheduler, an interactive visualization system with a time-series prediction algorithm and genetic algorithm to support staff shifting and scheduling in the tax scenarios. To evaluate the effectiveness of the system and understand how non-technical tax managers react to the system with advanced algorithms and visualizations, we conduct user interviews with tax managers and distill several implications for future system design.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Yuan, Linping; Wong, Kam Kwai; Zhang, Rong; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Li, Boyu] Xi An Jiao Tong Univ, Xian, Shaanxi, Peoples R China.
   [Li, Siqi] Tianjin Univ Sci & Technol, Tianjin, Peoples R China.
C3 Hong Kong University of Science & Technology; Xi'an Jiaotong University;
   Tianjin University Science & Technology
RP Qu, HM (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM huamin@cse.ust.hk
RI LI, BOYU/IUO-0933-2023; ZHU, JIALI/JNE-3065-2023; xu,
   lingzhi/JVZ-8748-2024
FU  [FSUST19-CWB09]
FX We would like to thank Ziqiang Zheng, Xingbo Wang, Dong Sun, and Dongyu
   Liu for their suggestions for this work. This research is supported by
   the grant FSUST19-CWB09 under the Foshan-HKUST Projects.
CR Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen Y, 2019, IEEE T CLOUD COMPUT, V7, P537, DOI 10.1109/TCC.2016.2607750
   Choi E, 2016, ADV NEUR IN, V29
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   CONNOR J, 1992, ADV NEUR IN, V4, P301
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Du Yuntao, 2021, CIKM '21: Proceedings of the 30th ACM International Conference on Information & Knowledge Management, P402, DOI 10.1145/3459637.3482315
   Elsayed S, 2021, Arxiv, DOI arXiv:2101.02118
   Fan MM, 2020, J USABILITY STUD, V15, P85
   Fonseca C.M., 1993, IEE C GENETIC ALGORI, P1
   Gretton A., 2012, Advances in Neural Information Processing Systems (NIPS 2012), V25
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   HAJELA P, 1992, STRUCT OPTIMIZATION, V4, P99, DOI 10.1007/BF01759923
   Horn J., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P82, DOI 10.1109/ICEC.1994.350037
   Ibrahim R, 2016, INT J FORECASTING, V32, P865, DOI 10.1016/j.ijforecast.2015.11.012
   Konak A, 2006, RELIAB ENG SYST SAFE, V91, P992, DOI 10.1016/j.ress.2005.11.018
   Lai GK, 2018, ACM/SIGIR PROCEEDINGS 2018, P95, DOI 10.1145/3209978.3210006
   Li SY, 2019, ADV NEUR IN, V32
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Lu W, 2022, Arxiv, DOI arXiv:2207.12020
   Luo Z., 2012, Web Information Systems Engineering-WISE 2012, P777
   Palaniyappan R, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P720, DOI 10.1145/3490099.3511150
   Pandit S.M., 1984, Time Series and System Analysis with Applications by Sudhakar Madhavrao Pandit and Shien-Ming Wu
   Ruan WJ, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2021, DOI 10.1145/2983323.2983899
   Seng HS, 2013, 2013 INTERNATIONAL CONFERENCE ON NEW MEDIA STUDIES (CONMEDIA)
   Shi QQ, 2020, AAAI CONF ARTIF INTE, V34, P5758
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Srinivas N., 1994, Evolutionary Computation, V2, P221, DOI 10.1162/evco.1994.2.3.221
   Sun D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376866
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   Sun Y, 2018, WIRELESS PERS COMMUN, V102, P1369, DOI 10.1007/s11277-017-5200-5
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P475, DOI 10.1109/TVCG.2021.3114790
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P3441, DOI 10.1109/TVCG.2021.3067200
   Wen RF, 2018, Arxiv, DOI [arXiv:1711.11053, 10.48550/arXiv.1711.11053]
   Wong K. K., 2023, IEEE T VIS COMPUT GR
   Wu WY, 2010, J WATER RES PL-ASCE, V136, P555, DOI 10.1061/(ASCE)WR.1943-5452.0000072
   Xu K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445083
   Xu K, 2020, IEEE T VIS COMPUT GR, V26, P1107, DOI 10.1109/TVCG.2019.2934613
   Yang L., 2021, IEEE T VIS COMPUT GR
   Yang MD, 2016, ENERG BUILDINGS, V122, P120, DOI 10.1016/j.enbuild.2016.04.027
   Yue XW, 2020, IEEE T VIS COMPUT GR, V26, P601, DOI 10.1109/TVCG.2019.2934660
   Zhang C., 2022, IEEE Transactions on Visualization and Computer Graphics
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
NR 45
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 30
EP 40
DI 10.1016/j.visinf.2023.02.001
EA JUN 2023
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA M9RI2
UT WOS:001033509100001
OA gold
DA 2024-07-18
ER

PT J
AU Chen, SY
   Zhang, JQ
   Zhao, YY
   Rosin, PL
   Lai, YK
   Gao, L
AF Chen, Shu-Yu
   Zhang, Jia-Qi
   Zhao, You-You
   Rosin, Paul L.
   Lai, Yu-Kun
   Gao, Lin
TI A review of image and video colorization: From analogies to deep
   learning
SO VISUAL INFORMATICS
LA English
DT Review
DE Image colorization; Sketch colorization; Manga colorization
AB Image colorization is a classic and important topic in computer graphics, where the aim is to add color to a monochromatic input image to produce a colorful result. In this survey, we present the history of colorization research in chronological order and summarize popular algorithms in this field. Early work on colorization mostly focused on developing techniques to improve the colorization quality. In the last few years, researchers have considered more possibilities such as combining colorization with NLP (natural language processing) and focused more on industrial applications. To better control the color, various types of color control are designed, such as providing reference images or color-scribbles. We have created a taxonomy of the colorization methods according to the input type, divided into grayscale, sketch-based and hybrid. The pros and cons are discussed for each algorithm, and they are compared according to their main characteristics. Finally, we discuss how deep learning, and in particular Generative Adversarial Networks (GANs), has changed this field.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Chen, Shu-Yu; Gao, Lin] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
   [Zhang, Jia-Qi] Beihang Univ, Beijing, Peoples R China.
   [Zhao, You-You] Univ Calif Santa Cruz, Santa Cruz, CA USA.
   [Rosin, Paul L.; Lai, Yu-Kun] Cardiff Univ, Cardiff, Wales.
   [Gao, Lin] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Beihang University; University of California System; University of
   California Santa Cruz; Cardiff University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
EM gaolin@ict.ac.cn
RI Lai, Yu-Kun/D-2343-2010; Gao, Lin/JNF-0375-2023
OI Rosin, Paul/0000-0002-4965-3884; Lai, Yukun/0000-0002-2094-5680
FU National Nat-ural Science Foundation of China; Beijing Municipal Natural
   Science Foun-dation for Distinguished Young Scholars; Youth Innovation
   Promotion Association CAS; Royal Society Newton Advanced Fellowship;
   NAF; Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University;  [61872440];  [62102403]
FX Acknowledgments We thank the anonymous reviewers for the constructive
   com-ments. This work was supported by grants from the National Nat-ural
   Science Foundation of China (No. 61872440, No. 62061136007 and No.
   62102403) , the Beijing Municipal Natural Science Foun-dation for
   Distinguished Young Scholars (No. JQ21013) , the Youth Innovation
   Promotion Association CAS, Royal Society Newton Advanced Fellowship (No.
   NAF\R2\192151) and the Open Project Program of State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang University (No.
   VRLAB2022C07) .
CR [Anonymous], 2001, Schooling for Tomorrow
   [Anonymous], 2015, CVPR
   [Anonymous], 2006, 2006 C COMPUTER VISI
   Antic J., Deoldify
   Anwar S, 2022, Arxiv, DOI [arXiv:2008.10774, DOI 10.48550/ARXIV.2008.10774]
   Bahng H, 2018, LECT NOTES COMPUT SC, V11216, P443, DOI 10.1007/978-3-030-01258-8_27
   Bénard P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461929
   Bugeau A, 2014, IEEE T IMAGE PROCESS, V23, P298, DOI 10.1109/TIP.2013.2288929
   Chang YL, 2019, IEEE I CONF COMP VIS, P9065, DOI 10.1109/ICCV.2019.00916
   Chen DD, 2017, IEEE I CONF COMP VIS, P1114, DOI 10.1109/ICCV.2017.126
   Chen JB, 2018, PROC CVPR IEEE, P8721, DOI 10.1109/CVPR.2018.00909
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SY, 2022, IEEE T VIS COMPUT GR, V28, P1198, DOI 10.1109/TVCG.2020.3009949
   Chen SY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459760
   Chen SY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392386
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Chen T, 2013, IEEE T VIS COMPUT GR, V19, P824, DOI 10.1109/TVCG.2012.148
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   Deshpande A, 2017, PROC CVPR IEEE, P2877, DOI 10.1109/CVPR.2017.307
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Fang FM, 2020, IEEE T VIS COMPUT GR, V26, P2931, DOI 10.1109/TVCG.2019.2908363
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fourey S., 2018, EG VMV 18 P C VISION, P1, DOI [10.2312/vmv.20181247, DOI 10.2312/VMV.20181247]
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Gao L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356488
   Ge C., 2022, IEEE T IMAGE PROCESS
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta R. K., 2012, P 20 ACM INT C MULT, P369, DOI DOI 10.1145/2393347.2393402
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hensel M, 2017, ADV NEUR IN, V30
   Hensman P, 2017, PROC INT CONF DOC, P72, DOI 10.1109/ICDAR.2017.295
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Iizuka S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356570
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Ishii D., 2009, STUDY CONTROL PARAME
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jamriska O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323006
   Jheng-Wei Su, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7965, DOI 10.1109/CVPR42600.2020.00799
   Kang SH, 2007, IEEE T IMAGE PROCESS, V16, P2251, DOI 10.1109/TIP.2007.903257
   Kim H, 2019, Arxiv, DOI arXiv:1908.05840
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2020, International Conference on Learning RepreSentations
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Lee YJ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964922
   Lei CY, 2019, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2019.00387
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li B, 2019, IEEE T IMAGE PROCESS, V28, P4606, DOI 10.1109/TIP.2019.2912291
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Lin A.S., 2017, arXiv
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu CX, 2017, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2017.143
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Liu YF, 2017, Arxiv, DOI arXiv:1705.01908
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luan Q., 2007, P 18 EUR C CREND TEC, P309
   Manjunatha Varun, 2018, NAACL HLT 2018, V2, P764
   Messaoud S, 2018, LECT NOTES COMPUT SC, V11210, P603, DOI 10.1007/978-3-030-01231-1_37
   Morimoto Y., 2009, SIGGRAPH 09, DOI 10.1145/1599301.1599333
   Odena A, 2017, PR MACH LEARN RES, V70
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Pierre F, 2015, SIAM J IMAGING SCI, V8, P536, DOI 10.1137/140979368
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Radford A, 2021, PR MACH LEARN RES, V139
   Ratliff ND, 2009, AUTON ROBOT, V27, P25, DOI 10.1007/s10514-009-9121-3
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Salimans T, 2016, ADV NEUR IN, V29
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Sato K., 2014, SIGGRAPH ASIA 2014 T, DOI [10.1145/2669024.2669037, DOI 10.1145/2669024.2669037]
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi Min, 2022, IEEE T VIS COMPUT GR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siyao L., 2021, P IEEECVF C COMPUTER, P6587
   Stone M, 2012, P SIGCHI C HUMAN FAC, P1007, DOI DOI 10.1145/2207676.2208547
   Sun TH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P683, DOI 10.1145/3343031.3351041
   Sykora D, 2005, IMAGE VISION COMPUT, V23, P767, DOI 10.1016/j.imavis.2005.05.010
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Thasarathan H., 2019, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Vondrick C, 2018, LECT NOTES COMPUT SC, V11217, P402, DOI 10.1007/978-3-030-01261-8_24
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P1241, DOI 10.1109/TPAMI.2012.47
   Wang XH, 2012, J COMPUT SCI TECH-CH, V27, P1119, DOI 10.1007/s11390-012-1290-4
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Wu YZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14357, DOI 10.1109/ICCV48922.2021.01411
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Yang LM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450284
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yi-Chin Huang, 2005, 13th Annual ACM International Conference on Multimedia, P351, DOI 10.1145/1101149.1101223
   Yonetsuji T., 2017, PAINTSCHAINER, V1, P2
   Yoo S, 2019, PROC CVPR IEEE, P11275, DOI 10.1109/CVPR.2019.01154
   Zeger I, 2021, IEEE ACCESS, V9, P113326, DOI 10.1109/ACCESS.2021.3104515
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang J., 2018, P JOINT S COMPUTATIO, P1
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
   Zou CQ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356561
NR 110
TC 7
Z9 7
U1 10
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2022
VL 6
IS 3
BP 51
EP 68
DI 10.1016/j.visinf.2022.05.003
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 5U7AG
UT WOS:000876695000001
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Yuan, L
   Fujishiro, I
AF Yuan, Liang
   Fujishiro, Issei
TI Multiview SVBRDF capture from unified shape and illumination
SO VISUAL INFORMATICS
LA English
DT Article
DE Appearance modeling; SVBRDF; Image processing
ID RECOVERY
AB This paper proposes a stable method for reconstructing spatially varying appearances (SVBRDFs) from multiview images captured under casual lighting conditions. Unlike flat surface capture methods, ours can be applied to surfaces with complex silhouettes. The proposed method takes multiview images as inputs and outputs a unified SVBRDF estimation. We generated a large-scale dataset containing the multiview images, SVBRDFs, and lighting appearance of vast synthetic objects to train a two-stream hierarchical U-Net for SVBRDF estimation that is integrated into a differentiable rendering network for surface appearance reconstruction. In comparison with state-of-the-art approaches, our method produces SVBRDFs with lower biases for more casually captured images.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Yuan, Liang; Fujishiro, Issei] Keio Univ, Tokyo, Japan.
C3 Keio University
RP Yuan, L (corresponding author), Keio Univ, Tokyo, Japan.
EM liangyuan@keio.jp
OI Fujishiro, Issei/0000-0002-8898-730X; Yuan, Liang/0000-0001-5610-9388
FU Research Grant of Keio Leading -edge Laboratory of Science Technology
   [JP21H04916]; Keio Leading-edge Laboratory of Science Technology
FX This work has been partially supported by Grant-in-Aid for Scientific
   Research (A) JP21H04916 and the Research Grant of Keio Leading-edge
   Laboratory of Science & Technology.
CR Asselin LP, 2020, INT CONF 3D VISION, P1157, DOI 10.1109/3DV50981.2020.00126
   Azinovic D, 2019, PROC CVPR IEEE, P2442, DOI 10.1109/CVPR.2019.00255
   Bi S, 2020, Arxiv, DOI [arXiv:2008.03824, 10.48550/arXiv.2008.03824, DOI 10.48550/ARXIV.2008.03824]
   Bi S, 2020, PROC CVPR IEEE, P5959, DOI 10.1109/CVPR42600.2020.00600
   Boss M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12664, DOI 10.1109/ICCV48922.2021.01245
   Boss M, 2020, PROC CVPR IEEE, P3981, DOI 10.1109/CVPR42600.2020.00404
   Boss Mark, 2022, ADV NEURAL INFORM PR
   Boss Mark, 2021, ADV NEURAL INFORM PR, P2
   Burley B., 2012, ACM SIGGRAPH 2012 CO, V2, P3
   Cole F, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6068, DOI 10.1109/ICCV48922.2021.00603
   Deschaintre V, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13765
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dong Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661283
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459854
   Guo Y, 2020, COMPUT GRAPH FORUM, V39, P255, DOI 10.1111/cgf.14142
   Guo Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417779
   Holroyd M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778836
   Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Kang KZ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356492
   Karis B., 2013, Proc. Physically Based Shading Theory Practice, V4, P1
   KASSON JM, 1992, ACM T GRAPHIC, V11, P373, DOI 10.1145/146443.146479
   Langguth F, 2016, LECT NOTES COMPUT SC, V9907, P469, DOI 10.1007/978-3-319-46487-9_29
   Lensch HPA, 2001, SPRING EUROGRAP, P103
   Lettry L, 2018, IEEE WINT CONF APPL, P1359, DOI 10.1109/WACV.2018.00153
   Li X., 2022, arXiv
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Li ZQ, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275055
   Liu GL, 2017, IEEE I CONF COMP VIS, P2280, DOI 10.1109/ICCV.2017.248
   Lombardi S, 2016, IEEE T PATTERN ANAL, V38, P129, DOI 10.1109/TPAMI.2015.2430318
   Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11
   Luan FJ, 2021, COMPUT GRAPH FORUM, V40, P101, DOI 10.1111/cgf.14344
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Munkberg J, 2022, PROC CVPR IEEE, P8270, DOI 10.1109/CVPR52688.2022.00810
   Nam G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275017
   Narihira T, 2015, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2015.342
   Paszke A, 2019, ADV NEUR IN, V32
   Pollefeys M, 2002, COMMUN ACM, V45, P50, DOI 10.1145/514236.514263
   PolyHaven, 2023, Poly Haven: The public 3D asset library
   Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sengupta S, 2022, IEEE T PATTERN ANAL, V44, P3272, DOI 10.1109/TPAMI.2020.3046915
   Shi L, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417781
   Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578
   Song SR, 2019, PROC CVPR IEEE, P6911, DOI 10.1109/CVPR.2019.00708
   Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401
   Tobin J, 2017, IEEE INT C INT ROBOT, P23
   Unity, 2023, High definition render pipeline in unity
   Vecchio G., 2021, P IEEE CVF INT C COM
   Verbin D, 2022, PROC CVPR IEEE, P5481, DOI 10.1109/CVPR52688.2022.00541
   Vicini D, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530139
   Wu HZ, 2016, IEEE T VIS COMPUT GR, V22, P2012, DOI 10.1109/TVCG.2015.2498617
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xia R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980248
   Xu ZX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323007
   Yariv L., 2020, Advances in Neural Information Processing Systems, V33, P2492, DOI DOI 10.48550/ARXIV.2003.09852
   Zhang C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392383
   Zhang K, 2021, PROC CVPR IEEE, P5449, DOI 10.1109/CVPR46437.2021.00541
   Zhang XM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480496
   Zhou XL, 2021, COMPUT GRAPH FORUM, V40, P315, DOI 10.1111/cgf.142635
NR 64
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2023
VL 7
IS 3
BP 11
EP 21
DI 10.1016/j.visinf.2023.06.006
EA SEP 2023
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA U2JQ8
UT WOS:001083122800001
OA gold
DA 2024-07-18
ER

PT J
AU Emami, N
   Sedaei, Z
   Ferdousi, R
AF Emami, Neda
   Sedaei, Zahra
   Ferdousi, Reza
TI Computerized cell tracking: Current methods, tools and challenges
SO VISUAL INFORMATICS
LA English
DT Review
DE Cell tracking; Digital cell tracking; Live-cell microscopy; Image
   analysis; Bioimage informatics; Subcellular location
ID SINGLE-PARTICLE TRACKING; MULTIPLE OBJECT TRACKING; MOLECULE TRACKING;
   SUBDIFFRACTIONAL TRACKING; LINEAGE CONSTRUCTION; AUTOMATED TRACKING;
   IMAGE-ANALYSIS; 3D TRACKING; MIGRATION; DYNAMICS
AB In developmental biology, knowledge of cell structure and their (morpho) dynamic behavior, leads to a comprehensive understanding of their conducts and the mechanisms in which they participate. This knowledge is a decisive factor in biological research and also in all drug development steps, medicinal or preventive therapies. Experimental cell analysis is hard, expensive, and time-consuming. To overcome these difficulties, in recent years, several computational object tracking methods, software system and packages have been developed in cell sciences that bring together different disciplines and branches of technologies.
   Object tracking is the process of locating and monitoring specific object and its behavior in sequential images. In this paper, a comprehensive review on object tracking stages and computational methods that are utilized in terms of cell tracking has been organized. Besides, the available software packages and toolkits, challenges, and their solution in time lapse microscopy images in this scope were reviewed. The aim of describing computational cell tracking methods and tools is that biologist and cell scientists might take advantage of these computational techniques to find another method to gain complementary information for their question of interest. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Emami, Neda; Ferdousi, Reza] Tabriz Univ Med Sci, Sch Management & Med Informat, Dept Hlth Informat Technol, Tabriz 516615731, Iran.
   [Sedaei, Zahra] Tabriz Univ Med Sci, Sch Management & Med Informat, Dept Hlth Serv Management, Tabriz 516615731, Iran.
C3 Tabriz University of Medical Science; Tabriz University of Medical
   Science
RP Ferdousi, R (corresponding author), Tabriz Univ Med Sci, Sch Management & Med Informat, Dept Hlth Informat Technol, Tabriz 516615731, Iran.
EM neda.emami72@gmail.com; sedaeizahra@gmail.com; ferdousi.r@gmail.com
RI Ferdousi, Reza/K-9977-2017
OI Ferdousi, Reza/0000-0001-5511-5452
FU Tabriz University of Medical Sciences, Iran
FX The authors like to acknowledge the financial support provided by the
   Tabriz University of Medical Sciences, Iran.
CR Abramoff M. D., 2004, BIOPHOTONICS INT, V11, P36, DOI DOI 10.1201/9781420005615.AX4
   Al-Kofahi O, 2006, CELL CYCLE, V5, P327, DOI 10.4161/cc.5.3.2426
   Altinok A, 2007, BMC CELL BIOL, V8, DOI 10.1186/1471-2121-8-S1-S4
   Aman A, 2010, DEV BIOL, V341, P20, DOI 10.1016/j.ydbio.2009.11.014
   [Anonymous], INT J MODERN TRENDS
   Appelhans T, 2017, METHODS MOL BIOL, V1567, P273, DOI 10.1007/978-1-4939-6824-4_17
   Asaithamby A, 2011, MUTAT RES-FUND MOL M, V711, P87, DOI 10.1016/j.mrfmmm.2010.11.002
   Bacher CP, 2004, BMC CELL BIOL, V5, DOI 10.1186/1471-2121-5-45
   Bise Ryoma., 2011, ENG MED BIOL SOC EMB
   Bjornsson CS, 2008, J NEUROSCI METH, V170, P165, DOI 10.1016/j.jneumeth.2007.12.024
   Blong CC, 2010, J NEUROSCI RES, V88, P1445, DOI 10.1002/jnr.22324
   Bosch PJ, 2014, BIOPHYS J, V107, P803, DOI 10.1016/j.bpj.2014.06.040
   Boukari F., 2018, IEEE ACM T COMPUT BI
   Boukari F, 2020, IEEE ACM T COMPUT BI, V17, P959, DOI 10.1109/TCBB.2018.2875684
   Boyle TJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-275
   Brasch ME, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211408
   Braun V, 2003, BIOINFORMATICS, V19, P851, DOI 10.1093/bioinformatics/btg087
   Buonviri A., 2019, AEROSP CONF PROC, DOI DOI 10.1109/aero.2019.8742216
   Carpenter AE, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-10-r100
   Celler K, 2013, BIOCHEM BIOPH RES CO, V438, P38, DOI 10.1016/j.bbrc.2013.07.016
   Chen DY, 2017, CELL REP, V21, P559, DOI 10.1016/j.celrep.2017.09.083
   Chenouard N, 2013, IEEE T PATTERN ANAL, V35, P2736, DOI 10.1109/TPAMI.2013.97
   Cognet L, 2014, CURR OPIN CHEM BIOL, V20, P78, DOI 10.1016/j.cbpa.2014.04.015
   Cooper S, 2017, BIOINFORMATICS, V33, P3320, DOI 10.1093/bioinformatics/btx404
   Cordelières FP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081266
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Courty S., 2013, COLD SPRING HARBOR P, V2013
   Daynac M, 2015, JOVE-J VIS EXP, DOI 10.3791/53247
   de Chaumont F, 2012, NAT METHODS, V9, P690, DOI [10.1038/nmeth.2075, 10.1038/NMETH.2075]
   Dou XQ, 2019, ACS APPL MATER INTER, V11, P38568, DOI 10.1021/acsami.9b15710
   Downey MJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027886
   Dupont A, 2013, BIOPHYS J, V104, P2373, DOI 10.1016/j.bpj.2013.04.005
   Emami N, 2020, J THEOR BIOL, V497, DOI 10.1016/j.jtbi.2020.110268
   Falconnet D, 2011, LAB CHIP, V11, P466, DOI [10.1039/c0lc00228c, 10.1039/c01c00228c]
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Feng LQ, 2011, J STRUCT BIOL, V173, P219, DOI 10.1016/j.jsb.2010.11.001
   Ferdousi R, 2020, BIOIMPACTS, V10, P97, DOI 10.34172/bi.2020.12
   Fiaz M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309665
   Gahlmann A, 2014, NAT REV MICROBIOL, V12, P9, DOI 10.1038/nrmicro3154
   Gardini L, 2015, SCI REP-UK, V5, DOI 10.1038/srep16088
   Georgescu W, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129438
   Gerlich D, 2003, METHODS, V29, P3, DOI 10.1016/S1046-2023(02)00287-6
   Gilad T, 2019, BIOINFORMATICS, V35, P2644, DOI 10.1093/bioinformatics/bty1034
   Godinez W.J., 2007, 2007 4 IEEE INT S BI
   Godinez William J, 2015, IEEE Trans Med Imaging, V34, P415, DOI 10.1109/TMI.2014.2359541
   Gómez-Villafuertes R, 2017, JOVE-J VIS EXP, DOI 10.3791/56291
   Gonzalez R.C., 1977, DIGITAL IMAGE PROCES
   Gupta H., 2019, REV IMAGE DENOISING
   Gupta K, 2008, ADVANCES IN COMPUTER AND INFORMATIOM SCIENCES AND ENGINEERING, P245, DOI 10.1007/978-1-4020-8741-7_44
   Hatakeyama H, 2017, MOL BIOL CELL, V28, P173, DOI 10.1091/mbc.E16-06-0413
   Hirose O, 2018, IEEE ACM T COMPUT BI, V15, P1822, DOI 10.1109/TCBB.2017.2782255
   Hodneland E, 2016, IEEE T MED IMAGING, V35, P957, DOI 10.1109/TMI.2015.2503328
   Hoornweg TE, 2016, J VIROL, V90, P4745, DOI 10.1128/JVI.03184-15
   Horigane S, 2019, J BIOCHEM, V165, P401, DOI 10.1093/jb/mvz012
   Huang YL, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/693484
   Huh S., 2013, THESIS
   Huth J, 2010, BMC CELL BIOL, V11, DOI 10.1186/1471-2121-11-24
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Jaqaman K, 2008, NAT METHODS, V5, P695, DOI 10.1038/nmeth.1237
   Javaremi AN, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082883
   Jiang LZ, 2019, APOPTOSIS, V24, P208, DOI 10.1007/s10495-018-01511-x
   Joensuu M, 2017, NAT PROTOC, V12, P2590, DOI 10.1038/nprot.2017.116
   Joensuu M, 2016, J CELL BIOL, V215, P277, DOI 10.1083/jcb.201604001
   Kalaidzidis Y, 2007, EUR J CELL BIOL, V86, P569, DOI 10.1016/j.ejcb.2007.05.005
   Kankaanpää P, 2012, NAT METHODS, V9, P683, DOI [10.1038/nmeth.2047, 10.1038/NMETH.2047]
   Keenan TM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013187
   Khan Z, 2004, LECT NOTES COMPUT SC, V2034, P279
   Kong J., 2015, 2015 IEEE 12 INT S B
   Kong J, 2015, I S BIOMED IMAGING, P1212, DOI 10.1109/ISBI.2015.7164091
   Kusumi A, 2005, SEMIN IMMUNOL, V17, P3, DOI 10.1016/j.smim.2004.09.004
   Kusumi A, 2014, NAT CHEM BIOL, V10, P524, DOI [10.1038/NCHEMBIO.1558, 10.1038/nchembio.1558]
   Kwak YH, 2010, CELL IMMUNOL, V265, P44, DOI 10.1016/j.cellimm.2010.07.001
   Kwakowsky A, 2013, J NEUROENDOCRINOL, V25, P1231, DOI 10.1111/jne.12083
   Li CH, 2016, TRENDS BIOCHEM SCI, V41, P818, DOI 10.1016/j.tibs.2016.07.012
   Li F, 2017, IMAGE VISION COMPUT, V60, P124, DOI 10.1016/j.imavis.2017.01.003
   Li FH, 2010, IEEE T MED IMAGING, V29, P96, DOI 10.1109/TMI.2009.2027813
   Li K, 2008, MED IMAGE ANAL, V12, P546, DOI 10.1016/j.media.2008.06.001
   Li L, 2013, BURNS TRAUMA, V1, DOI 10.4103/2321-3868.113331
   Liu Jun S, 2008, MONTE CARLO STRATEGI
   Liu M., 2019, IEEE ACM T COMPUT BI
   Liu M, 2018, IEEE ACM T COMPUT BI, V15, P1706, DOI 10.1109/TCBB.2017.2760300
   Liu WX, 2019, IEEE T IMAGE PROCESS, V28, P3766, DOI 10.1109/TIP.2019.2902784
   Lopes MB, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2937-8
   Lund FW, 2014, TRAFFIC, V15, P1406, DOI 10.1111/tra.12228
   Luo D., 1998, Journal of Computer-Assisted Microscopy, V10, P151, DOI 10.1023/A:1023482003483
   Ma YQ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15100
   MacGillavry H.D., 2013, CURRENT PROTOC NEURO, P1
   Maglica Z, 2015, MBIO, V6, DOI 10.1128/mBio.02236-14
   Majumdar R, 2019, CURR OPIN CELL BIOL, V57, P123, DOI 10.1016/j.ceb.2018.12.013
   Mankowski W.C., 2014, 2014 36 ANN INT C IE
   Maraschin SD, 2005, PLANTA, V220, P531, DOI 10.1007/s00425-004-1371-x
   Maska M, 2014, BIOINFORMATICS, V30, P1609, DOI 10.1093/bioinformatics/btu080
   Masuzzo P, 2016, TRENDS CELL BIOL, V26, P88, DOI 10.1016/j.tcb.2015.09.003
   Matov A, 2010, NAT METHODS, V7, P761, DOI 10.1038/nmeth.1493
   McColl J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31014-3
   Mehta SB, 2016, P NATL ACAD SCI USA, V113, pE6352, DOI 10.1073/pnas.1607674113
   Meijering E, 2012, IEEE SIGNAL PROC MAG, V29, P140, DOI 10.1109/MSP.2012.2204190
   Meijering E, 2012, METHOD ENZYMOL, V504, P183, DOI 10.1016/B978-0-12-391857-4.00009-4
   Meijering E, 2009, SEMIN CELL DEV BIOL, V20, P894, DOI 10.1016/j.semcdb.2009.07.004
   Meirovitch Y., 2019, P IEEE C COMP VIS PA
   Meunier B, 2010, HISTOCHEM CELL BIOL, V134, P307, DOI 10.1007/s00418-010-0733-7
   Moogk D, 2007, BIOTECHNOL BIOENG, V97, P1138, DOI 10.1002/bit.21335
   Moura M, 2019, BIOMOLECULES, V9, DOI 10.3390/biom9020055
   Mukewar P., 2004, BIOM IM NAN MACR 200
   Murray JI, 2006, NAT PROTOC, V1, P1468, DOI 10.1038/nprot.2006.222
   Namba T, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025303
   Neumann S, 2017, TRAFFIC, V18, P71, DOI 10.1111/tra.12456
   Nikouei SY, 2019, WILEY SER PARA DIST, P319
   Nketia TA, 2017, METHODS, V115, P65, DOI 10.1016/j.ymeth.2017.02.007
   Noctor SC, 2004, NAT NEUROSCI, V7, P136, DOI 10.1038/nn1172
   Ong ST, 2019, METHODS MOL BIOL, V1930, P33, DOI 10.1007/978-1-4939-9036-8_5
   Ong SH, 1996, COMPUT BIOL MED, V26, P269, DOI 10.1016/0010-4825(96)00004-2
   Parekh H.S., 2014, INT J INNOVATIVE RES, V2, P2970
   Piltti K.M., 2017, METHODS
   Piltti KM, 2018, METHODS, V133, P81, DOI 10.1016/j.ymeth.2017.10.003
   Pineda G, 2016, SCI REP-UK, V6, DOI 10.1038/srep23885
   Puliafito A, 2012, P NATL ACAD SCI USA, V109, P739, DOI 10.1073/pnas.1007809109
   Raef B, 2020, HEALTH INFORM J, V26, P1810, DOI 10.1177/1460458219892138
   Raef Behnaz, 2019, Acta Inform Med, V27, P205, DOI 10.5455/aim.2019.27.205-211
   Ram S, 2012, BIOPHYS J, V103, P1594, DOI 10.1016/j.bpj.2012.08.054
   Rapoport DH, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027315
   Reig G, 2014, DEVELOPMENT, V141, P1999, DOI 10.1242/dev.101451
   Rino J, 2016, METHODS, V98, P143, DOI 10.1016/j.ymeth.2016.02.005
   Roccio M, 2013, DEVELOPMENT, V140, P459, DOI 10.1242/dev.086215
   Rust M.J., 2011, Cold Spring Harb. Protoc, V2011, P1978
   Sacan A, 2008, BIOINFORMATICS, V24, P1647, DOI 10.1093/bioinformatics/btn247
   Sakaue-Sawano A, 2008, CELL, V132, P487, DOI 10.1016/j.cell.2007.12.033
   Samdurkar A.S., 2017, OVERVIEW OBJECT DETE
   Samdurkar S.A., 2017, OVERVIEW OBJECT DETE, P313
   Saurabh S., 2017, CURR PROTOC CELL BIO, P1
   Sbalzarini IF, 2005, J STRUCT BIOL, V151, P182, DOI 10.1016/j.jsb.2005.06.002
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Schmidt U, 2018, LECT NOTES COMPUT SC, V11071, P265, DOI 10.1007/978-3-030-00934-2_30
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shahen VA, 2018, ACTA HISTOCHEM, V120, P797, DOI 10.1016/j.acthis.2018.09.001
   Shen H, 2006, J R SOC INTERFACE, V3, P787, DOI 10.1098/rsif.2006.0137
   Shrier Diane K, 2004, J Am Acad Psychoanal Dyn Psychiatry, V32, P91, DOI 10.1521/jaap.32.1.91.28332
   Sigal L., 2004, INT WORKSH COMPL MOT
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   Skommer J, 2010, CELL CYCLE, V9, P2330, DOI 10.4161/cc.9.12.11911
   Smal I, 2008, MED IMAGE ANAL, V12, P764, DOI 10.1016/j.media.2008.03.004
   Smal I, 2008, IEEE T MED IMAGING, V27, P789, DOI 10.1109/TMI.2008.916964
   Spoerri L, 2017, METHODS MOL BIOL, V1612, P401, DOI 10.1007/978-1-4939-7021-6_29
   Sun ShiJie, 2019, IEEE T PATTERN ANAL
   Svensson CM, 2018, CYTOM PART A, V93A, P357, DOI 10.1002/cyto.a.23249
   Thomann D, 2002, J MICROSC-OXFORD, V208, P49, DOI 10.1046/j.1365-2818.2002.01066.x
   Thompson MA, 2010, P NATL ACAD SCI USA, V107, P17864, DOI 10.1073/pnas.1012868107
   Tofighi M, 2019, IEEE T MED IMAGING, V38, P2047, DOI 10.1109/TMI.2019.2895318
   Tokunaga T, 2014, BIOINFORMATICS, V30, P43, DOI 10.1093/bioinformatics/btu271
   Tosi S, 2019, METHODS MOL BIOL, V2040, P385, DOI 10.1007/978-1-4939-9686-5_18
   Ulman V, 2017, NAT METHODS, V14, P1141, DOI 10.1038/nmeth.4473
   Valente AJ, 2017, ACTA HISTOCHEM, V119, P315, DOI 10.1016/j.acthis.2017.03.001
   Vallotton P, 2017, TRAFFIC, V18, P840, DOI 10.1111/tra.12530
   Vallotton P, 2013, MICROSC MICROANAL, V19, P451, DOI 10.1017/S1431927612014328
   van der Schaar HM, 2008, PLOS PATHOG, V4, DOI 10.1371/journal.ppat.1000244
   Vicente-Manzanares M, 2011, METHODS MOL BIOL, V769, P1, DOI 10.1007/978-1-61779-207-6_1
   Wait E, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-328
   Wand M. P., 1994, KERNEL SMOOTHING, DOI DOI 10.1201/B14876
   Wen L, 2017, J NANOBIOTECHNOL, V15, DOI 10.1186/s12951-017-0270-9
   Xu Y, 2019, DATA BRIEF, V22, P605, DOI 10.1016/j.dib.2018.12.076
   Yan T., 2019, IEEE T IMAGE PROCESS
   Yang FW, 2016, J BIOMECH, V49, P1290, DOI 10.1016/j.jbiomech.2016.02.008
   Yokose J, 2011, NEUROSCI RES, V69, P223, DOI 10.1016/j.neures.2010.11.010
   Yoo J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010034
   Youssef S, 2011, INTEGR BIOL-UK, V3, P1095, DOI 10.1039/c1ib00035g
   Zerjatke T, 2017, CELL REP, V19, P1953, DOI 10.1016/j.celrep.2017.05.022
NR 166
TC 31
Z9 33
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2021
VL 5
IS 1
BP 1
EP 13
DI 10.1016/j.visinf.2020.11.003
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LE
UT WOS:000658194100001
OA gold
DA 2024-07-18
ER

PT J
AU Dwyer, T
   Cordeil, M
   Czauderna, T
   Haghighi, PD
   Ens, B
   Goodwin, S
   Jenny, B
   Marriott, K
   Wybrow, M
AF Dwyer, Tim
   Cordeil, Maxime
   Czauderna, Tobias
   Haghighi, Pari Delir
   Ens, Barrett
   Goodwin, Sarah
   Jenny, Bernhard
   Marriott, Kim
   Wybrow, Michael
TI The Data Visualisation and Immersive Analytics Research Lab at Monash
   University
SO VISUAL INFORMATICS
LA English
DT Article
DE Immersive Analytics; Data Visualisation; Network visualisation;
   Cartographic visualisation; Interactive optimisation
ID LAYOUT; MAPS; GENERATION; MODELS; SCALE
AB This article reviews two decades of research in topics in Information Visualisation emerging from the Data Visualisation and Immersive Analytics Lab at Monash University Australia (Monash IA Lab). The lab has been influential with contributions in algorithms, interaction techniques and experimental results in Network Visualisation, Interactive Optimisation and Geographic and Cartographic visualisation. It has also been a leader in the emerging topic of Immersive Analytics, which explores natural interactions and immersive display technologies in support of data analytics. We reflect on advances in these areas but also sketch our vision for future research and developments in data visualisation more broadly. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Dwyer, Tim; Cordeil, Maxime; Czauderna, Tobias; Haghighi, Pari Delir; Ens, Barrett; Goodwin, Sarah; Jenny, Bernhard; Marriott, Kim; Wybrow, Michael] Monash Univ, Clayton, Vic, Australia.
C3 Monash University
RP Dwyer, T (corresponding author), Monash Univ, Clayton, Vic, Australia.
EM tim.dwyer@monash.edu
RI Delir Haghighi, Pari/AAV-8378-2020
OI Delir Haghighi, Pari/0000-0001-9922-1214; Ens,
   Barrett/0000-0001-6695-4809; Wybrow, Michael/0000-0001-5536-7780;
   Cordeil, Maxime/0000-0002-9732-4874; Jenny,
   Bernhard/0000-0001-6101-6100; Goodwin, Sarah/0000-0001-8894-8282;
   Czauderna, Tobias/0000-0002-1788-9593; Dwyer, Tim/0000-0002-9076-9571
FU Australian Research Council [DP140100077, DP180100755]
FX This work was supported by the Australian Research Council through
   grants DP140100077 and DP180100755.
CR Austin CR, 2020, CARTOGR GEOGR INF SC, V47, P214, DOI 10.1080/15230406.2019.1696232
   Bach B., 2019, 2019 CHI C HUM FACT, P1
   Bach B, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P529, DOI 10.1145/2992154.2996365
   Bach Benjamin, 2017, IEEE VIS ACCEPTED WO, V2, P1
   Badros G.J., 2001, Proceedings of the 10th International Conference on World Wide Web, April 2001, P489
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Belov G, 2018, LECT NOTES COMPUT SC, V11008, P473, DOI 10.1007/978-3-319-98334-9_31
   Belov G, 2017, LECT NOTES COMPUT SC, V10416, P321, DOI 10.1007/978-3-319-66158-2_21
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Borning A, 2000, MULTIMEDIA SYST, V8, P177, DOI 10.1007/s005300000043
   Bouts QW, 2016, IEEE T VIS COMPUT GR, V22, P2200, DOI 10.1109/TVCG.2015.2500225
   Braganza C. M., 2009, P 18 INT C WORLD WID, P831, DOI DOI 10.1145/1526709.1526821
   Büchel F, 2013, BMC SYST BIOL, V7, DOI 10.1186/1752-0509-7-116
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Chen KT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376180
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE PAC VIS SYMP, P46, DOI 10.1109/PACIFICVIS.2017.8031578
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Czauderna T, 2018, LECT NOTES COMPUT SC, V11190, P289, DOI 10.1007/978-3-030-01388-2_10
   Czauderna T, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-250
   Danyluk K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300594
   Dourish P., 2004, ACTION IS FDN EMBODI
   Dwyer T, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P65, DOI 10.1109/INFVIS.2005.1532130
   Dwyer T., 2016, DAGSTUHL REP, V6, P1, DOI [10.4230/DagRep, DOI 10.4230/DAGREP]
   Dwyer T, 2008, IEEE T VIS COMPUT GR, V14, P1293, DOI 10.1109/TVCG.2008.130
   Dwyer T, 2006, IEEE T VIS COMPUT GR, V12, P821, DOI 10.1109/TVCG.2006.156
   Dwyer T, 2016, IEEE COMPUT GRAPH, V36, P78, DOI 10.1109/MCG.2016.117
   Dwyer T, 2014, IEEE PAC VIS SYMP, P105, DOI 10.1109/PacificVis.2014.46
   Dwyer T, 2013, IEEE T VIS COMPUT GR, V19, P2596, DOI 10.1109/TVCG.2013.151
   Dwyer T, 2010, LECT NOTES ARTIF INT, V6170, P212, DOI 10.1007/978-3-642-14600-8_20
   Dwyer T, 2009, IEEE T VIS COMPUT GR, V15, P961, DOI 10.1109/TVCG.2009.109
   Dwyer T, 2009, LECT NOTES COMPUT SC, V5417, P420, DOI 10.1007/978-3-642-00219-9_41
   Dwyer T, 2009, LECT NOTES COMPUT SC, V5417, P230, DOI 10.1007/978-3-642-00219-9_22
   Ens B., 2020, IEEE T VIS COMPUT GR, V1
   Ens B, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375145
   Goncu C, 2011, LECT NOTES COMPUT SC, V6946, P30, DOI 10.1007/978-3-642-23774-4_5
   Goodwin S, 2017, IEEE T VIS COMPUT GR, V23, P281, DOI 10.1109/TVCG.2016.2598545
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Haghighi P.D., 2017, JMIR PUBL HLTH SURVE, V3
   He W., 1998, Constraints, V3, P289, DOI 10.1023/A:1009771921595
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Jayaraman PP, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1350
   Jena A., 2021, COMPUT GRAPH APPL
   Jenny B., CARTOGR GEOGR INF SC
   Jenny B, 2020, CARTOGR GEOGR INF SC
   Jenny B., 2020, IEEE T VIS COMPUT GR
   Jenny B, 2018, CARTOGR GEOGR INF SC, V45, P62, DOI 10.1080/15230406.2016.1262280
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Kieffer S, 2016, IEEE T VIS COMPUT GR, V22, P349, DOI 10.1109/TVCG.2015.2467451
   Klapperstueck M., 2016, 2016 BIG DATA VISUAL, P1
   Lee B., 2020, TVCG
   Lee B, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P335, DOI 10.1145/3343055.3360746
   Lee BS, 2020, IEEE COMPUT GRAPH, V40, P82, DOI 10.1109/MCG.2020.2968244
   Liu, ARXIV PREPRINT ARXIV
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.00-23, 10.1109/VR46266.2020.1581122519414]
   Liu J, 2018, IEEE T VIS COMPUT GR, V24, P319, DOI 10.1109/TVCG.2017.2744418
   Marriott K., 2018, ZONE ISSUE
   Marriott K., 2018, IMMERSIVE ANAL
   Marriott K, 2012, IEEE T VIS COMPUT GR, V18, P2477, DOI 10.1109/TVCG.2012.245
   Marriott K, 2011, IEEE T VIS COMPUT GR, V17, P290, DOI 10.1109/TVCG.2010.45
   McConachie F, 2020, J MAPS, V16, P13, DOI 10.1080/17445647.2019.1701574
   Meulemans W, 2013, IEEE T VIS COMPUT GR, V19, P1846, DOI 10.1109/TVCG.2013.76
   Nicholson A.E., 2020, ARXIV200301207
   Pokharel R, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290720
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Quach Q, 2020, CARTOGR GEOGR INF SC, V47, P471, DOI 10.1080/15230406.2020.1771771
   Reinders S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376145
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Samsonov T, 2019, INT J GEOGR INF SCI, V33, P2072, DOI 10.1080/13658816.2019.1610965
   Satriadi K.A., 2020, PROC ACM HUM COMPUT
   Satriadi KA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P593, DOI [10.1109/vr.2019.8798340, 10.1109/VR.2019.8798340]
   Savric B, 2019, INT J GEOGR INF SCI, V33, P454, DOI 10.1080/13658816.2018.1504949
   Schreiber F, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-375
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Stivala A, 2011, BIOINFORMATICS, V27, P3315, DOI 10.1093/bioinformatics/btr575
   Wybrow M., 2008, ACM T COMPUT-HUM INT, V14, P1
   Yang Y., 2020, IEEE T VIS COMPUT GR
   Yang YL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376367
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
   Yang YL, 2017, IEEE T VIS COMPUT GR, V23, P411, DOI 10.1109/TVCG.2016.2598885
   Yang Y, 2020, IEEE T VIS COMPUT GR, V26, P1140, DOI 10.1109/TVCG.2019.2934557
   Yoghourdjian V., 2020, ARXIV PREPRINT ARXIV
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   Yoghourdjian V, 2018, IEEE T VIS COMPUT GR, V24, P3081, DOI 10.1109/TVCG.2018.2790961
   Yoghourdjian V, 2016, IEEE T VIS COMPUT GR, V22, P339, DOI 10.1109/TVCG.2015.2467251
NR 88
TC 3
Z9 3
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2020
VL 4
IS 4
BP 41
EP 49
DI 10.1016/j.visinf.2020.11.001
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KZ
UT WOS:000658193600020
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Ceneda, D
   Gschwandtner, T
   Miksch, S
AF Ceneda, Davide
   Gschwandtner, Theresia
   Miksch, Silvia
TI You get by with a little help: The effects of variable guidance degrees
   on performance and mental state
SO VISUAL INFORMATICS
LA English
DT Article
DE Guidance; User study; Knowledge; Trust; Mixed-initiative; Visual data
   analysis
ID SOFTWARE LIBRARY
AB Since it can be challenging for users to effectively utilize interactive visualizations, guidance is usually provided to assist users in solving tasks. Guidance is mentioned as an effective mean to overcome stall situations occurring during the analysis. However, the effectiveness of a peculiar guidance solution usually varies for different analysis scenarios. The same guidance may have different effects on users with (1) different levels of expertise. The choice of the appropriate (2) degree of guidance and the type of (3) task under consideration also affect the positive or negative outcome of providing guidance. Considering these three factors, we conducted a user study to investigate the effectiveness of variable degrees of guidance with respect to the user's previous knowledge in different analysis scenarios. Our results shed light on the appropriateness of certain degrees of guidance in relation to different tasks, and the overall influence of guidance on the analysis outcome in terms of user's mental state and analysis performance. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Ceneda, Davide; Gschwandtner, Theresia; Miksch, Silvia] TU Wien, Inst Visual Comp & Human Ctr Technol, Fac Informat, Favoritenstr 9-11-193, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Ceneda, D (corresponding author), TU Wien, Inst Visual Comp & Human Ctr Technol, Fac Informat, Favoritenstr 9-11-193, A-1040 Vienna, Austria.
EM davide.ceneda@tuwien.ac.at
OI Ceneda, Davide/0000-0003-1198-567X; Miksch, Silvia/0000-0003-4427-5703
FU Austrian Science Fund (FWF) [P31419-N31]; Austrian Science Fund (FWF)
   [P31419] Funding Source: Austrian Science Fund (FWF)
FX This work was supported and funded by the Austrian Science Fund (FWF),
   grant P31419-N31.
CR Aigner W, 2013, COMPUT GRAPH FORUM, V32, P41, DOI 10.1111/cgf.12091
   [Anonymous], 2005, ILLUMINATING PATH RE
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   Bederson B., 2003, CRAFT INFORM VISUALI
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernstein A, 2005, IEEE T KNOWL DATA EN, V17, P503, DOI 10.1109/TKDE.2005.67
   Bertini E., 2009, Proceedings of the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery: Integrating Automated Analysis with Interactive Exploration, P12
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   Brusilovsky P., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P3, DOI 10.1007/978-3-540-72079-9_1
   Çelik P, 2013, J EXP SOC PSYCHOL, V49, P635, DOI 10.1016/j.jesp.2013.02.010
   Ceneda D., 2018, EUROVA, P19, DOI DOI 10.2312/EUROVA.20181107
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen CM, 2005, IEEE COMPUT GRAPH, V25, P12, DOI 10.1109/MCG.2005.91
   Cloern James E, 2016, USGS
   de Winter J. F. C., 2010, PRACT ASSESS RES EVA, V15, P11, DOI DOI 10.7275/BJ1P-TS64
   Dix Alan, 2004, HUM-COMPUT INTERACT
   Gotz D, 2009, P 14 INT C INT US IN, P315, DOI [DOI 10.1145/1502650.1502695, 10.1145/1502650.15026951, DOI 10.1145/1502650.15026951]
   Horvitz Eric, 1999, P SIGCHI C HUM FACT, P159
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Mazurowski MA, 2010, MED PHYS, V37, P1152, DOI 10.1118/1.3301575
   R Core Team, 2018, R LANG ENV STAT COMP
   Rind A, 2013, IEEE T VIS COMPUT GR, V19, P2247, DOI 10.1109/TVCG.2013.206
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   SMITH S, 1986, ESDTR86278 MITR CORP
   Streit M, 2012, IEEE T VIS COMPUT GR, V18, P998, DOI 10.1109/TVCG.2011.108
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
NR 31
TC 4
Z9 4
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2019
VL 3
IS 4
BP 177
EP 191
DI 10.1016/j.visinf.2019.10.005
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YM
UT WOS:000658190500003
OA gold
DA 2024-07-18
ER

PT J
AU Boussejra, MO
   Uchiki, R
   Takeshima, Y
   Matsubayashi, K
   Takekawa, S
   Uemura, M
   Fujishiro, I
AF Boussejra, Malik Olivier
   Uchiki, Rikuo
   Takeshima, Yuriko
   Matsubayashi, Kazuya
   Takekawa, Shunya
   Uemura, Makoto
   Fujishiro, Issei
TI aflak: Visual programming environment enabling end-to-end provenance
   management for the analysis of astronomical datasets
SO VISUAL INFORMATICS
LA English
DT Article
DE Astronomy; Provenance; Visual programming; Visualization
AB This paper describes an extendable graphical framework, aflak, which provides a visualization and provenance management environment for the analysis of multi-spectral astronomical datasets. Via its node editor interface, aflak allows the astronomer to compose transforms on input datasets queryable from public astronomical data repositories, then to export the results of the analysis as Flexible Image Transport System (FITS) files, in a manner such that the full provenance of the output data be preserved and reviewable, and that the exported file be usable by other common astronomical analysis software. FITS is the standard of data interchange in astronomy. By embedding aflak's provenance data into FITS files, we both achieve interoperability with existing software and full reproducibility of the process by which astronomers make discoveries. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Boussejra, Malik Olivier; Uchiki, Rikuo; Fujishiro, Issei] Keio Univ, Kouhoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa, Japan.
   [Takeshima, Yuriko] Tokyo Univ Technol, 1404-1 Katakuramachi, Hachioji, Tokyo, Japan.
   [Matsubayashi, Kazuya] Kyoto Univ, 3037-5 Honjo, Okayama, Japan.
   [Takekawa, Shunya] Natl Astron Observ Japan, Nobeyama Radio Observ, 462-2 Nobeyama, Nagano, Japan.
   [Uemura, Makoto] Hiroshima Univ, 1-3-2 Kagamiyama, Higashihiroshima, Hiroshima, Japan.
C3 Keio University; Tokyo University of Technology; Kyoto University;
   National Institutes of Natural Sciences (NINS) - Japan; National
   Astronomical Observatory of Japan (NAOJ); Hiroshima University
RP Boussejra, MO (corresponding author), Keio Univ, Kouhoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa, Japan.
EM malik@boussejra.com
RI Uemura, Makoto/AEF-1123-2022
OI Uemura, Makoto/0000-0002-7375-7405; Takekawa, Shunya/0000-0001-8147-6817
FU JSPS KAKENHI (Japan) [17K00173, 17H00737]; Grants-in-Aid for Scientific
   Research [17K00173] Funding Source: KAKEN
FX This work is supported by JSPS KAKENHI (Japan) Grant Numbers 17K00173
   and 17H00737.
CR Altintas I, 2006, LECT NOTES COMPUT SC, V4145, P118
   Bavoil L, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P135, DOI 10.1109/visual.2005.1532788
   Borne K, 2018, ASTRONOMICAL DATA AN
   Boussejra M.O., 2019, IEEE SCIVIS 2018 SHO
   Boussejra M.O., P ASTR DAT AN SOFTW
   Cameron G., 1995, ACM COMPUTER GRAPHIC, V29, P3, DOI [10.1145/ 204362.204363, DOI 10.1145/204362.204363]
   Carroll B., 2007, PEARSON INT EDITION
   De La Peña MD, 2001, ASTR SOC P, V238, P59
   Dowler P., IVOA SIMPLE IMAGE AC
   Fujishiro Issei, 2018, Journal of Physics: Conference Series, V1036, DOI 10.1088/1742-6596/1036/1/012011
   Galkin A, 2018, LECT NOTES COMPUT SC, V11017, P252, DOI 10.1007/978-3-319-98379-0_30
   Groth P., 2010, ARXIV PREPRINT ARXIV
   Group F.W, 0000 DEFINITION FLEX
   Hassan AH, 2011, NEW ASTRON, V16, P100, DOI 10.1016/j.newast.2010.07.009
   Isuru Suriarachchi, 2015, J OPEN RES SOFTWARE, V3
   Joye W. A., 2003, ASP C SER, P489
   Kent BR, 2013, PUBL ASTRON SOC PAC, V125, P731, DOI 10.1086/671412
   Louys M., 2017, OBSERVATION DATA MOD
   Matsubayashi K, 2011, ASTROPHYS J, V729, DOI 10.1088/0004-637X/729/1/29
   Meyer-Spradow J, 2009, IEEE COMPUT GRAPH, V29, P6, DOI 10.1109/MCG.2009.130
   Muna D, 2016, ARXIV PREPRINT ARXIV
   Muna D, 2017, ASTR SOC P, V512, P621
   Muniswamy-Reddy KK, 2006, USENIX ASSOCIATION PROCEEDINGS OF THE 2006 USENIX ANNUAL TECHNICAL CONFERENCE, P43
   Ochsenbein F., 2013, VOTABLE FORMAT DEFIN
   Oka T, 2017, NAT ASTRON, V1, P709, DOI 10.1038/s41550-017-0224-z
   Ortiz I., 2008, IVOA ASTRONOMICAL DA
   Ott T, 2012, ascl:1210.019 2012ascl.soft10019O
   Parker SG, 1995, SUPERCOMP PROC, P1419
   Perkins S, 2014, NEW ASTRON, V30, P1, DOI 10.1016/j.newast.2013.12.007
   Raemaekers S, 2017, J SYST SOFTWARE, V129, P140, DOI 10.1016/j.jss.2016.04.008
   RITTER GX, 1990, COMPUT VISION GRAPH, V49, P297, DOI 10.1016/0734-189X(90)90106-6
   Robitaille TP, 2013, ASTRON ASTROPHYS, V558, DOI 10.1051/0004-6361/201322068
   Servillat M, 2018, IVOA PROVENANCE DATA
   Tody D., 1986, Instrumentation in astronomy VI, V627, P733, DOI [10.1117/12.968154, DOI 10.1117/12.968154]
   Wells D.C., 1979, Image Processing in Astronomy, P445
NR 35
TC 8
Z9 8
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2019
VL 3
IS 1
BP 1
EP 8
DI 10.1016/j.visinf.2019.03.001
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YJ
UT WOS:000658187900001
OA gold
DA 2024-07-18
ER

PT J
AU Ueno, Y
   Natsukawa, H
   Aoyama, N
   Koyamada, K
AF Ueno, Yuki
   Natsukawa, Hiroaki
   Aoyama, Nozomi
   Koyamada, Koji
TI Exploration behavior of group-in-a-box layouts
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual search; Eye-tracking; Group-in-a-box layout
AB To improve visualization, it is necessary to optimize the design by analyzing the behavior of users as well as improving the evaluation index of the computational experiment and the task performance (e.g., the correct answer rate and completion time) in the user experiment. Although various studies have investigated the influence of user behavior on the evaluation of visualization, majority of these studies focused on simple visualization tasks. A simple task does not indicate a simple visualization comprising a few visualization elements but a task in which the information obtained from visualization is the only clue for completing the task. However, a few studies have targeted complicated tasks in which multiple information obtained from visualization is considered to be a clue for completing the task regardless of the number of elements that are contained in the visualization. Therefore, in this study, we investigated the behavior of the participants who have performed complicated tasks. We selected two types of group-in-a-box (GIB) layouts, which can be considered to be a complicated visualization method, as the target of the user experiment. In the user experiment, participants were asked to perform an exploration task specific to GIB layouts; which group has the maximum number of intra-edges? We also collected the eye-tracking data in addition to task performance. The results showed that the correct answer rate is considerably affected by the visualization factor; whether the correct answer, the box with maximum number of intra-edges, is the box with the largest area. Furthermore, an analysis of the collected eye-tracking data revealed that this visualization factor affected the exploration behavior of the participants; however, it did not affect the location at which the participants were focused on. The obtained results indicated that the visualization elements that were not considered by the visualization designer can influence the task of extracting information from the data. Therefore, designers have to configure the visualization by considering the visual cognitive behavior of the users. (C) 2019 Zhejiang University and Zhejiang University Press.
C1 [Ueno, Yuki; Aoyama, Nozomi] Kyoto Univ, Dept Elect Engn, Kyoto, Japan.
   [Natsukawa, Hiroaki; Koyamada, Koji] Kyoto Univ, Acad Ctr Comp & Media Studies, Kyoto, Japan.
C3 Kyoto University; Kyoto University
RP Natsukawa, H (corresponding author), Kyoto Univ, Acad Ctr Comp & Media Studies, Kyoto, Japan.
EM natsukawa.hiroaki.3u@kyoto-u.ac.jp
RI Natsukawa, Hiroaki/ABA-1304-2020
FU JST CREST, Japan [JPMJCR1511]; Keihanshin Consortium for Fostering the
   Next Generation of Global Leaders in Research (K-CONNEX) by Human
   Resource Development Program for Science and Technology, MEXT
FX This work was supported by JST CREST, Japan Grant Number JPMJCR1511,
   Japan, and The Keihanshin Consortium for Fostering the Next Generation
   of Global Leaders in Research (K-CONNEX), established Dby Human Resource
   Development Program for Science and Technology, MEXT.
CR Andrienko G, 2012, IEEE T VIS COMPUT GR, V18, P2889, DOI 10.1109/TVCG.2012.276
   BECKER RA, 1995, IEEE T VIS COMPUT GR, V1, P16, DOI 10.1109/2945.468391
   Blascheck T, 2016, IEEE T VIS COMPUT GR, V22, P61, DOI 10.1109/TVCG.2015.2467871
   Bruls M, 2000, SPRING COMP SCI, P33
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2440, DOI 10.1109/TVCG.2011.193
   Chaturvedi S, 2014, COMPUT GRAPH FORUM, V33, P52, DOI 10.1111/cgf.12400
   Gansner ER, 2009, LECT NOTES COMPUT SC, V5417, P206, DOI 10.1007/978-3-642-00219-9_20
   Huang Weidong., 2008, P 2008 WORKSHOP TIME, P3
   Kim SH, 2012, IEEE T VIS COMPUT GR, V18, P2421, DOI 10.1109/TVCG.2012.215
   Kobourov S.G, 2004, 12 FORCE DIRECTED DR
   Netzel R, 2017, IEEE T VIS COMPUT GR, V23, P421, DOI 10.1109/TVCG.2016.2598898
   Netzel R, 2014, IEEE T VIS COMPUT GR, V20, P2221, DOI 10.1109/TVCG.2014.2346420
   Olsen A., 2012, TOBII TECHNOL, V21, P4
   Onoue Y, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139308
   Pohl M., 2009, COMPUTATIONAL AESTHE, P49, DOI [DOI 10.2312/COMPAESTH/COMPAESTH09/049-056, 10.5555/2381286.2381296]
   Purchase H. C., 2002, Empirical Software Engineering, V7, P233, DOI 10.1023/A:1016344215610
   Purchase H. C., 1997, LECT NOTES COMPUTER, V1353, P248, DOI [10.1007/3-540-63938-167, DOI 10.1007/3-540-63938-1_67, 10.1007/3-540-63938-1_677]
   Purchase HC, 1998, J VISUAL LANG COMPUT, V9, P647, DOI 10.1006/jvlc.1998.0093
   Rodrigues E. M., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P354, DOI 10.1109/PASSAT/SocialCom.2011.139
   Saket B., 2014, ARXIV PREPRINT ARXIV
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
NR 21
TC 3
Z9 3
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2019
VL 3
IS 1
BP 38
EP 47
DI 10.1016/j.visinf.2019.03.005
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YJ
UT WOS:000658187900005
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Klaus, J
   Blacher, M
   Goral, A
   Lucas, P
   Giesen, J
AF Klaus, Julien
   Blacher, Mark
   Goral, Andreas
   Lucas, Philipp
   Giesen, Joachim
TI A visual analytics workflow for probabilistic modeling
SO VISUAL INFORMATICS
LA English
DT Article
DE Probabilistic inference; Bayesian network; Structured query language;
   Table-based visualization
ID VISUALIZATION
AB Probabilistic programming is a powerful means for formally specifying machine learning models. The inference engine of a probabilistic programming environment can be used for serving complex queries on these models. Most of the current research in probabilistic programming is dedicated to the design and implementation of highly efficient inference engines. Much less research aims at making the power of these inference engines accessible to non-expert users. Probabilistic programming means writing code. Yet many potential users from promising application areas such as the social sciences lack programming skills. This prompted recent efforts in synthesizing probabilistic programs directly from data. However, working with synthesized programs still requires the user to read, understand, and write some code, for instance, when invoking the inference engine for answering queries. Here, we present an interactive visual approach to synthesizing and querying probabilistic programs that does not require the user to read or write code.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Klaus, Julien; Blacher, Mark; Goral, Andreas; Lucas, Philipp; Giesen, Joachim] Friedrich Schiller Univ Jena, Jena, Germany.
C3 Friedrich Schiller University of Jena
RP Klaus, J (corresponding author), Friedrich Schiller Univ Jena, Jena, Germany.
EM julien.klaus@uni-jena.de; mark.blacher@uni-jena.de;
   andreas.goral@uni-jena.de; philipp.lucas@uni-jena.de;
   joachim.giesen@uni-jena.de
OI Blacher, Mark/0009-0007-2009-7996
FU Carl Zeiss Foundation, Germany; Ministry for Economics, Sciences and
   Digital Society of Thuringia (TMWWDG) , Germany [DigLeben-5575/10-9]
FX This work was supported by the Carl Zeiss Foundation, Germany within the
   projects "Interactive Inference"and "A virtual Werkstatt for
   digitization in the sciences", and by the Ministry for Economics,
   Sciences and Digital Society of Thuringia (TMWWDG) , Germany under the
   framework of the Landesprogramm ProDigital (DigLeben-5575/10-9) .
CR Arora N., 2010, ADV NEURAL INFORM PR, V23, P73
   Arora N.S., 2011, P C ARTIFICIAL INTEL
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bingham E, 2019, J MACH LEARN RES, V20
   Blackwell A.F., 2019, P WORKSHOP PSYCHOL P
   Chasins S, 2017, LECT NOTES COMPUT SC, V10426, P279, DOI 10.1007/978-3-319-63387-9_14
   Dillon J. V, 2017, arXiv
   Evidentious Models Inc., BAYESBOX DEM
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Galton F., 1889
   Gelman A, 1996, STAT SINICA, V6, P733
   Gelman A, 2015, J EDUC BEHAV STAT, V40, P530, DOI 10.3102/1076998615606113
   GESIS - Leibniz-Institut fur Sozialwissenschaften, 2017, GESIS, V2.1.0, DOI 10.4232/1.12796
   Goodman N.D., 2020, DESIGN IMPLEMENTATIO
   Goodman ND., 2008, UAI, P220
   Gordon Andrew D., 2014, P FUTURE SOFTWARE EN, P167, DOI [10.1145/2593882.2593900, DOI 10.1145/2593882.2593900]
   Gorinova MI, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2533, DOI 10.1145/2858036.2858221
   Hartigan J. A., 1975, Journal of Statistical Computation and Simulation, V4, P187, DOI 10.1080/00949657508810123
   Herbrich R., 2006, P 19 INT C NEUR INF, P569
   Jessica Li W.C., 2012, TITANIC MACHINE LEAR
   Lucas P., 2021, J OPEN SOURCE SOFTW, V6, P3395
   Lunn D, 2009, STAT MED, V28, P3049, DOI 10.1002/sim.3680
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Milch B, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1352
   Minka T., 2018, Infer.NET 0.3
   Molina A, 2018, AAAI CONF ARTIF INTE, P3828
   MRC Biostatistics Unit, WINBUGS
   Nori AV, 2015, ACM SIGPLAN NOTICES, V50, P208, DOI [10.1145/2737924.2737982, 10.1145/2813885.2737982]
   Pearl J., 1986, Bayesian networks: a model of self-activated memory for evidential reasoning
   Quinlan J Ross, 1993, P 10 INT C MACH LEAR, P236, DOI [10 . 1016 / B978 - 1 - 55860 - 307 - 3 . 50037 - X, DOI 10.1016/B978-1-55860-307-3.50037-X]
   Salvatier J, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.55
   Satyanarayan A., 2014, Symposium on User Interface Software and Technology, P669, DOI DOI 10.1145/2642918.2647360
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Scanagatta M, 2019, PROG ARTIF INTELL, V8, P425, DOI 10.1007/s13748-019-00194-y
   Scutari M, 2010, J STAT SOFTW, V35, P1, DOI 10.18637/jss.v035.i03
   Spiegelhalter DJ., 2003, BAYESIAN APPROACHES
   Stigler S.M., 1986, HIST STAT MEASUREMEN
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Stolte C., 2002, P 8 ACM SIGKDD INT C, P112, DOI [10.1145/775047.7750648, DOI 10.1145/775047.7750648, DOI 10.1145/775047.775064]
   Tamassia R., 2016, Handbook on graph drawing and visualization
   Thaler R. H., 2021, NUDGE FINAL EDITION
   Tran D, 2017, Arxiv, DOI [arXiv:1701.03757, DOI 10.48550/ARXIV.1701.03757, 10.48550/arXiv.1701.03757]
   van de Meent Jan-Willem, 2018, arXiv, DOI DOI 10.48550/ARXIV.1809.10756
   Wilkinson L, 2005, The Grammar of Graphics, V2nd
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245
NR 49
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 72
EP 84
DI 10.1016/j.visinf.2023.05.001
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA M6TG5
UT WOS:001031515400001
OA gold
DA 2024-07-18
ER

PT J
AU Zhao, YH
   Jiang, JJ
   Chen, Y
   Liu, RC
   Yang, YL
   Xue, XY
   Chen, SM
AF Zhao, Yuheng
   Jiang, Jinjing
   Chen, Yi
   Liu, Richen
   Yang, Yalong
   Xue, Xiangyang
   Chen, Siming
TI Metaverse: Perspectives from graphics, interactions and visualization
SO VISUAL INFORMATICS
LA English
DT Article
DE Metaverse; Virtual reality/Augmented reality; Computer graphics; User
   interaction; Immersive visualization
ID VIRTUAL-REALITY; INFORMATION VISUALIZATION; NAVIGATION
AB The metaverse is a visual world that blends the physical world and digital world. At present, the development of the metaverse is still in the early stage, and there lacks a framework for the visual construction and exploration of the metaverse. In this paper, we propose a framework that summarizes how graphics, interaction, and visualization techniques support the visual construction of the metaverse and user-centric exploration. We introduce three kinds of visual elements that compose the metaverse and the two graphical construction methods in a pipeline. We propose a taxonomy of interaction technologies based on interaction tasks, user actions, feedback and various sensory channels, and a taxonomy of visualization techniques that assist user awareness. Current potential applications and future opportunities are discussed in the context of visual construction and exploration of the metaverse. We hope this paper can provide a stepping stone for further research in the area of graphics, interaction and visualization in the metaverse. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Zhao, Yuheng; Jiang, Jinjing; Xue, Xiangyang; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Chen, Yi] Beijing Technol Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.
   [Liu, Richen] Nanjing Normal Univ, Sch Comp & Elect Informat, Nanjing, Peoples R China.
   [Yang, Yalong] Virginia Tech, Dept Comp Sci, Blacksburg, VA USA.
C3 Fudan University; Beijing Technology & Business University; Nanjing
   Normal University; Virginia Polytechnic Institute & State University
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
EM yuhengzhao@fudan.edu.cn; simingchen@fudan.edu.cn
RI Zhang, Xiangyu/AFK-6967-2022; Chen, Siming/AAK-1874-2020; wang,
   wjd/GSD-2051-2022; Liu, Richen/AAB-2890-2022
OI Zhang, Xiangyu/0000-0003-4857-2318; Chen, Siming/0000-0002-2690-3588;
   Liu, Richen/0000-0002-5321-098X; Yang, Yalong/0000-0001-9414-9911; Chen,
   Yi/0000-0002-4141-0554; Zhao, Yuheng/0000-0003-1573-8772
FU Shanghai Municipal Science and Technology Major Project [2018SHZDZX01,
   2021SHZDZX0103]; Shanghai Sailing Program [21YF1402900]; Science and
   Technology Commission of Shanghai Municipality [21ZR1403300]; Open
   Research Fund of Beijing Key Laboratory of Big Data Technology for Food
   Safety [BTBD-2021KF03]; Beijing Technology and Business University; NSFC
   [61972010]; ZJLab
FX This work is supported by Shanghai Municipal Science and Technology
   Major Project (No. 2018SHZDZX01, 2021SHZDZX0103) and ZJLab. This work is
   also supported by Shanghai Sailing Program No. 21YF1402900, Science and
   Technology Commission of Shanghai Municipality (Grant No. 21ZR1403300),
   and supported by Open Research Fund of Beijing Key Laboratory of Big
   Data Technology for Food Safety (Project No. BTBD-2021KF03), Beijing
   Technology and Business University and NSFC No. 61972010.
CR Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   [Anonymous], P 6 INT C BOD AR NET
   Bargteil A.W., 2020, SIGGRAPH ASIA 2020 C
   Batch A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376733
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Beer S., 2015, P 2015 VIRT REAL INT, P1
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Billinghurst M, 1999, MIXED REALITY, P261
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Bouzbib E., 2021, ARXIV PREPRINT ARXIV
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Cantu A, 2018, IEEE PAC VIS SYMP, P175, DOI 10.1109/PacificVis.2018.00030
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Davis A, 2009, J ASSOC INF SYST, V10, P90, DOI 10.17705/1jais.00183
   Dehesa J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376714
   Deng TH, 2021, J MANAGE SCI ENG, V6, P125, DOI 10.1016/j.jmse.2021.03.003
   Duan HH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P153, DOI 10.1145/3474085.3479238
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B., 2014, P 2 ACM S SPAT US IN, P2, DOI DOI 10.1145/2659766.2659769
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Eynard R?my., 2015, 2015 IEEE INT C ENG, P1, DOI DOI 10.1109/ICE.2015.7438679
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Freiknecht Jonas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040027
   Friedman D, 2007, PRESENCE-TELEOP VIRT, V16, P100, DOI 10.1162/pres.16.1.100
   Genay A. C. S., 2021, IEEE Transactions on Visualization and Computer Graphics, V26, DOI 10.1109/TVCG.2021.3099290
   Greenwald S.W., 2017, 12 INT C COMPUTER SU
   Grubert J, 2018, IEEE T VIS COMPUT GR, V24, P2649, DOI 10.1109/TVCG.2017.2754257
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Habermann M., ARXIV PREPRINT ARXIV
   Huang XLD, 2021, COMPUT FLUIDS, V230, DOI 10.1016/j.compfluid.2021.105113
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Intwala AM, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2851, DOI 10.1109/ICEEOT.2016.7755218
   Ivanov A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188544
   Jankowski Jacek., 2013, Eurographics 2013-STAR
   Johnson D., 2019, PROC SOUND MUSIC COM, P202
   Joshua J, 2017, INTERDISCIP LIT STUD, V19, P17
   Kaplan O, 2016, IEEE SYS MAN CYBERN, P994, DOI 10.1109/SMC.2016.7844371
   Karunanayaka K, 2018, IEEE T VIS COMPUT GR, V24, P1496, DOI 10.1109/TVCG.2018.2794073
   Kelly JW, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P687, DOI 10.1109/VR50410.2021.00095
   Khaloo A, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000616
   Kocur M., 2020, 26 ACM S VIRTUAL REA, P1, DOI [10.1145/3385956.3418973, DOI 10.1145/3385956.3418973]
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Latif S, 2022, IEEE COMPUT GRAPH, V42, P73, DOI 10.1109/MCG.2021.3058129
   Lau M., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P271
   Lécuyer A, 2008, COMPUTER, V41, P66, DOI 10.1109/MC.2008.410
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee L., ARXIV PREPRINT ARXIV
   Lee LH, 2018, IEEE ACCESS, V6, P28712, DOI 10.1109/ACCESS.2018.2831081
   Leotta MJ, 2019, IEEE COMPUT SOC CONF, P1451, DOI 10.1109/CVPRW.2019.00186
   Li Y., ANIMATION, V3, P41
   Lin T., 2021, P ACM C HUM FACT COM, DOI DOI 10.1145/3411764.3445649
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Liu L., 2017, LEARNING SCHEDULE CO, V36
   Liu RC, 2021, BIOINFORMATICS, V37, P2033, DOI 10.1093/bioinformatics/btab052
   Liu YF, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000446
   Llobera J., 2021, ACM SIGGRAPH 2021 CO, P1
   Luo HW, 2021, PROC CVPR IEEE, P11657, DOI 10.1109/CVPR46437.2021.01149
   Lyu Q., 2020, IEEE T VIS COMPUT GR, P1
   Ma X, 2021, Free-form scanning of nonplanar appearance with neural trace photography, V40
   Ma ZL, 2018, ADV ENG INFORM, V37, P163, DOI 10.1016/j.aei.2018.05.005
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Murphy D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141217
   Navarro F, 2017, ROBOT
   Onorati T, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P176, DOI 10.1145/3266037.3271642
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Perez-Gonzalez J, 2019, IEEE LAT AM T, V17, P2053, DOI 10.1109/TLA.2019.9011551
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Pu S, 2006, INT ARCH PHOTOGRAMME, V36, P5
   Raaen K., 2019, NIK
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Richard E., 2006, Virtual Reality, V10, P207, DOI DOI 10.1007/S10055-006-0040-8
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Roth Daniel, 2015, i-com: A Journal of Interactive and Cooperative Media, V14, P107, DOI 10.1515/icom-2015-0030
   Roth D, 2017, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2017.7892275
   Saragih Jason M, 2011, Proc Int Conf Autom Face Gesture Recognit, P117, DOI 10.1109/FG.2011.5771400
   Satriadi Kadek Ananta, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427329
   Shi MY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3407659
   Smiley Jim, 2021, P ACM HUMAN COMPUTER, V5, P1
   Son H, 2015, J COMPUT CIVIL ENG, V29, DOI 10.1061/(ASCE)CP.1943-5487.0000401
   Sorger J, 2021, COMPUT GRAPH FORUM, V40, P241, DOI 10.1111/cgf.14417
   Spielberg S., 2018, Ready Player One
   Stotko P, 2019, IEEE T VIS COMPUT GR, V25, P2102, DOI 10.1109/TVCG.2019.2899231
   Tang YM., 2020, mixed reality and three-dimensional computer graphics, DOI 10.5772/intechopen.91443
   Usher W, 2018, IEEE T VIS COMPUT GR, V24, P994, DOI 10.1109/TVCG.2017.2744079
   Vogel D, 2018, 2018 IEEE 1ST WORKSHOP ON ANIMATION IN VIRTUAL AND AUGMENTED ENVIRONMENTS (ANIVAE)
   Wagner JA, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13430
   Wagner J, 2022, IEEE T VIS COMPUT GR, V28, P3252, DOI 10.1109/TVCG.2021.3060666
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Warpefelt H., 2015, P INT C GAM ENT TECH, P1
   Wei X., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P500, DOI [DOI 10.1145/1027527.1027648, 10.1145/1027527.1027648]
   Weissker T, 2020, IEEE T VIS COMPUT GR, V26, P1860, DOI 10.1109/TVCG.2020.2973474
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Wu MY, 2020, PROC CVPR IEEE, P1679, DOI 10.1109/CVPR42600.2020.00175
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
NR 100
TC 87
Z9 88
U1 9
U2 117
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 6
IS 1
BP 56
EP 67
DI 10.1016/j.visinf.2022.03.002
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2S0ZC
UT WOS:000821528800006
OA gold
DA 2024-07-18
ER

PT J
AU Mansoor, H
   Gerych, W
   Alajaji, A
   Buquicchio, L
   Chandrasekaran, K
   Agu, E
   Rundensteiner, E
AF Mansoor, Hamid
   Gerych, Walter
   Alajaji, Abdulaziz
   Buquicchio, Luke
   Chandrasekaran, Kavin
   Agu, Emmanuel
   Rundensteiner, Elke
TI ARGUS: Interactive visual analysis of disruptions in smartphone-detected
   Bio-Behavioral Rhythms
SO VISUAL INFORMATICS
LA English
DT Article
DE Interactive visual analytics; Circadian rhythms; Smartphone-sensed data
ID SLEEP DISORDERS; PREVALENCE
AB Human Bio-Behavioral Rhythms (HBRs) such as sleep-wake cycles (Circadian Rhythms), and the degree of regularity of sleep and physical activity have important health ramifications. Ubiquitous devices such as smartphones can sense HBRs by continuously analyzing data gathered passively by built-in sensors to discover important clues about the degree of regularity and disruptions in behavioral patterns. As human behavior is complex and smartphone data is voluminous with many channels (sensor types), it can be challenging to make meaningful observations, detect unhealthy HBR deviations and most importantly pin-point the causes of disruptions. Prior work has largely utilized computational methods such as machine and deep learning approaches, which while accurate, are often not explainable and present few actionable insights on HBR patterns or causes. To assist analysts in the discovery and understanding of HBR patterns, disruptions and causes, we propose ARGUS, an interactive visual analytics framework. As a foundation of ARGUS, we design an intuitive Rhythm Deviation Score (RDS) that analyzes users' smartphone sensor data, extracts underlying twenty-four-hour rhythms and quantifies their degree of irregularity. This score is then visualized using a glyph that makes it easy to recognize disruptions in the regularity of HBRs. ARGUS also facilitates deeper HBR insights and understanding of causes by linking multiple visualization panes that are overlaid with objective sensor information such as geo-locations and phone state (screen locked, charging), and user-provided or smartphone-inferred ground truth information. This array of visualization overlays in ARGUS enables analysts to gain a more comprehensive picture of HBRs, behavioral patterns and deviations from regularity. The design of ARGUS was guided by a goal and task analysis study involving an expert versed in HBR and smartphone sensing. To demonstrate its utility and generalizability, two different datasets were explored using ARGUS and our use cases and designs were strongly validated in evaluation sessions with expert and non-expert users. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Mansoor, Hamid; Gerych, Walter; Alajaji, Abdulaziz; Buquicchio, Luke; Chandrasekaran, Kavin; Agu, Emmanuel; Rundensteiner, Elke] Worcester Polytech Inst, Worcester, MA 01609 USA.
C3 Worcester Polytechnic Institute
RP Mansoor, H (corresponding author), Worcester Polytech Inst, Worcester, MA 01609 USA.
EM hmansoor@wpi.edu; wgerych@wpi.edu; asalajaji@wpi.edu;
   ljbuquicchio@wpi.edu; kchandrasekaran@wpi.edu; emmanuel@wpi.edu;
   rundenst@wpi.edu
OI Mansoor, Hamid/0000-0003-1970-6049; Rundensteiner,
   Elke/0000-0001-5375-9254
FU DARPA, USA [FA8750-18-2-0077]
FX We would like to thank Prof. Angela Rodriguez for her insightful
   feedback. This material is based on research sponsored by DARPA, USA
   under agreement number FA8750-18-2-0077. The U.S. Government is
   authorized to reproduce and distribute reprints for Governmental
   purposes not withstanding any copyright notation thereon. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of DARPA or the U.S.
   Government.
CR Abdullah S.S., 2020, VISUAL ANALYTICS ELE
   Abdullah S, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P673, DOI 10.1145/2632048.2632100
   Abdullah Saeed., 2017, Mobile Health, P35, DOI DOI 10.1007/978-3-319-51394-2_3
   [Anonymous], 2010, COLORBREWER 2 0 COLO
   Ben-Zeev D, 2017, PSYCHIATR REHABIL J, V40, P266, DOI 10.1037/prj0000243
   Boukhechba M., 2018, Smart Health, V9-10, P192, DOI DOI 10.1016/J.SMHL.2018.07.005
   Boukhechba M, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10101
   Buck B, 2019, SCHIZOPHR RES, V208, P167, DOI 10.1016/j.schres.2019.03.014
   Caballero HSG, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13667
   Calabrese F, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2655691
   Canzian L, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1293, DOI 10.1145/2750858.2805845
   Cao N, 2018, INFORM VISUAL, V17, P22, DOI 10.1177/1473871616686635
   Cao N, 2016, IEEE T VIS COMPUT GR, V22, P280, DOI 10.1109/TVCG.2015.2467196
   Chen ZY, 2013, INT CONF PER COMP, P145, DOI 10.4108/icst.pervasivehealth.2013.252148
   Choe EK, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P121, DOI 10.1145/2750858.2804266
   Ciman M, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/11930
   Cuttone A., 2017, THESIS TU DENMARK
   Dingler Tilman, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3132025
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fischer D, 2016, SCI REP-UK, V6, DOI 10.1038/srep38601
   Gaultney JF, 2010, J AM COLL HEALTH, V59, P91, DOI 10.1080/07448481.2010.483708
   Geissmann Q, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209331
   Gerych W, 2019, IEEE INT C SEMANT CO, P124, DOI 10.1109/ICOSC.2019.8665535
   Gupta A., 2017, INT C HUMAN COMPUTER, P232
   Gupta A, 2018, INT CONF PER COMP, P392, DOI 10.1145/3240925.3240954
   Gupta A, 2018, INT CONF PER COMP, P1, DOI 10.1145/3240925.3240956
   Heng TB., 2018, ELECT IMAGING, V30
   Huang Q, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0885
   Kakar T, 2019, COMPUT GRAPH FORUM, V38, P95, DOI 10.1111/cgf.13674
   Kakar T., 2019, INT JOINT C COMP VIS, P285
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Kerr J, 2016, MED SCI SPORT EXER, V48, P951, DOI 10.1249/MSS.0000000000000841
   Koven J, 2019, IEEE T VIS COMPUT GR, V25, P225, DOI 10.1109/TVCG.2018.2865023
   Kreitzman Leon., 2011, The rhythms of life: The biological clocks that control the daily lives of every living thing
   Le T, 2014, TECHNOL HEALTH CARE, V22, P657, DOI 10.3233/THC-140839
   Liang ZL, 2016, PERS UBIQUIT COMPUT, V20, P985, DOI 10.1007/s00779-016-0960-6
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   LOMB NR, 1976, ASTROPHYS SPACE SCI, V39, P447, DOI 10.1007/BF00648343
   Madan A, 2012, IEEE PERVAS COMPUT, V11, P36, DOI 10.1109/MPRV.2011.79
   Malik S., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10. 1145/2678025.2701407]
   Mansoor H., 2020, EUROVIS 2020 SHORT P
   Mansoor H, 2020, IEEE INT CONF BIG DA, P4882, DOI 10.1109/BigData50022.2020.9378147
   Mansoor H, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P11, DOI [10.1109/vds48975.2019.8973382, 10.1109/VDS48975.2019.8973382]
   Mansoor H, 2019, P INT COMP SOFTW APP, P233, DOI 10.1109/COMPSAC.2019.10212
   Matthews M, 2016, ASSESSMENT, V23, P472, DOI 10.1177/1073191116656794
   MEYER T.E., 2013, Visualizing patterns of drug prescriptions with eventflow: A pilot study of asthma medications in the military health system
   Min JK, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P477, DOI 10.1145/2556288.2557220
   Mohr DC, 2017, ANNU REV CLIN PSYCHO, V13, P23, DOI 10.1146/annurev-clinpsy-032816-044949
   Nguyen P.H., 2018, IEEE T VIS COMPUT GR
   Nguyen PH, 2020, IEEE T VIS COMPUT GR, V26, P77, DOI 10.1109/TVCG.2019.2934609
   Ohayon MM, 2002, J PSYCHOSOM RES, V53, P577, DOI 10.1016/S0022-3999(02)00438-5
   Onnela JP, 2016, NEUROPSYCHOPHARMACOL, V41, P1691, DOI 10.1038/npp.2016.7
   Payandeh S, 2019, LECT NOTES COMPUT SC, V11542, P316, DOI 10.1007/978-3-030-22514-8_26
   Plaisant C., 2003, The Craft of Information Visualization, P308, DOI DOI 10.1016/B978-155860915-0/50038-X
   Polack P. J., 2017, MOBILE HLTH SENSORS, P349
   Polack PJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3152888
   Pu Jiansu., 2011, P 2011 VISUAL INFORM, P13
   Rabbi M, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P385
   Rashid H, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411823
   Resnick Paul, 2014, P COMP JOURN C, V5
   Roenneberg T., 2012, Internal Time: Chronotypes, Social Jet Lag, and Why You're So Tired
   Roenneberg T, 2012, CURR BIOL, V22, P939, DOI 10.1016/j.cub.2012.03.038
   Saeb Sohrab, 2017, J Med Internet Res, V19, pe118, DOI 10.2196/jmir.6821
   Saeb S, 2016, PEERJ, V4, DOI 10.7717/peerj.2537
   SCARGLE JD, 1982, ASTROPHYS J, V263, P835, DOI 10.1086/160554
   Senaratne H, 2018, IEEE T INTELL TRANSP, V19, P1537, DOI 10.1109/TITS.2017.2727281
   Shen ZQ, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P175
   Vaizman Yonatan, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161192
   Vaizman Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174128
   van Berkel N., 2020, HUMAN ACCURACY MOBIL
   van den Elzen S, 2013, IEEE PAC VIS SYMP, P33, DOI 10.1109/PacificVis.2013.6596125
   Vetter C, 2020, EUR J NEUROSCI, V51, P531, DOI 10.1111/ejn.14255
   Walker WH II, 2020, TRANSL PSYCHIAT, V10, DOI 10.1038/s41398-020-0694-0
   Wang R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P3, DOI 10.1145/2632048.2632054
   Weichen Wang, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264951
   Xuhai Xu, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351274
   Yan RH, 2020, SCIENCE, V367, P1444, DOI 10.1126/science.abb2762
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
NR 78
TC 4
Z9 4
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 39
EP 53
DI 10.1016/j.visinf.2021.07.001
EA SEP 2021
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200004
OA gold
DA 2024-07-18
ER

PT J
AU Chawla, P
   Hazarika, S
   Shen, HW
AF Chawla, Piyush
   Hazarika, Subhashis
   Shen, Han-Wei
TI Token-wise sentiment decomposition for ConvNet: Visualizing a sentiment
   classifier
SO VISUAL INFORMATICS
LA English
DT Article
DE Convolutional neural networks; Visualization; Sentiment analysis
AB Convolutional neural networks are one of the most important and widely used constructs in natural language processing and AI in general. In many applications, they have achieved state-of-the-art performance, with training time faster than the other alternatives. However, due to their limited interpretability, they are less favored by practitioners over attention-based models, like RNNs and self-attention (Transformers), which can be visualized and interpreted more intuitively by analyzing the attention-weight heat-maps. In this work, we present a visualization technique that can be used to understand the inner workings of text-based CNN models. We also show how this method can be used to generate adversarial examples and learn the shortcomings of the training data. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Chawla, Piyush; Hazarika, Subhashis; Shen, Han-Wei] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Chawla, P (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM chawla.81@osu.edu; hazarika.3@osu.edu; shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012; Hazarika, Subhashis/GNP-3087-2022
OI Hazarika, Subhashis/0000-0003-0575-9318
CR Ain QT, 2017, INT J ADV COMPUT SC, V8, P424
   Alzantot M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2890
   Arras L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181142
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Baum L. E., 1972, Inequalities, V3, P1
   Biggio B, 2018, PATTERN RECOGN, V84, P317, DOI 10.1016/j.patcog.2018.07.023
   Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080832
   Cirik V., 2016, ARXIV PREPRINT ARXIV
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07
   Hazarika S, 2020, IEEE T VIS COMPUT GR, V26, P34, DOI 10.1109/TVCG.2019.2934591
   Hughes M, 2017, STUD HEALTH TECHNOL, V235, P246, DOI 10.3233/978-1-61499-753-5-246
   Jacovi A., 2018, ABS180908037
   Karpathy A., 2015, PROC CVPR IEEE
   Koh PW, 2017, PR MACH LEARN RES, V70
   Leavy S, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON GENDER EQUALITY IN SOFTWARE ENGINEERING (GE 2018), P14
   Lin Patrick, 2014, Robot Ethics: The Ethical and Social Implications of Robotics
   Lin Z., 2017, ARXIV PREPRINT ARXIV
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SS, 2018, IEEE T VIS COMPUT GR, V24, P553, DOI 10.1109/TVCG.2017.2745141
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Rios Anthony, 2015, ACM BCB, V2015, P258, DOI 10.1145/2808719.2808746
   Smilkov D., 2016, ARXIV PREPRINT ARXIV
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Thongtan T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P407
   Trottier L, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P207, DOI 10.1109/ICMLA.2017.00038
   Vellido A, 2020, NEURAL COMPUT APPL, V32, P18069, DOI 10.1007/s00521-019-04051-w
   Weng WH, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0556-8
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang Q, 2018, P ASME INT C OCEAN
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 35
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2020
VL 4
IS 2
SI SI
BP 132
EP 141
DI 10.1016/j.visinf.2020.04.006
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KK
UT WOS:000658192100007
OA gold
DA 2024-07-18
ER

PT J
AU Giovannangeli, L
   Bourqui, R
   Giot, R
   Auber, D
AF Giovannangeli, L.
   Bourqui, R.
   Giot, R.
   Auber, D.
TI Toward automatic comparison of visualization techniques: Application to
   graph visualization
SO VISUAL INFORMATICS
LA English
DT Article
DE Visualization; Machine learning; Deep learning; Automatic evaluation;
   Graph drawing
AB Many end-user evaluations of data visualization techniques have been run during the last decades. Their results are cornerstones to build efficient visualization systems. However, designing such an evaluation is always complex and time-consuming and may end in a lack of statistical evidence and reproducibility. We believe that modern and efficient computer vision techniques, such as deep convolutional neural networks (CNNs), may help visualization researchers to build and/or adjust their evaluation hypothesis. The basis of our idea is to train machine learning models on several visualization techniques to solve a specific task. Our assumption is that it is possible to compare the efficiency of visualization techniques based on the performance of their corresponding model. As current machine learning models are not able to strictly reflect human capabilities, including their imperfections, such results should be interpreted with caution. However, we think that using machine learning-based pre-evaluation, as a pre-process of standard user evaluations, should help researchers to perform a more exhaustive study of their design space. Thus, it should improve their final user evaluation by providing it better test cases. In this paper, we present the results of two experiments we have conducted to assess how correlated the performance of users and computer vision techniques can be. That study compares two mainstream graph visualization techniques: node-link (NL) and adjacency-matrix (AM) diagrams. Using two well-known deep convolutional neural networks, we partially reproduced user evaluations from Ghoniem et al. and from Okoe et al.. These experiments showed that some user evaluation results can be reproduced automatically. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Giovannangeli, L.; Bourqui, R.; Giot, R.; Auber, D.] Univ Bordeaux, LaBRI UMR CNRS 5800, Bordeaux, France.
C3 Universite de Bordeaux
RP Bourqui, R (corresponding author), Univ Bordeaux, LaBRI UMR CNRS 5800, Bordeaux, France.
EM loann.giovannangeli@labri.fr; romain.bourqui@labri.fr;
   romain.giot@labri.fr; david.auber@labri.fr
RI Giot, Romain/F-6747-2011
OI Giot, Romain/0000-0002-0638-7504; Giovannangeli,
   Loann/0000-0002-9395-6495; Auber, David/0000-0002-1114-8612; Bourqui,
   Romain/0000-0002-1847-2589
FU Region Nouvelle Aquitaine
FX This research project has been powered by Labo's in the Sky with Data
   (LSD), the LaBRI data platform partially funded by the Region Nouvelle
   Aquitaine.
CR Abuthawabeh A., 2013, Working Conference on Software Visualization (VISSOFT), P1, DOI DOI 10.1109/VISSOFT.2013.6650549
   Alper B., 2013, PROC SIGCHI C HUM FA, P483
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-44781-0_45
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Chimani M, 2004, BEND MINIMAL ORTHOGO
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Dodge S, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017)
   Dodge S, 2017, IEEE INT CONF COMP V, P2798, DOI 10.1109/ICCVW.2017.329
   Frick A., 1994, INT S GRAPH DRAW
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Haehn D., 2018, IEEE T VIS COMPUT GR
   Haleem H., 2018, ARXIV PREPRINT ARXIV
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Kobourov SG, 2014, LECT NOTES COMPUT SC, V8871, P234, DOI 10.1007/978-3-662-45803-7_20
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, V25, P1097
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lecun Y., 2015, NAT METHODS, V521, P436, DOI DOI 10.1038/nmeth.3707
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Mnih V., 2013, P ADV C NEUR INF PRO, P1
   Mueller C, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P141
   Okoe M., 2017, INT S GRAPH DRAW GD
   Okoe M, 2015, ECOLOGICAL VALIDITY
   Okoe M., 2018, IEEE T VIS COMPUT GR
   Purchase HC, 2012, EXPERIMENTAL HUMAN-COMPUTER INTERACTION: A PRACTICAL GUIDE WITH VISUAL EXAMPLES, P1
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Ren D, 2019, NETW SCI, V7, P242, DOI 10.1017/nws.2019.6
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sansen J, 2015, IEEE INT CONF INF VI, P62, DOI 10.1109/iV.2015.22
   Segui Santi, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P90, DOI 10.1109/CVPRW.2015.7301276
   Simonyan K., 2014, 14091556 ARXIV
   Thomas Andy, 2014, MEMRISTOR NETWORKS, P151, DOI [10.1007/978- 3- 319- 02630- 5_9, DOI 10.1007/978-3-319-02630-5_9]
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Zeiler M. D., 2012, CoRR
NR 38
TC 12
Z9 13
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2020
VL 4
IS 2
SI SI
BP 86
EP 98
DI 10.1016/j.visinf.2020.04.002
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KK
UT WOS:000658192100003
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Zhang, GF
   Zhu, ZH
   Zhu, SJ
   Liang, RH
   Sun, GD
AF Zhang, Gefei
   Zhu, Zihao
   Zhu, Sujia
   Liang, Ronghua
   Sun, Guodao
TI Towards a better understanding of the role of visualization in online
   learning: A review
SO VISUAL INFORMATICS
LA English
DT Review
DE Visualization in education; Online learning; Visual analytics
ID VISUAL ANALYTICS; TOOL; STUDENTS; INSTRUCTORS; COURSEVIS; SYSTEM
AB With the popularity of online learning in recent decades, MOOCs (Massive Open Online Courses) are increasingly pervasive and widely used in many areas. Visualizing online learning is particularly important because it helps to analyze learner performance, evaluate the effectiveness of online learning platforms, and predict dropout risks. Due to the large-scale, high-dimensional, and heterogeneous characteristics of the data obtained from online learning, it is difficult to find hidden information. In this paper, we review and classify the existing literature for online learning to better understand the role of visualization in online learning. Our taxonomy is based on four categorizations of online learning tasks: behavior analysis, behavior prediction, learning pattern exploration and assisted learning. Based on our review of relevant literature over the past decade, we also identify several remaining research challenges and future research work. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Zhang, Gefei; Zhu, Zihao; Zhu, Sujia; Liang, Ronghua; Sun, Guodao] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Technology
RP Sun, GD (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
EM godoor.sun@gmail.com
RI zhang, ZhangGeFei/HDO-8297-2022; liang, ronghua/H-4463-2012
OI Zhu, Zihao/0000-0001-9310-6493
FU National Natural Science Foundation of China;  [61972356];  [62036009]
FX Acknowledgments This work is partly supported by the National Natural
   Science Foundation of China (61972356, 62036009) . Guodao Sun is the
   corresponding author. We would like to thank Professor Jihong Ding for
   her valuable opinions, Wenjing Wang for her design and discussion about
   taxonomy, and all anonymous reviewers for their feedback.
CR Gómez-Aguilar DA, 2015, COMPUT HUM BEHAV, V47, P60, DOI 10.1016/j.chb.2014.11.001
   Anderson A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P687
   [Anonymous], LEARNING TECHNOLOGIE
   [Anonymous], 2018, 2018 International Joint Conference on Neural Networks (IJCNN), DOI 10.1145/2851141.2851145
   Asli MF, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05733
   Atapattu T., 2016, INT ED DATA MINING S
   Auvinen T, 2015, IEEE T LEARN TECHNOL, V8, P261, DOI 10.1109/TLT.2015.2441718
   Brinton CG, 2014, IEEE T LEARN TECHNOL, V7, P346, DOI 10.1109/TLT.2014.2337900
   Buder J, 2015, COMPUT HUM BEHAV, V44, P191, DOI 10.1016/j.chb.2014.11.043
   Bull S, 2016, LAK '16 CONFERENCE PROCEEDINGS: THE SIXTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE,, P30, DOI 10.1145/2883851.2883853
   Chang B., 2022, IEEE T VIS COMPUT GR, V1
   Chen Q, 2020, IEEE T VIS COMPUT GR, V26, P1622, DOI 10.1109/TVCG.2018.2872961
   Chen Q, 2016, IEEE T VIS COMPUT GR, V22, P2315, DOI 10.1109/TVCG.2015.2505305
   Chen YZ, 2016, IEEE CONF VIS ANAL, P111, DOI 10.1109/VAST.2016.7883517
   Citra Kurniawan, 2021, 2021 International Research Symposium On Advanced Engineering And Vocational Education (IRSAEVE), P33, DOI 10.1109/IRSAEVE52613.2021.9604012
   Cobos R., 2017, P 5 INT C TECHNOLOGI, P1
   Coffrin C., 2014, P 4 INT C LEARN AN K, P83, DOI DOI 10.1145/2567574.2567586
   Cui Y, 2021, COMPUT ELECTR ENG, V96, DOI 10.1016/j.compeleceng.2021.107544
   Denny P., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P763, DOI [DOI 10.1145/2470654.2470763, 10.1145/2470654.2470763]
   Dernoncourt F., 2013, NIPS WORKSHOP DATA D
   El-Assady M, 2018, COMPUT GRAPH FORUM, V37, P351, DOI 10.1111/cgf.13425
   Emmons SR, 2017, J ASSOC INF SCI TECH, V68, P2350, DOI 10.1002/asi.23852
   Fu SW, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3162075
   Fu SW, 2017, IEEE T VIS COMPUT GR, V23, P201, DOI 10.1109/TVCG.2016.2598444
   Gan XY, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P1816, DOI 10.1109/ICCSE.2009.5228253
   Gibbs WJ, 2006, EDUC TECHNOL SOC, V9, P232
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Han DY, 2022, IEEE T VIS COMPUT GR, V28, P4344, DOI 10.1109/TVCG.2021.3086414
   Hasnine MN, 2021, PROCEDIA COMPUT SCI, V192, P3423, DOI 10.1016/j.procs.2021.09.115
   He H, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P56, DOI [10.1109/VISUAL.2019.8933778, 10.1109/visual.2019.8933778]
   He H, 2018, IEEE CONF VIS ANAL, P25, DOI 10.1109/VAST.2018.8802383
   He H, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P99, DOI 10.1145/3300115.3309514
   Hsu HH, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P634, DOI 10.1109/ICBDA.2017.8078712
   Huimin Xu, 2021, ICDEL 2021: 2021 the 6th International Conference on Distance Education and Learning, P133, DOI 10.1145/3474995.3475017
   Ilves K, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P257, DOI 10.1145/3159450.3159509
   Jian-Syuan Wong, 2015, Social Computing, Behavioral-Cultural Modeling and Prediction. 8th International Conference, SBP 2015. Proceedings: LNCS 9021, P452, DOI 10.1007/978-3-319-16268-3_58
   Karavirta V, 2016, IEEE T LEARN TECHNOL, V9, P171, DOI 10.1109/TLT.2015.2490673
   Kayanda AM, 2020, ENG TECHNOL APPL SCI, V10, P5967
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kim J., 2022, MOBILE FRIENDLY CONT
   Kuosa K, 2016, INT J DIST EDUC, V14, P1, DOI 10.4018/IJDET.2016010101
   Kwon BC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P993, DOI 10.1145/2858036.2858101
   Li HT, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445294
   Li HT, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2589, DOI 10.1145/3340531.3412733
   Li X, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING IMIS 2015, P34, DOI 10.1109/IMIS.2015.10
   Liu M, 2015, IEEE T LEARN TECHNOL, V8, P215, DOI 10.1109/TLT.2014.2378786
   Moreno-Marcos PM, 2019, IEEE T LEARN TECHNOL, V12, P384, DOI 10.1109/TLT.2018.2856808
   Martins Tiago, 2018, International Journal of Creative Interfaces and Computer Graphics, V9, P32, DOI 10.4018/IJCICG.2018010103
   Matin MA, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON EDUCATION AND E-LEARNING (ICEEL 2018), P32, DOI 10.1145/3291078.3291104
   Mazza R, 2003, FR ART INT, V97, P279
   Mazza R., 2007, J INTERACTIVE LEARNI, V18, P251
   Mazza R, 2007, INT J HUM-COMPUT ST, V65, P125, DOI 10.1016/j.ijhcs.2006.08.008
   McGrath O.G., 2011, P ANN ACM SIGUCCS C, P229
   Meng Xia, 2020, L@S '20. Proceedings of the Seventh ACM Conference on Learning @ Scale, P37, DOI 10.1145/3386527.3405924
   Minematsu Tsubasa, 2020, Distributed, Ambient and Pervasive Interactions. 8th International Conference, DAPI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12203), P581, DOI 10.1007/978-3-030-50344-4_42
   Misailidis E, 2018, 22ND PAN-HELLENIC CONFERENCE ON INFORMATICS (PCI 2018), P82, DOI 10.1145/3291533.3291568
   Miyakita G, 2019, PROCEEDINGS OF 2019 IEEE LEARNING WITH MOOCS (IEEE LWMOOCS VI 2019), P42, DOI 10.1109/lwmoocs47620.2019.8939644
   Mu X., 2019, EUROVIS SHORT PAPERS, P91, DOI [DOI 10.2312/EVS.20191176, 10.2312/evs20191176/091-0952, DOI 10.2312/EVS20191176/091-0952]
   Mubarak AA, 2021, COMPUT APPL ENG EDUC, V29, P710, DOI 10.1002/cae.22328
   Muñoz-Merino PJ, 2015, COMPUT HUM BEHAV, V47, P108, DOI 10.1016/j.chb.2014.10.003
   Nakayama M., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P434, DOI 10.1109/IV.2012.75
   Nickels S, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P33, DOI 10.1109/BioVis.2013.6664344
   Oliveira AP, 2010, IEEE INT CONF INF VI, P219, DOI 10.1109/IV.2010.41
   Paiva R, 2018, LECT NOTES ARTIF INT, V10948, P251, DOI 10.1007/978-3-319-93846-2_46
   Pérez-Alvarez R, 2018, J UNIVERS COMPUT SCI, V24, P1090
   Qu HM, 2015, IEEE COMPUT GRAPH, V35, P69, DOI 10.1109/MCG.2015.137
   Rodola E., 2017, COMPUT GRAPH FORUM, V36, P222
   Ruiz S, 2016, LAK '16 CONFERENCE PROCEEDINGS: THE SIXTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE,, P254, DOI 10.1145/2883851.2883888
   Schubert M., 2018, P 8 EDITION INT WORK
   Schwab M, 2017, IEEE T VIS COMPUT GR, V23, P571, DOI 10.1109/TVCG.2016.2598518
   Shah D, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00084-y
   Shi CL, 2015, IEEE PAC VIS SYMP, P159, DOI 10.1109/PACIFICVIS.2015.7156373
   Shi HW, 2021, PROCEDIA COMPUT SCI, V192, P3885, DOI 10.1016/j.procs.2021.09.163
   Shi Y, 2022, IEEE T BIG DATA, V8, P377, DOI 10.1109/TBDATA.2020.2964169
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sun D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376866
   Suntiwichaya Supphachoke, 2018, 2018 15th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P98, DOI 10.1109/ECTICon.2018.8619976
   Tervakari AM, 2014, IEEE GLOB ENG EDUC C, P142, DOI 10.1109/EDUCON.2014.6826081
   Trimm D, 2012, IEEE T VIS COMPUT GR, V18, P2809, DOI 10.1109/TVCG.2012.288
   Tsung Sean, 2022, L@S '22: Proceedings of the Ninth ACM Conference on Learning @ Scale, P299, DOI 10.1145/3491140.3528298
   Tubman P, 2019, IEEE INT CONF ADV LE, P34, DOI 10.1109/ICALT.2019.00014
   Venkatarayalu N, 2018, PR IEEE INT CONF TEA, P725, DOI 10.1109/TALE.2018.8615266
   Vidakis N., 2019, INT C COMPUTER SUPPO, P629, DOI 10.1007/978-3-030-58459-7_30
   Vieira C, 2018, COMPUT EDUC, V122, P119, DOI 10.1016/j.compedu.2018.03.018
   Vivian R, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P380, DOI 10.1109/ICSE.2015.170
   Wang XH, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P1189
   Wei H, 2020, LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P645, DOI 10.1145/3375462.3375521
   Weiand A., 2015, P WORKSHOP VISUAL AN
   Williams FP, 2007, 7TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P872, DOI 10.1109/ICALT.2007.282
   Wong GKW, 2016, P INT COMP SOFTW APP, P706, DOI 10.1109/COMPSAC.2016.44
   Wong JS, 2018, VIS INFORM, V2, P37, DOI 10.1016/j.visinf.2018.04.005
   Wortman D, 2007, SIGCSE 2007: PROCEEDINGS OF THE THIRTY-EIGHTH SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P430, DOI 10.1145/1227504.1227458
   Wu M, 2020, PLATELETS, V31, P94, DOI 10.1080/09537104.2019.1581921
   Xia JY, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P251, DOI 10.1145/3159450.3159487
   Xia M., 2022, ARXIV
   Xia M, 2019, Arxiv, DOI arXiv:1909.04749
   Xia M, 2021, IEEE T VIS COMPUT GR, V27, P870, DOI 10.1109/TVCG.2020.3030337
   Xia M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300864
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan Zhang, 2008, 2008 Fourth International Conference on Semantics, Knowledge and Grid (SKG), P495, DOI 10.1109/SKG.2008.18
   Zarra T., 2018, P INT C LEARNING OPT, P1
   Zhao J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173903
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P4839, DOI 10.1109/TVCG.2021.3107297
   Zou M., 2020, INT C ARTIFICIAL INT, P175
NR 105
TC 8
Z9 8
U1 8
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 22
EP 33
DI 10.1016/j.visinf.2022.09.002
EA NOV 2022
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100003
OA gold
DA 2024-07-18
ER

PT J
AU Giovannangeli, L
   Bourqui, R
   Giot, R
   Auber, D
AF Giovannangeli, Loann
   Bourqui, Romain
   Giot, Romain
   Auber, David
TI Color and Shape efficiency for outlier detection from automated to user
   evaluation
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual search; Outlier detection; User evaluation; Deep learning;
   Automated evaluation
ID VISUAL-SEARCH; VISUALIZATION; BRIGHTNESS; PERCEPTION; SATURATION;
   ATTENTION; CAPACITY; TARGETS; LIMITS; SIZE
AB The design of efficient representations is well established as a fruitful way to explore and analyze complex or large data. In these representations, data are encoded with various visual attributes depending on the needs of the representation itself. To make coherent design choices about visual attributes, the visual search field proposes guidelines based on the human brain's perception of features. However, information visualization representations frequently need to depict more data than the amount these guidelines have been validated on. Since, the information visualization community has extended these guidelines to a wider parameter space.This paper contributes to this theme by extending visual search theories to an information visualization context. We consider a visual search task where subjects are asked to find an unknown outlier in a grid of randomly laid out distractors. Stimuli are defined by color and shape features for the purpose of visually encoding categorical data. The experimental protocol is made of a parameters space reduction step (i.e., sub-sampling) based on a machine learning model, and a user evaluation to validate hypotheses and measure capacity limits. The results show that the major difficulty factor is the number of visual attributes that are used to encode the outlier. When redundantly encoded, the display heterogeneity has no effect on the task. When encoded with one attribute, the difficulty depends on that attribute heterogeneity until its capacity limit (7 for color, 5 for shape) is reached. Finally, when encoded with two attributes simultaneously, performances drop drastically even with minor heterogeneity.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University
C1 [Giovannangeli, Loann; Bourqui, Romain; Giot, Romain; Auber, David] Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
C3 Universite de Bordeaux; Inria; Centre National de la Recherche
   Scientifique (CNRS)
RP Giovannangeli, L (corresponding author), Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
EM loann.giovannangeli@labri.fr; romain.bourqui@labri.fr;
   romain.giot@labri.fr; david.auber@labri.fr
RI Giot, Romain/F-6747-2011
OI Giot, Romain/0000-0002-0638-7504; Auber, David/0000-0002-1114-8612;
   Giovannangeli, Loann/0000-0002-9395-6495
CR Altunbay D, 2010, IEEE T BIO-MED ENG, V57, P665, DOI 10.1109/TBME.2009.2033804
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412
   Bauer B, 1996, VISION RES, V36, P1439, DOI 10.1016/0042-6989(95)00207-3
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Bertin J, 1983, IN PRESS
   CALLAGHAN TC, 1986, PERCEPT PSYCHOPHYS, V39, P32, DOI 10.3758/BF03207581
   Camgöz N, 2004, COLOR RES APPL, V29, P20, DOI 10.1002/col.10214
   Camgöz N, 2002, COLOR RES APPL, V27, P199, DOI 10.1002/col.10051
   CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077
   Chollet F., KERAS
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   de San Roman PP, 2017, COMPUT VIS IMAGE UND, V164, P82, DOI [10.1016/j.cviu.2017.03.001, 10.1016/j.cviu2017.03.001]
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Giovannangeli L, 2020, VIS INFORM, V4, P86, DOI 10.1016/j.visinf.2020.04.002
   Giovannangeli L, 2021, IEEE INT CONF INF VI, P129, DOI 10.1109/IV53921.2021.00029
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Gramazio CC, 2014, IEEE T VIS COMPUT GR, V20, P1953, DOI 10.1109/TVCG.2014.2346983
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Haroz S, 2012, IEEE T VIS COMPUT GR, V18, P2402, DOI 10.1109/TVCG.2012.233
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S, 2019, PROC CVPR IEEE, P10198, DOI 10.1109/CVPR.2019.01045
   Healey CG, 1996, IEEE VISUAL, P263, DOI 10.1109/VISUAL.1996.568118
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Horikawa T, 2019, SCI DATA, V6, DOI 10.1038/sdata.2019.12
   Huber DE, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P527
   Itoh T, 2004, IEEE T VIS COMPUT GR, V10, P302, DOI 10.1109/TVCG.2004.1272729
   Jacob G., NAT COMMUN, V12, P1
   Kheradpisheh SR, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00092
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Nothelfer C, 2017, J EXP PSYCHOL HUMAN, V43, P1667, DOI 10.1037/xhp0000314
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   PASHLER H, 1988, PERCEPT PSYCHOPHYS, V43, P307, DOI 10.3758/BF03208800
   Post FJ, 1995, VISUALIZATION '95 - PROCEEDINGS, P288, DOI 10.1109/VISUAL.1995.485141
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase H, 2012, Experimental Human-Computer Interaction-A Prac- tical Guide With Visual Examples
   Purchase HC, 1996, LECT NOTES COMPUT SC, V1027, P435, DOI 10.1007/BFb0021827
   QUINLAN PT, 1987, PERCEPT PSYCHOPHYS, V41, P455, DOI 10.3758/BF03203039
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   TREISMAN A, 1977, PERCEPT PSYCHOPHYS, V22, P1, DOI 10.3758/BF03206074
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   WARE C, 1988, HUM FACTORS, V30, P127, DOI 10.1177/001872088803000201
   Ware C., 2020, INFORM VISUALIZATION
   Wolfe J. M., 2007, INTEGRATED MODELS CO, P99, DOI [10.1093/acprof:oso/9780195189193.003.0008, DOI 10.1093/ACPROF:OSO/9780195189193.003.0008]
   Wolfe JM, 2020, ATTEN PERCEPT PSYCHO, V82, P383, DOI 10.3758/s13414-020-02022-1
   Wolfe JM, 2020, ATTEN PERCEPT PSYCHO, V82, P1, DOI 10.3758/s13414-019-01966-3
   Wolfe JM, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0058
   Zhou H, 2008, COMPUT GRAPH FORUM, V27, P1047, DOI 10.1111/j.1467-8659.2008.01241.x
   Zwillinger D., 1999, CRC Standard Probability and Statistics Tables and Formulae
NR 59
TC 2
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 25
EP 40
DI 10.1016/j.visinf.2022.03.001
EA MAY 2022
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2B9RT
UT WOS:000810519100002
OA gold
DA 2024-07-18
ER

PT J
AU Chen, XJ
   Tang, XT
   Luo, ZJ
   Zhang, JY
AF Chen, Xiaojiao
   Tang, Xiaoteng
   Luo, Zijing
   Zhang, Jiayi
TI Evaluating user cognition of network diagrams
SO VISUAL INFORMATICS
LA English
DT Article
DE Network diagram; Shortest path; Eye tracking; Cognitive evaluation
ID EEG
AB Edges crossing and nodes overlapping have a significant effect on the users' recognition and comprehension of network diagrams. In this study, we propose a visual evaluation method for users' cognition of network diagrams. First, this method carries out a set of cognitive experiments to collect the user's cognitive performance that affects the variables, including accuracy and response time. The user's pupil diameter is measured through an eye tracker to reflect their cognitive load. Second, the significance test points out the visual features as independent variables and then establishes an evaluation regression model. The experimental results show that the number of edges, edge length, node visual interference, and edge occlusion contribute to the evaluation models of response time, and edge occlusion and the number of node connections contribute to the accuracy model. Finally, these evaluation models demonstrate good predictability when assessing users' cognition of network diagrams and provide practical recommendations for their use. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Chen, Xiaojiao; Tang, Xiaoteng; Zhang, Jiayi] Zhejiang Univ, Sch Art & Archaeol, Hangzhou, Peoples R China.
   [Tang, Xiaoteng; Zhang, Jiayi] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Luo, Zijing] Southeast Univ, Sch Mech Engn, Nanjing, Peoples R China.
C3 Zhejiang University; Zhejiang University; Southeast University - China
RP Chen, XJ (corresponding author), Zhejiang Univ, Sch Art & Archaeol, Hangzhou, Peoples R China.
EM chenxiaojiao@zju.edu.cn; tangxiaoteng@zju.edu.cn; 18795866350@163.com;
   12121188@zju.edu.cn
OI Tang, Xiaoteng/0000-0003-1859-8488; Zhang, Jiayi/0009-0001-0726-0126
FU Provincial Key Social Science Foundation of Zhejiang, China [22JCXK03Z];
   Fundamental Research Funds for the Central Universities, China
FX The work was supported by the Provincial Key Social Science Foundation
   of Zhejiang, China (Grant No. 22JCXK03Z) and the Fundamental Research
   Funds for the Central Universities, China. We would like to thank the
   reviewers for their constructive comments and all the participants for
   actively participating in our experiment.
CR Afridi A.H., 2020, PERS UBIQUIT COMPUT
   Amende N., 2010, P HCI 2010
   Anderson EW, 2011, COMPUT GRAPH FORUM, V30, P791, DOI 10.1111/j.1467-8659.2011.01928.x
   [Anonymous], SOCIAL NETWORKING, DOI 10.4236/sn.2013.24019
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   Chen Xiaojiao, 2017, Journal of Southeast University (Natural Science Edition), V47, P38, DOI 10.3969/j.issn.1001-0505.2017.01.008
   Constantinidis C, 2004, NEUROSCIENTIST, V10, P553, DOI 10.1177/1073858404268742
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P167
   Dunne C, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2411412
   Gardony A.L., 2018, Human-Computer Interaction, P1
   Huang WD, 2006, LECT NOTES COMPUT SC, V3843, P262
   Just M.A., 2003, Theoretical Issues in Ergonomics Science, V4, P56, DOI [10.1080/14639220210159735, DOI 10.1080/14639220210159735, 10.1080/14639220210159735.]
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Knuth D.E., 2000, STANFORD GRAPHBASE P, V3, P1
   Kobourov SG, 2014, LECT NOTES COMPUT SC, V8871, P234, DOI 10.1007/978-3-662-45803-7_20
   Kosara R, 2003, IEEE COMPUT GRAPH, V23, P20, DOI 10.1109/MCG.2003.1210860
   Kyllonen P., 2016, Journal of Intelligence, V4, P14, DOI [DOI 10.3390/JINTELLIGENCE4040014, 10.3390/jintelligence4040014]
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Li W., 2005, APVIS 05, V45, P31
   MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010
   Mutzel P., 2006, SIAM J OPTIM, V11, P16
   Neokleous KC, 2011, PROCEDIA COMPUT SCI, V7, P244, DOI 10.1016/j.procs.2011.09.030
   Nuamah JK, 2020, APPL ERGON, V88, DOI 10.1016/j.apergo.2020.103173
   Padilla LMK, 2020, IEEE T VIS COMPUT GR, V26, P332, DOI 10.1109/TVCG.2019.2934286
   Pohl M., 2009, COMPARING READABILIT
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Shi HB, 2020, IEEE T COGN DEV SYST, V12, P695, DOI 10.1109/TCDS.2019.2924724
   Shui Chao, 2015, Computer Engineering and Science, V37, P457, DOI 10.3969/j.issn.1007-130X.2015.03.008
   Stolte M, 2020, J VISION, V20, DOI 10.1167/jov.20.6.21
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   [孙扬 SUN Yang], 2010, [计算机科学, Computer Science], V37, P12
   Szafir D. A., 2018, Interactions, V25, P26, DOI [DOI 10.1145/3231772, DOI 10.1145/32317721, 10.1145/3231772]
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Tunkelang D., 1994, COMPUT SCI, V30
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   William S.C., 1983, J AM STAT ASS, V79, P531
   Yang XS., 2018, SCI TECHNOL ENG, V18, P333
   [张喜涛 Zhang Xitao], 2019, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V31, P639
NR 38
TC 1
Z9 2
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 26
EP 33
DI 10.1016/j.visinf.2021.12.004
EA DEC 2021
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500004
OA gold
DA 2024-07-18
ER

PT J
AU Cao, AQ
   Xie, X
   Lan, J
   Lu, HH
   Hou, XL
   Wang, JC
   Zhang, H
   Liu, DY
   Wu, YC
AF Cao, Anqi
   Xie, Xiao
   Lan, Ji
   Lu, Huihua
   Hou, Xinli
   Wang, Jiachen
   Zhang, Hui
   Liu, Dongyu
   Wu, Yingcai
TI MIG-Viewer: Visual analytics of soccer player migration
SO VISUAL INFORMATICS
LA English
DT Article
DE Sports visualization; Soccer player migration; Design study
ID OF-THE-ART; FOREIGN PLAYERS; FOOTBALL; SYSTEM; GLOBALIZATION;
   EXPLORATION
AB How could soccer player migration impact national team performance, or vice versa? The answer to this question could play an essential role in making appropriate decisions and policies regarding the international mobility of soccer players. However, answering such a question faces two main challenges, including the complex relationship between variables in multi-attribute temporal data describing migrated players and national team performance, and the interpretation of analysis results in policymaking scenarios. In this work, we have closely collaborated with domain experts and characterized the problems of soccer player migration analysis. To address the first challenge, we adapt a cross-lagged panel analysis model into the player migration analysis problem. This cross-lagged panel analysis model is effective to evaluate the impact strength between player migration and national team performance, and straightforward to reveal the causal relationship. To address the second challenge, we design and develop a visual analytics system, MIG-Viewer, to help the experts to interpret the results of the proposed model efficiently. With MIG-Viewer, the experts can navigate the countries of interest in accordance with migration strategy, conduct comprehensive analysis with the comparison of impact strength, and adjust player migration and inspect further details of a specific country. We present two case studies using global player migration data since 1992 with three soccer analysis experts to demonstrate the effectiveness and usefulness of the system. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Cao, Anqi; Lan, Ji; Lu, Huihua; Hou, Xinli; Wang, Jiachen; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Xie, Xiao; Zhang, Hui] Zhejiang Univ, Dept Sport Sci, Hangzhou, Peoples R China.
   [Liu, Dongyu] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
C3 Zhejiang University; Zhejiang University; Massachusetts Institute of
   Technology (MIT)
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
EM caoanqi@zju.edu.cn; xxie@zju.edu.cn; lanjizju@zju.edu.cn;
   huihualu@zju.edu.cn; houxinli@zju.edu.cn; wangjiachen@zju.edu.cn;
   zhang_hui@zju.edu.cn; dongyu@mit.edu; ycwu@zju.edu.cn
RI wang, David/KFR-2555-2024; yang, yijing/JWO-8234-2024; long,
   chen/JVM-8568-2024; Liu, Dongyu/AGT-1288-2022; wang,
   yixuan/JGM-3893-2023; Zhao, ZiHao/KHT-4413-2024; zhen,
   wang/KBA-3844-2024; LAN, JI/M-2006-2018
OI Cao, Anqi/0000-0003-1794-4510; Liu, Dongyu/0000-0002-8915-2785; ,
   Hui/0000-0003-0601-3905; LAN, JI/0000-0002-8658-8620
FU NSFC [62072400]; Zhejiang Provincial Natural Science Foundation
   [LR18F020001]
FX The work was supported by NSFC (62072400) and Zhejiang Provincial
   Natural Science Foundation (LR18F020001).
CR Akindes G. A., 2013, Soccer and Society, V14, P684, DOI 10.1080/14660970.2013.792486
   Allan GJ, 2014, APPL ECON LETT, V21, P490, DOI 10.1080/13504851.2013.870641
   Andrienko G., 2019, IEEE T VIS COMPUT GR
   Andrienko G, 2017, DATA MIN KNOWL DISC, V31, P1793, DOI 10.1007/s10618-017-0513-2
   [Anonymous], 2016, Electronic Imaging, Visualization and Data Analysis
   Baur D. G., 2007, 217 IIIS
   Berlinschi R, 2013, LABOUR ECON, V21, P1, DOI 10.1016/j.labeco.2012.12.006
   Binder JJ, 2012, J SPORT ECON, V13, P107, DOI 10.1177/1527002511400278
   Chen M, 2011, COMPUTER, V44, P83, DOI 10.1109/MC.2011.313
   Cohen J., 2013, APPL MULTIPLE REGRES, DOI DOI 10.2307/2064799
   Dang Tuan Nhon, 2015, BMC Proc, V9, pS6, DOI 10.1186/1753-6561-9-S6-S6
   Deng HZ, 2019, VIS INFORM, V3, P166, DOI 10.1016/j.visinf.2019.10.004
   FIFA, 2020, FIFA WORLD RANK
   Flores R, 2010, KYKLOS, V63, P546, DOI 10.1111/j.1467-6435.2010.00487.x
   Gelade GA, 2007, SOC SCI QUART, V88, P244, DOI 10.1111/j.1540-6237.2007.00456.x
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Kearney M.W., 2017, The SAGE Encyclopedia of Communication Research Methods, DOI [10.4135/9781483381411, DOI 10.4135/9781483381411]
   Kui XY, 2020, VIS INFORM, V4, P1, DOI 10.1016/j.visinf.2020.06.001
   Lago-Peñas C, 2019, FRONT PSYCHOL, V10, DOI [10.3389/fmicb.2019.02645, 10.3389/fpsyg.2019.00616]
   Laursen B., 2011, HDB DEV RES METHODS
   Lu YF, 2017, COMPUT GRAPH FORUM, V36, P539, DOI 10.1111/cgf.13210
   Magee J., 2002, Journal of Sport & Social Issues, V26, P421, DOI 10.1177/0193732502238257
   Milanovic B, 2005, REV INT POLIT ECON, V12, P829, DOI 10.1080/09692290500339818
   Mondal D, 2019, VIS INFORM, V3, P18, DOI 10.1016/j.visinf.2019.03.003
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2016, IEEE COMPUT GRAPH, V36, P38, DOI 10.1109/MCG.2016.100
   Perin C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P887, DOI 10.1145/2556288.2557379
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Poli R, 2010, INT REV SOCIOL SPORT, V45, P491, DOI 10.1177/1012690210370640
   Royuela V, 2019, J SPORT ECON, V20, P718, DOI 10.1177/1527002518807960
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   Transfermarkt, 2020, FOOTB TRANSF RUM MAR
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Velema T.A., 2016, INT REV SOCIOL SPORT, P1
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wong JS, 2018, VIS INFORM, V2, P37, DOI 10.1016/j.visinf.2018.04.005
   World Bank, 2022, WORLD DEV IND
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Zhang ZY, 2015, IEEE T VIS COMPUT GR, V21, P289, DOI 10.1109/TVCG.2014.2350494
NR 44
TC 3
Z9 3
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 102
EP 113
DI 10.1016/j.visinf.2021.09.002
EA OCT 2021
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200009
OA gold
DA 2024-07-18
ER

PT J
AU Ji, XN
   Tu, YM
   He, WB
   Wang, JP
   Shen, HW
   Yen, PY
AF Ji, Xiaonan
   Tu, Yamei
   He, Wenbin
   Wang, Junpeng
   Shen, Han-Wei
   Yen, Po-Yin
TI USEVis: Visual analytics of attention-based neural embedding in
   information retrieval
SO VISUAL INFORMATICS
LA English
DT Article
DE Interactive visual system; Neural embedding; Attention mechanism;
   Document understanding; Information retrieval; Clinical decision-making
ID VISUALIZATION
AB Neural attention-based encoders, which effectively attend sentence tokens to their associated context without being restricted by long-term distance or dependency, have demonstrated outstanding performance in embedding sentences into meaningful representations (embeddings). The Universal Sentence Encoder (USE) is one of the most well-recognized deep neural network (DNN) based solutions, which is facilitated with an attention-driven transformer architecture and has been pre-trained on a large number of sentences from the Internet. Besides the fact that USE has been widely used in many downstream applications, including information retrieval (IR), interpreting its complicated internal working mechanism remains challenging. In this work, we present a visual analytics solution towards addressing this challenge. Specifically, focused on semantics and syntactics (concepts and relations) that are critical to domain clinical IR, we designed and developed a visual analytics system, i.e., USEVis. The system investigates the power of USE in effectively extracting sentences' semantics and syntactics through exploring and interpreting how linguistic properties are captured by attentions. Furthermore, by thoroughly examining and comparing the inherent patterns of these attentions, we are able to exploit attentions to retrieve sentences/documents that have similar semantics or are closely related to a given clinical problem in IR. By collaborating with domain experts, we demonstrate use cases with inspiring findings to validate the contribution of our work and the effectiveness of our system. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Ji, Xiaonan; Yen, Po-Yin] Washington Univ, Sch Med, Inst Informat, St Louis, MO 63110 USA.
   [Ji, Xiaonan; Tu, Yamei; He, Wenbin; Wang, Junpeng; Shen, Han-Wei] Ohio State Univ, Comp Sci & Engn, Columbus, OH 43210 USA.
C3 Washington University (WUSTL); University System of Ohio; Ohio State
   University
RP Ji, XN (corresponding author), Washington Univ, Sch Med, Inst Informat, St Louis, MO 63110 USA.
EM ji.62@osu.edu
RI Shen, Han-wei/A-4710-2012; Tu, Yamei/KSL-7529-2024; Ji,
   Xiaonan/W-2693-2019
CR [Anonymous], 1997, NEURAL COMPUT
   Bengio Y., 2014, TECHNICAL REPORT
   Cer D., 2018, ARXIV PREPRINT ARXIV
   Chen JQ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4046
   Cui Y., 2016, ARXIV PREPRINT ARXIV
   Devlin J., 2018, BERT PRE TRAINING DE
   DIBATTISTA G, 1994, COMP GEOM-THEOR APPL, V4, P235, DOI 10.1016/0925-7721(94)00014-X
   Görg C, 2014, INFORM VISUAL, V13, P336, DOI 10.1177/1473871613495674
   GrossTsur V, 1997, J PEDIATR-US, V130, P40, DOI 10.1016/S0022-3476(97)70308-1
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Henry N, 2007, LECT NOTES COMPUT SC, V4663, P288
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Henry N, 2006, IEEE T VIS COMPUT GR, V12, P677, DOI 10.1109/TVCG.2006.160
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Ji XN, 2019, IEEE T VIS COMPUT GR, V25, P2181, DOI 10.1109/TVCG.2019.2903946
   Kiros Ryan., 2015, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems, P3294
   Koren Y, 2005, COMPUT MATH APPL, V49, P1867, DOI 10.1016/j.camwa.2004.08.015
   Le Quoc V., 2014, P INT C MACH LEARN I
   Lin Z, 2019, ARXIV170303130
   Liu SS, 2018, IEEE T VIS COMPUT GR, V24, P553, DOI 10.1109/TVCG.2017.2745141
   Lopez MM, 2017, ARXIV PREPRINT ARXIV
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Mitra B, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P813, DOI 10.1145/3018661.3022755
   Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371
   Park C., 2019, ARXIV190909595
   Smilkov D., 2016, ARXIV PREPRINT ARXIV
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sutskever I, 2014, ADV NEUR IN, V27
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Vig Jesse, 2019, Visualizing attention in transformer based language representation models
   Zhao J, 2017, IEEE T VIS COMPUT GR, V24, P195
NR 33
TC 7
Z9 7
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2021
VL 5
IS 2
BP 1
EP 12
DI 10.1016/j.visinf.2021.03.003
EA APR 2021
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LF
UT WOS:000658194200001
OA gold
DA 2024-07-18
ER

PT J
AU Kui, XY
   Liu, NM
   Liu, Q
   Liu, JW
   Zeng, XQ
   Zhang, C
AF Kui, Xiaoyan
   Liu, Naiming
   Liu, Qiang
   Liu, Jingwei
   Zeng, Xiaoqian
   Zhang, Chao
TI A survey of visual analytics techniques for online education
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual analytics; Online education; Behavior analysis; Content analysis
ID SYSTEM; EXPLORATION; SUPPORT; TEXT
AB Visual analytics techniques are widely utilized to facilitate the exploration of online educational data. To help researchers better understand the necessity and the efficiency of these techniques in online education, we systematically review related works of the past decade to provide a comprehensive view of the use of visualization in online education problems. We establish a taxonomy based on the analysis goal and classify the existing visual analytics techniques into four categories: learning behavior analysis, learning content analysis, analysis of interactions among students, and prediction and recommendation. The use of visual analytics techniques is summarized in each category to show their benefits in different analysis tasks. At last, we discuss the future research opportunities and challenges in the utilization of visual analytics techniques for online education.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Kui, Xiaoyan; Liu, Naiming; Liu, Qiang; Liu, Jingwei; Zeng, Xiaoqian; Zhang, Chao] Cent South Univ, Sch Comp Sci, 932 Lushan South Rd, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Zhang, C (corresponding author), Cent South Univ, Sch Comp Sci, 932 Lushan South Rd, Changsha 410083, Hunan, Peoples R China.
EM chao.zhang@csu.edu.cn
FU National Natural Science Foundation of China [62177047]; Ministry of
   Education, China [31]; research Project of Teaching Reform in Colleges
   and Universities in Hunan Province, China (Xiangjiaotong) [232]; Hunan
   graduate education teaching reform research project, China
   [2020JGZD010]; Central South University Graduate Education Teaching
   Reform Research Project, China [2020JGA007]
FX The work described in this paper was supported by the grant from the
   National Natural Science Foundation of China (No. 62177047); The first
   batch of new liberal arts research and reform practice projects of the
   Ministry of Education, China (Teaching Hall Letter [2021] No. 31);
   research Project of Teaching Reform in Colleges and Universities in
   Hunan Province, China (Xiangjiaotong [2020] No. 232); Hunan graduate
   education teaching reform research project, China (2020JGZD010); Central
   South University Graduate Education Teaching Reform Research Project,
   China (2020JGA007).
CR [Anonymous], E LEARNING
   Aslan S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300534
   Atapattu T., 2016, TOPIC WISE CLASSIFIC
   Bueckle M., 2017, EMPOWERING INSTRUCTO
   Charleer S., 2013, ARTEL@ EC-TEL, V1103, P69
   Chen Q, 2019, IEEE PAC VIS SYMP, P237, DOI 10.1109/PacificVis.2019.00036
   Chen Q, 2020, IEEE T VIS COMPUT GR, V26, P1622, DOI 10.1109/TVCG.2018.2872961
   Chen Q, 2016, IEEE T VIS COMPUT GR, V22, P2315, DOI 10.1109/TVCG.2015.2505305
   Chen YZ, 2016, IEEE CONF VIS ANAL, P111, DOI 10.1109/VAST.2016.7883517
   Coffrin C., 2014, P 4 INT C LEARN AN K, P83, DOI DOI 10.1145/2567574.2567586
   Davis D., 2016, P 9 INT C ED DATA MI
   Deng HZ, 2019, VIS INFORM, V3, P166, DOI 10.1016/j.visinf.2019.10.004
   Dernoncourt F., 2013, NIPS WORKSHOP DATA D
   El-Assady M, 2018, COMPUT GRAPH FORUM, V37, P351, DOI 10.1111/cgf.13425
   El-Assady M, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.12919
   Fu S., 2018, Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI), P1, DOI [https://doi.org/10.1145/3173574.3174074, DOI 10.1109/SAHCN.2018.8397126]
   Fu SW, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3162075
   Fu SW, 2017, IEEE T VIS COMPUT GR, V23, P201, DOI 10.1109/TVCG.2016.2598444
   Ginda M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215964
   Aguilar DAG, 2009, J UNIVERS COMPUT SCI, V15, P1526
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   He H, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P56, DOI [10.1109/VISUAL.2019.8933778, 10.1109/visual.2019.8933778]
   He H, 2018, IEEE CONF VIS ANAL, P25, DOI 10.1109/VAST.2018.8802383
   He H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3521, DOI 10.1145/3308558.3314140
   He H, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P99, DOI 10.1145/3300115.3309514
   Ho J.C., 2018, J EDUC-S AFR, VOnline, P2
   Hoque E, 2014, COMPUT GRAPH FORUM, V33, P221, DOI 10.1111/cgf.12378
   Huang NF, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P753, DOI 10.1109/ICBDA.2017.8078738
   Kim J., 2014, P 1 ACM C LEARNING S
   Li H., 2017, 31 ANN C JAPANESE SO
   Li HT, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445294
   Li X, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING IMIS 2015, P34, DOI 10.1109/IMIS.2015.10
   Li X, 2017, 2017 IEEE 15TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 15TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 3RD INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS(DASC/PICOM/DATACOM/CYBERSCI, P101, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2017.31
   Liu Ching., 2018, P 2018 CHI C HUMAN F, P1
   Liu Z, 2018, 2018 INTERNATIONAL JOINT CONFERENCE ON INFORMATION, MEDIA AND ENGINEERING (ICIME), P177, DOI 10.1109/ICIME.2018.00044
   Meng Xia, 2020, L@S '20. Proceedings of the Seventh ACM Conference on Learning @ Scale, P37, DOI 10.1145/3386527.3405924
   Mu X., 2019, EUROVIS SHORT PAPERS, P91
   Okubo F., 2015, P 23 INT C COMP ED H, P739
   Okubo F, 2017, VISUALIZATION SYSTEM
   Poon LKM, 2017, LECT NOTES COMPUT SC, V10309, P166, DOI 10.1007/978-3-319-59360-9_15
   Qu HM, 2015, IEEE COMPUT GRAPH, V35, P69, DOI 10.1109/MCG.2015.137
   Rei A, 2017, P 2017 INT C E ED E, P42
   Schaffer J, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P380, DOI 10.1109/ASONAM.2016.7752262
   Schwab M, 2017, IEEE T VIS COMPUT GR, V23, P571, DOI 10.1109/TVCG.2016.2598518
   Shi CL, 2015, IEEE PAC VIS SYMP, P159, DOI 10.1109/PACIFICVIS.2015.7156373
   Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203
   Sung CY, 2016, P 2016 CHI C HUM FAC, P2185, DOI DOI 10.1145/2851581.2892327
   Tsung Sean, 2022, L@S '22: Proceedings of the Ninth ACM Conference on Learning @ Scale, P299, DOI 10.1145/3491140.3528298
   Vieira C, 2018, COMPUT EDUC, V122, P119, DOI 10.1016/j.compedu.2018.03.018
   Wachtler J., 2016, SE VBL LAK, V1579, P8
   Wang L, 2009, P HUM LANG TECHN 200, P200
   Wang X, 2020, IEEE GLOBE WORK, DOI 10.1109/GCWkshps50303.2020.9367552
   Wang YT, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P960, DOI 10.1145/3025453.3025819
   Wong GKW, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT, AND LEARNING FOR ENGINEERING (TALE), P109, DOI 10.1109/TALE.2016.7851779
   Wong JS, 2018, VIS INFORM, V2, P37, DOI 10.1016/j.visinf.2018.04.005
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Wu TS, 2016, IEEE PAC VIS SYMP, P194, DOI 10.1109/PACIFICVIS.2016.7465269
   Xia M, 2021, IEEE T VIS COMPUT GR, V27, P870, DOI 10.1109/TVCG.2020.3030337
   Xia M, 2020, COMPUT GRAPH FORUM, V39, P511, DOI 10.1111/cgf.13998
   Xia M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300864
   Zhao J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173903
   Zheng YF, 2018, EDUC TECHNOL SOC, V21, P91
NR 62
TC 4
Z9 4
U1 6
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 67
EP 77
DI 10.1016/j.visinf.2022.07.004
EA NOV 2022
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100006
DA 2024-07-18
ER

PT J
AU Su, BP
   Liu, XX
   Gao, WZ
   Yang, Y
   Chen, SX
AF Su, Benpeng
   Liu, Xuxing
   Gao, Weize
   Yang, Ye
   Chen, Shanxiong
TI A restoration method using dual generate adversarial networks for
   Chinese ancient characters
SO VISUAL INFORMATICS
LA English
DT Article
DE Stroke shape restoration; Texture restoration; Calligraphy style
AB Ancient books that record the history of different periods are precious for human civilization. But the protection of them is facing serious problems such as aging. It is significant to repair the damaged characters in ancient books and restore their original textures. The requirement of the restoration of the damaged character is keeping the stroke shape correct and the font style consistent. In order to solve these problems, this paper proposes a new restoration method based on generative adversarial networks. We use the shape restoration network to complete the stroke shape recovery and the font style recovery. The texture repair network is responsible for reconstructing texture details. In order to improve the accuracy of the generator in the shape restoration network, we use the adversarial feature loss (AFL), which can update the generator and discriminator synchronously to replace the traditional perceptual loss. Meanwhile, the font style loss is proposed to maintain the stylistic consistency for the whole character. Our model is evaluated on the datasets Yi and Qing, and shows that it outperforms current state-of-the-art techniques quantitatively and qualitatively. In particular, the Structural Similarity has increased by 8.0% and 6.7% respectively on the two datasets. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Su, Benpeng; Liu, Xuxing; Gao, Weize; Yang, Ye; Chen, Shanxiong] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
   [Chen, Shanxiong] Chinese Acad Sci, Chongqing Inst Green & Intelligent Technol, Chongqing Key Lab Automated Reasoning & Cognit, Chongqing 400714, Peoples R China.
C3 Southwest University - China; Chinese Academy of Sciences; Chongqing
   Institute of Green & Intelligent Technology, CAS
RP Chen, SX (corresponding author), Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
EM csxpml@swu.edu.cn
FU National Social Science Foundation of China [19BYY171]; Fundamental
   Research Funds for the Central Universities [XDJK2013C117]; Southwest
   University [20130553]; China Postdoctoral Science Foundation
   [2015M580765]; Chongqing Postdoctoral Science Foundation [Xm2016041];
   Chongqing Natural Science Foundation [cstc2019jcyj-msxmX0130]; Chongqing
   City science and technology education research projects [KJQN201801901]
FX This work was supported in part by the National Social Science
   Foundation of China under Grant 19BYY171, in part by the Fundamental
   Research Funds for the Central Universities under Grant XDJK2013C117, in
   part by Ph.D. Fund of Southwest University No. 20130553, in part by
   China Postdoctoral Science Foundation under Grant 2015M580765, in part
   by Chongqing Postdoctoral Science Foundation under Grant Xm2016041,
   Chongqing Natural Science Foundation (cstc2019jcyj-msxmX0130), Chongqing
   City science and technology education research projects (KJQN201801901).
   In additional, I would particularly like to acknowledge Professor
   Qunsheng Peng, for his wonderful collaboration and patient support.
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Chen S., 2020, ACTA AUTOMAT SINICA, V24, P1
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jingyuan Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7757, DOI 10.1109/CVPR42600.2020.00778
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kawai N, 2016, IEEE T VIS COMPUT GR, V22, P1236, DOI 10.1109/TVCG.2015.2462368
   Kingma D. P., 2014, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P3050, DOI 10.1109/TIFS.2017.2730822
   Liu JY, 2018, IEEE T MULTIMEDIA, V20, P3252, DOI 10.1109/TMM.2018.2831636
   Miyato T, 2018, INT C LEARN REPR
   Nazeri K., 2019, ARXIV190100212
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ruzic T, 2015, IEEE T IMAGE PROCESS, V24, P444, DOI 10.1109/TIP.2014.2372479
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 26
TC 6
Z9 6
U1 4
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 6
IS 1
BP 26
EP 34
DI 10.1016/j.visinf.2022.02.001
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2S0ZC
UT WOS:000821528800003
OA gold
DA 2024-07-18
ER

PT J
AU Liu, HY
   Chen, XH
   Wang, YD
   Zhang, B
   Chen, YP
   Zhao, Y
   Zhou, FF
AF Liu, Haiyan
   Chen, Xiaohui
   Wang, Yidi
   Zhang, Bing
   Chen, Yunpeng
   Zhao, Ying
   Zhou, Fangfang
TI Visualization and visual analysis of vessel trajectory data: A survey
SO VISUAL INFORMATICS
LA English
DT Review
DE Maritime traffic; Vessel trajectory data; Automatic identification
   system; Visualization and visual analysis
ID IDENTIFICATION SYSTEM AIS; INTERACTIVE VISUALIZATION; MOVEMENT; TIME;
   ANALYTICS; PATTERNS; DENSITY; SPACE; AGGREGATION; FRAMEWORK
AB Maritime transports play a critical role in international trade and commerce. Massive vessels sailing around the world continuously generate vessel trajectory data that contain rich spatial-temporal patterns of vessel navigations. Analyzing and understanding these patterns are valuable for maritime traffic surveillance and management. As essential techniques in complex data analysis and understanding, visualization and visual analysis have been widely used in vessel trajectory data analysis. This paper presents a literature review on the visualization and visual analysis of vessel trajectory data. First, we introduce commonly used vessel trajectory data sets and summarize main operations in vessel trajectory data preprocessing. Then, we provide a taxonomy of visualization and visual analysis of vessel trajectory data based on existing approaches and introduce representative works in details. Finally, we expound on the prospects of the remaining challenges and directions for future research. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Liu, Haiyan; Chen, Xiaohui; Zhang, Bing] Informat Engn Univ, Inst Data & Target Engn, Zhengzhou, Peoples R China.
   [Wang, Yidi; Chen, Yunpeng; Zhao, Ying; Zhou, Fangfang] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Zhao, Ying] Rail Data Res & Applicat Key Lab Hunan Prov, Changsha, Peoples R China.
C3 PLA Information Engineering University; Central South University
RP Chen, XH (corresponding author), Informat Engn Univ, Inst Data & Target Engn, Zhengzhou, Peoples R China.
EM liuharry2020@163.com; cxh_vrlab@163.com; wangyidi1999@gmail.com;
   2359641104@qq.com; cypresearch@csu.edu.cn; zhaoying@csu.edu.cn;
   zff@csu.edu.cn
RI wang, zhiwen/JDV-9990-2023; wen, liang/JNR-7720-2023; wang,
   yu/IUQ-6654-2023; fang, li/JNS-8415-2023; chen, xia/GXM-5435-2022; yang,
   xu/JMP-5558-2023; Zhang, Yunxuan/IXD-9283-2023; Yang,
   Tian/JFB-1008-2023; chen, xi/GXH-3653-2022; Chen, Xiao/JBJ-7561-2023;
   WANG, JIAXUAN/JMP-8599-2023; zhang, yuyang/IVV-5089-2023; chen,
   xia/GYR-3948-2022; XIE, WANYING/JNR-9259-2023; Liu, Yujie/IWU-6535-2023;
   Zhang, Jun/JPK-7723-2023; Zhang, Can/JUU-9511-2023; Chen,
   Xiao/GQA-8928-2022; chen, xin/IQW-3432-2023
OI Chen, Xiao/0000-0002-9797-8384; Liu, Yujie/0000-0002-1153-6156; Chen,
   Xiao/0000-0002-9797-8384; 
FU National Natural Science Foundation of China [41801313, 41901397,
   61872388]
FX The work is supported in part by the National Natural Science Foundation
   of China (No. 41801313, 41901397, and 61872388).
CR Amini F, 2015, IEEE T VIS COMPUT GR, V21, P122, DOI 10.1109/TVCG.2014.2329308
   Andrienko G, 2011, J VISUAL LANG COMPUT, V22, P213, DOI 10.1016/j.jvlc.2011.02.003
   Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043
   Andrienko G, 2008, INFORM VISUAL, V7, P173, DOI 10.1057/ivs.2008.23
   Andrienko G, 2008, IEEE S VIS ANAL, P51, DOI 10.1109/VAST.2008.4677356
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   Anneken M, 2015, 2015 SAI INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P169, DOI 10.1109/IntelliSys.2015.7361141
   [Anonymous], 2008, OCEANS 2008 MTS IEEE
   [Anonymous], 2012, INFORM VISUAL
   [Anonymous], 2002, Official Journal of the European Union, V358, P59
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Barrios C., 2006, 2006 IEEE INTELLIGEN, P1053, DOI [10.1109/itsc.2006.1707361, DOI 10.1109/ITSC.2006.1707361]
   Cao WQ, 2017, J SYST SOFTWARE, V126, P34, DOI 10.1016/j.jss.2017.01.003
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Cohen J, 2009, PROC VLDB ENDOW, V2, P1481, DOI 10.14778/1687553.1687576
   Cong L., 2017, 2016 INT C ENG ADV T, P110
   Demsar U, 2010, INT J GEOGR INF SCI, V24, P1527, DOI 10.1080/13658816.2010.511223
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Eiden G., 2010, TECHNICAL NOTE 4 1 V
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   EVENDEN LJ, 1969, SOC FORCES, V47, P356, DOI 10.2307/2575048
   Fang ZX, 2012, J TRANSP GEOGR, V23, P44, DOI 10.1016/j.jtrangeo.2012.03.018
   Feixiang Zhu, 2014, Applied Mechanics and Materials, V694, P59, DOI 10.4028/www.scientific.net/AMM.694.59
   Ferrà C, 2018, MAR POLICY, V94, P275, DOI 10.1016/j.marpol.2017.12.013
   Halpern BS, 2008, SCIENCE, V319, P948, DOI 10.1126/science.1149345
   Han YH, 2017, ACM T DATABASE SYST, V42, DOI 10.1145/3015457
   Harati-Mokhtari A, 2007, J NAVIGATION, V60, P373, DOI 10.1017/S0373463307004298
   Hightower J, 2004, LECT NOTES COMPUT SC, V3205, P88
   Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P58
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jiang X., 2017, P 27 ANN INT C COMPU, P192
   Jin L, 2018, J NAVIGATION, V71, P1195, DOI 10.1017/S0373463318000085
   Jonhson C.R., 2004, Visualization handbook
   Kaluza P, 2010, J R SOC INTERFACE, V7, P1093, DOI 10.1098/rsif.2009.0495
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Keogh E, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P289, DOI 10.1109/ICDM.2001.989531
   Koylu C, 2017, INFORM VISUAL, V16, P309, DOI 10.1177/1473871616681375
   Kroodsma DA, 2018, SCIENCE, V359, P904, DOI 10.1126/science.aao5646
   Labrinidis A, 2012, PROC VLDB ENDOW, V5, P2032, DOI 10.14778/2367502.2367572
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Last P, 2014, J NAVIGATION, V67, P791, DOI 10.1017/S0373463314000253
   Lavigne V., 2011, 2011 IEEE International Conference on Technologies for Homeland Security (HST 2011), P49, DOI 10.1109/THS.2011.6107846
   Laxhammar R., 2008, P 11 INT C INF FUS C, P1
   Laxhammar R, 2009, FUSION: 2009 12TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4, P756
   Lerin P.M., 2012, INTELLIGENT INTERACT, V14, P233, DOI DOI 10.1109/MDM.2009.50
   Liu CL, 2018, INT J SHIP TRANS LOG, V10, P63, DOI 10.1504/IJSTL.2018.088323
   Liu SY, 2013, IEEE T INTELL TRANSP, V14, P1586, DOI 10.1109/TITS.2013.2263225
   Lundblad P, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P379, DOI 10.1109/IV.2009.38
   Ma RX, 2021, IEEE T VIS COMPUT GR, V27, P3717, DOI 10.1109/TVCG.2020.2980227
   Malik A., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P221, DOI 10.1109/VAST.2011.6102460
   Martineau E, 2011, DRDCVALCARTIERTM2010
   Meratnia N, 2004, LECT NOTES COMPUT SC, V2992, P765
   Muckell J., 2010, SIGSPATIAL, P402, DOI DOI 10.1145/1869790.1869847
   Pack Michael L., 2009, 2009 IEEE International Conference on Information Reuse & Integration (IRI 2009), P200, DOI 10.1109/IRI.2009.5211551
   Pallotta G, 2013, ENTROPY-SWITZ, V15, P2218, DOI 10.3390/e15062218
   Patroumpas K, 2017, GEOINFORMATICA, V21, P389, DOI 10.1007/s10707-016-0266-x
   Peel D, 2011, CAN J FISH AQUAT SCI, V68, P1252, DOI 10.1139/F2011-055
   Pelich R, 2015, IEEE J-STARS, V8, P3892, DOI 10.1109/JSTARS.2014.2319195
   Peng P, 2019, ENERGY, V168, P966, DOI 10.1016/j.energy.2018.11.049
   Perera LP, 2018, J OCEAN ENG SCI, V3, P133, DOI 10.1016/j.joes.2018.04.002
   Phan D, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P219, DOI 10.1109/INFVIS.2005.1532150
   Potamias M., 2006, P 18 INT C SCI STAT, P275
   Pu JS, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 1, P127, DOI 10.1109/MDM.2013.23
   Rahm E., 2000, IEEE Data Eng. Bull, V23, P3, DOI [10.1145/1317331.1317341, DOI 10.1145/1317331.1317341]
   Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381
   Ren Lei, 2014, Journal of Software, V25, P1909, DOI 10.13328/j.cnki.jos.004645
   Riveiro M., 2009, VISUAL ANAL HOMELAND
   Riveiro M, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1266
   Roy J, 2008, PROC SPIE, V6945, DOI 10.1117/12.776230
   Scheepens R, 2011, IEEE PAC VIS SYMP, P147, DOI 10.1109/PACIFICVIS.2011.5742384
   Schuessler N, 2009, TRANSPORT RES REC, P28, DOI 10.3141/2105-04
   Silveira PAM, 2013, J NAVIGATION, V66, P879, DOI 10.1017/S0373463313000519
   Soares A, 2019, 2019 INTERNATIONAL CONFERENCE ON MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS (ICMCIS), DOI 10.1109/icmcis.2019.8842749
   Stern H, 2013, PATTERN RECOGN LETT, V34, P1980, DOI 10.1016/j.patrec.2013.02.007
   Tao J, 2017, IEEE PAC VIS SYMP, P1, DOI 10.1109/PACIFICVIS.2017.8031572
   Thomas J. J., 2005, Illuminating the Path: The Research and Development Agenda for Visual Analytics
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Tu EM, 2018, IEEE T INTELL TRANSP, V19, P1559, DOI 10.1109/TITS.2017.2724551
   Varlamis I, 2021, GEOINFORMATICA, V25, P69, DOI 10.1007/s10707-020-00421-y
   Wang PL, 2020, CHIN CONT DECIS CONF, P3671, DOI 10.1109/CCDC49329.2020.9163962
   Wei X, 2017, IEEE INT C CYBERNET, P1
   Willems N, 2009, COMPUT GRAPH FORUM, V28, P959, DOI 10.1111/j.1467-8659.2009.01440.x
   Wu L, 2019, IEEE I C ELECT CIRC, P1, DOI [10.1109/icecs46596.2019.8965046, 10.1109/ICECS46596.2019.8965046]
   Wu L, 2017, J NAVIGATION, V70, P67, DOI 10.1017/S0373463316000345
   Xiao Z, 2020, IEEE T INTELL TRANSP, V21, P1796, DOI 10.1109/TITS.2019.2908191
   Yan ZJ, 2020, APPL OCEAN RES, V101, DOI 10.1016/j.apor.2020.102271
   Yuan YH, 2014, INT J GEOGR INF SCI, V28, P496, DOI 10.1080/13658816.2013.854369
   Zeng W, 2013, COMPUT GRAPH FORUM, V32, P271, DOI 10.1111/cgf.12114
   Zhang LY, 2019, TRANSPORT RES E-LOG, V129, P287, DOI 10.1016/j.tre.2017.07.011
   Zhang SK, 2016, J NAVIGATION, V69, P729, DOI 10.1017/S0373463315000831
   Zhang Y, 2012, P 18 ACM SIGKDD INT, P606, DOI DOI 10.1145/2339530.2339629
   Zhao LB, 2019, J NAVIGATION, V72, P290, DOI 10.1017/S0373463318000723
   Zhao LB, 2018, OCEAN ENG, V166, P37, DOI 10.1016/j.oceaneng.2018.08.005
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zhao Y, 2020, IEEE T VIS COMPUT GR, V26, P590, DOI 10.1109/TVCG.2019.2934655
   Zhao Y, 2019, IEEE T VIS COMPUT GR, V25, P12, DOI 10.1109/TVCG.2018.2865020
   Zhou FF, 2019, J VISUAL-JAPAN, V22, P419, DOI 10.1007/s12650-018-0530-2
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
NR 101
TC 20
Z9 20
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 1
EP 10
DI 10.1016/j.visinf.2021.10.002
EA DEC 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500001
OA gold
DA 2024-07-18
ER

PT J
AU Bao, ZY
   Fu, G
   Duan, L
   Xiao, CX
AF Bao, Zhongyun
   Fu, Gang
   Duan, Lian
   Xiao, Chunxia
TI Interactive lighting editing system for single indoor low-light scene
   images with corresponding depth maps
SO VISUAL INFORMATICS
LA English
DT Article
DE Image processing; Interactive relighting; Spherical harmonic lighting;
   Depth map; Intrinsic image decomposition
ID SPARSE REPRESENTATION
AB We propose a novel interactive lighting editing system for lighting a single indoor RGB image based on spherical harmonic lighting. It allows users to intuitively edit illumination and relight the complicated low-light indoor scene. Our method not only achieves plausible global relighting but also enhances the local details of the complicated scene according to the spatially-varying spherical harmonic lighting, which only requires a single RGB image along with a corresponding depth map. To this end, we first present a joint optimization algorithm, which is based on the geometric optimization of the depth map and intrinsic image decomposition avoiding texture-copy, for refining the depth map and obtaining the shading map. Then we propose a lighting estimation method based on spherical harmonic lighting, which not only achieves the global illumination estimation of the scene, but also further enhances local details of the complicated scene. Finally, we use a simple and intuitive interactive method to edit the environment lighting map to adjust lighting and relight the scene. Through extensive experimental results, we demonstrate that our proposed approach is simple and intuitive for relighting the low-light indoor scene, and achieve state-of-the-art results.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Bao, Zhongyun; Fu, Gang; Duan, Lian; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM cxxiao@whu.edu.cn
RI xiao, ming/KHT-1774-2024
FU NSFC; Bingtuan Science and Technology Program;  [61972298];  [2019BC008]
FX Acknowledgments This work is partially supported by NSFC (No. 61972298)
   and Bingtuan Science and Technology Program (No. 2019BC008) .
CR [Anonymous], 2003, Advances in neural information processing systems
   [Anonymous], 2022, P IEEE CVF C COMP VI, P18542
   Bohme M, 2010, COMPUT VIS IMAGE UND, V114, P1329, DOI 10.1016/j.cviu.2010.08.001
   Boyadzhiev I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461973
   Cao XC, 2005, PROC CVPR IEEE, P918
   Chandraker M, 2011, IEEE I CONF COMP VIS, P1076, DOI 10.1109/ICCV.2011.6126354
   Fan QN, 2017, IEEE I CONF COMP VIS, P3258, DOI 10.1109/ICCV.2017.351
   Fu G, 2021, PROC CVPR IEEE, P7748, DOI 10.1109/CVPR46437.2021.00766
   Garon M, 2019, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2019.00707
   Gehler P., 2011, P ADV NEUR INF PROC, P765
   Green R, 2003, ARCH GAM DEV C
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   Gui Y, 2020, VISUAL COMPUT, V36, P469, DOI 10.1007/s00371-019-01633-6
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Haouchine N., 2017, VISUAL COMPUT
   Hara K, 2008, IEEE T PATTERN ANAL, V30, P25, DOI 10.1109/TPAMI.2007.1164
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Kadambi A, 2015, IEEE I CONF COMP VIS, P3370, DOI 10.1109/ICCV.2015.385
   Lagger P, 2006, INT C PATT RECOG, P587
   LANDIS H, 2002, ACM SIGGRAPH 2002 CO
   Lettry L, 2018, IEEE WINT CONF APPL, P1359, DOI 10.1109/WACV.2018.00153
   Li C, 2019, IEEE T PATTERN ANAL, V41, P1455, DOI 10.1109/TPAMI.2018.2832059
   Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346
   Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338
   Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Shen L, 2013, IEEE T PATTERN ANAL, V35, P2904, DOI 10.1109/TPAMI.2013.136
   Shen L, 2011, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2011.5995738
   Sun YL, 2020, VISUAL COMPUT, V36, P2407, DOI 10.1007/s00371-020-01892-8
   Tappen M., 2006, IEEE COMPUTER VISION, P1992
   Tunwattanapong B., 2011, 2011 Conference for Visual Media Production, P138, DOI 10.1109/CVMP.2011.22
   Wu CL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661232
   Wu JH, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3034185
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201313
   Yu LF, 2013, PROC CVPR IEEE, P1415, DOI 10.1109/CVPR.2013.186
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   Zollhöfer M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766887
NR 38
TC 1
Z9 1
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 90
EP 99
DI 10.1016/j.visinf.2022.08.001
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100008
OA gold
DA 2024-07-18
ER

PT J
AU Gove, R
   Cadalzo, L
   Leiby, N
   Singer, JM
   Zaitzeff, A
AF Gove, Robert
   Cadalzo, Lucas
   Leiby, Nicholas
   Singer, Jedediah M.
   Zaitzeff, Alexander
TI New guidance for using t-SNE: Alternative defaults, hyperparameter
   selection automation, and comparative evaluation
SO VISUAL INFORMATICS
LA English
DT Article
DE Dimensionality reduction; Machine learning; t-SNE
ID DATA VISUALIZATION; QUALITY METRICS; DIMENSIONALITY; REDUCTION
AB We present new guidelines for choosing hyperparameters for t-SNE and an evaluation comparing these guidelines to current ones. These guidelines include a proposed empirically optimum guideline derived from a t-SNE hyperparameter grid search over a large collection of data sets. We also introduce a new method to featurize data sets using graph-based metrics called scagnostics; we use these features to train a neural network that predicts optimal t-SNE hyperparameters for the respective data set. This neural network has the potential to simplify the use of t-SNE by removing guesswork about which hyperparameters will produce the best embedding. We evaluate and compare our neural network-derived and empirically optimum hyperparameters to several other t-SNE hyperparameter guidelines from the literature on 68 data sets. The hyperparameters predicted by our neural network yield embeddings with similar accuracy as the best current t-SNE guidelines. Using our empirically optimum hyperparameters is simpler than following previously published guidelines but yields more accurate embeddings, in some cases by a statistically significant margin. We find that the useful ranges for t-SNE hyperparameters are narrower and include smaller values than previously reported in the literature. Importantly, we also quantify the potential for future improvements in this area: using data from a grid search of t-SNE hyperparameters we find that an optimal selection method could improve embedding accuracy by up to two percentage points over the methods examined in this paper. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Gove, Robert; Cadalzo, Lucas; Leiby, Nicholas; Singer, Jedediah M.; Zaitzeff, Alexander] Two Six Technol, Arlington, VA 22203 USA.
RP Gove, R (corresponding author), Two Six Technol, Arlington, VA 22203 USA.
EM rpgove@gmail.com; lucas.cadalzo@twosixtech.com;
   nick.leiby@twosixtech.com; jed.singer@twosixtech.com;
   alexander.zaitzeff@twosixtech.com
CR Alcalá-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   [Anonymous], 2015, R: A language and environment for statistical computing
   [Anonymous], 2016, DISTILL, DOI [10.23915/distill.00002, DOI 10.23915/DISTILL.00002]
   Asuncion A., 2007, Uci machine learning repository
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Belkina AC, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13055-y
   Bertini E, 2011, IEEE T VIS COMPUT GR, V17, P2203, DOI 10.1109/TVCG.2011.229
   Bibal A., 2019, Safe Machine Learning Workshop at ICLR
   Bibal A, 2016, Arxiv, DOI arXiv:1611.06175
   Bunte K, 2012, NEURAL COMPUT, V24, P771, DOI 10.1162/NECO_a_00250
   Cannings TI, 2021, WIRES COMPUT STAT, V13, DOI 10.1002/wics.1499
   Cannings TI, 2017, J ROY STAT SOC B, V79, P959, DOI 10.1111/rssb.12228
   Cao YS, 2017, Arxiv, DOI arXiv:1708.03229
   Chen LS, 2009, J AM STAT ASSOC, V104, P209, DOI 10.1198/jasa.2009.0111
   Cohen MB, 2015, ACM S THEORY COMPUT, P163, DOI 10.1145/2746539.2746569
   Dunne C, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2411412
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Gisbrecht A, 2015, WIRES DATA MIN KNOWL, V5, P51, DOI 10.1002/widm.1147
   Johansson S, 2009, IEEE T VIS COMPUT GR, V15, P993, DOI 10.1109/TVCG.2009.153
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Lee JA, 2015, NEUROCOMPUTING, V169, P246, DOI 10.1016/j.neucom.2014.12.095
   Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017
   Lehmann DJ, 2015, IT-INF TECHNOL, V57, P11, DOI 10.1515/itit-2014-1070
   Maaten L.v.d., 2021, T SNE LAUR MAAT
   McInnes L., 2018, ARXIV
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pohl M., 2009, COMPUTATIONAL AESTHE, P49
   Policar PG., 2019, BIORXIV
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase H. C., 2002, Empirical Software Engineering, V7, P233, DOI 10.1023/A:1016344215610
   Purchase H. C., 2002, Journal of Graph Algorithms and Applications, V6, DOI 10.7155/jgaa.00054
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Purchase HC, 1998, OZCHI 98 - 1998 AUSTRALASIAN COMPUTER HUMAN INTERACTION CONFERENCE, PROCEEDINGS, P80, DOI 10.1109/OZCHI.1998.732199
   Purchase HC, 1996, LECT NOTES COMPUT SC, V1027, P435, DOI 10.1007/BFb0021827
   Rieck B, 2015, TOPOLOGICAL METHODS, P103
   Ribeiro MT, 2016, Arxiv, DOI [arXiv:1606.05386, 10.48550/arXiv.1606.05386]
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang YH, 2020, IEEE T VIS COMPUT GR, V26, P759, DOI 10.1109/TVCG.2019.2934796
   Weidong Huang, 2010, Proceedings 2010 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2010), P176, DOI 10.1109/VLHCC.2010.32
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
NR 45
TC 12
Z9 12
U1 3
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 87
EP 97
DI 10.1016/j.visinf.2022.04.003
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 3D7JN
UT WOS:000829473700005
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, HX
   Ni, YN
   Sun, L
   Chen, YY
   Xu, T
   Chen, XH
   Su, WH
   Zhou, ZG
AF Wang, Haoxuan
   Ni, Yuna
   Sun, Ling
   Chen, Yuanyuan
   Xu, Ting
   Chen, Xiaohui
   Su, Weihua
   Zhou, Zhiguang
TI Hierarchical visualization of geographical areal data with spatial
   attribute association
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual analytics; Geographical areal data; Multi-scale visualization;
   Spatial attribute association
ID VISUAL ANALYTICS; PATTERNS; AUTOCORRELATION; EXPLORATION; NETWORKS;
   SCALE
AB Geographical areal data usually presents hierarchical structures, and its characteristics vary at different scales. At the higher scales, the visualization of geographical areal data is abstract and the detailed features are easily missed. As a difference, more detailed information is presented at the lower scales while the visual perception of global features is easily disturbed due to the overdrawing of visual elements. As the geographical areal data is visualized at a single scale at the same time, it seems impossible to balance the visual perception of both the global features and detailed characteristics. In this paper, we propose a multi-scale geographical areal data visualization method based on spatial attribute association to enhance the visual perception of both the global features and detailed characteristics. Firstly, the geographical areal data is aggregated into hierarchical clusters based on the spatial similarity. Then, the coefficient of variation is applied to estimate the attribute distribution of each cluster in the hierarchy, and a novel geographical areal data visualization scheme is proposed to adaptively present the multi-scale clusters with lower variation coefficients at the same time. In addition, a rich set of visual interfaces and user-friendly interactions are provided enabling users to specify those clusters of interest at different scales and compare multi-scale visualizations with different hierarchies. Finally, we implement a geographical areal data visualization framework, allowing users to visually explore the global features and detailed characteristics at the same time and get deeper insights into the potential features in the geographical areal data. Case studies and quantitative comparisons based on real-world datasets have been conducted to demonstrate the effectiveness of the proposed multi-scale visualization method for in-depth visual exploration of geographical areal data. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wang, Haoxuan; Ni, Yuna; Sun, Ling; Zhou, Zhiguang] Zhejiang Univ Finance & Econ, Sch Informat Management & Artificial Intelligence, Hangzhou 310018, Peoples R China.
   [Chen, Yuanyuan] Zhejiang Univ Technol, Coll Environm, Hangzhou 310014, Peoples R China.
   [Xu, Ting] Zhejiang Univ, Affiliated Hosp 1, Sch Med, Hangzhou, Peoples R China.
   [Chen, Xiaohui] Informat Engn Univ China, Inst Data & Target Engn, Zhengzhou, Peoples R China.
   [Su, Weihua] Zhejiang Gongshang Univ, Coll Stat & Math, Hangzhou 310018, Peoples R China.
C3 Zhejiang University of Finance & Economics; Zhejiang University of
   Technology; Zhejiang University; Zhejiang Gongshang University
RP Zhou, ZG (corresponding author), Zhejiang Univ Finance & Econ, Sch Informat Management & Artificial Intelligence, Hangzhou 310018, Peoples R China.
EM whxxyhf@163.com; niniblg019@163.com; 1055389464@qq.com;
   yychen91@zjut.edu.cn; xut@zju.edu.cn; cxh_vrlab@163.com;
   swh@zjgsu.edu.cn; zhgzhou1983@163.com
RI Chen, Xiao/JBJ-7561-2023; chen, xi/GXH-3653-2022; Chen,
   Xiao/GQA-8928-2022; chen, xia/GXM-5435-2022; chen, xin/IQW-3432-2023;
   chen, xia/GYR-3948-2022; Chen, Yuanyuan/GXG-2130-2022
OI Chen, Xiao/0000-0002-9797-8384; Chen, Xiao/0000-0002-9797-8384; 
FU National Natural Science Foundation of China [61872314, 41901363,
   41801313]; Open Project Program of the State Key Lab of CADCG of
   Zhejiang University [A2001]; Public Welfare Technology Applied Research
   Project of Zhejiang Province [LGF20G010003]
FX We would like to thank the reviewers for their thoughtful comments. The
   work is supported in part by the National Natural Science Foundation of
   China (No. 61872314, No. 41901363 and No. 41801313), the Open Project
   Program of the State Key Lab of CADCG of Zhejiang University (No. A2001)
   and the Public Welfare Technology Applied Research Project of Zhejiang
   Province (No. LGF20G010003).
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arce-Orozco A, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER SCIENCE (INCISCOS), P369, DOI 10.1109/INCISCOS.2017.32
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Burch M, 2013, IEEE PAC VIS SYMP, P169, DOI 10.1109/PacificVis.2013.6596142
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2440, DOI 10.1109/TVCG.2011.193
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Chen W, 2016, IEEE T MULTIMEDIA, V18, P2247, DOI 10.1109/TMM.2016.2614221
   Delort JY, 2010, SECOND INTERNATIONAL CONFERENCE ON ADVANCED GEOGRAPHIC INFORMATION SYSTEMS, APPLICATIONS, AND SERVICES: GEOPROCESSING 2010, PROCEEDINGS, P33, DOI 10.1109/GEOProcessing.2010.13
   Dormann CF, 2007, ECOGRAPHY, V30, P609, DOI 10.1111/j.2007.0906-7590.05171.x
   Feng C, 2019, P COMP VIS MED C CVM
   Feng ZZ, 2021, IEEE T VIS COMPUT GR, V27, P828, DOI 10.1109/TVCG.2020.3030469
   Fisz M., 1999, Probability Theory and Mathematical Statistics
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   He M, 2011, 19 INT C GEOINFORMAT, P1, DOI [10.1109/GeoInformatics.2011.5980880, DOI 10.1109/GEOINFORMATICS.2011.5980880]
   Huang ZS, 2020, IEEE T VIS COMPUT GR, V26, P2576, DOI 10.1109/TVCG.2019.2892483
   Kong N, 2010, IEEE T VIS COMPUT GR, V16, P990, DOI 10.1109/TVCG.2010.186
   Lambert A, 2010, IEEE INT CONF INF VI, P329, DOI 10.1109/IV.2010.53
   Le Rest K, 2013, ECOL INFORM, V14, P17, DOI 10.1016/j.ecoinf.2012.11.008
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu H, 2019, VIS INFORM, V3, P140, DOI 10.1016/j.visinf.2019.10.002
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2014, VISUAL COMPUT, V30, P1373, DOI 10.1007/s00371-013-0892-3
   Lott SC, 2015, FRONT GENET, V6, DOI 10.3389/fgene.2015.00043
   Manley D, 2006, COMPUT ENVIRON URBAN, V30, P143, DOI 10.1016/j.compenvurbsys.2005.08.005
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Ninyerola M, 2007, THEOR APPL CLIMATOL, V89, P195, DOI 10.1007/s00704-006-0264-2
   Packer E, 2013, IEEE T VIS COMPUT GR, V19, P2179, DOI 10.1109/TVCG.2013.224
   Pinho R, 2006, INFORMATION VISUALIZATION-BOOK, P39
   Polczynski Mark., 2014, Cartographica: The International Journal for Geographic Information and Geovisualization, V49, P69
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Simmons A, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P219, DOI 10.1109/VLHCC.2015.7357220
   Stolte C, 2003, IEEE T VIS COMPUT GR, V9, P176, DOI 10.1109/TVCG.2003.1196005
   Thom D, 2016, IEEE T VIS COMPUT GR, V22, P1816, DOI 10.1109/TVCG.2015.2511733
   Tiede D, 2014, CARTOGR GEOGR INF SC, V41, P227, DOI 10.1080/15230406.2014.901900
   Turkay C, 2014, IEEE T VIS COMPUT GR, V20, P2033, DOI 10.1109/TVCG.2014.2346265
   van der Ploeg A, 2014, SOFTWARE PRACT EXPER, V44, P1467, DOI 10.1002/spe.2213
   Wang F, 2017, IEEE T INTELL TRANSP, V18, P2250, DOI 10.1109/TITS.2017.2711644
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang YT, 2010, ADV MATER RES-SWITZ, V92, P1, DOI 10.4028/www.scientific.net/AMR.92.1
   Wang ZC, 2014, IEEE T VIS COMPUT GR, V20, P1813, DOI 10.1109/TVCG.2014.2346746
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wood J, 2008, IEEE T VIS COMPUT GR, V14, P1348, DOI 10.1109/TVCG.2008.165
   Xia JZ, 2020, FRONT INFORM TECH EL, V21, P507, DOI 10.1631/FITEE.1900532
   Xia JZ, 2020, IEEE CONF VIS ANAL, P107, DOI 10.1109/VAST50239.2020.00015
   Xing R, 2018, 2018 2 IEEE ADV INF
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang JW, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2940, DOI 10.1145/3025453.3025801
   Zhang Y, 2016, COMPUT GRAPH FORUM, V35, P101, DOI 10.1111/cgf.12886
   Zhao SD, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2005.1532129
   Zhao Y., 2021, IEEE T VIS COMPUT GR
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zhao Y, 2020, IEEE T VIS COMPUT GR, V26, P590, DOI 10.1109/TVCG.2019.2934655
   Zhou FF, 2019, J VISUAL-JAPAN, V22, P419, DOI 10.1007/s12650-018-0530-2
   Zhou ZG, 2021, NEUROCOMPUTING, V459, P23, DOI 10.1016/j.neucom.2021.05.005
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
   Zhou ZG, 2020, NEUROCOMPUTING, V376, P244, DOI 10.1016/j.neucom.2019.10.072
   Zhou ZG, 2018, J VISUAL LANG COMPUT, V48, P169, DOI 10.1016/j.jvlc.2018.08.009
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
NR 59
TC 7
Z9 7
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 82
EP 91
DI 10.1016/j.visinf.2021.09.001
EA OCT 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200007
OA gold
DA 2024-07-18
ER

PT J
AU Zhu, HY
   Zhu, MF
   Feng, YCJ
   Cai, D
   Hu, YZ
   Wu, SL
   Wu, XY
   Chen, W
AF Zhu, Haiyang
   Zhu, Minfeng
   Feng, Yingchaojie
   Cai, Deng
   Hu, Yuanzhe
   Wu, Shilong
   Wu, Xiangyang
   Chen, Wei
TI Visualizing large-scale high-dimensional data via hierarchical embedding
   of KNN graphs
SO VISUAL INFORMATICS
LA English
DT Article
DE High-dimensional data visualization; KNN graph; Graph visualization
ID FIT
AB Visualizing intrinsic structures of high-dimensional data is an essential task in data analysis. Over the past decades, a large number of methods have been proposed. Among all solutions, one promising way for enabling effective visual exploration is to construct a k-nearest neighbor (KNN) graph and visualize the graph in a low-dimensional space. Yet, state-of-the-art methods such as the LargeVis still suffer from two main problems when applied to large-scale data: (1) they may produce unappealing visualizations due to the non-convexity of the cost function; (2) visualizing the KNN graph is still time-consuming. In this work, we propose a novel visualization algorithm that leverages a multi-level representation to achieve a high-quality graph layout and employs a cluster-based approximation scheme to accelerate the KNN graph layout. Experiments on various large-scale datasets indicate that our approach achieves a speedup by a factor of five for KNN graph visualization compared to LargeVis and yields aesthetically pleasing visualization results. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Zhu, Haiyang; Zhu, Minfeng; Feng, Yingchaojie; Cai, Deng; Hu, Yuanzhe; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Wu, Shilong] Univ Calif Santa Cruz, San Francisco, CA 95064 USA.
   [Wu, Xiangyang] Hangzhou Dianzi Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; University of California System; University of
   California Santa Cruz; Hangzhou Dianzi University
RP Wu, SL (corresponding author), Univ Calif Santa Cruz, San Francisco, CA 95064 USA.
EM hnsyzhy@zju.edu.cn; minfeng_zhu@zju.edu.cn; fycj@zju.edu.cn;
   dengcai@cad.zju.edu.cn; cadhyz@zju.edu.cn; swu97@ucsc.edu;
   wuxy@hdu.edu.cn; chenwei@cad.zju.edu.cn
RI wu, xiangyang/E-4437-2017; zhu, haiyang/JXY-1271-2024; Zhu,
   Minfeng/R-6788-2019
OI zhu, haiyang/0000-0002-4782-5654; Zhu, Minfeng/0000-0002-6711-3099;
   Feng, Yingchaojie/0000-0002-1418-4635
FU National Natural Science Foundation of China [61972122, 61772456]
FX This paper is supported by National Natural Science Foundation of China
   (61972122, 61772456) .
CR Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chan DM, 2018, INT SYM COMP ARCHIT, P330, DOI [10.1109/CAHPC.2018.8645912, 10.1109/SBAC-PAD.2018.00060]
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Fu C, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P176, DOI 10.1145/3292500.3330834
   Fu Cong, 2016, ABS160907228 CORR
   Gajer P., 2000, GD'00: Proceedings of the 8th International Symposium on Graph Drawing, P222, DOI [10.5555/647552.729406, DOI 10.5555/647552.729406]
   Guo RC, 2020, VIS INFORM, V4, P72, DOI 10.1016/j.visinf.2020.04.001
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Han DM, 2019, J VISUAL-JAPAN, V22, P1241, DOI 10.1007/s12650-019-00598-x
   He XF, 2004, ADV NEUR IN, V16, P153
   Hu Y., 2005, Mathematica J., V10, P37, DOI DOI 10.3402/QHW.V6I2.5918
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Joulin A., 2016, ARXIV PREPRINT ARXIV, V2, P427
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Leskovec J., 2014, SNAP Datasets: Stanford large network dataset collection
   Linderman GC, 2019, NAT METHODS, V16, P243, DOI 10.1038/s41592-018-0308-4
   Ma YX, 2021, IEEE T VIS COMPUT GR, V27, P241, DOI 10.1109/TVCG.2020.3011155
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Mahfouz A, 2015, METHODS, V73, P79, DOI 10.1016/j.ymeth.2014.10.004
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Meyerhenke H, 2018, IEEE T VIS COMPUT GR, V24, P1814, DOI 10.1109/TVCG.2017.2689016
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Sorzano C.O.S., 2014, A survey of dimensionality reduction techniques". In, P1
   Tang J, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P287, DOI 10.1145/2872427.2883041
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Veldhuizen T.L, 2007, ARXIV PREPRINT ARXIV
NR 34
TC 9
Z9 9
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2021
VL 5
IS 2
BP 51
EP 59
DI 10.1016/j.visinf.2021.06.002
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA WN8QS
UT WOS:000712032300002
OA gold
DA 2024-07-18
ER

PT J
AU Wu, HY
   Amirkhanov, A
   Grossmann, N
   Klein, T
   Kouril, D
   Miao, HC
   Luidolt, LR
   Mindek, P
   Raidou, RG
   Viola, I
   Waldner, M
   Gröller, ME
AF Wu, Hsiang-Yun
   Amirkhanov, Aleksandr
   Grossmann, Nicolas
   Klein, Tobias
   Kouril, David
   Miao, Haichao
   Luidolt, Laura R.
   Mindek, Peter
   Raidou, Renata G.
   Viola, Ivan
   Waldner, Manuela
   Grolier, M. Eduard
TI Visualization Working Group at TU Wien
SO VISUAL INFORMATICS
LA English
DT Review
DE Vis-group; Visualization; Visual analytics; Visual modelitics; Visual
   data science
ID VISUAL ANALYTICS; EXPLORATION; ATTENTION; DNA
AB Building-up and running a university-based research group is a multi-faceted undertaking. The visualization working group at TU Wien (vis-group) has been internationally active over more than 25 years. The group has been acting in a competitive scientific setting where sometimes contradicting multiple objectives require trade-offs and optimizations. Research-wise the group has been performing basic and applied research in visualization and visual computing. Teaching-wise the group has been involved in undergraduate and graduate lecturing in (medical) visualization and computer graphics. To be scientifically competitive requires to constantly expose the group and its members to a strong international competition at the highest level. This necessitates to shield the members against the ensuing pressures and demands and provide (emotional) support and encouragement. Internally, the vis-group has developed a unique professional and social interaction culture: work and celebrate, hard and together. This has crystallized into a nested, recursive, and triangular organization model, which concretizes what it takes to make a research group successful. The key elements are the creative and competent vis-group members who collaboratively strive for (scientific) excellence in a socially enjoyable environment. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wu, Hsiang-Yun; Amirkhanov, Aleksandr; Grossmann, Nicolas; Klein, Tobias; Kouril, David; Miao, Haichao; Luidolt, Laura R.; Mindek, Peter; Raidou, Renata G.; Viola, Ivan; Waldner, Manuela; Grolier, M. Eduard] TU Wien, Vienna, Austria.
C3 Technische Universitat Wien
RP Wu, HY (corresponding author), TU Wien, Vienna, Austria.
EM hsiang.yun.wu@acm.org; aamirkhanov@cg.tuwien.ac.at;
   ngrossmann@cg.tuwien.ac.at; tklein@cg.tuwien.ac.at;
   dvdkouril@cg.tuwien.ac.at; miao@cg.tuwien.ac.at;
   lluidolt@cg.tuwien.ac.at; mindek@cg.tuwien.ac.at;
   rraidou@cg.tuwien.ac.at; viola@cg.tuwien.ac.at; waldner@cg.tuwien.ac.at;
   groeller@cg.tuwien.ac.at
RI Waldner, Manuela/JZC-9267-2024; Viola, Ivan/O-8944-2014; Wu,
   Hsiang-Yun/T-8434-2018; Miao, Haichao/HNJ-6239-2023
OI Waldner, Manuela/0000-0003-1387-5132; Wu,
   Hsiang-Yun/0000-0003-1028-0010; Klein, Tobias/0000-0001-9455-7587;
   Raidou, Renata Georgia/0000-0003-2468-0664; Mindek,
   Peter/0000-0002-9434-5952; Luidolt, Laura R./0000-0003-3996-8337
CR Amirkhanov A, 2020, COMPUT GRAPH FORUM, V39, P635, DOI 10.1111/cgf.14174
   Amirkhanov A, 2019, COMPUT GRAPH FORUM, V38, P191, DOI 10.1111/cgf.13828
   [Anonymous], 2018, EUROVIS SHORT PAPERS
   Barisic I, 2020, NUCLEIC ACIDS RES
   Bernold G, 2019, P EUR WORKSH VIS COM, DOI [10.2312/vcbm.20191234, DOI 10.2312/VCBM.20191234]
   Bruckner S, 2011, P EUR 2011, P23
   Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1077, DOI 10.1109/TVCG.2006.140
   Deutsches Zentrum fur Herz- und Kreislaufforschung, 2021, CLIN RES PLATF DZHK
   Furmanová K, 2020, COMPUT GRAPH-UK, V91, P25, DOI 10.1016/j.cag.2020.07.001
   Klein T, 2018, IEEE T VIS COMPUT GR, V24, P862, DOI 10.1109/TVCG.2017.2744258
   Kouril D, 2019, IEEE T VIS COMPUT GR, V25, P977, DOI 10.1109/TVCG.2018.2864491
   Le Muzic M, 2016, COMPUT GRAPH FORUM, V35, P161, DOI 10.1111/cgf.12892
   Le Muzic Mathieu, 2015, Eurographics Workshop Vis Comput Biomed, V2015, P61, DOI 10.2312/vcbm.20151209
   Le Muzic M, 2015, IEEE PAC VIS SYMP, P247, DOI 10.1109/PACIFICVIS.2015.7156384
   Luidolt LR, 2020, IEEE T VIS COMPUT GR, V26, P3557, DOI 10.1109/TVCG.2020.3023604
   Mazurek M, 2018, COMPUT GRAPH FORUM, V37, P87, DOI 10.1111/cgf.13403
   Miao HC, 2018, IEEE T VIS COMPUT GR, V24, P1014, DOI 10.1109/TVCG.2017.2743981
   Mindek P, 2018, IEEE T VIS COMPUT GR, V24, P883, DOI 10.1109/TVCG.2017.2744518
   Mizuno K, 2019, COMPUT GRAPH FORUM, V38, P13, DOI 10.1111/cgf.13668
   Nguyen N, 2021, IEEE T VIS COMPUT GR, V27, P722, DOI 10.1109/TVCG.2020.3030415
   Ortner T, 2017, IEEE T VIS COMPUT GR, V23, P1139, DOI 10.1109/TVCG.2016.2520920
   Polatsek P, 2018, COMPUT GRAPH-UK, V72, P26, DOI 10.1016/j.cag.2018.01.010
   Raidou, 2021, PREVIS PREDICTIVE VI
   Raidou RG, 2015, COMPUT GRAPH FORUM, V34, P11, DOI 10.1111/cgf.12613
   Reh A, 2013, IEEE T VIS COMPUT GR, V19, P2906, DOI 10.1109/TVCG.2013.177
   Rothemund PWK, 2006, NATURE, V440, P297, DOI 10.1038/nature04586
   Sadlo F, 2018, VISION MODELING VISU
   Schindler M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P1, DOI 10.1109/VIS47514.2020.00007
   Steinbock D., 2018, INT S BIG DAT VIS IM, P1, DOI DOI 10.1109/BDVA.2018.8533894
   Viola I, 2020, MOLECUMENTARY SCALAB
   Viola I., 2020, IEEE T VIS COMPUT GR
   Viola I, 2020, IEEE T VIS COMPUT GR
   Viola I, 2006, IEEE T VIS COMPUT GR, V12, P933, DOI 10.1109/TVCG.2006.152
   VRVis, 2021, VRVIS ZENTRUM VIRTUA
   Waldin N, 2019, COMPUT GRAPH FORUM, V38, P150, DOI 10.1111/cgf.13611
   Waldin N, 2017, COMPUT GRAPH FORUM, V36, P467, DOI 10.1111/cgf.13141
   Waldner I, P 8 NORD C HUM COMP, P295
   Waldner M, 2021, INFORM VISUAL, V20, P47, DOI 10.1177/1473871620986249
   Waldner M, 2020, J COMPUT LANG, V57, DOI 10.1016/j.cola.2020.100959
   Waldner M, 2014, IEEE T VIS COMPUT GR, V20, P2456, DOI 10.1109/TVCG.2014.2346352
   Waldner Manuela, 2017, P 33 SPRING C COMPUT, P1, DOI DOI 10.1145/3154353.3154369
   Weissenböck J, 2019, IEEE T VIS COMPUT GR, V25, P1040, DOI 10.1109/TVCG.2018.2864510
   Wu H.- Y, 2020, P 28 INT S GRAPH DRA
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Wu HY, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2779-4
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
NR 46
TC 0
Z9 0
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2021
VL 5
IS 1
BP 76
EP 84
DI 10.1016/j.visinf.2021.02.003
EA MAR 2021
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LE
UT WOS:000658194100036
OA gold
DA 2024-07-18
ER

PT J
AU Zheng, WJ
   Li, J
   Zhang, Y
AF Zheng, Wanjie
   Li, Jie
   Zhang, Yang
TI Desirable molecule discovery via generative latent space exploration
SO VISUAL INFORMATICS
LA English
DT Article
DE Molecule generation; Latent space exploration; Constrained optimization
AB Drug molecule design is a classic research topic. Drug experts traditionally design molecules relying on their experience. Manual drug design is time-consuming and may produce low-efficacy and off -target molecules. With the popularity of deep learning, drug experts are beginning to use generative models to design drug molecules. A well-trained generative model can learn the distribution of training samples and infinitely generate drug-like molecules similar to the training samples. The automatic process improves design efficiency. However, most existing methods focus on proposing and optimizing generative models. How to discover ideal molecules from massive candidates is still an unresolved challenge. We propose a visualization system to discover ideal drug molecules generated by generative models. In this paper, we investigated the requirements and issues of drug design experts when using generative models, i.e., generating molecular structures with specific constraints and finding other molecular structures similar to potential drug molecular structures. We formalized the first problem as an optimization problem and proposed using a genetic algorithm to solve it. For the second problem, we proposed using a neighborhood sampling algorithm based on the continuity of the latent space to find solutions. We integrated the proposed algorithms into a visualization tool, and a case study for discovering potential drug molecules to make KOR agonists and experiments demonstrated the utility of our approach.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Zheng, Wanjie; Li, Jie; Zhang, Yang] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
C3 Tianjin University
RP Li, J (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
EM jie.li@tju.edu.cn
RI Li, Jie/X-4832-2018
OI Li, Jie/0000-0001-6511-4090
FU NSFC [61972278, 62372321]
FX The work is supported by the NSFC project (61972278) and the NSFC
   project (62372321).
CR Abbasi M., 2022, Designing optimized drug candidates with generative adversarial network
   Anderson Eric, 1987, Smiles, a Line Notation and Computerized Interpreter for Chemical Structures
   Anstine DM, 2023, J AM CHEM SOC, V145, P8736, DOI 10.1021/jacs.2c13467
   Arvanitidis G, 2021, Arxiv, DOI [arXiv:1710.11379, DOI 10.48550/ARXIV.1710.11379]
   Bento AP, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00456-1
   Bjerrum EJ, 2018, BIOMOLECULES, V8, DOI 10.3390/biom8040131
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   De Cao N, 2018, Arxiv, DOI arXiv:1805.11973
   DiMasi JA, 2016, J HEALTH ECON, V47, P20, DOI 10.1016/j.jhealeco.2016.01.012
   Eckert H, 2007, DRUG DISCOV TODAY, V12, P225, DOI 10.1016/j.drudis.2007.01.011
   Fernandes P, 2020, LECT NOTES COMPUT SC, V12104, P595, DOI 10.1007/978-3-030-43722-0_38
   Ganea OE, 2021, ADV NEUR IN, V34
   G¢mez-Bombarelli R, 2017, Arxiv, DOI arXiv:1610.02415
   Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grinberg Miguel, 2018, Flask web development: developing web applications with python
   Guimaraes GL, 2018, Arxiv, DOI [arXiv:1705.10843, 10.48550/arXiv.1705.10843, DOI 10.48550/ARXIV.1705.10843]
   Huang Q, 2022, INT SYM PERFORM ANAL, P277, DOI 10.1109/ISPASS55109.2022.00041
   Kikuchi K, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P88, DOI 10.1145/3474085.3475497
   Kingma D. P., 2022, ARXIV
   Li YX, 2018, Arxiv, DOI [arXiv:1701.07274, 10.48550/arxiv.1701.07274]
   Lim J, 2018, J CHEMINFORMATICS, V10, DOI 10.1186/s13321-018-0286-7
   Machín B, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION, GECCO 2022, P1878, DOI 10.1145/3520304.3533992
   Machín B, 2021, 2021 IEEE LATIN AMERICAN CONFERENCE ON COMPUTATIONAL INTELLIGENCE (LA-CCI), DOI 10.1109/LA-CCI48322.2021.9769851
   Masuda T, 2020, Arxiv, DOI [arXiv:2010.14442, 10.48550/arXiv.2010.14442]
   Maziarka L, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-019-0404-1
   Popova M, 2019, Arxiv, DOI arXiv:1905.13372
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Sanchez-Lengeling B., 2017, ChemRxiv, DOI 10.26434/chemrxiv.5309668.v3
   Shi CC, 2020, Arxiv, DOI [arXiv:2001.09382, 10.48550/arXiv.2001.09382, DOI 10.48550/ARXIV.2001.09382]
   Singh H., 2020, arXiv
   Trinajstic N., 1992, CHEM GRAPH THEORY
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   White T, 2016, Arxiv, DOI [arXiv:1609.04468, 10.48550/arXiv.1609.04468, DOI 10.48550/ARXIV.1609.04468]
   Willett P, 2011, METHODS MOL BIOL, V672, P133, DOI 10.1007/978-1-60761-839-3_5
   You JX, 2018, ADV NEUR IN, V31
NR 36
TC 2
Z9 2
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 13
EP 21
DI 10.1016/j.visinf.2023.10.002
EA NOV 2023
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CU5N5
UT WOS:001127765100001
OA gold
DA 2024-07-18
ER

PT J
AU Hu, ZP
   Fan, CJ
   Zheng, QW
   Wu, W
   Liu, B
AF Hu, Zhipeng
   Fan, Changjie
   Zheng, Qiwei
   Wu, Wei
   Liu, Bai
TI Asyncflow: A visual programming tool for game artificial intelligence
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual programming; Flowchart; Game Artificial Intelligence
AB Visual programming tools are widely applied in the game industry to assist game designers in developing game artificial intelligence (game AI) and gameplay. However, testing multiple game engines is a time-consuming operation, which degrades development efficiency. To provide an asynchronous platform for game designers, this paper introduces Asyncflow, an open-source visual programming solution. It consists of a flowchart maker for game logic explanation and a runtime framework integrating an asynchronous mechanism based on an event-driven architecture. Asyncflow supports multiple programming languages and can be easily embedded in various game engines to run flowcharts created by game designers. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Hu, Zhipeng] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Hu, Zhipeng; Fan, Changjie; Zheng, Qiwei; Wu, Wei; Liu, Bai] NetEase Inc, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Hu, ZP (corresponding author), NetEase Inc, Hangzhou, Peoples R China.
EM zphu@corp.netease.com; fanchangjie@corp.netease.com;
   hzzhengqiwei@corp.netease.com; wuwei02@corp.netease.com;
   hzliubai@corp.netease.com
CR Bolte F., 2020, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2019.2963651
   Boussejra MO, 2019, VIS INFORM, V3, P1, DOI 10.1016/j.visinf.2019.03.001
   Carlisle M.C., 2004, J. Comput. Small Coll, V19, P52
   Charntaweekhun K., 2006, 2006 International Symposium on Communications and Information Technologies (IEEE Cat No. 06EX1447C), P1062, DOI 10.1109/ISCIT.2006.339940
   Drosos I, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20)
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   Girault A, 1999, IEEE T COMPUT AID D, V18, P742, DOI 10.1109/43.766725
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Pearson M., 2020, PROMICROSOFT POWER P, P73
   Resnick M, 2009, COMMUN ACM, V52, P60, DOI 10.1145/1592761.1592779
   Sekhavat YA, 2017, INT J ARTIF INTELL T, V26, DOI 10.1142/S0218213017300010
   Shoulson Alexander, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P144, DOI 10.1007/978-3-642-25090-3_13
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Wagner F., 2006, MODELING SOFTWARE FI
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
   Yuan ZM, 2008, LECT NOTES COMPUT SC, V5328, P55
NR 19
TC 1
Z9 1
U1 6
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 20
EP 25
DI 10.1016/j.visinf.2021.11.001
EA DEC 2021
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500003
OA gold
DA 2024-07-18
ER

PT J
AU Wang, YT
   Wang, T
   Cui, Y
   Mei, HH
   Wen, X
   Lu, JZ
   Chen, W
AF Wang, Yiting
   Wang, Ting
   Cui, Ying
   Mei, Honghui
   Wen, Xiao
   Lu, Jinzhi
   Chen, Wei
TI COVID-19 data visualization public welfare activity
SO VISUAL INFORMATICS
LA English
DT Article
AB The coronavirus disease 2019 (COVID-19) pandemic started in early 2020. At the beginning of February, a public welfare activity in epidemic data visualization, jointly launched by China Computer Federation (CCF) (CCF) CAD & CG Technical Committee, Alibaba Cloud Tianchi (Alibaba Cloud Tianch), JiqiZhixin (JiqiZhixin), Alibaba Cloud DataV (Alibaba Cloud DataV), and DataWhale (DataWhale), was launched with the theme "Fighting the Epidemic with One Mind and Talents like Tianchi.'' Developers in general are expected to focus on several demand scenarios, such as epidemic situation display, epidemic popular science, trend prediction, material-supply situation, and rework and return situation of employees from all sectors and areas, to discover the relationship between complex heterogeneous multi-source data, develop various upbeat works and present useful information to the public in a coherent manner.
   The entry works take the form of data visualization and are divided into two categories: popular science publicity and application scenarios. The popular science publicity category includes works for the public, focused on epidemic situation display, epidemic popular science publicity, epidemic prevention and control, and others. The application scenario category consists of the works of frontline officers, which can provide anti-epidemic workers with effective data tools for efficient and intuitive epidemic analysis; offer reliable, understandable, and easily transmitted information for disease prevention; and assist governments, enterprises, and institutions in the fight against COVID-19. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wang, Yiting; Wang, Ting; Cui, Ying; Mei, Honghui; Wen, Xiao] Alicloud, Qingdao, Peoples R China.
   [Lu, Jinzhi; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
EM yiting.wangyt@alibaba-inc.com; tiandu.wangt@alibaba-inc.com;
   ying.cuiy@alibaba-inc.com; honghui.mhh@alibaba-inc.com;
   ninglang.wx@alibaba-inc.com; lujinzhi@cad.zju.edu.cn; chenvis@zju.edu.cn
RI Cui, Ying/E-3960-2018
FU Alibaba-Zhejiang University Joint Institute of Frontier Technologies
FX This project is partially funded by Alibaba-Zhejiang University Joint
   Institute of Frontier Technologies.
NR 0
TC 4
Z9 4
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2020
VL 4
IS 3
BP 51
EP 54
DI 10.1016/j.visinf.2020.09.003
PG 4
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KP
UT WOS:000658192600005
PM 38620335
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Chen, XY
   Shen, LM
   Sha, ZQ
   Liu, RC
   Chen, SM
   Ji, GL
   Tan, C
AF Chen, Xueyi
   Shen, Liming
   Sha, Ziqi
   Liu, Richen
   Chen, Siming
   Ji, Genlin
   Tan, Chao
TI A Survey of Multi-Space Techniques in Spatio-Temporal Simulation Data
   Visualization
SO VISUAL INFORMATICS
LA English
DT Article
DE Simulation data visualization; Spatio-temporal data visualization;
   Comparative visualization
AB The widespread use of numerical simulations in different scientific domains provides a variety of research opportunities. They often output a great deal of spatio-temporal simulation data, which are traditionally characterized as single-run, multi-run, multi-variate, multi-modal and multi-dimensional. From the perspective of data exploration and analysis, we noticed that many works focusing on spatio-temporal simulation data often share similar exploration techniques, for example, the exploration schemes designed in simulation space, parameter space, feature space and combinations of them. However, it lacks a survey to have a systematic overview of the essential commonalities shared by those works. In this survey, we take a novel multi-space perspective to categorize the state-of-the-art works into three major categories. Specifically, the works are characterized as using similar techniques such as visual designs in simulation space (e.g, visual mapping, boxplot-based visual summarization, etc.), parameter space analysis (e.g, visual steering, parameter space projection, etc.) and data processing in feature space (e.g, feature definition and extraction, sampling, reduction and clustering of simulation data, etc.). (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Chen, Xueyi; Shen, Liming; Sha, Ziqi; Liu, Richen; Ji, Genlin; Tan, Chao] Nanjing Normal Univ, Sch Comp Sci & Technol, 1 Wenyuan Rd, Nanjing, Jiangsu, Peoples R China.
   [Chen, Siming] Fraunhofer Inst Intelligent Anal & Informat Syst, St Augustin, Germany.
   [Chen, Siming] Univ Bonn, Bonn, Germany.
C3 Nanjing Normal University; Fraunhofer Gesellschaft; University of Bonn
RP Liu, RC (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, 1 Wenyuan Rd, Nanjing, Jiangsu, Peoples R China.
EM richen@pku.edu.cn
RI Chen, Siming/AAK-1874-2020; Tan, Chao/F-5858-2013; Liu,
   Richen/AAB-2890-2022
OI Chen, Siming/0000-0002-2690-3588; Liu, Richen/0000-0002-5321-098X
FU National Natural Science Foundation of China (NSFC) [61702271, 61702270]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) Grant Nos. 61702271 and 61702270.
CR Berger W, 2011, COMPUT GRAPH FORUM, V30, P911, DOI 10.1111/j.1467-8659.2011.01940.x
   Bergner S, 2013, IEEE T VIS COMPUT GR, V19, P1499, DOI 10.1109/TVCG.2013.61
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Coffey D, 2013, IEEE T VIS COMPUT GR, V19, P2783, DOI 10.1109/TVCG.2013.147
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Doleisch H., 2003, JOINT EUROGRAPHICS I
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Fofonov A., 2018, COMPUT GRAPH FORUM, P1
   Harvey W, 2010, COMPUT GRAPH FORUM, V29, P993, DOI 10.1111/j.1467-8659.2009.01706.x
   Höllt T, 2013, IEEE PAC VIS SYMP, P185, DOI 10.1109/PacificVis.2013.6596144
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   Jarema M, 2015, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2015.7347634
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Köthur P, 2014, IEEE T VIS COMPUT GR, V20, P1893, DOI 10.1109/TVCG.2014.2346751
   Kumpf A., 2018, IEEE T VIS COMPUT GR, P1
   Li S, 2018, COMPUT GRAPH FORUM, V37, P422, DOI 10.1111/cgf.13336
   Liu Renju., 2015, Proceedings of the 6th Asia-Pacific Workshop on Systems, P1
   Liu RC, 2017, J VISUAL-JAPAN, V20, P217, DOI 10.1007/s12650-016-0388-0
   Liu RC, 2016, IEEE PAC VIS SYMP, P96, DOI 10.1109/PACIFICVIS.2016.7465256
   Matkovic K, 2008, IEEE T VIS COMPUT GR, V14, P1699, DOI 10.1109/TVCG.2008.145
   Matkovic K, 2014, IEEE T VIS COMPUT GR, V20, P1803, DOI 10.1109/TVCG.2014.2346744
   Matkovic K, 2010, IEEE T VIS COMPUT GR, V16, P1449, DOI 10.1109/TVCG.2010.171
   Matkovic K, 2009, IEEE T VIS COMPUT GR, V15, P1351, DOI 10.1109/TVCG.2009.155
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Muigg P, 2008, COMPUT GRAPH FORUM, V27, P775, DOI 10.1111/j.1467-8659.2008.01207.x
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Oster T, 2014, COMPUT GRAPH FORUM, V33, P321, DOI 10.1111/cgf.12388
   Poco J, 2014, COMPUT GRAPH FORUM, V33, P341, DOI 10.1111/cgf.12390
   Poco J, 2014, IEEE T VIS COMPUT GR, V20, P1923, DOI 10.1109/TVCG.2014.2346755
   Potter K, 2010, COMPUT GRAPH FORUM, V29, P823, DOI 10.1111/j.1467-8659.2009.01677.x
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Potter K, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012089
   Rautenhaus M, 2018, IEEE T VIS COMPUT GR, V24, P3268, DOI 10.1109/TVCG.2017.2779501
   Ropinski T, 2011, COMPUT GRAPH-UK, V35, P392, DOI 10.1016/j.cag.2011.01.011
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Shu QY, 2016, IEEE PAC VIS SYMP, P56, DOI 10.1109/PACIFICVIS.2016.7465251
   Unger A, 2009, IEEE PAC VIS SYMP, P57, DOI 10.1109/PACIFICVIS.2009.4906838
   Wang J., 2015, IEEE T VIS COMPUT GR, V14, P1
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P1416, DOI 10.1109/TVCG.2007.70601
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Williams S, 2011, COMPUT GRAPH FORUM, V30, P991, DOI 10.1111/j.1467-8659.2011.01948.x
   Woodring J, 2011, COMPUT GRAPH FORUM, V30, P1151, DOI 10.1111/j.1467-8659.2011.01964.x
   Woodring J, 2016, IEEE T VIS COMPUT GR, V22, P857, DOI 10.1109/TVCG.2015.2467411
NR 47
TC 6
Z9 7
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2019
VL 3
IS 3
BP 129
EP 139
DI 10.1016/j.visinf.2019.08.002
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YL
UT WOS:000658189600002
OA gold
DA 2024-07-18
ER

PT J
AU Chen, BQ
   Zeng, Q
   Cheng, ZL
AF Chen, Baoquan
   Zeng, Qiong
   Cheng, Zhanglin
TI Quasi-holography computational model for urban computing
SO VISUAL INFORMATICS
LA English
DT Article
DE Holography model; Urban data representation
AB Vast amounts of data are produced with the development of smart cities and urban computing technologies. The data is often captured from multiple sensors, with heterogeneous structures and highly decentralized connections. Integrated data representation and smart computational models are required for more complex tasks in urban computing. We dwell deeply on two fundamental questions - can we provide an integrated data representation for the whole cyber-physical-social system? And, can we provide an integrated framework to choose the appropriate data for understanding a specific urban event? A holography data representation and the quasi-holography computational model have been proposed to address these problems. We describe case studies using the quasi-holography computational model, and discuss further problems to solve regarding our model. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Chen, Baoquan] Peking Univ, Beijing, Peoples R China.
   [Chen, Baoquan; Zeng, Qiong] Shandong Univ, Jinan, Shandong, Peoples R China.
   [Cheng, Zhanglin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
C3 Peking University; Shandong University; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS
RP Chen, BQ (corresponding author), Peking Univ, Beijing, Peoples R China.; Chen, BQ (corresponding author), Shandong Univ, Jinan, Shandong, Peoples R China.
EM baoquan@pku.eud.cn
OI Cheng, Zhanglin/0000-0002-3360-2679; Zeng, Qiong/0000-0002-2827-8261
FU National Basic Research Program of China (973 Program) [2015CB352501,
   2015CB352500]
FX This work was supported by National Basic Research Program of China (973
   Program) (2015CB352501, 2015CB352500).
CR Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   Cassandras CG, 2016, ENGINEERING, V2, P156, DOI 10.1016/J.ENG.2016.02.012
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Cook DJ, 2012, SCIENCE, V335, P1579, DOI 10.1126/science.1217640
   De S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101017
   Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Miotto R, 2016, SCI REP-UK, V6, DOI 10.1038/srep26094
   Ong BT, 2016, NEURAL COMPUT APPL, V27, P1553, DOI 10.1007/s00521-015-1955-3
   Paulos E., 2004, UBICOMP URBAN FRONTI, DOI [10.1184/R1/6470588.v1, DOI 10.1184/R1/6470588.V1]
   Paulos Eric., 2004, C HUM FACT COMP SYST, P223, DOI [10.1145/985692.985721, DOI 10.1145/985692.985721]
   Qi ZG, 2018, IEEE T KNOWL DATA EN, V30, P2285, DOI 10.1109/TKDE.2018.2823740
   Sheth A, 2013, IEEE INTELL SYST, V28, P78, DOI 10.1109/MIS.2013.20
   Silva TH, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3301284
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Varshney U, 2007, MOBILE NETW APPL, V12, P113, DOI 10.1007/s11036-007-0017-1
   Yi XW, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P965, DOI 10.1145/3219819.3219822
   Zhang SH, 2017, IEEE I CONF COMP VIS, P3687, DOI 10.1109/ICCV.2017.396
   Zhang SH, 2017, PROC CVPR IEEE, P4264, DOI 10.1109/CVPR.2017.454
   Zhao H., 2018, NEURIPS
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng Y, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2629592
NR 22
TC 3
Z9 3
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2019
VL 3
IS 2
BP 81
EP 86
DI 10.1016/j.visinf.2019.07.001
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YK
UT WOS:000658189200003
OA gold
DA 2024-07-18
ER

PT J
AU Chegini, M
   Bernard, J
   Berger, P
   Sourin, A
   Andrews, K
   Schreck, T
AF Chegini, Mohammad
   Bernard, Juergen
   Berger, Philip
   Sourin, Alexei
   Andrews, Keith
   Schreck, Tobias
TI Interactive labelling of a multivariate dataset for supervised machine
   learning using linked visualisations, clustering, and active learning
SO VISUAL INFORMATICS
LA English
DT Article
DE Labelling; Clustering; Classification; Active learning; Multivariate
   data; Visualisation
ID TOOL
AB Supervised machine learning techniques require labelled multivariate training datasets. Many approaches address the issue of unlabelled datasets by tightly coupling machine learning algorithms with interactive visualisations. Using appropriate techniques, analysts can play an active role in a highly interactive and iterative machine learning process to label the dataset and create meaningful partitions. While this principle has been implemented either for unsupervised, semi-supervised, or supervised machine learning tasks, the combination of all three methodologies remains challenging.
   In this paper, a visual analytics approach is presented, combining a variety of machine learning capabilities with four linked visualisation views, all integrated within the mVis (multivariate Visualiser) system. The available palette of techniques allows an analyst to perform exploratory data analysis on a multivariate dataset and divide it into meaningful labelled partitions, from which a classifier can be built. In the workflow, the analyst can label interesting patterns or outliers in a semi-supervised process supported by active learning. Once a dataset has been interactively labelled, the analyst can continue the workflow with supervised machine learning to assess to what degree the subsequent classifier has effectively learned the concepts expressed in the labelled training dataset. Using a novel technique called automatic dimension selection, interactions the analyst had with dimensions of the multivariate dataset are used to steer the machine learning algorithms.
   A real-world football dataset is used to show the utility of mVis for a series of analysis and labelling tasks, from initial labelling through iterations of data exploration, clustering, classification, and active learning to refine the named partitions, to finally producing a high-quality labelled training dataset suitable for training a classifier. The tool empowers the analyst with interactive visualisations including scatterplots, parallel coordinates, similarity maps for records, and a new similarity map for partitions. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Chegini, Mohammad; Andrews, Keith; Schreck, Tobias] Graz Univ Technol, Graz, Austria.
   [Chegini, Mohammad; Sourin, Alexei] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Bernard, Juergen] Tech Univ Darmstadt, Darmstadt, Germany.
   [Berger, Philip] Univ Rostock, Rostock, Germany.
C3 Graz University of Technology; Nanyang Technological University;
   Technical University of Darmstadt; University of Rostock
RP Chegini, M (corresponding author), Graz Univ Technol, Graz, Austria.
EM m.chegini@cgv.tugraz.at
RI Bernard, Jürgen/AAK-5732-2021; Sourin, Alexei/A-3701-2011
OI Bernard, Jürgen/0000-0001-8741-9709; NASSREDDINE,
   Redhaounia/0000-0002-5436-6484; Sourin, Alexei/0000-0003-4051-2927
CR Abe N., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P1
   Amershi S, 2014, AI MAG, V35, P105, DOI 10.1609/aimag.v35i4.2513
   Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Attenberg Josh, 2011, ACM SIGKDD Explorations Newsl, V12, P36, DOI [DOI 10.1145/1964897.1964906, 10.1145/1964897.1964906]
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Berger P., 2018, IEEE C INF VIS INFOV
   Bernard J, 2018, VISUAL COMPUT, V34, P1189, DOI 10.1007/s00371-018-1500-3
   Bernard J, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13406
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Bernard Jurgen, 2014, P 22 INT C CENTR EUR, V22, P329
   Bruneau P, 2015, NEUROCOMPUTING, V150, P627, DOI 10.1016/j.neucom.2014.09.062
   Chegini M, 2018, COMPUT GRAPH FORUM, V37, P99, DOI 10.1111/cgf.13404
   Cox M.A., 2008, HDB DATA VISUALIZATI, P315, DOI 10.1007/978-3-642-28753-4101322
   DMandML, 2018, GITHUB REPOSITORY
   Endert A., 2018, IEEE T VIS COMPUT GR, V24, P2223, DOI [10.1109/TVCG.2017.2711030, DOI 10.1109/TVCG.2017.2711030]
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hoi Steven C. H., 2006, Proceedings of the International Conference on the World Wide Web (WWW-2006), P633, DOI [10.1145/1135777.1135870, DOI 10.1145/1135777.1135870]
   Hund Michael, 2016, Brain Inform, V3, P233, DOI 10.1007/s40708-016-0043-5
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   Lee H, 2012, COMPUT GRAPH FORUM, V31, P1155, DOI 10.1111/j.1467-8659.2012.03108.x
   Lin H., 2017, COMPUT GRAPH FORUM C, V36, P458, DOI [10.1111/cgf.13092, DOI 10.1111/CGF.13092]
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Nam EJ, 2007, IEEE CONF VIS ANAL, P75
   Netzel R, 2017, VIS INFORM, V1, P118, DOI 10.1016/j.visinf.2017.11.001
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Qi GJ, 2009, IEEE T PATTERN ANAL, V31, P1880, DOI 10.1109/TPAMI.2008.218
   Rasmussen M, 2004, GCLUTO AN INTERACTIV
   Ritter C., 2018, EUROVA EUROVIS, DOI 10.2312/eurova.20181109
   Sacha D, 2017, NEUROCOMPUTING, V268, P164, DOI 10.1016/j.neucom.2017.01.105
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Settles B., 2012, Active Learning, V6, P1, DOI DOI 10.1007/978-3-031-01560-1
   Settles B, 2008, P C EMP METH NAT LAN, P1070, DOI DOI 10.3115/1613715.1613855
   Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417
   Shao L, 2017, COMPUT GRAPH FORUM, V36, P157, DOI 10.1111/cgf.13176
   Tuia D, 2011, IEEE J-STSP, V5, P606, DOI 10.1109/JSTSP.2011.2139193
   Wenskovitch J, 2018, IEEE T VIS COMPUT GR, V24, P131, DOI 10.1109/TVCG.2017.2745258
   Wu Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P529, DOI 10.1109/ICME.2006.262442
NR 42
TC 33
Z9 38
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2019
VL 3
IS 1
BP 9
EP 17
DI 10.1016/j.visinf.2019.03.002
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YJ
UT WOS:000658187900002
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Rebelo, SM
   Martins, T
   Ferreira, D
   Rebelo, A
AF Rebelo, Sergio M.
   Martins, Tiago
   Ferreira, Diogo
   Rebelo, Artur
TI Towards the automation of book typesetting
SO VISUAL INFORMATICS
LA English
DT Article
DE Design tools; Data-driven design; Generative design; Graphic design;
   Typography
ID GENETIC ALGORITHMS
AB This paper proposes a generative approach for the automatic typesetting of books in desktop publishing. The presented system consists in a computer script that operates inside a widely used design software tool and implements a generative process based on several typographic rules, styles and principles which have been identified in the literature. The performance of the proposed system is tested through an experiment which included the evaluation of its outputs with people. The results reveal the ability of the system to consistently create varied book designs from the same input content as well as visually coherent book designs with different contents while complying with fundamental typographic principles.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Rebelo, Sergio M.; Martins, Tiago; Ferreira, Diogo; Rebelo, Artur] Univ Coimbra, Ctr Informat & Syst, Dept Informat Engn, Coimbra, Portugal.
C3 Universidade de Coimbra
RP Rebelo, SM; Martins, T; Ferreira, D (corresponding author), Univ Coimbra, Ctr Informat & Syst, Dept Informat Engn, Coimbra, Portugal.
EM srebelo@dei.uc.pt; tiagofm@dei.uc.pt; df@diogoferreira.com
RI Rebelo, Sérgio M/JNE-9604-2023; Martins, Tiago/HJY-7033-2023
OI Martins, Tiago/0000-0003-2638-237X; /0000-0002-7276-8727; Rebelo,
   Artur/0000-0001-8741-078X
FU Foundation for Science and Technology, I.P./MCTES (Portugal) through
   national funds (PIDDAC) [UIDB/00326/2020, UIDP/00326/2020]; FCT
   [SFRH/BD/132728/2017, COVID/BD/151969/2021]
FX We would like to express our gratitude to all the participants in the
   evaluation sessions. This work is partially supported by the Foundation
   for Science and Technology, I.P./MCTES (Portugal) through national funds
   (PIDDAC), within the scope of project UIDB/00326/2020 or project code
   UIDP/00326/2020. Sergio M. Rebelo was funded by FCT under the grant
   SFRH/BD/132728/2017 and COVID/BD/151969/2021.
CR Ahmadullin I., 2013, P 2013 ACM S DOCUMEN, P141, DOI DOI 10.1145/2494266.2494276
   Ahn Y, 2016, LEONARDO, V49, P168, DOI 10.1162/LEON_a_01062
   Amitani S, 2008, DESIGN STUD, V29, P572, DOI 10.1016/j.destud.2008.07.007
   [Anonymous], 2002, Journal of Interactive Marketing, DOI DOI 10.1002/DIR.10002
   Armstrong H., 2016, DIGITAL DESIGN THEOR
   Barrett D., 2000, LETTERROR E VANBLOKL
   Boden MA, 2009, DIGIT CREAT, V20, P21, DOI 10.1080/14626260902867915
   Boll S., 2007, P 15 ACM INT C MULTI, P641, DOI DOI 10.1145/1291233.1291385
   Bringhurst R., 1997, The Elements of Typographic Style, V2nd
   Cleveland P, 2010, DESIGN STUD, V31, P3, DOI 10.1016/j.destud.2009.06.003
   Cooper M., 1989, DESIGN QUART, V142, P1, DOI 10.2307/4091189
   Cramer F., 2002, SEMINAR ALLGEMEINE V
   Damera-Venkata N, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P3
   de Oliveira JBS, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P141
   Ferreira D., 2019, THESIS U COIMBRA
   Galanter P., 2016, A Companion to Digital Art, P146, DOI [10.1002/9781118475249.ch5, DOI 10.1002/9781118475249.CH5]
   Geigel J, 2001, P SOC PHOTO-OPT INS, V4311, P79
   Gerstner K., 2019, DESIGNING PROGRAMMES
   Gerstner K., 1974, COMPENDIUM LITERATES
   Goldenberg E., 2002, THESIS U SUSSEX
   González J, 2002, IEEE T SYST MAN CY B, V32, P686, DOI 10.1109/TSMCB.2002.1033189
   Guo SN, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445117
   Haslam Andrew., 2006, Book Design
   Hochuli J., 2004, DESIGNING BOOKS PRAC
   Hochuli Jost, 2008, DETAIL TYPOGRAPHY
   Kikuchi K, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P88, DOI 10.1145/3474085.3475497
   Klein D., 2012, CROSSING MIXING MUTA
   Knuth D.E., 1991, TEXBOOK, V20th
   KNUTH DE, 1981, SOFTWARE PRACT EXPER, V11, P1119, DOI 10.1002/spe.4380111102
   KNUTH DE, 1982, VISIBLE LANG, V16, P3
   LESS, 2016, EV LAYOUT
   Levin G., 2001, INTERACTIVE LOGOGRAP
   Li JN, 2021, IEEE T PATTERN ANAL, V43, P2388, DOI 10.1109/TPAMI.2019.2963663
   Lopes D, 2022, LECT NOTES COMPUT SC, P162, DOI 10.1007/978-3-031-03789-4_11
   Lupton E., 2014, Thinking with Type: A Critical Guide for Designers, Writers, Editors, & Students
   Maeda J., 2000, Maeda @ Media
   Maffei NP, 2019, READING GRAPHIC DESIGN IN CULTURAL CONTEXT, P207
   Martins T, 2018, LECT NOTES COMPUT SC, V10783, P299, DOI 10.1007/978-3-319-77583-8_20
   Meggs PB, 2016, MEGGS HIST GRAPHIC D
   Middendorp J., 2018, DUTCH TYPE, P209
   Muller-Brockmann J., 1981, Grid Systems in Graphic Design
   Musgrave JF, 1996, IBM SYST J, V35, P499, DOI 10.1147/sj.353.0499
   Neue, 2010, VIS NORDK
   Onduygu D.C., 2010, Ph.D. thesis
   Purvis L., 2003, P 2003 ACM S DOC ENG, P68, DOI DOI 10.1145/958220.958234
   Quiroz JC, 2009, STUD COMPUT INTELL, V226, P309
   Quiroz JC, 2007, IEEE C EVOL COMPUTAT, P1366, DOI 10.1109/CEC.2007.4424630
   Reas C., 2010, LUST FORM CODE DESIG
   Rebelo SM, 2021, C&C'21: PROCEEDINGS OF THE 13TH CONFERENCE ON CREATIVITY AND COGNITION, DOI 10.1145/3450741.3465247
   Richardson A., 2016, Data-driven Graphic Design: Creative Coding for Visual Communication
   Sandhaus P., 2010, P 18 ACM INT C MULTI, P1555, DOI DOI 10.1145/1873951.1874283
   Sandhaus P, 2011, LECT NOTES COMPUT SC, V6523, P84
   Strecker T., 2009, OPERATIONS RES P 200, P469, DOI DOI 10.1007/978-3-642-00142-0_76
   The Magic Book Project, 2020, ABOUT US
   Tschichold Jan, 1991, FORM BOOK ESSAYS MOR
   Yin W., 2013, P 21 ACM INT C MULT, P927, DOI [DOI 10.1145/2502081.2502116, 10.1145/2502081]
   Ying C., 2014, TECH CRUNCH
   Zeller L., 2014, DESIGN USER EXPERIEN, P686, DOI DOI 10.1007/978-3-319-07668-3_66
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
NR 59
TC 1
Z9 1
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 1
EP 12
DI 10.1016/j.visinf.2023.01.003
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA N2VJ6
UT WOS:001035649100001
OA Green Submitted, gold, Green Published
DA 2024-07-18
ER

PT J
AU Piccolotto, N
   Bögl, M
   Gschwandtner, T
   Muehlmann, C
   Nordhausen, K
   Filzmoser, P
   Miksch, S
AF Piccolotto, Nikolaus
   Bogl, Markus
   Gschwandtner, Theresia
   Muehlmann, Christoph
   Nordhausen, Klaus
   Filzmoser, Peter
   Miksch, Silvia
TI TBSSvis: Visual analytics for Temporal Blind Source Separation
SO VISUAL INFORMATICS
LA English
DT Article
DE Blind source separation; Ensemble visualization; Visual analytics;
   Parameter space exploration
ID TIME-SERIES; VISUALIZATION; DESIGN; MODEL; REDUCTION
AB Temporal Blind Source Separation (TBSS) is used to obtain the true underlying processes from noisy temporal multivariate data, such as electrocardiograms. TBSS has similarities to Principal Component Analysis (PCA) as it separates the input data into univariate components and is applicable to suitable datasets from various domains, such as medicine, finance, or civil engineering. Despite TBSS's broad applicability, the involved tasks are not well supported in current tools, which offer only text-based interactions and single static images. Analysts are limited in analyzing and comparing obtained results, which consist of diverse data such as matrices and sets of time series. Additionally, parameter settings have a big impact on separation performance, but as a consequence of improper tooling, analysts currently do not consider the whole parameter space. We propose to solve these problems by applying visual analytics (VA) principles. Our primary contribution is a design study for TBSS, which so far has not been explored by the visualization community. We developed a task abstraction and visualization design in a user-centered design process. Task-specific assembling of well-established visualization techniques and algorithms to gain insights in the TBSS processes is our secondary contribution. We present TBSSvis, an interactive web-based VA prototype, which we evaluated extensively in two interviews with five TBSS experts. Feedback and observations from these interviews show that TBSSvis supports the actual workflow and combination of interactive visualizations that facilitate the tasks involved in analyzing TBSS results.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Piccolotto, Nikolaus; Bogl, Markus; Miksch, Silvia] TU Wien, Inst Visual Comp & Human Ctr Technol, Favoritenstr 9-11, A-1040 Vienna, Austria.
   [Gschwandtner, Theresia] Erste Grp Bank AG, Belvedere 1, A-1100 Vienna, Austria.
   [Muehlmann, Christoph; Filzmoser, Peter] TU Wien, Inst Stat & Math Methods Econ, Wiedner Hauptstr 8-10, A-1040 Vienna, Austria.
   [Nordhausen, Klaus] Univ Jyvaskyla, Dept Math & Stat, FI-40014 Jyvaskyla, Finland.
C3 Technische Universitat Wien; Technische Universitat Wien; University of
   Jyvaskyla
RP Piccolotto, N (corresponding author), TU Wien, Inst Visual Comp & Human Ctr Technol, Favoritenstr 9-11, A-1040 Vienna, Austria.
EM nikolaus.piccolotto@tuwien.ac.at
RI Nordhausen, Klaus/A-8644-2008; Filzmoser, Peter/A-7737-2015; Bögl,
   Markus/ISS-2644-2023
OI Nordhausen, Klaus/0000-0002-3758-8501; Bögl, Markus/0000-0002-8337-4774;
   Miksch, Silvia/0000-0003-4427-5703; Piccolotto,
   Nikolaus/0000-0001-6876-6502; Muehlmann, Christoph/0000-0001-7330-8434
FU Austrian Science Fund (FWF);  [P31881-N32]
FX Acknowledgments We would like to thank our experts for spending so much
   of their valuable time on discussions and evaluations with us. This work
   was supported by the Austrian Science Fund (FWF) under grant P31881-N32.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Amezquita-Sanchez JP, 2016, ARCH COMPUT METHOD E, V23, P1, DOI 10.1007/s11831-014-9135-7
   Anand A, 2012, IEEE CONF VIS ANAL, P43, DOI 10.1109/VAST.2012.6400490
   [Anonymous], 2005, ILLUMINATING PATH R
   [Anonymous], 2001, P 18 INT C MACH LEAR
   Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307
   Bögl M, 2013, IEEE T VIS COMPUT GR, V19, P2237, DOI 10.1109/TVCG.2013.222
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Buchmüller J, 2019, IEEE T VIS COMPUT GR, V25, P76, DOI 10.1109/TVCG.2018.2865049
   Ceneda D, 2020, COMPUT GRAPH FORUM, V39, P269, DOI 10.1111/cgf.14017
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Comon P, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P1
   De Lathauwer L, 2000, IEEE T BIO-MED ENG, V47, P567, DOI 10.1109/10.841326
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Elmqvist N, 2015, INFORM VISUAL, V14, P250, DOI 10.1177/1473871613513228
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Hao LH, 2015, IEEE SYM VIS CYB SEC
   Hao LH, 2016, IEEE T VIS COMPUT GR, V22, P787, DOI 10.1109/TVCG.2015.2468093
   Ilmonen P, 2010, LECT NOTES COMPUT SC, V6365, P229, DOI 10.1007/978-3-642-15995-4_29
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kincaid R, 2010, IEEE T VIS COMPUT GR, V16, P900, DOI 10.1109/TVCG.2010.193
   Köthur P, 2015, COMPUT GRAPH FORUM, V34, P411, DOI 10.1111/cgf.12653
   Liu XL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173561
   Liu XT, 2018, COMPUT GRAPH FORUM, V37, P7, DOI 10.1111/cgf.12526
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Matilainen M, 2017, AUST J STAT, V46, P57, DOI 10.17713/ajs.v46i3-4.671
   Matkovic K, 2018, WINT SIMUL C PROC, P321, DOI 10.1109/WSC.2018.8632312
   Matkovic K, 2009, IEEE T VIS COMPUT GR, V15, P1351, DOI 10.1109/TVCG.2009.155
   McLachlan P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1483
   Miettinen J, 2020, J TIME SER ANAL, V41, P293, DOI 10.1111/jtsa.12505
   Miettinen J, 2016, J TIME SER ANAL, V37, P337, DOI 10.1111/jtsa.12159
   Miettinen J, 2014, J MULTIVARIATE ANAL, V123, P214, DOI 10.1016/j.jmva.2013.09.009
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Nordhausen K, 2022, J MULTIVARIATE ANAL, V188, DOI 10.1016/j.jmva.2021.104844
   Nordhausen K, 2021, J STAT SOFTW, V98, P1, DOI 10.18637/jss.v098.i15
   Nordhausen K, 2018, WIRES COMPUT STAT, V10, DOI 10.1002/wics.1440
   Obermaier H, 2016, IEEE T VIS COMPUT GR, V22, P2331, DOI 10.1109/TVCG.2015.2507592
   Oja E, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P111, DOI 10.1109/ASSPCC.2000.882456
   Pan Y, 2022, WIRES COMPUT STAT, V14, DOI 10.1002/wics.1550
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Thanh PV, 2017, PROC INT CONF ADV, P260, DOI 10.1109/ATC.2017.8167629
   Piringer H, 2012, COMPUT GRAPH FORUM, V31, P1195, DOI 10.1111/j.1467-8659.2012.03112.x
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Rosen P., 2020, P EUROVIS SHORT PAPE, P85, DOI [10.2312/evs.20201053, DOI 10.2312/EVS.20201053]
   Schubert E, 2019, LECT NOTES COMPUT SC, V11807, P171, DOI 10.1007/978-3-030-32047-8_16
   Schwab M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300786
   Sedlmair M, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P152, DOI 10.1145/2993901.2993913
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shurkhovetskyy G, 2018, COMPUT GRAPH FORUM, V37, P125, DOI 10.1111/cgf.13237
   Stitz H, 2016, IEEE T VIS COMPUT GR, V22, P2594, DOI 10.1109/TVCG.2015.2513389
   Sun D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376866
   Tang AC, 2005, NEUROIMAGE, V28, P507, DOI 10.1016/j.neuroimage.2005.06.062
   Taskinen S, 2016, STAT PROBABIL LETT, V116, P21, DOI 10.1016/j.spl.2016.04.007
   Tominski C, 2017, COMPUT GRAPH FORUM, V36, P173, DOI 10.1111/cgf.12871
   Venables WN, 2002, MODERN APPL STAT S, DOI 10.1007/978-0-387-21706-2
   Vlachos M, 2005, SIAM PROC S, P449
   von Landesberger T, 2017, IEEE T VIS COMPUT GR, V23, P2028, DOI 10.1109/TVCG.2016.2603178
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xu K, 2019, IEEE T VIS COMPUT GR, V25, P109, DOI 10.1109/TVCG.2018.2864825
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
   Zhao KY, 2014, COMPUT GRAPH FORUM, V33, P331, DOI 10.1111/cgf.12389
NR 79
TC 3
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 51
EP 66
DI 10.1016/j.visinf.2022.10.002
EA NOV 2022
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100005
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Su, CY
   Yang, C
   Chen, YH
   Wang, FP
   Wang, F
   Wu, YD
   Zhang, XR
AF Su, Chengyu
   Yang, Chao
   Chen, Yonghui
   Wang, Fupan
   Wang, Fang
   Wu, Yadong
   Zhang, Xiaorong
TI Natural multimodal interaction in immersive flow visualization
SO VISUAL INFORMATICS
LA English
DT Article
DE Flow visualization; Virtual reality; Multimodal interaction;
   Human-computer interaction
ID INTERFACE
AB In the immersive flow visualization based on virtual reality, how to meet the needs of complex professional flow visualization analysis by natural human-computer interaction is a pressing problem. In order to achieve the natural and efficient human-computer interaction, we analyze the interaction requirements of flow visualization and study the characteristics of four human-computer interaction channels: hand, head, eye and voice. We give out some multimodal interaction design suggestions and then propose three multimodal interaction methods: head & hand, head & hand & eye and head & hand & eye & voice. The freedom of gestures, the stability of the head, the convenience of eyes and the rapid retrieval of voices are used to improve the accuracy and efficiency of interaction. The interaction load is balanced by multimodal interaction to reduce fatigue. The evaluation shows that our multimodal interaction has higher accuracy, faster time efficiency and much lower fatigue than the traditional joystick interaction. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Su, Chengyu; Chen, Yonghui; Wang, Fupan; Zhang, Xiaorong] Southwest Univ Sci & Technol, Sch Comp Sci & Tecnonol, Mianyang, Sichuan, Peoples R China.
   [Su, Chengyu; Yang, Chao; Wang, Fang] China Aerodynam Res & Dev Ctr, Computat Aerodynam Inst, Mianyang, Sichuan, Peoples R China.
   [Wu, Yadong] SiChuan Univ Sci & Engn, Chengdu, Peoples R China.
C3 Southwest University of Science & Technology - China; Sichuan University
   of Science & Engineering
RP Zhang, XR (corresponding author), Southwest Univ Sci & Technol, Sch Comp Sci & Tecnonol, Mianyang, Sichuan, Peoples R China.
EM zhangxiaorong@swust.edu.cn
FU National Natural Science Foundation of China [61872304, 61802320]; State
   Key Laboratory of Aerodynamics [SKLA20200203]; National Numerical
   Windtunnel Project [NNW2019ZT6-A17]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61872304, No. 61802320), the State Key
   Laboratory of Aerodynamics (SKLA20200203) and the National Numerical
   Windtunnel Project (NNW2019ZT6-A17).
CR Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   BIZZI E, 1974, SCI AM, V231, P100
   Blattgerste J, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206349
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Boring S., 2009, P 21 ANN C AUSTR COM, P161
   Bryson S., 1992, Proceedings. Supercomputing '92. (Cat. No.92CH3216-9), P275, DOI 10.1109/SUPERC.1992.236675
   Bryson S., 1991, P 2 C VIS
   Chen W., 2013, ELECTRON, P29
   Cohen PR, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P31, DOI 10.1145/266180.266328
   Drewes H., 2010, THESIS IMU
   Harris R.A., 2005, VOICE INTERACTION DE, P3
   Kok AJF, 2007, KNOWL INF SYST, V13, P197, DOI 10.1007/s10115-007-0066-6
   Koons D., 1998, INTELLIGENT MULTIMED, P53
   Laviola J. J.  Jr., 2000, Proceedings of the IASTED International Conference. Computer Graphics and Imaging, P1
   [雷金树 Lei Jinshu], 2019, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V31, P208
   Lucente M., 1998, Intelligent Environments. Papers from the 1998 AAAI Symposium, P87
   Oviatt S, 2000, HUM-COMPUT INTERACT, V15, P263, DOI 10.1207/S15327051HCI1504_1
   Paeres D., 2021, AIAA SCITECH 2021 FO
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Wang P, 2019, INT J ADV MANUF TECH, V105, P3031, DOI 10.1007/s00170-019-04434-2
   Wang S, 2020, IEEE PAC VIS SYMP, P166, DOI 10.1109/PacificVis48177.2020.1001
   Wang W., 2013, NATL DEF IND PRESS, P16
   Wernert E.A., 2012, IEEE VR 2012
   Xu S, 2021, J CHIN CHEM SOC-TAIP, V68, P1020, DOI 10.1002/jccs.202000447
   Yang L., 2019, Virtual Real. Intell. Hardw, V1, P84, DOI [10.3724/SP.J.2096-5796.2018.0006, DOI 10.3724/SP.J.2096-5796.2018.0006, 10.3724/sp.j.2096-5796.2018.0006]
   [张凤军 Zhang Fengjun], 2016, [中国科学. 信息科学, Scientia Sinica Informationis], V46, P1711
NR 27
TC 5
Z9 6
U1 3
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 56
EP 66
DI 10.1016/j.visinf.2021.12.005
EA DEC 2021
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500008
OA gold
DA 2024-07-18
ER

PT J
AU Pan, RS
   Wang, YH
   Sun, JS
   Liu, HB
   Zhao, Y
   Xia, JZ
   Chen, W
AF Pan, Rusheng
   Wang, Yunhai
   Sun, Jiashun
   Liu, Hongbo
   Zhao, Ying
   Xia, Jiazhi
   Chen, Wei
TI Simplifying social networks via triangle-based cohesive subgraphs
SO VISUAL INFORMATICS
LA English
DT Article
DE Graph simplification; Cohesive subgraphs; Graph triangle; Graph layout;
   Node-link diagrams
ID COMMUNITY SEARCH; GRAPH; VISUALIZATION
AB One main challenge for simplifying node-link diagrams of large-scale social networks lies in that simplified graphs generally contain dense subgroups or cohesive subgraphs. Graph triangles quantify the solid and stable relationships that maintain cohesive subgraphs. Understanding the mechanism of triangles within cohesive subgraphs contributes to illuminating patterns of connections within social networks. However, prior works can hardly handle and visualize triangles in cohesive subgraphs. In this paper, we propose a triangle-based graph simplification approach that can filter and visualize cohesive subgraphs by leveraging a triangle-connectivity called k-truss and a force-directed algorithm. We design and implement TriGraph, a web-based visual interface that provides detailed information for exploring and analyzing social networks. Quantitative comparisons with existing methods, two case studies on real-world datasets, and feedback from domain experts demonstrate the effectiveness of TriGraph. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Pan, Rusheng; Sun, Jiashun; Liu, Hongbo; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Yunhai] Shandong Univ, Sch Comp Sci & Technol, Qingdao, Peoples R China.
   [Zhao, Ying; Xia, Jiazhi] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
C3 Zhejiang University; Shandong University; Central South University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
EM chenvis@zju.edu.cn
RI Wang, YuHan/KGY-2933-2024; Sun, Yue/KHU-8159-2024; wang,
   rong/KFQ-7187-2024; Wang, Yuhan/KGL-5855-2024; liu, xinyi/KFB-4466-2024;
   Li, Hongbo/KHV-4191-2024; chen, xiao/KFQ-6812-2024; wang,
   yue/KDO-9209-2024; Zhou, Xinyi/KGM-6689-2024; Liu, Chang/KGL-6678-2024;
   wang, wang/KGW-2828-2024
OI Li, Hongbo/0000-0003-4495-0756; Pan, Rusheng/0000-0001-9284-0477
FU National Natural Sci-ence Foundation of China [62132017]; Fundamental
   Research Funds for the Central Universities, China [226-2022-00235]
FX The authors would like to thank Zihan Yan, for her contribu-tion to the
   work. This paper is supported by National Natural Sci-ence Foundation of
   China (62132017) and Fundamental Research Funds for the Central
   Universities, China (226-2022-00235) .
CR Akbas E, 2017, PROC VLDB ENDOW, V10, P1298, DOI 10.14778/3137628.3137640
   ALBA RD, 1973, J MATH SOCIOL, V3, P113, DOI 10.1080/0022250X.1973.9989826
   Allen P., 2022, Connections, V40, P1
   Angori L, 2019, LECT NOTES COMPUT SC, V11904, P276, DOI 10.1007/978-3-030-35802-0_22
   [Anonymous], 1949, Psychometrika, DOI DOI 10.1007/BF02289146
   [Anonymous], 1950, Psychometrika
   [Anonymous], 2008, P 2008 ACM SIGMOD IN, DOI DOI 10.1145/1376616.1376661
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   BAR-Joseph Z., 2001, BIOINFORMATICS S1, V17 Suppl 1, pS22, DOI [10.1093/bioinformatics/17.suppl1.S22, DOI 10.1093/BIOINFORMATICS/17.SUPPL_1.S22, 10.1093/bioinformatics/17.suppl_1.S224, DOI 10.1093/BIOINFORMATICS/17.SUPPL_1.S224]
   Boitmanis K, 2008, LECT NOTES COMPUT SC, V4875, P365
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Cohen J., 2008, NATL SECURITY AGENCY, P16
   Dianati N, 2016, PHYS REV E, V93, DOI 10.1103/PhysRevE.93.012304
   Dinkla K, 2012, IEEE T VIS COMPUT GR, V18, P2457, DOI 10.1109/TVCG.2012.208
   Faust K, 2010, SOC NETWORKS, V32, P221, DOI 10.1016/j.socnet.2010.03.004
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   Gupta R, 2016, SIAM J COMPUT, V45, P197, DOI 10.1137/140955331
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hu J., 2020, P COMPL NETW THEIR A, P237
   Huang H, 2015, IEEE T KNOWL DATA EN, V27, P3374, DOI 10.1109/TKDE.2015.2453956
   Huang X, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P77, DOI 10.1145/2882903.2882913
   Huang X, 2015, PROC VLDB ENDOW, V9, P276
   Huang X, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1311, DOI 10.1145/2588555.2610495
   Interdonato R, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100246
   Juszczyszyn K, 2011, 2011 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2011), P581, DOI 10.1109/ASONAM.2011.50
   Krackhardt D, 1999, RES SOC ORG, V16, P183
   Krackhardt D., 1998, POWER INFLUENCE ORG, V21, P21
   Lo TW, 2010, BRIT J CRIMINOL, V50, P851, DOI 10.1093/bjc/azq022
   Monir Md Moniruzzaman, 2020, Computational Data and Social Networks. 9th International Conference, CSoNet 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12575), P179, DOI 10.1007/978-3-030-66046-8_15
   Nick Bobo, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P525
   Ning Ruan, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P1200, DOI 10.1109/ICDM.2011.57
   Nocaj A., 2015, Journal of Graph Algorithms and Applications: JGAA, V19, P595, DOI [DOI 10.7155/JGAA.00370, 10.7155/jgaa.00370, https://doi.org/10.7155/jgaa.00370]
   Nocaj A, 2016, IEEE T VIS COMPUT GR, V22, P1662, DOI 10.1109/TVCG.2016.2534559
   Nocaj A, 2014, LECT NOTES COMPUT SC, V8871, P101, DOI 10.1007/978-3-662-45803-7_9
   Ortmann Mark, 2017, Appl Netw Sci, V2, P13, DOI 10.1007/s41109-017-0027-2
   Pham TM, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2121103119
   Prell Christina, 2008, Connections, V28, P4
   Rezvani M, 2022, SOFT COMPUT, V26, P55, DOI 10.1007/s00500-021-06468-9
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   SEIDMAN SB, 1978, J MATH SOCIOL, V6, P139, DOI 10.1080/0022250X.1978.9989883
   SEIDMAN SB, 1983, SOC NETWORKS, V5, P269, DOI 10.1016/0378-8733(83)90028-X
   Sun J, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.036116
   Traud AL, 2012, PHYSICA A, V391, P4165, DOI 10.1016/j.physa.2011.12.021
   Wang J, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P454, DOI 10.1109/ICMLC.2008.4620448
   Wang N, 2010, PROC VLDB ENDOW, V4, P58, DOI 10.14778/1921071.1921073
   Yoghourdjian V, 2018, IEEE T VIS COMPUT GR, V24, P3081, DOI 10.1109/TVCG.2018.2790961
   Zhao F, 2012, PROC VLDB ENDOW, V6, P85, DOI 10.14778/2535568.2448942
   Zhou H., 2021, P 2021 SIAM INT C DA, P280
NR 52
TC 1
Z9 1
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 84
EP 94
DI 10.1016/j.visinf.2023.07.003
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DX3Z2
UT WOS:001135356700001
OA gold
DA 2024-07-18
ER

PT J
AU Wu, HJ
   Zhang, HX
   Cheng, J
   Guo, JW
   Chen, W
AF Wu, Hongjia
   Zhang, Hongxin
   Cheng, Jiang
   Guo, Jianwei
   Chen, Wei
TI Perspectives on point cloud-based 3D scene modeling and XR presentation
   within the cloud-edge-client architecture
SO VISUAL INFORMATICS
LA English
DT Article
DE The cloud-edge-client integrated architecture; 3D scene perception and
   modeling; XR rendering; Cloud-edge-client integrated visualization
ID VISUAL ANALYSIS; REPRESENTATION; COMMUNICATION
AB With the support of edge computing, the synergy and collaboration among central cloud, edge cloud, and terminal devices form an integrated computing ecosystem known as the cloud-edge-client architecture. This integration unlocks the value of data and computational power, presenting significant opportunities for large-scale 3D scene modeling and XR presentation. In this paper, we explore the perspectives and highlight new challenges in 3D scene modeling and XR presentation based on point cloud within the cloud-edge-client integrated architecture. We also propose a novel cloud-edge-client integrated technology framework and a demonstration of municipal governance application to address these challenges. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Wu, Hongjia; Zhang, Hongxin; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
   [Cheng, Jiang] China Mobile Commun Grp Jiangxi Co Ltd, Nanchang, Peoples R China.
   [Guo, Jianwei] Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing, Peoples R China.
C3 Zhejiang University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Zhang, HX (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
EM hongjiawu@zju.edu.cn; zhx@cad.zju.edu.cn; chengjiang@jx.chinamobile.com;
   jianwei.guo@nlpr.ia.ac.cn; chenvis@zju.edu.cn
RI Chen, Wei/AAR-9817-2020; Zhang, Hongxin/T-3714-2019
FU National Natural Science Foundation of China [U22B2034]; Fundamental
   Research Funds for the Central Universities [226-2022-00064]
FX This paper was supported by the National Natural Science Foundation of
   China (U22B2034) and the Fundamental Research Funds for the Central
   Universities (226-2022-00064) .
CR Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Baciu George, 2017, International Journal of Software Science and Computational Intelligence, V9, P20, DOI 10.4018/IJSSCI.2017010102
   Chen K., 2015, COMPUT VIS MEDIA, V1, P267, DOI DOI 10.1007/S41095-015-0029-X
   Chen K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661239
   Chen W, 2021, FRONT INFORM TECH EL, V22, P1559, DOI 10.1631/FITEE.2100553
   Galati A, 2021, IEEE T VIS COMPUT GR, V27, P2714, DOI 10.1109/TVCG.2021.3067693
   Guo Jianwei, 2024, IEEE Trans Vis Comput Graph, V30, P3283, DOI 10.1109/TVCG.2022.3230369
   Guo JW, 2020, IEEE T VIS COMPUT GR, V26, P1372, DOI 10.1109/TVCG.2018.2869784
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Han DM, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0013-1
   Huang YJ, 2017, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2017.8031577
   [景庄伟 Jing Zhuangwei], 2021, [计算机科学与探索, Journal of Frontiers of Computer Science & Technology], V15, P1
   Kayongo P, 2022, IEEE INT WORK VIS SO, P5, DOI 10.1109/VISSOFT55257.2022.00010
   LaMothe R., 2013, Edge Computing
   Li K, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2039
   Liubogoshchev M, 2021, IEEE ACCESS, V9, P35287, DOI 10.1109/ACCESS.2021.3062555
   Mania K, 2006, IEEE T VIS COMPUT GR, V12, P396, DOI 10.1109/TVCG.2006.55
   Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201
   Muelder C, 2016, IEEE T VIS COMPUT GR, V22, P1694, DOI 10.1109/TVCG.2016.2534558
   Musialski P, 2013, COMPUT GRAPH FORUM, V32, P146, DOI 10.1111/cgf.12077
   Nan LL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366156
   Pan JC, 2020, FRONT INFORM TECH EL, V21, P491, DOI 10.1631/FITEE.1900310
   Qiao XQ, 2019, P IEEE, V107, P651, DOI 10.1109/JPROC.2019.2895105
   Ren JK, 2019, IEEE NETWORK, V33, P162, DOI 10.1109/MNET.2018.1800132
   Shi S, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348825
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Wang XM, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-023-2691-y
   Wen L., 2014, P 13 ACM SIGGRAPH IN, P95
   Wu Z., 2022, Front. Inf. Technol. Electronic Eng., P1
   Xiao Y, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0088-8
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Yao JL, 2009, LECT NOTES COMPUT SC, V5709, P264
   Yu S, 2022, IEEE T MOBILE COMPUT, V21, P421, DOI 10.1109/TMC.2020.3007654
   Zaki O, 1999, INT J HIGH PERFORM C, V13, P277, DOI 10.1177/109434209901300310
   Zhang H., 2020, Virtual Real. Intell. Hardw, V2, P368, DOI [10.1016/j.vrih.2020.07.001, DOI 10.1016/J.VRIH.2020.07.001]
   Zhang HX, 2013, INT C COMP AID DES C, P345, DOI 10.1109/CADGraphics.2013.52
   Zhang JY, 2020, LASER OPTOELECTRON P, V57, DOI 10.3788/LOP57.040002
   Zhang TY, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-019-9393-5
NR 40
TC 5
Z9 5
U1 6
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2023
VL 7
IS 3
BP 59
EP 64
DI 10.1016/j.visinf.2023.06.007
EA SEP 2023
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA W0OJ8
UT WOS:001088708700001
OA gold
DA 2024-07-18
ER

PT J
AU Gleicher, M
   Yu, XY
   Chen, YH
AF Gleicher, Michael
   Yu, Xinyi
   Chen, Yuheng
TI Trinary tools for continuously valued binary classifiers
SO VISUAL INFORMATICS
LA English
DT Article
ID CLASSIFICATION; PERFORMANCE
AB Classification methods for binary (yes/no) tasks often produce a continuously valued score. Machine learning practitioners must perform model selection, calibration, discretization, performance assessment, tuning, and fairness assessment. Such tasks involve examining classifier results, typically using summary statistics and manual examination of details. In this paper, we provide an interactive visualization approach to support such continuously-valued classifier examination tasks. Our approach addresses the three phases of these tasks: calibration, operating point selection, and examination. We enhance standard views and introduce task-specific views so that they can be integrated into a multiview coordination (MVC) system. We build on an existing comparison-based approach, extending it to continuous classifiers by treating the continuous values as trinary (positive, unsure, negative) even if the classifier will not ultimately use the 3-way classification. We provide use cases that demonstrate how our approach enables machine learning practitioners to accomplish key tasks. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Gleicher, Michael; Yu, Xinyi; Chen, Yuheng] Univ Wisconsin Madison, Dept Comp Sci, Madison, WI 53706 USA.
C3 University of Wisconsin System; University of Wisconsin Madison
RP Gleicher, M (corresponding author), Univ Wisconsin Madison, Dept Comp Sci, Madison, WI 53706 USA.
EM gleicher@cs.wisc.edu
RI wang, yue/ISA-4119-2023; liu, junyang/IXD-1201-2023; fang,
   yu/KCK-2014-2024; zhang, yu/HNS-5948-2023; LI, XIAO/IQV-9318-2023;
   zhang, yuyang/IVV-5089-2023; XU, nan/KDP-0628-2024; Zhang,
   Can/JUU-9511-2023; Li, Xiaoli/JVZ-4089-2024; Zhang,
   Wenxiao/KCK-3295-2024; li, yang/IQV-3559-2023; zhang, yue/JAC-3705-2023;
   wu, jun/ISB-8607-2023; ZHAO, S/IWV-4219-2023; liu,
   junyang/IXD-1252-2023; Li, Li/IAQ-0885-2023; Liu, Han/HMD-9231-2023; li,
   bo/JJC-2664-2023; Lu, Xiaomei/IUQ-2139-2023; LIU, HAO/JBI-9623-2023; LI,
   XIAO/JCE-6169-2023; cheng, shu/IZE-4788-2023; liang, YU/IYT-4334-2023
OI Liu, Han/0000-0002-5269-8477; liang, YU/0009-0007-3922-3454
FU National Science Foun-dation of the USA [1841349, 2007436]; Direct For
   Computer & Info Scie & Enginr; Div Of Information & Intelligent Systems
   [1841349] Funding Source: National Science Foundation; Direct For
   Computer & Info Scie & Enginr; Div Of Information & Intelligent Systems
   [2007436] Funding Source: National Science Foundation
FX Acknowledgments This research was supported in part by National Science
   Foun-dation of the USA awards 1841349 and 2007436.
CR Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   [Anonymous], 2018, ADV NEUR IN
   [Anonymous], 2015, TENSORFLOW LARGE SCA
   [Anonymous], 2013, Proceedings of the Twenty-Third international joint conference on Artificial Intelligence
   Brier G. W., 1950, MON WEATHER REV, V78, P1, DOI 10.1175/1520-0493(1950)078andlt;0001:VOFEITandgt;2.0.CO;2
   Lipton ZC, 2017, Arxiv, DOI [arXiv:1606.03490, 10.48550/arXiv.1606.03490]
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/vast47406.2019.8986948, 10.1109/VAST47406.2019.8986948]
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406
   Condessa F, 2017, PATTERN RECOGN, V63, P437, DOI 10.1016/j.patcog.2016.10.011
   Cortes C, 2016, LECT NOTES ARTIF INT, V9925, P67, DOI 10.1007/978-3-319-46379-7_5
   Das S, 2020, COMPUT GRAPH FORUM, V39, P153, DOI 10.1111/cgf.13970
   DEGROOT MH, 1983, J ROY STAT SOC D-STA, V32, P12
   Dua D., 2017, UCI MACHINE LEARNING
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2016, BIG DATA-US, V4, P75, DOI 10.1089/big.2016.0007
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2042, DOI 10.1109/TVCG.2013.157
   Gneiting T, 2007, J R STAT SOC B, V69, P243, DOI 10.1111/j.1467-9868.2007.00587.x
   Gomez O, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P531, DOI 10.1145/3377325.3377536
   Guo CA, 2017, PR MACH LEARN RES, V70
   Hanczar B, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106984
   Heimerl F, 2020, Arxiv, DOI arXiv:1810.02445
   Heyen F, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399814
   Hope J, 2010, SHAKESPEARE QUART, V61, P357
   Kapoor A, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1343
   Kery M. B., 2020, P 33 ANN ACM S US IN, P140, DOI [10.1145/3379337.34158429, DOI 10.1145/3379337.34158429, 10.1145/3379337.3415842, DOI 10.1145/3379337.3415842]
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kuleshov V, 2015, ADV NEUR IN, V28
   Landgrebe TCW, 2006, PATTERN RECOGN LETT, V27, P908, DOI 10.1016/j.patrec.2005.10.015
   Leathart T, 2020, Arxiv, DOI arXiv:2002.02644
   Ling C. X., 2002, Advances in Knowledge Discovery and Data Mining. 6th Pacific-Asia Conference, PAKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2336), P123
   Ling CX, 2003, LECT NOTES ARTIF INT, V2671, P329
   Nadeem M. S. A., 2009, MACHINE LEARNING SYS, P65
   Niculescu-Mizil A., 2005, P 22 INT C MACHINE L, P625, DOI [10.1145/1102351.1102430, DOI 10.1145/1102351.1102430]
   Parker C., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P517, DOI 10.1109/ICDM.2011.21
   Pedregosa F, 2011, J. Mach. Learn. Res., V12, P2825
   Platt JC, 2000, ADV NEUR IN, P61
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Provost F., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P445
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Schwarz J, 2019, BIOINFORMATICS, V35, P2458, DOI 10.1093/bioinformatics/bty984
   Szafir DA, 2016, COMPUT GRAPH FORUM, V35, P421, DOI 10.1111/cgf.12918
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1417, DOI 10.1109/TVCG.2020.3030449
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
NR 51
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 74
EP 86
DI 10.1016/j.visinf.2022.04.002
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 3D7JN
UT WOS:000829473700004
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Stoiber, C
   Ceneda, D
   Wagner, M
   Schetinger, V
   Gschwandtner, T
   Streit, M
   Miksch, S
   Aigner, W
AF Stoiber, Christina
   Ceneda, Davide
   Wagner, Markus
   Schetinger, Victor
   Gschwandtner, Theresia
   Streit, Marc
   Miksch, Silvia
   Aigner, Wolfgang
TI Perspectives of visualization onboarding and guidance in VA
SO VISUAL INFORMATICS
LA English
DT Article
DE User assistance; Visual Analytics; Conceptual model; Visualization
   onboarding; Guidance
ID VISUAL ANALYTICS; MODEL; NAVIGATION; DESIGN
AB A typical problem in Visual Analytics (VA) is that users are highly trained experts in their application domains, but have mostly no experience in using VA systems. Thus, users often have difficulties interpreting and working with visual representations. To overcome these problems, user assistance can be incorporated into VA systems to guide experts through the analysis while closing their knowledge gaps. Different types of user assistance can be applied to extend the power of VA, enhance the user's experience, and broaden the audience for VA. Although different approaches to visualization onboarding and guidance in VA already exist, there is a lack of research on how to design and integrate them in effective and efficient ways. Therefore, we aim at putting together the pieces of the mosaic to form a coherent whole. Based on the Knowledge-Assisted Visual Analytics model, we contribute a conceptual model of user assistance for VA by integrating the process of visualization onboarding and guidance as the two main approaches in this direction. As a result, we clarify and discuss the commonalities and differences between visualization onboarding and guidance, and discuss how they benefit from the integration of knowledge extraction and exploration. Finally, we discuss our descriptive model by applying it to VA tools integrating visualization onboarding and guidance, and showing how they should be utilized in different phases of the analysis in order to be effective and accepted by the user. (C) 2022 The Authors. Published by Elsevier B.V.
C1 [Stoiber, Christina; Wagner, Markus; Aigner, Wolfgang] St Polten Univ Appl Sci, Vienna, Austria.
   [Ceneda, Davide; Schetinger, Victor; Miksch, Silvia] TU Wien, Vienna, Austria.
   [Gschwandtner, Theresia] Erste Grp Bank AG, Vienna, Austria.
   [Streit, Marc] Johannes Kepler Univ Linz, Linz, Austria.
C3 St. Polten University of Applied Sciences; Technische Universitat Wien;
   Johannes Kepler University Linz
RP Stoiber, C (corresponding author), St Polten Univ Appl Sci, Vienna, Austria.
EM christina.stoiber@fhstp.ac.at; davide.ceneda@tuwien.ac.at;
   markus.wagner@fhstp.ac.at; victor.schetinger@tuwien.ac.at;
   Theresia.Gschwandtner@erstegroup.com; marc.streit@jku.at;
   silvia.miksch@tuwien.ac.at; wolfgang.aigner@fhstp.ac.at
OI Miksch, Silvia/0000-0003-4427-5703; Stoiber,
   Christina/0000-0002-1764-1467; Ceneda, Davide/0000-0003-1198-567X;
   Schetinger, Victor/0000-0002-8116-794X; Streit,
   Marc/0000-0001-9186-2092; Wagner, Markus/0000-0002-6619-6494
FU Austrian Science Fund (FWF) as part of the projects VisOnFire and KnoVA
   [P27975-NBL, P31419-N31]; Vienna Science and Technology Fund (WWTF)
   [ICT19-047]; Austrian Ministry for Transport, Innovation and Technology
   (BMVIT) under the ICT of the Future program via the SEVA project
   [874018]; FFG within the Austrian COMET Program Competence Centers for
   Excellent Technologies under the Austrian Federal Ministry for
   Transport, Innovation and Technology [854184]; Austrian Federal Ministry
   for Digital and Economic Affairs; Province of Upper Austria; Province of
   Styria
FX We would like to thank Frederico Limberger and Nelogica for their
   support in evaluating Profit, and all participants who attended our
   Application Spotlight Workshop at the IEEE Vis 2019 discussing and
   providing very helpful feedback to our approach. This work was supported
   by the Austrian Science Fund (FWF) as part of the projects VisOnFire and
   KnoVA (#P27975-NBL, #P31419-N31), the Vienna Science and Technology Fund
   (WWTF) via the grant ICT19-047 (GuidedVA), the Austrian Ministry for
   Transport, Innovation and Technology (BMVIT) under the ICT of the Future
   program via the SEVA project (#874018), as well as by the FFG, Contract
   No. 854184: ``Pro2Future'' is funded within the Austrian COMET Program
   Competence Centers for Excellent Technologies under the auspices of the
   Austrian Federal Ministry for Transport, Innovation and Technology, the
   Austrian Federal Ministry for Digital and Economic Affairs, and of the
   Provinces of Upper Austria and Styria. COMET is managed by the Austrian
   Research Promotion Agency FFG.
CR Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   [Anonymous], 2020, IBM COGNOS ANAL
   [Anonymous], 2020, ADVIZOR SOLUTION INT
   [Anonymous], 2019, IBM COGNOS ANAL
   [Anonymous], 2020, KESHIF DATA MADE EXP
   [Anonymous], 2011, PROC EUROVIS WORKSHO, DOI [10.2312/PE/EuroVAST/EuroVA11/009-012, DOI 10.2312/PE/EUROVAST/EUROVA11/009-012]
   [Anonymous], 2021, NELOGICA TECNOLOGIA
   [Anonymous], SAS Jmp
   [Anonymous], 2019, QLIKTECH QLIKVIEW
   [Anonymous], 1996, Technical Communication
   [Anonymous], 2019, MICROSOFT POWER BI
   [Anonymous], 2016, Evaluating onboarding experiences
   [Anonymous], 2019, TIBCO SPOTFIRE
   [Anonymous], 2019, SAP LUMIRA
   [Anonymous], 2015, Engaging new users: Guided Interaction
   Balboni K., 2016, WE CATEGORIZED 327 U
   Beaudouin-Lafon M., 2004, Proceedings of the working conference on Advanced visual interfaces, P15, DOI DOI 10.1145/989863.989865
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Card S K., 1999, READINGS INFORM VISU
   Ceneda D., 2018, P IEEE S VISUALIZATI
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen CM, 2005, IEEE COMPUT GRAPH, V25, P12, DOI 10.1109/MCG.2005.91
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Dix A, 2004, HUM-COMPUT INTERACT
   Engels R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P170
   Federico P., 2015, EUROVIS WORKSHOP VIS, DOI [10.2312/eurova.20151108, DOI 10.2312/EUROVA.20151108]
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Gotz D, 2009, P 14 INT C INT US IN, P315, DOI [DOI 10.1145/1502650.1502695, 10.1145/1502650.15026951, DOI 10.1145/1502650.15026951]
   Harman G, 2010, CAMB J ECON, V34, P17, DOI 10.1093/cje/bep021
   Hart Geoff, 2002, The five w's of online help systems
   Holtz Y., 2021, DATA VIZ FIND GRAPHI
   Hulick S., 2020, USER ONBOARDING FREQ
   Hulick S., 2019, ELEMENTS USER ONBOAR
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kang H., 2003, P 2003 ANN NAT C DIG, P1
   Keim E.D., 2010, Mastering the information age: Solving problems with visual analytics, eurographics association
   Klein HJ, 2015, INT J SELECT ASSESS, V23, P263, DOI 10.1111/ijsa.12113
   Kumar A., 2017, WHY USER ONBOARDING
   Kwon BC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P993, DOI 10.1145/2858036.2858101
   Lamin A, 2012, ORGAN SCI, V23, P47, DOI 10.1287/orsc.1100.0631
   Luboschik M., 2012, 2012 IEEE Symposium on Biological Data Visualization (BioVis 2012), P33, DOI 10.1109/BioVis.2012.6378590
   May T, 2012, COMPUT GRAPH FORUM, V31, P985, DOI 10.1111/j.1467-8659.2012.03091.x
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Ola O, 2017, INFORMATICS-BASEL, V4, DOI 10.3390/informatics4040033
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Ribecca S., 2020, DATA VISUALISATION C
   Rind A., 2019, ARXIV190807752 CS
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   SCHULZ HJ, 2013, P IEEE S INF VIS
   SILVER MS, 1991, MIS QUART, V15, P105, DOI 10.2307/249441
   Smith S. L., 1986, GUIDELINES DESIGNING
   Stoiber C., 2019, IEEE WORKSHOP VISUAL
   Streit M, 2012, IEEE T VIS COMPUT GR, V18, P998, DOI 10.1109/TVCG.2011.108
   Tableau Public Software, 2019, TABLEAU SOFTWARE
   Tanahashi Y, 2016, COMPUT GRAPH FORUM, V35, P117, DOI 10.1111/cgf.13009
   Thomas J. J., 2005, Illuminating the Path: The Research and Development Agenda for Visual Analytics
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   van Wijk JJ, 2006, IEEE T VIS COMPUT GR, V12, P421, DOI 10.1109/TVCG.2006.80
   Wagner M., 2017, THESIS VIENNA U TECH
   Wang XY, 2009, COMPUT GRAPH-UK, V33, P616, DOI 10.1016/j.cag.2009.06.004
   Wang ZZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376271
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Yalcin M.A., 2016, THESIS U MARYLAND CO
NR 74
TC 9
Z9 9
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 6
IS 1
BP 68
EP 83
DI 10.1016/j.visinf.2022.02.005
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2S0ZC
UT WOS:000821528800007
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Han, DM
   Pan, JC
   Zhao, XD
   Chen, W
AF Han, Dongming
   Pan, Jiacheng
   Zhao, Xiaodong
   Chen, Wei
TI NetV.js: A web-based library for high-efficiency visualization of
   large-scale graphs and networks
SO VISUAL INFORMATICS
LA English
DT Article
DE Graph; Graph visualization; Network visualization; Node-link diagram
ID INTERACTIVE VISUALIZATION; INFORMATION VISUALIZATION; DESIGN; VEGA
AB Graph visualization plays an important role in several fields, such as social media networks, protein-protein interaction networks, and traffic networks. A number of visualization design tools and programming toolkits have been widely used in graph-related applications. However, a key challenge remains in the high-efficiency visualization of large-scale graph data. In this study, we present NetV.js, an open-source and WebGL-based JavaScript library that supports the fast visualization of large-scale graph data (up to 50 thousand nodes and 1 million edges) at an interactive frame rate with a commodity computer. Experimental results demonstrate that our library outperforms existing toolkits (Sigma.js, D3.js, Cytoscape.js, and Stardust.js) in terms of performance. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Han, Dongming; Pan, Jiacheng; Zhao, Xiaodong; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Han, Dongming; Pan, Jiacheng; Zhao, Xiaodong] Zhejiang Lab, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang Laboratory
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM chenwei@cad.zju.edu.cn
FU National Natural Science Foundation of China [61772456]
FX This paper is supported by National Natural Science Foundation of China
   (61772456).
CR [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   Bastian Mathieu., 2009, International_AAAI_Conference_on_Weblogs_and Social_Media, DOI DOI 10.1609/ICWSM.V3I1.13937
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Coene J.-P., Journal of Open Source Software, V3, P814, DOI [10.21105/joss.00814, DOI 10.21105/JOSS.00814, 10.21105/JOSS.00814]
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Doncheva NT, 2012, NAT PROTOC, V7, P670, DOI 10.1038/nprot.2012.004
   Ellson J, 2004, MATH VIS, P127
   Franz M, 2016, BIOINFORMATICS, V32, P309, DOI 10.1093/bioinformatics/btv557
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Hansen DL, 2011, ANALYZING SOCIAL MEDIA NETWORKS WITH NODEXL: INSIGHTS FROM A CONNECTED WORLD, P11, DOI 10.1016/B978-0-12-382229-1.00002-3
   Heer J, 2010, IEEE T VIS COMPUT GR, V16, P1149, DOI 10.1109/TVCG.2010.144
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Leskovec J, 2016, ACM T INTEL SYST TEC, V8, DOI 10.1145/2898361
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Li J.K., 2020, IEEE T VIS COMPUT GR
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1151, DOI 10.1109/TVCG.2019.2934537
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1548, DOI 10.1109/TVCG.2018.2871139
   Lu JH, 2020, IEEE COMPUT GRAPH, V40, P18, DOI 10.1109/MCG.2020.2968249
   Mei HH, 2020, VIS INFORM, V4, P12, DOI 10.1016/j.visinf.2020.07.001
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Pan J., 2020, IEEE T VIS COMPUT GR
   Pan JC, 2020, FRONT INFORM TECH EL, V21, P491, DOI 10.1631/FITEE.1900310
   Reas C., 2003, GRAPH 03 P SIGGRAPH, P1
   Reas C., 2005, ACM SIGGRAPH 2005 WE, p[14, ACM]
   Ren DH, 2017, COMPUT GRAPH FORUM, V36, P179, DOI 10.1111/cgf.13178
   Ren DH, 2014, IEEE T VIS COMPUT GR, V20, P2092, DOI 10.1109/TVCG.2014.2346291
   Satyanarayan A., 2014, Symposium on User Interface Software and Technology, P669, DOI DOI 10.1145/2642918.2647360
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Van der Spuy R., 2015, LEARN PIXI
   Wang XM, 2019, IEEE T VIS COMPUT GR, V25, P193, DOI 10.1109/TVCG.2018.2865021
   Wickham H, 2011, WIRES COMPUT STAT, V3, P180, DOI 10.1002/wics.147
   Zong J., 2020, IEEE T VIS COMPUT GR
NR 36
TC 24
Z9 25
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2021
VL 5
IS 1
BP 61
EP 66
DI 10.1016/j.visinf.2021.01.002
EA MAR 2021
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LE
UT WOS:000658194100034
OA gold
DA 2024-07-18
ER

PT J
AU Guo, RC
   Fujiwara, T
   Li, YR
   Lima, KM
   Sen, SM
   Tran, NK
   Ma, KL
AF Guo, Rongchen
   Fujiwara, Takanori
   Li, Yiran
   Lima, Kelly M.
   Sen, Soman
   Tran, Nam K.
   Ma, Kwan-Liu
TI Comparative visual analytics for assessing medical records with sequence
   embedding
SO VISUAL INFORMATICS
LA English
DT Article
DE Electronic medical records; Event sequence data; Autoencoder;
   Self-attention; Sequence similarity; Visual analytics
AB Machine learning for data-driven diagnosis has been actively studied in medicine to provide better healthcare. Supporting analysis of a patient cohort similar to a patient under treatment is a key task for clinicians to make decisions with high confidence. However, such analysis is not straightforward due to the characteristics of medical records: high dimensionality, irregularity in time, and sparsity. To address this challenge, we introduce a method for similarity calculation of medical records. Our method employs event and sequence embeddings. While we use an autoencoder for the event embedding, we apply its variant with the self-attention mechanism for the sequence embedding. Moreover, in order to better handle the irregularity of data, we enhance the self-attention mechanism with consideration of different time intervals. We have developed a visual analytics system to support comparative studies of patient records. To make a comparison of sequences with different lengths easier, our system incorporates a sequence alignment method. Through its interactive interface, the user can quickly identify patients of interest and conveniently review both the temporal and multivariate aspects of the patient records. We demonstrate the effectiveness of our design and system with case studies using a real-world dataset from the neonatal intensive care unit of UC Davis. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Guo, Rongchen] Beihang Univ, Dept Comp Sci, Beijing, Peoples R China.
   [Fujiwara, Takanori; Li, Yiran; Ma, Kwan-Liu] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Lima, Kelly M.; Tran, Nam K.] Univ Calif Davis, Dept Pathol & Lab Med, Davis, CA 95616 USA.
   [Sen, Soman] Univ Calif Davis, Dept Surg, Davis, CA 95616 USA.
C3 Beihang University; University of California System; University of
   California Davis; University of California System; University of
   California Davis; University of California System; University of
   California Davis
RP Guo, RC (corresponding author), Beihang Univ, Dept Comp Sci, Beijing, Peoples R China.
EM rongchen.guo1020@gmail.com
RI Fujiwara, Takanori/AAY-5045-2020
OI Fujiwara, Takanori/0000-0002-6382-2752
FU U.S. National Science Foundation [IIS-1741536]; CITRIS; Banatao
   Institute at the University of California, United States
FX The authors wish to thank Dr. Mark A. Underwood at UC Davis Children's
   Hospital. This research is sponsored in part by the U.S. National
   Science Foundation through grant IIS-1741536 and a 2019 Seed Fund Award
   from CITRIS and the Banatao Institute at the University of California,
   United States.
CR ARAD I D, 1986, American Journal of Perinatology, V3, P1, DOI 10.1055/s-2007-999812
   Bahdanau D., 2014, 3 INT C LEARN REPR
   Berner ES, 2016, HEALTH INFORM SER, P1, DOI 10.1007/978-3-319-31913-1_1
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   CAMPION WM, 1989, J MARKETING RES, V26, P485, DOI 10.2307/3172772
   Chen L, 2004, P 30 INT C VER LARG, V30, P792, DOI [DOI 10.1016/B978-012088469-8.50070-X, DOI 10.1016/B978-012088469-8/50070-X]
   Chen L., 2005, P 2005 ACM SIGMOD IN, P491
   Du F, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200490
   Du F, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5498, DOI 10.1145/3025453.3025777
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Gotz D., 2011, IEEE VISWEEK WORKSH, P25
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Harerimana G, 2019, IEEE ACCESS, V7, P101245, DOI 10.1109/ACCESS.2019.2928363
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu R., 2019, IEEE T VIS COMPUT GR
   Huang L, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103291
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Ji XN, 2019, IEEE T VIS COMPUT GR, V25, P2181, DOI 10.1109/TVCG.2019.2903946
   Jin Z., 2019, ACM T COMPUT HEALTHC
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kawaler Emily, 2012, AMIA Annu Symp Proc, V2012, P436
   Koyner JL, 2018, CRIT CARE MED, V46, P1070, DOI 10.1097/CCM.0000000000003123
   KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209
   Kwon B.C., 2019, ARXIV190411652
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lee C., 2017, Handbook of large-scale distributed computing in smart healthcare, P11, DOI 10.1007/978-3-319-58280-1_2
   Li O, 2017, ARXIV PREPRINT ARXIV
   Li XZ, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2617-8
   Li XC, 2018, PROC INT CONF DATA, P617, DOI 10.1109/ICDE.2018.00062
   Lin Z., 2017, PROC INT C LEARN REP
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Ming Y, 2019, P ACM SIGKDD INT C K
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Perer A, 2015, J BIOMED INFORM, V56, P369, DOI 10.1016/j.jbi.2015.06.020
   Nguyen P, 2017, IEEE J BIOMED HEALTH, V21, P22, DOI 10.1109/JBHI.2016.2633963
   Ratanamahatana CA, 2005, SIAM PROC S, P506
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sutskever I, 2014, ADV NEUR IN, V27
   Pham T, 2017, J BIOMED INFORM, V69, P218, DOI 10.1016/j.jbi.2017.04.001
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verleysen M, 2005, LECT NOTES COMPUT SC, V3512, P758
   Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784
   Warrens M.J, 2017, WILEY STATSREF STAT, P1, DOI DOI 10.1002/9781118445112.STAT02470.PUB2
   Wells Brian J, 2013, EGEMS (Wash DC), V1, P1035, DOI 10.13063/2327-9214.1035
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Yadav Shweta., 2016, Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP), P32
   Yazhini K., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P195, DOI 10.1109/ICOEI.2019.8862730
   Yi BK, 1998, PROC INT CONF DATA, P201, DOI 10.1109/ICDE.1998.655778
   Zhao R., 2017, IEEE Trans. Vis. Comput. Graphics, P1
   Zhu ZH, 2016, IEEE DATA MINING, P749, DOI [10.1109/ICDM.2016.90, 10.1109/ICDM.2016.0086]
NR 53
TC 24
Z9 25
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2020
VL 4
IS 2
SI SI
BP 72
EP 85
DI 10.1016/j.visinf.2020.04.001
PG 14
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KK
UT WOS:000658192100002
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Deng, HZ
   Wang, XM
   Guo, ZY
   Decker, A
   Duan, XJ
   Wang, CL
   Ambrose, GA
   Abbott, K
AF Deng, Haozhang
   Wang, Xuemeng
   Guo, Zhiyi
   Decker, Ashley
   Duan, Xiaojing
   Wang, Chaoli
   Ambrose, G. Alex
   Abbott, Kevin
TI PerformanceVis: Visual analytics of student performance data from an
   introductory chemistry course
SO VISUAL INFORMATICS
LA English
DT Article
DE Student performance; Item analysis; Grade prediction; Learning
   analytics; Knowledge discovery
AB We present PerformanceVis, a visual analytics tool for analyzing student admission and course performance data and investigating homework and exam question design. Targeting a university-wide introductory chemistry course with nearly 1000 student enrollment, we consider the requirements and needs of students, instructors, and administrators in the design of PerformanceVis. We study the correlation between question items from assignments and exams, employ machine learning techniques for student grade prediction, and develop an interface for interactive exploration of student course performance data. PerformanceVis includes four main views (overall exam grade pathway, detailed exam grade pathway, detailed exam item analysis, and overall exam & homework analysis) which are dynamically linked together for user interaction and exploration. We demonstrate the effectiveness of PerformanceVis through case studies along with an ad-hoc expert evaluation. Finally, we conclude this work by pointing out future work in this direction of learning analytics research. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Deng, Haozhang; Wang, Xuemeng] Univ Rochester, Rochester, NY 14627 USA.
   [Guo, Zhiyi] Fudan Univ, Shanghai 200433, Peoples R China.
   [Decker, Ashley; Duan, Xiaojing; Wang, Chaoli; Ambrose, G. Alex; Abbott, Kevin] Univ Notre Dame, Notre Dame, IN 46556 USA.
C3 University of Rochester; Fudan University; University of Notre Dame
RP Duan, XJ (corresponding author), Univ Notre Dame, Notre Dame, IN 46556 USA.
EM xduan@nd.edu
RI Guo, Zhiyi/I-5411-2015; Wang, Chaoli/AAJ-5173-2020
OI Wang, Chaoli/0000-0002-0859-3619; Duan, Xiaojing/0000-0003-0822-2022;
   DENG, HAOZHANG/0000-0001-6443-7867; Abbott, Kevin/0000-0002-6887-5319
FU U.S. National Science Foundation [IIS-1455886, DUE-1833129]; Schlindwein
   Family Tel Aviv University -Notre Dame Research Collaboration, United
   States Grant
FX This work was supported in part by the U.S. National Science Foundation
   through grants IIS-1455886 and DUE-1833129, and the Schlindwein Family
   Tel Aviv University -Notre Dame Research Collaboration, United States
   Grant. Haozhang Deng, Xuemeng Wang, Zhiyi Guo, and Ashley Decker
   conducted this work as an undergraduate research project at the
   University of Notre Dame during Summer 2019. We also thank the following
   collaborators: J. Daniel Gezelter, Kelley M. H. Young, Kevin Barry, Mark
   Gunty, and Catlin Schalk.
CR Ali L, 2012, COMPUT EDUC, V58, P470, DOI 10.1016/j.compedu.2011.08.030
   Arias JJ, 2004, J ECON EDUC, V35, P311, DOI 10.3200/JECE.35.4.311-329
   Arnold K. E., 2012, Proceedings of the 2nd international conference on learning analytics and knowledge, P267, DOI 10.1145/2330601.2330666
   Bakharia A., 2011, Proceedings of the 1st International Conference on Learning Analytics and Knowledge, P168, DOI DOI 10.1145/2090116.2090144
   Baradwaj BK, 2011, INT J ADV COMPUT SC, V2, P63
   Charleer S, 2018, IEEE T LEARN TECHNOL, V11, P389, DOI 10.1109/TLT.2017.2720670
   Denley T., 2013, EDUCAUSE Review Online
   Elen J., 2014, Handbook of Research on Educational Communications and Technology, P791, DOI [10.1007/978-1-4614-3185-5_64, DOI 10.1007/978-1-4614-3185-5_64, DOI 10.1007/978-1-4614-3185-564]
   Essa A., 2012, P INT C LEARN AN KNO, P517
   Fu SW, 2017, IEEE T VIS COMPUT GR, V23, P201, DOI 10.1109/TVCG.2016.2598444
   Goulden M.C., 2019, P IS T C VIS DAT AN
   Govaerts S., 2012, P 2012 ACM ANN C HUM, P869
   Hingorjo MR, 2012, J PAK MED ASSOC, V62, P142
   Jivet I, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'18): TOWARDS USER-CENTRED LEARNING ANALYTICS, P31, DOI 10.1145/3170358.3170421
   King M., 2012, Compendium of Effective Practice in Higher Education Retention and Success, P121
   Kingma D. P., 2015, INT C LEARNING REPRE
   Krumm A.E., 2014, Learning analytics: From research to practice, P103, DOI [DOI 10.1007/978-1-4614-3305-7_6, 10.1007/978-1-4614-3305-7_6, DOI 10.1007/978-1-4614-3305-76]
   Lim L, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'19), P250, DOI 10.1145/3303772.3303804
   Lonn S., 2013, Proceedings of the Third International Conference on Learning Analytics and Knowledge - LAK '13, P235, DOI [DOI 10.1145/2460296.2460343, 10.1145/2460296.2460343]
   Moreno-Marcos PM, 2018, BEHAV INFORM TECHNOL, V37, P1021, DOI 10.1080/0144929X.2018.1458904
   McKay T., 2012, Proceedings of the 2nd International Conference on Learning Analytics and Knowledge, P88, DOI DOI 10.1145/2330601.2330627
   Okubo F, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P598, DOI 10.1145/3027385.3029479
   Park Y, 2015, J UNIVERS COMPUT SCI, V21, P110
   Pérez-Alvarez R, 2017, LECT NOTES COMPUT SC, V10474, P517, DOI 10.1007/978-3-319-66610-5_53
   Podgorelec V, 2011, ELEKTRON ELEKTROTECH, P111
   Santos JL., 2013, Proceedings of the Third International Conference on Learning Analytics and Knowledge, P14, DOI DOI 10.1145/2460296.2460301
   Tao J, 2017, IEEE PAC VIS SYMP, P1, DOI 10.1109/PACIFICVIS.2017.8031572
   Tavakol M, 2011, MED TEACH, V33, P447, DOI 10.3109/0142159X.2011.564682
   University of Washington, 2019, UND IT AN
   Verbert K, 2013, AM BEHAV SCI, V57, P1500, DOI 10.1177/0002764213479363
   Wu TS, 2016, IEEE PAC VIS SYMP, P194, DOI 10.1109/PACIFICVIS.2016.7465269
   Zhou YW, 2018, INFORM SCIENCES, V444, P135, DOI 10.1016/j.ins.2018.02.053
NR 32
TC 17
Z9 20
U1 2
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2019
VL 3
IS 4
BP 166
EP 176
DI 10.1016/j.visinf.2019.10.004
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YM
UT WOS:000658190500002
OA gold
DA 2024-07-18
ER

PT J
AU Akbulut, O
   Mclaughlin, L
   Xin, T
   Forshaw, M
   Holliman, NS
AF Akbulut, Osman
   Mclaughlin, Lucy
   Xin, Tong
   Forshaw, Matthew
   Holliman, Nicolas S.
TI Visualizing ordered bivariate data on node-link diagrams
SO VISUAL INFORMATICS
LA English
DT Article
DE Bivariate network visualization; Edge visualization; Uncertainty
   visualization; Node-link diagram; Quantitative evaluation
ID OF-THE-ART; UNCERTAINTY; SEARCH; GRAPHS; COLOR; EDGES; USER
AB Node-link visual representation is a widely used tool that allows decision-makers to see details about a network through the appropriate choice of visual metaphor. However, existing visualization methods are not always effective and efficient in representing bivariate graph-based data. This study proposes a novel node-link visual model - visual entropy (Vizent) graph - to effectively represent both primary and secondary values, such as uncertainty, on the edges simultaneously. We performed two user studies to demonstrate the efficiency and effectiveness of our approach in the context of static nodelink diagrams. In the first experiment, we evaluated the performance of the Vizent design to determine if it performed equally well or better than existing alternatives in terms of response time and accuracy. Three static visual encodings that use two visual cues were selected from the literature for comparison: Width-Lightness, Saturation-Transparency, and Numerical values. We compared the Vizent design to the selected visual encodings on various graphs ranging in complexity from 5 to 25 edges for three different tasks. The participants achieved higher accuracy of their responses using Vizent and Numerical values; however, both Width-Lightness and Saturation-Transparency did not show equal performance for all tasks. Our results suggest that increasing graph size has no impact on Vizent in terms of response time and accuracy. The performance of the Vizent graph was then compared to the Numerical values visualization. The Wilcoxon signed-rank test revealed that mean response time in seconds was significantly less when the Vizent graphs were presented, while no significant difference in accuracy was found. The results from the experiments are encouraging and we believe justify using the Vizent graph as a good alternative to traditional methods for representing bivariate data in the context of node-link diagrams.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University (http://creativecommons.org/licenses/by/4.0/).
C1 [Akbulut, Osman; Mclaughlin, Lucy; Xin, Tong; Forshaw, Matthew] Newcastle Univ, Sch Comp, 1 Sci Sq, Newcastle Upon Tyne NE4 5TG, England.
   [Holliman, Nicolas S.] Kings Coll London, CUSP London, Dept Informat, Bush House,30 Aldwych, London WC2B 4BG, England.
   [Akbulut, Osman] Duzce Univ, Fac Engn, Dept Comp Engn, Duzce, Turkiye.
C3 Newcastle University - UK; University of London; King's College London;
   Duzce University
RP Akbulut, O (corresponding author), Newcastle Univ, Sch Comp, 1 Sci Sq, Newcastle Upon Tyne NE4 5TG, England.; Akbulut, O (corresponding author), Duzce Univ, Fac Engn, Dept Comp Engn, Duzce, Turkiye.
EM o.akbulut2@newcastle.ac.uk
RI Tong, Xin/P-2521-2016
OI Xin, Tong/0000-0001-5479-262X; Forshaw, Matthew/0000-0001-7014-9837;
   Holliman, Nicolas Steven/0000-0003-4418-4908; AKBULUT,
   OSMAN/0000-0002-3949-2845
FU Ministry of National Education, Turkey
FX We thank the Ministry of National Education, Turkey for financially
   supporting the first author's PhD study at Newcastle University, UK.
CR Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Andreyev Alexey, 2014, Introducing data center fabric, the next-generation facebook data center network
   Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131
   Bae J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P64, DOI 10.5220/0006102300640074
   Bertin J., 1983, SEMIOLOGY GRAPHICS D
   Boukhelifa N, 2012, IEEE T VIS COMPUT GR, V18, P2769, DOI 10.1109/TVCG.2012.220
   Brodlie K, 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [DOI 10.1007/978-1-4471-2804-5_6, 10.1007/978-1-4471-2804-5_6]
   Burch M, 2021, IEEE ACCESS, V9, P4173, DOI 10.1109/ACCESS.2020.3047616
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   Cohen J., 1988, Statistical power analyses for behavioral sciences, V2nd, DOI [10.4324/9780203771587, DOI 10.4324/9780203771587]
   Crameri F, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19160-7
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Hagberg A. A., 2008, EXPLORING NETWORK ST, P11, DOI DOI 10.1016/J.JELECTROCARD.2010.09.003
   Holliman NS, 2022, Arxiv, DOI arXiv:1907.12879
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2011, IEEE PAC VIS SYMP, P195, DOI 10.1109/PACIFICVIS.2011.5742390
   Kamal A, 2021, J VISUAL-JAPAN, V24, P861, DOI 10.1007/s12650-021-00755-1
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168168
   Liu SX, 2014, VISUAL COMPUT, V30, P1373, DOI 10.1007/s00371-013-0892-3
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   McGee F, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P620, DOI 10.1145/2254556.2254670
   Menneer T., 2008, Cognitive and Cultural Influences on Eye Movements, P129
   Napierala MA, 2012, AAOS Now, P40
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Pohl M., 2009, COMPUTATIONAL AESTHE, P49, DOI [DOI 10.2312/COMPAESTH/COMPAESTH09/049-056, 10.5555/2381286.2381296]
   Purchase HC, 1998, J VISUAL LANG COMPUT, V9, P647, DOI 10.1006/jvlc.1998.0093
   QUINLAN PT, 1987, PERCEPT PSYCHOPHYS, V41, P455, DOI 10.3758/BF03203039
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Romat H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173761
   Ropinski T, 2011, COMPUT GRAPH-UK, V35, P392, DOI 10.1016/j.cag.2011.01.011
   Rosenthal R., 1994, The handbook of research synthesis, P231, DOI DOI 10.7758/9781610441377
   Schwank J, 2016, IEEE INT CONF INF VI, P45, DOI 10.1109/IV.2016.19
   Shiravi H, 2012, IEEE T VIS COMPUT GR, V18, P1313, DOI 10.1109/TVCG.2011.144
   Smart S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300899
   Stroud MJ, 2012, J EXP PSYCHOL HUMAN, V38, P113, DOI 10.1037/a0025887
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   von Landesberger T, 2017, IEEE COMPUT GRAPH, V37, P18, DOI 10.1109/MCG.2017.3621220
   Windhager F, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6030029
   Wu JT, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090625
   Xu K, 2012, IEEE T VIS COMPUT GR, V18, P2449, DOI 10.1109/TVCG.2012.189
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
NR 44
TC 2
Z9 2
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2023
VL 7
IS 3
BP 22
EP 36
DI 10.1016/j.visinf.2023.06.003
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA U3AZ9
UT WOS:001083574100001
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Pommé, LE
   Bourqui, R
   Giot, R
   Vallet, J
   Auber, D
AF Pomme, Luc -Etienne
   Bourqui, Romain
   Giot, Romain
   Vallet, Jason
   Auber, David
TI NetPrune: A sparklines visualization for network pruning
SO VISUAL INFORMATICS
LA English
DT Article
DE Explainable pruning; Guided Fine-tuning; Visualization; Deep learning
ID NEURAL-NETWORKS
AB Current deep learning approaches are cutting-edge methods for solving classification tasks. Arising transfer learning techniques allows applying large generic model to simple tasks whereas simpler models could be used. Large models raise the major problem of their memory consumption and processor usage and lead to a prohibitive ecological footprint. In that paper, we present a novel visual analytics approach to interactively prune those networks and thus limit that issue. Our technique leverages a novel sparkline matrix visualization technique as well as a novel local metric which evaluates the discriminatory power of a filter to guide the pruning process and make it interpretable. We assess the well-founded of our approach through two realistic case studies and a user study. For both of them, the interactive refinement of the model led to a significantly smaller model having similar prediction accuracy than the original one.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Pomme, Luc -Etienne; Bourqui, Romain; Giot, Romain; Vallet, Jason; Auber, David] Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
C3 Universite de Bordeaux; Inria; Centre National de la Recherche
   Scientifique (CNRS)
RP Pommé, LE (corresponding author), Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
EM luc.pomme-cassierou@labri.fr; romain.bourqui@labri.fr;
   romain.giot@labri.fr; jason.vallet@labri.fr; david.auber@labri.fr
RI Giot, Romain/F-6747-2011
OI Giot, Romain/0000-0002-0638-7504; Auber, David/0000-0002-1114-8612;
   Pomme, Luc/0000-0002-4690-7260
FU LyRE [AAPR2020-2019-8171810]; Nouvelle-Aquitaine Region; Bordeaux
   Metropole; SUEZ
FX We acknowledge the Nouvelle-Aquitaine Region, Bordeaux Metropole and
   SUEZ,le LyRE for mainly funding and supporting this work through the
   Convention N degrees AAPR2020-2019-8171810.
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   [Anonymous], 1990, Adv Neural Inform Process Syst.
   [Anonymous], 2022, DATASET DOGS VS CATS
   Ba LJ, 2014, ADV NEUR IN, V27
   Cashman D, 2020, IEEE T VIS COMPUT GR, V26, P863, DOI 10.1109/TVCG.2019.2934261
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7
   Courbariaux Y., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   Denil M., 2013, ADV NEURAL INFORM PR
   Dreyfus Gerard., 2005, Neural Networks: Methodology and Applications, DOI DOI 10.1007/3-540-28847-3
   Elmqvist N, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P215
   France J, 2018, HIST WARFARE, V116, P1, DOI 10.1163/9789004349599_002
   Garcia R, 2018, COMPUT GRAPH-UK, V77, P30, DOI 10.1016/j.cag.2018.09.018
   Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Görtler J, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501823
   Gong YC, 2014, Arxiv, DOI arXiv:1412.6115
   Guo YW, 2016, ADV NEUR IN, V29
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hainaut A, 2020, IVAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 3: IVAPP, P231, DOI 10.5220/0008989702310239
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Han S, 2015, ADV NEUR IN, V28
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hu HY, 2016, Arxiv, DOI arXiv:1607.03250
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li FF, 2016, Arxiv, DOI arXiv:1605.04711
   Li G, 2021, IEEE T VIS COMPUT GR, V27, P1364, DOI 10.1109/TVCG.2020.3030461
   Li H, 2017, Arxiv, DOI arXiv:1608.08710
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Lin XF, 2017, ADV NEUR IN, V30
   Liu JY, 2020, Arxiv, DOI arXiv:2005.04275
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Martin R. C., 2002, AGILE SOFTWARE DEV P
   Molchanov P., 2017, 5 INTERCONF LEARNING
   Pomme L.-E., 2022, IV2022 IVE INFORM VI
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrinivasan YB, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.87
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tai C, 2016, Arxiv, DOI [arXiv:1511.06067, DOI 10.48550/ARXIV.1511.06067]
   Tufte E.R, 2006, GRAPHIS PR, P46
   Wang YL, 2020, AAAI CONF ARTIF INTE, V34, P6299
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Yuan J., 2020, COMPUT VIS MEDIA, P1
   Zeng HP, 2017, Arxiv, DOI arXiv:1710.05285
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhong W., 2017, ICML WORKSHOP VISUAL
   Zhou YF, 2019, IEEE I CONF COMP VIS, P3305, DOI 10.1109/ICCV.2019.00340
NR 57
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 85
EP 99
DI 10.1016/j.visinf.2023.04.001
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA M6WO3
UT WOS:001031602100001
OA gold
DA 2024-07-18
ER

PT J
AU Dhar, S
   Shamir, L
AF Dhar, Sanchari
   Shamir, Lior
TI Evaluation of the benchmark datasets for testing the efficacy of deep
   convolutional neural networks
SO VISUAL INFORMATICS
LA English
DT Article
DE Convolutional neural networks; Data acquisition bias; Deep learning;
   Experimental design
AB In the past decade, deep neural networks, and specifically convolutional neural networks (CNNs), have been becoming a primary tool in the field of biomedical image analysis, and are used intensively in other fields such as object or face recognition. CNNs have a clear advantage in their ability to provide superior performance, yet without the requirement to fully understand the image elements that reflect the biomedical problem at hand, and without designing specific algorithms for that task. The availability of easy-to-use libraries and their non-parametric nature make CNN the most common solution to problems that require automatic biomedical image analysis. But while CNNs have many advantages, they also have certain downsides. The features determined by CNNs are complex and unintuitive, and therefore CNNs often work as a ``Black Box''. Additionally, CNNs learn from any piece of information in the pixel data that can provide a discriminative signal, making it more difficult to control what the CNN actually learns. Here we follow common practices to test whether CNNs can classify biomedical image datasets, but instead of using the entire image we use merely parts of the images that do not have biomedical content. The experiments show that CNNs can provide high classification accuracy even when they are trained with datasets that do not contain any biomedical information, or can be systematically biased by irrelevant information in the image data. The presence of such consistent irrelevant data is difficult to identify, and can therefore lead to biased experimental results. Possible solutions to this downside of CNNs can be control experiments, as well as other protective practices to validate the results and avoid biased conclusions based on CNN-generated annotations. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Dhar, Sanchari; Shamir, Lior] Kansas State Univ, Manhattan, KS 66506 USA.
C3 Kansas State University
RP Shamir, L (corresponding author), Kansas State Univ, Manhattan, KS 66506 USA.
EM lshamir@mtu.edu
OI Shamir, Lior/0000-0002-6207-1491
FU NSF, United States [AST-1903823]; Zhejiang University Press
FX The research was funded in part by NSF, United States grant AST-1903823.
   We would like to thank the two knowledgeable anonymous reviewers for the
   insightful comments that helped to improve the manuscript. We would also
   like to thank Zhejiang University Press for the funding that makes the
   paper open access.
CR Abraham VC, 2004, TRENDS BIOTECHNOL, V22, P15, DOI 10.1016/j.tibtech.2003.10.012
   Aina OE, 2019, INT CONF ELECT COMP, DOI 10.1109/ICECCO48375.2019.9043220
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   Chen Y-C., 2019, Journal of Orofacial Sciences, V11
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Hu Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P240, DOI 10.1007/978-3-030-58565-5_15
   Hu ZL, 2018, PATTERN RECOGN, V83, P134, DOI 10.1016/j.patcog.2018.05.014
   Huang L., 2011, P 4 ACM WORKSH SEC A, P43
   Jaipuria N, 2020, IEEE COMPUT SOC CONF, P3344, DOI 10.1109/CVPRW50498.2020.00394
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Khosla A, 2012, LECT NOTES COMPUT SC, V7572, P158, DOI 10.1007/978-3-642-33718-5_12
   Kingma D. P., 2014, arXiv
   Kortylewski A, 2019, IEEE COMPUT SOC CONF, P2261, DOI 10.1109/CVPRW.2019.00279
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Y, 2019, PROC CVPR IEEE, P9564, DOI 10.1109/CVPR.2019.00980
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   McLaughlin N, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068
   Moore S, 2020, RADIOGRAPHY, V26, pE297, DOI 10.1016/j.radi.2020.04.005
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Shamir L, 2011, J MICROSC-OXFORD, V243, P284, DOI 10.1111/j.1365-2818.2011.03502.x
   Shamir L, 2008, MED BIOL ENG COMPUT, V46, P943, DOI 10.1007/s11517-008-0380-5
   Shamir L, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000974
   Shamir L, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P96, DOI 10.1109/LISSA.2009.4906718
   Shamir L, 2008, SOURCE CODE BIOL MED, V3, DOI 10.1186/1751-0473-3-13
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Singh S, 2014, J BIOMOL SCREEN, V19, P640, DOI 10.1177/1087057114528537
   Sultana F, 2018, 2018 FOURTH IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P122, DOI 10.1109/ICRCICN.2018.8718718
   Thomsen K, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.574329
   Tommasi T, 2017, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-58347-1_2
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Wainberg M, 2018, NAT BIOTECHNOL, V36, P829, DOI 10.1038/nbt.4233
   Yi PH, 2021, J DIGIT IMAGING, V34, P27, DOI 10.1007/s10278-020-00407-0
   Zanella F, 2010, TRENDS BIOTECHNOL, V28, P237, DOI 10.1016/j.tibtech.2010.02.005
   Zhang YJ, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103294
NR 40
TC 11
Z9 12
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 92
EP 101
DI 10.1016/j.visinf.2021.10.001
EA OCT 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200008
OA gold
DA 2024-07-18
ER

PT J
AU Sebai, D
   Sehli, M
   Ghorbel, F
AF Sebai, Dorsaf
   Sehli, Maryem
   Ghorbel, Faouzi
TI Sparse Representations-based depth images quality assessment
SO VISUAL INFORMATICS
LA English
DT Article
DE Depth maps; Sparse representations; Transform domain; Image Quality
   Assessment; 3D-HEVC
ID MULTIVIEW VIDEO
AB The conventional 2D metrics can be used for measuring the quality of depth maps, but none of them is considered to be efficient and is not accurate when used for evaluating 3D quality. In this paper, we propose a new full reference objective metric, called Sparse Representations-Mean Squared Error (SR-MSE), which efficiently evaluates the depth maps compression distortions. It adaptively models the reference and compressed depth maps in a mixed redundant transform domain dedicated to depth features. Then, it computes the mean squared error between the sparse coefficients issued from this modeling. As a benchmark of quality assessment, we perform a subjective evaluation test for depth maps compressed using the latest 3D High Efficiency Video Coding standard at various bitrates. We compare the subjective results with the proposed and conventional objective metrics. Experimental results demonstrate that the proposed SR-MSE, compared to the conventional image quality assessment metrics, yields the highest correlated scores to the subjective ones. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Sebai, Dorsaf; Sehli, Maryem; Ghorbel, Faouzi] Univ Manouba, Natl Sch Comp Sci, Manouba, Tunisia.
C3 Universite de la Manouba
RP Sebai, D (corresponding author), Univ Manouba, Natl Sch Comp Sci, Manouba, Tunisia.
EM dorsaf.sebai@ensi-uma.tn
OI Ghorbel, Faouzi/0000-0002-6364-1089; Sebai, Dorsaf/0000-0001-7720-2741
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aharon M, 2008, SIAM J IMAGING SCI, V1, P228, DOI 10.1137/07070156X
   Al-Najjar YAY., 2012, Int J Sci Eng Res, V3, P1
   [Anonymous], 2012, JTC1SC29WG11 ISO IEC
   [Anonymous], 2007, INT WORKSH VID PROC
   [Anonymous], 1925, STAT METHODS RES WOR
   Banitalebi-Dehkordi A., 2013, ISOIECJTC1SC29WG11
   Banitalebi-Dehkordi A., 2013, IEEE 4 MSP WORKSH 3D
   Bosc E, 2011, IEEE IMAGE PROC
   Chen G.H., 2006, IEEE INT C AC SPEECH
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Chen Y, 2015, TEST MODEL 11 3D HEV
   Cheung G, 2011, IEEE IMAGE PROC, P129, DOI 10.1109/ICIP.2011.6115673
   Conze P., 2012, OBJECTIVE VIEW SYNTH
   De Silva D., 2010, INT C US CENTR MED
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Girod Bernd, 1993, P207
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P9, DOI 10.1109/79.952802
   Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031
   Jin L., NOVEL STEREO VIDEO Q
   Jin L., 2011, EUR SIGN PROC C EURO
   Karen E., 2006, INT WORKSH VID PROC
   Kim W.-S., 2009, IEEE INT C IM PROC
   Koumaras H.G, 2008, BT50011 ITU R
   Mairal J., 2009, P 26 ANN INT C MACH, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]
   Maitre M, 2010, J VIS COMMUN IMAGE R, V21, P513, DOI 10.1016/j.jvcir.2010.03.005
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Mohammadiand P., 2015, IJ ELECT ENG, V9
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Peotta L, 2006, SIGNAL PROCESS, V86, P444, DOI 10.1016/j.sigpro.2005.05.023
   Rebollo-Neira L, 2013, J OPT SOC AM A, V30, P758, DOI 10.1364/JOSAA.30.000758
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schwarz H, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P1, DOI 10.1109/PCS.2012.6213271
   Sebai D, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0086-7
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen G., 2010, PICT COD S
   Shen G., 2010, PICT COD S PCS
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Zhang L., 2012, INT C IM PROC ICIP
NR 44
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2021
VL 5
IS 1
BP 67
EP 75
DI 10.1016/j.visinf.2021.02.004
EA MAR 2021
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LE
UT WOS:000658194100035
OA gold
DA 2024-07-18
ER

PT J
AU Andrienko, N
   Andrienko, G
   Miksch, S
   Schumann, H
   Wrobel, S
AF Andrienko, Natalia
   Andrienko, Gennady
   Miksch, Silvia
   Schumann, Heidrun
   Wrobel, Stefan
TI A theoretical model for pattern discovery in visual analytics
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual analytics; Data distribution; Pattern; Abstraction; Data
   organisation; Data arrangement; Data variation; Pattern discovery
ID VISUALIZATION; GUIDANCE
AB The word 'pattern' frequently appears in the visualisation and visual analytics literature, but what do we mean when we talk about patterns? We propose a practicable definition of the concept of a pattern in a data distribution as a combination of multiple interrelated elements of two or more data components that can be represented and treated as a unified whole. Our theoretical model describes how patterns are made by relationships existing between data elements. Knowing the types of these relationships, it is possible to predict what kinds of patterns may exist. We demonstrate how our model underpins and refines the established fundamental principles of visualisation. The model also suggests a range of interactive analytical operations that can support visual analytics workflows where patterns, once discovered, are explicitly involved in further data analysis. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Andrienko, Natalia; Andrienko, Gennady; Wrobel, Stefan] Fraunhofer Inst IAIS, St Augustin, Germany.
   [Andrienko, Natalia; Andrienko, Gennady] City Univ London, London, England.
   [Miksch, Silvia] TU Wien, Vienna, Austria.
   [Schumann, Heidrun] Univ Rostock, Rostock, Germany.
   [Wrobel, Stefan] Univ Bonn, Bonn, Germany.
C3 Fraunhofer Gesellschaft; City University London; Technische Universitat
   Wien; University of Rostock; University of Bonn
RP Andrienko, N (corresponding author), Fraunhofer Inst IAIS, Schloss Birlinghoven, D-53757 St Augustin, Germany.
EM natalia.andrienko@iais.fraunhofer.de
RI Andrienko, Gennady L./B-6486-2014; Andrienko, Natalia/KHV-4755-2024
OI Andrienko, Gennady L./0000-0002-8574-6295; Andrienko,
   Natalia/0000-0003-3313-1560; Miksch, Silvia/0000-0003-4427-5703
FU Fraunhofer Center for Machine Learning within the Fraunhofer Cluster for
   Cognitive Internet Technologies; DFG [1894]; EU in project SoBigData++;
   Austrian Science Fund (FWF) project KnowVA [P31419-N31]; SESAR in
   project TAPAS; SESAR in project SIMBAD
FX This research was supported by Fraunhofer Center for Machine Learning
   within the Fraunhofer Cluster for Cognitive Internet Technologies, by
   DFG within Priority Programme 1894 (SPP VGI), by EU in project
   SoBigData++, by SESAR in projects TAPAS and SIMBAD, and by Austrian
   Science Fund (FWF) project KnowVA (grant P31419-N31).
CR Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   Andrienko N, 2020, Visual Analytics for Data Scientists
   Andrienko N., 2006, Exploratory analysis of spatial and temporal data: A systematic approach, DOI DOI 10.1007/3-540-31190-4
   [Anonymous], 2015, Data mining: the textbook
   [Anonymous], 1996, Advances in knowledge discovery & data mining
   [Anonymous], 2014, AK PETERS VISUALIZAT
   [Anonymous], 2009, Merriam-Webster Online Dictionary
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bae J, 2014, IEEE T VIS COMPUT GR, V20, P1973, DOI 10.1109/TVCG.2014.2346998
   Bertin J., 1983, SEMIOLOGY GRAPHICS D
   Borregaard, 2009, ENCY ECOLOGY, P3304
   Bruce P, 2017, Practical statistics for data scientists, DOI 10.1080/00401706.2021.1904738
   Ceneda D, 2020, COMPUT GRAPH FORUM, V39, P269, DOI 10.1111/cgf.14017
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen M, 2014, COMPUT GRAPH FORUM, V33, P241, DOI 10.1111/cgf.12380
   Chen M, 2016, IEEE T VIS COMPUT GR, V22, P2619, DOI 10.1109/TVCG.2015.2513410
   Chou YH, 1995, LECT NOTES COMPUT SC, V988, P365
   Collins C, 2018, VIS INFORM, V2, P166, DOI 10.1016/j.visinf.2018.09.003
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Demiralp C, 2014, IEEE COMPUT GRAPH, V34, P10, DOI 10.1109/MCG.2014.18
   Devlin K., 1996, Mathematics: The science of patterns: The search for order in life, 171 mind and the universe
   Feixas M., 2014, SYNTH LECT COMPUT GR, V6, P1, DOI DOI 10.2200/S00560ED1V01Y201312CGR015
   Forbes C., 2010, STAT DISTRIBUTIONS
   Getis A., 2004, LESPACE G OGRAPHIQUE, P61, DOI DOI 10.3917/EG.033.0061
   Grinstein G., 2011, IEEE VAST CHALLENGE
   Han J., 2005, DATA MINING CONCEPTS
   Hardle W.K., 2015, INTRO STAT, DOI [10.1007/978-3-319-17704-5, DOI 10.1007/978-3-319-17704-5]
   HORNBY A.S., 2000, Oxford Advanced Learner's Dictionary of current English
   JOHNSON B, 1991, VISUALIZATION 91, P284
   Karer B, 2020, COMPUT GRAPH FORUM, V39, P5, DOI 10.1111/cgf.13899
   Kerlinger F., 2000, PSY 200 300 QUANTITA
   Kijmongkolchai N, 2017, COMPUT GRAPH FORUM, V36, P73, DOI 10.1111/cgf.13169
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   Klir GJ, 2002, ARCHITECTURE SYSTEMS
   Klosgen W., 2002, Handbook of Data Mining and Knowledge Discovery
   Krishnamoorthy K, 2006, STAT TEXTB MONOGR, P1
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Metzger F., 2006, Laws of seeing
   Oliveri G, 1997, SYNTHESE, V112, P379, DOI 10.1023/A:1004906107430
   Resnik M., 1997, Mathematics as a Science of Patterns
   Rosenberg M, 2016, OXFORD BIBLIO ECOLOG, DOI [10.1093/OBO/97801998300600144, DOI 10.1093/OBO/97801998300600144]
   Ruiz F.E., 2009, INFORM THEORY COMPUT
   Schomaker, 2017, INTRO STAT DATA ANAL, DOI DOI 10.1007/978-3-319-46162-5
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Souris M, 2019, EPIDEMIOLOGY AND GEOGRAPHY: PRINCIPLES, METHODS AND TOOLS OF SPATIAL ANALYSIS, P109
   Tufte ER, 1990, Envisioning Information
   van den Elzen S, 2016, IEEE T VIS COMPUT GR, V22, P1, DOI 10.1109/TVCG.2015.2468078
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Ware C., 2020, INFORM VISUALIZATION
   Wattenberg M., 2004, Information Visualization, V3, P123, DOI 10.1057/palgrave.ivs.9500070
   Willems N, 2009, COMPUT GRAPH FORUM, V28, P959, DOI 10.1111/j.1467-8659.2009.01440.x
   Wise J. A., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), P51, DOI 10.1109/INFVIS.1995.528686
   Witten IH, 2011, MOR KAUF D, P1
NR 54
TC 18
Z9 18
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2021
VL 5
IS 1
BP 23
EP 42
DI 10.1016/j.visinf.2020.12.002
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LE
UT WOS:000658194100003
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Shi, L
   Liao, Q
   Tong, HH
   Hu, YF
   Wang, CL
   Lin, C
   Qian, WH
AF Shi, Lei
   Liao, Qi
   Tong, Hanghang
   Hu, Yifan
   Wang, Chaoli
   Lin, Chuang
   Qian, Weihong
TI OnionGraph: Hierarchical topology+attribute multivariate network
   visualization
SO VISUAL INFORMATICS
LA English
DT Article
DE Multivariate network visualization; Hierarchical abstraction;
   Focus+context; Entropy
ID GRAPH VISUALIZATION; VISUAL ANALYSIS; EXPLORATION; FRAMEWORK
AB Hierarchical abstraction is a scalable strategy to deal with large networks. Existing visualization methods have allowed to aggregate the network nodes into hierarchies based on the node attributes or network topology, each of which has its own advantage. Very few previous system has the capability to enjoy the best of both worlds. This paper presents OnionGraph, an integrated framework for the exploratory visual analysis of heterogeneous multivariate networks. OnionGraph allows nodes to be aggregated based on either node attributes, topology, or a hierarchical combination of both. These aggregations can be split, merged and filtered under the focus+context interaction model, or automatically traversed by the information-theoretic navigation method. Node aggregations that contain subsets of nodes are displayed by the onion metaphor, indicating the level and details of the abstraction. We have evaluated the OnionGraph tool in three real-world cases. Performance experiments demonstrate that on a commodity desktop, our method can scale to million-node networks while preserving the interactivity for analysis. (C) 2020 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Shi, Lei] Beihang Univ, Dept Comp Sci & Engn, ACT&BDBC, Beijing 100191, Peoples R China.
   [Liao, Qi] Cent Michigan Univ, Dept Comp Sci, Mt Pleasant, MI 48859 USA.
   [Tong, Hanghang] Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA.
   [Hu, Yifan] Yahoo Labs, New York, NY 10036 USA.
   [Wang, Chaoli] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Lin, Chuang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Qian, Weihong] Alibaba Cloud, Beijing 100102, Peoples R China.
C3 Beihang University; Central Michigan University; University of Illinois
   System; University of Illinois Urbana-Champaign; Yahoo! Inc; Yahoo! Inc
   United States; University of Notre Dame; Tsinghua University; Alibaba
   Group
RP Qian, WH (corresponding author), Alibaba Cloud, Beijing 100102, Peoples R China.
EM leishi@buaa.edu.cn; qi.liao@cmich.edu; htong@illinois.edu;
   yifanhu@yahoo.com; chaoli.wang@nd.edu; chlin@tsinghua.edu.cn;
   weihong.qwh@alibaba-inc.com
RI Wang, Chaoli/AAJ-5173-2020; Lin, Lin/JTU-1595-2023
OI Wang, Chaoli/0000-0002-0859-3619; Tong, Hanghang/0000-0003-4405-3887
FU NSFC [61772504]; Fundamental Research Funds for the Central Universities
FX This work was supported by NSFC Grants 61772504 and the Fundamental
   Research Funds for the Central Universities. Weihong Qian is the
   corresponding author.
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   [Anonymous], LNCS
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   Auber D, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P75, DOI 10.1109/infvis.2003.1249011
   Auber D, 2004, MATH VIS, P105
   Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Bezerianos A, 2010, COMPUT GRAPH FORUM, V29, P863, DOI 10.1111/j.1467-8659.2009.01687.x
   Biswas A, 2013, IEEE T VIS COMPUT GR, V19, P2683, DOI 10.1109/TVCG.2013.133
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bordoloi UD, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P487
   Cao N, 2010, IEEE T VIS COMPUT GR, V16, P1172, DOI 10.1109/TVCG.2010.154
   Card S K., 1999, READINGS INFORM VISU
   Chen M, 2010, IEEE T VIS COMPUT GR, V16, P1206, DOI 10.1109/TVCG.2010.132
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Dinkla K, 2012, IEEE T VIS COMPUT GR, V18, P2457, DOI 10.1109/TVCG.2012.208
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Dunne C., 2012, P SIGCHI C HUM FACT, P1663, DOI [10.1145/2207676.2208293, DOI 10.1145/2207676.2208293]
   Eger S, 2013, J INTEGER SEQ, V16
   Elmqvist N, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P215
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Gansner E, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P175, DOI 10.1109/INFVIS.2004.66
   Gray WR, 2012, IEEE PULSE, V3, P42, DOI 10.1109/MPUL.2011.2181023
   Hadlak S., 2015, EUROVIS 15 STATE OF
   Heer J., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P51, DOI 10.1109/VAST.2011.6102441
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Jusufi Ilir, 2013, 2013 17th International Conference on Information Visualisation, P19, DOI 10.1109/IV.2013.3
   Kang H., 2007, Information Visualization, V6, P18
   Kerren A, 2014, LECT NOTES COMPUT SC, V8380, P1, DOI 10.1007/978-3-319-06793-3_1
   Ko S, 2014, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2014.7042484
   Lei Shi, 2013, 2013 IEEE International Conference on Big Data, P606, DOI 10.1109/BigData.2013.6691629
   Lorrain F., 1971, J MATH SOCIOL, V1, P49, DOI [DOI 10.1080/0022250X.1971.9989788, 10.1080/0022250X.1971.9989788]
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Pretorius AJ, 2008, COMPUT GRAPH FORUM, V27, P967, DOI 10.1111/j.1467-8659.2008.01231.x
   Pretorius AJ, 2006, IEEE T VIS COMPUT GR, V12, P685, DOI 10.1109/TVCG.2006.192
   Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B, 2006, IEEE T VIS COMPUT GR, V12, P733, DOI 10.1109/TVCG.2006.166
   Sindre G., 1993, Proceedings 1993 IEEE Symposium on Visual Languages (Cat. No.93TH0562-9), P287, DOI 10.1109/VL.1993.269613
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Takahashi S, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P495
   Tang J., 2008, SIGKDD, P990, DOI DOI 10.1145/1401890.1402008
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Tominski C, 2009, COMPUT GRAPH-UK, V33, P660, DOI 10.1016/j.cag.2009.06.002
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   Viola I, 2006, IEEE T VIS COMPUT GR, V12, P933, DOI 10.1109/TVCG.2006.152
   Wang CL, 2008, IEEE T VIS COMPUT GR, V14, P1547, DOI 10.1109/TVCG.2008.140
   Wang CL, 2006, IEEE T VIS COMPUT GR, V12, P1029, DOI 10.1109/TVCG.2006.159
   Wang CL, 2011, IEEE PAC VIS SYMP, P99, DOI 10.1109/PACIFICVIS.2011.5742378
   Wang CL, 2011, ENTROPY-SWITZ, V13, P254, DOI 10.3390/e13010254
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Weaver C., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P75, DOI 10.1109/VAST.2010.5652520
   WHITE DR, 1983, SOC NETWORKS, V5, P193, DOI 10.1016/0378-8733(83)90025-4
   Wu Y, 2006, P 2006 AS PAC S INF, V60, P77
   Xu K, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P33
   Zhicheng Liu, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P41, DOI 10.1109/VAST.2011.6102440
NR 56
TC 6
Z9 6
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2020
VL 4
IS 1
BP 43
EP 57
DI 10.1016/j.visinf.2020.01.002
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KB
UT WOS:000658191200005
OA gold
DA 2024-07-18
ER

PT J
AU Oleiwi, ZC
   Al-Shammary, D
   Al-Asfoor, M
   Ibaida, A
AF Oleiwi, Zahraa Ch
   Al-Shammary, Dhiah
   Al-Asfoor, Muntasir
   Ibaida, Ayman
TI Light network high performance discrete cosine transform for digital
   images
SO VISUAL INFORMATICS
LA English
DT Article
DE Fast DCT; DCT; Health network; Network
ID DCT
AB This paper proposes a new high-performance Discrete Cosine Transform (DCT) for image and signal processing applications. Generally, DCT has been developed in a wide range of applications such as image compression and motion detection. However, the high complexity and required processing have effectively minimized the practical utilization of DCT. A New mathematical derivation for DCT is achieved in this paper with the purpose to reduce its complexity and speed up its processing. The new fast DCT version is mainly based on removing coefficients redundant calculations. The new developed model has shown a potential performance in comparison with standard DCT. Moreover, the proposed model has a high quality that has been investigated based on Mean Square Error (MSE) and Peak Signal to Noise Ratio (PSNR). Fast DCT requires only 0.15%-6% processing time in comparison with traditional DCT. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Oleiwi, Zahraa Ch] Univ Al Qadisiyah, Coll Sci, Al Diwaniyah, Iraq.
   [Al-Shammary, Dhiah; Al-Asfoor, Muntasir] Univ Al Qadisiyah, Coll Comp Sci & Informat Technol, Al Diwaniyah, Iraq.
   [Ibaida, Ayman] Victoria Univ, Coll Engn & Sci, Discipline IT, Footscray, Vic, Australia.
C3 University of Al-Qadisiyah; University of Al-Qadisiyah; Victoria
   University
RP Al-Shammary, D (corresponding author), Univ Al Qadisiyah, Coll Comp Sci & Informat Technol, Al Diwaniyah, Iraq.
EM zahraa.chaffat@qu.edu.iq; d.alshammary@qu.edu.iq;
   alasfoor.muntasir@qu.edu.iq; ayman.ibaida@vu.edu.au
RI chaffat, zahraa/S-4364-2017
OI chaffat, zahraa/0000-0001-9969-7394; Al-Shammary,
   Dhiah/0000-0002-7927-2900; Ibaida, Ayman/0000-0003-1581-7219
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   August NJ, 2004, IEEE T MULTIMEDIA, V6, P414, DOI 10.1109/TMM.2004.827491
   Britanak V., 2006, Discrete Cosine and Sine Transforms: General Properties, Fast Algorithms and Integer Approximations
   Cintra RJ, 2014, SIGNAL PROCESS, V99, P201, DOI 10.1016/j.sigpro.2013.12.027
   He ZH, 2008, IEEE T CIRC SYST VID, V18, P851, DOI 10.1109/TCSVT.2008.919087
   Huang C., 2009 5 INT C NAT COM
   Hussain ZM, 2011, DIGITAL SIGNAL PROCESSING: AN INTRODUCTION WITH MATLAB AND APPLICATIONS, P1, DOI 10.1007/978-3-642-15591-8
   Ichita T., 2017, DIRECTIONAL DISCRETE
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   LIU S, 2001, IEEE T CIRCUITS SYST
   Miri A, 2018, OPTIK, V156, P938, DOI 10.1016/j.ijleo.2017.12.074
   NARASIMHA MJ, 1978, IEEE T COMMUN, V26, P934, DOI 10.1109/TCOM.1978.1094144
   Pang C, 2018, SIGNAL IMAGE COMPRES
   Park CS, 2016, DIGIT SIGNAL PROCESS, V58, P20, DOI 10.1016/j.dsp.2016.07.011
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Poularikas A.D, 2000, The Transforms and Applications Handbook, V2nd
   Rao K.R, 2014, DISCRETE COSINE TRAN
   SKODRAS AN, 1994, IEEE T SIGNAL PROCES, V42, P1833, DOI 10.1109/78.298293
   Solomon D., 2007, DATA COMPRESSION, p4E
   Zhou J., 2009 PAC AS C CIRC C
NR 20
TC 1
Z9 1
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2021
VL 5
IS 2
BP 41
EP 50
DI 10.1016/j.visinf.2021.06.001
EA JUL 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA WN8QS
UT WOS:000712032300001
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Leite, RA
   Arleo, A
   Sorger, J
   Gschwandtner, T
   Miksch, S
AF Leite, Roger A.
   Arleo, Alessio
   Sorger, Johannes
   Gschwandtner, Theresia
   Miksch, Silvia
TI <i>Hermes</i>: Guidance-enriched Visual Analytics for economic network
   exploration
SO VISUAL INFORMATICS
LA English
DT Article
DE Data visualization; Economics; Network exploration; Supply chain
ID SYSTEM; DESIGN
AB The economy of a country can be modeled as a complex system in which several players buy and sell goods from each other. By analyzing the investment flows, it is possible to reconstruct the supply chain for the production of most goods, whose understanding is important to analysts and public officials interested in creating and evaluating strategies for informed and strategic decision making, for instance, adjusting tax policies. Those networks of players and investments, however, tend to be complex and very dense, which leads to over-plotted visualizations that obfuscate precious information such as the dependencies between productive sectors and regions. In this paper, we propose Hermes, a guidanceenriched Visual Analytics environment (named after the Greek God of Commerce) for the exploration of complex economic networks, to uncover supply chains, regions' productivity, and sector-to-sector relationships. With practical knowledge regarding guidance, we designed and implemented a visual sub-graph querying approach to extract patterns from such complex investment graphs obtained from real-world data.
   We present a three-fold evaluation of the system: we perform a qualitative evaluation of our approach with three domain experts, a separate assessment of the proposed guidance features with an expert researcher in this field, and a case study of Hermes using a bank account network dataset to demonstrate the generalizability of our approach. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Leite, Roger A.; Arleo, Alessio; Gschwandtner, Theresia; Miksch, Silvia] Vienna Univ Technol TU Wien, Vienna, Austria.
   [Sorger, Johannes] Complex Sci Hub Vienna, Vienna, Austria.
C3 Technische Universitat Wien
RP Leite, RA (corresponding author), Vienna Univ Technol TU Wien, Vienna, Austria.
EM roger.leite@tuwien.ac.at; alessio.arleo@tuwien.ac.at; sorger@csh.ac.at;
   theresia.gschwandtner@tuwien.ac.at; silvia.miksch@tuwien.ac.at
RI Arleo, Alessio/IRZ-8036-2023
OI Arleo, Alessio/0000-0003-2008-3651; Miksch, Silvia/0000-0003-4427-5703
FU Research Cluster "Smart Communities and Technologies (SmartCT)'' at TU
   Wien; Austrian Science Fund (FWF) [P31419-N31]; Austrian Science Fund
   (FWF) [P31419] Funding Source: Austrian Science Fund (FWF)
FX This work was partially supported by the Research Cluster "Smart
   Communities and Technologies (SmartCT)'' at TU Wien and the Austrian
   Science Fund (FWF), grant P31419-N31 Knowledge-Assisted Visual Analytics
   (KnoVA).
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Allen F., 2009, Networks in finance. The network challenge: Strategy, profit, and risk in an interlinked world
   Andrienko N, 2006, Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach
   [Anonymous], 2012, INFORM VISUAL
   Archambault D., 2012, P INT S GRAPH DRAW, P475
   Bigelow A, 2019, IEEE CONF VIS ANAL, P81, DOI [10.1109/VAST47406.2019.8986909, 10.1109/vast47406.2019.8986909]
   CENEDA D, 2018, VISUALIZATION DATA S
   Ceneda D., 2018, EUROVIS WORKSH VIS A
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Didimo W, 2018, DECIS SUPPORT SYST, V110, P71, DOI 10.1016/j.dss.2018.03.008
   Didimo W, 2015, LECT NOTES COMPUT SC, V9411, P272, DOI 10.1007/978-3-319-27261-0_23
   Didimo W, 2011, IEEE PAC VIS SYMP, P203, DOI 10.1109/PACIFICVIS.2011.5742391
   Duen Horng Chau, 2008, 2008 IEEE International Conference on Data Mining Workshops, P963, DOI 10.1109/ICDMW.2008.99
   Dumas M., 2014, POSTER ABSTRACTS IEE
   FRITZ O, 2003, AUSTR EC Q, V8, P23
   Fujiwara T, 2018, VIS INFORM, V2, P213, DOI 10.1016/j.visinf.2018.12.002
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Holten D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2299
   Horvitz Eric, 1999, P SIGCHI C HUM FACT, P159
   Huang ML, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P197, DOI 10.1109/IV.2009.23
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Klein G., 2013, SEEING WHAT OTHERS D
   Ko S, 2016, COMPUT GRAPH FORUM, V35, P599, DOI 10.1111/cgf.12931
   Koenig P.-Y., 2010, PROC C GRAPH INTERFA, P113
   Kriglstein S., 2018, EUROVIS WORKSH REPR
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Okoe M., 2018, IEEE T VIS COMPUT GR
   Pienta Robert, 2016, AVI, V2016, P272, DOI 10.1145/2909132.2909246
   Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107
   Tekusova T., 2008, ELECT IMAGING 2008
   Timmer MP, 2015, REV INT ECON, V23, P575, DOI 10.1111/roie.12178
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Wien W., 2019, SABINA INFO DATENBAN
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
NR 40
TC 8
Z9 8
U1 2
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2020
VL 4
IS 4
BP 11
EP 22
DI 10.1016/j.visinf.2020.09.006
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KZ
UT WOS:000658193600002
OA gold
DA 2024-07-18
ER

PT J
AU Mei, HH
   Guan, HH
   Xin, CY
   Wen, X
   Chen, W
AF Mei, Honghui
   Guan, Huihua
   Xin, Chengye
   Wen, Xiao
   Chen, Wei
TI DataV: Data Visualization on large high-resolution displays
SO VISUAL INFORMATICS
LA English
DT Article
DE Information visualization; Large high-resolution displays; Interactive
   design; Software-as-a-service
ID INFORMATION VISUALIZATION; DESIGN
AB In recent years, the technology and applications of visualizations on large high-resolution displays (LHDs) have received widespread attention because of its perceptual benefits and improved productivity. However, existing work on LHD visualization lacks both comprehensive guidance for design requirements and tools developed for its specific usage scenarios. In this paper, we present the scenarios, design, and implementation of DataV, a Software-as-a-Service (SaaS) visual deployment tool that enables rapid construction and cross-platform publishing of interactive visualization on LHDs. Our framework can support rich components for the high-performance rendering of multi-source heterogeneous data. DataV provides a full-fledged toolchain to help the user efficiently specify layout and interactions. We present its accessibility and impressive visual effects with examples and comparison with Tableau, Power BI, VisComposer, and iVisDesigner. We also report the performance of using DataV for 3D map rendering by comparing it with deck.gl. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Mei, Honghui; Guan, Huihua; Xin, Chengye; Wen, Xiao] Alibaba Grp, Hangzhou, Peoples R China.
   [Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Chen, Wei] Alibaba Zhejiang Univ, Joint Inst Frontier Technol, Hangzhou, Peoples R China.
C3 Alibaba Group; Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.; Chen, W (corresponding author), Alibaba Zhejiang Univ, Joint Inst Frontier Technol, Hangzhou, Peoples R China.
EM honghui.mhh@alibaba-inc.com; huihua.ghh@alibaba-inc.com;
   mier.cxy@taobao.com; ninglang.wx@taobao.com; chenwei@cad.zju.edu.cn
FU National Natural Science Foundation of China [61772456, 61761136020];
   Alibaba-Zhejiang University Joint Institute of Frontier Technologies
   (AZFT)
FX Wei Chen is supported by National Natural Science Foundation of China
   (61772456, 61761136020). This project is also partially funded by
   Alibaba-Zhejiang University Joint Institute of Frontier Technologies
   (AZFT).
CR Andrews C, 2011, INFORM VISUAL, V10, P341, DOI 10.1177/1473871611415997
   Ball R, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P191
   Bezerianos A, 2012, IEEE T VIS COMPUT GR, V18, P2516, DOI 10.1109/TVCG.2012.251
   Bradel L, 2013, INT J HUM-COMPUT ST, V71, P1078, DOI 10.1016/j.ijhcs.2013.07.004
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Heer J, 2008, LECT NOTES COMPUT SC, V4950, P92, DOI 10.1007/978-3-540-70956-5_5
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Mei H., 2016, J SOFTW
   Mei HH, 2018, VIS INFORM, V2, P71, DOI 10.1016/j.visinf.2018.04008
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Ni T, 2006, P IEEE VIRT REAL ANN, P223
   Reda K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2759, DOI 10.1145/2702123.2702406
   Ren DH, 2014, IEEE T VIS COMPUT GR, V20, P2092, DOI 10.1109/TVCG.2014.2346291
   Robinson AnthonyChristian., 2008, DESIGN SYNTHESIS GEO
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Stodder D., 2013, TDWI RES
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Wilkinson L., 2006, The grammar of graphics
   Yost B, 2006, IEEE T VIS COMPUT GR, V12, P837, DOI 10.1109/TVCG.2006.184
   Zhang TY, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-0428-2
NR 24
TC 15
Z9 16
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2020
VL 4
IS 3
BP 12
EP 23
DI 10.1016/j.visinf.2020.07.001
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KP
UT WOS:000658192600002
OA gold
DA 2024-07-18
ER

PT J
AU Zhu, SJ
   Sun, GD
   Jiang, Q
   Zha, M
   Liang, RH
AF Zhu, Sujia
   Sun, Guodao
   Jiang, Qi
   Zha, Meng
   Liang, Ronghua
TI A survey on automatic infographics and visualization recommendations
SO VISUAL INFORMATICS
LA English
DT Article
DE Automatic visualization; Data-driven; Knowledge-based; Machine learning;
   Visual embellishments
ID DESIGN; CHARTS; MODEL; TASK
AB Automatic infographics generators employ machine learning algorithms/user-defined rules and visual embellishments into the creation of infographics. It is an emerging topic in the field of information visualization that has requirements in many sectors, such as dashboard design, data analysis, and visualization recommendation. The growing popularity of visual analytics in recent years brings increased attention to automatic infographics. This creates the need for a broad survey that reviews and assesses the significant advances in this field. Automatic tools aim to lower the barrier for visually analyzing data by automatically generating visualizations for analysts to search and make a choice, instead of manually specifying. This survey reviews and classifies automatic tools and papers of visualization recommendations into a set of application categories including network-graph visualizations, annotation visualizations, and storytelling visualization. More importantly, this report presents several challenges and promising directions for future work in the field of automatic infographics and visualization recommendations. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Zhu, Sujia; Sun, Guodao; Jiang, Qi; Zha, Meng; Liang, Ronghua] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Zhejiang University of Technology
RP Sun, GD (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
EM guodao@zjut.edu.cn
RI Askamp, Leonie/GYU-0316-2022; liang, ronghua/H-4463-2012
FU National Natural Science Foundation of China [61972356, 61902350];
   Zhejiang Provincial Natural Science Foundation of China; Zhejiang
   Provincial Key Research and Development Program of China [2019C01009];
   Fundamental Research Funds for the Provincial Universities of Zhejiang
   [RF-C2019001]
FX This work is partly supported by National Natural Science Foundation of
   China (No. 61972356, 61902350), Zhejiang Provincial Natural Science
   Foundation of China (NO.LY19F020026), Zhejiang Provincial Key Research
   and Development Program of China (No. 2019C01009), and Fundamental
   Research Funds for the Provincial Universities of Zhejiang (NO.
   RF-C2019001).
CR Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2012, ACM
   [Anonymous], 2013, P 2013 CHI C HUMAN F, DOI [10.1145/2470654.2481374, DOI 10.1145/2470654.2481374]
   [Anonymous], 2018, 2018 International Joint Conference on Neural Networks (IJCNN), DOI 10.1145/2851141.2851145
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bastian M, 2009, GEPHI OPEN SOURCE SO
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Bigelow A, 2017, IEEE T VIS COMPUT GR, V23, P481, DOI 10.1109/TVCG.2016.2598609
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Bordegoni M, 1997, COMP STAND INTER, V18, P477, DOI 10.1016/S0920-5489(97)00013-5
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Burges C., 2005, ICML, P89
   Bylinskii Zoya, 2017, ARXIV170909215
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen F, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1166, DOI 10.1145/2623330.2623619
   Chen Y., 2010, CHI 10 EXTENDED ABST, P703
   Chen Y, 2009, IEEE PAC VIS SYMP, P49, DOI 10.1109/PACIFICVIS.2009.4906837
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Chu WT, 2015, IEEE T MULTIMEDIA, V17, P201, DOI 10.1109/TMM.2014.2383616
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Di Battista G., 1999, GRAPH DRAWING, V357
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   dos Santos Vieira R., 2015, Proc. International Conference on Information, Process, P112
   Duncan CA, 2011, LECT NOTES COMPUT SC, V6502, P195, DOI 10.1007/978-3-642-18469-7_18
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   Elmeleegy Hazem, 2008, 2008 IEEE International Conference on Web Services (ICWS), P337, DOI 10.1109/ICWS.2008.128
   ElSaid MG, 1997, COMPUT GRAPH, V21, P79, DOI 10.1016/S0097-8493(96)00072-6
   Frick A., 1994, INT S GRAPH DRAW, P388, DOI DOI 10.1007/3-540-58950-3_393
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gao T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3005, DOI 10.1145/2556288.2557228
   Garcia R.L., 2007, SOFTWARE PROCESS IMP
   GOLDSTEIN J, 1994, J VISUAL LANG COMPUT, V5, P339, DOI 10.1006/jvlc.1994.1020
   Gotz D, 2009, P 14 INT C INT US IN, P315, DOI [DOI 10.1145/1502650.1502695, 10.1145/1502650.15026951, DOI 10.1145/1502650.15026951]
   Grammarly, 2012, GRAMMARLY
   Grammel L., 2013, EUROVISSHORT PAPERS
   Hamilton W. L., 2017, Representation learning on graphs: methods and applications
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Henry N, 2006, IEEE T VIS COMPUT GR, V12, P677, DOI 10.1109/TVCG.2006.160
   Honghui M., 2018, VIS INF
   Hopkins A.K., 2020, P EUR C VIS
   Hu K., 2019, CHI 2019 P 2019 CHI, P1
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Johnson r.A., 2018, ARXIV181008061
   Kandogan E, 2012, IEEE CONF VIS ANAL, P73, DOI 10.1109/VAST.2012.6400487
   Ke MT, 2013, NAT NEUROSCI, V16, P1154, DOI 10.1038/nn.3447
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kipf T.N., 2016, BAYESIAN DEEP LEARNI
   Kong HK, 2017, COMPUT GRAPH FORUM, V36, P515, DOI 10.1111/cgf.13207
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   KOSAK C, 1994, IEEE T SYST MAN CYB, V24, P440, DOI 10.1109/21.278993
   Lai C., 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, P1
   Lampert C.H., 2008, PROC CVPR IEEE, P1
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lu JF, 2021, IEEE T COMPUT SOC SY, V8, P246, DOI 10.1109/TCSS.2020.2964284
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Marks J., 1991, Journal of Visual Languages and Computing, V2, P395, DOI 10.1016/S1045-926X(05)80006-0
   Marks J., 1990, Proceedings of the 1990 IEEE Workshop on Visual Languages (Cat. No.90TH0330-1), P104, DOI 10.1109/WVL.1990.128390
   Marks J.W, 1991, AUTOMATING DESIGN NE
   Mauri M., 2017, P 12 BIANN C IT SIGC, DOI DOI 10.1145/3125571.3125585
   Mei HH, 2018, VIS INFORM, V2, P71, DOI 10.1016/j.visinf.2018.04008
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Mendez GG, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P841, DOI 10.1145/3025453.3025942
   Mittal VO, 1998, COMPUT LINGUIST, V24, P431
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Ou MD, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1105, DOI 10.1145/2939672.2939751
   Pantazos Kostas, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P731
   Park JH, 2018, IEEE COMPUT GRAPH, V38, P67, DOI 10.1109/MCG.2018.2879066
   Pioch N.J., 2006, P CIKM, P513, DOI DOI 10.1145/1183614.1183688
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ren DH, 2014, IEEE T VIS COMPUT GR, V20, P2092, DOI 10.1109/TVCG.2014.2346291
   Retrieval F.T.I.I, 2010, INT ACM SIGIR C RES
   Roth S. F., 1990, SIGCHI Bulletin, P193
   Roth S. F., 1991, Proceedings. Seventh IEEE Conference on Artificial Intelligence Applications (Cat. No.91CH2967-8), P90, DOI 10.1109/CAIA.1991.120851
   Roth S.F., 1995, C COMP HUM FACT COMP, P409
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Saket B, 2018, IEEE T VIS COMPUT GR, V24, P1316, DOI 10.1109/TVCG.2017.2680452
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Soares A, 2017, IEEE COMPUT GRAPH, V37, P28, DOI 10.1109/MCG.2017.3621221
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sun GD, 2013, J COMPUT SCI TECH-CH, V28, P852, DOI 10.1007/s11390-013-1383-8
   Tang B, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1509, DOI 10.1145/3035918.3035922
   Valizadegan R., 2009, ADV NEURAL INFORM PR
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wen MH, 2012, CONF TECHNOL APPL, P314, DOI 10.1109/TAAI.2012.28
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   Wongsuphasawat K, 2016, P WORKSH HUM IN THE, P1, DOI [10.1145/2939502.2939506, 10.1145/2939502.29395061,2,3,9, DOI 10.1145/2939502.29395061,2,3,9]
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wun T, 2016, COMPUT GRAPH FORUM, V35, P111, DOI 10.1111/cgf.12887
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu K., 2020, SURVEY ANAL USER INT
   Xu K, 2012, IEEE T VIS COMPUT GR, V18, P2449, DOI 10.1109/TVCG.2012.189
   Yang Chen, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P155, DOI 10.1109/VAST.2010.5652885
   You Jiaxuan., 2018, CoRR
   Yu L, 2010, COMPUT GRAPH FORUM, V29, P2271, DOI 10.1111/j.1467-8659.2010.01816.x
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhe C., 2018, INFORM VISUAL
NR 119
TC 45
Z9 47
U1 2
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2020
VL 4
IS 3
BP 24
EP 40
DI 10.1016/j.visinf.2020.07.002
PG 17
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KP
UT WOS:000658192600003
OA gold
DA 2024-07-18
ER

PT J
AU Zhu, LC
   Li, M
   Xu, WW
AF Zhu, Liangchao
   Li, Ming
   Xu, Weiwei
TI Direct design to stress mapping for cellular structures
SO VISUAL INFORMATICS
LA English
DT Article
DE Instant simulation; Parametric solution; Cellular structures; Proper
   generalized decomposition (PGD); Model reduction
ID OPTIMIZATION; DECOMPOSITION; REDUCTION; SOLVERS; FAMILY
AB This paper aims to instantly predict within any accuracy the stress distribution of cellular structures under parametric design, including the shapes or distributions of the cell geometries, or the magnitudes of external loadings. A classical model reduction technique has to balance the simulation accuracy and interaction speed, and has difficulty achieving this goal. We achieve this by computing offline a design-to-stress mapping that ultimately expresses the stress distribution as an explicit function in terms of its design parameters. The mapping is determined as a solution to an extended finite element analysis problem in a high-dimension space, including both the spatial coordinates and the design parameters. The well-known curse of dimensionality intrinsic to the high-dimension problem is (partly) resolved through a spatial separation using two main techniques. First, the target mapping takes a reduced form as a sum of the products of separated one-variable functions, extending the proper generalized decomposition technique. Second, the simulation problem in a varied computation domain is reformulated as that in a fixed-domain, taking an integration function as the sum of the products of separated one-variable functions, in combination with high-order singular value decomposition. Extensive 2D and 3D examples are shown to demonstrate the approach's performance. (C) 2019 Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press.
C1 [Zhu, Liangchao; Li, Ming; Xu, Weiwei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Li, M (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM liming@cad.zju.edu.cn
FU National Key Research and Development Program of China [2018YFB1700603];
   NSF of China [61872320]
FX The work described in this paper is partially supported by the National
   Key Research and Development Program of China (No. 2018YFB1700603) and
   the NSF of China (No. 61872320).
CR Ammar A, 2007, J NON-NEWTON FLUID, V144, P98, DOI 10.1016/j.jnnfm.2007.03.009
   Ammar A, 2006, J NON-NEWTON FLUID, V139, P153, DOI 10.1016/j.jnnfm.2006.07.007
   Andreassen E, 2014, COMP MATER SCI, V83, P488, DOI 10.1016/j.commatsci.2013.09.006
   ASHBY MF, 1983, METALL TRANS A, V14, P1755, DOI 10.1007/BF02645546
   Bader B.W., 2017, 0000 MATLAB TENSOR T
   Barbic J., 2012, ACM SIGGRAPH 2012 CO, P1
   Barbic J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964986
   BENDSOE MP, 1988, COMPUT METHOD APPL M, V71, P197, DOI 10.1016/0045-7825(88)90086-2
   Bialecki RA, 2005, INT J NUMER METH ENG, V62, P774, DOI 10.1002/nme.1205
   Chen J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201386
   Chen X, 2017, IEEE T VIS COMPUT GR, V23, P2314, DOI 10.1109/TVCG.2016.2618875
   Chen Y., 2008, Computer-aided Design and Application, V5, P565
   Chen Yong., 2007, COMPUTER AIDED DESIG, V4, P761
   Chinesta F, 2011, J NON-NEWTON FLUID, V166, P578, DOI 10.1016/j.jnnfm.2010.12.012
   Chinesta F, 2011, ARCH COMPUT METHOD E, V18, P395, DOI 10.1007/s11831-011-9064-7
   Chinesta F, 2010, ARCH COMPUT METHOD E, V17, P327, DOI 10.1007/s11831-010-9049-y
   Cueto E., 2016, Proper generalized decompositions: an introduction to computer implementation with matlab
   Falcó A, 2011, J MATH ANAL APPL, V376, P469, DOI 10.1016/j.jmaa.2010.12.003
   Fleck NA, 2010, P ROY SOC A-MATH PHY, V466, P2495, DOI 10.1098/rspa.2010.0215
   Fullwood DT, 2010, PROG MATER SCI, V55, P477, DOI 10.1016/j.pmatsci.2009.08.002
   Ganapathysubramanian B, 2007, J COMPUT PHYS, V226, P326, DOI 10.1016/j.jcp.2007.04.009
   Gibson L. J., 1997, Cellular Solids: Structure and Properties
   Gielis J, 2003, AM J BOT, V90, P333, DOI 10.3732/ajb.90.3.333
   Huang XD, 2015, COMPUT METHOD APPL M, V283, P503, DOI 10.1016/j.cma.2014.10.007
   Kim DY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462020
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lamari H, 2010, ARCH COMPUT METHOD E, V17, P373, DOI 10.1007/s11831-010-9051-4
   Li SW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601217
   Liu XC, 2017, COMPUT AIDED DESIGN, V90, P199, DOI 10.1016/j.cad.2017.05.013
   Lu L, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601168
   Olson GB, 1997, SCIENCE, V277, P1237, DOI 10.1126/science.277.5330.1237
   Panchal JH, 2013, COMPUT AIDED DESIGN, V45, P4, DOI 10.1016/j.cad.2012.06.006
   Panetta J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073649
   Panetta J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766937
   Regli W, 2016, COMPUT AIDED DESIGN, V77, P73, DOI 10.1016/j.cad.2016.03.002
   Rodrigues H, 2002, STRUCT MULTIDISCIP O, V24, P1, DOI 10.1007/s00158-002-0209-z
   Rvachev VL, 1995, Appl Mech Rev, V48, P151
   Schulz A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073688
   Schumacher C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766926
   Shapiro V., 1991, THEORY R FUNCTIONS A
   SIGMUND O, 1994, INT J SOLIDS STRUCT, V31, P2313, DOI 10.1016/0020-7683(94)90154-6
   Sigmund O, 2013, STRUCT MULTIDISCIP O, V48, P1031, DOI 10.1007/s00158-013-0978-6
   Treuille A, 2006, ACM T GRAPHIC, V25, P826, DOI 10.1145/1141911.1141962
   Umetani N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964985
   Wang LF, 2012, INT J SOLIDS STRUCT, V49, P2881, DOI 10.1016/j.ijsolstr.2012.05.008
   Wang WM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508382
   Wu J, 2018, IEEE T VIS COMPUT GR, V24, P1127, DOI 10.1109/TVCG.2017.2655523
   Wu J, 2016, IEEE T VIS COMPUT GR, V22, P1195, DOI 10.1109/TVCG.2015.2502588
   Xu C, 2017, COMPUT STRUCT, V182, P284, DOI 10.1016/j.compstruc.2016.12.006
   Xu C, 2017, COMP MATER SCI, V130, P39, DOI 10.1016/j.commatsci.2016.12.031
   Xu HY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699648
   Zhu B, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3095815
   Zhu LC, 2016, COMPUT AIDED DESIGN, V78, P3, DOI 10.1016/j.cad.2016.05.006
NR 53
TC 2
Z9 2
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2019
VL 3
IS 2
BP 69
EP 80
DI 10.1016/j.visinf.2019.07.002
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YK
UT WOS:000658189200002
OA gold
DA 2024-07-18
ER

PT J
AU Hu, H
   Wang, S
   Chen, YH
AF Hu, Hao
   Wang, Song
   Chen, Yonghui
TI IVMS: An immersive virtual meteorological sandbox based on WYSIWYG
SO VISUAL INFORMATICS
LA English
DT Article
DE Immersive Analytics; WYSIWYG; Virtual sanbox; Immersive meteorological
   visualization
ID VISUALIZATION
AB A novel approach to visually represent meteorological data has emerged with the maturation of Immersive Analytics (IA). We have proposed an immersive meteorological virtual sandbox as a solution to the limitations of 2D analysis in expressing and perceiving data. This innovative visual method enables users to interact directly with data through non-contact aerial gestures (NCAG). Referring to the "What you see is what you get"concept in scientific visualization, we proposed a novel approach for the visual exploration of meteorological data that aims to immerse users in the analysis process. We hope this approach can inspire immersive visualization techniques for other types of geographic data as well. Finally, we conducted a user questionnaire to evaluate our system and work. The evaluation results demonstrate that our system effectively reduces cognitive burden, alleviates mental workload, and enhances users' retention of analysis findings.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Hu, Hao; Wang, Song; Chen, Yonghui] Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang, Peoples R China.
C3 Southwest University of Science & Technology - China
RP Wang, S (corresponding author), Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang, Peoples R China.
EM wangsong@swust.edu.cn
RI HU, Hao/GWD-0099-2022; wang, song/N-5543-2014
OI HU, Hao/0000-0002-2008-3822; wang, song/0000-0002-7047-8726
FU Natural Science Foundation of Sichuan Province [2022NSFSC0961]; Ph.D.
   Research Foundation of Southwest University of Science and Technology
   [19zx7144]; Special Research Foundation of China (Mianyang) Science and
   Technology City Network Emergency Management Research Center
   [WLYJGL2023ZD04]
FX This work was supported by Natural Science Foundation of Sichuan
   Province (Grant No. 2022NSFSC0961) the Ph.D. Research Foundation of
   Southwest University of Science and Technology (Grant No. 19zx7144) the
   Special Research Foundation of China (Mianyang) Science and Technology
   City Network Emergency Management Research Center (Grant No.
   WLYJGL2023ZD04) .
CR Bo Sun, 2019, 2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS). Proceedings, P24
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Gautier J, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P71, DOI 10.1109/VIS47514.2020.00021
   Goncalves T., 2016, P 30 INT BCS HUM COM, DOI [10.14236/ewic/HCI2016.22, DOI 10.14236/EWIC/HCI2016.22]
   Guo HQ, 2011, IEEE T VIS COMPUT GR, V17, P2106, DOI 10.1109/TVCG.2011.261
   Korunoski M, 2019, PROCEEDINGS OF 18TH INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES (IEEE EUROCON 2019), DOI 10.1109/eurocon.2019.8861609
   Kotlarek J, 2020, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis48177.2020.4722
   Ling Ma, 2020, 2020 International Conference on Computer Information and Big Data Applications (CIBDA). Proceedings, P60, DOI 10.1109/CIBDA50819.2020.00022
   Mathews NS, 2020, Arxiv, DOI arXiv:2006.02136
   Samee I.U., 2019, P 2019 4 INT C EM TR, P2, DOI [10.1109/ICEEST48626.2019.8981707, DOI 10.1109/ICEEST48626.2019.8981707]
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Skarbez R, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00082
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Treinish LA, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P549, DOI 10.1109/VISUAL.2002.1183827
   Urribarri DK, 2022, COMPUT GRAPH-UK, V104, P1, DOI 10.1016/j.cag.2022.02.011
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   Wang S, 2020, IEEE PAC VIS SYMP, P166, DOI 10.1109/PacificVis48177.2020.1001
   Wiss U, 1998, IEEE INFOR VIS, P137, DOI 10.1109/IV.1998.694211
   Wu BJ, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1882
   Yadav Suman Avdhesh, 2020, 2020 International Conference on Intelligent Engineering and Management (ICIEM), P29, DOI 10.1109/ICIEM48762.2020.9160110
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   [叶帅男 Ye Shuainan], 2021, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V33, P497
   Yuan HL, 2016, INT GEOSCI REMOTE SE, P5724, DOI 10.1109/IGARSS.2016.7730495
NR 24
TC 1
Z9 1
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 100
EP 109
DI 10.1016/j.visinf.2023.08.001
EA DEC 2023
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DX4L1
UT WOS:001135368800001
OA gold
DA 2024-07-18
ER

PT J
AU Hu, TX
   Zheng, H
   Liang, C
   Zhu, SR
   Imirzian, N
   Zhang, YZ
   Wang, CL
   Hughes, DP
   Chen, DZ
AF Hu, Tianxiao
   Zheng, Hao
   Liang, Chen
   Zhu, Sirou
   Imirzian, Natalie
   Zhang, Yizhe
   Wang, Chaoli
   Hughes, David P.
   Chen, Danny Z.
TI AntVis: A web-based visual analytics tool for exploring ant movement
   data
SO VISUAL INFORMATICS
LA English
DT Article
DE Ant movement; Object detection; Image segmentation; Visual analytics;
   Knowledge discovery
ID AGGREGATION; EXPLORATION
AB We present AntVis, a web-based visual analytics tool for exploring ant movement data collected from the video recording of ants moving on tree branches. Our goal is to enable domain experts to visually explore massive ant movement data and gain valuable insights via effective visualization, filtering, and comparison. This is achieved through a deep learning framework for automatic detection, segmentation, and labeling of ants, ant movement clustering based on their trace similarity, and the design and development of five coordinated views (the movement, similarity, timeline, statistical, and attribute views) for user interaction and exploration. We demonstrate the effectiveness of AntVis with several case studies developed in close collaboration with domain experts. Finally, we report the expert evaluation conducted by an entomologist and point out future directions of this study. (C) 2020 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Hu, Tianxiao] Facebook Inc, Menlo Pk, CA 94025 USA.
   [Zheng, Hao; Zhang, Yizhe; Wang, Chaoli; Chen, Danny Z.] Univ Notre Dame, Notre Dame, IN 46556 USA.
   [Liang, Chen; Zhu, Sirou] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Imirzian, Natalie; Hughes, David P.] Penn State Univ, University Pk, PA 16802 USA.
C3 Facebook Inc; University of Notre Dame; Carnegie Mellon University;
   Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park
RP Zheng, H (corresponding author), Univ Notre Dame, Notre Dame, IN 46556 USA.
EM tianxiaohu@fb.com; hzheng3@nd.edu; liangchendlj@gmail.com;
   srzhu97@gmail.com; nsi2@psu.edu; yzhang29@nd.edu; chaoli.wang@nd.edu;
   dhughes@psu.edu; dchen@nd.edu
RI ray, jay/GYV-3810-2022; zheng, hao/HHM-6949-2022; zheng,
   hao/JQI-4215-2023; Wang, Chaoli/AAJ-5173-2020
OI Wang, Chaoli/0000-0002-0859-3619; Zhu, Sirou/0000-0002-1999-2447; Zheng,
   Hao/0000-0002-9790-7607; Imirzian, Natalie/0000-0003-4977-0404
FU US National Science Foundation [IIS-1456763, IIS-1455886, CNS-1629914,
   CCF-1617735, DUE-1833129]; US National Institutes of Health [R01
   GM116927]
FX This research was supported in part by the US National Science
   Foundation through grants IIS-1456763, IIS-1455886, CNS-1629914,
   CCF-1617735, and DUE-1833129, and by the US National Institutes of
   Health through grant R01 GM116927. T. Hu, S. Zhu, and C. Liang conducted
   this work as iSURE (International Summer Undergraduate Research
   Experience) students at the University of Notre Dame during Summer 2017.
CR Al-Dohuki S, 2017, IEEE T VIS COMPUT GR, V23, P11, DOI 10.1109/TVCG.2016.2598416
   Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Andrienko G, 2018, IEEE T VIS COMPUT GR, V24, P34, DOI 10.1109/TVCG.2017.2744322
   Andrienko G, 2008, IEEE S VIS ANAL, P51, DOI 10.1109/VAST.2008.4677356
   Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   Bang PX, 2019, I S BIOMED IMAGING, P339, DOI [10.1109/isbi.2019.8759430, 10.1109/ISBI.2019.8759430]
   Cao N, 2018, IEEE T VIS COMPUT GR, V24, P23, DOI 10.1109/TVCG.2017.2744419
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen JX, 2016, I S BIOMED IMAGING, P968, DOI 10.1109/ISBI.2016.7493426
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Doraiswamy H, 2014, IEEE T VIS COMPUT GR, V20, P2634, DOI 10.1109/TVCG.2014.2346449
   Fourcassié V, 2010, J EXP BIOL, V213, P2357, DOI 10.1242/jeb.031237
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Greene MJ, 2007, AM NAT, V170, P943, DOI 10.1086/522843
   Hartmann G, 2012, LECT NOTES COMPUT SC, V7583, P198, DOI 10.1007/978-3-642-33863-2_20
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   Imirzian N, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49655-3
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Wang YW, 2016, INT J GEOGR INF SCI, V30, P929, DOI 10.1080/13658816.2015.1091462
   Wang ZC, 2014, IEEE T VIS COMPUT GR, V20, P1813, DOI 10.1109/TVCG.2014.2346746
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Zhang DW, 2017, PROC CVPR IEEE, P5340, DOI 10.1109/CVPR.2017.567
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang Y, 2015, PROC CVPR IEEE, P3641, DOI 10.1109/CVPR.2015.7298987
   Zheng H, 2019, LECT NOTES COMPUT SC, V11765, P759, DOI 10.1007/978-3-030-32245-8_84
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
NR 43
TC 6
Z9 7
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2020
VL 4
IS 1
BP 58
EP 70
DI 10.1016/j.visinf.2020.02.001
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KB
UT WOS:000658191200006
OA gold
DA 2024-07-18
ER

PT J
AU Ren, MJ
   Nie, WZ
   Liu, AA
   Su, YT
AF Ren, Minjie
   Nie, Weizhi
   Liu, Anan
   Su, Yuting
TI Multi-modal Correlated Network for emotion recognition in speech
SO VISUAL INFORMATICS
LA English
DT Article
DE Multi-modal; Emotion recognition; Neural networks
AB With the growing demand of automatic emotion recognition system, emotion recognition is becoming more and more crucial for human-computer interaction (HCI) research. Recently, there is a continuous improvement in the performance of automatic emotion recognition due to the development of both hardware and deep learning methods. However, because of the abstract concept and multiple expressions of emotion, automatic emotion recognition is still a challenging task. In this paper, we propose a novel Multi-modal Correlated Network for emotion recognition aiming at exploiting the information from both audio and visual channels to achieve more robust and accurate detection. In the proposed method, the audio signals and visual signals are first preprocessed for the feature extraction. After preprocessing, we obtain the Mel-spectrograms, which can be treated as images, and the representative frames from visual segments. Then the Mel-spectrograms are fed to the convolutional neural network (CNN) to get the audio features and the representative frames are fed to the CNN and LSTM to get features. Specially, we employ the triplet loss to increase the differentiation of inter-class. Meanwhile, we propose a novel correlated loss to reduce the differentiation of intra-class. Finally, we apply the feature fusion method to fuse the audio and visual feature for emotion recognition classification. The experimental result on AEFW dataset demonstrates the correlation information of multiple modals is crucial for automatic emotion recognition and the proposed method can achieve the state-of-the-art performance on the classification task. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Ren, Minjie; Nie, Weizhi; Liu, Anan; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Nie, WZ; Liu, AA (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM weizhinie@tju.edu.cn; anan0422@gmail.com
RI Nie, Weizhi/ABF-5316-2021; lu, lala/GQQ-3784-2022
OI lu, lala/0000-0002-6080-8074; nie, weizhi/0000-0002-0578-8138
CR [Anonymous], 2017, ARXIV170709917
   Bargal SA, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P433, DOI 10.1145/2993148.2997627
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cai J, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P443, DOI 10.1109/MIPR.2019.00089
   Chen M, 2018, IEEE COMMUN MAG, V56, P164, DOI 10.1109/MCOM.2018.1700274
   Chen M, 2017, MOBILE NETW APPL, V22, P1159, DOI 10.1007/s11036-017-0866-1
   Darwin C., 1872, P374
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Ding W, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P506, DOI 10.1145/2993148.2997637
   Doctor Faiyaz, 2016, 2016 IEEE S SERIES C, P1, DOI DOI 10.1109/SSCI.2016.7850044
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Guthier Benjamin., 2014, Proceedings of the 1st International Workshop on Emerging Multimedia Applications and Services for Smart Cities - EMASC'14, P23, DOI DOI 10.1145/2661704.2661708
   Han K, 2014, INTERSPEECH, P223
   Han WJ, 2018, INTERSPEECH, P932, DOI 10.21437/Interspeech.2018-1858
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hossain MS, 2018, MOBILE NETW APPL, V23, P239, DOI 10.1007/s11036-017-0928-4
   Hossain MS, 2017, IEEE ACCESS, V5, P2281, DOI 10.1109/ACCESS.2017.2672829
   Hu P, 2017, P 19 ACM INT C MULT, P553, DOI DOI 10.1145/3136755.3143009
   Huang, 2018, CVPR
   Huang D.-Y., 2017, P 19 ACM INT C MULT, P577, DOI DOI 10.1145/3136755.3143012
   Huang XH, 2016, COMPUT VIS IMAGE UND, V147, P114, DOI 10.1016/j.cviu.2015.09.015
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kim D.H., 2017, P ICMI 2017 19 ACM I, P529, DOI [10.1145/3136755.3143005, DOI 10.1145/3136755.3143005]
   Koerich, 2019, CVPR
   Lin K, 2016, IEEE ACCESS, V4, P6901, DOI 10.1109/ACCESS.2016.2616643
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Mahoor, 2019, 14 IEEE INT C AUT FA
   Mao SY, 2019, INT CONF ACOUST SPEE, P6715, DOI 10.1109/ICASSP.2019.8683172
   Menezes MLR, 2017, PERS UBIQUIT COMPUT, V21, P1003, DOI 10.1007/s00779-017-1072-7
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Sun B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061407
   Tao J., 2008, BLIZZARD CHALLENGE 2
   Tian Q, 2017, IEEE T CIRC SYST VID, V99
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Vielzeuf V., 2017, P 19 ACM INT C MULT, P569
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu JL, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P464, DOI 10.1145/2993148.2997631
   Yan JW, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P458, DOI 10.1145/2993148.2997630
   Yao AB, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P472, DOI 10.1145/2993148.2997639
   Yao AB, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P451, DOI 10.1145/2818346.2830585
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517
NR 47
TC 18
Z9 19
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2019
VL 3
IS 3
BP 150
EP 155
DI 10.1016/j.visinf.2019.10.003
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YL
UT WOS:000658189600004
OA gold
DA 2024-07-18
ER

PT J
AU Firat, EE
   Denisova, A
   Wilson, ML
   Laramee, RS
AF Firat, Elif E.
   Denisova, Alena
   Wilson, Max L.
   Laramee, Robert S.
TI P-Lite: A study of parallel coordinate plot literacy
SO VISUAL INFORMATICS
LA English
DT Article
DE Human-centered computing; Visualization systems and tool; Empirical
   studies in visualization
ID VISUALIZATION; EXPLORATION
AB Visualization literacy, the ability to interpret and comprehend visual designs, is recognized as an essential skill by the visualization community. We identify and investigate barriers to comprehending parallel coordinates plots (PCPs), one of the advanced graphical representations for the display of multivariate and high-dimensional data. We develop a parallel coordinates literacy test with diverse images generated using popular PCP software tools. The test improves PCP literacy and evaluates the user's literacy skills. We introduce an interactive educational tool that assists the teaching and learning of parallel coordinates by offering a more active learning experience. Using this pedagogical tool, we aim to advance novice users' parallel coordinates literacy skills. Based on the hypothesis that an interactive tool that links traditional Cartesian Coordinates with PCPs interactively will enhance PCP literacy further than static slides, we compare the learning experience using traditional slides with our novel software tool and investigate the efficiency of the educational software with an online, crowdsourced user-study. User-study results show that our pedagogical tool positively impacts a user's PCP comprehension.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Firat, Elif E.; Wilson, Max L.; Laramee, Robert S.] Univ Nottingham, Sch Comp Sci, Nottingham, England.
   [Denisova, Alena] Univ York, Dept Comp Sci, York, England.
C3 University of Nottingham; University of York - UK
RP Firat, EE (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham, England.
EM elif.firat@nottingham.ac.uk
RI Denisova, Alena/AAQ-2340-2020; Firat, Elif E/HKE-7954-2023
OI Denisova, Alena/0000-0002-1497-5808; Firat, Elif E/0000-0001-9497-7928;
   Laramee, Robert S/0000-0002-3874-6145
FU EPSRC Grant EPSRC; Ministry of Ed-ucation of the Turkish Republic; 
   [EP/S010238/2]
FX Acknowledgment This research was funded in part by EPSRC Grant EPSRC
   EP/S010238/2. We would also like to thank the Ministry of Ed-ucation of
   the Turkish Republic for their financial support.
CR Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   AMT, 2020, AM MECH TURK
   [Anonymous], IEEE Transactions on Visualization and Computer Graphics
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2018, COMPUT GRAPH FORUM, V37, P573, DOI 10.1111/cgf.13444
   Borner K., 2019, IEEE T VIS COMPUT GR
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brodbeck D., 2021, HIGH D TOOL
   Brodbeck D., 2021, HIGH D DATASETS
   Claessen JHT, 2011, IEEE T VIS COMPUT GR, V17, P2310, DOI 10.1109/TVCG.2011.201
   Cook D., 2021, GGOBI DATA VISUALIZA
   Dasgupta A, 2012, COMPUT GRAPH FORUM, V31, P1015, DOI 10.1111/j.1467-8659.2012.03094.x
   DeRochefort E, 2021, XDAT TOOL FREE PARAL
   Doerfler R, 2021, SLIVER TOOL MULTIVAR
   Firat E.E., 2020, INSTRUCTIONS EXPT VI
   Firat E. E., 2020, Eurographics 2020-Education Papers, P29, DOI DOI 10.2312/EGED.20201032
   Firat E.E., 2020, INTRO PARALLEL COORD
   Firat E.E., 2020, PARALLEL COORDINATES
   Firat E. E., 2018, CGVC, P91
   Firat E.E., 2020, TOOL SUPPORT PARALLE
   Firat EE, 2022, IEEE COMPUT GRAPH, V42, P99, DOI 10.1109/MCG.2022.3161767
   Firat EE, 2022, INFORM VISUAL, V21, P285, DOI 10.1177/14738716221081831
   Heinrich J, 2012, EUROGRAPHICS STATE A, P22, DOI [10.2312/conf/EG2013/stars/095-116, DOI 10.2312/CONF/EG2013/STARS/095-116]
   IBM Corporation, 2021, IBM SPSS statistics for windows.Version 21.0
   Inselberg A., 2009, Parallel Coordinates. Visual Multidimensional Geometry and its Applications, DOI DOI 10.1007/978-0-387-68628-8
   Johansson J, 2016, IEEE T VIS COMPUT GR, V22, P579, DOI 10.1109/TVCG.2015.2466992
   Kanjanabose R, 2015, COMPUT GRAPH FORUM, V34, P261, DOI 10.1111/cgf.12638
   Kim Sung-Hee, 2014, IEEEVIS 2014 WORKSH
   Kirk A, 2020, VISUALIZING DATA
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Kwon BC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P993, DOI 10.1145/2858036.2858101
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lima M, 2014, BOOK TREES VISUALIZI, V5
   Lind M, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P25, DOI 10.1109/IV.2009.43
   Liu XX, 2021, IEEE INT CONF INF VI, P160, DOI 10.1109/IV53921.2021.00034
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Powerbi, 2021, MICR POWERBI
   Quadrigam, 2021, QUADR TOOL
   Reas C., 2003, GRAPH 03 P SIGGRAPH, P1
   Reckase MD, 2009, STAT SOC BEHAV SC, P79, DOI 10.1007/978-0-387-89976-3_4
   Rees D, 2019, COMPUT GRAPH FORUM, V38, P610, DOI 10.1111/cgf.13595
   Romero Mario, 2014, EUROVIS WORKSH
   Rosenbaum R, 2012, IEEE PAC VIS SYMP, P25, DOI 10.1109/PacificVis.2012.6183570
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Siirtola H, 2003, INTERNATIONAL CONFERENCE ON COORDINATED AND MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P63, DOI 10.1109/CMV.2003.1215004
   Siirtola H, 2006, INTERACT COMPUT, V18, P1278, DOI 10.1016/j.intcom.2006.03.006
   Smith R., 2020, QUALTRICS
   Theus M, 2021, MONDRIAN TOOL
   Tibco, 2021, SPOTF TOOL
   Ward M., 2015, Interactive data visualization: Foundations, techniques, and applications
   Ward M.O, 2021, XMDV TOOL
   Ward M.O, 2020, XMDV DATASETS
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Yang J, 2003, COMPUT GRAPH-UK, V27, P265, DOI 10.1016/S0097-8493(02)00283-2
NR 58
TC 3
Z9 3
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2022
VL 6
IS 3
BP 81
EP 99
DI 10.1016/j.visinf.2022.05.002
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 5U7AG
UT WOS:000876695000002
OA gold
DA 2024-07-18
ER

PT J
AU Ritter, M
   Schiffner, D
   Harders, M
AF Ritter, Marcel
   Schiffner, Daniel
   Harders, Matthias
TI Robust reconstruction of curved line structures in noisy point clouds
SO VISUAL INFORMATICS
LA English
DT Article
DE Computational geometry; Noisy point clouds; Line reconstruction;
   Automatic; Adaptive control
ID SURFACE GEOMETRY; TRACTOGRAPHY; COMPUTATION
AB Point-based geometry representations have become widely used in numerous contexts, ranging from particle-based simulations, over stereo image matching, to depth sensing via light detection and ranging. Our application focus is on the reconstruction of curved line structures in noisy 3D point cloud data. Respective algorithms operating on such point clouds often rely on the notion of a local neighborhood. Regarding the latter, our approach employs multi-scale neighborhoods, for which weighted covariance measures of local points are determined. Curved line structures are reconstructed via vector field tracing, using a bidirectional piecewise streamline integration. We also introduce an automatic selection of optimal starting points via multi-scale geometric measures. The pipeline development and choice of parameters was driven by an extensive, automated initial analysis process on over a million prototype test cases. The behavior of our approach is controlled by several parameters - the majority being set automatically, leaving only three to be controlled by a user. In an extensive, automated final evaluation, we cover over one hundred thousand parameter sets, including 3D test geometries with varying curvature, sharp corners, intersections, data holes, and systematically applied varying types of noise. Further, we analyzed different choices for the point of reference in the co-variance computation; using a weighted mean performed best in most cases. In addition, we compared our method to current, publicly available line reconstruction frameworks. Up to thirty times faster execution times were achieved in some cases, at comparable error measures. Finally, we also demonstrate an exemplary application on four real-world 3D light detection and ranging datasets, extracting power line cables. (C) 2021 The Author( s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Ritter, Marcel; Harders, Matthias] Univ Innsbruck, Dept Comp Sci, Interact Graph & Simulat Grp, Innsbruck, Austria.
   [Ritter, Marcel] Airborne Hydromapping GmbH, Innsbruck, Austria.
   [Schiffner, Daniel] DIPF Leibniz Inst Res & Informat Educ, Frankfurt, Germany.
C3 University of Innsbruck
RP Ritter, M (corresponding author), Univ Innsbruck, Dept Comp Sci, Interact Graph & Simulat Grp, Innsbruck, Austria.
EM marcel.ritter@uibk.ac.at; Schiffner@dipf.de; matthias.harders@uibk.ac.at
OI Ritter, Marcel/0000-0003-4495-4546; Schiffner,
   Daniel/0000-0002-0794-0359
FU University of Innsbruck
FX This research was funded through the Vice Rectorate of Research of the
   University of Innsbruck within the scope of the doctoral program
   Computational Interdisciplinary Modelling (DK CIM).
CR Alexa M., 2004, SPBG 04 S POINT BAS
   [Anonymous], 1997, Proceedings of ISMRM, page
   Basser PJ, 2000, MAGNET RESON MED, V44, P625, DOI 10.1002/1522-2594(200010)44:4<625::AID-MRM17>3.0.CO;2-O
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Berger M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451246
   BERKMANN J, 1994, IEEE T PATTERN ANAL, V16, P1114, DOI 10.1109/34.334391
   Chou MC, 2006, J MAGN RESON IMAGING, V24, P451, DOI 10.1002/jmri.20652
   DeVore R, 2013, SIAM J IMAGING SCI, V6, P1, DOI 10.1137/110856009
   Dey TK, 2001, COMP GEOM-THEOR APPL, V19, P89, DOI 10.1016/S0925-7721(01)00015-3
   Eiselt HA, 2011, INT SER OPER RES MAN, V155, P1, DOI 10.1007/978-1-4419-7572-0
   Flöry S, 2009, COMPUT AIDED GEOM D, V26, P192, DOI 10.1016/j.cagd.2008.04.003
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Giraudot S, 2013, COMPUT GRAPH FORUM, V32, P229, DOI 10.1111/cgf.12189
   Hasirci Z, 2011, 2011 34TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P478, DOI 10.1109/TSP.2011.6043685
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Ihmsen M., 2014, Eurographics 2014-State of the Art Reports
   Jaw Y, 2017, ISPRS J PHOTOGRAMM, V125, P193, DOI 10.1016/j.isprsjprs.2017.01.013
   Lin CH, 2014, ISPRS J PHOTOGRAMM, V94, P70, DOI 10.1016/j.isprsjprs.2014.04.016
   Lin HW, 2005, VISUAL COMPUT, V21, P418, DOI 10.1007/s00371-005-0304-4
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276405
   Lu XQ, 2017, COMPUT AIDED GEOM D, V54, P49, DOI 10.1016/j.cagd.2017.02.011
   McDougall J, 1939, PHILOS TR R SOC S-A, V237, P67
   McIvor AM, 1997, MACH VISION APPL, V10, P17, DOI 10.1007/s001380050055
   Ming Liu, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P91, DOI 10.1109/ROBIO.2012.6490949
   Natale D., 2010, P APPL IMAGERY PATTE, P1
   Ohrhallinger S, 2019, COMPUT GRAPH FORUM, V38, P126, DOI 10.1111/cgf.13395
   Ohrhallinger S, 2016, COMPUT GRAPH FORUM, V35, P167, DOI 10.1111/cgf.12973
   Ohrhallinger S., 2018, P 26 PAC C COMP GRAP, P1, DOI [10.2312/pg.20181266, DOI 10.2312/PG.20181266]
   Ohtake Yutaka., 2005, S SOLID MODELING APP, P61, DOI DOI 10.1145/1060244.1060252
   Öztürk M, 2013, TURK J ELECTR ENG CO, V21, P2239, DOI 10.3906/elk-1203-114
   Philsu K., 2010, MATH PROBL ENG, P17
   Ritter M., 2012, J WSCG
   Ritter M., 2021, EUROGRAPHICS 2021 SH
   Ruiz O. E., 2013, GRAPP IVAPP, P35
   Tao J, 2013, IEEE T VIS COMPUT GR, V19, P393, DOI 10.1109/TVCG.2012.143
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   Toth C., 2016, ISPRS J PHOTOGR R SE, V115
   Weinmann M, 2015, ISPRS J PHOTOGRAMM, V105, P286, DOI 10.1016/j.isprsjprs.2015.01.016
   Weinstein D., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P249, DOI 10.1109/VISUAL.1999.809894
   Wendland H., 2004, Scattered data approximation, DOI [10.1017/CBO9780511617539, DOI 10.1017/CBO9780511617539]
   Zeng Y, 2008, COMPUT AIDED DESIGN, V40, P210, DOI 10.1016/j.cad.2007.10.010
NR 41
TC 4
Z9 4
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 1
EP 14
DI 10.1016/j.visinf.2021.05.001
EA JUN 2021
PG 14
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Nguyen, QV
   Miller, N
   Arness, D
   Huang, WD
   Huang, ML
   Simoff, S
AF Quang Vinh Nguyen
   Miller, Natalie
   Arness, David
   Huang, Weidong
   Huang, Mao Lin
   Simoff, Simeon
TI Evaluation on interactive visualization data with scatterplots
SO VISUAL INFORMATICS
LA English
DT Article
DE Multivariate data visualization; Multidimensional data visualization;
   Scatterplots; Scatterplot matrix; Controlled study
ID MATRIX
AB Scatterplots and scatterplot matrix methods have been popularly used for showing statistical graphics and for exposing patterns in multivariate data. A recent technique, called Linkable Scatterplots, provides an interesting idea for interactive visual exploration which provides a set of necessary plot panels on demand together with interaction, linking and brushing. This article presents a controlled study with a mixed-model design to evaluate the effectiveness and user experience on the visual exploration when using a Sequential-Scatterplots who a single plot is shown at a time, Multiple-Scatterplots who number of plots can be specified and shown, and Simultaneous-Scatterplots who all plots are shown as a scatterplot matrix. Results from the study demonstrated higher accuracy using the Multiple-Scatterplots visualization, particularly in comparison with the Simultaneous-Scatterplots. While the time taken to complete tasks was longer in the Multiple-Scatterplots technique, compared with the simpler Sequential-Scatterplots, Multiple-Scatterplots is inherently more accurate. Moreover, the Multiple-Scatterplots technique is the most highly preferred and positively experienced technique in this study. Overall, results support the strength of Multiple-Scatterplots and highlight its potential as an effective data visualization technique for exploring multivariate data. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Quang Vinh Nguyen; Simoff, Simeon] Western Sydney Univ, MARCS Inst, Sydney, NSW, Australia.
   [Quang Vinh Nguyen; Simoff, Simeon] Western Sydney Univ, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Miller, Natalie; Arness, David] Western Sydney Univ, Sch Psychol, Sydney, NSW, Australia.
   [Huang, Weidong] Univ Technol, Fac Transdisciplinary Innovat, Sydney, NSW, Australia.
   [Huang, Mao Lin] Univ Technol, Fac Engn & IT, Sch Software, Sydney, NSW, Australia.
C3 Western Sydney University; Western Sydney University; Western Sydney
   University; University of Technology Sydney; University of Technology
   Sydney
RP Nguyen, QV (corresponding author), Western Sydney Univ Parramatta, Sch Comp Data & Math Sci, Parramatta, NSW, Australia.
EM Q.Nguyen@westernsydney.edu.au; Natmill303@gmail.com;
   D.Arness@westernsydney.edu.au; Weidong.Huang@uts.edu.au;
   Mao.Huang@uts.edu.au; S.Simoff@westernsydney.edu.au
RI Huang, Weidong/B-7504-2011; Nguyen, Quang Ngoc/Y-8745-2018; Arness,
   David Caelum/AEL-6621-2022
OI Nguyen, Quang Ngoc/0000-0002-0941-7318; Arness, David
   Caelum/0000-0003-2334-0641; Huang, Weidong/0000-0002-5190-7839; Nguyen,
   Quang Vinh/0000-0002-0815-6224
CR Albuquerque G., 2009, VIS MOD VIS VMV
   [Anonymous], 2005, Methodology, DOI [10.1027/1614-1881.1.1.27, DOI 10.1027/1614-1881.1.1.27]
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P807, DOI 10.2307/2288711
   Cui QG, 2006, PROC SPIE, V6060, DOI 10.1117/12.650409
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Emerson JW, 2013, J COMPUT GRAPH STAT, V22, P79, DOI 10.1080/10618600.2012.694762
   FEW STEPHEN., 2013, ENCY HUMAN COMPUTER, V2nd
   Freedman EG, 2002, LECT NOTES ARTIF INT, V2317, P18
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Heinrich J., 2012, Euro-VisShort2012, P37
   Huang W., 2008, 2008 WORKSH TIM ERR
   Huang WD, 2009, INFORM VISUAL, V8, P139, DOI 10.1057/ivs.2009.10
   Im JF, 2013, IEEE T VIS COMPUT GR, V19, P2606, DOI 10.1109/TVCG.2013.160
   Lund A M., 2001, USABILITY INTERFACE, V8, P3, DOI DOI 10.1177/1078087402250360
   Nguyen Q., 2016, P 9 INT S VISUAL INF, P43
   Nguyen QV, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-013-4870-1
   Packham L, 2005, ADV ENG INFORM, V19, P263, DOI 10.1016/j.aei.2005.07.006
   Nguyen QV, 2016, J IMAGING, V2, DOI 10.3390/jimaging2040029
   Quang Vinh Nguyen, 2014, Genomics & Informatics, V12, P21, DOI 10.5808/GI.2014.12.1.21
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Tabachnick, 2013, Using multivariate statistics, V6th
   Tory M, 2007, IEEE T VIS COMPUT GR, V13, P1262, DOI 10.1109/TVCG.2007.70596
   Tory M, 2009, IEEE T VIS COMPUT GR, V15, P1033, DOI 10.1109/TVCG.2009.127
   Wang Wang., 2015, Digital Technologies, V1, P33, DOI DOI 10.12691/DT-1-1-7
   Ware C., 2020, INFORM VISUALIZATION
   Yurdugül H, 2008, HACET UNIV EGIT FAK, P397
   Zhu Y., 2007, ADV VIS COMP ISVC 20
NR 30
TC 9
Z9 11
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2020
VL 4
IS 4
BP 1
EP 10
DI 10.1016/j.visinf.2020.09.004
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KZ
UT WOS:000658193600001
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, F
   Yu, H
   Jiang, J
   Wang, ZY
   Qin, XJ
AF Zhang, Fan
   Yu, Hang
   Jiang, Jie
   Wang, Zhangye
   Qin, Xujia
TI Brain-computer control interface design for virtual household appliances
   based on steady-state visually evoked potential recognition
SO VISUAL INFORMATICS
LA English
DT Article
DE Brain-computer interface; Steady-state visually evoked potential;
   Canonical correlation analysis
ID CANONICAL CORRELATION-ANALYSIS; SSVEP
AB Brain-computer interface is a new form of interaction between humans and machines. This interaction helps the human brain control or operate external devices directly using electroencephalograph (EEG) signals. In this study, we first adopt a canonical correlation analysis method to find the stimulation frequency by calculating the correlation coefficient between the EEG data and multiple sets of harmonics with different frequencies. Then, we select the maximum correlation coefficient as the stimulus frequency and consequently identify steady-state visual evoked potentials. Afterward, we introduce power spectral density to adjust the stimulus frequency and a voting mechanism to reduce the false activation rate. Finally, we build a virtual household electrical appliance brain-computer control interface, which achieves over 72.84% accuracy for three classification problems. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Zhang, Fan; Yu, Hang; Jiang, Jie; Qin, Xujia] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Zhangye] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University
RP Jiang, J; Qin, XJ (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
EM jj@zjut.edu.cn; qxj@zjut.edu.cn
OI Yu, Hang/0000-0002-0185-2737
FU National Natural Science Foundation of China [U1736109, U1609217,
   61772456]
FX Fan Zhang, Jie Jiang and Xujia Qin are supported by National Natural
   Science Foundation of China (U1736109, U1609217, 61772456).
CR Bakardjian H, 2010, NEUROSCI LETT, V469, P34, DOI 10.1016/j.neulet.2009.11.039
   Bin GY, 2009, J NEURAL ENG, V6, DOI 10.1088/1741-2560/6/4/046002
   Chen ZT, 2017, VIS INFORM, V1, P132, DOI 10.1016/j.visinf.2017.11.002
   [高上凯 GAO Shang-kai], 2009, [生命科学, Chinese Bulletin of Life Sciences], V21, P177
   [侯书东 Hou Shudong], 2012, [自动化学报, Acta Automatica Sinica], V38, P659
   Huang Man-ling, 2008, Transactions of Beijing Institute of Technology, V28, P957
   Jia C., 2007, INT C FDN AUGMENTED, V11, P3
   [孔丽文 Kong Liwen], 2015, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V29, P317
   Li S, 2004, J ALLOY COMPD, V364, P250, DOI 10.1016/S0925-8388(03)00535-8
   Li YQ, 2013, IEEE T BIO-MED ENG, V60, P3156, DOI 10.1109/TBME.2013.2270283
   Lin ZL, 2007, IEEE T BIO-MED ENG, V54, P1172, DOI 10.1109/TBME.2006.889197
   Lin ZL, 2006, IEEE T BIO-MED ENG, V53, P2610, DOI 10.1109/TBME.2006.886577
   Liu H.S., 2003, PROG NAT SCI-MATER, V13, P59
   Maggi L, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P1264
   Nan WY, 2011, I IEEE EMBS C NEUR E, P469, DOI 10.1109/NER.2011.5910588
   Pfurtscheller G., 2010, FRONT NEUROSCI-SWITZ, V4, P30, DOI [10.3389/fnpro.2010.00003, DOI 10.3389/fnpro.2010.00003]
   Shyu KK, 2010, IEEE T BIOMED CIRC S, V4, P125, DOI 10.1109/TBCAS.2010.2042595
   Volosyak I., 2009, INT WORK C ART NEUR, V70, P6
   Wang X.R, 1980, J YUNNAN U NAT SCI, V1980, P3
   Wu Z.H, 2008, J U ELECT SCI TECHNO, V05
   Yan Zheng, 2009, Journal of Tsinghua University (Science and Technology), V49, P2013
   Zhang Y, 2013, IEEE T NEUR SYS REH, V21, P887, DOI 10.1109/TNSRE.2013.2279680
   Zhu Danhua, 2010, Comput Intell Neurosci, P702357, DOI 10.1155/2010/702357
NR 23
TC 7
Z9 7
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2020
VL 4
IS 1
BP 1
EP 7
DI 10.1016/j.visinf.2019.12.001
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KB
UT WOS:000658191200001
OA gold
DA 2024-07-18
ER

PT J
AU Liu, H
   Jin, SC
   Yan, YY
   Tao, YB
   Lin, H
AF Liu, Huan
   Jin, Sichen
   Yan, Yuyu
   Tao, Yubo
   Lin, Hai
TI Visual analytics of taxi trajectory data via topical sub-trajectories
SO VISUAL INFORMATICS
LA English
DT Article
DE Trajectory pattern mining; Trajectory visualization; Visual analytics;
   Topic model
AB GPS-based taxi trajectories contain valuable knowledge about movement patterns for transportation and urban planning. Topic modeling is an effective tool to extract semantic information from taxi trajectory data. However, previous methods generally ignore trajectory directions that are important in the analysis of movement patterns. In this paper, we employ the bigram topic model rather than traditional topic models to analyze textualized trajectories and consider the direction information of trajectories. We further propose a modified Apriori algorithm to extract topical sub-trajectories and use them to represent each topic. Finally, we design a visual analytics system with several linked views to facilitate users to interactively explore movement patterns from topics and topical sub-trajectories. The case studies with Chengdu taxi trajectory data demonstrate the effectiveness of the proposed system. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Liu, Huan; Jin, Sichen; Yan, Yuyu; Tao, Yubo; Lin, Hai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Tao, YB (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM 21721064@zju.edu.cn; 3150104297@zju.edu.cn; yanyuyu001@gmail.com;
   taoyubo@cad.zju.edu.cn; lin@cad.zju.edu.cn
OI Xu, Jin/0000-0003-2132-8825
FU National Key Research & Development Program of China [2017YFB0202203];
   National Natural Science Foundation of China [61472354, 61672452];
   NSFCGuangdong Joint Fund, China [U1611263]
FX This work was supported by the National Key Research & Development
   Program of China (2017YFB0202203), National Natural Science Foundation
   of China (61472354 and 61672452), and NSFCGuangdong Joint Fund, China
   (U1611263).
CR Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Al-Dohuki S, 2017, IEEE T VIS COMPUT GR, V23, P11, DOI 10.1109/TVCG.2016.2598416
   Alvares L.O., 2007, DATA MIN KNOWL DISC, V12
   Andrienko G, 2008, IEEE S VIS ANAL, P51, DOI 10.1109/VAST.2008.4677356
   Andrienko N., 2000, Proceedings of the working conference on advanced visual interfaces, P217, DOI [10.1145/345513.345319, DOI 10.1145/345513.345319]
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   [Anonymous], 2011, Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, DOI DOI 10.1145/2093973.2093980
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen W, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2436897
   Chu D, 2014, IEEE PAC VIS SYMP, P137, DOI 10.1109/PacificVis.2014.50
   Cui WW, 2008, IEEE T VIS COMPUT GR, V14, P1277, DOI 10.1109/TVCG.2008.135
   Demsar U, 2010, INT J GEOGR INF SCI, V24, P1527, DOI 10.1080/13658816.2010.511223
   Ersoy O, 2011, IEEE T VIS COMPUT GR, V17, P2364, DOI 10.1109/TVCG.2011.233
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Gaffney S., 1999, 5 ACM SIGKDD INT C K, P63, DOI [10.1145/312129.312198, DOI 10.1145/312129.312198]
   Guo HQ, 2011, IEEE PAC VIS SYMP, P163, DOI 10.1109/PACIFICVIS.2011.5742386
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   Hurter C, 2009, IEEE T VIS COMPUT GR, V15, P1017, DOI 10.1109/TVCG.2009.145
   Jin SC, 2019, IEEE PAC VIS SYMP, P174, DOI 10.1109/PacificVis.2019.00027
   Kraak M.-J., 2003, P 21 INT CARTOGRAPHI, P1988, DOI [10. 1007 / 3 - 540 - 26772 - 7_15, DOI 10.1007/3-540-26772-7_15]
   Lee J G, 2007, SIGMOD C, P593, DOI DOI 10.1145/1247480.1247546
   Linderman G.C., 2017, ARXIV PREPRINT ARXIV
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu K, 2019, COMPUT ENVIRON URBAN, V74, P50, DOI 10.1016/j.compenvurbsys.2018.12.001
   Liu Z., 2010, P 2010 C EMP METH NA, P366
   Lu M, 2015, IEEE PAC VIS SYMP, P311, DOI 10.1109/PACIFICVIS.2015.7156392
   Mazimpaka JD, 2016, J SPAT INF SCI, P61, DOI 10.5311/JOSIS.2016.13.263
   Pu J., 2012, Advanced Data Mining and Applications, P502
   Pu JS, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 1, P127, DOI 10.1109/MDM.2013.23
   Tang Y, 2018, J VISUAL-JAPAN, V21, P661, DOI 10.1007/s12650-018-0481-7
   Teneva N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P530, DOI 10.18653/v1/P17-2084
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wallach H.M., 2006, Proc. 23rd Int. Conf. Mach. Learn, P977984
   Wang ZC, 2014, IEEE T VIS COMPUT GR, V20, P1813, DOI 10.1109/TVCG.2014.2346746
   Ying J. J., 2010, P 2 ACM SIGSPATIAL I, P19, DOI DOI 10.1145/1867699.1867703
   Zhang FM, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5060078
   Zheng Y, 2011, COMPUTING WITH SPATIAL TRAJECTORIES, P1, DOI 10.1007/978-1-4614-1629-6
   Zheng Y, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2629592
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
NR 42
TC 16
Z9 19
U1 4
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2019
VL 3
IS 3
BP 140
EP 149
DI 10.1016/j.visinf.2019.10.002
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YL
UT WOS:000658189600003
OA gold
DA 2024-07-18
ER

PT J
AU Li, TM
   Wu, SQ
   Jin, YN
   Shi, HP
   Liu, SR
AF Li, Tiemeng
   Wu, Songqian
   Jin, Yanning
   Shi, Haopai
   Liu, Shiran
TI X-Space: Interaction design of extending mixed reality space from Web2D
   visualization
SO VISUAL INFORMATICS
LA English
DT Article
DE Mobile and ubiquitous visualization; Visualization system and toolkit
   design; Immersive analytic; Information data visualization;
   Human-computer interaction
ID INFORMATION
AB Mixed reality offers a larger visualization space and more intuitive means of interaction for data exploration, and many works have been dedicated to combining 2D visualizations on screen with mixe reality. However, for each combination, we need to customize the implementation of the corresponding mixed reality 3D visualization. It is a challenge to simplify this development process and enable agile building of mixed reality 3D visualizations for 2D visualizations. In addition, many existing 2D visualizations do not provide interfaces oriented to immersive analytics, so how to extend the mixed reality 3D space from existing 2D visualizations is another challenge. This work presents an agile and flexible approach to interactively transfer visualizations from 2D screens to mixed reality 3D spaces. We designed an interactive process for spatial generation of mixed-reality 3D visualizations, defined a unified data transfer framework, integrated data deconstruction techniques for 2D visualizations, implemented interfaces to immersive visualization building tool-kits, and encapsulated these techniques into a tool named X-Space. We validated that the approach is feasible and effective through 2D visualization cases including scatter plots, stacked bar charts, and adjacency matrix. Finally, we conducted expert interviews to discuss the usability and value of the method. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Li, Tiemeng; Wu, Songqian; Jin, Yanning; Shi, Haopai; Liu, Shiran] Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, Beijing, Peoples R China.
   [Li, Tiemeng] Beijing Key Lab Network Syst & Network Culture, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Li, TM (corresponding author), Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, Beijing, Peoples R China.
EM tiemeng@bupt.edu.cn
OI LI, Tiemeng/0000-0001-5507-0397
FU National Natural Science Foundation of China [61702042]
FX <B>Acknowledgments</B> This work was supported by the National Natural
   Science Foundation of China (61702042) .
CR Andrews K., 2018, WORKSH DAT VIS MOB D, P4
   [Anonymous], 2011, P 24 ANN ACM S US IN
   Badam SK, 2021, INFORM VISUAL, V20, P229, DOI 10.1177/14738716211038614
   Biener V, 2020, Arxiv, DOI arXiv:2008.04559
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brath R, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P25, DOI 10.1109/3DVis.2014.7160096
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Chen KY, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P565, DOI 10.1145/2632048.2632090
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Di Geronimo L, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098530
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Harper Jonathan, 2014, P 27 ANN ACM S USER, V14, P253, DOI [10.1145/2642918.2647411, DOI 10.1145/2642918.26474112, DOI 10.1145/2642918.2647411]
   Huang WH, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P9
   Huang ZP, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P341, DOI 10.1145/2733373.2806266
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kim H, 2021, COMPUT GRAPH FORUM, V40, P459, DOI 10.1111/cgf.14321
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376675
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Li TM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122312182
   Li TM, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2086
   Louis V, 2017, Suicide statictics of India, Insights by State/UT spanning accross 2001 to 2013
   Lu M, 2017, IEEE PAC VIS SYMP, P61
   Lystbaek Mathias N., 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3530886
   Mandalika VBH, 2018, J DIGIT IMAGING, V31, P56, DOI 10.1007/s10278-017-0002-6
   Marriott K., 2018, IMMERSIVE ANAL
   Mojica GF., 2019, The Mathematics Teacher, V112, P473, DOI DOI 10.5951/MATHTEACHER.112.6.0473
   Nelson L, 1999, COMPUTATION STAT, V14, P39, DOI 10.1007/PL00022704
   de Araújo TDO, 2021, IEEE INT CONF INF VI, P88, DOI 10.1109/IV53921.2021.00023
   Paay J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6608, DOI 10.1145/3025453.3025724
   Prasad VSN, 2007, INT WORK CONTENT MUL, P85
   Reichherzer C, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451839
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Seraji MR, 2022, IEEE INT SYMP M AU R, P155, DOI 10.1109/ISMAR-Adjunct57072.2022.00036
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.1582298687237, 10.1109/VR46266.2020.00-20]
   Wu SZ, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383170
   Zeng W., 2023, IEEE Trans. Vis. Comput. Graphics
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhou W, 2022, J VISUAL-JAPAN, V25, P207, DOI 10.1007/s12650-021-00792-w
   Zhu FY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376233
NR 45
TC 1
Z9 1
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 73
EP 83
DI 10.1016/j.visinf.2023.10.001
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DQ7P4
UT WOS:001133594700001
OA gold
DA 2024-07-18
ER

PT J
AU Rasheed, F
   Masood, TB
   Murthy, TG
   Natarajan, V
   Hotz, I
AF Rasheed, Farhan
   Masood, Talha Bin
   Murthy, Tejas G.
   Natarajan, Vijay
   Hotz, Ingrid
TI Multi-scale visual analysis of cycle characteristics in
   spatially-embedded graphs
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual data analysis; Planar graph; Force network; Granular materials;
   Persistence homology; Force loops; Computational geometry
ID GRANULAR-MATERIALS
AB We present a visual analysis environment based on a multi-scale partitioning of a 2d domain into regions bounded by cycles in weighted planar embedded graphs. The work has been inspired by an application in granular materials research, where the question of scale plays a fundamental role in the analysis of material properties. We propose an efficient algorithm to extract the hierarchical cycle structure using persistent homology. The core of the algorithm is a filtration on a dual graph exploiting Alexander's duality. The resulting partitioning is the basis for the derivation of statistical properties that can be explored in a visual environment. We demonstrate the proposed pipeline on a few synthetic and one real-world dataset.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Rasheed, Farhan; Masood, Talha Bin; Hotz, Ingrid] Linkoping Univ, Dept Sci & Technol, Bredgatan 33, S-60221 Norrkoping, Sweden.
   [Murthy, Tejas G.] Indian Inst Sci, Dept Civil Engn, Bangalore 560012, India.
   [Natarajan, Vijay] Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, India.
C3 Linkoping University; Indian Institute of Science (IISC) - Bangalore;
   Indian Institute of Science (IISC) - Bangalore
RP Rasheed, F (corresponding author), Linkoping Univ, Dept Sci & Technol, Bredgatan 33, S-60221 Norrkoping, Sweden.
EM farhan.rasheed@liu.se
OI Hotz, Ingrid/0000-0001-7285-0483; Natarajan, Vijay/0000-0002-7956-1470;
   Murthy, Tejas Gorur/0000-0002-6264-7710
FU Wallenberg AI, Autonomous Systems and Software Program (WASP) - Knut and
   Alice Wallenberg Foundation; SeRC (Swedish e-Science Research Center);
   ELLIIT environment for strategic research in Sweden; Swedish Research
   Council (VR) [2019-05487]; Indo-Swedish joint network project
   [DST/INT/SWD/VR/P-02/2019, 2018-07085]; Swedish Research Council
   [2019-05487, 2018-07085] Funding Source: Swedish Research Council
FX This work was supported by the Wallenberg AI, Autonomous Systems and
   Software Program (WASP) funded by the Knut and Alice Wallenberg
   Foundation, the SeRC (Swedish e-Science Research Center) and the ELLIIT
   environment for strategic research in Sweden, the Swedish Research
   Council (VR) grant 2019-05487 and an Indo-Swedish joint network project:
   DST/INT/SWD/VR/P-02/2019 VR grant 2018-07085.
CR Aurenhammer F., 2013, Voronoi Diagrams and Delaunay Triangulations, DOI [10.1142/8685, DOI 10.1142/8685]
   Cambou B, 2016, DISCRET GRANUL MECH, P25
   Daniels K.E, 2017, EPJ WEB C EDP SCI
   Edelsbrunner H., 2006, GEOMETRY TOPOLOGY ME
   Edelsbrunner H, 2008, CONTEMP MATH, V453, P257
   Fu PC, 2015, INT J SOLIDS STRUCT, V63, P68, DOI 10.1016/j.ijsolstr.2015.02.041
   Hajij M, 2018, IEEE PAC VIS SYMP, P125, DOI 10.1109/PacificVis.2018.00024
   Hatcher A., 2003, ALGEBRAIC TOPOLOGY
   Hiraoka Y, 2019, Topological data analysis on materials science
   Jönsson D, 2020, IEEE T VIS COMPUT GR, V26, P3241, DOI 10.1109/TVCG.2019.2920639
   Jungnickel D., 2012, Algorithms and Computation in Mathematics, Vfourth
   Kavitha T, 2009, COMPUT SCI REV, V3, P199, DOI 10.1016/j.cosrey.2009.08.001
   Kondic L., 2017, EPJ WEB C, V140, P15014
   Kramár M, 2014, PHYS REV E, V90, DOI 10.1103/PhysRevE.90.052203
   Krámar M, 2014, PHYSICA D, V283, P37, DOI 10.1016/j.physd.2014.05.009
   Kuhn MR, 2015, ACTA GEOTECH, V10, P399, DOI 10.1007/s11440-015-0397-5
   Pandey K, 2022, GRANUL MATTER, V24, DOI 10.1007/s10035-021-01182-7
   Papadopoulos L, 2018, J COMPLEX NETW, V6, P485, DOI 10.1093/comnet/cny005
   Shahin G, 2022, EXTREME MECH LETT, V51, DOI 10.1016/j.eml.2021.101590
   Smart AG, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.041307
   Wan R, 2005, SOILS FOUND, V45, P77, DOI 10.3208/sandf.45.2_77
   Yang JK, 2021, MATERIALS, V14, DOI 10.3390/ma14216542
   Zhu HX, 2017, EUR J ENVIRON CIV EN, V21, P912, DOI 10.1080/19648189.2016.1229229
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2023
VL 7
IS 3
BP 49
EP 58
DI 10.1016/j.visinf.2023.06.005
EA SEP 2023
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA EH1D7
UT WOS:001137930600001
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Luo, F
   Zhu, YQ
   Fu, YP
   Zhou, HJ
   Chen, ZZ
   Xiao, CX
AF Luo, Fei
   Zhu, Yongqiong
   Fu, Yanping
   Zhou, Huajian
   Chen, Zezheng
   Xiao, Chunxia
TI Sparse RGB-D images create a real thing: A flexible voxel based 3D
   reconstruction pipeline for single object
SO VISUAL INFORMATICS
LA English
DT Article
DE Sparse RGB-D; 3D reconstruction; TSDF; Depth map
ID DEPTH; REGISTRATION
AB Reconstructing 3D models for single objects with complex backgrounds has wide applications like 3D printing, AR/VR, and so on. It is necessary to consider the tradeoff between capturing data at low cost and getting high-quality reconstruction results. In this work, we propose a voxel-based modeling pipeline with sparse RGB-D images to effectively and efficiently reconstruct a single real object without the geometrical post-processing operation on background removal. First, referring to the idea of VisualHull, useless and inconsistent voxels of a targeted object are clipped. It helps focus on the target object and rectify the voxel projection information. Second, a modified TSDF calculation and voxel filling operations are proposed to alleviate the problem of depth missing in the depth images. They can improve TSDF value completeness for voxels on the surface of the object. After the mesh is generated by the MarchingCube, texture mapping is optimized with view selection, color optimization, and camera parameters fine-tuning. Experiments on Kinect capturing dataset, TUM public dataset, and virtual environment dataset validate the effectiveness and flexibility of our proposed pipeline.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Luo, Fei; Zhou, Huajian; Chen, Zezheng; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Zhu, Yongqiong] Wuhan Business Univ, Sch Art, Wuhan 430000, Hubei, Peoples R China.
   [Fu, Yanping] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
C3 Wuhan University; Wuhan Business University; Anhui University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM cxxiao@whu.edu.cn
RI Luo, Fei/IZQ-5485-2023
OI Luo, Fei/0000-0002-8481-8357; Zhou, Eagle/0000-0001-9160-0041; Luo,
   Fei/0000-0001-7320-5144
FU Key Technological Innovation Projects of Hubei Province, China
   [2018AAA062]; National Natural Science Foundation of China [61972298];
   Ministry of Education of Humanities and Social Sciences Project, China
   [17YJC760124]; Scientific Research Project of Department of Education of
   Hubei Province, China [B2021278]
FX This work is partially supported by the Key Technological Innovation
   Projects of Hubei Province, China (No. 2018AAA062) , the National
   Natural Science Foundation of China (No. 61972298) , the Ministry of
   Education of Humanities and Social Sciences Project, China (No.
   17YJC760124) and the Scientific Research Project of Department of
   Education of Hubei Province, China (No. B2021278) .
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benjemaa R., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P34, DOI 10.1007/BFb0054732
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bi S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073610
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Choi S, 2015, PROC CVPR IEEE, P5556, DOI 10.1109/CVPR.2015.7299195
   Cui Y, 2010, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2010.5540082
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Deng Kangle, 2022, CVPR, P12882
   Fu YP, 2020, PROC CVPR IEEE, P5949, DOI 10.1109/CVPR42600.2020.00599
   Fu YP, 2020, VISUAL COMPUT, V36, P2215, DOI 10.1007/s00371-020-01899-1
   Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488
   Gálvez-López D, 2011, IEEE INT C INT ROBOT, P51, DOI 10.1109/IROS.2011.6048525
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Huang J., 2017, ACM T GRAPHIC, V36, P1, DOI 10.1111/njb.01468
   Huang JH, 2021, PROC CVPR IEEE, P8928, DOI 10.1109/CVPR46437.2021.00882
   Izadi S., 2011, ACM SIGGRAPH 2011 Talks, P23, DOI 10.1145/2037826.2037857
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Krishnan S., 2005, Proc. Symposium on Geometry Processing, P187
   Liao J, 2021, COMPUT GRAPH-UK, V97, P268, DOI 10.1016/j.cag.2021.04.016
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338
   Masuda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P879, DOI 10.1109/ICPR.1996.546150
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Pekelny Y, 2008, COMPUT GRAPH FORUM, V27, P399, DOI 10.1111/j.1467-8659.2008.01137.x
   Seitz Steve., CVPR, V1, P519
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54
   Weder S, 2020, PROC CVPR IEEE, P4886, DOI 10.1109/CVPR42600.2020.00494
   Whelan Thomas, 2013, 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2013), P548, DOI 10.1109/IROS.2013.6696405
   Yang L, 2018, IEEE T VIS COMPUT GR, V24, P1190, DOI 10.1109/TVCG.2017.2657766
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yariv L., 2020, Advances in Neural Information Processing Systems, V33, P2492, DOI DOI 10.48550/ARXIV.2003.09852
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Yu T, 2021, PROC CVPR IEEE, P5742, DOI 10.1109/CVPR46437.2021.00569
   Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52
   Zhou QY, 2018, Arxiv, DOI arXiv:1801.09847
NR 42
TC 2
Z9 2
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2023
VL 7
IS 1
BP 66
EP 76
DI 10.1016/j.visinf.2022.12.002
EA APR 2023
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA F4AA6
UT WOS:000981776300001
OA gold
DA 2024-07-18
ER

PT J
AU Jin, YC
   Zhu, FL
   Li, JH
   Ma, L
AF Jin, Yichao
   Zhu, Fuli
   Li, Jianhua
   Ma, Lei
TI TCMFVis: A visual analytics system toward bridging together traditional
   Chinese medicine and modern medicine
SO VISUAL INFORMATICS
LA English
DT Article
DE Traditional Chinese medicine; Visual analytics; Set visualization;
   Molecular mechanism
ID SET VISUALIZATION; HERBAL FORMULAS; DISEASE; PAIR
AB Although traditional Chinese medicine (TCM) and modern medicine (MM) have considerably different treatment philosophies, they both make important contributions to human health care. TCM physicians usually treat diseases using TCM formula (TCMF), which is a combination of specific herbs, based on the holistic philosophy of TCM, whereas MM physicians treat diseases using chemical drugs that interact with specific biological molecules. The difference between the holistic view of TCM and the atomistic view of MM hinders their combination. Tools that are able to bridge together TCM and MM are essential for promoting the combination of these disciplines. In this paper, we present TCMFVis, a visual analytics system that would help domain experts explore the potential use of TCMFs in MM at the molecular level. TCMFVis deals with two significant challenges, namely, (i) intuitively obtaining valuable insights from heterogeneous data involved in TCMFs and (ii) efficiently identifying the common features among a cluster of TCMFs. In this study, a four-level (herb-ingredient-targetdisease) visual analytics framework was designed to facilitate the analysis of heterogeneous data in a proper workflow. Several set visualization techniques were first introduced into the system to facilitate the identification of common features among TCMFs. Case studies on two groups of TCMFs clustered by function were conducted by domain experts to evaluate TCMFVis. The results of these case studies demonstrate the usability and scalability of the system.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Jin, Yichao; Li, Jianhua] East China Univ Sci & Technol, Sch Informat Sci & Engn, Meilong Rd 130, Shanghai, Peoples R China.
   [Zhu, Fuli; Ma, Lei] East China Univ Sci & Technol, Sch Pharm, Shanghai Key Lab New Drug Design, Meilong Rd 130, Shanghai, Peoples R China.
C3 East China University of Science & Technology; East China University of
   Science & Technology
RP Li, JH (corresponding author), East China Univ Sci & Technol, Sch Informat Sci & Engn, Meilong Rd 130, Shanghai, Peoples R China.; Ma, L (corresponding author), East China Univ Sci & Technol, Sch Pharm, Shanghai Key Lab New Drug Design, Meilong Rd 130, Shanghai, Peoples R China.
EM y30201040@mail.ecust.edu.cn; y30211244@mail.ecust.edu.cn;
   jhli@ecust.edu.cn; malei@ecust.edu.cn
RI Li, Jianhua/I-7383-2013
OI Li, Jianhua/0000-0002-5438-1529
FU National Key R and D Program of China [2016YFA0502304]; Important Drug
   Development Fund, Ministry of Science and Technology of China
   [2018ZX09735002]
FX The work was supported by National Key R and D Program of China (under
   Grant No. 2016YFA0502304) and Important Drug Development Fund, Ministry
   of Science and Technology of China (2018ZX09735002) .
CR Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   Alsallakh B., 2014, EuroVis (STARs), DOI DOI 10.2312/EUROVISSTAR.20141170
   Alsallakh B, 2017, IEEE T VIS COMPUT GR, V23, P361, DOI 10.1109/TVCG.2016.2598496
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Bederson BB, 2002, ACM T GRAPHIC, V21, P833, DOI 10.1145/571647.571649
   Bothorel G, 2013, LECT NOTES COMPUT SC, V8034, P396, DOI 10.1007/978-3-642-41939-3_38
   Bu DC, 2021, COMPUT STRUCT BIOTEC, V19, P62, DOI 10.1016/j.csbj.2020.11.036
   Cao AQ, 2021, VIS INFORM, V5, P102, DOI 10.1016/j.visinf.2021.09.002
   Chen JL, 2015, METAB BRAIN DIS, V30, P129, DOI 10.1007/s11011-014-9635-z
   Chen YB, 2019, EVID-BASED COMPL ALT, V2019, DOI 10.1155/2019/3961395
   Chung H, 2022, IEEE T VIS COMPUT GR, V28, P2983, DOI 10.1109/TVCG.2020.3047111
   Collins Christopher, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P91, DOI 10.1109/VAST.2009.5333443
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Commission C.P., 2015, Chinese Pharmacopoeia
   Csermely P, 2005, TRENDS PHARMACOL SCI, V26, P178, DOI 10.1016/j.tips.2005.02.007
   Diener HC, 2006, LANCET NEUROL, V5, P310, DOI 10.1016/S1474-4422(06)70382-9
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Hu TX, 2020, VIS INFORM, V4, P58, DOI 10.1016/j.visinf.2020.02.001
   Huang L, 2018, NUCLEIC ACIDS RES, V46, pD1117, DOI 10.1093/nar/gkx1028
   Hulsen T, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-488
   Khan H, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10010059
   Kim S, 2016, NUCLEIC ACIDS RES, V44, pD1202, DOI 10.1093/nar/gkv951
   Konkimalla VB, 2008, J ETHNOPHARMACOL, V116, P207, DOI 10.1016/j.jep.2007.12.009
   Kui XY, 2020, VIS INFORM, V4, P1, DOI 10.1016/j.visinf.2020.06.001
   Lamy JB, 2020, IEEE T VIS COMPUT GR, V26, P3285, DOI 10.1109/TVCG.2019.2921544
   Lamy JB, 2017, J VISUAL LANG COMPUT, V43, P71, DOI 10.1016/j.jvlc.2017.09.003
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Li S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S11-S6
   Liang XJ, 2014, MOL BIOSYST, V10, P1014, DOI 10.1039/c3mb70507b
   Liu H, 2019, VIS INFORM, V3, P140, DOI 10.1016/j.visinf.2019.10.002
   Liu Y, 2012, EVID-BASED COMPL ALT, V2012, DOI 10.1155/2012/184503
   Lu PH, 2020, EVID-BASED COMPL ALT, V2020, DOI 10.1155/2020/8854772
   Meulemans W, 2013, IEEE T VIS COMPUT GR, V19, P1846, DOI 10.1109/TVCG.2013.76
   Pirooznia M, 2007, BIOINFORMATION, V1, P420, DOI 10.6026/97320630001420
   Rao JK, 1999, ANN INTERN MED, V131, P409, DOI 10.7326/0003-4819-131-6-199909210-00003
   Ru JL, 2014, J CHEMINFORMATICS, V6, DOI 10.1186/1758-2946-6-13
   Schreck T., 2006, Proceedings of Computer Graphics (SCCG 2006), P184, DOI DOI 10.1145/2602161.2602183
   Shang H., 2022, J TRADIT CHIN MED SC, V9, P100, DOI [10.1016/j.jtcms.2022.04.004, DOI 10.1016/J.JTCMS.2022.04.004]
   Tu YY, 2011, NAT MED, V17, P1217, DOI 10.1038/nm.2471
   Wan YX, 2019, BMC COMPLEM ALTERN M, V19, DOI 10.1186/s12906-019-2580-y
   Wang Y, 2017, CHIN J INTEGR MED, V23, P654, DOI 10.1007/s11655-017-2408-x
   Wang YY, 2017, CURR PHARM DESIGN, V23, P5180, DOI 10.2174/1381612823666170918120018
   Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD1074, DOI 10.1093/nar/gkx1037
   Wu X.-y., 2020, SHANXI J TRADIT CHIN, V36, P60, DOI [10.3969/j.issn.1000-7156.2020.08.030, DOI 10.3969/J.ISSN.1000-7156.2020.08.030]
   Wu Y, 2019, NUCLEIC ACIDS RES, V47, pD1110, DOI 10.1093/nar/gky1021
   Xia P, 2020, EVID-BASED COMPL ALT, V2020, DOI 10.1155/2020/9719872
   Xin-Di H., 2019, DIGIT CHIN MED, V2, P195, DOI [10.1016/j.dcmed.2020.01.001, DOI 10.1016/J.DCMED.2020.01.001]
   Xing Y, 2020, IEEE INT C BIOINFORM, P1617, DOI 10.1109/BIBM49941.2020.9313490
   Xiong XJ, 2013, HYPERTENS RES, V36, P570, DOI 10.1038/hr.2013.18
   Yang WT, 2017, BIOCHEM PHARMACOL, V141, P143, DOI 10.1016/j.bcp.2017.07.002
   Ye HZ, 2011, CHIN J INTEGR MED, V17, P698, DOI 10.1007/s11655-011-0853-5
   Yu GH, 2018, BMC COMPLEM ALTERN M, V18, DOI 10.1186/s12906-018-2356-9
   Zhang H., 2021, IOP Conf. Ser Earth Environ. Sci, V714, P022065, DOI [10.1088/1755-1315/714/2/022065, DOI 10.1088/1755-1315/714/2/022065]
   Zhang RZ, 2019, FRONT PHARMACOL, V10, DOI 10.3389/fphar.2019.00123
   Zhang Y, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/1862168
   Zhu Y, 2019, IEEE INT C BIOINFORM, P2520, DOI 10.1109/BIBM47256.2019.8983113
NR 56
TC 1
Z9 1
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2023
VL 7
IS 1
BP 41
EP 55
DI 10.1016/j.visinf.2022.11.001
EA APR 2023
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA F2BU4
UT WOS:000980458600001
OA gold
DA 2024-07-18
ER

PT J
AU Wang, BQ
   Adachi, N
   Fujishiro, I
AF Wang, Baoqing
   Adachi, Noboru
   Fujishiro, Issei
TI FORSETI: A visual analysis environment enabling provenance awareness for
   the accountability of e-autopsy reports
SO VISUAL INFORMATICS
LA English
DT Article
DE Computational forensics; Legal medicine; Accountability; Provenance;
   Immersive analytics; Authority
ID VISUALIZATION
AB Autopsy reports play a pivotal role in forensic science. Medical examiners (MEs) and diagnostic radiologists (DRs) cross-reference autopsy results in the form of autopsy reports, while judicial personnel derive legal documents from final autopsy reports. In our prior study, we presented a visual analysis system called the forensic autopsy system for e-court instruments (FORSETI) with an extended legal medicine markup language (x-LMML) that enables MEs and DRs to author and review e-autopsy reports. In this paper, we present our extended work to incorporate provenance infrastructure with authority management into FORSETI for forensic data accountability, which contains two features. The first is a novel provenance management mechanism that combines the forensic autopsy workflow management system (FAWfMS) and a version control system called lmmlgit for x-LMML files. This management mechanism allows much provenance data on e-autopsy reports and their documented autopsy processes to be individually parsed. The second is provenance-supported immersive analytics, which is intended to ensure that the DRs' and MEs' autopsy provenances can be viewed, listed, and analyzed so that a principal ME can author their own report through accountable autopsy referencing in an augmented reality setting. A fictitious case with a synthetic wounded body is used to demonstrate the effectiveness of the provenance-aware FORSETI system in terms of data accountability through the experience of experts in legal medicine.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Wang, Baoqing; Fujishiro, Issei] Keio Univ, Grad Sch Sci & Technol, 3-14-1 Hiyoshi, Kohoku Ku, Yokohama, Kanagawa 2238522, Japan.
   [Adachi, Noboru] Univ Yamanashi, Grad Sch Med Sci, 1110 Shimokato, Chuo, Yamanashi 4093898, Japan.
C3 Keio University; University of Yamanashi
RP Fujishiro, I (corresponding author), Keio Univ, Grad Sch Sci & Technol, 3-14-1 Hiyoshi, Kohoku Ku, Yokohama, Kanagawa 2238522, Japan.
EM wangbaoqing@keio.jp; fuji@ics.keio.ac.jp
OI Fujishiro, Issei/0000-0002-8898-730X; Wang, Baoqing/0000-0002-6184-4245
FU JSPS, Japan KAKENHI [26240015, 17H00737, 21H04916]
FX Acknowledgments We gratefully thank the anonymous reviewers for their
   com-ments and suggestions regarding this work. In addition, we
   sin-cerely appreciate the evaluation of forensic experts, who gave
   professional feedback on the current FORSETI system and plans for future
   R & D on it. This work was supported in part by JSPS, Japan KAKENHI
   under the three Grants-in-Aid for Scientific Research (A) Nos. 26240015,
   17H00737, and 21H04916.
CR Ackerman MJ, 1998, P IEEE, V86, P504, DOI 10.1109/5.662875
   Al-Awami AK, 2016, IEEE T VIS COMPUT GR, V22, P738, DOI 10.1109/TVCG.2015.2467441
   Altintas I, 2004, 16TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, PROCEEDINGS, P423
   Asayama Y, 2021, 2021 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2021), P129, DOI 10.1109/CW52790.2021.00028
   Boussejra M.O., 2016, P 2016 EUROVIS SHORT, P31
   Callahan S. P., 2006, P 2006 ACM SIGMOD IN, P745, DOI [10.1145/1142473.1142574, DOI 10.1145/1142473.1142574]
   Cambridge-Dictionary, 2022, ACCOUNTABILITY
   Can O, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12427
   Cheney J, 2011, MATH STRUCT COMP SCI, V21, P1301, DOI 10.1017/S0960129511000211
   Frew J, 2008, LECT NOTES COMPUT SC, V5272, P200, DOI 10.1007/978-3-540-89965-5_21
   Gadelha LMR, 2011, FUTURE GENER COMP SY, V27, P775, DOI 10.1016/j.future.2010.05.003
   Hayatpur D., 2020, P 33 ANN ACM S US IN, P818
   Hull D, 2006, NUCLEIC ACIDS RES, V34, pW729, DOI 10.1093/nar/gkl320
   Knudsen S., 2017, P IEEE VIS 2017 WORK
   Lin KJ, 2010, INT CON ADV INFO NET, P34, DOI 10.1109/AINA.2010.167
   Loeliger J, 2012, Version Control with Git
   Lundström C, 2011, IEEE T VIS COMPUT GR, V17, P1775, DOI 10.1109/TVCG.2011.224
   Mashima D., 2012, P 3 USENIX WORKSH HL
   Muniswamy-Reddy KK, 2006, USENIX ASSOCIATION PROCEEDINGS OF THE 2006 USENIX ANNUAL TECHNICAL CONFERENCE, P43
   Murta L, 2015, LECT NOTES COMPUT SC, V8628, P71, DOI 10.1007/978-3-319-16462-5_6
   Nosowsky R, 2006, ANNU REV MED, V57, P575, DOI 10.1146/annurev.med.57.121304.131257
   Pearson S., 2013, P INT WORKSH TRUSTW
   Pearson S, 2011, IEEE INTERNET COMPUT, V15, P64, DOI 10.1109/MIC.2011.98
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Rhyne TM, 2021, IEEE COMPUT GRAPH, V41, P125, DOI 10.1109/MCG.2021.3075258
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   Simmhan YL, 2005, SIGMOD REC, V34, P31, DOI 10.1145/1084805.1084812
   Stevens JLR, 2013, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00044
   Wang B, 2022, P BIGVIS WORKSHOP ED
   Wang BQ, 2021, VISUAL COMPUT, V37, P2951, DOI 10.1007/s00371-021-02201-7
NR 30
TC 0
Z9 0
U1 7
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2022
VL 6
IS 3
BP 69
EP 80
DI 10.1016/j.visinf.2022.05.005
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 4Y5ZN
UT WOS:000861605900001
OA gold
DA 2024-07-18
ER

PT J
AU Wang, YJ
   Zhuang, YX
   Liu, YZ
   Chen, BQ
AF Wang, Yujie
   Zhuang, Yixin
   Liu, Yunzhe
   Chen, Baoquan
TI MDISN: Learning multiscale deformed implicit fields from single images
SO VISUAL INFORMATICS
LA English
DT Article
DE Single -view 3D reconstruction; Implicit neural representation;
   Multiscale deformation
AB We present a multiscale deformed implicit surface network (MDISN) to reconstruct 3D objects from single images by adapting the implicit surface of the target object from coarse to fine to the input image. The basic idea is to optimize the implicit surface according to the change of consecutive feature maps from the input image. And with multi-resolution feature maps, the implicit field is refined progressively, such that lower resolutions outline the main object components, and higher resolutions reveal fine-grained geometric details. To better explore the changes in feature maps, we devise a simple field deformation module that receives two consecutive feature maps to refine the implicit field with finer geometric details. Experimental results on both synthetic and real-world datasets demonstrate the superiority of the proposed method compared to state-of-the-art methods.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Wang, Yujie; Zhuang, Yixin; Liu, Yunzhe; Chen, Baoquan] Peking Univ, Beijing, Peoples R China.
   [Wang, Yujie] Shandong Univ, Jinan, Peoples R China.
C3 Peking University; Shandong University
RP Zhuang, YX; Chen, BQ (corresponding author), Peking Univ, Beijing, Peoples R China.
EM yixin.zhuang@gmail.com; baoquan.chen@gmail.com
RI Li, Binxu/KDO-3273-2024
OI zhuang, yixin/0000-0002-2317-4412
FU National Key R&D Program of China [2018YFB1403901, 2019YFF0302902]; NSF
   China [61902007]; Joint NSFC-ISF Research Grant, China [62161146002]
FX We thank the anonymous reviewers for their valuable comments. This work
   was supported in part by National Key R&D Program of China
   (2018YFB1403901, 2019YFF0302902) , NSF China (61902007) and Joint
   NSFC-ISF Research Grant, China (62161146002) .
CR Chen Z., 2021, PROC IEEE INT C COMP, P13087
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Deng Y, 2021, PROC CVPR IEEE, P10281, DOI 10.1109/CVPR46437.2021.01015
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Insafutdinov E, 2018, ADV NEUR IN, V31
   Jiang Y, 2020, PROC CVPR IEEE, P1248, DOI 10.1109/CVPR42600.2020.00133
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Li MY, 2020, Arxiv, DOI arXiv:2012.06650
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Liu L., 2020, ADV NEURAL INF PROCE, V33
   Liu SH, 2020, PROC CVPR IEEE, P2016, DOI 10.1109/CVPR42600.2020.00209
   Liu SC, 2019, Arxiv, DOI arXiv:1901.05567
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Mandikal P, 2019, Arxiv, DOI arXiv:1807.07796
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475
   Pan JY, 2019, IEEE I CONF COMP VIS, P9963, DOI 10.1109/ICCV.2019.01006
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Simonyan K., 2014, ARXIV
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tang JP, 2019, PROC CVPR IEEE, P4536, DOI 10.1109/CVPR.2019.00467
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang WY, 2021, Arxiv, DOI [arXiv:1905.10711, DOI 10.48550/ARXIV.1905.10711, 10.48550/arXiv.1905.10711]
   Wang WY, 2019, PROC CVPR IEEE, P1038, DOI 10.1109/CVPR.2019.00113
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu RD, 2020, PROC CVPR IEEE, P826, DOI 10.1109/CVPR42600.2020.00091
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xu Y., 2020, ECCV, P248
   Yan X., 2016, P 30 INT C NEURAL IN, P1704
   Yang MY, 2021, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR46437.2021.00328
   Yao Y, 2020, PROC CVPR IEEE, P528, DOI 10.1109/CVPR42600.2020.00061
   Zhang XM, 2018, Arxiv, DOI arXiv:1812.11166
NR 39
TC 3
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 41
EP 49
DI 10.1016/j.visinf.2022.03.003
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 3D7JN
UT WOS:000829473700001
OA gold
DA 2024-07-18
ER

PT J
AU Pinaud, B
   Vallet, J
   Melançon, G
AF Pinaud, Bruno
   Vallet, Jason
   Melancon, Guy
TI On visualization techniques comparison for large social networks
   overview: A user experiment
SO VISUAL INFORMATICS
LA English
DT Article
DE Overview visualization; User evaluation; Graphs and networks; Social
   networks
ID GRAPH LAYOUT
AB Visualizing social networks, especially an overview emphasizing their structure, i.e., communities and their interconnections, is known to be a challenging problem. In this paper, we present a set of design rationales to build such overview visualizations of social networks and our solution called Jasper. We evaluate its performances against two of the most wide-spread visualization techniques (matrix and node-link diagram) in a human-computer controlled experiment based on community-related tasks. While none of the techniques emerge as the overwhelming winner, Jasper appears to be one of the best methods for each task; a fact sustained by the marks given by the users. Overall, Jasper can be seen as an all-encompassing solution for quickly producing legible and compact overviews of large social networks on a single modern computer. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Pinaud, Bruno; Vallet, Jason; Melancon, Guy] Univ Bordeaux, CNRS, UMR 5800, LaBRI, Bordeaux, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS)
RP Pinaud, B (corresponding author), Univ Bordeaux, CNRS, UMR 5800, LaBRI, Bordeaux, France.
EM bruno.pinaud@u-bordeaux.fr; jason.vallet@u-bordeaux.fr;
   guy.melancon@u-bordeaux.fr
OI Melancon, Guy/0000-0003-3193-7261; Pinaud, Bruno/0000-0003-4814-3273
FU European Union's Horizon 2020 research and innovation programme
   [688670]; French National Research Agency [ANR-15-CE23-0002]; Agence
   Nationale de la Recherche (ANR) [ANR-15-CE23-0002] Funding Source:
   Agence Nationale de la Recherche (ANR); H2020 - Industrial Leadership
   [688670] Funding Source: H2020 - Industrial Leadership
FX This project has indirectly benefited of fundings from the European
   Union's Horizon 2020 research and innovation programme under grant
   agreement No 688670, as well as from the French National Research Agency
   under grant agreement no ANR-15-CE23-0002.
CR [Anonymous], 2013, ANAL SOCIAL WEB 1
   [Anonymous], 2014, AK PETERS VISUALIZAT
   [Anonymous], 2014, EUROVIS STARS
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   Archambault D, 2007, IEEE T VIS COMPUT GR, V13, P305, DOI 10.1109/TVCG.2007.46
   Archambault D, 2016, INFORM VISUAL, V15, P51, DOI 10.1177/1473871615576758
   Archambault D, 2009, IEEE PAC VIS SYMP, P113, DOI 10.1109/PACIFICVIS.2009.4906845
   Arleo A, 2019, IEEE T PARALL DISTR, V30, P754, DOI 10.1109/TPDS.2018.2869805
   Arleo A, 2017, INFORM SCIENCES, V381, P124, DOI 10.1016/j.ins.2016.11.012
   Auber D, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P75, DOI 10.1109/infvis.2003.1249011
   Auber D, 2013, IEEE T VIS COMPUT GR, V19, P1820, DOI 10.1109/TVCG.2013.91
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bo Wang, 2014, 2014 IEEE International Conference on Orange Technologies (ICOT), P129, DOI 10.1109/ICOT.2014.6956616
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Di Battista G., 1999, Graph Drawing: Algorithms for the Visualization of Graphs, V357
   Didimo W, 2014, INFORM SCIENCES, V260, P185, DOI 10.1016/j.ins.2013.09.048
   Duarte FSLG, 2014, IEEE T VIS COMPUT GR, V20, P2063, DOI 10.1109/TVCG.2014.2346276
   Fekete JD, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P117, DOI 10.1109/INFVIS.2002.1173156
   Fernández M, 2018, J LOG ALGEBR METHODS, V96, P12, DOI 10.1016/j.jlamp.2017.12.005
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Frishman Y., 2007, EUROVIS, P75, DOI [10.2312/VisSym/EuroVis07/075-082, DOI 10.2312/VISSYM/EUROVIS07/075-082]
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Gove R., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P19, DOI 10.1109/PASSAT/SocialCom.2011.216
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Hachul Stefan, 2007, Journal of Graph Algorithms and Applications, V11, P345, DOI 10.7155/jgaa.00150
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Huang ML, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P920, DOI 10.1109/ICIG.2007.10
   Itoh T, 2009, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2009.4906846
   Keim D.A., 1996, J COMPUT GRAPH STAT, V5, P58, DOI [10.2307/1390753, DOI 10.1080/10618600.1996.10474695]
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Klimt B, 2004, LECT NOTES COMPUT SC, V3201, P217
   KOBOUROV SG, 2012, ABS12013011 CORR
   Leskovec J., 2010, P 19 INT C WORLD WID, P641, DOI [10.1145/1772690.1772756, DOI 10.1145/1772690.1772756]
   Leskovec J., 2014, SNAP Datasets: Stanford large network dataset collection
   Leskovec J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1361
   Leskovec J, 2009, INTERNET MATH, V6, P29, DOI 10.1080/15427951.2009.10129177
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Lu J, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P592, DOI 10.1109/ICALIP.2014.7009863
   Meyerhenke H, 2015, LECT NOTES COMPUT SC, V9411, P30, DOI 10.1007/978-3-319-27261-0_3
   Morton G. M., 1966, COMPUTER ORIENTED GE
   Moscovich T, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2319
   Muelder C, 2008, IEEE T VIS COMPUT GR, V14, P1301, DOI 10.1109/TVCG.2008.158
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nick Bobo, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P525
   Nocaj A., 2015, Journal of Graph Algorithms and Applications: JGAA, V19, P595, DOI [DOI 10.7155/JGAA.00370, 10.7155/jgaa.00370, https://doi.org/10.7155/jgaa.00370]
   Ortmann M., 2017, J. Graph Algorithms Appl., V21, P791
   Perrot A, 2020, IEEE T BIG DATA, V6, P80, DOI 10.1109/TBDATA.2018.2869165
   Purchase H, 2012, Experimental Human-Computer Interaction-A Prac- tical Guide With Visual Examples
   Rufiange S, 2012, COMPUT GRAPH FORUM, V31, P89, DOI 10.1111/j.1467-8659.2011.02087.x
   Sansen J, 2015, IEEE INT CONF INF VI, P62, DOI 10.1109/iV.2015.22
   Schreck T., 2006, Proceedings of Computer Graphics (SCCG 2006), P184, DOI DOI 10.1145/2602161.2602183
   Shi L, 2009, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2009.4906836
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B., 2008, Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD '08, P3
   Stein K, 2010, 2010 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2010), P233, DOI 10.1109/ASONAM.2010.18
   Vallone J, 2016, IEEE ENER CONV
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P73, DOI 10.1109/INFVIS.1999.801860
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Wang L, 2006, EUR PHYS J B, V53, P361, DOI 10.1140/epjb/e2006-00389-0
   Wolfe AW, 1997, AM ETHNOL, V24, P219, DOI 10.1525/ae.1997.24.1.219
   Zinsmaier M, 2012, IEEE T VIS COMPUT GR, V18, P2486, DOI 10.1109/TVCG.2012.238
NR 62
TC 4
Z9 4
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2020
VL 4
IS 4
BP 23
EP 34
DI 10.1016/j.visinf.2020.09.005
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KZ
UT WOS:000658193600003
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Latif, S
   Beck, F
AF Latif, Shahid
   Beck, Fabian
TI Interactive map reports summarizing bivariate geographic data
SO VISUAL INFORMATICS
LA English
DT Article
DE Geographic visualization; Natural language generation; Interactive
   documents
AB Bivariate map visualizations use different encodings to visualize two variables but comparison across multiple encodings is challenging. Compared to a univariate visualization, it is significantly harder to read regional differences and spot geographical outliers. Especially targeting inexperienced users of visualizations, we advocate the use of natural language text for augmenting map visualizations and understanding the relationship between two geo-statistical variables. We propose an approach that selects interesting findings from data analysis, generates a respective text and visualization, and integrates both into a single document. The generated reports interactively link the visualization with the textual narrative. Users can get additional explanations and have the ability to compare different regions. The text generation process is flexible and adapts to various geographical and contextual settings based on small sets of parameters. We showcase this flexibility through a number of application examples. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Latif, Shahid; Beck, Fabian] Univ Duisburg Essen, Paluno Ruhr Inst Software Technol, Duisburg, Germany.
C3 University of Duisburg Essen
RP Latif, S (corresponding author), Univ Duisburg Essen, Paluno Ruhr Inst Software Technol, Duisburg, Germany.
EM shahid.latif@paluno.uni-due.de; fabian.beck@paluno.uni-due.de
OI Latif, Shahid/0000-0003-2060-5122
FU Baden-Wurttemberg Stiftung
FX Fabian Beck is indebted to the Baden-Wurttemberg Stiftung for the
   financial support of this research project within the Postdoctoral
   Fellowship for Leading Early Career Researchers.
CR [Anonymous], 2013, P 2013 CHI C HUMAN F, DOI [10.1145/2470654.2481374, DOI 10.1145/2470654.2481374]
   [Anonymous], 2006, BEAUTIFUL EVIDENCE
   Beck F, 2017, 2017 IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT 2017), P1, DOI 10.1109/VISSOFT.2017.11
   Beck F, 2017, IEEE T VIS COMPUT GR, V23, P1576, DOI 10.1109/TVCG.2017.2674958
   Braun D, 2018, NAT LANG ENG, V24, P551, DOI 10.1017/S1351324918000050
   Brewer C., 1998, Cartographic Perspectives, P6
   Brewer CA, 1997, ANN ASSOC AM GEOGR, V87, P411, DOI 10.1111/1467-8306.00061
   Dale R, 2005, J RES PRACT INF TECH, V37, P89
   DEAN RB, 1951, ANAL CHEM, V23, P636, DOI 10.1021/ac60052a025
   Demir S, 2012, COMPUT LINGUIST, V38, P527, DOI 10.1162/COLI_a_00091
   Elmer M.E., 2012, THESIS U WISCONSIN M
   Flannery James John, 1971, Cartographica, V8, P96, DOI DOI 10.3138/J647-1776-745H-3667
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gkatzia D, 2017, IEEE COMPUT INTELL M, V12, P10, DOI 10.1109/MCI.2017.2708998
   Goffin P, 2014, IEEE T VIS COMPUT GR, V20, P2291, DOI 10.1109/TVCG.2014.2346435
   Hardle W, 2007, Applied multivariate statistical analysis, V2007
   Hoaglin D.C., 2000, UNDERSTANDING ROBUST, V1
   Howard D., 1996, CARTOGR GEOGR INFORM, V23, P59, DOI DOI 10.1559/152304096782562109
   Hunter J, 2008, FRONT ARTIF INTEL AP, V178, P678, DOI 10.3233/978-1-58603-891-5-678
   Jain A, 2015, IEEE ENG MED BIO, P7634, DOI 10.1109/EMBC.2015.7320160
   Jo J, 2019, IEEE T VIS COMPUT GR, V25, P470, DOI 10.1109/TVCG.2018.2865141
   Kim S, 2013, IEEE T VIS COMPUT GR, V19, P1438, DOI 10.1109/TVCG.2013.66
   Kwon B. C., 2014, VISJOCKEY ENRICHING, P2
   Latif S, 2019, IEEE T VIS COMPUT GR, V25, P152, DOI 10.1109/TVCG.2018.2865022
   MACEACHREN A. M., 2004, How Maps Work: Representation, Visualization, and Design
   Mittal V. O., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1276
   Molina M, 2015, SENSORS-BASEL, V15, P16009, DOI 10.3390/s150716009
   Monmonier Mark., 1990, Cartographica, V27, P30, DOI 10.3138/U558-H737-6577-8U311
   Nelson ElisabethS., 2002, Cartographica: The International Journal for Geographic Information and Geovisualization, V37, P61, DOI DOI 10.3138/V743-K505-5510-66Q5
   Ramos-Soto A, 2017, INT J INTELL SYST, V32, DOI 10.1002/int.21835
   Ramos-Soto A, 2015, IEEE T FUZZY SYST, V23, P44, DOI 10.1109/TFUZZ.2014.2328011
   Reiter E., 2000, Building natural language generation systems
   Rousseeuw PJ, 1999, AM STAT, V53, P382, DOI 10.2307/2686061
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sripada S., 2007, P WORKSH MULT OUTP G, P149
   Thomas KavitaE., 2007, Proceedings of the Eleventh European Workshop on Natural Language Generation, P163
   Toker D, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P199, DOI 10.1145/3172944.3173009
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Turner R., 2008, P 5 INT NAT LANG GEN, P16, DOI [10.3115/1708322.1708328, DOI 10.3115/1708322.1708328]
   United Nations, 1999, STAT DIV COUNTR AR G
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   WAHLSTER W, 1993, ARTIF INTELL, V63, P387, DOI 10.1016/0004-3702(93)90022-4
NR 42
TC 11
Z9 13
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2019
VL 3
IS 1
BP 27
EP 37
DI 10.1016/j.visinf.2019.03.004
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YJ
UT WOS:000658187900004
OA gold
DA 2024-07-18
ER

PT J
AU Feng, JL
   Wu, KH
   Chen, SM
AF Feng, Jielin
   Wu, Kehao
   Chen, Siming
TI TopicBubbler: An interactive visual analytics system for cross-level
   fine-grained exploration of social media data
SO VISUAL INFORMATICS
LA English
DT Article
DE Cross level analysis; Fine grained exploration; Topic analysis; Social
   media
ID VISUALIZATION
AB How to explore fine-grained but meaningful information from the massive amount of social media data is critical but challenging. To address this challenge, we propose the TopicBubbler, a visual analytics system that supports the cross-level fine-grained exploration of social media data. To achieve the goal of cross-level fine-grained exploration, we propose a new workflow. Under the procedure of the workflow, we construct the fine-grained exploration view through the design of bubble-based word clouds. Each bubble contains two rings that can display information through different levels, and recommends six keywords computed by different algorithms. The view supports users collecting information at different levels and to perform fine-grained selection and exploration across different levels based on keyword recommendations. To enable the users to explore the temporal information and the hierarchical structure, we also construct the Temporal View and Hierarchical View, which satisfy users to view the cross-level dynamic trends and the overview hierarchical structure. In addition, we use the storyline metaphor to enable users to consolidate the fragmented information extracted across levels and topics and ultimately present it as a complete story. Case studies from real-world data confirm the capability of the TopicBubbler from different perspectives, including event mining across levels and topics, and fine-grained mining of specific topics to capture events hidden beneath the surface.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Feng, Jielin; Wu, Kehao; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Feng, Jielin] Univ Sydney, Fac Engn, Sydney, Australia.
   [Chen, Siming] Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
C3 Fudan University; University of Sydney
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.; Chen, SM (corresponding author), Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
EM jfen8896@uni.sydney.edu.au; simingchen@fudan.edu.cn
RI Chen, Siming/AAK-1874-2020
OI Chen, Siming/0000-0002-2690-3588; Wu, Kehao/0009-0005-4716-8016
FU Natural Science Foundation of China (NSFC) [62202105]; Shanghai
   Municipal Science and Technology Major Project, China [2021SHZDZX0103];
   General Program, China [21ZR1403300]; Sailing Program, China
   [21YF1402900]; ZJLab
FX This work is supported by the Natural Science Foundation of China (NSFC
   No. 62202105) and Shanghai Municipal Science and Technology Major
   Project, China (2021SHZDZX0103) , General Program (No. 21ZR1403300) ,
   Sailing Program, China (No. 21YF1402900) and ZJLab.
CR Alsakran J, 2012, IEEE COMPUT GRAPH, V32, P34, DOI 10.1109/MCG.2011.91
   [Anonymous], 2010, P 16 ACM SIGKDD INT
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch H, 2013, IEEE T VIS COMPUT GR, V19, P2022, DOI 10.1109/TVCG.2013.186
   Bouma Gerlof, 2009, Normalized (Pointwise) Mutual Information in Collocation Extraction
   Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431
   Byron L, 2008, IEEE T VIS COMPUT GR, V14, P1245, DOI 10.1109/TVCG.2008.166
   Castellà Q, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P664, DOI 10.1145/2566486.2567977
   Chen SH, 2018, DES AUT CON, DOI 10.1145/3195970.3196045
   Chen SM, 2021, IEEE T VIS COMPUT GR, V27, P1612, DOI 10.1109/TVCG.2020.3030411
   Chen SM, 2017, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST.2017.8585638
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chuang Jason, 2012, P SIGCHI C HUMAN FAC, P443, DOI [10.1145/2207676.2207738, DOI 10.1145/2207676.2207738]
   Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   Dou WW, 2012, IEEE CONF VIS ANAL, P93, DOI 10.1109/VAST.2012.6400485
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Heimerl F, 2014, P ANN HICSS, P1833, DOI 10.1109/HICSS.2014.231
   Hetzler EG, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P89, DOI 10.1109/INFVIS.2005.1532133
   Kim H, 2021, IEEE T VIS COMPUT GR, V27, P3644, DOI 10.1109/TVCG.2020.2981456
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Kontaxaki Sofia, 2010, SPIE, V7530, P232
   Kuang D, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P739
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Maceachren AM, 1997, COMPUT GEOSCI, V23, P335, DOI 10.1016/S0098-3004(97)00018-6
   Manovich L, 2012, DEBATES IN THE DIGITAL HUMANITIES, P460
   Marcus A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P227
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Schulz Hans-Jorg, 2013, P 13 INT C KNOWL MAN, P1
   Sen B.A., 2008, P 13 INT S HLTH INF, P1
   Sheth N., 2003, Proc. IEEE Information Visualization Conference, P128
   Sinclair J, 2008, J INF SCI, V34, P15, DOI 10.1177/0165551506078083
   Sun GD, 2014, IEEE T VIS COMPUT GR, V20, P1753, DOI 10.1109/TVCG.2014.2346919
   Tanahashi Y, 2015, IEEE T VIS COMPUT GR, V21, P730, DOI 10.1109/TVCG.2015.2392771
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Wenwen Dou, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P231, DOI 10.1109/VAST.2011.6102461
   Wu YC, 2018, IEEE T VIS COMPUT GR, V24, P2758, DOI 10.1109/TVCG.2017.2764459
   Xu PP, 2013, IEEE T VIS COMPUT GR, V19, P2012, DOI 10.1109/TVCG.2013.221
   Zhao J, 2013, IEEE T VIS COMPUT GR, V19, P2080, DOI 10.1109/TVCG.2013.167
NR 43
TC 1
Z9 1
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 41
EP 56
DI 10.1016/j.visinf.2023.08.002
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DQ9U2
UT WOS:001133655100001
OA gold
DA 2024-07-18
ER

PT J
AU Wang, XL
   Zhang, RF
   Shen, CH
   Kong, T
AF Wang, Xinlong
   Zhang, Rufeng
   Shen, Chunhua
   Kong, Tao
TI DenseCL: A simple framework for self-supervised dense visual
   pre-training
SO VISUAL INFORMATICS
LA English
DT Article
DE Self-supervised learning; Visual pre-training; Dense prediction tasks
AB Self-supervised learning aims to learn a universal feature representation without labels. To date, most existing self-supervised learning methods are designed and optimized for image classification. These pre-trained models can be sub-optimal for dense prediction tasks due to the discrepancy between image-level prediction and pixel-level prediction. To fill this gap, we aim to design an effective, dense self-supervised learning framework that directly works at the level of pixels (or local features) by tak-ing into account the correspondence between local features. Specifically, we present dense contrastive learning (DenseCL), which implements self-supervised learning by optimizing a pairwise contrastive (dis)similarity loss at the pixel level between two views of input images. Compared to the supervised ImageNet pre-training and other self-supervised learning methods, our self-supervised DenseCL pre -training demonstrates consistently superior performance when transferring to downstream dense prediction tasks including object detection, semantic segmentation and instance segmentation. Specif-ically, our approach significantly outperforms the strong MoCo-v2 by 2.0% AP on PASCAL VOC object detection, 1.1% AP on COCO object detection, 0.9% AP on COCO instance segmentation, 3.0% mIoU on PASCAL VOC semantic segmentation and 1.8% mIoU on Cityscapes semantic segmentation. The improvements are up to 3.5% AP and 8.8% mIoU over MoCo-v2, and 6.1% AP and 6.1% mIoU over supervised counterpart with frozen-backbone evaluation protocol.Code and models are available at: https://git.io/DenseCL (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Wang, Xinlong; Shen, Chunhua] Univ Adelaide, Adelaide, Australia.
   [Shen, Chunhua] Zhejiang Univ, Hangzhou, Peoples R China.
   [Zhang, Rufeng] Tongji Univ, Shanghai, Peoples R China.
   [Kong, Tao] ByteDance AI Lab, Beijing, Peoples R China.
C3 University of Adelaide; Zhejiang University; Tongji University
RP Shen, CH (corresponding author), Univ Adelaide, Adelaide, Australia.
EM Chunhua@icloud.com
RI zhang, rufeng/KMX-8433-2024; Wang, Xinlong/HTS-0660-2023
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Chaitanya K, 2020, Arxiv, DOI arXiv:2006.10511
   Chen Ting, P INT C MACH LEARN
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   Choy CB, 2016, ADV NEUR IN, V29
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Gidaris S., 2018, PROC INT C LEARN REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goyal P, 2019, IEEE I CONF COMP VIS, P6400, DOI 10.1109/ICCV.2019.00649
   Grill J.-B., 2020, arXiv, V33, P21271
   Halimi O, 2019, PROC CVPR IEEE, P4365, DOI 10.1109/CVPR.2019.00450
   Han Tengda, 2020, PROC ADV NEURAL INF, V33
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650
   Kim S, 2017, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2017.73
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Li H., 2019, ARXIV, DOI 1905.09979
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Oord Aaron van den, 2018, COMP RES REPOS
   OpenMMLab, 2020, MMSEGM
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pinheiro Pedro, 2020, COMP RES REPOS
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tian Y., 2020, NeurIPS, V33, P6827
   Tian YL, 2020, Arxiv, DOI arXiv:1906.05849
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang XL, 2021, PROC CVPR IEEE, P3023, DOI 10.1109/CVPR46437.2021.00304
   Wu Y., 2019, DETECTRON2
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xie SN, 2020, Arxiv, DOI arXiv:2007.10985
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhan XH, 2020, PROC CVPR IEEE, P6687, DOI 10.1109/CVPR42600.2020.00672
   Zhang C, 2016, INT J COMPUT VISION, V116, P90, DOI 10.1007/s11263-015-0829-6
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhao NX, 2021, Arxiv, DOI arXiv:2006.06606
   Zhou DZ, 2020, Arxiv, DOI arXiv:2004.12178
NR 52
TC 2
Z9 2
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2023
VL 7
IS 1
BP 30
EP 40
DI 10.1016/j.visinf.2022.09.003
EA MAR 2023
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA D9IH4
UT WOS:000971785500001
OA gold
DA 2024-07-18
ER

PT J
AU Bryan, C
   Mishra, A
   Shidara, H
   Ma, KL
AF Bryan, Chris
   Mishra, Aditi
   Shidara, Hidekazu
   Ma, Kwan-Liu
TI Analyzing gaze behavior for text-embellished narrative visualizations
   under different task scenarios
SO VISUAL INFORMATICS
LA English
DT Article
DE Narrative visualization; Eye tracking; Perception; User study
ID ANNOTATED ILLUSTRATIONS; EYE-MOVEMENTS; ATTENTION; SEARCH; DESIGN
AB We conduct an eye tracking study to investigate perception text-embellished narrative visualizations under different task conditions. Study stimuli are data visualizations embellished with text-based elements: annotations, captions, labels, and descriptive text. We consider three common viewing tasks that occur when these types of graphics are viewed: (1) simple observation, (2) active search to answer a query, and (3) information memorization for later recall. The overarching goal is to understand, at a perceptual level, if and how task affects how these visualizations are interacted with. By analyzing collected gaze data and conducting advanced semantic scanpath analysis, we find, at a high level, diverse patterns of gaze behavior: simple observation and information memorization lead to similar optical viewing strategies, while active search significantly diverges, both in regards to which areas of the visualization are focused upon and how often embellishments are interacted with. We discuss study outcomes in the context of embellishing visualizations with text for various usage scenarios. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Bryan, Chris; Mishra, Aditi] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA.
   [Shidara, Hidekazu; Ma, Kwan-Liu] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
C3 Arizona State University; Arizona State University-Tempe; University of
   California System; University of California Davis
RP Bryan, C (corresponding author), Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA.
EM cbryan16@asu.edu
OI Bryan, Christopher/0000-0003-2430-815X
FU National Science Foundation, United States [IIS-1528203]
FX This research has been sponsored in part by the National Science
   Foundation, United States through grant IIS-1528203.
CR Acarturk C., 2012, Diagrammatic representation and inference, P95, DOI DOI 10.1007/978-3-642-31223-6_13
   Atkinson R. C., 1968, Psychology of learning and motivation, V2, P89, DOI [10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3, DOI 10.1017/CBO9781316422250.025]
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cohen S, 2011, COMMUN ACM, V54, P66, DOI 10.1145/2001269.2001288
   Drieghe Denis., 2011, OXFORD HDB EYE MOVEM
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Goldberg J, 2011, INFORM VISUAL, V10, P182, DOI 10.1177/1473871611406623
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   HEGARTY M, 1993, J MEM LANG, V32, P717, DOI 10.1006/jmla.1993.1036
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Kenneth HolmqvistMarcus Nystrom., 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Matzen LE, 2018, IEEE T VIS COMPUT GR, V24, P563, DOI 10.1109/TVCG.2017.2743939
   Matzen LE, 2017, LECT NOTES ARTIF INT, V10284, P176, DOI 10.1007/978-3-319-58628-1_15
   Mayer RE, 2005, J EXP PSYCHOL-APPL, V11, P256, DOI 10.1037/1076-898X.11.4.256
   MAYER RE, 1995, ETR&D-EDUC TECH RES, V43, P31, DOI 10.1007/BF02300480
   Moere AV, 2011, INFORM VISUAL, V10, P356, DOI 10.1177/1473871611415996
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Neisser U., 1979, PERCEPTION ITS DEV T, P201
   Netzel R, 2017, SPAT COGN COMPUT, V17, P39, DOI 10.1080/13875868.2016.1226839
   Netzel R, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P183, DOI 10.1145/2857491.2857498
   Netzel R, 2017, IEEE T VIS COMPUT GR, V23, P421, DOI 10.1109/TVCG.2016.2598898
   Ottley A., 2019, EUROVIS SHORT PAPERS, P121
   Polatsek P, 2018, COMPUT GRAPH-UK, V72, P26, DOI 10.1016/j.cag.2018.01.010
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Rayner K, 2009, Q J EXP PSYCHOL, V62, P1457, DOI 10.1080/17470210902816461
   Reppa Irene, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P1155, DOI 10.1518/107118108X351644
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shah P, 2002, EDUC PSYCHOL REV, V14, P47, DOI 10.1023/A:1013180410169
   Shen CY, 2014, LECT NOTES COMPUT SC, V8695, P33, DOI 10.1007/978-3-319-10584-0_3
   Sireci SG, 2003, J EDUC MEAS, V40, P277, DOI 10.1111/j.1745-3984.2003.tb01108.x
   Steichen B., 2013, P INT C INT US INT A, P317, DOI [10.1145/2449396.2449439, DOI 10.1145/2449396.2449439]
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774
   Yarbus A. L., 1967, Eye Movements and Vision
NR 43
TC 6
Z9 7
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2020
VL 4
IS 3
BP 41
EP 50
DI 10.1016/j.visinf.2020.08.001
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KP
UT WOS:000658192600004
OA gold
DA 2024-07-18
ER

PT J
AU Dong, Y
AF Dong, Yue
TI Deep appearance modeling: A survey
SO VISUAL INFORMATICS
LA English
DT Article
DE Appearance modeling; Surface reflectance; Reflectance field; Light field
AB Appearance modeling is an essential task in computer graphics for capturing and reproducing rich appearance of real world materials under different lighting and viewing conditions. With recent advances of deep learning techniques, a set of deep learning based approaches have been proposed for improving the efficiency and result quality of appearance modeling. In this paper, we provide a survey of these deep appearance modeling techniques from both graphics and machine learning perspectives, and discuss the challenges and opportunities along this direction. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Dong, Yue] Microsoft Res Asia, T2 Microsoft Bldg,5th Danling St, Beijing, Peoples R China.
C3 Microsoft; Microsoft Research Asia
RP Dong, Y (corresponding author), Microsoft Res Asia, T2 Microsoft Bldg,5th Danling St, Beijing, Peoples R China.
EM yuedong@microsoft.com
CR Aittala M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925917
   Aittala M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461978
   Allegorithmic,, 2019, AD STOCK
   Allegorithmic, 2018, SUBSTANCE SHARE
   [Anonymous], 2018, ARXIV180406215
   [Anonymous], 2012, P 29 INT C MACH LEAR
   [Anonymous], 2019, COMPUTER GRAPHICS FO
   [Anonymous], 2015, ACM SIGGRAPH ASIA CO
   Ashikhmin M, 2000, COMP GRAPH, P65, DOI 10.1145/344779.344814
   Belcour L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201289
   Bell S, 2015, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR.2015.7298970
   Bell S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462002
   Brady A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601193
   Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819
   Deschaintre V, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13765
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dong B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766979
   Dong Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778835
   Dorsey J, 2008, MKS COMP GRAPH GEOME, P1
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Guojun Chen, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601180
   Holzschuch N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073621
   Jakob W, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601186
   Jakob W, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601139
   Jensen HW, 2002, ACM T GRAPHIC, V21, P576, DOI 10.1145/566570.566619
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Kim K, 2017, IEEE I CONF COMP VIS, P20, DOI 10.1109/ICCV.2017.12
   Lan YX, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461989
   Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949
   Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Li ZQ, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275055
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Lombardi S, 2012, PROC CVPR IEEE, P238, DOI 10.1109/CVPR.2012.6247681
   Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343
   Mcallister D.K., 2002, THESIS
   Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280
   Nicodemus F. E., 1992, Geometrical Considerations and Nomenclature for Reflectance, P94
   Nicodemus F.E., 1977, MONOGRAPH NAT BUR ST, V161
   Peers P, 2006, ACM T GRAPHIC, V25, P746, DOI 10.1145/1141911.1141950
   Peers P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477929
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Ren PR, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462009
   Ren PR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964940
   Riviere J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130894
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Toisoul A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275077
   Toisoul A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3012001
   Walter B., 2007, EUROGRAPHICS C RENDE
   Wang J., 2007, ACM T GRAPHIC, V27
   Wang JP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360640
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
   Werner S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130840
   Wu HZ, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508394
   Wu HZ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024179
   Wu HZ, 2009, COMPUT GRAPH FORUM, V28, P1227, DOI 10.1111/j.1467-8659.2009.01500.x
   Xu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201313
   Yan LQ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925915
   Yan LQ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601155
   Ye W., 2018, COMPUT GRAPH FORUM, V37
   Zeltner T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201321
   Zhou ZM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980247
   Zickler Todd., 2005, RENDERING TECHNIQUES, P253
   Zsolnai-Fehér K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201307
NR 69
TC 30
Z9 34
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2019
VL 3
IS 2
BP 59
EP 68
DI 10.1016/j.visinf.2019.07.003
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YK
UT WOS:000658189200001
OA gold
DA 2024-07-18
ER

PT J
AU Mao, X
   Xu, J
   Lang, JH
   Zhang, SS
AF Mao, Xue
   Xu, Jie
   Lang, Jiahong
   Zhang, Shangshu
TI Visualization of isomorphism-synesthesia of colour and music
SO VISUAL INFORMATICS
LA English
DT Article
DE Synesthesia in art; Music visualization tools; Custom interaction
AB Music and colour, as human hearing and visual art, are closely related to human psychological feelings and symbolic associations. There is an isomorphic relationship between music and colour. The article uses the concept of "synesthesia"in psychology and the "co-construction"relationship in mathematics as a bridge, based on Kandinsky's "inner sound"theory and Mallion's "tone-colour system", an interdisciplinary theoretical model of "timbre isomorphism synesthesia"(ISCM) is constructed. At the practical level, based on the ISCM theory, a set of timbre synesthesia visualization tools ASAH and visualization processes are designed, through music data input, graphics mapping visualization, colour mapping visualization, real-time interactive visualization, and finally output timbre synesthesia visualization works. In order to avoid the visual homogenization caused by algorithm design, ASHA has set up a custom editor, which emphasizes the individual differences and multi-sensory experience of tonal synesthesia visualization.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Mao, Xue; Xu, Jie; Lang, Jiahong; Zhang, Shangshu] China Acad Art, Hangzhou, Peoples R China.
C3 China Academy of Art
RP Mao, X (corresponding author), China Acad Art, Hangzhou, Peoples R China.
EM 0121058@caa.edu.cn
CR [Anonymous], 1787, Entdeckungen Uber die Theorie des Klanges
   Cytowic RichardE., 2002, Synesthesia: A Union of the Senses
   Field George, 1839, Relat. Purp. Nat. Sci., V1
   Jenny Hans., 2007, Cymatics: A Study of Wave Phenomena and Vibration
   Jones R, 2005, COMPUT MUSIC J, V29, P55, DOI 10.1162/014892605775179900
   Kandinsky Wassily., 1979, Point and Line to Plane
   Maryon Edward., 1919, Marcotone: The Science of Tone-Color
   McLuhan Marshall, 2001, Understanding Media: The Extensions of Man(1964), P11
   Salzinger Julia., 2010, metaphorik, V18, P57
NR 9
TC 2
Z9 2
U1 5
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 110
EP 114
DI 10.1016/j.visinf.2023.10.006
EA DEC 2023
PG 5
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DX5I8
UT WOS:001135393100001
OA gold
DA 2024-07-18
ER

PT J
AU Liu, AA
   Wang, XW
   Xu, N
   Guo, JB
   Jin, GQ
   Zhang, Q
   Tang, YJ
   Zhang, SY
AF Liu, An-An
   Wang, Xiaowen
   Xu, Ning
   Guo, Junbo
   Jin, Guoqing
   Zhang, Quan
   Tang, Yejun
   Zhang, Shenyuan
TI A review of feature fusion-based media popularity prediction methods
SO VISUAL INFORMATICS
LA English
DT Review
DE Social media; Popularity prediction; Multi-modal analysis
ID INFORMATION DIFFUSION; MICROBLOGS; SENTIMENT; MODEL
AB With the popularization of social media, the way of information transmission has changed, and the prediction of information popularity based on social media platforms has attracted extensive attention. Feature fusion-based media popularity prediction methods focus on the multi-modal features of social media, which aim at exploring the key factors affecting media popularity. Meanwhile, the methods make up for the deficiency in feature utilization of traditional methods based on information propagation processes. In this paper, we review feature fusion-based media popularity prediction methods from the perspective of feature extraction and predictive model construction. Before that, we analyze the influencing factors of media popularity to provide intuitive understanding. We further argue about the advantages and disadvantages of existing methods and datasets to highlight the future directions. Finally, we discuss the applications of popularity prediction. To the best of our knowledge, this is the first survey reporting feature fusion-based media popularity prediction methods. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Liu, An-An; Guo, Junbo; Jin, Guoqing] Peoples Daily Online, State Key Lab Commun Content Cognit, Beijing 100733, Peoples R China.
   [Liu, An-An; Wang, Xiaowen; Xu, Ning] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Zhang, Quan] Peking Univ, Beijing 100871, Peoples R China.
   [Tang, Yejun] Kuaishou Technol, Beijing 100000, Peoples R China.
   [Zhang, Shenyuan] New Media Ctr, Peoples Daily, Beijing 100000, Peoples R China.
C3 Tianjin University; Peking University
RP Xu, N (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM ningxu@tju.edu.cn
FU National Natural Science Foundation of China [62002257, U21B2024];
   Funding Project of the State Key Laboratory of Communication Content
   Cognition [A02106]; Open Funding Project of the State Key Laboratory of
   Communication Content Cognition [20K04]; China Postdoctoral Science
   Foundation [2021M692395]
FX This work was supported in part by National Natural Science Foundation
   of China (62002257, U21B2024) , the Funding Project of the State Key
   Laboratory of Communication Content Cognition (Grant No. A02106) , the
   Open Funding Project of the State Key Laboratory of Communication
   Content Cognition (Grant No. 20K04) and the China Postdoctoral Science
   Foundation (2021M692395) .
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Agarwal D., 2008, ADV NEURAL INF PROCE, V21
   [Anonymous], 2012, P 5 ACM INT C WEB SE, DOI [10.1145/2124295.2124320, DOI 10.1145/2124295.2124320]
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   [Anonymous], 2012, CHIN J INF SCI
   Bae Y, 2012, J AM SOC INF SCI TEC, V63, P2521, DOI 10.1002/asi.22768
   Bakshy E., 2011, P 4 ACM INT C WEB SE, P65
   Bao P, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P9, DOI 10.1145/2740908.2742744
   Bao P, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P177
   Bao S., 2007, P 16 INT C WORLD WID, P501, DOI DOI 10.1145/1242572.1242640
   Bao Z., 2019, THESIS BEIJING JIAOT
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Chen GD, 2019, NEUROCOMPUTING, V333, P221, DOI 10.1016/j.neucom.2018.12.039
   [陈江 Chen Jiang], 2015, [中文信息学报, Journal of Chinese Information Processing], V29, P150
   Chen JH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2692, DOI 10.1145/3343031.3356072
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cheng J, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P925, DOI 10.1145/2566486.2567997
   Daley DJ, 1965, IMA J Appl Math, V1, P42, DOI DOI 10.1093/IMAMAT/1.1.42
   Deng Q., 2015, J TSINGHUA U NAT SCI, P1342
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding KY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1979, DOI 10.1145/3343031.3351007
   Ding KY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2682, DOI 10.1145/3343031.3356062
   Ferrara E, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.26
   Figueiredo F, 2016, INFORM SCIENCES, V349, P172, DOI 10.1016/j.ins.2016.02.025
   Gao S, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P107, DOI 10.1145/2684822.2685303
   Gelli F, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P907, DOI 10.1145/2733373.2806361
   Gharibshah Z, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3446662
   Ghose A, 2009, MANAGE SCI, V55, P1605, DOI 10.1287/mnsc.1090.1054
   Gonçalves MA, 2010, IEEE INTERNET COMPUT, V14, P42, DOI 10.1109/MIC.2010.73
   Hajarian M, 2021, STRATEGIC CORPORATE COMMUNICATION IN THE DIGITAL AGE, P235, DOI 10.1108/978-1-80071-264-520211014
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2672, DOI 10.1145/3343031.3356054
   Hsu CC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2687, DOI 10.1145/3343031.3356064
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu Y, 2016, NEUROCOMPUTING, V210, P55, DOI 10.1016/j.neucom.2015.10.143
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Kang PP, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2677, DOI 10.1145/3343031.3356060
   Ke GL, 2017, ADV NEUR IN, V30
   Kong Qing-Chao, 2014, Journal of Software, V25, P2767, DOI 10.13328/j.cnki.jos.004730
   Koren Y, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P447
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai X, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4565, DOI 10.1145/3394171.3416273
   Li JN, 2019, IEEE DATA MINING, P1174, DOI 10.1109/ICDM.2019.00143
   Li Y, 2020, NEUROCOMPUTING, V412, P372, DOI 10.1016/j.neucom.2020.05.092
   Lifshits Yury., 2010, Ediscope: Social Analytics for Online News
   Lin HH, 2022, IEEE ACCESS, V10, P4448, DOI 10.1109/ACCESS.2021.3136552
   Maki D.P., 1973, Technical report
   Matsubara Y, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P721, DOI 10.1145/2736277.2741092
   Mazloom M., 2016, P ACM MULT, P197, DOI [10.1145/2964284.2967210, 10]
   Nancy JGA, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION AND ELECTRONICS SYSTEMS (ICCES 2018), P749, DOI 10.1109/CESYS.2018.8724022
   Prokhorenkova L, 2018, ADV NEUR IN, V31
   Sabate F, 2014, EUR MANAG J, V32, P1001, DOI 10.1016/j.emj.2014.05.001
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sanjo S, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2279, DOI 10.1145/3132847.3133137
   Shen HW, 2014, AAAI CONF ARTIF INTE, P291
   Stieglitz S, 2013, J MANAGE INFORM SYST, V29, P217, DOI 10.2753/MIS0742-1222290408
   Suh DM, 2010, INTERSOC C THERMAL T
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Tan CH, 2014, Arxiv, DOI arXiv:1405.1438
   Tatar A, 2014, J INTERNET SERV APPL, V5, DOI 10.1186/s13174-014-0008-y
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Van Canneyt S, 2018, MULTIMED TOOLS APPL, V77, P1409, DOI 10.1007/s11042-017-4348-z
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, CHINA COMMUN, V10, P13, DOI 10.1109/CC.2013.6488827
   Wang K, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4570, DOI 10.1145/3394171.3416294
   Weng L., 2014, 8 INT AAAI C WEBLOGS
   Wu B, 2017, Arxiv, DOI arXiv:1712.04443
   Wu B, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2667, DOI 10.1145/3343031.3356084
   Wu B, 2015, INT J INFORM MANAGE, V35, P702, DOI 10.1016/j.ijinfomgt.2015.07.003
   Xiao CJ, 2020, INFORM SCIENCES, V525, P82, DOI 10.1016/j.ins.2020.03.056
   Xiong F, 2012, PHYS LETT A, V376, P2103, DOI 10.1016/j.physleta.2012.05.021
   Xu KL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4580, DOI 10.1145/3394171.3416274
   Yang J., 2011, P 4 ACM INT C WEB SE, P177, DOI DOI 10.1145/1935826.1935863
   Yang J, 2010, ICIM 2010: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON INDUSTRIAL MANAGEMENT, P356
   Yang J, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 2, P593, DOI 10.1109/ICCSIT.2010.5564008
   Zhang H, 2020, Arxiv, DOI arXiv:2004.08955
NR 79
TC 1
Z9 1
U1 3
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 78
EP 89
DI 10.1016/j.visinf.2022.07.003
EA NOV 2022
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100007
DA 2024-07-18
ER

PT J
AU Sun, YJ
   Li, J
   Chen, SM
   Andrienko, G
   Andrienko, N
   Zhang, K
AF Sun, Yongjian
   Li, Jie
   Chen, Siming
   Andrienko, Gennady
   Andrienko, Natalia
   Zhang, Kang
TI A learning-based approach for efficient visualization construction
SO VISUAL INFORMATICS
LA English
DT Article
DE Learned index; Neural network; Visualization index; Interactive
   exploration; Spatiotemporal visualization
ID REAL-TIME EXPLORATION; LARGE-SCALE GRAPHS; VISUAL ANALYTICS; LAYOUT
AB We propose an approach to underpin interactive visual exploration of large data volumes by training Learned Visualization Index (LVI). Knowing in advance the data, the aggregation functions that are used for visualization, the visual encoding, and available interactive operations for data selection, LVI allows to avoid time-consuming data retrieval and processing of raw data in response to user's interactions. Instead, LVI directly predicts aggregates of interest for the user's data selection. We demonstrate the efficiency of the proposed approach in application to two use cases of spatio-temporal data at different scales. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Sun, Yongjian; Li, Jie] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
   [Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Andrienko, Gennady; Andrienko, Natalia] Fraunhofer Inst IAIS, Berlin, Germany.
   [Andrienko, Gennady; Andrienko, Natalia] City Univ London, London, England.
   [Zhang, Kang] Beijing Normal Univ Hong Kong Baptist Univ United, Beijing, Peoples R China.
C3 Tianjin University; Fudan University; Fraunhofer Gesellschaft; City
   University London; Hong Kong Baptist University; Beijing Normal
   University - Hong Kong Baptist University United International College
RP Li, J (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
EM jie.li@tju.edu.cn
RI Andrienko, Natalia/KHV-4755-2024; Sun, Yongjian/HHR-9577-2022;
   Andrienko, Gennady L./B-6486-2014; Chen, Siming/AAK-1874-2020
OI Sun, Yongjian/0000-0001-8688-8394; Andrienko, Gennady
   L./0000-0002-8574-6295; Chen, Siming/0000-0002-2690-3588
FU National Key R&D Program of China [2018YFC0831700]; NSFC project
   [61972278]; Natural Science Foundation of Tianjin [20JCQNJC01620];
   Browser Project [CEIEC-2020-ZM02-0132]
FX This work is supported by National Key R&D Program of China
   (2018YFC0831700), NSFC project (61972278), Natural Science Foundation of
   Tianjin (20JCQNJC01620), and the Browser Project (CEIEC-2020-ZM02-0132).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Amershi S, 2014, AI MAG, V35, P105, DOI 10.1609/aimag.v35i4.2513
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   [Anonymous], 2008, P 2008 ACM SIGMOD IN, DOI DOI 10.1145/1376616.1376675
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Bertin J, 1983, IN PRESS
   Cao GF, 2015, COMPUT ENVIRON URBAN, V51, P70, DOI 10.1016/j.compenvurbsys.2015.01.002
   Chaudhuri S., 1997, SIGMOD Record, V26, P65, DOI 10.1145/248603.248616
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Collins C, 2018, VIS INFORM, V2, P166, DOI 10.1016/j.visinf.2018.09.003
   Crow F. C., 1984, Computers & Graphics, V18, P207
   El-Assady M, 2018, IEEE T VIS COMPUT GR, V24, P382, DOI 10.1109/TVCG.2017.2745080
   Guo J, 2015, ARXIV150901354
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Haroz S, 2012, IEEE T VIS COMPUT GR, V18, P2402, DOI 10.1109/TVCG.2012.233
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kraska T., 2019, CIDR
   Kraska T, 2018, INT CONF MANAGE DATA, P489, DOI 10.1145/3183713.3196909
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Li MZ, 2018, COMPUT GRAPH FORUM, V37, P217, DOI 10.1111/cgf.13414
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Ma K.-L, 2018, IEEE T VIS COMPUT GR
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Mei HH, 2020, IEEE T VIS COMPUT GR, V26, P1161, DOI 10.1109/TVCG.2019.2934800
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Miranda F, 2018, COMPUT GRAPH FORUM, V37, P23, DOI 10.1111/cgf.13398
   Miranda F, 2018, IEEE T VIS COMPUT GR, V24, P1394, DOI 10.1109/TVCG.2017.2671341
   MySQL A B., 2001, MySQL
   Pahins CAL, 2017, IEEE T VIS COMPUT GR, V23, P671, DOI 10.1109/TVCG.2016.2598624
   Paszke A., 2017, PYTORCH COMPUT SOFTW, V6
   Richter S, 2015, PROC VLDB ENDOW, V9, P96
   Sacha D, 2018, IEEE T VIS COMPUT GR, V24, P120, DOI 10.1109/TVCG.2017.2744805
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Shekhar S, 2002, IEEE 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P674, DOI 10.1109/ITSC.2002.1041299
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang Z., 2018, CORR ABS180808983 AR
   Wang Z, 2017, IEEE T VIS COMPUT GR, V23, P681, DOI 10.1109/TVCG.2016.2598694
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xia JZ, 2021, IEEE COMPUT GRAPH, V41, P79, DOI 10.1109/MCG.2021.3098804
   Xia JZ, 2020, IEEE CONF VIS ANAL, P107, DOI 10.1109/VAST50239.2020.00015
   Xie P., 2021, ARXIV PREPRINT ARXIV
   Zhao Y, 2019, IEEE T VIS COMPUT GR, V25, P12, DOI 10.1109/TVCG.2018.2865020
   Zhu MF, 2021, IEEE T VIS COMPUT GR, V27, P1666, DOI 10.1109/TVCG.2020.3030447
NR 55
TC 3
Z9 3
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 6
IS 1
BP 14
EP 25
DI 10.1016/j.visinf.2022.01.001
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2S0ZC
UT WOS:000821528800002
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Li, M
   Wang, Y
   Xu, YQ
AF Li, Meng
   Wang, Yun
   Xu, Ying-Qing
TI Computing for Chinese Cultural Heritage
SO VISUAL INFORMATICS
LA English
DT Article
DE Cultural computing; Chinese Cultural Heritage; Computable cultural
   ecosystem; Mogao caves; Guqin
AB Implementing computational methods for preservation, inheritance, and promotion of Cultural Heritage (CH) has become a research trend across the world since the 1990s. In China, generations of scholars have dedicated themselves to studying the country's rich CH resources; there are great potential and opportunities in the field of computational research on specific cultural artefacts or artforms. Based on previous works, this paper proposes a systematic framework for Chinese Cultural Heritage Computing that consists of three conceptual levels which are Chinese CH protection and development strategy, computing process, and computable cultural ecosystem. The computing process includes three modules: (1) data acquisition and processing, (2) digital modeling and database construction, and (3) data application and promotion. The modules demonstrate the computing approaches corresponding to different phases of Chinese CH protection and development, from digital preservation and inheritance to presentation and promotion. The computing results can become the basis for the generation of cultural genes and eventually the formation of computable cultural ecosystem Case studies on the Mogao caves in Dunhuang and the art of Guqin, recognized as world's important tangible and intangible cultural heritage, are carried out to elaborate the computing process and methods within the framework. With continuous advances in data collection, processing, and display technologies, the framework can provide constructive reference for building up future research roadmaps in Chinese CH computing and related fields, for sustainable protection and development of Chinese CH in the digital age. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Li, Meng] Commun Univ China, Beijing 100024, Peoples R China.
   [Li, Meng] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.
   [Wang, Yun] Beihang Univ, Beijing 100191, Peoples R China.
   [Wang, Yun; Xu, Ying-Qing] Tsinghua Univ, Beijing 100084, Peoples R China.
C3 Communication University of China; Beijing University of Posts &
   Telecommunications; Beihang University; Tsinghua University
RP Wang, Y (corresponding author), Beihang Univ, Beijing 100191, Peoples R China.; Wang, Y; Xu, YQ (corresponding author), Tsinghua Univ, Beijing 100084, Peoples R China.
EM wang_yun@buaa.edu.cn; yqxu@mail.tsinghua.edu.cn
OI Li, Meng/0000-0002-0737-2910
FU Engineering Research Center of Digital Film and Television Animation
   Creation Ministry of Education of China [2021CGE11]
FX This work is supported by the Engineering Research Center of Digital
   Film and Television Animation Creation Ministry of Education of China
   (2021CGE11). The authors would thank Zijin Li, Rongfeng Li, Xinyi Fu, Di
   Zhao, Li Huang for proofreading, and the anonymous reviewers for their
   valuable comments and suggestions for improving the quality of this
   paper.
CR [Anonymous], 2009, J NANJING ARTS I MUS, DOI DOI 10.3969/J.ISSN.1008-9667.2009.03.018
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   CHEN C, 1989, CHINESE J COMPUT, P525
   Chen G., 2012, J HANGZHOU NORM U NA, V11, P561, DOI [10.3969/j.issn.1674-232X.2012.06.017, DOI 10.3969/J.ISSN.1674-232X.2012.06.017]
   Chen G., 2010, J HANGZHOU NORM U NA, V9, P473, DOI [10.3969/j.issn.1674-232X.2010.06.016, DOI 10.3969/J.ISSN.1674-232X.2010.06.016]
   Chen T., 2014, LIT ART CRIT, V09, P77, DOI [10.16566/j.cnki.1003-5672.2014.09.018, DOI 10.16566/J.CNKI.1003-5672.2014.09.018]
   Chen Z., 2016, DUNHUANG RES CHINA, V156, P100, DOI [10.13584/j.cnki.issn1000-4106.2016.02.014, DOI 10.13584/J.CNKI.ISSN1000-4106.2016.02.014]
   Cignoni P., 2008, ACM Journal on Computing and Cultural Heritage, V1, P1, DOI [10.1145/1367080.1367082, DOI 10.1145/1367080.1367082]
   DAWKINS R, 1976, SELFISH GENE
   DING X, 2008, MUSICOLOGY IN CHINA, P93, DOI DOI 10.3969/J.ISSN.1003-0042.2008.02.018
   Dragos E., 2015, P 7 BALKAN C INFORMA, V1, P2, DOI [10.1145/2801081.2801083, DOI 10.1145/2801081.2801083]
   Fan J., 2004, DUNHUANG RES, V85, P5
   Fan Jinshi., 2009, ART MOGAO GROTTOES D
   Foni AE, 2010, ACM J COMPUT CULT HE, V3, DOI 10.1145/1805961.1805962
   Fu X., 2019, J ZHUANGSHI, V309, P7, DOI [10.16272/j.cnki.cn11-1392/j.2019.01.007, DOI 10.16272/J.CNKI.CN11-1392/J.2019.01.007]
   Fu X., 2017, ISPRS Annals of the Photogrammetry Remote Sensing and Spatial Information Sciences, V4, P99
   Fu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376673
   Fu XY., 2021, Dunhuang Res, V01, P137
   Giglitto D, 2019, 9TH INTERNATIONAL CONFERENCE ON COMMUNITIES & TECHNOLOGIES (C&T), P81, DOI 10.1145/3328320.3328386
   Gu Y., 2010, MIND COMPUT, V04, P128
   [胡最 Hu Zui], 2021, [地球信息科学学报, Journal of Geo-Information Science], V23, P1632
   [华忠 Hua Zhong], 2002, [中国图象图形学报. A, Journal of image and graphics], V7, P181
   Huang M, 2011, CULTURE IND GUIDE, V2011, P14
   Koller D., 2010, ACM J COMPUT CULT HE, V2, p7:1
   Li M., 2008, CHINESE MUSIC, V01, P86, DOI [10.3969/j.issn.1002-9923.2008.01.013, DOI 10.3969/J.ISSN.1002-9923.2008.01.013]
   Li Ming-xin, 2013, Journal of Jilin University (Engineering and Technology Edition), V43, P152
   Li S., 1995, DUNHUANG RES, V03, P29
   [李圣辰 Li Shengchen], 2020, [复旦学报. 自然科学版, Journal of Fudan University. Natural Sciences], V59, P276
   Li Z., 2002, Dunhuang Res, V74, P11
   Liang X., 2017, DUNHUANG RES, V161, P132, DOI [10.13584/j.cnki.issn1000-4106.2017.01.032, DOI 10.13584/J.CNKI.ISSN1000-4106.2017.01.032]
   Lin W., 2019, DESIGN, V11, P146
   [刘菊 Liu Ju], 2019, [地球信息科学学报, Journal of Geo-Information Science], V21, P844
   Liu Y., 2010, J BEIJING INF SCI TE, V25, P61, DOI [10.16508/j.cnki.11-5866/n.2010.s2.001, DOI 10.16508/J.CNKI.11-5866/N.2010.S2.001]
   [鲁东明 Lu Dongming], 2002, [测绘学报, Acta Geodetica et Cartographica Sinica], V31, P12
   [吕兰兰 Lu Lanlan], 2012, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V25, P63
   [马晓娜 Ma Xiaona], 2019, [中国科学. 信息科学, Scientia Sinica Informationis], V49, P121
   Miao J., 2002, MUSIC RES, V02, P7, DOI [10.3969/j.issn.0512-7939.2002.02.002, DOI 10.3969/J.ISSN.0512-7939.2002.02.002]
   Michel JB, 2011, SCIENCE, V331, P176, DOI 10.1126/science.1199644
   Pan T., 2021, J CHINA INTANGIBLE C, V03, P7
   Pan Y., 2001, ACTA GEOD CARTOGR SI, V15, P12
   Pan Yun-he, 2003, Journal of System Simulation, V15, P310
   Singh G, 2014, IEEE COMPUT GRAPH, V34, P4
   Sun Q, 2010, ACM J COMPUT CULT HE, V3, DOI 10.1145/1841317.1841320
   Sun R., 1993, DUNHUANG RES, V4, P19, DOI [10.13584/j.cnki.issn1000-4106.1993.04.008, DOI 10.13584/J.CNKI.ISSN1000-4106.1993.04.008]
   Tosa N, 2005, LECT NOTES COMPUT SC, V3711, P13
   Tu L., 2019, ZHUANGSHI, V309, P28, DOI [10.16272/j.cnki.cn11-1392/j.2019.01.008, DOI 10.16272/J.CNKI.CN11-1392/J.2019.01.008]
   UNESCO, 2008, GUQ ITS MUS
   UNESCO, 1987, MOG CAV
   UNESCO, 2007, CONV PROT WORLD CULT
   UNESCO, 1972, WHAT IS INT CULT HER
   Wang H, 2011, CULTURAL RELICS, V01, P81, DOI [10.13619/j.cnki.cn11-1532/k.2011.01.011, DOI 10.13619/J.CNKI.CN11-1532/K.2011.01.011]
   Wang Y, 2015, PROCEEDINGS OF THE 2017 8TH INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING (IC4E 2017), P46, DOI 10.1145/3026480.3026495
   Wu Z., 2005, PEOPLES MUSIC, V6, P22, DOI [10.15943/j.cnki.fdxb-jns.2020.03.004, DOI 10.15943/J.CNKI.FDXB-JNS.2020.03.004]
   Xiaojing Liang, 2019, Proceedings of the 6th Conference on Sound and Music Technology (CSMT). Revised Selected Papers: Lecture Notes in Electrical Engineering (LNEE 568), P53, DOI 10.1007/978-981-13-8707-4_5
   Xie X., 2017, CULT HERIT, V2017, P149
   Xing J., 2019, PACKAG ENG, V40, P77, DOI [10.19554/j.cnki.1001-3563.2019.24.012, DOI 10.19554/J.CNKI.1001-3563.2019.24.012]
   Xu W., 1983, DUNHUANG RES, P187
   Yi-Hung Liu, 2001, 2001 IEEE International Conference on Systems, Man and Cybernetics. e-Systems and e-Man for Cybernetics in Cyberspace (Cat.No.01CH37236), P2632, DOI 10.1109/ICSMC.2001.972961
   Yu H., 1993, J XIAN CONSERVATORY, V03, P56
   Yu MJ, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445175
   [喻扬涛 Yu Yangtao], 2019, [中国科学. 信息科学, Scientia Sinica Informationis], V49, P159
   Zanfeng M., 2014, Dunhuang Res., V147, P108, DOI [10.13584/j.cnki.issn1000-4106.2014.05.015, DOI 10.13584/J.CNKI.ISSN1000-4106.2014.05.015]
   Zang Q, 2017, VOCAT TECH ED CHINA, V2017, P58
   Zhang M, 2020, 2020 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND HUMAN-COMPUTER INTERACTION (ICHCI 2020), P95, DOI 10.1109/ICHCI51889.2020.00028
   Zhang X., 2015, ARCH CONSTR, V09, P30
   Zhang Y., 2015, CHINESE CHI 15, P23
   Zhang Y., 2018, INF TECHNOL INF, V09, P28, DOI [10.3969/j.issn.1672-9528.2018.09.005, DOI 10.3969/J.ISSN.1672-9528.2018.09.005]
   Zhao H., 2016, COMPUT METHOD APPL M, V25, P1
   [赵海英 Zhao Haiying], 2019, [图学学报, Journal of Graphics], V40, P810
   Zhao Z., 2008, HENAN SOC SCI, V02, P50
   Zhou Chang-le, 2009, Journal of System Simulation, V21, P572
   Zhu X.-F., 2021, Mod. Inf., V41, P54, DOI [10.3969/j.issn.1008-0821.2021.06.005, DOI 10.3969/J.ISSN.1008-0821.2021.06.005]
NR 72
TC 28
Z9 28
U1 9
U2 68
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 6
IS 1
BP 1
EP 13
DI 10.1016/j.visinf.2021.12.006
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 2S0ZC
UT WOS:000821528800001
OA gold
DA 2024-07-18
ER

PT J
AU Ghosh, S
   Hazarika, AP
   Chandra, A
   Mudi, RK
AF Ghosh, Sukanta
   Hazarika, Amlan Pratim
   Chandra, Abhijit
   Mudi, Rajani K.
TI Adaptive neighbor constrained deviation sparse variant fuzzy c-means
   clustering for brain MRI of AD subject
SO VISUAL INFORMATICS
LA English
DT Article
DE MRI; Fuzzy c-means; Neighbor information modeling; Sparse; Rician noise;
   AD
ID LOCAL INFORMATION; MEANS ALGORITHM; SEGMENTATION
AB Progression of Alzheimer's disease (AD) bears close proximity with the tissue loss in the medial temporal lobe (MTL) and enlargement of lateral ventricle (LV). The early stage of AD, mild cognitive impairment (MCI), can be traced by diagnosing brain MRI scans with advanced fuzzy c-means clustering algorithm that helps to take an appropriate intervention. In this paper, firstly the sparsity is initiated in clustering method that too rician noise is also incorporated for brain MR scans of AD subject. Secondly, a novel neighbor pixel constrained fuzzy c-means clustering algorithm is designed where topoloty-based selection of parsimonious neighbor pixels is automated. The adaptability in choice of neighbor pixel class outliers more justified object edge boundary which outperforms a dynamic cluster output. The proposed adaptive neighbor constrained deviation sparse variant fuzzy c-means clustering (AN_DsFCM) can withhold imposed sparsity and withstands rician noise at imposed sparse environment. This novel algorithm is applied for MRI of AD subjects and normative data is acquired to analyse clustering accuracy. The data processing pipeline of theoretically plausible proposition is elaborated in detail. The experimental results are compared with state-of-the-art fuzzy clustering methods for test MRI scans. Visual evaluation and statistical measures are studied to meet both image processing and clinical neurophysiology standards. Overall the performance of proposed AN_DsFCM is significantly better than other methods. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Ghosh, Sukanta; Hazarika, Amlan Pratim; Chandra, Abhijit; Mudi, Rajani K.] Jadavpur Univ, Dept Instrumentat & Elect Engn, Kolkata 700106, India.
C3 Jadavpur University
RP Ghosh, S (corresponding author), Jadavpur Univ, Dept Instrumentat & Elect Engn, Kolkata 700106, India.
EM sukantarpe@gmail.com; amlanhaz@gmail.com; abhijit922@yahoo.co.in;
   rkmudi@yahoo.com
OI GHOSH, SUKANTA/0000-0002-4284-8718
FU Ministry of Electronics and Information Technology, Government of India
   under Sir Visvesvaraya PhD Scheme for Electronics and IT
FX This work is supported in part by Ministry of Electronics and
   Information Technology, Government of India under Sir Visvesvaraya PhD
   Scheme for Electronics and IT.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Bai XZ, 2018, IEEE T FUZZY SYST, V26, P1946, DOI 10.1109/TFUZZ.2017.2756827
   Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P778, DOI 10.1109/3477.809032
   Bezdek James C., 1981, PATTERN RECOGN
   Bischkopf J, 2002, ACTA PSYCHIAT SCAND, V106, P403, DOI 10.1034/j.1600-0447.2002.01417.x
   Burns A, 2009, BMJ-BRIT MED J, V338, DOI 10.1136/bmj.b158
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Elazab A, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/485495
   Gauthier S, 2006, LANCET, V367, P1262, DOI 10.1016/S0140-6736(06)68542-5
   Ghosh S, 2019, MULTIMED TOOLS APPL, V78, P12465, DOI 10.1007/s11042-018-6773-z
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gu J, 2018, IEEE T FUZZY SYST, V26, P612, DOI 10.1109/TFUZZ.2017.2686804
   Guo FF, 2016, IET IMAGE PROCESS, V10, P272, DOI 10.1049/iet-ipr.2015.0236
   Guo YW, 2018, IEEE T FUZZY SYST, V26, P2846, DOI 10.1109/TFUZZ.2018.2814591
   Hsiao JJ, 2013, NEURODEGENER DIS MAN, V3, P147, DOI 10.2217/NMT.13.10
   Kochanek Kenneth D, 2019, Natl Vital Stat Rep, V68, P1
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krishnapuram R, 1996, IEEE T FUZZY SYST, V4, P385, DOI 10.1109/91.531779
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Misra C, 2009, NEUROIMAGE, V44, P1415, DOI 10.1016/j.neuroimage.2008.10.031
   Muñoz X, 2003, PATTERN RECOGN LETT, V24, P375, DOI 10.1016/S0167-8655(02)00262-3
   Organization W.H., 2017, DEMENTIA FACT SHEET, V2
   Pal NR, 2005, IEEE T FUZZY SYST, V13, P517, DOI 10.1109/TFUZZ.2004.840099
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Singh B, 2014, JAMA NEUROL, V71, P581, DOI 10.1001/jamaneurol.2014.94
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Xenaki SD, 2016, IEEE T FUZZY SYST, V24, P1611, DOI 10.1109/TFUZZ.2016.2543752
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang H, 2017, IEEE T GEOSCI REMOTE, V55, P5057, DOI 10.1109/TGRS.2017.2702061
   Zhang YX, 2019, IEEE T FUZZY SYST, V27, P185, DOI 10.1109/TFUZZ.2018.2883033
   Zhao F, 2013, DIGIT SIGNAL PROCESS, V23, P184, DOI 10.1016/j.dsp.2012.09.016
   Zhao ZX, 2014, IET IMAGE PROCESS, V8, P150, DOI 10.1049/iet-ipr.2011.0128
   Zhu L, 2009, IEEE T SYST MAN CY B, V39, P578, DOI 10.1109/TSMCB.2008.2004818
NR 39
TC 12
Z9 12
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 67
EP 80
DI 10.1016/j.visinf.2021.12.001
PG 14
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500009
OA gold
DA 2024-07-18
ER

PT J
AU Shi, HZ
   Xu, D
   He, KJ
   Zhang, H
   Yue, YY
AF Shi, Hongzhen
   Xu, Dan
   He, Kangjian
   Zhang, Hao
   Yue, Yingying
TI Contrastive learning for a single historical painting's blind
   super-resolution
SO VISUAL INFORMATICS
LA English
DT Article
DE Degradation representation; Blind superresolution; Contrastive learning;
   Historical painting; Deep learning
ID IMAGE SUPERRESOLUTION; NETWORK
AB Most of the existing blind super-resolution(SR) methods explicitly estimate the kernel in pixel space, which usually has a large deviation and results in poor SR performance. As a seminal work, DASR learns abstract representations to distinguish various degradations in the feature space, which effectively reduces degradation estimation bias. Therefore, we also employ the feature space to extract degradation representations for an ancient painting. However, most of the blind SR mehods, including DASR, are committed to removing degradations introduced by kernels, downsampling and additive noise. Among them, downsampling degradation is often accompanied by unpleasant artifacts. To address this issue, the paper designs a high-resolution(HR) representation encoder EHR based on contrastive learning to distinguish artifacts introduced by downsampling. Moreover, to optimize the illposed nature of blind SR, we propose a contrastive regularization(CR) to minimize the contrastive loss based on VGG-19. With the help of CR, the SR images are pulled closer to the HR images and pushed far away from bicubic LR observations. Benefiting from these improvements, our method consistently achieves higher quantitative performance and better visual quality with more natural textures than state-of-the-art approaches on a specialized painting dataset. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Shi, Hongzhen; Xu, Dan; He, Kangjian; Zhang, Hao; Yue, Yingying] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Yunnan, Peoples R China.
C3 Yunnan University
RP Xu, D (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Yunnan, Peoples R China.
EM danxu@ynu.edu.cn
RI He, Kangjian/CAG-0300-2022; He, Kangjian/R-6183-2016; Xu,
   Dan/KPA-7396-2024; zheng, liu/KHU-2329-2024
OI He, Kangjian/0000-0001-6207-9728; Xu, Dan/0000-0003-4602-3550; Zhang,
   Hao/0000-0002-0404-6941
FU National Natural Science Foundation of China [62162068, 61761049,
   61540062, 62061049]; Yunnan Province Ten Thousand Talents Program and
   Yunling Scholars Special Project [YNWR-YLXZ-2018-022]; Yunnan Provincial
   Science and Technology Department-Yunnan University "Double First
   Class'' Construction Joint Fund Project [2019FY003012]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62162068, Grant 61761049, Grant 61540062
   and Grant 62061049, in part by the Yunnan Province Ten Thousand Talents
   Program and Yunling Scholars Special Project under Grant
   YNWR-YLXZ-2018-022, in part by the Yunnan Provincial Science and
   Technology Department-Yunnan University ``Double First Class''
   Construction Joint Fund Project under Grant No. 2019FY003012.
CR Bachman P, 2019, ADV NEUR IN, V32
   Bell-Kligler S, 2019, ADV NEUR IN, V32
   Chen T, 2020, PR MACH LEARN RES, V119
   Cruz RS, 2017, PROC CVPR IEEE, P6044, DOI 10.1109/CVPR.2017.640
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Devlin J., 2018, BERT PRE TRAINING DE
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu JJ, 2019, PROC CVPR IEEE, P1604, DOI 10.1109/CVPR.2019.00170
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He JW, 2019, PROC CVPR IEEE, P11048, DOI 10.1109/CVPR.2019.01131
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Ji XZ, 2020, IEEE COMPUT SOC CONF, P1914, DOI 10.1109/CVPRW50498.2020.00241
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Luo Z., 2020, ARXIV PREPRINT ARXIV
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Radford A., 2019, LANGUAGE MODELS ARE
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Soh JW, 2020, PROC CVPR IEEE, P3513, DOI 10.1109/CVPR42600.2020.00357
   Taesung Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P319, DOI 10.1007/978-3-030-58545-7_19
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   vandenOord Aaron, 2018, ARXIV180703748
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang LG, 2021, PROC CVPR IEEE, P10576, DOI 10.1109/CVPR46437.2021.01044
   Yonglong Tian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P776, DOI 10.1007/978-3-030-58621-8_45
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou RF, 2019, IEEE I CONF COMP VIS, P2433, DOI 10.1109/ICCV.2019.00252
NR 45
TC 1
Z9 1
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 81
EP 88
DI 10.1016/j.visinf.2021.11.002
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500010
OA gold
DA 2024-07-18
ER

PT J
AU Wang, M
   Wenskovitch, J
   House, L
   Polys, N
   North, C
AF Wang, Ming
   Wenskovitch, John
   House, Leanna
   Polys, Nicholas
   North, Chris
TI Bridging cognitive gaps between user and model in interactive dimension
   reduction
SO VISUAL INFORMATICS
LA English
DT Article
DE Interactive machine learning; Visual analytics; Dimension reduction;
   Usability; Cognitive gaps
ID VISUALIZATION; EXPLORATION; PROJECTION; BIPLOTS
AB Interactive machine learning (ML) systems are difficult to design because of the "Two Black Boxes" problem that exists at the interface between human and machine. Many algorithms that are used in interactive ML systems are black boxes that are presented to users, while the human cognition represents a second black box that can be difficult for the algorithm to interpret. These black boxes create cognitive gaps between the user and the interactive ML model. In this paper, we identify several cognitive gaps that exist in a previously-developed interactive visual analytics (VA) system, Andromeda, but are also representative of common problems in other VA systems. Our goal with this work is to open both black boxes and bridge these cognitive gaps by making usability improvements to the original Andromeda system. These include designing new visual features to help people better understand how Andromeda processes and interacts with data, as well as improving the underlying algorithm so that the system can better implement the intent of the user during the data exploration process. We evaluate our designs through both qualitative and quantitative analysis, and the results confirm that the improved Andromeda system outperforms the original version in a series of high-dimensional data analysis tasks. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wang, Ming; Wenskovitch, John; Polys, Nicholas; North, Chris] Virginia Tech, Comp Sci, Blacksburg, VA 24060 USA.
   [Wenskovitch, John] Pacific Northwest Natl Lab PNNL, Richland, WA USA.
   [House, Leanna] Virginia Tech, Stat, Blacksburg, VA USA.
C3 Virginia Polytechnic Institute & State University; United States
   Department of Energy (DOE); Pacific Northwest National Laboratory;
   Virginia Polytechnic Institute & State University
RP North, C (corresponding author), Virginia Tech, Comp Sci, Blacksburg, VA 24060 USA.
EM north@vt.edu
RI Wenskovitch, John/AAY-4371-2020; North, Chris/T-6465-2019
OI Wenskovitch, John/0000-0002-0573-6442; North, Chris/0000-0003-4849-8496;
   Polys, Nicholas/0000-0002-8503-970X
FU NSF [CSSI-2003387]; NSF I/UCRC via the NSF Center for Space,
   Highperformance, and Resilient Computing (SHREC) [CNS-1822080]
FX This work was supported in part by NSF grant CSSI-2003387 and NSF I/UCRC
   CNS-1822080 via the NSF Center for Space, Highperformance, and Resilient
   Computing (SHREC).
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   Alsakran J, 2011, IEEE PAC VIS SYMP, P131, DOI 10.1109/PACIFICVIS.2011.5742382
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Amorim EPD, 2012, IEEE CONF VIS ANAL, P53, DOI 10.1109/VAST.2012.6400489
   [Anonymous], 2017, DARPA I20 PROGR UPD
   Ashaari N.S., 2011, PROCEDIA SOCIAL BEHA, V18, P287
   Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018
   Bradel L, 2014, IEEE CONF VIS ANAL, P163, DOI 10.1109/VAST.2014.7042492
   Broekens J., 2006, Proceedings of the 18th BelgiumNetherlands Conference on Arti cial Intelligence (BNAIC), P59
   Brown ET, 2012, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2012.6400486
   Chen X., 2017, IEEE Trans. Learn. Technol, V11, P81
   Cox T. F., 2000, Multidimensional scaling
   Desjardins M, 2007, 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P361
   Dowling M., 2018, P WORKSH MACH LEARN, V11, P74
   Dowling M, 2019, IEEE T VIS COMPUT GR, V25, P172, DOI 10.1109/TVCG.2018.2865047
   Endert A., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P121, DOI 10.1109/VAST.2011.6102449
   Endert A, 2012, IEEE T VIS COMPUT GR, V18, P2879, DOI 10.1109/TVCG.2012.260
   Endert Alex., 2012, P SIGCHI C HUM FACT, P473, DOI DOI 10.1145/2207676.2207741
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Frutos E, 2014, STOCH ENV RES RISK A, V28, P1629, DOI 10.1007/s00477-013-0821-z
   Fry JT, 2018, COMPUT STAT DATA AN, V128, P340, DOI 10.1016/j.csda.2018.08.003
   Ingram S., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P3, DOI 10.1109/VAST.2010.5652392
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Jaegul Choo, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P67, DOI 10.1109/VAST.2009.5332629
   Krug S., 2000, DONT MAKE ME THINK C
   Kulesza T., 2015, P 20 INT C INTELLIGE, P126, DOI DOI 10.1145/2678025.2701399
   la Grange A, 2009, J STAT SOFTW, V30, P1
   Lampert Christoph H., 2009, Animals with Attributes: A Dataset for Attribute Based Classification
   Leman SC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0050474
   Lespinats S, 2011, COMPUT GRAPH FORUM, V30, P113, DOI 10.1111/j.1467-8659.2010.01835.x
   Lyons Joseph B., 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P181, DOI 10.1007/978-3-319-07458-0_18
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   Paulovich FV, 2011, COMPUT GRAPH FORUM, V30, P1091, DOI 10.1111/j.1467-8659.2011.01958.x
   Self J. Z., 2015, ANDROMEDA OBSERVATIO
   Self J.Z., DESIGNING INTERACTIV
   Self JZ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3158230
   Self Jessica Zeitz, 2016, P WORKSH HUM LOOP DA, P1, DOI DOI 10.1145/2939502.2939505
   Self Jessica Zeitz, 2016, CHI 2016 WORKSH HUM, P7
   Sharko J, 2008, IEEE T VIS COMPUT GR, V14, P1444, DOI 10.1109/TVCG.2008.173
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Udina F, 2005, J STAT SOFTW, V13, P1
   Wattenberg M., 2016, Distill, V1, DOI DOI 10.23915/DISTILL.00002
   Wenskovitch John, 2020, IUI '20: Proceedings of the 25th International Conference on Intelligent User Interfaces, P177, DOI 10.1145/3377325.3377516
   Wenskovitch J, 2021, IEEE T VIS COMPUT GR, V27, P1742, DOI 10.1109/TVCG.2020.3028890
   Wenskovitch J, 2020, COMPUTER, V53, P29, DOI 10.1109/MC.2020.2996416
   Wenskovitch J, 2019, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES: COMPANION (IUI 2019), P89, DOI 10.1145/3308557.3308718
   Wenskovitch J, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P38, DOI [10.1109/vds48975.2019.8973381, 10.1109/VDS48975.2019.8973381]
   Wenskovitch John, 2017, P 2 WORKSH HUM LOOP, DOI [10.1145/3077257.3077259, DOI 10.1145/3077257.3077259]
   Wong P.C., 2004, IEEE S INF VIS, pR2
   Yi J. S., 2005, Information Visualization, V4, P239, DOI 10.1057/palgrave.ivs.9500099
   Zeitz J., 2018, J COMPUT SCI COLL, V33, P115
NR 52
TC 5
Z9 5
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2021
VL 5
IS 2
BP 13
EP 25
DI 10.1016/j.visinf.2021.03.002
EA MAY 2021
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LF
UT WOS:000658194200002
OA gold, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Ginger, Y
   Danon, D
   Averbuch-Elor, H
   Cohen-Or, D
AF Ginger, Yiftach
   Danon, Dov
   Averbuch-Elor, Hadar
   Cohen-Or, Daniel
TI Implicit pairs for boosting unpaired image-to-image translation
SO VISUAL INFORMATICS
LA English
DT Article
DE Generative adversarial networks; Image-to-image translation; Data
   augmentation; Synthetic samples
AB In image-to-image translation the goal is to learn a mapping from one image domain to another. In the case of supervised approaches the mapping is learned from paired samples. However, collecting large sets of image pairs is often either prohibitively expensive or not possible. As a result, in recent years more attention has been given to techniques that learn the mapping from unpaired sets.
   In our work, we show that injecting implicit pairs into unpaired sets strengthens the mapping between the two domains, improves the compatibility of their distributions, and leads to performance boosting of unsupervised techniques by up to 12% across several measurements.
   The competence of the implicit pairs is further displayed with the use of pseudo-pairs, i.e., paired samples which only approximate a real pair. We demonstrate the effect of the approximated implicit samples on image-to-image translation problems, where such pseudo-pairs may be synthesized in one direction, but not in the other. We further show that pseudo-pairs are significantly more effective as implicit pairs in an unpaired setting, than directly using them explicitly in a paired setting. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Ginger, Yiftach; Danon, Dov; Averbuch-Elor, Hadar; Cohen-Or, Daniel] Tel Aviv Univ, Tel Aviv, Israel.
C3 Tel Aviv University
RP Ginger, Y (corresponding author), Tel Aviv Univ, Tel Aviv, Israel.
EM iftachg@mail.tau.ac.il
RI Averbuch-Elor, Hadar/AAO-4246-2021
OI Ginger, Yiftach/0000-0001-8575-7405
CR Amodio M, 2019, PROC CVPR IEEE, P8975, DOI 10.1109/CVPR.2019.00919
   [Anonymous], 2017, ARXIV170609138
   [Anonymous], 2017, ARXIV170906548
   [Anonymous], 2018, ARXIV180503189
   [Anonymous], 2017, ARXIV170600826
   [Anonymous], 2018, ARXIV180105401
   [Anonymous], 2017, ADV NEUR IN
   [Anonymous], 2016, CMU-CS-16-118
   [Anonymous], 2015, CORR
   [Anonymous], 2019, ARXIV190606423
   [Anonymous], 2017, ARXIV171110352
   [Anonymous], 2017, ARXIV170300848
   [Anonymous], 2015, ARXIV150404003
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Antoniou A., 2017, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-030-01424-7_58
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bellon R, 2016, LECT NOTES ARTIF INT, V9904, P17, DOI 10.1007/978-3-319-46073-4_2
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   DeVries T., 2017, P 2017 COMPUTER VISI
   Fang HS, 2019, IEEE I CONF COMP VIS, P682, DOI 10.1109/ICCV.2019.00077
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   González A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060820
   Goodfellow IJ, 2014, ADV NEUR IN, P2672, DOI DOI 10.1145/3422622
   Hauberg S., 2015, ARXIV151002795
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jin C.-B., 2018, arXiv:1805.10790
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jolicoeur-Martineau A, 2019, ARXIVABS190102474
   Kim J., 2019, INT C LEARN REPR
   Kim TH, 2017, IEEE I CONF COMP VIS, P4058, DOI 10.1109/ICCV.2017.435
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CX, 2017, ADV NEUR IN, V30
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mariani G., 2018, Bagan: Data augmentation with balancing gan
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nowozin S., 2016, ARXIVABS160600709
   Ronneberger O, 2015, PROC INT C MED IMAGE, P1, DOI [10.1007/978-3-319-24574-4_28, DOI 10.1007/978-3-319-24574-4_28]
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sixt L., 2016, ARXIV161101331
   Sun YH, 2017, IEEE ICC
   Tustison NJ, 2019, ACAD RADIOL, V26, P412, DOI 10.1016/j.acra.2018.08.003
   Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39
   Uzunova Hristina, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P223, DOI 10.1007/978-3-319-66182-7_26
   Xie Q., 2020, ADV NEURAL INFORM PR, V33, P6256, DOI DOI 10.48550/ARXIV.1904.12848
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
NR 47
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2020
VL 4
IS 4
BP 50
EP 58
DI 10.1016/j.visinf.2020.10.001
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KZ
UT WOS:000658193600021
OA gold, Green Submitted
DA 2024-07-18
ER

PT J
AU Mondal, D
   Mondal, M
   Roy, CK
   Schneider, KA
   Li, YK
   Wang, SS
AF Mondal, Debajyoti
   Mondal, Manishankar
   Roy, Chanchal K.
   Schneider, Kevin A.
   Li, Yukun
   Wang, Shisong
TI Clone-World: A visual analytic system for large scale software clones
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual analytics; Software clones; Multivariate networks
AB With the era of big data approaching, the number of software systems, their dependencies, as well as the complexity of the individual system is becoming larger and more intricate. Understanding these evolving software systems is thus a primary challenge for cost-effective software management and maintenance. In this paper we perform a case study with evolving code clones. The programmers often need to manually analyze the co-evolution of clone fragments to decide about refactoring, tracking, and bug removal. However, manual analysis is time consuming, and nearly infeasible for a large number of clones, e.g., with millions of similarity pairs, where clones are evolving over hundreds of software revisions.
   We propose an interactive visual analytics system, Clone-World, which leverages big data visualization approach to manage code clones in large software systems. Clone-World, gives an intuitive yet powerful solution to the clone analytic problems. Clone-World combines multiple information-linked zoomable views, where users can explore and analyze clones through interactive exploration in real time. User studies and experts' reviews suggest that Clone-World may assist developers in many real-life software development and maintenance scenarios. We believe that Clone-World will ease the management and maintenance of clones, and inspire future innovation to adapt visual analytics to manage big software systems. (C) 2019 Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press.
C1 [Mondal, Debajyoti; Mondal, Manishankar; Roy, Chanchal K.; Schneider, Kevin A.; Li, Yukun; Wang, Shisong] Univ Saskatchewan, Dept Comp Sci, Saskatoon, SK, Canada.
C3 University of Saskatchewan
RP Mondal, D (corresponding author), Univ Saskatchewan, Dept Comp Sci, Saskatoon, SK, Canada.
EM dmondal@cs.usask.ca; mshankar.mondal@usask.ca; croy@cs.usask.ca;
   Kevin.Schneider@usask.ca; moran.li@usask.ca; shisong.wang@usask.ca
RI Schneider, Kevin/KQV-5113-2024
OI Schneider, Kevin/0000-0003-1113-1754
FU Global Water Future (GWF) at the University of Saskatchewan under a
   CFREF grant
FX This work is supported in part by Global Water Future (GWF) at the
   University of Saskatchewan under a CFREF grant.
CR Adar E, 2007, PROC INT CONF SOFTW, P762
   [Anonymous], MYSQL DATA SUBJECT S
   Asaduzzaman M., 2011, IWSC, P77
   Bacher I, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P17, DOI 10.5220/0006072300170028
   Barbour L., 2011, 2011 IEEE 27th International Conference on Software Maintenance, P273, DOI 10.1109/ICSM.2011.6080794
   Basit HA, 2015, 2015 IEEE 3RD WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P46, DOI 10.1109/VISSOFT.2015.7332414
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Cordy JR, 2011, CONF PROC INT SYMP C, P219, DOI 10.1109/ICPC.2011.26
   Forbes C, 2012, P INT COMP SOFTW APP, P366, DOI 10.1109/COMPSAC.2012.58
   Göde N, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P311, DOI 10.1145/1985793.1985836
   Harder J., 2011, P 5 INT WORKSH SOFTW, P81
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Juergens E, 2009, PROC INT CONF SOFTW, P485, DOI 10.1109/ICSE.2009.5070547
   Kapser CJ, 2008, EMPIR SOFTW ENG, V13, P645, DOI 10.1007/s10664-008-9076-6
   Khaloo P, 2017, 2017 IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT 2017), P43, DOI 10.1109/VISSOFT.2017.10
   Klimenta Mirza, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P55, DOI 10.1007/978-3-642-36763-2_6
   Krinke J, 2008, EIGHTH IEEE INTERNATIONAL WORKING CONFERENCE ON SOURCE CODE ANALYSIS AND MANIPULATION, PROCEEDINGS, P57, DOI 10.1109/SCAM.2008.14
   Li JY, 2012, PROC INT CONF SOFTW, P310, DOI 10.1109/ICSE.2012.6227183
   Mondal D, 2018, VISIGRAPP 2018: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS / INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS (IVAPP), VOL 3, P108, DOI 10.5220/0006618101080119
   Mondal M., 2012, P ACM S APPL COMPUTI, P1227, DOI DOI 10.1145/2245276.2231969
   Mondal M, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P484, DOI 10.1109/SANER.2015.7081861
   Mondal M, 2014, 2014 SOFTWARE EVOLUTION WEEK - IEEE CONFERENCE ON SOFTWARE MAINTENANCE, REENGINEERING, AND REVERSE ENGINEERING (CSMR-WCRE), P114, DOI 10.1109/CSMR-WCRE.2014.6747161
   Mondal M, 2014, IEEE INT WORK C SO, P11, DOI 10.1109/SCAM.2014.11
   Mondal M, 2012, APPL COMPUT REV, V12, P20, DOI 10.1145/2387358.2387360
   Oberhauser R, 2017, INT J ADV SOFTWARE, V10, P46
   Reniers D., 2010, P INT WORKSH ADV AC, V1
   Roy CK, 2014, 2014 SOFTWARE EVOLUTION WEEK - IEEE CONFERENCE ON SOFTWARE MAINTENANCE, REENGINEERING, AND REVERSE ENGINEERING (CSMR-WCRE), P18, DOI 10.1109/CSMR-WCRE.2014.6747168
   Roy CK, 2008, INT C PROGRAM COMPRE, P172, DOI 10.1109/ICPC.2008.41
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Svajlenko J, 2014, PROC IEEE INT CONF S, P321, DOI 10.1109/ICSME.2014.54
   Vincur J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P509, DOI 10.1109/QRS-C.2017.88
   Voinea L., 2005, P BELG NETH WORKSH S, V101
   Voinea L, 2014, 2014 SECOND IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P79, DOI 10.1109/VISSOFT.2014.22
   Walshaw C., 2003, Journal of Graph Algorithms and Applications, V7, DOI 10.7155/jgaa.00070
   Wettel R, 2008, ICSE'08 PROCEEDINGS OF THE THIRTIETH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P921
NR 35
TC 9
Z9 9
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2019
VL 3
IS 1
BP 18
EP 26
DI 10.1016/j.visinf.2019.03.003
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YJ
UT WOS:000658187900003
OA gold
DA 2024-07-18
ER

PT J
AU Wu, Y
   Zheng, MH
   Weng, CQ
AF Wu, Yi
   Zheng, Minghong
   Weng, Changqing
TI KnowU social teleprompter: Interaction design applied to intervention
   therapy for language decline in early AD patients
SO VISUAL INFORMATICS
LA English
DT Article
DE Alzheimer's disease; Digital socialization; Art creation; Language
   association
ID OLDER-PEOPLE; DEMENTIA; INTERNET; ADULTS; ART
AB Art therapy as an intervention has been shown to alleviate social impairment in people with AD. Meanwhile, digital technology (DTS) has been shown to perform well in different degenerative dementias through mobile devices and apps. However, it is unclear whether digital art creation therapy has an impact on the speech function of people with early AD. Therefore, the aim of this study was to confirm whether digital art creation therapy has an ameliorating effect on language decline in AD patients through the KnowU social teleprompter. This study was a controlled trial in which 16 patients with early AD worked with us and were divided into a paper-based art creation therapy group (control group) and a KnowU social teleprompter therapy group for a 6-week intervention. In the digital art creation intervention group we introduced the KnowU digital kit, consisting of a creation plug-in for the Procreate app on a tablet and a wearable device and its app. The entire treatment process is recorded and combined with a quantitative analysis of the McNemar chi 2 test to analyze the differences in outcomes of verbal communication function in early AD patients after different therapies. Ultimately, it is shown that early AD patients utilizing the KnowU social teleprompter are more effective in the intervention treatment of language decline in the real social domain compared to the paper-based art creation therapy group. The discussion further demonstrates that DTs and art therapy can provide a better social experience, creative approach and emotional recall of language loss in early AD patients, as well as increase the collaborative relationship between early AD patients and their caregivers. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Wu, Yi; Zheng, Minghong] Sch Design & Innovat China Acad Art, Hangzhou, Peoples R China.
   [Weng, Changqing] Zhejiang Univ Sci & Technol, Hangzhou, Peoples R China.
C3 Zhejiang University of Science & Technology
RP Wu, Y; Zheng, MH (corresponding author), Sch Design & Innovat China Acad Art, Hangzhou, Peoples R China.
EM 0197021@caa.edu.cn; 390239576@qq.com; 85691407@qq.com
OI zheng, minghong/0000-0002-9353-0750
CR [Anonymous], Ministry of Health and Social Affairs, Swedish Association of Local Authorities and Regions. vision for eHealth 2025-common starting
   Baig MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1365-7
   Bober S., 2002, Journal of Social Work in Long-Term Care, V1, P73, DOI DOI 10.1300/J181V01N04_06
   Collingwood R.G., 1938, PRINCIPLES ART
   CZAJA SJ, 1993, BEHAV INFORM TECHNOL, V12, P197, DOI 10.1080/01449299308924382
   Davidsson P., 2018, Svenskarna och internet
   Fraser KC, 2014, CORTEX, V55, P43, DOI 10.1016/j.cortex.2012.12.006
   Garrard P, 2005, BRAIN, V128, P250, DOI 10.1093/brain/awh341
   Garrard P, 2014, CORTEX, V55, P122, DOI 10.1016/j.cortex.2013.05.008
   Harlan J.E., 1993, LOSS GREIF CARE, V6, P99, DOI DOI 10.1300/J132V06N04_13
   Kahn-Dennis K.B., 1997, Art Therapy: Journal of the American Art Therapy Association, V14, P194, DOI [DOI 10.1080/07421656.1987.10759281, 10.1080/07421656.1987.10759281]
   Kampmeijer R, 2016, BMC HEALTH SERV RES, V16, DOI 10.1186/s12913-016-1522-3
   Kottorp A, 2016, J OCCUP SCI, V23, P382, DOI 10.1080/14427591.2016.1151457
   Larsson E, 2016, BRIT J OCCUP THER, V79, P629, DOI 10.1177/0308022616641701
   Leist AK, 2013, GERONTOLOGY, V59, P378, DOI 10.1159/000346818
   Lubben J, 2003, SOICAL WORK AND HEALTH CARE IN AN AGING WORLD: EDUCATION, POLICY, PRACTICE, AND RESEARCH, P319
   Morley T., 2007, Art, angst, and trauma: Right brain interventions with developmental issues, P230
   Morris ME, 2014, AUSTRALAS J AGEING, V33, P142, DOI 10.1111/ajag.12154
   Nyman A, 2015, SCAND J OCCUP THER, V22, P387, DOI 10.3109/11038128.2015.1020867
   Olphert W, 2013, GERONTOLOGY, V59, P564, DOI 10.1159/000353630
   Peisah C, 2011, INT PSYCHOGERIATR, V23, P1011, DOI 10.1017/S1041610211000457
   Safar LT, 2011, ART THER, V28, P96, DOI 10.1080/07421656.2011.599734
   Stewart Ellen Greene, 2004, ART THER, V21, P148, DOI DOI 10.1080/07421656.2004.10129499
   Stuck AE, 1999, SOC SCI MED, V48, P445, DOI 10.1016/S0277-9536(98)00370-0
   Wald J., 1993, ART THER, V10, P88, DOI DOI 10.1080/07421656.1993.10758987
NR 25
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 95
EP 99
DI 10.1016/j.visinf.2023.10.004
EA DEC 2023
PG 5
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DR0N9
UT WOS:001133675500001
OA gold
DA 2024-07-18
ER

PT J
AU Su, KH
   Zhang, J
   Xie, DY
   Tao, J
AF Su, Kunhua
   Zhang, Jun
   Xie, Deyue
   Tao, Jun
TI Importance guided stream surface generation and feature exploration
SO VISUAL INFORMATICS
LA English
DT Article
DE Flow visualization; Flow feature; Stream surface
AB Exploring flow features and patterns hidden behind the data has received extensive academic attention in flow visualization. In this paper, we introduce an importance-guided surface generation and exploration scheme to explore the features and their connections. The features are expressed as an importance field, which can either be derived from a scalar field or be specified as a flow pattern. Guided by the importance field, we sample a pool of seeding curves along the binormal direction and construct stream surfaces to fit the regions of high-importance values. Our scheme evaluates candidate seeding curves by collecting importance scores from the curve and corresponding streamlines. The candidate seeding curves are refined using the high-score segments to identify the optimal surfaces. Comparative visualization among different kinds of flow features across time steps can be easily derived for flow structure analysis. In order to reduce the visual complexity, we leverage SurfRiver to achieve clearer observation by flattening and aligning the surface. Finally, we apply our surface generation scheme guided by flow patterns and scalar fields to evaluate the effectiveness of the proposed tool.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Su, Kunhua; Zhang, Jun; Xie, Deyue; Tao, Jun] Sun Yat Sen Univ, Higher Educ Mega Ctr, Sch Comp Sci & Engn, 132 Outerring East Rd, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Tao, J (corresponding author), Sun Yat Sen Univ, Higher Educ Mega Ctr, Sch Comp Sci & Engn, 132 Outerring East Rd, Guangzhou 510006, Guangdong, Peoples R China.
EM sukh@mail2.sysu.edu.cn; zhangj297@mail2.sysu.edu.cn;
   xiedy5@mail2.sysu.edu.cn; taoj23@mail.sysu.edu.cn
FU National Key Ramp;D Program of China [2021YFB0300103]; National Natural
   Science Foundation of China [61902446, 62172456, 91937302]; National
   Numerical Windtunnel Project
FX Acknowledgments This work is supported by National Key R & D Program of
   China through grant 2021YFB0300103, the National Natural Science
   Foundation of China through grants 61902446, 62172456, and 91937302, and
   the National Numerical Windtunnel Project.
CR Auzinger T, 2013, IEEE T VIS COMPUT GR, V19, P2858, DOI 10.1109/TVCG.2013.215
   Bader R, 2020, IEEE T VIS COMPUT GR, V26, P259, DOI 10.1109/TVCG.2019.2934310
   Borkin MA, 2011, IEEE T VIS COMPUT GR, V17, P2479, DOI 10.1109/TVCG.2011.192
   Born S, 2010, IEEE T VIS COMPUT GR, V16, P1329, DOI 10.1109/TVCG.2010.166
   Brambilla A, 2015, COMPUT GRAPH-UK, V47, P123, DOI 10.1016/j.cag.2015.01.002
   Bujack R, 2015, IEEE PAC VIS SYMP, P9, DOI 10.1109/PACIFICVIS.2015.7156350
   Bujack R, 2014, IEEE PAC VIS SYMP, P41, DOI 10.1109/PacificVis.2014.16
   Carnecky R, 2013, IEEE T VIS COMPUT GR, V19, P838, DOI 10.1109/TVCG.2012.159
   Chen W, 2008, COMPUT GRAPH FORUM, V27, P1071, DOI 10.1111/j.1467-8659.2008.01244.x
   Esturo JM, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12031
   Garth C., 2004, P 6 JOINT EUR IEEE T, V4, P155, DOI DOI 10.2312/VISSYM/VISSYM04/155-164
   Gunther T., 2014, COMPUT GRAPH FORUM, V33, P1725
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   HULTQUIST JPM, 1992, VISUALIZATION 92 : PROCEEDINGS, P171
   Hummel M, 2010, IEEE T VIS COMPUT GR, V16, P1319, DOI 10.1109/TVCG.2010.173
   Jiang KR, 2020, IEEE PAC VIS SYMP, P96, DOI 10.1109/PacificVis48177.2020.1718
   Kanitsar A, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P37, DOI 10.1109/VISUAL.2002.1183754
   Kern M, 2019, IEEE T VIS COMPUT GR, V25, P1080, DOI 10.1109/TVCG.2018.2864806
   Ma J, 2013, IEEE PAC VIS SYMP, P233, DOI 10.1109/PacificVis.2013.6596150
   McLoughlin T, 2009, P 2009 COMP GRAPH IN, P73
   McLoughlin T, 2013, IEEE T VIS COMPUT GR, V19, P1342, DOI 10.1109/TVCG.2012.150
   Moberts B, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P65
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P719, DOI 10.1109/TVCG.2019.2934367
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P3147, DOI 10.1109/TVCG.2019.2920157
   Oeltze S, 2014, IEEE T VIS COMPUT GR, V20, P686, DOI 10.1109/TVCG.2013.2297914
   Schafhitzel Tobias, 2007, Proceedings Graphics Interface 2007, P289, DOI 10.1145/1268517.1268564
   Scheuermann G, 2001, IEEE VISUAL, P151
   Schulze M, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12356
   Tao J, 2018, IEEE T VIS COMPUT GR, V24, P2622, DOI 10.1109/TVCG.2017.2750681
   Tao J, 2014, IEEE PAC VIS SYMP, P9, DOI 10.1109/PacificVis.2014.12
   Theisel H, 2022, Arxiv, DOI arXiv:2202.09566
   Verma V, 2004, IEEE T VIS COMPUT GR, V10, P609, DOI 10.1109/TVCG.2004.39
   Wang Z, 2017, COMPUT GRAPH FORUM, V36, P7, DOI 10.1111/cgf.12990
   Wang ZJ, 2016, IEEE T VIS COMPUT GR, V22, P807, DOI 10.1109/TVCG.2015.2467292
   Zhang J, 2021, IEEE T VIS COMPUT GR, V27, P2783, DOI 10.1109/TVCG.2021.3074585
   Zhang SH, 2009, J FLUID MECH, V639, P343, DOI 10.1017/S002211200999108X
NR 36
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 54
EP 63
DI 10.1016/j.visinf.2023.05.002
EA JUN 2023
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA M3CP3
UT WOS:001028993800001
OA gold
DA 2024-07-18
ER

PT J
AU Shirato, G
   Andrienko, N
   Andrienko, G
AF Shirato, Gota
   Andrienko, Natalia
   Andrienko, Gennady
TI Identifying, exploring, and interpreting time series shapes in
   multivariate time intervals
SO VISUAL INFORMATICS
LA English
DT Article
DE Temporal patterns; Multivariate time series; Time intervals
ID MODEL; REPRESENTATION; VISUALIZATION; EXPLORATION; ANALYTICS; MOVEMENT
AB We introduce a concept of episode referring to a time interval in the development of a dynamic phenomenon that is characterized by multiple time-variant attributes. A data structure representing a single episode is a multivariate time series. To analyse collections of episodes, we propose an approach that is based on recognition of particular patterns in the temporal variation of the variables within episodes. Each episode is thus represented by a combination of patterns. Using this representation, we apply visual analytics techniques to fulfil a set of analysis tasks, such as investigation of the temporal distribution of the patterns, frequencies of transitions between the patterns in episode sequences, and co-occurrences of patterns of different variables within same episodes. We demonstrate our approach on two examples using real-world data, namely, dynamics of human mobility indicators during the COVID-19 pandemic and characteristics of football team movements during episodes of ball turnover.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Shirato, Gota; Andrienko, Natalia; Andrienko, Gennady] Fraunhofer IAIS, D-53757 St Augustin, Germany.
   [Shirato, Gota] Univ Bonn, Regina Pacis Weg 3, D-53113 Bonn, Germany.
   [Andrienko, Natalia; Andrienko, Gennady] Univ London, City, Northampton Sq, London EC1V 0HB, England.
C3 University of Bonn; University of London
RP Shirato, G (corresponding author), Fraunhofer IAIS, D-53757 St Augustin, Germany.
EM gota.shirato@iais.fraunhofer.de; natalia.andrienko@iais.fraunhofer.de;
   gennady.andrienko@iais.fraunhofer.de
RI Andrienko, Gennady L./B-6486-2014; Andrienko, Natalia/KHV-4755-2024
OI Andrienko, Gennady L./0000-0002-8574-6295; Andrienko,
   Natalia/0000-0003-3313-1560; Shirato, Gota/0000-0001-6517-9994
FU Federal Ministry of Education and Research of Germany [Lamarr22B]; EU;
   DFG; state of North-Rhine Westphalia as part of the Lamarr Institute for
   Machine Learning and Artificial Intelligence (Lamarr22B)
FX This work was partly supported by Federal Ministry of Education and
   Research of Germany and the state of North-Rhine Westphalia as part of
   the Lamarr Institute for Machine Learning and Artificial Intelligence
   (Lamarr22B) , by EU in projects SoBigData++ and CrexData , and by DFG
   within priority research program SPP VGI (project EVA-VGI) .
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531
   Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   Andrienko N., 2020, Visual Analytics for Data Scientists
   Andrienko N, 2021, VIS INFORM, V5, P23, DOI 10.1016/j.visinf.2020.12.002
   Andrienko N, 2017, VIS INFORM, V1, P25, DOI 10.1016/j.visinf.2017.01.004
   Bale K., 2007, Information Visualization, V6, P155, DOI DOI 10.1057/PALGRAVE.IVS.9500154
   Bernard J., 2012, Journal of WSCG, V2, P97
   Bernard Jurgen., 2016, Proceedings of the EuroVis Workshop on Visual Analytics, P31
   Buono P., 2016, P INT WORK C ADV VIS, P348
   Collins C, 2018, VIS INFORM, V2, P166, DOI 10.1016/j.visinf.2018.09.003
   Crisan A., 2021, IEEE T VIS COMPUT GR
   Das G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P16
   Fonseca S, 2013, INT J PERF ANAL SPOR, V13, P179, DOI 10.1080/24748668.2013.11868640
   Gharghabi S, 2019, DATA MIN KNOWL DISC, V33, P96, DOI 10.1007/s10618-018-0589-3
   Gibson H, 2013, INFORM VISUAL, V12, P324, DOI 10.1177/1473871612455749
   Google, 2022, COVID 19 COMMUNITY M
   Hale T, 2021, NAT HUM BEHAV, V5, P529, DOI 10.1038/s41562-021-01079-8
   Hao M, 2011, PROC SPIE, V7868, DOI 10.1117/12.872169
   Haroz S, 2016, IEEE T VIS COMPUT GR, V22, P2174, DOI 10.1109/TVCG.2015.2502587
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669
   Keogh E, 2007, KNOWL INF SYST, V11, P1, DOI [10.1007/s10115-006-0034-6, 10.1007/S10115-006-0034-6]
   Lee TY, 2009, IEEE T VIS COMPUT GR, V15, P1359, DOI 10.1109/TVCG.2009.200
   Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z
   Liu LQ, 2016, SCIENTOMETRICS, V109, P953, DOI 10.1007/s11192-016-2100-5
   Lu Y, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1173, DOI 10.1145/3534678.3539271
   Mauceri S, 2021, GENET PROGRAM EVOL M, V22, P267, DOI 10.1007/s10710-021-09403-x
   PEUQUET DJ, 1994, ANN ASSOC AM GEOGR, V84, P441, DOI 10.1111/j.1467-8306.1994.tb01869.x
   Qiang Y, 2012, INFORM VISUAL, V11, P255, DOI 10.1177/1473871612436775
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Rosling H., 2006, BEST STATS YOUVE EVE
   Schreck Tobias., 2007, ACM SIGKDD EXPLORATI, V9, P30, DOI DOI 10.1145/1345448.1345454
   Shirato G., IEEE VIS 2021
   Steinarsson S., 2013, Downsampling Time Series for Visual Representation
   Tanisaro P, 2019, LECT NOTES COMPUT SC, V11482, P246, DOI 10.1007/978-3-030-20205-7_21
   Tominski C., 2020, Interactive visual data analysis
   Van de Weghe N, 2007, J ARCHAEOL SCI, V34, P649, DOI 10.1016/j.jas.2006.07.007
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Vung Pham, 2019, 2019 IEEE International Conference on Big Data (Big Data), P3267, DOI 10.1109/BigData47090.2019.9006559
   Yeh CCM, 2017, IEEE DATA MINING, P565, DOI 10.1109/ICDM.2017.66
   Zhao J, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P433, DOI 10.1145/2254556.2254639
   Zhao JF, 2008, INFORM VISUAL, V7, P198, DOI 10.1057/palgrave.ivs.9500184
NR 46
TC 5
Z9 5
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2023
VL 7
IS 1
BP 77
EP 91
DI 10.1016/j.visinf.2023.01.001
EA APR 2023
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA F4QW8
UT WOS:000982219700001
OA gold, Green Accepted
DA 2024-07-18
ER

PT J
AU Stoiber, C
   Walchshofer, C
   Pohl, M
   Potzmann, B
   Grassinger, F
   Stitz, H
   Streit, M
   Aigner, W
AF Stoiber, Christina
   Walchshofer, Conny
   Pohl, Margit
   Potzmann, Benjamin
   Grassinger, Florian
   Stitz, Holger
   Streit, Marc
   Aigner, Wolfgang
TI Comparative evaluations of visualization onboarding methods
SO VISUAL INFORMATICS
LA English
DT Article
DE Visualization literacy; User onboarding; Learning; Visual analytic
ID LITERACY; VEGA
AB Comprehending and exploring large and complex data is becoming increasingly important for a diverse population of users in a wide range of application domains. Visualization has proven to be well-suited in supporting this endeavor by tapping into the power of human visual perception. However, non-experts in the field of visual data analysis often have problems with correctly reading and interpreting information from visualization idioms that are new to them. To support novices in learning how to use new digital technologies, the concept of onboarding has been successfully applied in other fields and first approaches also exist in the visualization domain. However, empirical evidence on the effectiveness of such approaches is scarce. Therefore, we conducted three studies with Amazon Mechanical Turk (MTurk) workers and students investigating visualization onboarding at different levels: (1) Firstly, we explored the effect of visualization onboarding, using an interactive step-by-step guide, on user performance for four increasingly complex visualization techniques with time-oriented data: a bar chart, a horizon graph, a change matrix, and a parallel coordinates plot. We performed a between-subject experiment with 596 participants in total. The results showed that there are no significant differences between the answer correctness of the questions with and without onboarding. Particularly, participants commented that for highly familiar visualization types no onboarding is needed. However, for the most unfamiliar visualization type - the parallel coordinates plot - performance improvement can be observed with onboarding. (2) Thus, we performed a second study with MTurk workers and the parallel coordinates plot to assess if there is a difference in user performances on different visualization onboarding types: step-by-step, scrollytelling tutorial, and video tutorial. The study revealed that the video tutorial was ranked as the most positive on average, based on a sentiment analysis, followed by the scrollytelling tutorial and the interactive step-by-step guide. (3) As videos are a traditional method to support users, we decided to use the scrollytelling approach as a less prevalent way and explore it in more detail. Therefore, for our third study, we gathered data towards users' experience in using the in-situ scrollytelling for the VA tool Netflower. The results of the evaluation with students showed that they preferred scrollytelling over the tutorial integrated in the Netflower landing page. Moreover, for all three studies we explored the effect of task difficulty. In summary, the in-situ scrollytelling approach works well for integrating onboarding in a visualization tool. Additionally, a video tutorial can help to introduce interaction techniques of visualization.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Stoiber, Christina; Grassinger, Florian; Aigner, Wolfgang] St Poelten Univ Appl Sci, St Polten, Austria.
   [Walchshofer, Conny; Streit, Marc] Johannes Kepler Univ Linz, Linz, Austria.
   [Pohl, Margit; Potzmann, Benjamin] TU Wien, Vienna, Austria.
   [Stitz, Holger] datavisyn GmbH, Linz, Austria.
C3 Johannes Kepler University Linz; Technische Universitat Wien
RP Stoiber, C (corresponding author), St Poelten Univ Appl Sci, St Polten, Austria.
EM cstoiber@fhstp.ac.at
OI Potzmann, Benjamin/0000-0002-5286-2433; Stoiber,
   Christina/0000-0002-1764-1467; Stitz, Holger/0000-0002-4742-2636;
   Grassinger, Florian/0000-0003-4409-788X; Pohl,
   Margit/0000-0001-7880-8702; Streit, Marc/0000-0001-9186-2092;
   Walchshofer, Conny/0000-0003-3942-8445
FU Austrian Ministry for Transport, Innovation and Technology (BMVIT) under
   the ICT of the Future program via the SEVA project [874018]; FFG under
   the Austrian Federal Ministry for Climate Action, Environment, Energy,
   Mobility, Innovation and Technology [881844]; Austrian Federal Ministry
   for Digital and Economic Affairs; Province of Upper Austria; Province of
   Styria
FX The authors wish to thank Victor Adriel de Jesus Oliveira for his
   valuable feedback. This work was funded by the Austrian Ministry for
   Transport, Innovation and Technology (BMVIT) under the ICT of the Future
   program via the SEVA project (no. 874018) , as well as the FFG, Contract
   No. 881844: "Pro2Future is funded within the Austrian COMET Program
   Competence Centers for Excellent Technologies under the auspices of the
   Austrian Federal Ministry for Climate Action, Environment, Energy,
   Mobility, Innovation and Technology, the Austrian Federal Ministry for
   Digital and Economic Affairs and of the Provinces of Upper Austria and
   Styria. COMET is managed by the Austrian Research Promotion Agency FFG".
CR Advizor Solutions, 2022, US
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   Amabili L., 2019, STORYTELLING SCROLLY
   [Anonymous], 2022, REACT VEGA
   [Anonymous], 2022, MED DAT
   [Anonymous], 2020, UNHCR REFUGEE STAT
   [Anonymous], 2022, IBM COGNOS ANAL
   [Anonymous], 2017, SPOTIFY CLASSIFICATI
   [Anonymous], 2022, D3 LANGUAGE
   [Anonymous], 2022, CAR DATA
   [Anonymous], 2017, CHOCOLATE BAR RATING
   [Anonymous], 2022, REACT LANGUAGE
   Ant Design, 2022, US
   Baker R.S., 2001, P ANN M COGN SCI SOC, V23
   Banovic N, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P83
   Bishop F, 2020, IEEE T VIS COMPUT GR, V26, P451, DOI 10.1109/TVCG.2019.2934804
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Budiu R., 2016, POWER LAW LEARNING C
   Card S K., 1999, READINGS INFORM VISU
   dos Santos S, 2004, COMPUT GRAPH-UK, V28, P311, DOI 10.1016/j.cag.2004.03.013
   ECAD, 2019, US
   Echeverria V., 2017, P 29 AUSTR C COMP HU, P347, DOI [10.1145/3152771.3156134, DOI 10.1145/3152771.3156134]
   Few Stephen, 2012, SHOW ME NUMBERS DESI, Vsecond
   Firat E. E., 2020, Eurographics 2020-Education Papers, P29, DOI DOI 10.2312/EGED.20201032
   Firat EE, 2022, INFORM VISUAL, V21, P285, DOI 10.1177/14738716221081831
   Freedman EG, 2002, LECT NOTES ARTIF INT, V2317, P18
   Friel SN, 2001, J RES MATH EDUC, V32, P124, DOI 10.2307/749671
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Gerrig R.J., 2015, Psychology and life, Vtwentieth
   Göbel F, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204544
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Grossman T, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1515
   Holtz Y., LIB CATALOG
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Huron Samuel, 2014, P 2014 C DESIGNING I, P433, DOI [DOI 10.1145/2598510.2598566, 10.1145/2598510.25985661,2, DOI 10.1145/2598510.25985661,2]
   Kai, 2021, PARALLEL COORDINATES
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   KOSSLYN SM, 1989, APPL COGNITIVE PSYCH, V3, P185, DOI 10.1002/acp.2350030302
   Kwon BC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P993, DOI 10.1145/2858036.2858101
   Lafreniere B., 2013, Proceedings of the 2013 ACM annual conference on Human factors in computing systems, P1779, DOI [10.1145/2470654.2466235, DOI 10.1145/2470654.2466235]
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Lu S., 2022, D3-annotation
   LubomirBourdev ShaiAvidan, 2011, P 24 ANN ACM S USER, P135, DOI DOI 10.1145/2047196.2047213.URL
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   MacCaw A., 2022, TEXT ANAL
   Manning JP, 2005, EARLY CHILD EDUC J, V32, P371, DOI 10.1007/s10643-005-0004-8
   Mayring P., 2010, Handbuch Qualitative Forschung in der Psychologie, P601, DOI [10.1007/978-3-531-92052-8_42, DOI 10.1007/978-3-531-92052-8_42]
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nolan D, 2016, AM STAT, V70, P260, DOI 10.1080/00031305.2015.1123651
   Ola O, 2017, INFORMATICS-BASEL, V4, DOI 10.3390/informatics4040033
   Olympic World Library, 2022, US
   Perkhofer LM, 2019, J APPL ACCOUNT RES, V20, P497, DOI 10.1108/JAAR-10-2017-0114
   Pohontsch NJ, 2019, REHABILITATION, V58, P413, DOI 10.1055/a-0801-5465
   Ribecca Severino, 2022, DATA VISUALISATION C
   Riche NH, 2018, Data-Driven Storytelling
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Stoiber Christina, 2021, VINCI 2021: The 14th International Symposium on Visual Information Communication and Interaction, DOI 10.1145/3481549.3481558
   Stoiber C, 2019, COMPUT GRAPH FORUM, V38, P699, DOI 10.1111/cgf.13721
   Stoiber C., 2019, Visualization onboarding: Learning how to read and use visualizations, DOI [10.31219/osf.io/c38ab, DOI 10.31219/OSF.IO/C38AB]
   Swabish J., 2014, GRAPHIC CONTINUUM PO
   Tanahashi Y, 2016, COMPUT GRAPH FORUM, V35, P117, DOI 10.1111/cgf.13009
   van Wijk JJ, 2006, IEEE T VIS COMPUT GR, V12, P421, DOI 10.1109/TVCG.2006.80
   Wang ZZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376271
   Yalcin M.A., 2016, THESIS U MARYLAND CO
   Yalcin M.A., 2022, KESHIF DATA MADE EXP
   Zeid A, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION, 2011, VOL 5, P305
   Zhi Q, 2019, COMPUT GRAPH FORUM, V38, P675, DOI 10.1111/cgf.13719
NR 74
TC 3
Z9 3
U1 8
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 34
EP 50
DI 10.1016/j.visinf.2022.07.001
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100004
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Maqableh, W
   Alzyoud, FY
   Zraqou, J
AF Maqableh, Waleed
   Alzyoud, Faisal Y.
   Zraqou, Jamal
TI The use of facial expressions in measuring students' interaction with
   distance learning environments during the COVID-19 crisis
SO VISUAL INFORMATICS
LA English
DT Article
DE COVID-19; Face-to-face learning; Facial expressions; Heart pulse;
   E-learning
ID TEACHERS
AB Digital learning is becoming increasingly important in the crisis COVID-19 and is widespread in most countries. The proliferation of smart devices and 5G telecommunications systems are contributing to the development of digital learning systems as an alternative to traditional learning systems. Digital learning includes blended learning, online learning, and personalized learning which mainly depends on the use of new technologies and strategies, so digital learning is widely developed to improve education and combat emerging disasters such as COVID-19 diseases. Despite the tremendous benefits of digital learning, there are many obstacles related to the lack of digitized curriculum and collaboration between teachers and students. Therefore, many attempts have been made to improve the learning outcomes through the following strategies: collaboration, teacher convenience, personalized learning, cost and time savings through professional development, and modeling. In this study, facial expressions and heart rate are used to measure the effectiveness of digital learning systems and the level of learners' engagement in learning environments. The results showed that the proposed approach outperformed the known related works in terms of learning effectiveness. The results of this research can be used to develop a digital learning environment.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Maqableh, Waleed] Luminus Tech Univ Coll, SAE Amman Inst, Amman, Jordan.
   [Alzyoud, Faisal Y.] Isra Univ, Amman, Jordan.
   [Zraqou, Jamal] Univ Petra, Amman, Jordan.
C3 Isra University; Petra University
RP Maqableh, W (corresponding author), Luminus Tech Univ Coll, SAE Amman Inst, Amman, Jordan.
EM W.Maqableh@saejordan.com; Faisal.Alzyoud@iu.edu.jo;
   Jamal.Zraqou@uop.edu.jo
RI Zraqou, Jamal/JNJ-7318-2023
OI Maqableh, Waleed/0000-0001-5342-0461; Zraqou, Jamal/0000-0001-9060-7188
CR Al-Helali A.H.M, 2021, J THEOR APPL INFORM, V99
   Ayvaz U, 2017, INF TECHNOL LEARN TO, V60, P95, DOI 10.33407/itlt.v60i4.1743
   Benta KI, 2015, ROEDUNET IEEE, P34, DOI 10.1109/RoEduNet.2015.7311824
   Buja LM, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1535-9
   Cao Y, 2005, ACM T GRAPHIC, V24, P1283, DOI 10.1145/1095878.1095881
   Chai CS, 2014, J COMPUT EDUC, V1, P1, DOI 10.1007/s40692-014-0002-1
   Cranford KN, 2014, J CHEM EDUC, V91, P641, DOI 10.1021/ed400576n
   Dewan MAA, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-018-0080-z
   Fabbri R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322434
   Gaur Uma, 2020, SN Compr Clin Med, V2, P1992, DOI 10.1007/s42399-020-00528-1
   Geng G, 2011, AUST J TEACH EDUC, V36, P17, DOI 10.14221/ajte.2011v36n7.5
   Harris PL, 2012, Trusting what you're told: How children learn from others
   Hodges C., 2020, The difference between emergency remote teaching and online learning, P1
   Kirschner PA, 2015, INSTR SCI, V43, P309, DOI 10.1007/s11251-015-9346-9
   Maier KJ, 2003, ANN BEHAV MED, V26, P32, DOI 10.1207/S15324796ABM2601_05
   Moore JL, 2011, INTERNET HIGH EDUC, V14, P129, DOI 10.1016/j.iheduc.2010.10.001
   Mukhtar K, 2020, PAK J MED SCI, V36, pS27, DOI 10.12669/pjms.36.COVID19-S4.2785
   Munoz A, 2019, J UNIV TEACH LEARN P, V16
   Nezami OM, 2020, LECT NOTES ARTIF INT, V11908, P273, DOI 10.1007/978-3-030-46133-1_17
   Ozadowicz A, 2020, EDUC SCI, V10, DOI 10.3390/educsci10100292
   Pather N, 2020, ANAT SCI EDUC, V13, P284, DOI 10.1002/ase.1968
   Peled R, 2008, BMC CANCER, V8, DOI 10.1186/1471-2407-8-245
   Rizwan SA, 2020, INT CONF ADV COMP SC, DOI 10.1109/icacs47775.2020.9055954
   Sathik M, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-455
   Shen DM, 2013, INTERNET HIGH EDUC, V19, P10, DOI 10.1016/j.iheduc.2013.04.001
   Tian Y.-l., 2000, P 4 IEEE INT C AUTOM
   Tian YL, 2000, PROC CVPR IEEE, P294, DOI 10.1109/CVPR.2000.855832
   Ting Wu, 2012, Advances in Brain Inspired Cognitive Systems. Proceedings 5th International Conference, BICS 2012, P392, DOI 10.1007/978-3-642-31561-9_44
   Vail AK, 2016, LECT NOTES COMPUT SC, V9684, P154, DOI 10.1007/978-3-319-39583-8_15
   Van Heerden D., 2020, PROMOTING INCLUSIVE, P118
   Welsen S., 2020, 2020 IFEES WORLD ENG, P1
   Wu CH, 2016, PORTL INT CONF MANAG, P1719, DOI 10.1109/PICMET.2016.7806648
   Zraqou J., 2014, International Journal of Technology and Educational Marketing, V4, P95, DOI 10.4018/ijtem.2014010108
NR 33
TC 6
Z9 6
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2022
VL 7
IS 1
BP 1
EP 17
DI 10.1016/j.visinf.2022.10.001
PG 17
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 7F1KJ
UT WOS:000901614900001
PM 36312746
OA Green Published, gold
DA 2024-07-18
ER

PT J
AU Wang, YY
   Bai, ZN
   Lin, ZF
   Dong, XQ
   Feng, YCJ
   Pan, JC
   Chen, W
AF Wang, Yanyan
   Bai, Zhanning
   Lin, Zhifeng
   Dong, Xiaoqing
   Feng, Yingchaojie
   Pan, Jiacheng
   Chen, Wei
TI G6: A web-based library for graph visualization
SO VISUAL INFORMATICS
LA English
DT Article
DE Graph visualization; Node-link diagram; Web-based visualization;
   Visualization library
ID MULTIMODAL INTERACTION; EXPLORATION; VEGA
AB Authoring graph visualization poses great challenges to developers due to its high requirements on both domain knowledge and development skills. Although existing libraries and tools reduce the difficulty of generating graph visualization, there are still many challenges. We work closely with developers and formulate several design goals, then design and implement G6, a web-based library for graph visualization. It combines template-based configuration for high usability and flexible customization for high expressiveness. To enhance development efficiency, G6 proposes a range of optimizations, including state management and interaction modes. We demonstrate its capabilities through an extensive gallery, a quantitative performance evaluation, and an expert interview. G6 was first released in 2017 and has been iterated for 317 versions. It has served as a web-based library for thousands of applications and received 8312 stars on GitHub. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wang, Yanyan; Bai, Zhanning; Lin, Zhifeng] Ant Grp, Guangzhou, Peoples R China.
   [Dong, Xiaoqing] Alibaba Grp, Shenzhen, Peoples R China.
   [Feng, Yingchaojie; Pan, Jiacheng; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
C3 Alibaba Group; Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
EM shiwu.wyy@antgroup.com; zhanning.bzn@antgroup.com;
   yushu.lzf@antgroup.com; xiaoqing.dongxq@antfin.com; fycj@zju.edu.cn;
   panjiacheng@zju.edu.cn; chenvis@zju.edu.cn
RI Dong, Xiaoqing/G-1386-2014
OI Feng, Yingchaojie/0000-0002-1418-4635
FU National Natural Science Foundation of China [61772456]
FX We would like to thank Tong Huang, Xuzhi Ming, Libo Zheng, Chenlu Li,
   Yilin Qiu, Huasi Chen, and Bo Pan for their kind help on this paper. Wei
   Chen is supported by National Natural Science Foundation of China
   (61772456).
CR [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   Bastian M., 2009, INT AAAI C WEBL SOC
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Brandes Ulrik, 2011, Journal of Graph Algorithms and Applications, V15, P157, DOI 10.7155/jgaa.00221
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Cui W., 2007, A survey on graph visualization, P145
   Dwyer T, 2009, LECT NOTES COMPUT SC, V5417, P420, DOI 10.1007/978-3-642-00219-9_41
   Eades P., 1984, C NUMERANTIUM, V42, P149
   Franz M, 2016, BIOINFORMATICS, V32, P309, DOI 10.1093/bioinformatics/btv557
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Guare J., 2000, 6 DEGREES SEPARATION
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Heer J, 2010, IEEE T VIS COMPUT GR, V16, P1149, DOI 10.1109/TVCG.2010.144
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li J.K., 2020, IEEE T VIS COMPUT GR, V27, P380
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1151, DOI 10.1109/TVCG.2019.2934537
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1548, DOI 10.1109/TVCG.2018.2871139
   Pinaud B, 2020, VIS INFORM, V4, P23, DOI 10.1016/j.visinf.2020.09.005
   Romat H., 2019, IEEE T VIS COMPUT GR
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wickham H, 2011, WIRES COMPUT STAT, V3, P180, DOI 10.1002/wics.147
   Xie C, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200765
   Zhu HY, 2021, VIS INFORM, V5, P51, DOI 10.1016/j.visinf.2021.06.002
   Zhu M., 2020, IEEE T VIS COMPUT GR, V27, P1666
NR 34
TC 8
Z9 9
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 49
EP 55
DI 10.1016/j.visinf.2021.12.003
EA DEC 2021
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500007
OA gold
DA 2024-07-18
ER

PT J
AU Zhang, J
   Zhou, DD
   Zhao, Y
   Nie, WZ
   Su, YT
AF Zhang, Jing
   Zhou, Dangdang
   Zhao, Yue
   Nie, Weizhi
   Su, Yuting
TI MV-LFN: Multi-view based local information fusion network for 3D shape
   recognition
SO VISUAL INFORMATICS
LA English
DT Article
DE 3D model retrieval; Multi-view; Local information
ID NEURAL-NETWORK
AB 3D shape recognition is a challenging task due to the difficulty of representing the complex structure of 3D shapes. Recently, the view-based approaches that utilize the multiple views rendered from the shape for visual information extraction and feature aggregation to generate a global shape descriptor, achieved promising performance. However, the view-based approaches commonly ignore the exploration and utilization of local information in the multiple views, which influences the effectiveness of generated features. In this paper, we design a novel Multi-view based Local Information Fusion Network (MV-LFN) for the 3D shape recognition task. The local correlation attention mechanism (LCAM) is introduced to exploit the local correlations in the feature maps for generating a more effective view descriptor. Then, we hierarchically aggregate the multi-view feature maps to generate a shape super matrix (SSM). The local information is effectively extracted and maintained during the multi-view aggregation process, and the discrimination of shape descriptors is significantly improved. We conduct comparative experiments on the ModelNet and ShapeNetCore55 databases. The experimental performances effectively validate the superiority of MV-LFN. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Zhang, Jing; Zhou, Dangdang; Zhao, Yue; Nie, Weizhi; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Zhao, Y (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM yuezhao@tju.edu.cn
OI nie, weizhi/0000-0002-0578-8138
FU National Key Research and Development Program of China [2020YF
   B1711704]; National Natural Science Foundation of China [61872267,
   61702471, 61772359]
FX This work was supported in part by the National Key Research and
   Development Program of China (2020YF B1711704), and the National Natural
   Science Foundation of China (61872267, 61702471, 61772359).
CR Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Cheraghian A, 2019, IEEE WINT CONF APPL, P1194, DOI 10.1109/WACV.2019.00132
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Esteves C, 2019, IEEE I CONF COMP VIS, P1568, DOI 10.1109/ICCV.2019.00165
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Furuya T., 2016, P BMVC, V7, P8
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P3986, DOI 10.1109/TIP.2019.2904460
   He XW, 2019, IEEE I CONF COMP VIS, P7514, DOI 10.1109/ICCV.2019.00761
   Jia K, 2019, IEEE T IMAGE PROCESS, V28, P5121, DOI 10.1109/TIP.2019.2912356
   Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Ma C, 2019, IEEE T MULTIMEDIA, V21, P1169, DOI 10.1109/TMM.2018.2875512
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Naffouti SE, 2017, SIGNAL PROCESS-IMAGE, V58, P228, DOI 10.1016/j.image.2017.07.005
   Nie WZ, 2021, IEEE T IMAGE PROCESS, V30, P4371, DOI 10.1109/TIP.2021.3071687
   Qi C. R., 2017, Advances in neural information processing systems, P5099
   Sarkar K, 2018, LECT NOTES COMPUT SC, V11220, P74, DOI 10.1007/978-3-030-01270-0_5
   Savva M., 2017, P WORKSH 3D OBJ RETR, P39, DOI DOI 10.2312/3DOR.20171050
   Sfikas K., 2017, 3dor@ eurographics
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Su Jong-Chyi, 2018, ECCV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yang Z, 2019, IEEE I CONF COMP VIS, P7504, DOI 10.1109/ICCV.2019.00760
   Yavartanoo M., 2018, Asian Conference on Computer Vision, P691
   You HX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1310, DOI 10.1145/3240508.3240702
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
NR 32
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 114
EP 119
DI 10.1016/j.visinf.2021.09.003
EA NOV 2021
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200010
OA gold
DA 2024-07-18
ER

PT J
AU Filipov, V
   Schetinger, V
   Raminger, K
   Soursos, N
   Zapke, S
   Miksch, S
AF Filipov, Velitchko
   Schetinger, Victor
   Raminger, Kathrin
   Soursos, Nathalie
   Zapke, Susana
   Miksch, Silvia
TI Gone full circle: A radial approach to visualize event-based networks in
   digital humanities
SO VISUAL INFORMATICS
LA English
DT Article
DE Event-based networks; Information visualization; Digital humanities
ID DESIGN
AB In the application domain of digital humanities network visualization is increasingly being used to conduct research as the main interests of the domain experts lie in exploring and analyzing relationships between entities and their changes over time. Visualizing the dynamics and different perspectives of such data is a non-trivial task but it enables researchers to explore connections between disparate entities and investigate historical narratives that emerge. In this paper we present Circular, an interactive exploration environment to visualize event-based networks and support research in digital humanities through visualization of historical subjects in space and time. Our radial design is the result of iterative collaboration with domain experts, and we discuss the process of collaborative development and exploration of public music festivities in Vienna as an example of immersive development methodology. We validate our approach by means of both domain and visualization expert interviews and show the potential of this approach in supporting the visual exploration of historical subjects. We discuss our design rationales, visual encodings, and interactions as to allow the reproducibility of this approach within a framework of transdisciplinary collaboration with digital humanities. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Filipov, Velitchko; Schetinger, Victor; Miksch, Silvia] TU Wien, Favoritenstr 9-11, A-1040 Vienna, Austria.
   [Raminger, Kathrin; Soursos, Nathalie; Zapke, Susana] Mus & Kunst Privatuniv, Johannesgasse 4A, A-1010 Vienna, Austria.
C3 Technische Universitat Wien
RP Filipov, V (corresponding author), TU Wien, Favoritenstr 9-11, A-1040 Vienna, Austria.
EM velitchko.filipov@tuwien.ac.at
RI Filipov, Velitchko/JSK-6634-2023
OI Miksch, Silvia/0000-0003-4427-5703; Schetinger,
   Victor/0000-0002-8116-794X; Soursos, Nathalie
   Patricia/0000-0002-7236-4466; Filipov, Velitchko/0000-0001-9592-2179
FU Austrian Science Fund (FWF) [AR384-G24, P31419-N31]; Austrian Science
   Fund (FWF) [P31419] Funding Source: Austrian Science Fund (FWF)
FX This work was conducted within the framework of the project
   ``Interactive Music Mapping Vienna`` (AR384-G24) and
   ``Knowledge-Assisted Visual Analytics`` (P31419-N31) funded by the
   Austrian Science Fund (FWF).
CR Ahn JW, 2014, IEEE T VIS COMPUT GR, V20, P365, DOI 10.1109/TVCG.2013.238
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   Andrienko N., 2006, Exploratory analysis of spatial and temporal data: A systematic approach, DOI DOI 10.1007/3-540-31190-4
   Bale K., 2007, Information Visualization, V6, P155, DOI DOI 10.1057/PALGRAVE.IVS.9500154
   Beck F., 2014, EUROVIS STARS, DOI [10.2312/eurovisstar, DOI 10.2312/EUROVISSTAR]
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Borner K., 2019, DAGSTUHL REPORTS, V8, DOI [10.4230/DagRep.8.11.139, DOI 10.4230/DAGREP.8.11.139]
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Burch M, 2008, COMPUT GRAPH FORUM, V27, P823, DOI 10.1111/j.1467-8659.2008.01213.x
   Burch M., 2014, Handbook of Human Centric Visualization, P429, DOI DOI 10.1007/978146147485217
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   Castermans T, 2019, IEEE T VIS COMPUT GR, V25, P2969, DOI 10.1109/TVCG.2018.2865361
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Dang TN, 2016, COMPUT GRAPH FORUM, V35, P61, DOI 10.1111/cgf.12882
   Di Bartolomeo S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376237
   Diehl S, 2010, IEEE T VIS COMPUT GR, V16, P935, DOI 10.1109/TVCG.2010.209
   Draper GM, 2009, IEEE T VIS COMPUT GR, V15, P759, DOI 10.1109/TVCG.2009.23
   Du F, 2017, IEEE T VIS COMPUT GR, V23, P1636, DOI 10.1109/TVCG.2016.2539960
   Filipov V, 2019, DOI 10.17605/OSF.IO/RVHDS
   Hall KW, 2020, IEEE T VIS COMPUT GR, V26, P109, DOI 10.1109/TVCG.2019.2934790
   Hinrichs U, 2 WORKSH VIS DIG HUM
   Hohman F, 2020, Distill, DOI DOI 10.23915/DISTILL.00028
   KEIM D.A., 2004, AVI 04, P179, DOI 10.1145/989863.989891
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Klein G, 2006, IEEE INTELL SYST, V21, P70, DOI 10.1109/MIS.2006.75
   Krzywinski M, 2009, GENOME RES, V19, P1639, DOI 10.1101/gr.092759.109
   Lamqaddam H, 2018, IEEE TVCG
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168168
   Lewis C, 1982, USING THINKING ALOUD, DOI [10.1080/00140139008927157, DOI 10.1080/00140139008927157]
   Lincoln, 2016, INT J DIGITAL ART HI, V2, DOI [10.11588/dah.2016.2.25337, DOI 10.11588/DAH.2016.2.25337]
   Liu QS, 2015, IEEE CONF VIS ANAL, P65, DOI 10.1109/VAST.2015.7347632
   Maças C, 2018, IEEE INT CON INF VIS, P96, DOI 10.1109/iV.2018.00027
   Mashima D, 2012, IEEE T VIS COMPUT GR, V18, P1424, DOI 10.1109/TVCG.2011.288
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Monroe M., 2013, P ACM C HUMAN FACTOR, P2349, DOI DOI 10.1145/2470654.2481325
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Munzner T., 2014, K PETERS VISUALIZATI
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nightingale F, 1987, NOTES MATTERS AFFECT
   O'Madadhain Joshua., 2005, SIGKDD Explorations Newsletter, V7, P23, DOI DOI 10.1145/1117454.1117458
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Playfair William., 1801, STAT BREVIARY SHEWIN
   Schetinger V., 2019, 4 WORKSHOP VISUALIZA
   Schich M, 2014, SCIENCE, V345, P558, DOI 10.1126/science.1240064
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Shi Y, 2018, IEEE COMPUT GRAPH, V38, P83, DOI 10.1109/MCG.2018.2879067
   Simonetto P, 2020, IEEE T VIS COMPUT GR, V26, P2373, DOI 10.1109/TVCG.2018.2886901
   Stoiber C., 2019, Visualization onboarding: Learning how to read and use visualizations, DOI [10.31219/osf.io/c38ab, DOI 10.31219/OSF.IO/C38AB]
   Tory M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P151, DOI 10.1109/INFVIS.2004.59
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   Vehlow C., 2015, EUROVIS STARS, P21, DOI DOI 10.2312/EUROVISSTAR.20151110
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
NR 55
TC 8
Z9 8
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2021
VL 5
IS 1
BP 45
EP 60
DI 10.1016/j.visinf.2021.01.001
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3LE
UT WOS:000658194100033
OA gold
DA 2024-07-18
ER

PT J
AU Xie, C
   Li, MK
   Wang, HY
   Dong, JY
AF Xie, Cui
   Li, Mingkui
   Wang, Haoying
   Dong, Junyu
TI A survey on visual analysis of ocean data
SO VISUAL INFORMATICS
LA English
DT Article
DE Ocean data; Visualization; Visual analysis
ID MULTIDIMENSIONAL VISUALIZATION; MARINE-ENVIRONMENT; 4D VISUALIZATION;
   TIME; EXPLORATION; ANALYTICS
AB A major challenge in analysis of huge amounts of ocean data is the complexity of the data and the inherent complexity of ocean dynamic processes. Interactive visual analysis serves as an efficient complementary approach for the detection of various phenomena or patterns, and correlation exploring or comparing multiple variables in researchers daily work. Firstly, this paper presents a basic concept of the ocean data produced from numerous measurement devices or computer simulations. The characteristics of ocean data and the related data processing techniques are also described. Secondly, the main tasks of ocean data analysis are introduced. Based on the main analysis tasks in the field of oceanography, the survey emphasizes related interactive visualization techniques and tools from four aspects: visualization of multiple ocean environmental elements and multivariate analysis, ocean phenomena identification and tracking, patterns or correlation discovery, ensembles and uncertainties exploration. Finally, the opportunities are discussed for future studies. (C) 2019 Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press.
C1 [Xie, Cui; Li, Mingkui; Wang, Haoying; Dong, Junyu] Ocean Univ China, Coll Informat Sci & Engn, 238 Songling Rd, Qingdao, Peoples R China.
C3 Ocean University of China
RP Dong, JY (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, 238 Songling Rd, Qingdao, Peoples R China.
EM spring@ouc.edu.cn
FU National Natural Science Foundation of China [41706010, U1706218,
   41576011]; Major Research plan of the National Natural Science
   Foundation of Shandong Province [ZR2018ZB0852]
FX The authors wish to acknowledge the financial support from the National
   Natural Science Foundation of China (No. 41706010, U1706218, 41576011),
   the Major Research plan of the National Natural Science Foundation of
   Shandong Province (No. ZR2018ZB0852). They also would like to thank the
   anonymous reviewers for their comments that helped to improve the paper.
CR Aigner W, 2007, COMPUT GRAPH-UK, V31, P401, DOI 10.1016/j.cag.2007.01.030
   Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043
   Andrienko N, 2003, IEEE INFOR VIS, P237, DOI 10.1109/IV.2003.1217985
   Andrienko N, 2013, DATA MIN KNOWL DISC, V27, P55, DOI 10.1007/s10618-012-0285-7
   [Anonymous], 2015, EUR C VIS EUROVIS 20, DOI DOI 10.2312/EUROVISSHORT.20151124
   Baptista A, 2008, COMPUT SCI ENG, V10, P53, DOI 10.1109/MCSE.2008.83
   Bavoil L., 2015, VISUALIZATION VIS 05, DOI [10.1109/VISUAL.2005, DOI 10.1109/VISUAL.2005]
   Beard K, 2008, INFORM VISUAL, V7, P133, DOI 10.1057/palgrave.ivs.9500165
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Blaas J, 2008, IEEE T VIS COMPUT GR, V14, P1436, DOI 10.1109/TVCG.2008.131
   Blower JD, 2009, PHILOS T R SOC A, V367, P1035, DOI 10.1098/rsta.2008.0180
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Crossno P, 2018, IEEE COMPUT GRAPH, V38, P122, DOI 10.1109/MCG.2018.021951640
   Darles E, 2011, COMPUT GRAPH FORUM, V30, P43, DOI 10.1111/j.1467-8659.2010.01828.x
   Demir I, 2016, IEEE PAC VIS SYMP, P204, DOI 10.1109/PACIFICVIS.2016.7465271
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Diehl A, 2015, COMPUT GRAPH FORUM, V34, P381, DOI 10.1111/cgf.12650
   Diehl A., 2017, COMPUT GRAPH FORUM, DOI [10.1111/cgf, DOI 10.1111/CGF]
   Doleisch H., 2004, P 2004 EUROGRAPHICSI, P91, DOI DOI 10.2312/VISSYM/VISSYM04/091-096
   Dorier M, 2016, IEEE INT C CL COMP, P269, DOI 10.1109/CLUSTER.2016.25
   Duvenhage Bernardt., 2009, AFRIGRAPH 09, P81, DOI DOI 10.1145/1503454.1503469
   Ellsworth D. A., 2017, LDAV, DOI [10.1109/LDAV.2017.8231849, DOI 10.1109/LDAV.2017.8231849]
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Franz K, 2018, INT GEOSCI REMOTE SE, P6887, DOI 10.1109/IGARSS.2018.8519261
   Frey S, 2012, IEEE T VIS COMPUT GR, V18, P2023, DOI 10.1109/TVCG.2012.284
   Fuchs R, 2009, COMPUT GRAPH FORUM, V28, P1670, DOI 10.1111/j.1467-8659.2009.01429.x
   George R.L., 2010, THEORY PRACTICE COMP, P991, DOI [10.2312/LocalChapterEvents/TPCG/TPCG10/099-105, DOI 10.2312/LOCALCHAPTEREVENTS/TPCG/TPCG10/099-105]
   George R.L., 2013, C RES SERV REP, V53, P23, DOI [10.1111/head.12004, DOI 10.1111/HEAD.12004]
   George RLSF, 2014, ENVIRON EARTH SCI, V72, P3753, DOI 10.1007/s12665-014-3283-9
   Grainger S, 2016, ENVIRON MODELL SOFTW, V85, P299, DOI 10.1016/j.envsoft.2016.09.004
   Grochow K, 2008, J PHYS CONF SER, V125, DOI 10.1088/1742-6596/125/1/012092
   Hao LH, 2016, IEEE T VIS COMPUT GR, V22, P787, DOI 10.1109/TVCG.2015.2468093
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   He YW, 2010, CHIN J OCEANOL LIMN, V28, P1086, DOI 10.1007/s00343-010-0029-8
   Helbig C, 2017, INT J DIGIT EARTH, V10, P1070, DOI 10.1080/17538947.2017.1327618
   Ho Q., 2008, NATL CTR VIS ANAL NC, DOI psu:10.1.1.211.831 7
   Höllt T, 2015, NAT HAZARDS, V77, P317, DOI 10.1007/s11069-015-1596-y
   Höllt T, 2014, IEEE T VIS COMPUT GR, V20, P1114, DOI 10.1109/TVCG.2014.2307892
   Höllt T, 2013, IEEE PAC VIS SYMP, P185, DOI 10.1109/PacificVis.2013.6596144
   Horenko I, 2010, DYNAM ATMOS OCEANS, V49, P164, DOI 10.1016/j.dynatmoce.2009.04.003
   Hsu KC, 2010, ADV WATER RESOUR, V33, P190, DOI 10.1016/j.advwatres.2009.11.005
   Jarema M, 2015, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2015.7347634
   Johnson-Roberson M, 2010, J FIELD ROBOT, V27, P21, DOI 10.1002/rob.20324
   Kappe CP, 2019, IEEE T VIS COMPUT GR, V25, P1499, DOI 10.1109/TVCG.2018.2810919
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kehrer J, 2011, IEEE T VIS COMPUT GR, V17, P934, DOI 10.1109/TVCG.2010.111
   Köthur P, 2014, IEEE T VIS COMPUT GR, V20, P1893, DOI 10.1109/TVCG.2014.2346751
   Köthur P, 2014, INFORM VISUAL, V13, P283, DOI 10.1177/1473871613481692
   Kothur P., 2012, EUROVIS SHORT PAPERS, DOI [10.2312/PE/EuroVisShort/EuroVisShort2012/115-119, DOI 10.2312/PE/EUROVISSHORT/EUROVISSHORT2012/115-119]
   Kumatani S, 2016, IEEE INT CONF INF VI, P63, DOI 10.1109/IV.2016.50
   Kumpf A, 2019, IEEE T VIS COMPUT GR, V25, P98, DOI 10.1109/TVCG.2018.2864901
   Kumpf A, 2018, IEEE T VIS COMPUT GR, V24, P109, DOI 10.1109/TVCG.2017.2745178
   Lavigne V., 2011, IEEE INT C TECHN HOM, DOI [10.1109/THS.2011.6107846, DOI 10.1109/THS.2011.6107846]
   Li WQ, 2011, COMPUT GEOSCI-UK, V37, P1743, DOI 10.1016/j.cageo.2011.04.009
   Lima E, 2017, IEEE GEOSCI REMOTE S, V14, P354, DOI 10.1109/LGRS.2016.2643000
   Lipsa DR, 2012, COMPUT GRAPH FORUM, V31, P2317, DOI 10.1111/j.1467-8659.2012.03184.x
   Liu RC, 2017, J VISUAL-JAPAN, V20, P217, DOI 10.1007/s12650-016-0388-0
   Liu RC, 2016, IEEE PAC VIS SYMP, P96, DOI 10.1109/PACIFICVIS.2016.7465256
   Liu S, 2017, COMPUT GEOSCI-UK, V104, P20, DOI 10.1016/j.cageo.2017.03.021
   Liu XT, 2016, IEEE T VIS COMPUT GR, V22, P955, DOI 10.1109/TVCG.2015.2467431
   Liu YJ, 2016, LECT NOTES COMPUT SC, V9784, P212, DOI 10.1007/978-3-319-42553-5_18
   Matsuoka D, 2016, PROCEDIA COMPUT SCI, V80, P1601, DOI 10.1016/j.procs.2016.05.491
   Matsuoka D, 2014, IEEE PAC VIS SYMP, P340, DOI 10.1109/PacificVis.2014.64
   Mei Hong-Hui, 2016, Journal of Software, V27, P1140, DOI 10.13328/j.cnki.jos.004954
   Mingkui L., VISUALIZATION OCEAN
   Miyachi H, 2018, LECT NOTE DATA ENG, V7, P690, DOI 10.1007/978-3-319-65521-5_61
   Obermaier H, 2016, IEEE T VIS COMPUT GR, V22, P2331, DOI 10.1109/TVCG.2015.2507592
   Peng Z., 2011, EUROGRAPHICS POSTERS, P13
   Phhh Q., 2000, IEEE VIS C, DOI [10.1145/375213.375317, DOI 10.1145/375213.375317]
   Rautenhaus M, 2018, IEEE T VIS COMPUT GR, V24, P3268, DOI 10.1109/TVCG.2017.2779501
   Ravi L., 2013, P 2013 INT C COMP TH, DOI [10.1007/978-3-540-87987-9_2, DOI 10.1007/978-3-540-87987-9_2]
   Resch B, 2014, CARTOGR GEOGR INF SC, V41, P235, DOI 10.1080/15230406.2014.901901
   Roberts J.C., 2014, IEEE C VIS VIS
   Rocha A., 2017, WORKSH VIS ENV SCI E, V2, DOI [10.2312/envirvis.20171101, DOI 10.2312/ENVIRVIS.20171101]
   Rust HW, 2010, J CLIMATE, V23, P6573, DOI 10.1175/2010JCLI3432.1
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Samsel F., 2016, SIGCHI ACM, P700
   Schubert E, 2015, PROC VLDB ENDOW, V8, P1977
   Signell RP, 2019, J MAR SCI ENG, V7, DOI 10.3390/jmse7040110
   Silva R.A., 2013, INTERACTIVE VISUALIZ
   Silva RA, 2016, LECT NOTES GEOINF CA, P219, DOI 10.1007/978-3-319-33783-8_13
   Sips M, 2012, IEEE T VIS COMPUT GR, V18, P2899, DOI 10.1109/TVCG.2012.191
   Su TY, 2016, ADV ENG SOFTW, V95, P7, DOI 10.1016/j.advengsoft.2016.01.009
   Tamim A, 2015, PATTERN RECOGN LETT, V55, P28, DOI 10.1016/j.patrec.2014.12.006
   Tominski C., 2004, Proceedings of the 2004 ACM symposium on Applied computing, P1242, DOI [10.1145/967900.968153, DOI 10.1145/967900.968153]
   Turdukulov UD, 2007, COMPUT GRAPH-UK, V31, P370, DOI 10.1016/j.cag.2007.01.028
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wang SZ, 2017, INFORMATICS-BASEL, V4, DOI 10.3390/informatics4030017
   Ware C., 2001, OCEANS, DOI [10.1109/OCEANS.2001.968146, DOI 10.1109/OCEANS.2001.968146]
   Woodring J, 2016, IEEE T VIS COMPUT GR, V22, P857, DOI 10.1109/TVCG.2015.2467411
   Yong C.Z., 2016, J GUANGDONG OCEAN U, V36, P82, DOI [10.3969/j.issn.1673-9159.2016.03.014, DOI 10.3969/J.ISSN.1673-9159.2016.03.014]
   Zhang HJ, 2018, VISUAL COMPUT, V34, P531, DOI 10.1007/s00371-017-1359-8
   Zhang Y, 2017, J VISUAL LANG COMPUT, V41, P121, DOI 10.1016/j.jvlc.2017.03.005
   Zhang ZY, 2015, IEEE T VIS COMPUT GR, V21, P289, DOI 10.1109/TVCG.2014.2350494
   Zhihan L., 2015, ABS150401049 ARXIV
NR 96
TC 18
Z9 19
U1 2
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2019
VL 3
IS 3
BP 113
EP 128
DI 10.1016/j.visinf.2019.08.001
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YL
UT WOS:000658189600001
OA gold
DA 2024-07-18
ER

PT J
AU Li, YX
   Li, XH
   Shen, SQ
   Zeng, LB
   Liu, RC
   Zheng, QB
   Feng, JF
   Chen, SM
AF Li, Yuxiao
   Li, Xinhong
   Shen, Siqi
   Zeng, Longbin
   Liu, Richen
   Zheng, Qibao
   Feng, Jianfeng
   Chen, Siming
TI DTBVis: An interactive visual comparison system for digital twin brain
   and human brain
SO VISUAL INFORMATICS
LA English
DT Article
DE Brain; Digital twin brain; Visual analytics; Comparative analysis
ID VISUALIZATION; CONNECTIVITY; NETWORKS; SUBJECT
AB The digital twin brain (DTB) computing model from brain-inspired computing research is an emerging artificial intelligence technique, which is realized by a computational modeling approach of hardware and software. It can achieve various cognitive abilities and their synergistic mechanisms in a manner similar to the human brain. Given that the task of the DTB is to simulate the functions of the human brain, comparing the similarities and differences between the two is crucial. However, the visualization study of the DTB is still under-researched. Moreover, the complexity of the datasets (multilevel spatiotemporal granularity and different types of comparison tasks) presents new challenges to the analysis and exploration of visualization. Therefore, in this study, we proposed DTBVis, a visual analytics system that supports comparison tasks for the DTB. DTBVis supports iterative explorations from different levels and at different granularities. Combined with automatic similarity recommendation, and high-dimensional exploration, DTBVis can assist experts in understanding the similarities and differences between the DTB and the human brain, thus helping them adjust their model and enhance its functionality. The highest level of DTBVis shows an overview of the datasets from the brain, which is used for comparison and exploration of the function and structure of the DTB and the human brain. The medium level is used for the comparison and exploration of a designated brain region. The low level can analyze a designated brain voxel. We worked closely with experts of brain science and held regular seminars with them. Feedback from the experts indicates that our approach helps them conduct comparative studies of the DTB and human brain and make modeling adjustments of the DTB through intuitive visual comparisons and interactive explorations.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Li, Yuxiao; Li, Xinhong; Shen, Siqi; Feng, Jianfeng; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Zeng, Longbin; Zheng, Qibao; Feng, Jianfeng] Fudan Univ, Inst Sci & Technol Brain Inspired Intellignece, Shanghai, Peoples R China.
   [Liu, Richen] Nanjing Normal Univ, Sch Comp & Elect Informat, Nanjing, Peoples R China.
C3 Fudan University; Fudan University; Nanjing Normal University
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.; Liu, RC (corresponding author), Nanjing Normal Univ, Sch Comp & Elect Informat, Nanjing, Peoples R China.
EM 21210980048@m.fudan.edu.cn; richen@pku.edu.cn; simingchen@fudan.edu.cn
RI Liu, Richen/AAB-2890-2022; Chen, Siming/AAK-1874-2020
OI Liu, Richen/0000-0002-5321-098X; Chen, Siming/0000-0002-2690-3588; zeng,
   longbin/0000-0002-3816-468X; Li, Yuxiao/0000-0002-8715-5982
FU National Natural Science Foundation of China (NSFC) [62202105]; Shanghai
   Municipal Science and Technology Major Project, China [2018SHZDZX01,
   2021SHZDZX0103]; General Program, China [21ZR1403300]; Sailing Program,
   China [21YF1402900]; ZJLab, China
FX The authors wish to thank Leijun Ye from the DTB research team and the
   reviewers for their suggestions. This work is supported by National
   Natural Science Foundation of China (NSFC No. 62202105), Shanghai
   Municipal Science and Technology Major Project, China (No. 2018SHZDZX01,
   2021SHZDZX0103), General Program, China (No. 21ZR1403300) , Sailing
   Program, China (No. 21YF1402900) and ZJLab, China.
CR Abbasloo A, 2016, IEEE T VIS COMPUT GR, V22, P975, DOI 10.1109/TVCG.2015.2467031
   Al-Awami AK, 2016, IEEE T VIS COMPUT GR, V22, P738, DOI 10.1109/TVCG.2015.2467441
   Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Alper B., 2013, PROC SIGCHI C HUM FA, P483
   Andrienko G, 2017, IEEE T VIS COMPUT GR, V23, P2120, DOI 10.1109/TVCG.2016.2616404
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   Böttger J, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00015
   Böttger J, 2014, IEEE T VIS COMPUT GR, V20, P471, DOI 10.1109/TVCG.2013.114
   Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575
   Collins C, 2007, IEEE T VIS COMPUT GR, V13, P1192, DOI 10.1109/TVCG.2007.70521
   De Perrot T, 2022, J CLIN MED, V11, DOI 10.3390/jcm11071921
   Deniz F, 2019, J NEUROSCI, V39, P7722, DOI 10.1523/JNEUROSCI.0675-19.2019
   Everts MH, 2015, IEEE T VIS COMPUT GR, V21, P808, DOI 10.1109/TVCG.2015.2403323
   Fink GR, 2007, NEUROBIOLOGY OF DISEASE, P839
   Forlines C., 2010, WAKAME SENSE MAKING, P33, DOI [10.1145/1842993.1843000, DOI 10.1145/1842993.1843000]
   Gatalsky P, 2004, IEEE INFOR VIS, P145, DOI 10.1109/IV.2004.1320137
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Ilagcrstrand T, 1970, PAPERS REGIONAL SCI, V24
   Irimia A, 2012, NEUROIMAGE, V60, P1340, DOI 10.1016/j.neuroimage.2012.01.107
   Kapler T., 2005, Information Visualization, V4, P136, DOI 10.1057/palgrave.ivs.9500097
   Kraak M.-J., 2008, PROC 21 INT CARTOGR
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Lichtman JW, 2011, SCIENCE, V334, P618, DOI 10.1126/science.1209168
   Liu RC, 2022, IEEE T HUM-MACH SYST, V52, P1338, DOI 10.1109/THMS.2022.3211317
   Lu Q., 2022, arXiv
   Margulies DS, 2013, NEUROIMAGE, V80, P445, DOI 10.1016/j.neuroimage.2013.04.111
   OGAWA S, 1990, P NATL ACAD SCI USA, V87, P9868, DOI 10.1073/pnas.87.24.9868
   Schmidt J, 2014, IEEE CONF VIS ANAL, P153, DOI 10.1109/VAST.2014.7042491
   Sherbondy A, 2005, IEEE T VIS COMPUT GR, V11, P419, DOI 10.1109/TVCG.2005.59
   Shi L, 2022, IEEE T VIS COMPUT GR, V28, P4640, DOI 10.1109/TVCG.2021.3098123
   Shirinbayan SI, 2019, HUM BRAIN MAPP, V40, P151, DOI 10.1002/hbm.24361
   Thakur S, 2010, IEEE INT CONF INF VI, P336, DOI 10.1109/IV.2010.54
   Tominski C, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P175, DOI 10.1109/IV.2005.3
   Tominski C., 2012, Vision, Modeling, and Visualization, P199, DOI DOI 10.2312/PE/VMV/VMV12/199-206
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Yang XS, 2017, IEEE T VIS COMPUT GR, V23, P181, DOI 10.1109/TVCG.2016.2598472
   Zhang CG, 2016, IEEE T VIS COMPUT GR, V22, P797, DOI 10.1109/TVCG.2015.2467435
   Zhao YH, 2022, VIS INFORM, V6, P56, DOI 10.1016/j.visinf.2022.03.002
NR 39
TC 4
Z9 4
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2023
VL 7
IS 2
BP 41
EP 53
DI 10.1016/j.visinf.2023.02.002
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA M6QW0
UT WOS:001031452400001
OA gold
DA 2024-07-18
ER

PT J
AU Cheng, SH
   Giesen, J
   Huang, TY
   Lucas, P
   Mueller, K
AF Cheng, Shenghui
   Giesen, Joachim
   Huang, Tianyi
   Lucas, Philipp
   Mueller, Klaus
TI Identifying the skeptics and the undecided through visual cluster
   analysis of local network geometry
SO VISUAL INFORMATICS
LA English
DT Article
DE Graph/network data; High dimensional data visualization; Visualization
   in social and information sciences; Data clustering coordinated and
   multiple views
ID COMMUNITIES
AB By skeptics and undecided we refer to nodes in clustered social networks that cannot be assigned easily to any of the clusters. Such nodes are typically found either at the interface between clusters (the undecided) or at their boundaries (the skeptics). Identifying these nodes is relevant in marketing applications like voter targeting, because the persons represented by such nodes are often more likely to be affected in marketing campaigns than nodes deeply within clusters. So far this identification task is not as well studied as other network analysis tasks like clustering, identifying central nodes, and detecting motifs. We approach this task by deriving novel geometric features from the network structure that naturally lend themselves to an interactive visual approach for identifying interface and boundary nodes.
   (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by- nc- nd/4.0/).
C1 [Cheng, Shenghui; Huang, Tianyi] Westlake Univ, Hangzhou, Peoples R China.
   [Mueller, Klaus] SUNY Stony Brook, Stony Brook, NY 11794 USA.
   [Giesen, Joachim; Lucas, Philipp] Friedrich Schiller Univ Jena, Jena, Germany.
   [Cheng, Shenghui; Huang, Tianyi] Westlake Inst Adv Study, Hangzhou, Peoples R China.
   [Cheng, Shenghui] Res Ctr Ind Future, Hangzhou, Peoples R China.
C3 Westlake University; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook; Friedrich Schiller University
   of Jena; Westlake University
RP Cheng, SH (corresponding author), Westlake Univ, Hangzhou, Peoples R China.
EM chengshenghui@westlake.edu.cn
RI Zhang, Xiaofeng/JMC-6060-2023; Wang, Jiacheng/ABE-5948-2020
OI Zhang, Xiaofeng/0000-0003-2738-3286; Wang, Jiacheng/0000-0003-4327-1508;
   Cheng, Shenghui/0000-0002-3767-8371; Huang, Tinayi/0000-0003-1606-0588
CR Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Bezerianos A, 2010, COMPUT GRAPH FORUM, V29, P863, DOI 10.1111/j.1467-8659.2009.01687.x
   Borg I., 2005, MODERN MULTIDIMENSIO, DOI DOI 10.18637/JSS.V014.B04
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Cheng SH, 2018, IEEE ACCESS, V6, P57191, DOI 10.1109/ACCESS.2018.2872344
   Cheng SH, 2019, IEEE T VIS COMPUT GR, V25, P1361, DOI 10.1109/TVCG.2018.2808489
   Cheng SH, 2017, PROCESSES, V5, DOI 10.3390/pr5040075
   Cheng SH, 2014, 2014 FIRST WORKSHOP ON VISUAL PERFORMANCE ANALYSIS (VPA), P9, DOI 10.1109/VPA.2014.7
   Cheng SH, 2015, IEEE PAC VIS SYMP, P295, DOI 10.1109/PACIFICVIS.2015.7156390
   Cheng SH, 2016, IEEE T VIS COMPUT GR, V22, P121, DOI 10.1109/TVCG.2015.2467552
   Cormen T.H., 2009, INTRO ALGORITHMS
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Hartigan J. A., 1975, Journal of Statistical Computation and Simulation, V4, P187, DOI 10.1080/00949657508810123
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Kandogan E., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P107, DOI 10.1145/502512.502530
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168168
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lorrain F., 1971, J MATH SOCIOL, V1, P49, DOI [DOI 10.1080/0022250X.1971.9989788, 10.1080/0022250X.1971.9989788]
   Marc B.S., 2014, Mapping twitter topic networks: From polarized crowds to community clusters
   McAuley J, 2014, ACM T KNOWL DISCOV D, V8, P73, DOI 10.1145/2556612
   Nadler B., 2008, Principal Manifolds for Data Visualization and Dimension Reduction, DOI DOI 10.1007/978-3-540-73750-6_10
   Nishikawa T, 2011, SCI REP-UK, V1, DOI 10.1038/srep00151
   Nocaj A, 2014, LECT NOTES COMPUT SC, V8871, P101, DOI 10.1007/978-3-662-45803-7_9
   Pretorius AJ, 2014, LECT NOTES COMPUT SC, V8380, P77, DOI 10.1007/978-3-319-06793-3_5
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Valiati E.R., 2006, P 2006 AVI WORKSHOP, P1, DOI DOI 10.1145/1168149.1168169
   Van Dongen S, 2008, SIAM J MATRIX ANAL A, V30, P121, DOI 10.1137/040608635
   Vehlow C, 2013, IEEE T VIS COMPUT GR, V19, P2486, DOI 10.1109/TVCG.2013.232
   Viau C, 2010, IEEE T VIS COMPUT GR, V16, P1100, DOI 10.1109/TVCG.2010.205
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Wong PC, 2006, IEEE T VIS COMPUT GR, V12, P1399, DOI 10.1109/TVCG.2006.92
   Wu YH, 2015, IEEE PAC VIS SYMP, P47, DOI 10.1109/PACIFICVIS.2015.7156355
   Zhang XY, 2023, IEEE T VIS COMPUT GR, V29, P3775, DOI 10.1109/TVCG.2022.3170531
NR 35
TC 7
Z9 7
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2022
VL 6
IS 3
BP 11
EP 22
DI 10.1016/j.visinf.2022.07.002
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6M5IA
UT WOS:000888899400002
OA gold
DA 2024-07-18
ER

PT J
AU Han, J
   Wang, CL
AF Han, Jun
   Wang, Chaoli
TI VCNet: A generative model for volume completion
SO VISUAL INFORMATICS
LA English
DT Article
DE Volume visualization; Generative adversarial network; Data completion
ID FLOW; SUPERRESOLUTION; STREAMLINES
AB We present VCNet, a new deep learning approach for volume completion by synthesizing missing subvolumes. Our solution leverages a generative adversarial network (GAN) that learns to complete volumes using the adversarial and volumetric losses. The core design of VCNet features dilated residual block and long-term connection. During training, VCNet first randomly masks basic subvolumes (e.g., cuboids, slices) from complete volumes and learns to recover them. Moreover, we design a twostage algorithm for stabilizing and accelerating network optimization. Once trained, VCNet takes an incomplete volume as input and automatically identifies and fills in the missing subvolumes with high quality. We quantitatively and qualitatively test VCNet with volumetric data sets of various characteristics to demonstrate its effectiveness. We also compare VCNet against a diffusion-based solution and two GAN-based solutions. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Han, Jun; Wang, Chaoli] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Han, J (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM jhan5@nd.edu
RI Wang, Chaoli/AAJ-5173-2020
OI Wang, Chaoli/0000-0002-0859-3619
FU U.S. National Science Foundation [IIS-1455886, CNS-1629914, DUE
   -1833129, IIS-1955395, IIS-2101696, OAC-2104158]
FX This work was supported in part by the U.S. National Science Foundation
   through grants IIS-1455886, CNS-1629914, DUE -1833129, IIS-1955395,
   IIS-2101696, and OAC-2104158. The authors would like to thank the
   anonymous reviewers for their insightful comments.
CR An YF, 2021, IEEE COMPUT GRAPH, V41, P122, DOI 10.1109/MCG.2021.3097555
   [Anonymous], 2016, P INT C LEARN REPR
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Bruckner S, 2010, COMPUT GRAPH FORUM, V29, P773, DOI 10.1111/j.1467-8659.2009.01689.x
   Cheng HC, 2019, IEEE T VIS COMPUT GR, V25, P1378, DOI 10.1109/TVCG.2018.2796085
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu P., P IEEE PACIFIC VISUA
   Gu PF, 2021, IEEE COMPUT GRAPH, V41, P111, DOI 10.1109/MCG.2021.3089627
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P2445, DOI 10.1109/TVCG.2020.3032123
   Han J, 2022, COMPUT GRAPH-UK, V103, P168, DOI 10.1016/j.cag.2022.02.001
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P270, DOI 10.1109/TVCG.2021.3114815
   Han J, 2021, IEEE T VIS COMPUT GR, V27, P1290, DOI 10.1109/TVCG.2020.3030346
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2019, IEEE COMPUT GRAPH, V39, P54, DOI 10.1109/MCG.2018.2881523
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kingma D. P., 2014, arXiv
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305
   Li H, 2018, ADV NEUR IN, V31
   Liang X, 2018, IEEE INT CONF BIG DA, P438, DOI 10.1109/BigData.2018.8622520
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Porter WP, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P131, DOI [10.1109/VISUAL.2019.8933759, 10.1109/visual.2019.8933759]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tkachev G., IEEE T VIS COMPUT GR
   Tkachev G, 2021, IEEE T VIS COMPUT GR, V27, P3091, DOI 10.1109/TVCG.2019.2961893
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Y, 2018, ADV NEUR IN, V31
   Weiss S., 2020, IEEE T VIS COMPUT GR
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
NR 47
TC 4
Z9 4
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2022
VL 6
IS 2
BP 62
EP 73
DI 10.1016/j.visinf.2022.04.004
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 3D7JN
UT WOS:000829473700003
OA gold
DA 2024-07-18
ER

PT J
AU Shen, JY
   Wang, RQ
   Shen, HW
AF Shen, Jingyi
   Wang, Runqi
   Shen, Han-Wei
TI Visual exploration of latent space for traditional Chinese music
SO VISUAL INFORMATICS
LA English
DT Article
DE Music information retrieval; Latent space analysis; Long Short-Term
   Memory; Autoencoder; Traditional Chinese music
AB Generating compact and effective numerical representations of data is a fundamental step for many machine learning tasks. Traditionally, handcrafted features are used but as deep learning starts to show its potential, using deep learning models to extract compact representations becomes a new trend. Among them, adopting vectors from the model's latent space is the most popular. There are several studies focused on visual analysis of latent space in NLP and computer vision. However, relatively little work has been done for music information retrieval (MIR) especially incorporating visualization. To bridge this gap, we propose a visual analysis system utilizing Autoencoders to facilitate analysis and exploration of traditional Chinese music. Due to the lack of proper traditional Chinese music data, we construct a labeled dataset from a collection of pre-recorded audios and then convert them into spectrograms. Our system takes music features learned from two deep learning models (a fully-connected Autoencoder and a Long Short-Term Memory (LSTM) Autoencoder) as input. Through interactive selection, similarity calculation, clustering and listening, we show that the latent representations of the encoded data allow our system to identify essential music elements, which lay the foundation for further analysis and retrieval of Chinese music in the future. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Shen, Jingyi; Wang, Runqi; Shen, Han-Wei] Ohio State Univ, 2015 Neil Ave, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Shen, JY (corresponding author), Ohio State Univ, 2015 Neil Ave, Columbus, OH 43210 USA.
EM shen.1250@osu.edu; wang.6863@osu.edu; shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012
FU US Department of Energy Los Alamos National Laboratory [47145];
   UT-Battelle LLC [4000159447]
FX This work was supported in part by US Department of Energy Los Alamos
   National Laboratory contract 47145 and UT-Battelle LLC contract
   4000159447 program manager Laura Biven.
CR Agostini G, 2003, EURASIP J APPL SIG P, V2003, P5, DOI 10.1155/S1110865703210118
   [Anonymous], 1980, PHYS MUSIC
   [Anonymous], 2013, ARXIV13112901 CORR
   [Anonymous], 2013, ISMIR
   Athar A, 2019, NUCLEIC ACIDS RES, V47, pD711, DOI 10.1093/nar/gky964
   Camargo J.E., 2014 IEEE INT C MULT, P1, DOI [10.1109/ICMEW.2014.6890716, DOI 10.1109/ICMEW.2014.6890716]
   Camargo J.E., 2014 IEEE INT C MULT, P1, DOI [10.1109/ICMEW.2014, DOI 10.1109/ICMEW.2014]
   Choi K., 2016, ARXIV160600298 CORR
   Chuan CH, 2020, NEURAL COMPUT APPL, V32, P1023, DOI 10.1007/s00521-018-3923-1
   Cooper M, 2006, COMPUT MUSIC J, V30, P42, DOI 10.1162/comj.2006.30.2.42
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Cruz L, 2018, LECT NOTES COMPUT SC, V11265, P468, DOI 10.1007/978-3-030-01692-0_31
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Downie JS, 2004, COMPUT MUSIC J, V28, P12, DOI 10.1162/014892604323112211
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   Eck D, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P747, DOI 10.1109/NNSP.2002.1030094
   Foote J, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P77, DOI 10.1145/319463.319472
   Garcia-Gasulla D., 2015, ARXIV150708818 CORR
   Hristov Y., 2018, ARXIV180706583 CORR
   Janssen B, 2017, J NEW MUSIC RES, V46, P118, DOI 10.1080/09298215.2017.1316292
   Ji XN, 2019, IEEE T VIS COMPUT GR, V25, P2181, DOI 10.1109/TVCG.2019.2903946
   Jiang DN, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P113, DOI 10.1109/ICME.2002.1035731
   Kim HW, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P47, DOI 10.1109/FUZZY.2009.5277047
   Koenigstein N, 2011, P 5 ACM C REC SYST, P165, DOI [DOI 10.1145/2043932.2043964, 10.1145/20]
   Korzeniowski F., 2016, ARXIV161205082 CORR
   LADEN B, 1989, COMPUT MUSIC J, V13, P12, DOI 10.2307/3679550
   Lee J., 2017, ARXIV170301789 CORR
   Li XX, 2016, INT CONF ACOUST SPEE, P544, DOI 10.1109/ICASSP.2016.7471734
   Liu SS, 2018, IEEE T VIS COMPUT GR, V24, P553, DOI 10.1109/TVCG.2017.2745141
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Marchi E, 2015, INT CONF ACOUST SPEE, P1996, DOI 10.1109/ICASSP.2015.7178320
   McFee B., 2011, ARXIV11052344 CORR
   Meyer M., 2017, ARXIV171203835 CORR
   Müller M, 2011, IEEE J-STSP, V5, P1088, DOI 10.1109/JSTSP.2011.2112333
   Nabney IT, 2005, IEEE T KNOWL DATA EN, V17, P384, DOI 10.1109/TKDE.2005.49
   Nam J., 2012, ISMIR
   Panda S., 2019, VISUALIZING MUSIC GE, DOI [10.5281/zenodo.3249352, DOI 10.5281/ZENODO.3249352]
   Peeters G., 2004, CUIDADO 1 PROJECT RE
   Schluter J., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P118, DOI 10.1109/ICMLA.2011.102
   Sigtia S, 2015, INT CONF ACOUST SPEE, P2061, DOI 10.1109/ICASSP.2015.7178333
   Slaney M., 2008, LEARNING METRIC MUSI, P313
   Srivastava N., 2015, ARXIV150204681 CORR
   Sumit Arif, 2012, INT J APPL INFORM SY, V1, P16, DOI DOI 10.5120/IJAIS12-450131
   Sutskever I., 2014, ARXIV14093215 CORR
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1598, DOI 10.1145/3240508.3240526
   Van den Oord A., 2013, P NIPS
   van den Oord A., 2016, ARXIV160903499 CORR
   West K, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/24602
   Xu C, 2003, 2003 IEEE INT C AC S, V5, pV, DOI DOI 10.1109/ICASSP.2003.1199998
   Yim J.-D., 2009, MUSICIAN MAP VISUALI, V7243, DOI [10.1117/12, DOI 10.1117/12]
   Yu Y, 2020, NEUROCOMPUTING, V372, P84, DOI 10.1016/j.neucom.2019.09.054
   Zhao F, 2018, IEEE T IMAGE PROCESS, V27, P778, DOI 10.1109/TIP.2017.2771408
   Zhu WZ, 2007, COMPUT GRAPH-UK, V31, P338, DOI 10.1016/j.cag.2007.01.025
NR 53
TC 10
Z9 10
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2020
VL 4
IS 2
SI SI
BP 99
EP 108
DI 10.1016/j.visinf.2020.04.003
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KK
UT WOS:000658192100004
OA gold
DA 2024-07-18
ER

PT J
AU Shirato, G
   Andrienko, N
   Andrienko, G
AF Shirato, Gota
   Andrienko, Natalia
   Andrienko, Gennady
TI Exploring and visualizing temporal relations in multivariate time series
SO VISUAL INFORMATICS
LA English
DT Article
DE Temporal relations; Temporal abstraction; Multivariate time series; Time
   intervals
ID DISCOVERY; KNOWLEDGE
AB This paper introduces an approach to analyzing multivariate time series (MVTS) data through progressive temporal abstraction of the data into patterns characterizing the behavior of the studied dynamic phenomenon. The paper focuses on two core challenges: identifying basic behavior patterns of individual attributes and examining the temporal relations between these patterns across the range of attributes to derive higher-level abstractions of multi-attribute behavior. The proposed approach combines existing methods for univariate pattern extraction, computation of temporal relations according to the Allen's time interval algebra, visual displays of the temporal relations, and interactive query operations into a cohesive visual analytics workflow. The paper describes the application of the approach to real-world examples of population mobility data during the COVID-19 pandemic and characteristics of episodes in a football match, illustrating its versatility and effectiveness in understanding composite patterns of interrelated attribute behaviors in MVTS data. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Shirato, Gota; Andrienko, Natalia; Andrienko, Gennady] Fraunhofer IAIS, St Augustin, Germany.
   [Shirato, Gota] Univ Bonn, Bonn, Germany.
   [Andrienko, Natalia; Andrienko, Gennady] City Univ London, London, England.
C3 University of Bonn; City University London
RP Shirato, G (corresponding author), Fraunhofer IAIS, St Augustin, Germany.
EM gota.shirato@iais.fraunhofer.de; natalia.andrienko@iais.fraunhofer.de;
   gennady.andrienko@iais.fraunhofer.de
RI Andrienko, Natalia/KHV-4755-2024; Andrienko, Gennady L./B-6486-2014
OI Andrienko, Gennady L./0000-0002-8574-6295; Andrienko,
   Natalia/0000-0003-3313-1560
FU Federal Ministry of Education and Research of Germany; State of
   North-Rhine Westphalia as part of the Lamarr Institute for Machine
   Learning and Artificial Intelligence; EU [101092749]
FX This work was partly supported by Federal Ministry of Education and
   Research of Germany and the state of North-Rhine Westphalia as part of
   the Lamarr Institute for Machine Learning and Artificial Intelligence
   (Lamarr22B) , and by EU in projects SoBigData++ and CrexData (grant
   agreement 101092749) .
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Andrienko N., 2020, Visual Analytics for Data Scientists
   Andrienko N, 2023, COMPUT GRAPH FORUM, V42, DOI 10.1111/cgf.14845
   Andrienko N, 2021, VIS INFORM, V5, P23, DOI 10.1016/j.visinf.2020.12.002
   Bertin J, 1983, Semiology of Graphics, P11
   Combi C, 2012, ARTIF INTELL MED, V54, P75, DOI 10.1016/j.artmed.2011.10.004
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Fonseca S, 2012, HUM MOVEMENT SCI, V31, P1652, DOI 10.1016/j.humov.2012.04.006
   Google, 2020, Google COVID-19 community mobility reports
   Gotz D., 2011, IEEE VISWEEK WORKSH, P25
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Hochheiser H, 2001, Computer Science Dept. Tech Report, CS-TR-4365
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Islind AS, 2020, Arxiv, DOI [arXiv:2008.10505, DOI 10.48550/ARXIV.2008.10505,ARXIV.ORG]
   Keogh E., 2004, Data mining in time series databases, P1, DOI [DOI 10.1142/97898125654020001, 10.1142/9789812565402_0001, DOI 10.1142/9789812565402_0001]
   kicker, 2018, Furioser BVB! Nach Robert-Lewandowski-Doppelpack drehen Reus & Co. auf-Borussia Dortmund baut Vorsprung auf Bayern Munchen auf insgesamt sieben Punkten aus
   Köthur P, 2015, COMPUT GRAPH FORUM, V34, P411, DOI 10.1111/cgf.12653
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lee TY, 2009, IEEE T VIS COMPUT GR, V15, P1359, DOI 10.1109/TVCG.2009.200
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z
   Liu Shuhan, 2023, IEEE Trans Vis Comput Graph, V29, P1091, DOI 10.1109/TVCG.2022.3209430
   Lutkepohl H., 1991, Introduction to Multiple Time Series Analysis, DOI [10.1007/978-3-662-02691-5, DOI 10.1007/978-3-662-02691-5]
   Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Murphy Kevin Patrick, 2002, Dynamic bayesian networks: representation, inference and learning
   Patel P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P370, DOI 10.1109/ICDM.2002.1183925
   Sacchi L, 2007, DATA MIN KNOWL DISC, V15, P217, DOI 10.1007/s10618-007-0077-7
   Shahar Y, 1997, ARTIF INTELL, V90, P79, DOI 10.1016/S0004-3702(96)00025-2
   Shirato G, 2023, VIS INFORM, V7, P77, DOI 10.1016/j.visinf.2023.01.001
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Tufte ER, 1990, Envisioning Information
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Walker J, 2016, IEEE T VIS COMPUT GR, V22, P549, DOI 10.1109/TVCG.2015.2467751
   Yi JS, 2010, INT J HUM-COMPUT INT, V26, P1031, DOI 10.1080/10447318.2010.516722
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
NR 36
TC 2
Z9 2
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 57
EP 72
DI 10.1016/j.visinf.2023.09.001
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA DQ8Z1
UT WOS:001133632900001
OA gold
DA 2024-07-18
ER

PT J
AU Yu, MZ
   Wang, Y
   Yu, XM
   Shan, GH
   Jin, Z
AF Yu, Minzhu
   Wang, Yang
   Yu, Xiaomin
   Shan, Guihua
   Jin, Zhong
TI PubExplorer: An interactive analytical system for visualizing
   publication data
SO VISUAL INFORMATICS
LA English
DT Article
DE Scientific literature; Research points analysis; Visual analytics
   system; Publication analysis; Text visualization
ID SLEEPING BEAUTIES
AB With the intersection and convergence of multiple disciplines and technologies, more and more researchers are actively exploring interdisciplinary cooperation outside their main research fields. Facing a new research field, researchers often hope to quickly learn what is being studied in this field, which research points are receiving high attention, which researchers are studying these research points, and then consider the possibility of collaborating with core researchers on these research points. In addition, students who are preparing for academic further education usually conduct research on mentors and mentors' research platforms, including academic connections, employment opportunities, etc. In order to satisfy these requirements, we (1) design a research point state map based on a science map to help researchers and students understand the development state of a new research field; (2) design a bar-link author-affiliation information graph to help researchers and students clarify academic networks of scholars and find suitable collaborators or mentors; (3) designs citation pattern histogram to quickly discover research achievements with high research value, such as the Sleeping Beauty papers, recently hot papers, classic papers and so on. Finally, an interactive analytical system named PubExplorer was implemented with IEEE VIS publication data, and its effectiveness is verified through case studies. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Yu, Minzhu; Wang, Yang; Yu, Xiaomin; Shan, Guihua; Jin, Zhong] Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
   [Yu, Minzhu; Wang, Yang; Yu, Xiaomin; Shan, Guihua; Jin, Zhong] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Computer Network Information Center, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Shan, GH (corresponding author), Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
EM sgh@cnic.cn
OI Shan, Guihua/0000-0002-8283-2278
FU Strategic Priority Research Program of the Chinese Academy of Sciences
   [XDB38030300]
FX <BOLD>Acknowledgements</BOLD> This work was supported by the Strategic
   Priority Research Program of the Chinese Academy of Sciences, Grant No.
   XDB38030300.
CR Bhattacharya S, 1998, SCIENTOMETRICS, V43, P359, DOI 10.1007/BF02457404
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   BRAAM RR, 1991, J AM SOC INFORM SCI, V42, P233, DOI 10.1002/(SICI)1097-4571(199105)42:4<233::AID-ASI1>3.0.CO;2-I
   Byron L, 2008, IEEE T VIS COMPUT GR, V14, P1245, DOI 10.1109/TVCG.2008.166
   Chen CM, 2006, J AM SOC INF SCI TEC, V57, P359, DOI 10.1002/asi.20317
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239
   Davidson GS, 1998, J INTELL INF SYST, V11, P259, DOI 10.1023/A:1008690008856
   Fried D., 2013, Maps of computer science, P1
   Guo Zhichun, 2022, IEEE Trans. Vis. Comput. Graphics, P1
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Heimerl F, 2016, IEEE CONF VIS ANAL, P11, DOI 10.1109/VAST.2016.7883507
   Ke Q, 2015, P NATL ACAD SCI USA, V112, P7426, DOI 10.1073/pnas.1424329112
   Li ZY, 2020, IEEE T VIS COMPUT GR, V26, P1182, DOI 10.1109/TVCG.2019.2934667
   Lin Y., 2010, SIAM Data Mining Conference, P418, DOI [10.1137/1.9781611972801.37, DOI 10.1137/1.9781611972801.37]
   Liu S., 2009, P 18 ACM C INF KNOWL, P543
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P2482, DOI 10.1109/TVCG.2018.2834341
   Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Morris SA, 2003, J AM SOC INF SCI TEC, V54, P413, DOI 10.1002/asi.10227
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   PERSSON O, 1994, J AM SOC INFORM SCI, V45, P31, DOI 10.1002/(SICI)1097-4571(199401)45:1<31::AID-ASI4>3.0.CO;2-G
   PRICE DJD, 1965, SCIENCE, V149, P510
   Skupin A, 2004, P NATL ACAD SCI USA, V101, P5274, DOI 10.1073/pnas.0307654100
   SMALL H, 1973, J AM SOC INFORM SCI, V24, P265, DOI 10.1002/asi.4630240406
   van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3
   van Raan AFJ, 2004, SCIENTOMETRICS, V59, P467, DOI 10.1023/B:SCIE.0000018543.82441.f1
   van Raan AFJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139786
   Wang Y., 2020, Comput. Syst. Appl., V29, P14, DOI [10.15888/j.cnki.csa.007527, DOI 10.15888/J.CNKI.CSA.007527]
   Wang Y, 2019, J VISUAL-JAPAN, V22, P941, DOI 10.1007/s12650-019-00585-2
NR 30
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2023
VL 7
IS 3
BP 65
EP 74
DI 10.1016/j.visinf.2023.07.001
EA SEP 2023
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA W0OL3
UT WOS:001088710200001
OA gold
DA 2024-07-18
ER

PT J
AU Zhao, WX
   Wang, GJ
   Wang, Z
   Liu, L
   Wei, X
   Wu, YD
AF Zhao, Weixin
   Wang, Guijuan
   Wang, Zhong
   Liu, Liang
   Wei, Xu
   Wu, Yadong
TI A uncertainty visual analytics approach for bus travel time
SO VISUAL INFORMATICS
LA English
DT Article
DE Uncertainty visualization; Bus prediction; Bayesian neural network
ID PREDICTION
AB Bus travel time is uncertain due to the dynamic change in the environment. Passenger analyzing bus travel time uncertainty has significant implications for understanding bus running errors and reducing travel risks. To quantify the uncertainty of the bus travel time prediction model, a visual analysis method about the bus travel time uncertainty is proposed in this paper, which can intuitively obtain uncertain information of bus travel time through visual graphs. Firstly, a Bayesian encoder-decoder deep neural network (BEDDNN) model is proposed to predict the bus travel time. The BEDDNN model outputs results with distributional properties to calculate the prediction model uncertainty degree and provide the estimation of the bus travel time uncertainty. Second, an interactive uncertainty visualization system is developed to analyze the time uncertainty associated with bus stations and lines. The prediction model and the visualization model are organically combined to better demonstrate the prediction results and uncertainties. Finally, the model evaluation results based on actual bus data illustrate the effectiveness of the model. The results of the case study and user evaluation show that the visualization system in this paper has a positive impact on the effectiveness of conveying uncertain information and on user perception and decision making.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang UniversityPress Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Zhao, Weixin; Wang, Guijuan; Wang, Zhong; Liu, Liang; Wei, Xu; Wu, Yadong] Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang, Peoples R China.
   [Wu, Yadong] Sichuan Univ Sci & Engn, Sch Comp Sci & Engn, Zigong, Peoples R China.
C3 Southwest University of Science & Technology - China; Sichuan University
   of Science & Engineering
RP Zhao, WX; Wu, YD (corresponding author), Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang, Peoples R China.
EM weixin.zhao@outlook.com; wyd028@163.com
RI zhang, Weihua/JJD-6447-2023; zhao, weiwei/JUU-6585-2023; Zhang,
   wen/ITT-1192-2023; zhang, wb/JGM-5316-2023
FU National Natural Science Founda-tion of China; Excellent Youth
   Foundation of Si?chuan;  [61872304];  [61802320];  [19JCQN0108]
FX Acknowledgments This work was supported by National Natural Science
   Founda-tion of China (Grant No. 61872304, No. 61802320) and Excellent
   Youth Foundation of Si?chuan (Grant No. 19JCQN0108) .
CR Deitrick S., 2006, Progress in Spatial Data Handling, P719, DOI [DOI 10.1007/3-540-35589-845, 10.1007/3-540-35589-845, DOI 10.1007/3-540-35589-8_45]
   Elliot AJ, 2014, ANNU REV PSYCHOL, V65, P95, DOI 10.1146/annurev-psych-010213-115035
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gal Yarin, 2016, Uncertainty in deep learning
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Gurmu ZK, 2014, J PUBLIC TRANSPORT, V17, P45, DOI 10.5038/2375-0901.17.2.3
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Karduni A, 2021, IEEE T VIS COMPUT GR, V27, P978, DOI 10.1109/TVCG.2020.3029412
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kee CY, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE), P150, DOI 10.1109/ICITE.2017.8056898
   Kiureghian AD, 2009, STRUCT SAF, V31, P105, DOI 10.1016/j.strusafe.2008.06.020
   Li Jie, 2020, IEEE Trans Vis Comput Graph, V26, P1789, DOI 10.1109/TVCG.2018.2882449
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Mazloumi E, 2011, ENG APPL ARTIF INTEL, V24, P534, DOI 10.1016/j.engappai.2010.11.004
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pang A. T., 2001, Proceedings of the workshop on the intersections between geospatial information and information technology, V10, P3823
   Pang JB, 2019, IEEE T INTELL TRANSP, V20, P3283, DOI 10.1109/TITS.2018.2873747
   Petersen NC, 2019, EXPERT SYST APPL, V120, P426, DOI 10.1016/j.eswa.2018.11.028
   Springer, 2012, NOMBR ED
   Treethidtaphat W, 2017, IEEE INT C INTELL TR
   Xie P., 2021, ARXIV
   Zhao WX, 2019, J COMPUT LANG, V53, P1, DOI 10.1016/j.cola.2019.01.001
NR 24
TC 12
Z9 12
U1 4
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 1
EP 11
DI 10.1016/j.visinf.2022.06.002
EA NOV 2022
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100001
OA gold
DA 2024-07-18
ER

PT J
AU Zhang, W
   Ma, Q
   Pan, RS
   Chen, W
AF Zhang, Wei
   Ma, Qian
   Pan, Rusheng
   Chen, Wei
TI Visual storytelling of Song Ci and the poets in the social-cultural
   context of Song dynasty
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual storytelling of Song Ci; Spatio-temporal visualization; Textual
   visual analysis
ID DIGITAL HUMANITIES; VISUALIZATION; HISTORY
AB Song Ci is treasured in traditional Chinese culture, which indicates social and cultural evolution in ancient times. Despite the efforts by historians and litterateurs in investigating the characteristics of Song Ci, it is still unclear how to effectively distribute and promote Song Ci in the public sphere. The complexity and abstraction of Song Ci hamper the general public from closely reading, analyzing, and appreciating these excellent works. By means of a set of visual analysis methods, e.g. the spatiotemporal visualization, we exploit visual storytelling to explicitly present the latent and abstractive features of Song Ci. We apply straightway visual charts and lighten the burden of understanding the stories, in order to achieve an effective public distribution. The effectiveness and aesthetics of our work are demonstrated by a user study of three participants with different backgrounds. The result reveals that our story is effective in the distribution, understanding, and promotion of Song Ci. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Zhang, Wei; Pan, Rusheng; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
   [Ma, Qian] Univ Miami, UM User Experience Lab, Miami, FL 33152 USA.
C3 Zhejiang University; University of Miami
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.; Ma, Q (corresponding author), Univ Miami, UM User Experience Lab, Miami, FL 33152 USA.
EM qxm70@miami.edu; chenvis@zju.edu.cn
FU National Natural Science Foundation of China [61772456, 61972122];
   Fundamental Research Funds for the Central Universities
   [2-2050205-21-688]
FX We would like to thank Yichao Yao, Zihua Liu, Jianxu Chen, Shaojie Ye,
   Pengyang Li, Siwei Tan, Yuxin Ma, Yuhe Peng and Yixin Zhao, the
   developers of this website, for their contribution to this work. This
   work is supported by the National Natural Science Foundation of China
   (61772456, 61972122) and the Fundamental Research Funds for the Central
   Universities (2-2050205-21-688).
CR Andrews K., 2002, Information Visualization, V1, P166, DOI 10.1057/palgrave.ivs.9500023
   Armstrong G, 2020, ITAL STUD, V75, P194, DOI 10.1080/00751634.2020.1744867
   Barber JF, 2016, COGENT ARTS HUMANITE, V3, DOI 10.1080/23311983.2016.1181037
   Benito A., 2017, 2 WORKSH VIS DIG HUM
   Bol PK, 2013, ANN ASSOC AM GEOGR, V103, P1087, DOI 10.1080/00045608.2013.792178
   Bollini L, 2013, LECT NOTES COMPUT SC, V7973, P481, DOI 10.1007/978-3-642-39646-5_35
   Bradley A.J., 2018, VISUALIZATION DIGITA
   Bradley AJ, 2018, IEEE COMPUT GRAPH, V38, P26, DOI 10.1109/MCG.2018.2878900
   Castermans T., 2017, VIS4DH 17 2 WORKSH V
   Chatterjee P, 2019, INT CONF ADV COMMUN, P573, DOI [10.23919/ICACT.2019.8702047, 10.23919/icact.2019.8702047]
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Cho I, 2016, IEEE T VIS COMPUT GR, V22, P210, DOI 10.1109/TVCG.2015.2467971
   Coles K., 2017, 2 WORKSH VIS DIG HUM
   D'Ignazio C., 2016, WORKSH VIS DIG HUM V
   Earley-Spadoni T, 2017, J ARCHAEOL SCI, V84, P95, DOI 10.1016/j.jas.2017.05.003
   El-Assady M., 2016, 1 IEEE VIS WORKSH DI
   Fong G.S, 2014, W WENYING ART SO SO
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Heimerl F, 2014, P ANN HICSS, P1833, DOI 10.1109/HICSS.2014.231
   Hinrichs Uta., 2017, Risk the drift! Stretching disciplinary boundaries through critical collaborations between the humanities and visualization
   Hohman F., 2017, P 2 WORKSH VIS DIG H
   Janicke S, 2016, WORKSHOP VISUALIZATI
   Lamqaddam H., 2018, IEEE T VIS COMPUT GR
   Lavorel M., 2017, INTERMEDIALITES, V36
   Li J., 2018, IEEE T VIS COMPUT GR, V26, P2018
   McNutt A, 2020, 2020 IEEE 5TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2020), P1, DOI 10.1109/VIS4DH51463.2020.00005
   Qian Z.Y., 2014, LIBR INF SERV, P105
   Qiu B., 2008, MICROCOMPUTER INFORM, V24, P100
   Rodrigues A, 2021, REVIST EDUC, V15, P27
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Schetinger V., 2019, WORKSH VIS DIG HUM I
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Sharma N., 2019, 4 WORKSH VIS DIG HUM
   [石民 Shi Min], 2010, [中文信息学报, Journal of Chinese Information Processing], V24, P39
   Tebeau M, 2013, ORAL HIST REV, V40, P25, DOI 10.1093/ohr/oht037
   Valtolina S, 2016, DATA SCI ENG, V1, P114, DOI 10.1007/s41019-016-0007-z
   Viegas FB., 2008, INTERACTIONS, V15, P49, DOI [DOI 10.1145/1374489.1374501, 10.1145/1374489.1374501]
   Windhager F., 2017, P 2 IEEE VIS WORKSHO, V2
   Zhang CH, 2021, IEEE T COMPUT SOC SY, V8, P754, DOI 10.1109/TCSS.2021.3061702
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P4839, DOI 10.1109/TVCG.2021.3107297
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
NR 43
TC 4
Z9 5
U1 6
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 34
EP 40
DI 10.1016/j.visinf.2021.12.002
EA DEC 2021
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500005
OA gold
DA 2024-07-18
ER

PT J
AU Tominski, C
   Andrienko, G
   Andrienko, N
   Bleisch, S
   Fabrikant, SI
   Mayr, E
   Miksch, S
   Pohl, M
   Skupin, A
AF Tominski, Christian
   Andrienko, Gennady
   Andrienko, Natalia
   Bleisch, Susanne
   Fabrikant, Sara Irina
   Mayr, Eva
   Miksch, Silvia
   Pohl, Margit
   Skupin, Andre
TI Toward flexible visual analytics augmented through smooth display
   transitions
SO VISUAL INFORMATICS
LA English
DT Article
DE Visual analytics; Animated transitions; Multi-faceted data
ID ANIMATED TRANSITIONS; DESIGN SPACE; VISUALIZATION; TIME
AB Visualizing big and complex multivariate data is challenging. To address this challenge, we propose flexible visual analytics (FVA) with the aim to mitigate visual complexity and interaction complexity challenges in visual analytics, while maintaining the strengths of multiple perspectives on the studied data. At the heart of our proposed approach are transitions that fluidly transform data between user-relevant views to offer various perspectives and insights into the data. While smooth display transitions have been already proposed, there has not yet been an interdisciplinary discussion to systematically conceptualize and formalize these ideas. As a call to further action, we argue that future research is necessary to develop a conceptual framework for flexible visual analytics. We discuss preliminary ideas for prioritizing multi-aspect visual representations and multi-aspect transitions between them, and consider the display user for whom such depictions are produced and made available for visual analytics. With this contribution we aim to further facilitate visual analytics on complex data sets for varying data exploration tasks and purposes based on different user characteristics and data use contexts. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Tominski, Christian] Univ Rostock, Rostock, Germany.
   [Andrienko, Gennady; Andrienko, Natalia] Fraunhofer IAIS, St Augustin, Germany.
   [Andrienko, Gennady; Andrienko, Natalia] City Univ London, London, England.
   [Bleisch, Susanne] FHNW Univ Appl Sci & Arts Northwestern Switzerlan, Muttenz, Switzerland.
   [Fabrikant, Sara Irina] Univ Zurich, Zurich, Switzerland.
   [Mayr, Eva] Danube Univ Krems, Krems, Austria.
   [Miksch, Silvia; Pohl, Margit] TU Wien, Vienna, Austria.
   [Skupin, Andre] San Diego State Univ, San Diego, CA 92182 USA.
C3 University of Rostock; City University London; FHNW University of
   Applied Sciences & Arts Northwestern Switzerland; University of Zurich;
   Danube University Krems; Technische Universitat Wien; California State
   University System; San Diego State University
RP Tominski, C (corresponding author), Univ Rostock, Rostock, Germany.
EM christian.tominski@uni-rostock.de; gennady.adrienko@iais.fraunhofer.de;
   natalia.andrienko@iais.fraunhofer.de; susanne.bleisch@fhnw.ch;
   sara.fabrikant@geo.uzh.ch; eva.mayr@donau-uni.ac.at;
   miksch@ifs.tuwien.ac.at; margit@igw.tuwien.ac.at; skupin@sdsu.edu
RI Fabrikant, Sara Irina/IUQ-6951-2023; Tominski, Christian/H-6388-2019;
   Andrienko, Gennady L./B-6486-2014; Skupin, André/B-5072-2010; Andrienko,
   Natalia/KHV-4755-2024
OI Fabrikant, Sara Irina/0000-0003-1263-8792; Tominski,
   Christian/0000-0001-7704-355X; Andrienko, Gennady
   L./0000-0002-8574-6295; Andrienko, Natalia/0000-0003-3313-1560; Pohl,
   Margit/0000-0001-7880-8702; Miksch, Silvia/0000-0003-4427-5703; Skupin,
   Andre/0000-0002-8398-8119; Bleisch, Susanne/0000-0002-4563-060X; Mayr,
   Eva/0000-0001-8402-5990
FU Leibniz Association, Germany; European Research Council (ERC), under the
   GeoViSense Project [740426]; European Research Council (ERC) [740426]
   Funding Source: European Research Council (ERC)
FX The authors gratefully acknowledge that this work is a result of the
   Dagstuhl Seminar 19192 on Visual Analytics for Sets over Time and Space
   (Fabrikant et al., 2019). Dagstuhl seminars are funded by the Leibniz
   Association, Germany. Sara Irina Fabrikant gratefully acknowledges
   funding from the European Research Council (ERC), under the GeoViSense
   Project, Grant number 740426.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Amini F, 2015, IEEE T VIS COMPUT GR, V21, P122, DOI 10.1109/TVCG.2014.2329308
   Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043
   [Anonymous], 2014, Overview and State-of-the-Art of Uncertainty Visualization
   Bach B, 2014, IEEE T VIS COMPUT GR, V20, P740, DOI 10.1109/TVCG.2013.254
   Brosz M. A., 2013, P 26 ANN ACM S US IN, P97, DOI [10.1145/2501988.2502046.19, DOI 10.1145/2501988.2502046.19]
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen H., 2004, Information Visualization, V3, P96, DOI 10.1057/palgrave.ivs.9500068
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chevalier N. H., 2016, P INT WORK C ADV VIS, P280
   Collins C, 2007, IEEE T VIS COMPUT GR, V13, P1192, DOI 10.1109/TVCG.2007.70521
   Dessart CE, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P341, DOI 10.1145/2254556.2254623
   Du F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P289
   Dübel S, 2017, INFORMATICS-BASEL, V4, DOI 10.3390/informatics4010006
   Dykes J., 2005, INT CARTOGRAPHIC ASS
   Fabrikant S. I., 2019, DAGSTUHL REP, V9, P31, DOI DOI 10.4230/DAGREP.9.5.31
   Fabrikant SI, 2008, CARTOGR J, V45, P201, DOI 10.1179/000870408X311396
   Fabris S., 2005, Phys. Rev. B, P6
   Fish C, 2011, CARTOGR GEOGR INF SC, V38, P350, DOI 10.1559/15230406384350
   Gapminder Foundation, 2021, GAPM TOOLS
   Goldsberry K., 2009, Cartographica, V44, P201, DOI [DOI 10.3138/CARTO.44.3.201, 10.3138/carto.44.3.201]
   Gruendl H, 2016, COMPUT GRAPH FORUM, V35, P321, DOI 10.1111/cgf.12908
   Hadlak S, 2010, INT J GEOGR INF SCI, V24, P1497, DOI 10.1080/13658816.2010.510840
   Hadlak S., 2015, EUR C VIS EUROVIS 20, P1, DOI DOI 10.2312/EUROVISSTAR.20151109
   Hanrahan P, 2009, EUR IEEE S VIS EUROV
   Harrower M., 2007, Cartographica, Int. J. Geographic Inf. Geovisualization, V42, P349, DOI [10.3138/carto.42.4.349, DOI 10.3138/CARTO.42.4.349]
   Harrower M., GEOGRAPHIC VISUALIZA, P49, DOI [10.1002/9780470987643.ch4, DOI 10.1002/9780470987643.CH4]
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Horak T, 2021, IEEE T VIS COMPUT GR, V27, P1644, DOI 10.1109/TVCG.2020.3030371
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kim Y, 2021, IEEE T VIS COMPUT GR, V27, P485, DOI 10.1109/TVCG.2020.3030360
   Kim Y, 2019, COMPUT GRAPH FORUM, V38, P541, DOI 10.1111/cgf.13709
   Kriglstein S., 2014, Handbook of human centric visualization, P203, DOI DOI 10.1007/978-1-4614-7485-2_8
   Kriglstein S, 2016, LECT NOTES COMPUT SC, V9781, P235, DOI 10.1007/978-3-319-42333-3_19
   Laya A, 2012, 2012 IEEE 23RD INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1, DOI 10.1109/PIMRC.2012.6362682
   Lowe R.K., 2014, Handbook of human centric visualization, P581, DOI DOI 10.1007/978-1-4614-7485-2_23
   Lowe RK, 2016, LEARN INSTR, V45, P72, DOI 10.1016/j.learninstruc.2016.06.005
   Maggi S, 2016, CARTOGRAPHICA, V51, P25, DOI 10.3138/cart.51.1.3176
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Opach T, 2014, CARTOGR J, V51, P330, DOI 10.1179/1743277413Y.0000000049
   Pulo K, 2007, IEEE INT CONF INF VI, P271
   Rensink RonaldA., 2002, Proceedings of the 2nd international symposium on Smart graphics, SMARTGRAPH '02, P63
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Salisu S., 2019, SHAPES TIME VISUALIZ, DOI [10.2312/eurp.20191142, DOI 10.2312/EURP.20191142]
   Schulz HJ, 2015, J VISUAL LANG COMPUT, V31, P9, DOI 10.1016/j.jvlc.2015.09.004
   Shipley T. F., 2013, COGN LINGUIST, P259, DOI [10.1007/978-3-642-34359-9_14, DOI 10.1007/978-3-642-34359-9_14]
   Shu X., 2021, IEEE T VIS COMPUT GR, V27, DOI DOI 10.1109/TVCG.2020.3030396
   Spence R, 1999, INT J HUM-COMPUT ST, V51, P919, DOI 10.1006/ijhc.1999.0265
   Steinberger M, 2011, IEEE T VIS COMPUT GR, V17, P2249, DOI 10.1109/TVCG.2011.183
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Sweller J, 2019, EDUC PSYCHOL REV, V31, P261, DOI 10.1007/s10648-019-09465-5
   Sweller J, 2011, EXPLOR LEARN SCI, P3, DOI 10.1007/978-1-4419-8126-4
   Tamassia R., 2016, Handbook on graph drawing and visualization
   Thompson J, 2020, COMPUT GRAPH FORUM, V39, P207, DOI 10.1111/cgf.13974
   Tominski C., 2012, Vision, Modeling, and Visualization, P199, DOI DOI 10.2312/PE/VMV/VMV12/199-206
   Tominski C., 2020, Interactive Visual Data Analysis, DOI [10.1201/9781315152707, DOI 10.1201/9781315152707]
   Tominski C., 2016, P EUR IEEE VGTC C VI, P137, DOI DOI 10.2312/EUROVISSHORT
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Tominski C, 2009, COMPUT GRAPH-UK, V33, P660, DOI 10.1016/j.cag.2009.06.002
   Wang XY, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399906
   Windhager F, 2020, IEEE COMPUT GRAPH, V40, P58, DOI 10.1109/MCG.2020.2985368
   Windhager F, 2018, OPEN LIBR HUMANIT, V4, DOI 10.16995/olh.276
   Wu CC, 2018, CURR BIOL, V28, P3430, DOI 10.1016/j.cub.2018.08.042
   Yuan XR, 2009, IEEE T VIS COMPUT GR, V15, P1001, DOI 10.1109/TVCG.2009.179
   Zheng YX, 2018, J VISUAL LANG COMPUT, V48, P61, DOI 10.1016/j.jvlc.2018.06.006
NR 69
TC 11
Z9 11
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 28
EP 38
DI 10.1016/j.visinf.2021.06.004
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200003
OA Green Accepted, gold
DA 2024-07-18
ER

PT J
AU Umbleja, K
   Ichino, M
   Yaguchi, H
AF Umbleja, Kadri
   Ichino, Manabu
   Yaguchi, Hiroyuki
TI Improving symbolic data visualization for pattern recognition and
   knowledge discovery
SO VISUAL INFORMATICS
LA English
DT Article
DE Data visualization; Symbolic data; Zoomstar; Shape encoding; Exploratory
   data analysis
ID PRINCIPAL COMPONENT ANALYSIS
AB This paper examines the visualization of symbolic data and considers the challenges rising from its complex structure. Symbolic data is usually aggregated from large data sets and used to hide entry specific details and to transform huge amounts of data (like big data) into analyzable quantities. It is also used to offer an overview in places where general trends are more important than individual details. Symbolic data comes in many forms like intervals, histograms, categories and modal multi-valued objects. Symbolic data can also be considered as a distribution. Currently, the de facto visualization approach for symbolic data is zoomstars which has many limitations. The biggest limitation is that the default distributions (histograms) are not supported in 2D as additional dimension is required. This paper proposes several new improvements for zoomstars which would enable it to visualize histograms in 2D by using a quantile or an equivalent interval approach. In addition, several improvements for categorical and modal variables are proposed for a clearer indication of presented categories. Recommendations for different approaches to zoomstars are offered depending on the data type and the desired goal. Furthermore, an alternative approach that allows visualizing the whole data set in comprehensive table-like graph, called shape encoding, is proposed. These visualizations and their usefulness are verified with three symbolic data sets in exploratory data mining phase to identify trends, similar objects and important features, detecting outliers and discrepancies in the data. (C) 2020 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Umbleja, Kadri; Ichino, Manabu; Yaguchi, Hiroyuki] Tokyo Denki Univ, Sch Sci & Engn, Hatoyama, Saitama 3500394, Japan.
C3 Tokyo Denki University
RP Umbleja, K (corresponding author), Tokyo Denki Univ, Sch Sci & Engn, Hatoyama, Saitama 3500394, Japan.
EM kadriumbleja@gmail.com
OI Umbleja, Kadri/0000-0001-8264-2856
FU JSPS, Japan International Research Fellow Program
FX Kadri Umbleja's research has been supported by JSPS, Japan International
   Research Fellow Program.
CR Amelie M., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P388, DOI 10.1109/ICDMW.2010.192
   [Anonymous], 2006, Symbolic Data Analysis: Conceptual Statistics and Data Mining
   BEDDOW J, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P238, DOI 10.1109/VISUAL.1990.146387
   D'Esposito M. R., 2006, ITAL J APPL STAT, V18, P343
   Diday E., 2003, Intelligent Data Analysis, V7, P583
   Diday E., 2008, Symbolic data analysis and the SODAS software
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Hoffman P.E., 1999, Table Visualizations: A Formal Model and Its Applications
   Ichino Manabu, 2011, Statistical Analysis and Data Mining, V4, P184, DOI 10.1002/sam.10111
   ICHINO M, 1994, IEEE T SYST MAN CYB, V24, P698, DOI 10.1109/21.286391
   Ichino M., 2008, P IASC, P5
   Inselberg A., 1987, COMPUTER GRAPHICS 19, P25
   Kao CH, 2014, COMPUT STAT DATA AN, V79, P14, DOI 10.1016/j.csda.2014.04.012
   Lauro CN, 2000, COMPUTATION STAT, V15, P73, DOI 10.1007/s001800050038
   Le-Rademacher J, 2012, J COMPUT GRAPH STAT, V21, P413, DOI 10.1080/10618600.2012.679895
   Long W, 2009, PAC-BASIN FINANC J, V17, P224, DOI 10.1016/j.pacfin.2008.02.001
   Meng J, 2010, CHIN CONTR CONF, P5555
   Noirhomme-Fraiture M, 2002, ELECT J SYMBOL DATA, P26
   NoirhommeFraiture M, 1997, HUMAN-COMPUTER INTERACTION - INTERACT '97, P100
   U.S. Geological Survey, 2013, TABLES HISTOGRAM DAT
   Valova I., 2008, P PCAPAC08
   Verde R., 2003, ELECT J SYMBOLIC DAT, V1, P1
NR 22
TC 6
Z9 7
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2020
VL 4
IS 1
BP 23
EP 31
DI 10.1016/j.visinf.2019.12.003
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KB
UT WOS:000658191200003
OA gold
DA 2024-07-18
ER

PT J
AU Zhang, C
   Chen, Y
   Yang, J
   Yin, ZC
AF Zhang, Chong
   Chen, Yang
   Yang, Jing
   Yin, Zhengcong
TI An association rule based approach to reducing visual clutter in
   parallel sets
SO VISUAL INFORMATICS
LA English
DT Article
DE Association rule; Parallel sets; Visual clutter; Visual analytics
ID EXPLORATION
AB Although Parallel Sets, a popular categorical data visualization technique, intuitively reveals the frequency based relationships in details, a high-dimensional categorical dataset brings a cluttered visual display that seriously obscures the relationship explorations. Association rule mining is a popular approach to discovering relationships among categorical variables. It could complement Parallel Sets to group ribbons in a meaningful way. However, it is difficult to understand a larger number of rules discovered from a high-dimensional categorical dataset. In this paper, we integrate the two approaches into a visual analytics system for exploring high-dimensional categorical data with dichotomous outcome. The system not only helps users interpret association rules intuitively, but also provides an effective dimension and category reduction approach towards a less clustered and more organized visualization. The effectiveness and efficiency of our approach are illustrated by a set of user studies and experiments with benchmark datasets. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Zhang, Chong; Yang, Jing] UNC Charlotte, Charlotte, NC USA.
   [Chen, Yang] I4 Data, Troy, MI USA.
   [Yin, Zhengcong] Texas A&M Univ, College Stn, TX 77843 USA.
C3 University of North Carolina; University of North Carolina Charlotte;
   Texas A&M University System; Texas A&M University College Station
RP Zhang, C (corresponding author), UNC Charlotte, Charlotte, NC USA.
EM czhang@esri.com
RI Zhang, Chong/AGX-1132-2022; Yin, Zhengcong/GZB-0206-2022
OI Zhang, Chong/0000-0003-0576-6016; 
CR Agresti A., 2007, INTRO CATEGORICAL DA, V423
   Alsakran J, 2014, IEEE PAC VIS SYMP, P81, DOI 10.1109/PacificVis.2014.43
   Alsallakh B, 2012, IEEE T VIS COMPUT GR, V18, P2849, DOI 10.1109/TVCG.2012.254
   Ankerst M, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P52, DOI 10.1109/INFVIS.1998.729559
   Bendix F, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P133, DOI 10.1109/INFVIS.2005.1532139
   Bing Liu, 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P80
   Bojanowski M., 2016, ALLUVIAL R PACKAGE C
   Borgelt Christian, 2003, FIMI03 P IEEE ICDM W
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Dua D., 2017, UCI MACHINE LEARNING
   Fernstad SJ, 2011, IEEE INT CONF INF VI, P80, DOI 10.1109/IV.2011.92
   FRIENDLY M, 1994, J AM STAT ASSOC, V89, P190
   Hahsler M., 2011, 42nd Symposium on the Interface: Statistical, Machine Learning, and Visualization Algorithms, P1
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Johnson R.A., 2002, Applied Multivariate Statistical Analysis, V5th ed.
   JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588
   Jolliffe I.T., 1986, Principal component analysis, V487
   Kolatch Erica, 2001, PROJECT REPORT
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Kruskal JB, 1978, MULTIDIMENSIONAL SCA
   LEVANDOWSKY M, 1971, NATURE, V234, P34, DOI 10.1038/234034a0
   Liu B., 2007, Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data
   Liu B., 2006, P 12 ACM SIGKDD INT, P297
   Liu G., 2012, KDD DEMO, P1536
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Nielsen J., 1990, SIGCHI Bulletin, P249
   Pak Chung Wong, 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P120, DOI 10.1109/INFVIS.1999.801866
   Peng W, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P89
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Sekhavat Y. A., 2013, INT J INTELL SCI, V3, P34
   Yang J, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P105
   Yang L, 2005, IEEE T KNOWL DATA EN, V17, P60, DOI 10.1109/TKDE.2005.14
   Zarate DC, 2018, IEEE PAC VIS SYMP, P135, DOI 10.1109/PacificVis.2018.00025
   Zhang C, 2016, IEEE PAC VIS SYMP, P136, DOI 10.1109/PACIFICVIS.2016.7465261
NR 35
TC 5
Z9 6
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2019
VL 3
IS 1
BP 48
EP 57
DI 10.1016/j.visinf.2019.03.006
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YJ
UT WOS:000658187900006
OA gold
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Wang, ZY
   Zhang, JH
   Shan, GH
   Tian, D
AF Zhang, Yue
   Wang, Zhenyuan
   Zhang, Jinhui
   Shan, Guihua
   Tian, Dong
TI A survey of immersive visualization: Focus on perception and interaction
SO VISUAL INFORMATICS
LA English
DT Review
DE Human-centered computing; Visualization; Visualization theory; Concepts
   and paradigms; Human computer interaction (HCI); Interaction paradigms;
   Virtual reality
ID FLOW; SCATTERPLOT; SYSTEM; HAND
AB Immersive visualization utilizes virtual reality, mixed reality devices, and other interactive devices to create a novel visual environment that integrates multimodal perception and interaction. This technology has been maturing in recent years and has found broad applications in various fields. Based on the latest research advancements in visualization, this paper summarizes the state-of-the-art work in immersive visualization from the perspectives of multimodal perception and interaction in immersive environments, additionally discusses the current hardware foundations of immersive setups. By examining the design patterns and research approaches of previous immersive methods, the paper reveals the design factors for multimodal perception and interaction in current immersive environments. Furthermore, the challenges and development trends of immersive multimodal perception and interaction techniques are discussed, and potential areas of growth in immersive visualization design directions are explored.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Zhang, Yue; Wang, Zhenyuan; Zhang, Jinhui; Shan, Guihua; Tian, Dong] Univ Chinese Acad Sci, Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Computer Network Information Center, CAS;
   University of Chinese Academy of Sciences, CAS
RP Tian, D (corresponding author), Univ Chinese Acad Sci, Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
EM zhangyue@cnic.cn; wangzhenyuan23@mails.ucas.ac.cn;
   zhangjinhui22@mails.ucas.ac.cn; sgh@sccas.cn; tiandong@cnic.cn
RI Wang, Zhenyuan/JRW-8670-2023; Liu, Zhe/KEJ-5299-2024
OI Wang, Zhenyuan/0000-0002-2970-3661; Shan, Guihua/0000-0002-8283-2278
FU Beijing Natural Science Foundation [4212030]
FX <B>Acknowledgments</B> This work was supported in part by Beijing
   Natural Science Foundation (4212030) .
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Alharbi R, 2023, IEEE T VIS COMPUT GR, V29, P1860, DOI 10.1109/TVCG.2021.3133592
   [Anonymous], 1885, Nature, V31, P551
   Aoyama K, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214916
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Bach B, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P529, DOI 10.1145/2992154.2996365
   Bahremand A, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P241, DOI 10.1109/VR51125.2022.00043
   Balogun MB, 2019, AFRICON, DOI [10.1109/africon46755.2019.9133906, 10.1145/3290605.3300331]
   Ban RG, 2022, INT SYM MIX AUGMENT, P748, DOI 10.1109/ISMAR55827.2022.00093
   Batch A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376733
   Benda B, 2020, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR50242.2020.00050
   Bhatia N, 2022, IEEE INT SYMP M AU R, P865, DOI 10.1109/ISMAR-Adjunct57072.2022.00186
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Boyack Kevin W., 2003, DLIB Magazine, V9
   Breitkreutz C, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P719, DOI 10.1109/VR51125.2022.00093
   Brisc F, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P238, DOI 10.1109/VRW52623.2021.00051
   Brunhart-Lupo N, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P19, DOI 10.1109/IMMERSIVE.2016.7932377
   Brunhart-Lupo Nicholas, 2020, PREPRINT
   Büschel W, 2018, LECT NOTES COMPUT SC, V11190, P95, DOI 10.1007/978-3-030-01388-2_4
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Cabrera A, 2016, COMPUT MUSIC J, V40, P47, DOI 10.1162/COMJ_a_00382
   Cashman D, 2021, IEEE T VIS COMPUT GR, V27, P1731, DOI 10.1109/TVCG.2020.3030443
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/vr.2019.8797733, 10.1109/VR.2019.8797733]
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Chang RC, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545613
   Chen C, 2022, INT SYM MIX AUGMENT, P384, DOI 10.1109/ISMAR55827.2022.00054
   Chen Pei, 2023, Designing a smart VR painting system with multisensory interaction for immersive experience, P711
   Chen ZT, 2017, VIS INFORM, V1, P132, DOI 10.1016/j.visinf.2017.11.002
   CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Costa J, 2021, IEEE T VIS COMPUT GR, V27, P785, DOI 10.1109/TVCG.2020.3030333
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Cui Dixuan, 2022, 2022 IEEE INT S MIXE, P1
   Daeijavad P, 2022, IEEE INT SYMP M AU R, P258, DOI 10.1109/ISMAR-Adjunct57072.2022.00057
   Dai Shaozhang, 2023, IEEE Trans Vis Comput Graph, V29, P451, DOI 10.1109/TVCG.2022.3209433
   Degraen Donald, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P936, DOI 10.1145/3472749.3474797
   Dieter Szafir, 2021, CHI '21
   Dobbelstein D, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P130, DOI 10.1145/3123021.3123035
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   ElSayed NAM, 2016, J VISUAL LANG COMPUT, V36, P13, DOI 10.1016/j.jvlc.2016.07.006
   ElSayed NAM, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Febretti A, 2013, PROC SPIE, V8649, DOI 10.1117/12.2005484
   Fishkeller M., 1974, An interactive multidimensional data display and analysis system
   Fouche G, 2022, 28TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2022, DOI 10.1145/3562939.3565612
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Fussell SR, 2004, HUM-COMPUT INTERACT, V19, P273, DOI 10.1207/s15327051hci1903_3
   Gloumeau PC, 2021, IEEE T VIS COMPUT GR, V27, P2488, DOI 10.1109/TVCG.2020.2987834
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Harrington MCR, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040018
   Hashimoto K, 2016, P IEEE VIRT REAL ANN, P179, DOI 10.1109/VR.2016.7504712
   Hayatpur D., 2020, P 33 ANN ACM S US IN, P818
   Heilig M.L., 1962, SENSORAMA SIMULATOR
   Hertel J, 2021, INT SYM MIX AUGMENT, P431, DOI 10.1109/ISMAR52148.2021.00060
   Horst Robin, 2022, 2022 IEEE GAMES ENTE, P1
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Inselberg A., 1987, P COMPUTER GRAPHICS, P25
   Ishii Hiroshi, 1998, C HUMAN FACTORS COMP, P173
   Ishrat M, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATICS, HEALTH & TECHNOLOGY (ICIHT)
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   Jing A, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P250, DOI 10.1109/VR51125.2022.00044
   Johnson Seth, 2016, Immersive analytics for medicine: Hybrid 2D/3D sketch- based interfaces for annotating medical data and designing medical devices, P107
   Joyner SC, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517630
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Kelleher C, 2021, ENVIRON MODELL SOFTW, V143, DOI 10.1016/j.envsoft.2021.105113
   Khadka R, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P225, DOI 10.1109/VRW58643.2023.00055
   Kim D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P653, DOI 10.1109/VR50410.2021.00091
   King T, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P709, DOI 10.1109/VRW58643.2023.00197
   Klapperstück M, 2016, 2016 INTERNATIONAL SYMPOSIUM ON BIG DATA VISUAL ANALYTICS (BDVA), P7, DOI 10.1109/WiMOB.2016.7763189
   Koren Y, 2004, IEEE T VIS COMPUT GR, V10, P459, DOI 10.1109/TVCG.2004.17
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376675
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kwok TCK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300721
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P802, DOI 10.1109/VR51125.2022.00102
   Li F, 2021, INT C COMP SUPP COOP, P861, DOI 10.1109/CSCWD49262.2021.9437692
   Li GS, 2008, IEEE T VIS COMPUT GR, V14, P1067, DOI 10.1109/TVCG.2008.58
   Li N., P 2021 CHI C HUMAN F, P1
   Li NL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376698
   Li ZP, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545646
   Liao J, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545702
   Lin TC, 2023, IEEE COMPUT GRAPH, V43, P84, DOI 10.1109/MCG.2022.3222042
   Lin TC, 2023, IEEE T VIS COMPUT GR, V29, P1831, DOI 10.1109/TVCG.2021.3133511
   Lin WY, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P232, DOI 10.1109/VR51125.2022.00042
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Louis Thibault, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1248, DOI 10.1145/3379337.3415893
   Lu XS, 2020, INT SYM MIX AUGMENT, P344, DOI 10.1109/ISMAR50242.2020.00061
   Magallanes J, 2022, IEEE T VIS COMPUT GR, V28, P901, DOI 10.1109/TVCG.2021.3114868
   Mahfoud Eli., 2016, Proceedings_of_the_2016_ACM_Companion_on_Interactive_Surfaces_and_Spaces, ISS'16 Companion, P77
   Maio SW, 2019, ENERG CONVERS MANAGE, V183, P590, DOI 10.1016/j.enconman.2019.01.001
   Masopust LM, 2021, INT SYM MIX AUGMENT, P460, DOI 10.1109/ISMAR52148.2021.00063
   Minsky M. R., 1984, Computers & Graphics, V18, P195
   Mirzaei M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P582, DOI 10.1109/VR50410.2021.00083
   Miyashita H., 2020, Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1085, DOI DOI 10.1145/3379337.3415852
   Miyashita H, 2021, ADJUNCT PROCEEDINGS OF THE 34TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2021, P37, DOI 10.1145/3474349.3480223
   Mojica CMM, 2019, IEEE INT C BIOINF BI, P1002, DOI 10.1109/BIBE.2019.00186
   Montano-Murillo RA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P53, DOI [10.1109/VR46266.2020.1581198507712, 10.1109/VR46266.2020.00-81]
   Morse PE, 2022, IEEE T VIS COMPUT GR, V28, P2641, DOI 10.1109/TVCG.2020.3037226
   Onishi Y, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545615
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Patel D., 2021, Interactive Data Processing and 3D Visualization of the Solid Earth, P1
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Pfeuffer Ken, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P149, DOI 10.1145/3472749.3474741
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Pointecker F, 2022, INT SYM MIX AUGMENT, P827, DOI 10.1109/ISMAR55827.2022.00101
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Qiu DY, 2022, IEEE INT SYMP M AU R, P907, DOI 10.1109/ISMAR-Adjunct57072.2022.00199
   Qu Huamin, 2022, IEEE Trans. Vis. Comput. Graphics, P1
   Ragozin K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1831, DOI 10.1109/VR.2019.8798125
   Rahman Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P868, DOI [10.1109/VR46266.2020.1581300202881, 10.1109/VR46266.2020.00014]
   Reipschläger P, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517676
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Richardson Mark., 2020, P 33 ANN ACM S US IN, P686
   Schjerlund J, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501873
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Seraji MR, 2022, IEEE INT SYMP M AU R, P155, DOI 10.1109/ISMAR-Adjunct57072.2022.00036
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Shen VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501960
   Sidenmark L, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376438
   Siu A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517678
   Siu AF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376353
   Spiegelhalter D, 2011, SCIENCE, V333, P1393, DOI 10.1126/science.1191181
   Ssin SY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P210, DOI [10.1109/VR.2019.8797812, 10.1109/vr.2019.8797812]
   Strohmeier Paul, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P579, DOI 10.1145/3379337.3415828
   Su SM, 2022, IEEE INT SYMP M AU R, P139, DOI 10.1109/ISMAR-Adjunct57072.2022.00034
   Sun TC, 2019, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis.2019.00010
   Sun ZD, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3511892
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Sutherland I. E., 1964, P SHAR DES AUT WORKS, DOI [DOI 10.1177/003754976400200514, 10.1177/003754976400200514]
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Suzuki Ryo, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1269, DOI 10.1145/3472749.3474821
   Szafir D, 2019, LECT NOTES COMPUT SC, V11575, P124, DOI 10.1007/978-3-030-21565-1_9
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Tadeja SK, 2020, AERONAUT J, V124, P1615, DOI 10.1017/aer.2020.49
   Tang Bixia, 2021, AR. Innov., V2
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   Unemi Tatsuo, 2018, 2D generative faces for evolutionary social simulation
   Usher W, 2018, IEEE T VIS COMPUT GR, V24, P994, DOI 10.1109/TVCG.2017.2744079
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Wang XM, 2019, IEEE T VIS COMPUT GR, V25, P193, DOI 10.1109/TVCG.2018.2865021
   Wang YQ, 2022, IEEE T VIS COMPUT GR, V28, P623, DOI 10.1109/TVCG.2021.3114765
   Wang Z, 2017, IEEE T VIS COMPUT GR, V23, P681, DOI 10.1109/TVCG.2016.2598694
   Wang ZM, 2022, IEEE T VIS COMPUT GR, V28, P3843, DOI 10.1109/TVCG.2022.3203110
   Ware C, 2008, MORG KAUF SER INTER, P1
   Wen Zhen, 2023, IEEE Trans Vis Comput Graph, V29, P440, DOI 10.1109/TVCG.2022.3209475
   Whitlock M, 2020, IEEE T VIS COMPUT GR, V26, P503, DOI 10.1109/TVCG.2019.2934282
   Xia HJ, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3503537
   Xu WG, 2022, INT SYM MIX AUGMENT, P131, DOI 10.1109/ISMAR55827.2022.00027
   Yan Yixian, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P223, DOI 10.1145/3379337.3415859
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517673
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yu DF, 2022, INT SYM MIX AUGMENT, P637, DOI 10.1109/ISMAR55827.2022.00081
   Zhang YD, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P599, DOI [10.1109/AEECA55500.2022.9918832, 10.1109/VR51125.2022.00080]
   Zhang ZY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P3, DOI 10.1145/2733373.2817845
   Zhao Y, 2023, Vis Inform
   Zhao Ying, 2023, IEEE Trans Vis Comput Graph, V29, P214, DOI 10.1109/TVCG.2022.3209469
   Zheng MY, 2022, INT SYM MIX AUGMENT, P508, DOI 10.1109/ISMAR55827.2022.00067
   Zheng YZ, 2015, J VISUAL-JAPAN, V18, P111, DOI 10.1007/s12650-014-0230-5
   Zhou Q, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501884
   Zhou QS, 2020, IEEE T VIS COMPUT GR, V26, P3423, DOI [10.1109/TVCG.2020.3023570, 10.1109/TVCG.2020.3023.570]
   Zhu HZ, 2023, IEEE T MOBILE COMPUT, V22, P515, DOI 10.1109/TMC.2021.3069981
   Zhu Wenjie, 2019, P 2019 CHI C HUMAN F, P1
   Zhu YF, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-020-00068-4
NR 177
TC 4
Z9 4
U1 12
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2023
VL 7
IS 4
BP 22
EP 35
DI 10.1016/j.visinf.2023.10.003
EA NOV 2023
PG 14
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CW4G2
UT WOS:001128252300001
OA gold
DA 2024-07-18
ER

PT J
AU Chotisarn, N
   Gulyanon, S
   Zhang, TY
   Chen, W
AF Chotisarn, Noptanit
   Gulyanon, Sarun
   Zhang, Tianye
   Chen, Wei
TI VISHIEN-MAAT: Scrollytelling visualization design for explaining Siamese
   Neural Network concept to non-technical users
SO VISUAL INFORMATICS
LA English
DT Article
DE Story synthesis; Scrollytelling; Visual storytelling; Visualizing deep
   learning; Learning science
AB The past decade has witnessed rapid progress in AI research since the breakthrough in deep learning. AI technology has been applied in almost every field; therefore, technical and non-technical endusers must understand these technologies to exploit them. However existing materials are designed for experts, but non-technical users need appealing materials that deliver complex ideas in easy-tofollow steps. One notable tool that fits such a profile is scrollytelling, an approach to storytelling that provides readers with a natural and rich experience at the reader's pace, along with in-depth interactive explanations of complex concepts. Hence, this work proposes a novel visualization design for creating a scrollytelling that can effectively explain an AI concept to non-technical users. As a demonstration of our design, we created a scrollytelling to explain the Siamese Neural Network for the visual similarity matching problem. Our approach helps create a visualization valuable for a shorttimeline situation like a sales pitch. The results show that the visualization based on our novel design helps improve non-technical users' perception and machine learning concept knowledge acquisition compared to traditional materials like online articles.(c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Chotisarn, Noptanit; Zhang, Tianye; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Minist Educ, Lab Art & Archaeol Image, Hangzhou, Peoples R China.
   [Gulyanon, Sarun] Thammasat Univ, Coll Interdisciplinary Studies, Bangkok, Thailand.
C3 Zhejiang University; Zhejiang University; Thammasat University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM chotisarn@zju.edu.cn; sarung@tu.ac.th; zhangtianye1026@zju.edu.cn;
   chenvis@zju.edu.cn
RI Chen, Wei/AAR-9817-2020
OI Gulyanon, Sarun/0000-0003-0858-7881
FU National Natural Sci-ence Foundation of China [62132017]
FX Acknowledgments This paper is partially supported by the National
   Natural Sci-ence Foundation of China (No. 62132017) . The first author
   wishes to thank Mr. Wissarut Pimanmassuriya, Ms. Panita Rerkpitivit, Ms.
   Chalida Liamwiset and Mr. Kittikun Kamrai for their valuable technical,
   data support on this project.
CR Amabili L., 2019, MEDIUM
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Caputo T.C., 2003, VISUAL STORYTELLING
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chotisarn N., 2020, J VISUAL-JAPAN, P1
   Chotisarn N, 2021, IEEE ACCESS, V9, P108049, DOI 10.1109/ACCESS.2021.3102174
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Ghojogh B, 2020, Arxiv, DOI arXiv:2004.04674
   Godulla A., 2017, Digitale Langformen im Journalismus und Corporate Publishing
   Kirschner KN, 2020, IEEE GLOB ENG EDUC C, P808, DOI [10.1109/educon45650.2020.9125242, 10.1109/EDUCON45650.2020.9125242]
   Lipton ZC., 2018, QUEUE, V16, P31, DOI 10.1145/3236386.3241340
   Lu JH, 2021, IEEE PAC VIS SYMP, P21, DOI 10.1109/PacificVis52677.2021.00011
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83
   Nittono H, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046362
   Riche NH, 2018, Data-Driven Storytelling
   Rippel O, 2016, Arxiv, DOI arXiv:1511.05939
   Safitri D., 2021, INT J INTERACT MOB T, V15
   Schneiders P, 2020, MEDIA COMMUN-LISBON, V8, P218, DOI 10.17645/mac.v8i1.2507
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Seyser D, 2018, IEEE INT CON INF VIS, P401, DOI 10.1109/iV.2018.00075
   Stolper C. D., 2016, Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Veit A, 2015, IEEE I CONF COMP VIS, P4642, DOI 10.1109/ICCV.2015.527
   Vishvakarma A, 2019, Arxiv, DOI arXiv:1903.00905
   Wattenberg M., 2016, Distill, V1, DOI DOI 10.23915/DISTILL.00002
NR 29
TC 3
Z9 3
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2023
VL 7
IS 1
BP 18
EP 29
DI 10.1016/j.visinf.2023.01.004
EA MAR 2023
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA C9HZ7
UT WOS:000964958700001
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Wang, YC
   Zhu, ZH
   Wang, L
   Sun, GD
   Liang, RH
AF Wang, Yunchao
   Zhu, Zihao
   Wang, Lei
   Sun, Guodao
   Liang, Ronghua
TI Visualization and visual analysis of multimedia data in manufacturing: A
   survey
SO VISUAL INFORMATICS
LA English
DT Article
DE Visualization; Visual analysis; Manufacturing; Multi-media data;
   Industry 4; 0; Digital twin
ID DESIGN; EVOLUTION; ANALYTICS; PATTERNS; TIME
AB With the development of production technology and social needs, sectors of manufacturing are constantly improving. The use of sensors and computers has made it increasingly convenient to collect multimedia data in manufacturing. Targeted, rapid, and detailed analysis based on the type of multimedia data can make timely decisions at different stages of the entire manufacturing process. Visualization and visual analytics are frequently adopted in multimedia data analysis of manufacturing because of their powerful ability to understand, present, and analyze data intuitively and interactively. In this paper, we present a literature review of visualization and visual analytics specifically for manufacturing multimedia data. We classify existing research according to visualization techniques, interaction analysis methods, and application areas. We discuss the differences when visualization and visual analytics are applied to different types of multimedia data in the context of particular examples of manufacturing research projects. Finally, we summarize the existing challenges and prospective research directions.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Wang, Yunchao; Zhu, Zihao; Wang, Lei; Sun, Guodao; Liang, Ronghua] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Technology
RP Sun, GD (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
EM guodao@zjut.edu.cn
RI liang, ronghua/H-4463-2012
OI Zhu, Zihao/0000-0001-9310-6493
FU National Key Research and Development Program of China; Na-tional
   Natural Science Foundation of China;  [2020YFB1707700];  [61972356]; 
   [62036009]
FX Acknowledgments This work is partly supported by the National Key
   Research and Development Program of China (2020YFB1707700) , and
   Na-tional Natural Science Foundation of China (61972356, 62036009) .
CR Amirkhanov A, 2016, COMPUT GRAPH FORUM, V35, P201, DOI 10.1111/cgf.12896
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Basole RC, 2014, DECIS SUPPORT SYST, V67, P109, DOI 10.1016/j.dss.2014.08.008
   Becher M, 2022, IEEE COMPUT GRAPH, V42, P33, DOI 10.1109/MCG.2022.3157961
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Blumenschein M, 2018, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST.2018.8802486
   Bruno F, 2006, J VISUAL-JAPAN, V9, P319, DOI 10.1007/BF03181679
   Büttner S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376720
   Burch M, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00088-8
   Cardoso J., 2010, 2010 IEEE 7th International Conference on Services Computing (SCC 2010), P602, DOI 10.1109/SCC.2010.93
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   Chhikara P, 2022, SOFTWARE PRACT EXPER, V52, P658, DOI 10.1002/spe.2876
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   Coffey D, 2013, IEEE T VIS COMPUT GR, V19, P2783, DOI 10.1109/TVCG.2013.147
   Cui YS, 2020, ROBOT CIM-INT MANUF, V62, DOI 10.1016/j.rcim.2019.101861
   Datta S, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3047009
   Cardoso LFD, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.106159
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Duggal AS, 2022, IET COMMUN, V16, P521, DOI 10.1049/cmu2.12284
   Dutta S, 2017, IEEE T VIS COMPUT GR, V23, P811, DOI 10.1109/TVCG.2016.2598604
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   Fan YP, 2021, J MANUF SYST, V60, P176, DOI 10.1016/j.jmsy.2021.05.010
   Friedl J, 2021, PROCEDIA COMPUT SCI, V180, P628, DOI 10.1016/j.procs.2021.01.285
   Fulda J, 2016, IEEE T VIS COMPUT GR, V22, P300, DOI 10.1109/TVCG.2015.2467531
   Giske LAL, 2019, PROC CIRP, V81, P512, DOI 10.1016/j.procir.2019.03.139
   Gkorou D, 2017, ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2017, P338, DOI 10.1145/3075564.3078883
   Gove R, 2021, IEEE SYM VIS CYB SEC, P1, DOI 10.1109/VizSec53666.2021.00005
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guo SN, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445117
   Hamid NSS, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P1034, DOI 10.1109/SAI.2014.6918317
   Herr D, 2018, IEEE INT CON INF VIS, P251, DOI 10.1109/iV.2018.00051
   Huettenberger L, 2015, IEEE PAC VIS SYMP, P135, DOI 10.1109/PACIFICVIS.2015.7156369
   Jiang J, 2020, IEEE ACCESS, V8, P121074, DOI 10.1109/ACCESS.2020.3006582
   Jo J, 2014, IEEE T VIS COMPUT GR, V20, P2329, DOI 10.1109/TVCG.2014.2346454
   Kagaya M, 2017, IEEE T SEMICONDUCT M, V30, P333, DOI 10.1109/TSM.2017.2750719
   Kang HS, 2016, INT J PR ENG MAN-GT, V3, P111, DOI 10.1007/s40684-016-0015-5
   Klacansky P, 2022, IEEE PAC VIS SYMP, P81, DOI 10.1109/PacificVis53943.2022.00017
   Klammer C, 2020, EUROMICRO CONF PROC, P1, DOI 10.1109/SEAA51224.2020.00012
   Lei ZC, 2022, IEEE T IND INFORM, V18, P1716, DOI 10.1109/TII.2021.3086149
   Li Q, 2020, COMPUT GRAPH FORUM, V39, P483, DOI 10.1111/cgf.13996
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Marconi M, 2021, INT J INTERACT DES M, V15, P211, DOI 10.1007/s12008-021-00753-5
   McNutt A, 2021, COMPUT GRAPH FORUM, V40, P61, DOI 10.1111/cgf.14289
   Mei HH, 2020, IEEE T VIS COMPUT GR, V26, P1161, DOI 10.1109/TVCG.2019.2934800
   Meyer M, 2016, IEEE PAC VIS SYMP, P160, DOI 10.1109/PACIFICVIS.2016.7465264
   Mohammad-Amini Maryam, 2021, 2021 IEEE 8th International Conference on Industrial Engineering and Applications (ICIEA), P126, DOI 10.1109/ICIEA52957.2021.9436703
   Moreland J, 2019, STEEL RES INT, V90, DOI 10.1002/srin.201800513
   Narechania A., 2020, IEEE T VIS COMPUT GR, V27, P1688
   Oppermann M, 2021, IEEE T VIS COMPUT GR, V27, P495, DOI 10.1109/TVCG.2020.3030387
   Pantförder D, 2009, IEEE SYS MAN CYBERN, P824, DOI 10.1109/ICSMC.2009.5346921
   Park H, 2016, DECIS SUPPORT SYST, V91, P89, DOI 10.1016/j.dss.2016.08.003
   Park KT, 2020, INT J PR ENG MAN-GT, V7, P791, DOI 10.1007/s40684-020-00227-1
   Pretorius J, 2011, IEEE T VIS COMPUT GR, V17, P2402, DOI 10.1109/TVCG.2011.253
   Qian AJ, 2022, J VISUAL-JAPAN, V25, P191, DOI 10.1007/s12650-021-00788-6
   Qu YJ, 2019, INT J ADV MANUF TECH, V103, P3751, DOI 10.1007/s00170-019-03754-7
   Rosales J, 2021, PROCEDIA MANUF, V53, P618, DOI 10.1016/j.promfg.2021.06.062
   Runji JM, 2020, ROBOT CIM-INT MANUF, V64, DOI 10.1016/j.rcim.2020.101957
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Schlereth T., 2007, IEEE COMPUT GRAPH, V27, P80
   Sharif A, 2014, P ANN HICSS, P3478, DOI 10.1109/HICSS.2014.433
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   Suschnigg J., 2020, EDBT/ICDT Workshops p, P1
   Suzuki T, 2020, ADDIT MANUF, V31, DOI 10.1016/j.addma.2019.100942
   Tang JX, 2022, IEEE T VIS COMPUT GR, V28, P857, DOI 10.1109/TVCG.2021.3114878
   Tao WB, 2020, MICRON, V131, DOI 10.1016/j.micron.2020.102826
   Vivanco DF, 2019, J IND ECOL, V23, P520, DOI 10.1111/jiec.12779
   Wang L, 2022, VIS INFORM, V6, P47, DOI 10.1016/j.visinf.2022.02.003
   Wang XM, 2018, IEEE T VIS COMPUT GR, V24, P351, DOI 10.1109/TVCG.2017.2745139
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wu WC, 2018, IEEE PAC VIS SYMP, P140, DOI 10.1109/PacificVis.2018.00026
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Yao XF, 2019, J INTELL MANUF, V30, P2805, DOI 10.1007/s10845-017-1384-5
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yin S, 2014, IEEE T IND ELECTRON, V61, P6418, DOI 10.1109/TIE.2014.2301773
   Yoo S, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115430
   Yu BW, 2017, IEEE T VIS COMPUT GR, V23, P251, DOI 10.1109/TVCG.2016.2598497
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zappulla MLS, 2019, STEEL RES INT, V90, DOI 10.1002/srin.201800540
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P4839, DOI 10.1109/TVCG.2021.3107297
   Zhao Y, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3345640
   Zhou FF, 2019, J VISUAL-JAPAN, V22, P419, DOI 10.1007/s12650-018-0530-2
   Zhou FF, 2018, J VISUAL LANG COMPUT, V44, P58, DOI 10.1016/j.jvlc.2017.11.004
   Zhu ZX, 2019, PROC CIRP, V81, P898, DOI 10.1016/j.procir.2019.03.223
NR 84
TC 5
Z9 5
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2022
VL 6
IS 4
BP 12
EP 21
DI 10.1016/j.visinf.2022.09.001
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6P1CV
UT WOS:000890673100002
OA gold
DA 2024-07-18
ER

PT J
AU Li, CL
   Cao, MQ
   Wen, XL
   Zhu, HT
   Liu, SS
   Zhang, XY
   Zhu, M
AF Li, Changlin
   Cao, Mengqi
   Wen, Xiaolin
   Zhu, Haotian
   Liu, Shangsong
   Zhang, Xinyi
   Zhu, Min
TI MDIVis: Visual analytics of multiple destination images on tourism user
   generated content
SO VISUAL INFORMATICS
LA English
DT Article
DE Tourism destination images; Visual analysis; Sentiment visualization;
   User-generated content
ID INFORMATION; MODEL
AB Abundant tourism user-generated content (UGC) contains a wealth of cognitive and emotional information, providing valuable data for building destination images that depict tourists' experiences and appraisal of the destinations during the tours. In particular, multiple destination images can assist tourism managers in exploring the commonalities and differences to investigate the elements of interest of tourists and improve the competitiveness of the destinations. However, existing methods usually focus on the image of a single destination, and they are not adequate to analyze and visualize UGC to extract valuable information and knowledge. Therefore, we discuss requirements with tourism experts and present MDIVis, a multi-level interactive visual analytics system that allows analysts to comprehend and analyze the cognitive themes and emotional experiences of multiple destination images for comparison. Specifically, we design a novel sentiment matrix view to summarize multiple destination images and improve two classic views to analyze the time-series pattern and compare the detailed information of images. Finally, we demonstrate the utility of MDIVis through three case studies with domain experts on real-world data, and the usability and effectiveness are confirmed through expert interviews.
   (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by- nc- nd/4.0/).
C1 [Li, Changlin; Cao, Mengqi; Wen, Xiaolin; Liu, Shangsong; Zhang, Xinyi; Zhu, Min] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Zhu, Haotian] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou 215000, Peoples R China.
C3 Sichuan University; Xi'an Jiaotong-Liverpool University
RP Zhu, M (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
EM lichanglin@stu.scu.edu.cn; zhumin@scu.edu.cn
RI 0, 0/KEE-7704-2024; Li, Changlin/GRX-7207-2022
OI Li, Changlin/0000-0002-8486-7482
FU Chengdu Science and Technology Bureau, China [2019-YF05-02121-SN]
FX This work was supported by the Chengdu Science and Technology Bureau,
   China (Grant No. 2019-YF05-02121-SN).
CR Agus S., 2020, INT J RELIG TOUR PIL, V8
   Baloglu S, 1999, ANN TOURISM RES, V26, P868, DOI 10.1016/S0160-7383(99)00030-4
   Barroso Caroline M., 2020, Human-Computer Interaction. Design and User Experience. Thematic Area, HCI 2020 Held as Part of the 22nd International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12181), P538, DOI 10.1007/978-3-030-49059-1_40
   Beerli A, 2004, ANN TOURISM RES, V31, P657, DOI 10.1016/j.annals.2004.01.010
   Cao MQ, 2020, FRONT INFORM TECH EL, V21, P536, DOI 10.1631/FITEE.1900631
   Chen Y, 2018, IEEE PAC VIS SYMP, P190, DOI 10.1109/PacificVis.2018.00032
   Chiu WS, 2016, INT J CULT TOUR HOSP, V10, P223, DOI 10.1108/IJCTHR-07-2015-0080
   Erkan I., 2015, Information and Communication Technologies in Tourism, P19, DOI [10.1007/978-3-319-14343-9_2, DOI 10.1007/978-3-319-14343-9_2]
   Garay L, 2019, TOUR MANAG PERSPECT, V32, DOI 10.1016/j.tmp.2019.100560
   Gkritzali A, 2018, J TRAVEL RES, V57, P540, DOI 10.1177/0047287517705225
   Han P., 2021, INT C ARTIFICIAL INT, P476
   Hu MD, 2017, IEEE T VIS COMPUT GR, V23, P621, DOI 10.1109/TVCG.2016.2598590
   Huang WD, 2021, COMPUT J, V64, P296, DOI 10.1093/comjnl/bxaa064
   Jeng CR, 2019, TOUR HOSP RES, V19, P112, DOI 10.1177/1467358417704884
   Kim K, 2017, TECHNOL FORECAST SOC, V123, P362, DOI 10.1016/j.techfore.2017.01.001
   Knittel J., 2021, IEEE T VIS COMPUT GR
   Kucher K, 2020, J VISUAL-JAPAN, V23, P1015, DOI 10.1007/s12650-020-00684-5
   Lekovic K, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12229413
   Li QS, 2016, J VISUAL-JAPAN, V19, P489, DOI 10.1007/s12650-015-0330-x
   Qi SS, 2019, J CHINA TOUR RES, V15, P503, DOI 10.1080/19388160.2019.1577199
   Sheng FQ, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02344-w
   Triantafillidou A., 2019, Economic and financial challenges for Eastern Europe, P345, DOI [https://doi.org/10.1007/978-3-030-12169-3_22, DOI 10.1007/978-3-030-12169-3_22]
   Troudi A, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2112, DOI 10.1145/3297280.3297488
   Wang J, 2021, TOUR REV, V76, P125, DOI 10.1108/TR-04-2019-0132
   Woosnam KM, 2020, J SUSTAIN TOUR, V28, P917, DOI 10.1080/09669582.2019.1708920
   Xiao X, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9120730
   Xu HL, 2015, J INF SCI, V41, P830, DOI 10.1177/0165551515603323
   Yuan H, 2016, INT J INFORM MANAGE, V36, P1306, DOI 10.1016/j.ijinfomgt.2016.02.009
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang K., 2019, J MODEL MANAG
   Zhang K, 2019, TOURISM MANAGE, V75, P595, DOI 10.1016/j.tourman.2019.07.002
NR 31
TC 6
Z9 7
U1 5
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2022
VL 6
IS 3
BP 1
EP 10
DI 10.1016/j.visinf.2022.06.001
EA SEP 2022
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6M5IA
UT WOS:000888899400001
OA gold
DA 2024-07-18
ER

PT J
AU Chen, L
   Peng, SD
   Zhou, XW
AF Chen, Lu
   Peng, Sida
   Zhou, Xiaowei
TI Towards efficient and photorealistic 3D human reconstruction: A brief
   survey
SO VISUAL INFORMATICS
LA English
DT Review
DE 3D human reconstruction; Neural representation; Differentiable rendering
AB Reconstructing 3D digital models of humans from sensory data is a long-standing problem in computer vision and graphics with a variety of applications in VR/AR, film production, and human-computer interaction, etc. While a huge amount of effort has been devoted to developing various capture hardware and reconstruction algorithms, traditional reconstruction pipelines may still suffer from high-cost capture systems and tedious capture processes, which prevent them from being easily accessible. Moreover, the dedicatedly hand-crafted pipelines are prone to reconstruction artifacts, resulting in limited visual quality. To solve these challenges, the recent trend in this area is to use deep neural networks to improve reconstruction efficiency and robustness by learning human priors from existing data. Neural network-based implicit functions have been also shown to be a favorable 3D representation compared to traditional forms like meshes and voxels. Furthermore, neural rendering has emerged as a powerful tool to achieve highly photorealistic modeling and re-rendering of humans by end-to-end optimizing the visual quality of output images. In this article, we will briefly review these advances in this fast-developing field, discuss the advantages and limitations of different approaches, and finally, share some thoughts on future research directions. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Chen, Lu] Shandong Univ, Taishan Coll, Qingdao, Peoples R China.
   [Peng, Sida; Zhou, Xiaowei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Chen, Lu] Zhejiang Univ, Hangzhou, Peoples R China.
C3 Shandong University; Taishan University; Zhejiang University; Zhejiang
   University
RP Zhou, XW (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
EM xwzhou@zju.edu.cn
OI Peng, Sida/0000-0001-6546-4525; Chen, Lu/0000-0002-2628-3876
FU NSFC [62172364]
FX The authors would like to acknowledge the support from NSFC (No.
   62172364).
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2018, INT CONF 3D VISION, P98, DOI 10.1109/3DV.2018.00022
   Berretti S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3182179
   Bhatnagar Bharat Lal, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P311, DOI 10.1007/978-3-030-58536-5_19
   Bi S., 2020, European Conference on Computer Vision (ECCV), P294
   Bi S., ARXIV PREPRINT ARXIV
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Boss M., 2020, ARXIV PREPRINT ARXIV
   Bozic A, 2021, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR46437.2021.00150
   Chen X., ARXIV PREPRINT ARXIV
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Deng B., 2020, P EUR C COMP VIS, P612
   Desmarais Y, 2021, COMPUT VIS IMAGE UND, V212, DOI 10.1016/j.cviu.2021.103275
   Dong JT, 2019, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2019.00798
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Garbin Stephan J, 2021, ICCV
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Gilbert A, 2018, LECT NOTES COMPUT SC, V11215, P591, DOI 10.1007/978-3-030-01252-6_35
   Graham B., 2017, Submanifold sparse convolutional networks
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Habermann M., ARXIV PREPRINT ARXIV
   Habermann M, 2020, PROC CVPR IEEE, P5051, DOI 10.1109/CVPR42600.2020.00510
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   He T., 2020, ARXIV PREPRINT ARXIV
   Hong Y, 2021, PROC CVPR IEEE, P535, DOI 10.1109/CVPR46437.2021.00060
   Huang Z, 2020, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR42600.2020.00316
   Huang Z, 2018, LECT NOTES COMPUT SC, V11220, P351, DOI 10.1007/978-3-030-01270-0_21
   Jiang WT, 2020, PROC CVPR IEEE, P5193, DOI 10.1109/CVPR42600.2020.00524
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Junting Dong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P210, DOI 10.1007/978-3-030-58536-5_13
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Li Rui, 2020, ECCV
   Li Z., P IEEE CVF C COMP VI, P6498
   Liu SH, 2020, PROC CVPR IEEE, P2016, DOI 10.1109/CVPR42600.2020.00209
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Luyang Zhu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P177, DOI 10.1007/978-3-030-58558-7_11
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Park K., 2021, ICCV, P5865
   Park Keunhong, 2021, ARXIV PREPRINT ARXIV, V40
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Pumarola Albert, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P10313, DOI 10.1109/CVPR46437.2021.01018
   Saito S, 2021, PROC CVPR IEEE, P2885, DOI 10.1109/CVPR46437.2021.00291
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Su S.-Y., 2021, C NEURAL INFORM PROC
   Su SY, 2021, ADV NEUR IN, V34
   Su Zhuo, 2020, ECCV
   Sun G., 2021, ARXIV PREPRINT ARXIV
   Suo X, 2021, PROC CVPR IEEE, P6222, DOI 10.1109/CVPR46437.2021.00616
   Tancik M, 2021, PROC CVPR IEEE, P2845, DOI 10.1109/CVPR46437.2021.00287
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Wang P, 2021, PROC CVPR IEEE, P124, DOI 10.1109/CVPR46437.2021.00019
   Wang Q., 2021, P IEEECVF C COMPUTER, P4690
   Xiang D., 2021, ARXIV PREPRINT ARXIV
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Yang Z, 2021, PROC CVPR IEEE, P13279, DOI 10.1109/CVPR46437.2021.01308
   Yariv L., 2021, ARXIV210612052
   Yaron L., 2020, NEURIPS
   Yu A., 2021, ARXIV PREPRINT ARXIV
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu H.-X., ARXIV PREPRINT ARXIV
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Zhang JK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459756
   Zhang X., 2021, ARXIV PREPRINT ARXIV
   Zhang YX, 2020, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR42600.2020.00140
   Zheng EL, 2014, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2014.196
   Zheng Y., 2021, ARXIV PREPRINT ARXIV
   Zheng Z., 2021, IEEE T PATTERN ANAL
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 93
TC 10
Z9 12
U1 3
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2021
VL 5
IS 4
BP 11
EP 19
DI 10.1016/j.visinf.2021.10.003
EA DEC 2021
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IY
UT WOS:000752694500002
OA gold
DA 2024-07-18
ER

PT J
AU Krake, T
   Reinhardt, S
   Hlawatsch, M
   Eberhardt, B
   Weiskopf, D
AF Krake, T.
   Reinhardt, S.
   Hlawatsch, M.
   Eberhardt, B.
   Weiskopf, D.
TI Visualization and selection of Dynamic Mode Decomposition components for
   unsteady flow
SO VISUAL INFORMATICS
LA English
DT Article
DE Dynamic Mode Decomposition; Spectral decomposition
ID PROPER ORTHOGONAL DECOMPOSITION; COHERENT STRUCTURES; EXTRACTION
AB Dynamic Mode Decomposition (DMD) is a data-driven and model-free decomposition technique. It is suitable for revealing spatio-temporal features of both numerically and experimentally acquired data. Conceptually, DMD performs a low-dimensional spectral decomposition of the data into the following components: the modes, called DMD modes, encode the spatial contribution of the decomposition, whereas the DMD amplitudes specify their impact. Each associated eigenvalue, referred to as DMD eigenvalue, characterizes the frequency and growth rate of the DMD mode. In this paper, we demonstrate how the components of DMD can be utilized to obtain temporal and spatial information from time-dependent flow fields. We begin with the theoretical background of DMD and its application to unsteady flow. Next, we examine the conventional process with DMD mathematically and put it in relationship to the discrete Fourier transform. Our analysis shows that the current use of DMD components has several drawbacks. To resolve these problems we adjust the components and provide new and meaningful insights into the decomposition: we show that our improved components capture the spatio-temporal patterns of the flow better. Moreover, we remove redundancies in the decomposition and clarify the interplay between components, allowing users to understand the impact of components. These new representations, which respect the spatio-temporal character of DMD, enable two clustering methods that segment the flow into physically relevant sections and can therefore be used for the selection of DMD components. With a number of typical examples, we demonstrate that the combination of these techniques allows new insights with DMD for unsteady flow. (C) 2021 The Author( s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Krake, T.; Reinhardt, S.; Hlawatsch, M.; Weiskopf, D.] Visualizat Res Ctr VISUS, Allmandring 19, D-70569 Stuttgart, Germany.
   [Krake, T.; Reinhardt, S.; Eberhardt, B.] Hsch Medien, Nobelstr 10, D-70569 Stuttgart, Germany.
RP Krake, T (corresponding author), Visualizat Res Ctr VISUS, Allmandring 19, D-70569 Stuttgart, Germany.
EM tim.krake@visus.uni-stuttgart.de;
   stefan.reinhardt@visus.uni-stuttgart.de;
   marcel.hlawatsch@visus.uni-stuttgart.de; eberhardt@hdm-stuttgart.de;
   daniel.weiskopf@visus.uni-stuttgart.de
OI Weiskopf, Daniel/0000-0003-1174-1026; Eberhardt,
   Bernhard/0000-0001-6428-4610; Krake, Tim/0009-0004-7084-3633
FU "Kooperatives Promotionskolleg Digital Media'' at Hochschule der Medien;
   University of Stuttgart; "Deutsche Forschungsgemeinschaft'' (DFG, German
   Research Foundation) [251654672 - TRR 161]
FX This work is partly supported by "Kooperatives Promotionskolleg Digital
   Media'' at Hochschule der Medien and the University of Stuttgart. It is
   also funded by the "Deutsche Forschungsgemeinschaft'' (DFG, German
   Research Foundation) - Project-ID 251654672 - TRR 161.
CR Ali N., 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 1967, Atmospheric Turbulence and Radio Wave Propagation, DOI DOI 10.1016/S0376-0421(03)00076-9
   Bagheri S, 2013, J FLUID MECH, V726, P596, DOI 10.1017/jfm.2013.249
   BERKOOZ G, 1993, ANNU REV FLUID MECH, V25, P539, DOI 10.1146/annurev.fl.25.010193.002543
   Bhatia H, 2013, IEEE T VIS COMPUT GR, V19, P1386, DOI 10.1109/TVCG.2012.316
   BI C, 2017, IEEE PHOTONICS J, V9, P1
   Brunton S. L., 2015, J. Comput. Dyn, V2, P165, DOI DOI 10.3934/JCD.2015002
   Bujack R, 2020, COMPUT GRAPH FORUM, V39, P811, DOI 10.1111/cgf.14037
   Chen GN, 2007, IEEE T VIS COMPUT GR, V13, P769, DOI 10.1109/TVCG.2007.1021
   Erichson NB, 2019, J REAL-TIME IMAGE PR, V16, P1479, DOI 10.1007/s11554-016-0655-2
   Kou JQ, 2017, EUR J MECH B-FLUID, V62, P109, DOI 10.1016/j.euromechflu.2016.11.015
   Krake T., 2019, ARXIV PREPRINT ARXIV
   Kutz JN, 2016, OTHER TITL APPL MATH, V149
   Kutz JN, 2017, IEEE INT CONF COMP V, P1862, DOI 10.1109/ICCVW.2017.220
   Kutz J Nathan., 2014, ARXIV PREPRINT ARXIV
   Lusseyran F, 2011, J PHYS CONF SER, V318, DOI 10.1088/1742-6596/318/4/042036
   Mikhailov A, 2019, GOOGLE AI BLOG TURBO
   Mohapatra Saurav, 2016, 2016 Power Systems Computation Conference (PSCC), P1, DOI 10.1109/PSCC.2016.7540904
   Moore E.H., 1920, On the reciprocal of the general Bull Amer Math Soc algebraic matrix, V26, P394, DOI 10.1090/S0002-9904-1920-03322-7
   Nair V, 2016, COMPUT FLUIDS, V140, P397, DOI 10.1016/j.compfluid.2016.09.001
   Pobitzer A, 2011, COMPUT GRAPH FORUM, V30, P771, DOI 10.1111/j.1467-8659.2011.01926.x
   Reich W., 2017, TOPOLOGICAL METHODS, P205
   Rojo IB, 2020, IEEE T VIS COMPUT GR, V26, P280, DOI 10.1109/TVCG.2019.2934375
   Rowley CW, 2009, J FLUID MECH, V641, P115, DOI 10.1017/S0022112009992059
   Sampath R, 2014, EXP FLUIDS, V55, DOI 10.1007/s00348-014-1792-7
   Sayadi T., 2013, ANN RES BRIEFS, P189
   Sayadi T., 2012, P SUMMER PROGRAM, P5
   Schmid P, 2011, THEOR COMP FLUID DYN, V25, P249, DOI 10.1007/s00162-010-0203-9
   Schmid PJ, 2010, J FLUID MECH, V656, P5, DOI 10.1017/S0022112010001217
   Seena A, 2011, INT J HEAT FLUID FL, V32, P1098, DOI 10.1016/j.ijheatfluidflow.2011.09.008
   Shadden SC, 2005, PHYSICA D, V212, P271, DOI 10.1016/j.physd.2005.10.007
   Tu JH., 2014, J COMPUT DYNAM, V1, P391, DOI DOI 10.3934/JCD.2014.1.391
   Weheliye WH, 2018, PHYS FLUIDS, V30, DOI 10.1063/1.5016305
   Wiebel A, 2007, IEEE T VIS COMPUT GR, V13, P641, DOI [10.1109/TVCG.2007.4293009, 10.1109/TVCG.2007.1036]
   Zhang QS, 2014, J FLUID STRUCT, V49, P53, DOI 10.1016/j.jfluidstructs.2014.04.002
NR 35
TC 14
Z9 16
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 15
EP 27
DI 10.1016/j.visinf.2021.06.003
EA JUL 2021
PG 13
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200002
OA Green Submitted, gold
DA 2024-07-18
ER

PT J
AU Zhang, M
   Zheng, YY
AF Zhang, Meng
   Zheng, Youyi
TI <i>Hair-GAN</i>: Recovering 3D hair structure from a single image using
   generative adversarial networks
SO VISUAL INFORMATICS
LA English
DT Article
DE Single-view hair modeling; 3D volumetric structure; Deep learning;
   Generative adversarial networks
AB We introduce Hair-GAN, an architecture of generative adversarial networks, to recover the 3D hair structure from a single image. The goal of our networks is to build a parametric transformation from 2D hair maps to 3D hair structure. The 3D hair structure is represented as a 3D volumetric field which encodes both the occupancy and the orientation information of the hair strands. Given a single hair image, we first align it with a bust model and extract a set of 2D maps encoding the hair orientation information in 2D, along with the bust depth map to feed into our Hair-GAN. With our generator network, we compute the 3D volumetric field as the structure guidance for the final hair synthesis. The modeling results not only resemble the hair in the input image but also possesses many vivid details in other views. The efficacy of our method is demonstrated by using a variety of hairstyles and comparing with the prior art. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Zhang, Meng; Zheng, Youyi] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Zheng, YY (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM youyizheng@zju.edu.cn
FU National Key Research & Development Program of China [2018YFE0100900];
   China Young 1000 Talent Program; Fundamental Research Funds for the
   Central Universities
FX We would like to thank the anonymous reviewers for their constructive
   suggestions. This work is partially supported by the National Key
   Research & Development Program of China (2018YFE0100900), the China
   Young 1000 Talent Program, and the Fundamental Research Funds for the
   Central Universities.
CR Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Chai ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925961
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Echevarria JI, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601133
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hensel M, 2017, ADV NEUR IN, V30
   Herrera TL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366165
   Hu LW, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3130800.3130887, 10.1145/3130800.31310887]
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Hu LW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601194
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jakob W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618510
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kingma D. P., 2014, arXiv
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Luo LJ, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462026
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Odena A, 2017, PR MACH LEARN RES, V70
   Paris S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360629
   Reed S, 2016, PR MACH LEARN RES, V48
   Saito S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275019
   Wang LD, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531362
   Ward K, 2007, IEEE T VIS COMPUT GR, V13, P213, DOI 10.1109/TVCG.2007.30
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Zhang M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275039
   Zhang M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073627
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11215, P249, DOI 10.1007/978-3-030-01252-6_15
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 32
TC 23
Z9 24
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2019
VL 3
IS 2
BP 102
EP 112
DI 10.1016/j.visinf.2019.06.001
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YK
UT WOS:000658189200005
OA gold
DA 2024-07-18
ER

PT J
AU Yuan, ZY
   He, SQ
   Liu, Y
   Yu, LY
AF Yuan, Ziyue
   He, Shuqi
   Liu, Yu
   Yu, Lingyun
TI MEinVR: Multimodal interaction techniques in immersive exploration
SO VISUAL INFORMATICS
LA English
DT Article
DE Multimodal interaction; Virtual reality; Scientific visualization
ID VIRTUAL-REALITY; USER-INTERFACE; VISUALIZATION; SYSTEM; EXPECTATIONS;
   DICTATION; DESIGN; EYE
AB Immersive environments have become increasingly popular for visualizing and exploring large-scale, complex scientific data because of their key features: immersion, engagement, and awareness. Virtual reality offers numerous new interaction possibilities, including tactile and tangible interactions, gestures, and voice commands. However, it is crucial to determine the most effective combination of these techniques for a more natural interaction experience. In this paper, we present MEinVR, a novel multimodal interaction technique for exploring 3D molecular data in virtual reality. MEinVR combines VR controller and voice input to provide a more intuitive way for users to manipulate data in immersive environments. By using the VR controller to select locations and regions of interest and voice commands to perform tasks, users can efficiently perform complex data exploration tasks. Our findings provide suggestions for the design of multimodal interaction techniques in 3D data exploration in virtual reality. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Yuan, Ziyue; He, Shuqi; Liu, Yu; Yu, Lingyun] Xian Jiaotong Liverpool Univ, Sch Adv Technol, 111 Renai Rd, Suzhou 215123, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University
RP Yu, LY (corresponding author), Xian Jiaotong Liverpool Univ, Sch Adv Technol, 111 Renai Rd, Suzhou 215123, Jiangsu, Peoples R China.
EM Lingyun.Yu@xjtlu.edu.cn
RI Yang, Ning/KHD-1133-2024; Zhou, Xinyi/KGM-6689-2024
FU NSFC, PR China [62272396]; XJTLU Research Development Funding, PR China
   [RDF-19-02-11]
FX The work was supported by NSFC, PR China (62272396) and XJTLU Research
   Development Funding, PR China RDF-19-02-11.
CR Alfaro L, 2018, INT J ADV COMPUT SC, V9, P254
   Arangarasan R, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P331, DOI 10.1109/ICMI.2002.1167017
   Basapur S, 2007, LECT NOTES COMPUT SC, V4551, P217
   Bee N, 2008, LECT NOTES ARTIF INT, V5078, P111, DOI 10.1007/978-3-540-69369-7_13
   Begany G.M., 2015, Factors affecting user perception of a spoken language vs. Textual search interface: A content analysis, interacting with computers, DOI [10.1093/iwc/iwv029,iwv029, DOI 10.1093/IWC/IWV029,IWV029]
   Benko H., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P19, DOI DOI 10.1145/1936652.1936657
   Berglund A., 2004, Universal Access in the Information Society, V3, P224, DOI 10.1007/s10209-004-0106-x
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Blattgerste J, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206349
   Boletsis Costas., 2019, INT J VIRTUAL REALIT, V19, P2, DOI [DOI 10.20870/IJVR.2019.19.3.2917, 10.20870/IJVR.2019.19.3.2917, DOI 10.20870/IJVR.2019.19.32917]
   Bonanni L, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P251
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Brun D, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382837
   Brun D, 2017, INT J PERVASIVE COMP, V13, P41, DOI 10.1108/IJPCC-02-2017-0011
   Burdea G. C., 2003, Virtual reality technology
   Caceres PC, 2018, IEEE GLOB ENG EDUC C, P183, DOI 10.1109/EDUCON.2018.8363226
   Cavallo M, 2019, Arxiv, DOI arXiv:1903.03700
   Chakraborty A., 2014, CHI '14 Extended Abstracts on Human Factors in Computing Systems. CHI EA '14, P1315, DOI DOI 10.1145/2559206.2581340
   Chen F., 2012, ACM T INTERACT INTEL, V2, P1, DOI DOI 10.1145/2395123.2395127
   Christensen DJ, 2014, IEEE ROMAN, P56, DOI 10.1109/ROMAN.2014.6926230
   Chun J, 2016, INT WINT WORKSH BR
   Ciftci UA, 2017, IEEE INT CON MULTI, P715, DOI 10.1109/ICME.2017.8019545
   Conner D.B., 1992, P S INTERACTIVE 3D G, P183, DOI 10.1145/147156.147199
   Cox K., 2001, International Journal of Speech Technology, V4, P297, DOI 10.1023/A:1011368926479
   Dai L, 2005, BEHAV INFORM TECHNOL, V24, P219, DOI 10.1080/01449290412331328563
   Daily M., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P57, DOI 10.1145/351006.351013
   Dey P, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P329, DOI [10.1109/ICREST.2019.8644322, 10.1109/icrest.2019.8644322]
   Dim NK, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P204, DOI 10.1145/2901790.2901834
   Dorozhkin Denis V., 2002, ASME 2002 INT DES EN, V1, P61, DOI [10.1115/DETC2002/CIE-34390, DOI 10.1115/DETC2002/CIE-34390]
   Dunser A., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P107, DOI [10.1145/2414536.2414554, DOI 10.1145/2414536.2414554]
   Englmeier D, 2020, A tangible spherical proxy for object manipulation in augmented reality, DOI [10.1109/VR46266.2020.00041, DOI 10.1109/VR46266.2020.00041]
   Eroglu S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P475, DOI 10.1109/VR.2018.8446595
   Falah J, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P752, DOI 10.1109/SAI.2014.6918271
   Botero-Ospina AF, 2017, REV FAC ING-UNIV ANT, P40, DOI 10.17533/udea.redin.n82a05
   Ferracani A, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1233, DOI 10.1145/3123266.3127916
   Ferrer CDR, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230042
   Fleury C., 2012, P 18 ACM S VIRTUAL R, P129, DOI DOI 10.1145/2407336.2407361
   Foley J.D., 1996, Computer Graphics: Principles and Practice, 12110, DOI [10.1002/(SICI)1520-6378(199702)22:13.0.CO;2-7, DOI 10.1002/(SICI)1520-6378(199702)22:13.0.CO;2-7]
   Gallo L, 2011, COMP MED SY, DOI 10.1109/CBMS.2011.5999138
   Gallo Luigi., 2008, AVI '08: Proceedings of the working conference on Advanced visual interfaces, P429, DOI DOI 10.1145/1385569.1385651
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gelsomini M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376667
   Genty A., 2014, P 2014 VIRT REAL INT, DOI [10. 1145/2617841.2620716, DOI 10.1145/2617841.2620716]
   Giannopoulos I, 2017, P 21 PAN HELL C INF, P1, DOI [10.1145/3139367.3139424, DOI 10.1145/3139367.3139424]
   Goddard TD, 2018, PROTEIN SCI, V27, P14, DOI 10.1002/pro.3235
   Gomez SR, 2010, LECT NOTES COMPUT SC, V6454, P373, DOI 10.1007/978-3-642-17274-8_37
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Hansen JP, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3208330
   Heydn KAM, 2019, INT CONF GAMES VIRTU, P118, DOI 10.1109/vs-games.2019.8864589
   Hofmann H., 2014, P 19 INT C INT US IN, P215, DOI [10.1145/2557500.2557509, DOI 10.1145/2557500.2557509]
   Holly M, 2021, EDUC TECHNOL SOC, V24, P107
   Honnibal M., 2017, IN PRESS, DOI DOI 10.3233/978-1-60750-588-4-1080
   Hoste L, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P156, DOI 10.1145/2254556.2254585
   Hou WJ, 2021, INT J HUM-COMPUT INT, V37, P484, DOI 10.1080/10447318.2020.1826190
   Houde S., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P135, DOI 10.1145/142750.142772
   Isokoski Poika., 2000, P 2000 S EYE TRACKIN, P15, DOI [DOI 10.1145/355017.355020, 10.1145/355017.355020]
   Issarter P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2014.6798839
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   Jie L, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON UNMANNED SYSTEMS (ICUS), P353, DOI 10.1109/ICUS.2017.8278368
   Jota R, 2010, J REAL-TIME IMAGE PR, V5, P91, DOI 10.1007/s11554-009-0141-1
   Kaiser E., 2003, ICMI 03, P12
   Keefe DF, 2007, IEEE T VIS COMPUT GR, V13, P1067, DOI 10.1109/TVCG.2007.1060
   Khadka R, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P327, DOI 10.1145/3279778.3281458
   Kim J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3143420
   Kirmizibayrak Can., 2011, P 10 INT C VIRTUAL R, P69, DOI [10.1145/2087756.2087764, DOI 10.1145/2087756.2087764]
   Kosuru R.K., 2019, P MENSCH UND COMP 20, P643, DOI [10.1145/3340764.3344884, DOI 10.1145/3340764.3344884]
   Kumar Anuj, 2012, P SIGCHI C HUMAN FAC, P2277, DOI [10.1145/2207676.2208386, DOI 10.1145/2207676.2208386]
   Kumar D, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2358, DOI 10.1109/ICACCI.2016.7732407
   Laha Bireswar., 2013, Proceedings of the 1st symposium on Spatial user interaction, P61, DOI [10.1145/2491367.2491368, DOI 10.1145/2491367.2491368]
   Latoschik ME, 1998, IEEE IND ELEC, P2028, DOI 10.1109/IECON.1998.724030
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee EC, 2010, J NEUROSCI METH, V190, P289, DOI 10.1016/j.jneumeth.2010.05.008
   Löhr A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P979
   Lubos P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P191
   Luger K, 1997, NATURE, V389, P251, DOI 10.1038/38444
   Luro FL, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317956.3318153
   Lyons MJ, 2004, IEEE SYS MAN CYBERN, P598
   Ma XY, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P263, DOI 10.1145/3172944.3172988
   Masai K, 2020, INT SYM MIX AUGMENT, P374, DOI 10.1109/ISMAR50242.2020.00064
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   McClinton W, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312968
   Melichar M., 2006, Proceedings of the 8th international Conference on Multimodal interfaces, ICMI '06, P59, DOI DOI 10.1145/1180995.1181008
   Mendes D, 2019, COMPUT GRAPH FORUM, V38, P21, DOI 10.1111/cgf.13390
   Mewes A, 2016, INT J COMPUT ASS RAD, V11, P157, DOI 10.1007/s11548-015-1215-0
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Minakata K, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317956.3318150
   Minett JW, 2012, INT J HUM-COMPUT INT, V28, P472, DOI 10.1080/10447318.2011.622970
   Munzner T, 2014, VISUALIZATION ANAL D, DOI DOI 10.1201/B17511
   Nawrocka A, 2013, PROCEEDINGS OF THE 2013 14TH INTERNATIONAL CARPATHIAN CONTROL CONFERENCE (ICCC), P251
   Nooruddin, 2020, IEEE SYS MAN CYBERN, P744, DOI [10.1109/SMC42975.2020.9283348, 10.1109/smc42975.2020.9283348]
   O'Hara K, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2442106.2442111
   Oviatt S, 2000, COMMUN ACM, V43, P45, DOI 10.1145/330534.330538
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Pan X, 2017, CHIN CONTR CONF, P11034, DOI 10.23919/ChiCC.2017.8029119
   Pedersen BKMK, 2018, PROCEEDINGS OF THE 8TH IEEE INTEGRATED STEM EDUCATION CONFERENCE (ISEC 2018), P37, DOI 10.1109/ISECon.2018.8340502
   Pick S, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P109, DOI 10.1109/3DUI.2016.7460039
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Reddivari S, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P280, DOI 10.1109/CHASE.2017.102
   Reisman JL, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P69
   Rick T, 2011, STUD HEALTH TECHNOL, V163, P486, DOI 10.3233/978-1-60750-706-2-486
   Sammon M.J., 2006, P 8 C HUM COMP INT M, P41, DOI [10.1145/1152215.1152224, DOI 10.1145/1152215.1152224]
   Sarcar S., 2013, P 11 ASIA PACIFIC C, P215, DOI [DOI 10.1145/2525194.2525288, 10.1145/2525194.2525288]
   Schaffer S, 2015, INT J HUM-COMPUT ST, V75, P21, DOI 10.1016/j.ijhcs.2014.11.004
   Schkolne S, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P227, DOI 10.1109/VISUAL.2004.47
   Schroeder B. L., 2017, Commun. Comput. Inf. Sci, P54, DOI DOI 10.1007/978-3-319-58753-09
   Sears A, 2003, HUM-COMPUT INTERACT, V18, P229, DOI 10.1207/S15327051HCI1803_2
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Sidorakis N, 2015, 2015 IEEE 1ST WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P15, DOI 10.1109/WEVR.2015.7151689
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Siu AF, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173865
   Sivaraman V, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1045
   Ruppert GCS, 2012, WORLD J UROL, V30, P687, DOI 10.1007/s00345-012-0879-0
   Speicher Marco, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130967
   Spindler Martin., 2009, Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces-ITS '09, P69, DOI [DOI 10.1145/1731903.1731920, 10.1145/1731903, DOI 10.1145/1731903]
   Sun YW, 2010, LECT NOTES COMPUT SC, V6133, P184
   Tan Jeffrey Too Chuan, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P296, DOI 10.1109/ROMAN.2013.6628431
   Tawara T, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P121, DOI 10.1109/3DUI.2010.5444707
   Tsong C.K., 2013, 2013 IEEE S COMP INF, P22, DOI [10.1109/ISCI.2013.6612407, DOI 10.1109/ISCI.2013.6612407]
   Tuddenham P, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2223
   Valentin J., 2015, ACM SIGGRAPH 2015 TA, P1, DOI [10.1145/2775280.2792589, DOI 10.1145/2775280.2792589]
   Wang DL, 2008, COMPUT HUM BEHAV, V24, P2507, DOI 10.1016/j.chb.2008.03.014
   Wang KJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P161, DOI 10.1109/AIVR.2018.00034
   Xiao J, 2019, IEEE ACCESS, V7, P22059, DOI 10.1109/ACCESS.2019.2898324
   Yan YK, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3380983
   Yu G, 2018, AIVR 2018: 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY, P31, DOI 10.1145/3293663.3293672
   Yu LY, 2012, IEEE T VIS COMPUT GR, V18, P2245, DOI 10.1109/TVCG.2012.217
   Yukang Yan, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287076
   Zhao QB, 2009, CHINESE SCI BULL, V54, P78, DOI 10.1007/s11434-008-0547-3
   Zielasko D, 2017, IEEE SYMP 3D USER, P40, DOI 10.1109/3DUI.2017.7893316
NR 132
TC 2
Z9 2
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2023
VL 7
IS 3
BP 37
EP 48
DI 10.1016/j.visinf.2023.06.001
EA SEP 2023
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA U3AA3
UT WOS:001083548400001
OA gold
DA 2024-07-18
ER

PT J
AU Jiang, A
   Nacenta, MA
   Ye, J
AF Jiang, Ai
   Nacenta, Miguel A.
   Ye, Juan
TI VisuaLizations As Intermediate Representations (VLAIR): An approach for
   applying deep learning-based computer vision to non-image-based data
SO VISUAL INFORMATICS
LA English
DT Article
DE Information visualization; Convolutional neural networks; Human activity
   recognition; Smart homes; Data representation; Intermediate
   representations; Interpretability Machine learning; Deep learning
ID HUMAN ACTIVITY RECOGNITION; SENSOR
AB Deep learning algorithms increasingly support automated systems in areas such as human activity recognition and purchase recommendation. We identify a current trend in which data is transformed first into abstract visualizations and then processed by a computer vision deep learning pipeline. We call this VisuaLization As Intermediate Representation (VLAIR) and believe that it can be instrumental to support accurate recognition in a number of fields while also enhancing humans' ability to interpret deep learning models for debugging purposes or for personal use. In this paper we describe the potential advantages of this approach and explore various visualization mappings and deep learning architectures. We evaluate several VLAIR alternatives for a specific problem (human activity recognition in an apartment) and show that VLAIR attains classification accuracy above classical machine learning algorithms and several other non-image-based deep learning algorithms with several data representations.
   (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Jiang, Ai; Ye, Juan] Univ St Andrews, Sch Comp Sci, St Andrews, Fife, Scotland.
   [Nacenta, Miguel A.] Univ Victoria, Victoria, BC, Canada.
C3 University of St Andrews; University of Victoria
RP Jiang, A (corresponding author), Univ St Andrews, Sch Comp Sci, St Andrews, Fife, Scotland.
EM aj99@st-andrews.ac.uk
OI Ye, Juan/0000-0002-2838-6836; Jiang, Ai/0000-0003-4521-3387
FU China Scholarship Council (CSC); NSERC [2020-04401]
FX We thank the China Scholarship Council (CSC) for financially supporting
   my PhD study at University of St Andrews, UK, and NSERC Discovery Grant
   2020-04401 (Miguel Nacenta). We also thank Paria Naghavi for comments on
   manuscript.
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Ahmad Z, 2018, IEEE INT SYM MULTIM, P223, DOI 10.1109/ISM.2018.000-2
   Alberdi A, 2018, IEEE J BIOMED HEALTH, V22, P1720, DOI 10.1109/JBHI.2018.2798062
   Aminikhanghahi S, 2019, IEEE T KNOWL DATA EN, V31, P1010, DOI [10.1109/TKDE.2018.2850347, 10.1109/tkde.2018.2850347]
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/D15-1166, DOI 10.48550/ARXIV.1508.04025]
   Bianchi V, 2019, IEEE INTERNET THINGS, V6, P8553, DOI 10.1109/JIOT.2019.2920283
   Chen L, 2018, Arxiv, DOI arXiv:1812.07606
   Cook DJ, 2009, METHOD INFORM MED, V48, P480, DOI 10.3414/ME0592
   Cook DJ, 2013, COMPUTER, V46, P62, DOI 10.1109/MC.2012.328
   Fan CR, 2021, IEEE T VIS COMPUT GR, V27, P4495, DOI 10.1109/TVCG.2020.3002950
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Feuz KD, 2017, KNOWL INF SYST, V53, P337, DOI 10.1007/s10115-017-1043-3
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Ha S, 2015, IEEE SYS MAN CYBERN, P3017, DOI 10.1109/SMC.2015.525
   Hatami N, 2018, PROC SPIE, V10696, DOI 10.1117/12.2309486
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hochreiter S., 1997, Neural Computation, V9, P1735
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang A., 2020, P 14 EAI INT C PERV
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee ALXD, 2020, Arxiv, DOI arXiv:2008.12747
   Li Q, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P1321, DOI 10.1145/3196709.3196771
   Liu HY, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.10.002
   Logan B, 2007, LECT NOTES COMPUT SC, V4717, P483
   Manovich L, 2011, VISUAL STUD, V26, P36, DOI 10.1080/1472586X.2011.548488
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Morales FJO, 2016, IEEE INT SYM WRBL CO, P92, DOI 10.1145/2971767.2971764
   Patel A, 2019, J AMB INTEL SMART EN, V11, P301, DOI 10.3233/AIS-190529
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pourbabaee B, 2018, IEEE T SYST MAN CY-S, V48, P2095, DOI 10.1109/TSMC.2017.2705582
   Radu Valentin, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161174
   Ravì D, 2016, INT CONF WEARAB IMPL, P71, DOI 10.1109/BSN.2016.7516235
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh MS, 2017, IEEE IJCNN, P2665, DOI 10.1109/IJCNN.2017.7966182
   Sprint G, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102219
   Stoiber C, 2022, VIS INFORM, V6, P68, DOI 10.1016/j.visinf.2022.02.005
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thomaz E, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P85
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   van Kasteren TLM, 2011, ATL AMB PERVAS INTEL, V4, P165
   Wang J, 2017, IEEE T VEH TECHNOL, V66, P6258, DOI 10.1109/TVT.2016.2635161
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Zhiguang, 2015, Workshops at the twenty-ninth AAAI conference on artificial intelligence, V1
   Wu Z., 2017, FRONTIERS MULTIMEDIA, P3, DOI DOI 10.1145/3122865.3122867
   Xiong GM, 2021, IEEE T VIS COMPUT GR, V27, P4413, DOI 10.1109/TVCG.2020.3005680
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Hammerla NY, 2016, Arxiv, DOI [arXiv:1604.08880, 10.48550/arXiv.1604.08880]
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Ye J, 2015, PERVASIVE MOB COMPUT, V19, P47, DOI 10.1016/j.pmcj.2014.02.003
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
   Zeng W, 2021, IEEE T VIS COMPUT GR, V27, P839, DOI 10.1109/TVCG.2020.3030410
   Zhang JB, 2017, AAAI CONF ARTIF INTE, P1655
NR 60
TC 4
Z9 4
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2022
VL 6
IS 3
BP 35
EP 50
DI 10.1016/j.visinf.2022.05.001
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 6M5IA
UT WOS:000888899400004
OA gold, Green Published
DA 2024-07-18
ER

PT J
AU Gupta, M
   Soeny, K
AF Gupta, Mehul
   Soeny, Kabir
TI Algorithms for rapid digitalization of prescriptions
SO VISUAL INFORMATICS
LA English
DT Article
DE Artificial intelligence; Image processing; Healthcare technology;
   Pattern intelligence
ID MEDICATION INFORMATION; EXTRACTION; SYSTEM
AB Prescription data are invaluable for healthcare research and intelligence, yet, extraction of these data is challenging as this information is intertwined in the unstructured and non-grammatical text in prescription images. Moreover, text extraction from images in itself is hard, particularly for handwritten text. While piecemeal solutions exist, they are either limited to a small set of entities of interest or have very low accuracy and are not scalable. In this paper, we present two algorithms: the C-Cube algorithm for digitization of computer-printed prescriptions and the 3-Step Filtering algorithm for handwritten prescriptions. While a brute-force approach would match every word that is received from an optical character reader (OCR) with all possible entries in the database, this approach is inefficient and imprecise. The premise of our algorithms is an application of pattern intelligence to select a much smaller set of words (from the words returned by the OCR) as potential entities of interest. We rigorously tested the two algorithms on a corpus of more than 10,000 prescriptions' images, taking the brute-force technique as the baseline methodology. Regarding latencies, we found that the C-Cube and the 3-Step Filtering algorithms were 588 and 231 times faster than the brute-force approach. In terms of accuracies, we found that the F-score of the C-cube algorithm was 90% higher than the F-score of the brute-force approach whereas the F-score for the 3-Step filtering algorithm was found to be 8,600% higher. The algorithms are decidedly faster and more accurate than the brute-force approach. These attributes make them suitable for implementation in real-time environments as well as for use in batch-mode for various applications. We expect the algorithms to play a significant role in the digitalization of healthcare information and briefly discuss a few applications. (C) 2021 The Author( s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Gupta, Mehul; Soeny, Kabir] 1Mg Technol Private Ltd, Gurugram, India.
RP Gupta, M (corresponding author), 1Mg Technol Private Ltd, Gurugram, India.
OI Soeny, Kabir/0000-0003-0426-6108
CR 1mg Technologies, 2021, 1MG ONL MED STOR HEA
   Agrebi S, 2020, ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS, P415, DOI 10.1016/B978-0-12-817133-2.00018-5
   Almario Christopher V, 2017, Gastroenterol Hepatol (N Y), V13, P437
   Baeza-Yates R., 1994, Combinatorial Pattern Matching. 5th Annual Symposium, CPM 94. Proceedings, P198
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   Caruana EJ, 2015, J THORAC DIS, V7, pE537, DOI 10.3978/j.issn.2072-1439.2015.10.63
   Chrimes D, 2016, 2016 IEEE 14TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 14TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 2ND INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/DATACOM/CYBERSC, P811, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2016.140
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   Davis TC, 2009, J GEN INTERN MED, V24, P57, DOI 10.1007/s11606-008-0833-4
   Doan S., 2009, P 3 I2B2 WORKSH CHAL
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fajardo L., 2019, DOCTORS CURSIVE HAND, P1
   Google, 2021, VIS AI
   Google, 2021, VIS AI DOC
   Grouin C., 2009, P 3 I2B2 WORKSH CHAL
   Hamon T., 2009, P 3 I2B2 WORKSH CHAL
   Hosseini H, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P101, DOI 10.1109/ICMLA.2017.0-172
   Konstantinidis S, 2007, INFORM COMPUT, V205, P1307, DOI 10.1016/j.ic.2007.06.001
   Li ZF, 2010, J AM MED INFORM ASSN, V17, P563, DOI 10.1136/jamia.2010.004077
   Ling ZH, 2017, ARCH PHARM PRACT, V8, P8, DOI 10.4103/2045-080X.199613
   Lyons R, 1998, BRIT MED J, V317, P863, DOI 10.1136/bmj.317.7162.863
   Medicine I., 2000, QUALITY CHASM SERIES, V627
   Microsoft, 2021, COMPUTER VISION
   Nair K, 2002, CAN FAM PHYSICIAN, V48, P104
   Patrick J., 2009, Proceedings of the Australasian Language Technology Association Workshop 2009, P99
   Solt I., 2009, P 3 I2B2 WORKSH CHAL
   Spasic I, 2010, J AM MED INFORM ASSN, V17, P532, DOI 10.1136/jamia.2010.003657
   Tao C, 2017, J BIOMED INFORM, V72, P60, DOI 10.1016/j.jbi.2017.07.002
   Uzuner Ö, 2010, J AM MED INFORM ASSN, V17, P514, DOI 10.1136/jamia.2010.003947
   Wang X, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P85, DOI 10.1145/2623330.2623754
   Wilburn J, 2019, INT J INFECT DIS, V89, P146, DOI 10.1016/j.ijid.2019.10.011
   Wolf MS, 2007, PATIENT EDUC COUNS, V67, P293, DOI 10.1016/j.pec.2007.03.024
   Yang H.A., 2009, P 3 I2B2 WORKSH CHAL
NR 33
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2021
VL 5
IS 3
BP 54
EP 69
DI 10.1016/j.visinf.2021.07.002
EA SEP 2021
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YV4IB
UT WOS:000752692200005
OA gold
DA 2024-07-18
ER

PT J
AU Han, G
   Jo, J
   Chae, HJ
   Seo, J
AF Han, GuHyun
   Jo, Jaemin
   Chae, Han Joo
   Seo, Jinwook
TI Human-Computer Interaction Lab (HCIL) in Seoul National University
SO VISUAL INFORMATICS
LA English
DT Article
DE Lab introduction; Information visualization; Visual analytics;
   Progressive visualization; Machine learning for visualization; MR and AR
ID VISUAL ANALYTICS TOOL; VISUALIZATION
AB This article introduces Human-Computer Interaction Laboratory (HCIL) established at Seoul National University, Korea, in 2009. We first summarized the history of foundation, achievement, and collaboration for the last 10 years. Then, we delineated our current research directions related to information visualization. Finally, we presented our facilities and equipment to adequately support the research. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Han, GuHyun; Seo, Jinwook] Seoul Natl Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Jo, Jaemin] Sungkyunkwan Univ, Coll Comp, Seoul, South Korea.
   [Chae, Han Joo] ROKIT Healthcare, Seoul, South Korea.
C3 Seoul National University (SNU); Sungkyunkwan University (SKKU)
RP Seo, J (corresponding author), Seoul Natl Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM jseo@snu.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1A2C2089062]
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2019R1A2C2089062).
CR Chae H.J., 2016, P 29 ANN S US INT SO, P205
   Chae HJ, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P45, DOI 10.1145/3242587.3242631
   Cho M, 2014, IEEE T VIS COMPUT GR, V20, P808, DOI 10.1109/TVCG.2013.2297933
   Han Joo Chae, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382885
   Jo J., 2019, IEEE T VIS COMPUT GR
   Jo J, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P136, DOI [10.1109/VISUAL.2019.8933670, 10.1109/visual.2019.8933670]
   Jo J, 2020, IEEE T VIS COMPUT GR, V26, P1347, DOI 10.1109/TVCG.2018.2869149
   Jo J, 2019, IEEE T VIS COMPUT GR, V25, P470, DOI 10.1109/TVCG.2018.2865141
   Jo J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2660, DOI 10.1145/3025453.3025752
   Jo J, 2017, IEEE PAC VIS SYMP, P131, DOI 10.1109/PACIFICVIS.2017.8031587
   Jo J, 2015, IEEE COMPUT GRAPH, V35, P20, DOI 10.1109/MCG.2015.113
   Jo J, 2014, IEEE T VIS COMPUT GR, V20, P2329, DOI 10.1109/TVCG.2014.2346454
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Jung Daekyoung, 2015, BMC Proc, V9, pS2, DOI 10.1186/1753-6561-9-S6-S2
   Kim J, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P315, DOI 10.1145/3343055.3360741
   Ko H.-K., 2020, EUROVIS 2020 SHORT P, DOI [10.2312/evs, DOI 10.2312/EVS]
   L'Yi S, 2019, COMPUT GRAPH FORUM, V38, P201, DOI 10.1111/cgf.13682
   L'Yi S, 2017, METHODS, V124, P78, DOI 10.1016/j.ymeth.2017.06.004
   L'Yi S, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/1471-2105-16-S11-S5
   Park H, 2016, SECOND INTERNATIONAL CONFERENCE ON IOT IN URBAN SPACE (URB-IOT 2016), P18, DOI 10.1145/2962735.2962746
   Song H, 2017, IEEE T VIS COMPUT GR, V23, P311, DOI 10.1109/TVCG.2016.2598796
   Song H, 2014, IEEE T VIS COMPUT GR, V20, P726, DOI 10.1109/TVCG.2013.271
   Yoo S., 2020, IEEE Access, V8
   Yoo S, 2018, VIS INFORM, V2, P82, DOI 10.1016/j.visint2018.04.009
NR 24
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD DEC
PY 2020
VL 4
IS 4
BP 35
EP 39
DI 10.1016/j.visinf.2020.10.002
PG 5
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KZ
UT WOS:000658193600004
OA gold
DA 2024-07-18
ER

PT J
AU Wang, CL
AF Wang, Chaoli
TI Visualization Laboratory at University of Notre Dame
SO VISUAL INFORMATICS
LA English
DT Article
ID INTERFACE; STREAMLINES
AB This article introduces the Visualization Laboratory at the Department of Computer Science & Engineering, the University of Notre Dame, including the lab's overview, current research directions, facilities, and international collaborations. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press Co. Ltd.
C1 [Wang, Chaoli] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Wang, CL (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM chaoli.wang@nd.edu
RI Wang, Chaoli/AAJ-5173-2020
OI Wang, Chaoli/0000-0002-0859-3619
FU U.S. National Science Foundation [IIS1017935, CNS-1229297, IIS-1456763,
   IIS-1455886, CNS-1629914, DUE-1833129, IIS-1955395]
FX The research works described in this article have been supported by the
   U.S. National Science Foundation through grants IIS1017935, CNS-1229297,
   IIS-1456763, IIS-1455886, CNS-1629914, DUE-1833129, and IIS-1955395.
CR [Anonymous], 2020, VISVISUAL
   [Anonymous], OSUCISRC104TR05
   [Anonymous], 2020, CSRANKINGS COMPUTER
   Bailey S.M., 2018, P IS T C VIS DAT AN
   Chen CK, 2011, IEEE PAC VIS SYMP, P27, DOI 10.1109/PACIFICVIS.2011.5742369
   Deng HZ, 2019, VIS INFORM, V3, P166, DOI 10.1016/j.visinf.2019.10.004
   Goulden M.C., 2019, P IS T C VISUALIZATI
   Gu Y, 2017, COMPUT GRAPH-UK, V62, P1, DOI 10.1016/j.cag.2016.11.001
   Gu Y, 2017, INFORM VISUAL, V16, P21, DOI 10.1177/1473871616630778
   Gu Y, 2016, IEEE T VIS COMPUT GR, V22, P965, DOI 10.1109/TVCG.2015.2468031
   Gu Y, 2013, IEEE PAC VIS SYMP, P137, DOI 10.1109/PacificVis.2013.6596138
   Gu Y, 2011, IEEE T VIS COMPUT GR, V17, P2015, DOI 10.1109/TVCG.2011.246
   Gu Y, 2010, LECT NOTES COMPUT SC, V6455, P437
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Han J., IEEE T VIS COMPUT GR
   Han J., IEEE T VIS COMPUT GR, V27
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2019, IEEE COMPUT GRAPH, V39, P54, DOI 10.1109/MCG.2018.2881523
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Hu TX, 2020, VIS INFORM, V4, P58, DOI 10.1016/j.visinf.2020.02.001
   Imre M., 2020, PROC AM SOC ENG ED A
   Imre M, 2018, COMPUT GRAPH-UK, V72, P82, DOI 10.1016/j.cag.2018.02.002
   Imre M, 2017, IEEE PAC VIS SYMP, P180, DOI 10.1109/PACIFICVIS.2017.8031592
   Li Y., 2014, P IS T SPIE C VIS DA
   Li YF, 2015, COMPUT GRAPH-UK, V52, P79, DOI 10.1016/j.cag.2015.06.003
   Ma J, 2019, J VISUAL-JAPAN, V22, P1125, DOI 10.1007/s12650-019-00592-3
   Ma J, 2014, IEEE PAC VIS SYMP, P25, DOI 10.1109/PacificVis.2014.14
   Ma J, 2014, IEEE T VIS COMPUT GR, V20, P1127, DOI 10.1109/TVCG.2013.236
   Ma J, 2013, IEEE PAC VIS SYMP, P233, DOI 10.1109/PacificVis.2013.6596150
   Ma J, 2013, PROC SPIE, V8654, DOI 10.1117/12.2001887
   Porter WP, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P131, DOI [10.1109/VISUAL.2019.8933759, 10.1109/visual.2019.8933759]
   Sukharev J, 2009, IEEE PAC VIS SYMP, P161, DOI 10.1109/PACIFICVIS.2009.4906852
   Tao J., 2016, P ACM SIGGRAPH AS S
   Tao J, 2017, IEEE PAC VIS SYMP, P1, DOI 10.1109/PACIFICVIS.2017.8031572
   Tao J, 2019, IEEE T VIS COMPUT GR, V25, P1236, DOI 10.1109/TVCG.2018.2864808
   Tao J, 2018, IEEE T VIS COMPUT GR, V24, P2622, DOI 10.1109/TVCG.2017.2750681
   Tao J, 2018, IEEE T VIS COMPUT GR, V24, P3200, DOI 10.1109/TVCG.2017.2773071
   Tao J, 2016, COMPUT GRAPH-UK, V59, P79, DOI 10.1016/j.cag.2016.05.024
   Tao J, 2016, IEEE T VIS COMPUT GR, V22, P1503, DOI 10.1109/TVCG.2015.2440252
   Tao J, 2014, IEEE PAC VIS SYMP, P9, DOI 10.1109/PacificVis.2014.12
   Tao J, 2014, IEEE T VIS COMPUT GR, V20, P42, DOI 10.1109/TVCG.2013.100
   Tao J, 2013, IEEE T VIS COMPUT GR, V19, P393, DOI 10.1109/TVCG.2012.143
   Wang C., 2015, Proc. SPIE Vis. Data Anal.
   Wang CL, 2008, IEEE T VIS COMPUT GR, V14, P1547, DOI 10.1109/TVCG.2008.140
   Wang C, 2008, IEEE T VIS COMPUT GR, V14, P590, DOI 10.1109/TVCG.2007.70628
   Wang CL, 2006, IEEE T VIS COMPUT GR, V12, P1029, DOI 10.1109/TVCG.2006.159
   Wang CL, 2007, IEEE T VIS COMPUT GR, V13, P122, DOI 10.1109/TVCG.2007.15
   Wang CL, 2011, IEEE PAC VIS SYMP, P99, DOI 10.1109/PACIFICVIS.2011.5742378
   Wang CL, 2005, VOLUME GRAPHICS 2005, P11
   Wang CL, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P259
   Wang M., 2016, P IST C VIS DAT AN
   Wang M., 2013, FLOWVISUAL DES EV VI
NR 52
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD SEP
PY 2020
VL 4
IS 3
BP 63
EP 68
DI 10.1016/j.visinf.2020.09.001
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KP
UT WOS:000658192600007
OA gold
DA 2024-07-18
ER

PT J
AU Cao, RC
   Dey, S
   Cunningham, A
   Walsh, J
   Smith, RT
   Zucco, JE
   Thomas, BH
AF Cao, Ruochen
   Dey, Subrata
   Cunningham, Andrew
   Walsh, James
   Smith, Ross T.
   Zucco, Joanne E.
   Thomas, Bruce H.
TI Examining the use of narrative constructs in data videos
SO VISUAL INFORMATICS
LA English
DT Article
DE Narrative visualization; Data videos; Taxonomy; Narrative approaches
ID VISUALIZATION; CONSTRAINTS
AB Data videos are a highly impactful method of communication and are becoming a prevalent medium for communicating information. While the majority of current research focuses on the cinematic aspects of data videos, very little is known about the narrative methodologies involved. This paper presents our insights derived from an initial exploration of this area. We present a taxonomy based on the analysis of 70 existing data videos examining their narrative and visual approaches. We propose that our taxonomy can be used to explain the characteristics or design of data videos. Applying this taxonomy, we present our observations, including the trend of popular technologies applied in current data videos, the under-utilization of promising methods, and highlight research opportunities in the field. (C) 2019 Zhejiang University and Zhejiang University Press. Published by Elsevier B.V.
C1 [Cao, Ruochen; Cunningham, Andrew; Walsh, James; Smith, Ross T.; Zucco, Joanne E.; Thomas, Bruce H.] Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA, Australia.
   [Dey, Subrata] Univ Adelaide, Dept Media, Adelaide, SA, Australia.
C3 University of South Australia; University of Adelaide
RP Cao, RC (corresponding author), Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA, Australia.
EM ruochen.cao@mymail.unisa.edu.au; subrata.dey@adelaide.edu.au;
   andrew.cunningham@unisa.edu.au; james.walsh@unisa.edu.au;
   ross.t.smith@unisa.edu.au; joanne.zucco@unisa.edu.au;
   bruce.thomas@unisa.edu.au
RI Cunningham, Andrew/AAI-2907-2021; Smith, Ross/L-4790-2016; Zucco,
   Joanne/F-4195-2013; Thomas, Bruce/A-1470-2008
OI Cunningham, Andrew/0000-0003-2536-3011; Walsh,
   James/0000-0002-4822-990X; Smith, Ross/0000-0002-9044-9199; Zucco,
   Joanne/0000-0003-0310-6364; DEY, SUBRATA/0000-0002-2353-174X; Cao,
   Ruochen/0000-0002-0312-8355; Thomas, Bruce/0000-0002-9148-085X
FU Data to Decisions Cooperative Research Centre - Australian Commonwealth
   Government's Cooperative Research Centres Programme
FX This work has been supported by the Data to Decisions Cooperative
   Research Centre whose activities are funded by the Australian
   Commonwealth Government's Cooperative Research Centres Programme.
CR Abercrombie Nicholas., 1996, TELEVISION SOC
   Allen R.C., 1989, REMOTE CONTROL TELEV, P44
   Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 1995, MEDIA DISCOURSE
   Baber C., 2011, VAW2011, P7
   Bach B, 2018, Data-Driven Storytelling, P107, DOI DOI 10.1201/9781315281575-5
   Bastiras J, 2017, 2017 INTERNATIONAL SYMPOSIUM ON BIG DATA VISUAL ANALYTICS (BDVA), P17
   Beaver FrankE., 1983, Dictionary of Film Terms
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boyd-Bowman S., 1981, POPULAR TELEVISION F
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Cao R., 2017, BIG DATA VISUAL ANAL
   Card SK, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P92, DOI 10.1109/INFVIS.1997.636792
   Chandler D., 1997, An introduction to genre theory
   Chevalier N. H., 2016, P INT WORK C ADV VIS, P280
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Claes S, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P833, DOI 10.1145/3064663.3064684
   Cohn N, 2013, COGNITIVE SCI, V37, P413, DOI 10.1111/cogs.12016
   Figueiras A, 2014, IEEE INT CONF INF VI, P46, DOI 10.1109/IV.2014.79
   Friendly M., 2008, Handbook of Data Visualization, P15, DOI [10.1007/978-3-540-33037-0_2, DOI 10.1007/978-3-540-33037-0_2]
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Glaser B.G., 2017, SOCIOLOGY
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Herman David., 2011, Basic Elements of Narrative
   Hook J, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P43, DOI 10.1145/3210825.3210826
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Kelliher A, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.13
   Kosara R., 2017, Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short Papers, P31
   Liang J, 2010, IEEE INT CONF INF VI, P79, DOI 10.1109/IV.2010.21
   Marcengo A, 2014, ADV DATA MIN DATABAS, P236, DOI 10.4018/978-1-4666-4309-3.ch012
   Marriott K., 2018, IMMERSIVE ANAL, V11190
   Mayer RE, 2001, J EDUC PSYCHOL, V93, P187, DOI 10.1037//0022-0663.93.1.187
   Ojo A, 2018, DIGIT JOURNAL, V6, P693, DOI 10.1080/21670811.2017.1403291
   Orehovec Barbara., 2003, REVISITING READING W
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Rayner P., 2008, MEDIA STUDIES ESSENT
   Richards L., 2014, HANDLING QUALITATIVE
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Stam Robert., 2000, FILM THEORY ANTHOLOG
   Thudt Alice, 2017, Information Design Journal, V23, P48, DOI 10.1075/idj.23.1.07thu
   Wang YZH, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI [10.1145/2851141.2851145, 10.1145/3016078.2851145]
   Yu L, 2010, COMPUT GRAPH FORUM, V29, P2271, DOI 10.1111/j.1467-8659.2010.01816.x
NR 49
TC 15
Z9 17
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD MAR
PY 2020
VL 4
IS 1
BP 8
EP 22
DI 10.1016/j.visinf.2019.12.002
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SN3KB
UT WOS:000658191200002
OA gold
DA 2024-07-18
ER

PT J
AU Lu, JH
   Xie, X
   Lan, J
   Peng, TQ
   Wu, YC
   Chen, W
AF Lu, Junhua
   Xie, Xiao
   Lan, Ji
   Peng, Tai-Quan
   Wu, Yingcai
   Chen, Wei
TI BeXplorer: Visual analytics of dynamic interplay between communication
   and purchase behaviors in MMORPGs
SO VISUAL INFORMATICS
LA English
DT Article
DE Behavior visualization; Game visualization; MMORPG
AB With the rapid development of massively multiplayer online role-playing games (MMORPGs), a huge amount of fine-grained data on the in-game activities of players have been recorded by MMORPGs operators. These data provide considerable opportunities with which to study the dynamic interplay between player behaviors and investigate the roles of various social structures that underlie such interplay. However, it is challenging to model and visualize these behavioral data. This study proposes a novel influence-susceptible model to measure the dynamic interplay between behaviors. Based on this model, we introduce a new visual analytics system called BeXplorer. This system enables analysts to interactively explore the dynamic interplay between player purchase and communication behaviors and to examine the manner in which this interplay is bound by social structures where players are embedded. Three case studies and a task-based evaluation are conducted to demonstrate the effectiveness and applicability of our method. (C) 2019 Published by Elsevier B.V. on behalf of Zhejiang University and Zhejiang University Press.
C1 [Lu, Junhua; Xie, Xiao; Lan, Ji; Wu, Yingcai; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Peng, Tai-Quan] Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA.
C3 Zhejiang University; Michigan State University
RP Wu, YC; Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM akiori@zju.edu.cn; xxie@zju.edu.cn; lanjisteven@zju.edu.cn;
   pengtaiq@msu.edu; ycwu@zju.edu.cn; chenwei@zju.edu.cn
RI Furtado, Kássia/AAU-5007-2020; LAN, JI/M-2006-2018; Peng,
   Tai-Quan/B-3176-2011
OI Peng, Tai-Quan/0000-0002-2588-7491
FU National Natural Science Foundation of China [61772456, 61761136020,
   61502416]; NSFC-Zhejiang Joint Fund for the Integration of
   Industrialization and Informatization [U1609217]; Zhejiang Provincial
   Natural Science Foundation [LR18F020001]; 100 Talents Program of
   Zhejiang University
FX Yingcai Wu and Wei Chen are supported by National Natural Science
   Foundation of China (61772456, 61761136020, 61502416), NSFC-Zhejiang
   Joint Fund for the Integration of Industrialization and Informatization
   (U1609217), Zhejiang Provincial Natural Science Foundation
   (LR18F020001), and the 100 Talents Program of Zhejiang University.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   [Anonymous], APPL MULTIPLE REGRES
   Aral S, 2012, SCIENCE, V337, P337, DOI 10.1126/science.1215842
   BANERJEE AV, 1992, Q J ECON, V107, P797, DOI 10.2307/2118364
   Burt RS, 2014, RES SOCIOL ORGAN-RES, V40, P161, DOI 10.1108/S0733-558X(2014)0000040008
   Castronova E, 2009, NEW MEDIA SOC, V11, P685, DOI 10.1177/1461444809105346
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Easley D., 2010, Networks, Crowds, and Markets: Reasoning about a highly connected world, V8
   Golder SA, 2014, ANNU REV SOCIOL, V40, P129, DOI 10.1146/annurev-soc-071913-043145
   Gomez Rodriguez M., 2010, SIGKDD, P1019
   Havre S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P115, DOI 10.1109/INFVIS.2000.885098
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Hughes CM, 2017, COMPUT HUM BEHAV, V69, P386, DOI 10.1016/j.chb.2016.12.043
   Kossinets G, 2009, AM J SOCIOL, V115, P405, DOI 10.1086/599247
   Krueger R, 2016, IEEE PAC VIS SYMP, P176, DOI 10.1109/PACIFICVIS.2016.7465266
   Kuan YT, 2017, IEEE CONF VIS ANAL, P71, DOI 10.1109/VAST.2017.8585594
   Li Q, 2017, IEEE PAC VIS SYMP, P31, DOI 10.1109/PACIFICVIS.2017.8031576
   Li Q, 2017, IEEE T VIS COMPUT GR, V23, P211, DOI 10.1109/TVCG.2016.2598415
   Liu SX, 2016, IEEE T VIS COMPUT GR, V22, P2451, DOI 10.1109/TVCG.2015.2509990
   Luo DN, 2012, IEEE T VIS COMPUT GR, V18, P93, DOI 10.1109/TVCG.2010.225
   MARSDEN PV, 1993, SOCIOL METHOD RES, V22, P127, DOI 10.1177/0049124193022001006
   McElroy M.B., 1977, J ECONOMETRICS, V6, P381, DOI DOI 10.1016/0304-4076(77)90008-2
   Moretti E, 2011, REV ECON STUD, V78, P356, DOI 10.1093/restud/rdq014
   Muelder C, 2016, IEEE T VIS COMPUT GR, V22, P1694, DOI 10.1109/TVCG.2016.2534558
   Munzner T., 2014, VISUALIZATION ANAL D, P239
   Newman MEJ, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.208701
   Pao HK, 2010, IEEE T COMP INTEL AI, V2, P162, DOI 10.1109/TCIAIG.2010.2072506
   Prieto DF, 2015, IEEE PAC VIS SYMP, P123, DOI 10.1109/PACIFICVIS.2015.7156367
   RAPOPORT ANATOL, 1953, BULL MATH BIOPHYS, V15, P523, DOI 10.1007/BF02476440
   Rodriguez MG, 2014, NETW SCI, V2, P26, DOI 10.1017/nws.2014.3
   Shalizi CR, 2011, SOCIOL METHOD RES, V40, P211, DOI 10.1177/0049124111404820
   Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203
   SIMKIN D, 1987, J AM STAT ASSOC, V82, P454, DOI 10.2307/2289447
   Skau D, 2016, COMPUT GRAPH FORUM, V35, P121, DOI 10.1111/cgf.12888
   Sun GD, 2014, IEEE T VIS COMPUT GR, V20, P1753, DOI 10.1109/TVCG.2014.2346919
   SUPERDATA, 2015, MMO MARK REP 2015
   Szell M, 2010, P NATL ACAD SCI USA, V107, P13636, DOI 10.1073/pnas.1004008107
   Thawonmas R, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/906931
   Thom D, 2015, IEEE PAC VIS SYMP, P183, DOI 10.1109/PACIFICVIS.2015.7156376
   Ware C., 2012, INFORM VISUALIZATION, P199
   Wikipedia, 2017, NOV EFF
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Wu WC, 2018, IEEE PAC VIS SYMP, P140, DOI 10.1109/PacificVis.2018.00026
   Xu PP, 2013, IEEE T VIS COMPUT GR, V19, P2012, DOI 10.1109/TVCG.2013.221
   ZELLNER A, 1962, J AM STAT ASSOC, V57, P348, DOI 10.2307/2281644
NR 45
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-502X
J9 VIS INFORM
JI Vis. Inform.
PD JUN
PY 2019
VL 3
IS 2
BP 87
EP 101
DI 10.1016/j.visinf.2019.06.002
PG 15
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK0YK
UT WOS:000658189200004
OA gold
DA 2024-07-18
ER

EF